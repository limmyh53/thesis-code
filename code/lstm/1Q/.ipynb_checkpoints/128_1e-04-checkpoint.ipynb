{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/128_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-4\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 128 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 128 \n",
      "Learning rate = 1e-06 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-06\n",
      "Fold: 1  Epoch: 1  Training loss = 3.3170  Validation loss = 3.4857  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.3167  Validation loss = 3.4852  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.3164  Validation loss = 3.4846  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.3160  Validation loss = 3.4841  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.3157  Validation loss = 3.4835  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.3154  Validation loss = 3.4831  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.3151  Validation loss = 3.4826  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.3147  Validation loss = 3.4820  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.3144  Validation loss = 3.4814  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.3140  Validation loss = 3.4808  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.3137  Validation loss = 3.4803  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.3133  Validation loss = 3.4797  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.3130  Validation loss = 3.4792  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.3127  Validation loss = 3.4787  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.3124  Validation loss = 3.4783  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.3121  Validation loss = 3.4777  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.3118  Validation loss = 3.4772  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.3114  Validation loss = 3.4766  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.3111  Validation loss = 3.4761  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.3107  Validation loss = 3.4755  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.3103  Validation loss = 3.4748  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.3099  Validation loss = 3.4742  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.3094  Validation loss = 3.4734  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.3091  Validation loss = 3.4729  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.3088  Validation loss = 3.4724  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.3085  Validation loss = 3.4719  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.3081  Validation loss = 3.4713  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.3078  Validation loss = 3.4707  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.3074  Validation loss = 3.4701  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.3070  Validation loss = 3.4695  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.3067  Validation loss = 3.4690  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.3065  Validation loss = 3.4686  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.3062  Validation loss = 3.4682  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.3058  Validation loss = 3.4675  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.3055  Validation loss = 3.4670  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.3052  Validation loss = 3.4665  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.3048  Validation loss = 3.4658  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.3044  Validation loss = 3.4652  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.3041  Validation loss = 3.4647  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.3037  Validation loss = 3.4641  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.3034  Validation loss = 3.4635  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.3031  Validation loss = 3.4630  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.3028  Validation loss = 3.4626  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.3024  Validation loss = 3.4619  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.3020  Validation loss = 3.4613  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.3016  Validation loss = 3.4606  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.3012  Validation loss = 3.4601  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.3008  Validation loss = 3.4593  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.3003  Validation loss = 3.4586  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.2999  Validation loss = 3.4579  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.2996  Validation loss = 3.4574  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.2992  Validation loss = 3.4568  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.2988  Validation loss = 3.4561  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.2984  Validation loss = 3.4555  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.2980  Validation loss = 3.4547  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.2976  Validation loss = 3.4541  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.2972  Validation loss = 3.4535  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.2968  Validation loss = 3.4528  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.2964  Validation loss = 3.4521  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.2960  Validation loss = 3.4514  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.2956  Validation loss = 3.4508  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.2953  Validation loss = 3.4503  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.2949  Validation loss = 3.4496  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.2946  Validation loss = 3.4491  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.2943  Validation loss = 3.4487  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.2938  Validation loss = 3.4479  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.2935  Validation loss = 3.4474  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.2931  Validation loss = 3.4466  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.2927  Validation loss = 3.4461  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.2925  Validation loss = 3.4458  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.2923  Validation loss = 3.4453  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.2920  Validation loss = 3.4450  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.2918  Validation loss = 3.4445  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.2913  Validation loss = 3.4438  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.2910  Validation loss = 3.4433  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.2907  Validation loss = 3.4427  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.2904  Validation loss = 3.4423  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.2901  Validation loss = 3.4418  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.2898  Validation loss = 3.4414  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.2895  Validation loss = 3.4408  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.2892  Validation loss = 3.4403  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.2889  Validation loss = 3.4398  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.2885  Validation loss = 3.4391  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.2881  Validation loss = 3.4385  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.2879  Validation loss = 3.4381  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.2876  Validation loss = 3.4376  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.2871  Validation loss = 3.4369  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.2867  Validation loss = 3.4362  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.2864  Validation loss = 3.4357  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.2862  Validation loss = 3.4353  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.2859  Validation loss = 3.4349  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.2855  Validation loss = 3.4342  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.2851  Validation loss = 3.4336  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.2848  Validation loss = 3.4331  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.2844  Validation loss = 3.4324  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.2841  Validation loss = 3.4319  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.2838  Validation loss = 3.4315  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.2835  Validation loss = 3.4309  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.2832  Validation loss = 3.4304  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.2828  Validation loss = 3.4297  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.2824  Validation loss = 3.4291  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.2821  Validation loss = 3.4286  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.2818  Validation loss = 3.4282  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.2816  Validation loss = 3.4277  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.2813  Validation loss = 3.4272  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.2810  Validation loss = 3.4267  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.2807  Validation loss = 3.4263  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.2804  Validation loss = 3.4257  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.2800  Validation loss = 3.4251  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.2796  Validation loss = 3.4245  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.2792  Validation loss = 3.4238  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.2788  Validation loss = 3.4232  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.2785  Validation loss = 3.4226  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.2783  Validation loss = 3.4223  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.2780  Validation loss = 3.4217  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.2776  Validation loss = 3.4212  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.2774  Validation loss = 3.4207  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.2769  Validation loss = 3.4200  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.2766  Validation loss = 3.4194  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.2763  Validation loss = 3.4190  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.2759  Validation loss = 3.4184  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.2756  Validation loss = 3.4179  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.2754  Validation loss = 3.4174  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.2749  Validation loss = 3.4166  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.2745  Validation loss = 3.4159  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.2741  Validation loss = 3.4152  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.2737  Validation loss = 3.4147  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.2734  Validation loss = 3.4142  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.2729  Validation loss = 3.4133  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.2726  Validation loss = 3.4128  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.2723  Validation loss = 3.4123  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.2720  Validation loss = 3.4118  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.2715  Validation loss = 3.4111  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.2712  Validation loss = 3.4105  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.2709  Validation loss = 3.4101  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.2706  Validation loss = 3.4095  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.2703  Validation loss = 3.4090  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.2701  Validation loss = 3.4086  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.2697  Validation loss = 3.4080  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.2694  Validation loss = 3.4076  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.2690  Validation loss = 3.4068  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.2686  Validation loss = 3.4062  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.2684  Validation loss = 3.4058  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.2680  Validation loss = 3.4051  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.2677  Validation loss = 3.4046  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.2673  Validation loss = 3.4040  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.2671  Validation loss = 3.4036  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.2667  Validation loss = 3.4030  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.2663  Validation loss = 3.4024  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.2660  Validation loss = 3.4019  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.2658  Validation loss = 3.4015  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.2656  Validation loss = 3.4011  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.2652  Validation loss = 3.4006  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.2650  Validation loss = 3.4002  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.2647  Validation loss = 3.3997  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.2643  Validation loss = 3.3991  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.2640  Validation loss = 3.3985  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.2636  Validation loss = 3.3979  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.2633  Validation loss = 3.3974  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.2631  Validation loss = 3.3970  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.2628  Validation loss = 3.3965  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.2626  Validation loss = 3.3962  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.2623  Validation loss = 3.3957  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.2620  Validation loss = 3.3951  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.2616  Validation loss = 3.3945  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.2612  Validation loss = 3.3938  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.2609  Validation loss = 3.3934  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.2606  Validation loss = 3.3929  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.2603  Validation loss = 3.3923  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.2600  Validation loss = 3.3918  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.2596  Validation loss = 3.3912  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.2594  Validation loss = 3.3909  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.2591  Validation loss = 3.3903  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.2587  Validation loss = 3.3897  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.2583  Validation loss = 3.3890  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.2580  Validation loss = 3.3885  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.2577  Validation loss = 3.3879  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.2574  Validation loss = 3.3875  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.2570  Validation loss = 3.3868  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.2568  Validation loss = 3.3866  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.2565  Validation loss = 3.3859  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.2561  Validation loss = 3.3853  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.2558  Validation loss = 3.3848  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.2555  Validation loss = 3.3843  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.2551  Validation loss = 3.3835  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.2548  Validation loss = 3.3830  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.2544  Validation loss = 3.3824  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.2541  Validation loss = 3.3819  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.2538  Validation loss = 3.3814  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.2536  Validation loss = 3.3811  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.2532  Validation loss = 3.3804  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.2528  Validation loss = 3.3797  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.2523  Validation loss = 3.3789  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.2520  Validation loss = 3.3784  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.2516  Validation loss = 3.3777  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.2513  Validation loss = 3.3772  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.2509  Validation loss = 3.3766  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.2506  Validation loss = 3.3761  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.2503  Validation loss = 3.3754  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.2499  Validation loss = 3.3749  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.2496  Validation loss = 3.3744  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.2494  Validation loss = 3.3739  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.2491  Validation loss = 3.3734  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.2487  Validation loss = 3.3728  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.2483  Validation loss = 3.3722  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.2481  Validation loss = 3.3718  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.2477  Validation loss = 3.3712  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.2475  Validation loss = 3.3708  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.2472  Validation loss = 3.3703  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.2469  Validation loss = 3.3699  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.2467  Validation loss = 3.3694  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.2464  Validation loss = 3.3690  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.2461  Validation loss = 3.3685  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.2459  Validation loss = 3.3681  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.2455  Validation loss = 3.3675  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.2451  Validation loss = 3.3668  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.2447  Validation loss = 3.3662  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.2444  Validation loss = 3.3656  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.2440  Validation loss = 3.3650  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.2438  Validation loss = 3.3646  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.2435  Validation loss = 3.3641  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.2432  Validation loss = 3.3635  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.2429  Validation loss = 3.3630  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.2425  Validation loss = 3.3624  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.2422  Validation loss = 3.3620  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.2420  Validation loss = 3.3615  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.2416  Validation loss = 3.3609  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.2413  Validation loss = 3.3603  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.2410  Validation loss = 3.3598  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.2407  Validation loss = 3.3593  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.2404  Validation loss = 3.3589  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.2401  Validation loss = 3.3584  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.2398  Validation loss = 3.3577  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.2395  Validation loss = 3.3572  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.2391  Validation loss = 3.3566  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.2388  Validation loss = 3.3560  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.2384  Validation loss = 3.3555  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.2381  Validation loss = 3.3549  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.2376  Validation loss = 3.3541  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.2374  Validation loss = 3.3537  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.2371  Validation loss = 3.3531  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.2369  Validation loss = 3.3528  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.2365  Validation loss = 3.3522  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.2361  Validation loss = 3.3516  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.2358  Validation loss = 3.3509  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.2355  Validation loss = 3.3504  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.2351  Validation loss = 3.3498  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.2348  Validation loss = 3.3493  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.2343  Validation loss = 3.3485  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.2339  Validation loss = 3.3478  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.2337  Validation loss = 3.3474  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.2334  Validation loss = 3.3470  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.2333  Validation loss = 3.3467  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.2330  Validation loss = 3.3462  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.2326  Validation loss = 3.3456  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.2323  Validation loss = 3.3450  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.2319  Validation loss = 3.3444  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.2317  Validation loss = 3.3441  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.2313  Validation loss = 3.3433  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.2310  Validation loss = 3.3429  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.2307  Validation loss = 3.3424  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.2304  Validation loss = 3.3418  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.2301  Validation loss = 3.3413  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.2299  Validation loss = 3.3409  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.2294  Validation loss = 3.3401  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.2292  Validation loss = 3.3397  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.2289  Validation loss = 3.3393  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.2287  Validation loss = 3.3389  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.2284  Validation loss = 3.3385  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.2281  Validation loss = 3.3380  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.2278  Validation loss = 3.3374  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.2275  Validation loss = 3.3370  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.2272  Validation loss = 3.3364  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.2269  Validation loss = 3.3359  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.2266  Validation loss = 3.3353  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.2262  Validation loss = 3.3346  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.2259  Validation loss = 3.3342  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.2257  Validation loss = 3.3338  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.2254  Validation loss = 3.3333  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.2252  Validation loss = 3.3329  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.2250  Validation loss = 3.3327  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.2246  Validation loss = 3.3320  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.2243  Validation loss = 3.3315  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.2241  Validation loss = 3.3311  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.2239  Validation loss = 3.3308  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.2236  Validation loss = 3.3302  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.2233  Validation loss = 3.3298  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.2230  Validation loss = 3.3293  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.2228  Validation loss = 3.3289  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.2224  Validation loss = 3.3282  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.2221  Validation loss = 3.3277  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.2219  Validation loss = 3.3273  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.2215  Validation loss = 3.3267  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.2211  Validation loss = 3.3260  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.2208  Validation loss = 3.3255  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.2206  Validation loss = 3.3251  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.2203  Validation loss = 3.3247  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.2199  Validation loss = 3.3240  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.2197  Validation loss = 3.3236  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.2194  Validation loss = 3.3232  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.2192  Validation loss = 3.3228  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.2189  Validation loss = 3.3223  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.2187  Validation loss = 3.3219  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.2184  Validation loss = 3.3215  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.2180  Validation loss = 3.3208  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.2177  Validation loss = 3.3202  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.2174  Validation loss = 3.3198  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.2172  Validation loss = 3.3193  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.2169  Validation loss = 3.3189  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.2166  Validation loss = 3.3184  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.2164  Validation loss = 3.3179  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.2160  Validation loss = 3.3173  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.2158  Validation loss = 3.3169  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.2155  Validation loss = 3.3164  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.2151  Validation loss = 3.3158  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.2148  Validation loss = 3.3152  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.2145  Validation loss = 3.3147  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.2142  Validation loss = 3.3142  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.2138  Validation loss = 3.3136  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.2135  Validation loss = 3.3131  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.2134  Validation loss = 3.3128  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.2131  Validation loss = 3.3124  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.2127  Validation loss = 3.3118  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.2125  Validation loss = 3.3113  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.2122  Validation loss = 3.3108  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.2118  Validation loss = 3.3102  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.2115  Validation loss = 3.3096  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.2112  Validation loss = 3.3091  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.2109  Validation loss = 3.3086  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.2106  Validation loss = 3.3081  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.2104  Validation loss = 3.3077  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.2101  Validation loss = 3.3073  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.2098  Validation loss = 3.3068  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.2096  Validation loss = 3.3064  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.2093  Validation loss = 3.3059  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.2090  Validation loss = 3.3054  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.2088  Validation loss = 3.3050  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.2085  Validation loss = 3.3046  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 3.2083  Validation loss = 3.3042  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 3.2079  Validation loss = 3.3035  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 3.2075  Validation loss = 3.3028  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 3.2071  Validation loss = 3.3022  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 3.2068  Validation loss = 3.3015  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 3.2065  Validation loss = 3.3010  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 3.2063  Validation loss = 3.3007  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 3.2061  Validation loss = 3.3004  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 3.2057  Validation loss = 3.2996  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 3.2054  Validation loss = 3.2991  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 3.2052  Validation loss = 3.2988  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 3.2049  Validation loss = 3.2983  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 3.2046  Validation loss = 3.2978  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 3.2043  Validation loss = 3.2972  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 3.2040  Validation loss = 3.2967  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 3.2036  Validation loss = 3.2960  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 3.2033  Validation loss = 3.2955  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 3.2031  Validation loss = 3.2951  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 3.2028  Validation loss = 3.2946  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 3.2025  Validation loss = 3.2942  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 3.2022  Validation loss = 3.2935  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 3.2019  Validation loss = 3.2931  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 3.2016  Validation loss = 3.2925  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 3.2013  Validation loss = 3.2921  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 3.2011  Validation loss = 3.2917  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 3.2009  Validation loss = 3.2914  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 3.2007  Validation loss = 3.2910  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 3.2004  Validation loss = 3.2904  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 3.2001  Validation loss = 3.2898  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 3.1998  Validation loss = 3.2894  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 3.1995  Validation loss = 3.2889  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 3.1992  Validation loss = 3.2884  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 3.1989  Validation loss = 3.2879  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 3.1986  Validation loss = 3.2874  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 3.1984  Validation loss = 3.2869  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 3.1981  Validation loss = 3.2865  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 3.1977  Validation loss = 3.2857  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 3.1974  Validation loss = 3.2852  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 3.1971  Validation loss = 3.2848  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 3.1968  Validation loss = 3.2842  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 3.1965  Validation loss = 3.2836  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 3.1962  Validation loss = 3.2831  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 3.1959  Validation loss = 3.2827  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 3.1956  Validation loss = 3.2822  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 3.1953  Validation loss = 3.2817  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 3.1950  Validation loss = 3.2811  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 3.1947  Validation loss = 3.2806  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 3.1945  Validation loss = 3.2803  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 3.1943  Validation loss = 3.2799  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 3.1942  Validation loss = 3.2797  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 3.1939  Validation loss = 3.2793  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 3.1937  Validation loss = 3.2789  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 3.1934  Validation loss = 3.2783  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 3.1931  Validation loss = 3.2778  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 3.1928  Validation loss = 3.2773  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 3.1925  Validation loss = 3.2768  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 3.1921  Validation loss = 3.2761  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 3.1918  Validation loss = 3.2756  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 3.1915  Validation loss = 3.2751  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 3.1912  Validation loss = 3.2745  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 3.1908  Validation loss = 3.2739  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 3.1905  Validation loss = 3.2733  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 3.1901  Validation loss = 3.2727  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 3.1899  Validation loss = 3.2722  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 3.1897  Validation loss = 3.2718  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 3.1895  Validation loss = 3.2715  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 3.1891  Validation loss = 3.2709  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 3.1889  Validation loss = 3.2704  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 3.1886  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 3.1884  Validation loss = 3.2696  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 3.1881  Validation loss = 3.2692  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 3.1878  Validation loss = 3.2685  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 3.1875  Validation loss = 3.2681  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 3.1873  Validation loss = 3.2677  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 3.1869  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 3.1867  Validation loss = 3.2667  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 3.1865  Validation loss = 3.2664  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 3.1862  Validation loss = 3.2658  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 3.1859  Validation loss = 3.2653  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 3.1856  Validation loss = 3.2647  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 3.1852  Validation loss = 3.2640  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 3.1848  Validation loss = 3.2634  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 3.1845  Validation loss = 3.2629  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 3.1842  Validation loss = 3.2623  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 3.1839  Validation loss = 3.2618  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 3.1836  Validation loss = 3.2613  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 3.1833  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 3.1830  Validation loss = 3.2603  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 3.1828  Validation loss = 3.2599  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 3.1826  Validation loss = 3.2595  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 3.1823  Validation loss = 3.2590  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 3.1820  Validation loss = 3.2586  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 3.1818  Validation loss = 3.2581  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 3.1815  Validation loss = 3.2576  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 3.1812  Validation loss = 3.2570  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 3.1809  Validation loss = 3.2566  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 3.1806  Validation loss = 3.2560  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 3.1803  Validation loss = 3.2555  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 3.1800  Validation loss = 3.2549  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 3.1797  Validation loss = 3.2545  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 3.1795  Validation loss = 3.2540  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 3.1792  Validation loss = 3.2535  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 3.1788  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 3.1785  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 3.1783  Validation loss = 3.2519  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 3.1780  Validation loss = 3.2515  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 3.1777  Validation loss = 3.2510  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 3.1775  Validation loss = 3.2506  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 3.1772  Validation loss = 3.2500  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 3.1769  Validation loss = 3.2495  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 3.1766  Validation loss = 3.2489  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 3.1763  Validation loss = 3.2485  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 3.1760  Validation loss = 3.2480  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 3.1757  Validation loss = 3.2475  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 3.1755  Validation loss = 3.2470  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 3.1752  Validation loss = 3.2466  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 3.1750  Validation loss = 3.2461  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 3.1747  Validation loss = 3.2456  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 3.1743  Validation loss = 3.2450  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 3.1740  Validation loss = 3.2444  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 3.1737  Validation loss = 3.2439  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 3.1734  Validation loss = 3.2433  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 3.1732  Validation loss = 3.2430  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 3.1729  Validation loss = 3.2424  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 3.1727  Validation loss = 3.2421  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 3.1724  Validation loss = 3.2416  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 3.1721  Validation loss = 3.2410  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 3.1718  Validation loss = 3.2404  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 3.1715  Validation loss = 3.2400  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 3.1712  Validation loss = 3.2394  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 3.1708  Validation loss = 3.2388  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 3.1705  Validation loss = 3.2382  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 3.1700  Validation loss = 3.2374  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 3.1697  Validation loss = 3.2368  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 3.1695  Validation loss = 3.2364  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 3.1692  Validation loss = 3.2358  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 3.1689  Validation loss = 3.2353  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 3.1686  Validation loss = 3.2348  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 3.1683  Validation loss = 3.2343  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 3.1679  Validation loss = 3.2336  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 3.1676  Validation loss = 3.2331  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 3.1673  Validation loss = 3.2325  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 3.1669  Validation loss = 3.2318  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 3.1666  Validation loss = 3.2313  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 3.1664  Validation loss = 3.2309  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 3.1660  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 3.1657  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 3.1655  Validation loss = 3.2293  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 3.1653  Validation loss = 3.2289  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 3.1650  Validation loss = 3.2284  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 3.1646  Validation loss = 3.2278  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 3.1644  Validation loss = 3.2275  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 3.1641  Validation loss = 3.2270  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 3.1639  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 3.1637  Validation loss = 3.2262  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 3.1634  Validation loss = 3.2257  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 3.1631  Validation loss = 3.2252  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 3.1628  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 3.1625  Validation loss = 3.2241  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 3.1622  Validation loss = 3.2235  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 3.1620  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 3.1617  Validation loss = 3.2227  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 3.0988  Validation loss = 3.1439  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 3.0986  Validation loss = 3.1434  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 3.0982  Validation loss = 3.1429  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 3.0978  Validation loss = 3.1423  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 3.0976  Validation loss = 3.1420  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 3.0972  Validation loss = 3.1414  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 3.0969  Validation loss = 3.1409  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 3.0966  Validation loss = 3.1405  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 3.0963  Validation loss = 3.1400  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 3.0961  Validation loss = 3.1397  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 3.0957  Validation loss = 3.1392  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 3.0953  Validation loss = 3.1386  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 3.0950  Validation loss = 3.1381  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 3.0947  Validation loss = 3.1378  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 3.0944  Validation loss = 3.1372  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 3.0940  Validation loss = 3.1367  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 3.0937  Validation loss = 3.1362  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 3.0935  Validation loss = 3.1358  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 3.0932  Validation loss = 3.1354  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 3.0928  Validation loss = 3.1349  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 3.0926  Validation loss = 3.1345  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 3.0923  Validation loss = 3.1341  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 3.0920  Validation loss = 3.1337  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 3.0918  Validation loss = 3.1333  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 3.0915  Validation loss = 3.1329  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 3.0913  Validation loss = 3.1326  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 3.0909  Validation loss = 3.1320  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 3.0905  Validation loss = 3.1314  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 3.0902  Validation loss = 3.1310  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 3.0899  Validation loss = 3.1305  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 3.0896  Validation loss = 3.1301  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 3.0892  Validation loss = 3.1295  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 3.0890  Validation loss = 3.1291  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 3.0887  Validation loss = 3.1287  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 3.0885  Validation loss = 3.1284  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 3.0882  Validation loss = 3.1280  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 3.0879  Validation loss = 3.1275  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 3.0876  Validation loss = 3.1270  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 3.0872  Validation loss = 3.1265  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 3.0870  Validation loss = 3.1262  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 3.0867  Validation loss = 3.1257  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 3.0865  Validation loss = 3.1253  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 3.0861  Validation loss = 3.1248  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 3.0858  Validation loss = 3.1244  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 3.0856  Validation loss = 3.1240  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 3.0852  Validation loss = 3.1235  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 3.0848  Validation loss = 3.1228  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 3.0845  Validation loss = 3.1225  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 3.0842  Validation loss = 3.1220  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 3.0839  Validation loss = 3.1216  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 3.0836  Validation loss = 3.1211  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 3.0834  Validation loss = 3.1208  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 3.0831  Validation loss = 3.1203  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 3.0828  Validation loss = 3.1198  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 3.0825  Validation loss = 3.1194  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 3.0821  Validation loss = 3.1188  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 3.0818  Validation loss = 3.1184  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 3.0816  Validation loss = 3.1180  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 3.0812  Validation loss = 3.1174  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 3.0809  Validation loss = 3.1170  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 3.0806  Validation loss = 3.1164  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 3.0804  Validation loss = 3.1161  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 3.0800  Validation loss = 3.1156  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 3.0798  Validation loss = 3.1153  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 3.0795  Validation loss = 3.1149  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 3.0792  Validation loss = 3.1145  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 3.0790  Validation loss = 3.1142  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 3.0786  Validation loss = 3.1136  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 3.0784  Validation loss = 3.1133  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 3.0781  Validation loss = 3.1128  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 3.0778  Validation loss = 3.1124  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 3.0776  Validation loss = 3.1120  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 3.0774  Validation loss = 3.1117  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 3.0772  Validation loss = 3.1114  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 3.0769  Validation loss = 3.1110  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 3.0767  Validation loss = 3.1106  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 3.0764  Validation loss = 3.1102  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 3.0761  Validation loss = 3.1096  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 3.0757  Validation loss = 3.1092  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 3.0755  Validation loss = 3.1088  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 3.0752  Validation loss = 3.1084  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 3.0749  Validation loss = 3.1079  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 3.0746  Validation loss = 3.1075  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 3.0744  Validation loss = 3.1071  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 3.0741  Validation loss = 3.1067  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 3.0738  Validation loss = 3.1062  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 3.0735  Validation loss = 3.1058  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 3.0732  Validation loss = 3.1053  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 3.0729  Validation loss = 3.1048  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 3.0726  Validation loss = 3.1045  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 3.0723  Validation loss = 3.1040  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 3.0720  Validation loss = 3.1036  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 3.0718  Validation loss = 3.1032  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 3.0714  Validation loss = 3.1026  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 3.0711  Validation loss = 3.1022  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 3.0708  Validation loss = 3.1017  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 3.0704  Validation loss = 3.1012  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 3.0702  Validation loss = 3.1009  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 3.0699  Validation loss = 3.1005  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 3.0696  Validation loss = 3.0999  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 3.0694  Validation loss = 3.0996  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 3.0691  Validation loss = 3.0992  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 3.0688  Validation loss = 3.0988  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 3.0685  Validation loss = 3.0983  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 3.0682  Validation loss = 3.0979  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 3.0679  Validation loss = 3.0974  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 3.0675  Validation loss = 3.0969  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 3.0673  Validation loss = 3.0965  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 3.0670  Validation loss = 3.0961  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 3.0668  Validation loss = 3.0957  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 3.0664  Validation loss = 3.0952  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 3.0661  Validation loss = 3.0947  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 3.0659  Validation loss = 3.0944  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 3.0657  Validation loss = 3.0941  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 3.0655  Validation loss = 3.0938  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 3.0652  Validation loss = 3.0933  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 3.0648  Validation loss = 3.0928  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 3.0646  Validation loss = 3.0924  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 3.0643  Validation loss = 3.0920  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 3.0641  Validation loss = 3.0917  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 3.0639  Validation loss = 3.0914  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 3.0635  Validation loss = 3.0908  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 3.0632  Validation loss = 3.0903  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 3.0628  Validation loss = 3.0897  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 3.0625  Validation loss = 3.0892  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 3.0622  Validation loss = 3.0888  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 3.0619  Validation loss = 3.0883  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 3.0617  Validation loss = 3.0879  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 3.0614  Validation loss = 3.0875  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 3.0612  Validation loss = 3.0871  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 3.0609  Validation loss = 3.0867  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 3.0606  Validation loss = 3.0863  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 3.0603  Validation loss = 3.0859  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 3.0600  Validation loss = 3.0854  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 3.0598  Validation loss = 3.0851  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 3.0595  Validation loss = 3.0846  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 3.0590  Validation loss = 3.0839  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 3.0588  Validation loss = 3.0835  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 3.0586  Validation loss = 3.0832  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 3.0584  Validation loss = 3.0829  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 3.0581  Validation loss = 3.0824  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 3.0578  Validation loss = 3.0821  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 3.0576  Validation loss = 3.0816  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 3.0574  Validation loss = 3.0813  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 3.0571  Validation loss = 3.0809  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 3.0568  Validation loss = 3.0804  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 3.0565  Validation loss = 3.0799  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 3.0562  Validation loss = 3.0794  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 3.0559  Validation loss = 3.0790  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 3.0557  Validation loss = 3.0786  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 3.0555  Validation loss = 3.0783  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 3.0552  Validation loss = 3.0779  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 3.0550  Validation loss = 3.0776  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 3.0547  Validation loss = 3.0772  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 3.0545  Validation loss = 3.0769  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 3.0543  Validation loss = 3.0765  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 3.0540  Validation loss = 3.0761  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 3.0537  Validation loss = 3.0756  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 3.0534  Validation loss = 3.0752  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 3.0531  Validation loss = 3.0747  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 3.0528  Validation loss = 3.0743  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 3.0526  Validation loss = 3.0739  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 3.0522  Validation loss = 3.0734  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 3.0520  Validation loss = 3.0730  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 3.0516  Validation loss = 3.0725  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 3.0514  Validation loss = 3.0721  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 3.0512  Validation loss = 3.0717  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 3.0509  Validation loss = 3.0713  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 3.0507  Validation loss = 3.0709  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 3.0504  Validation loss = 3.0705  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 3.0501  Validation loss = 3.0700  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 3.0499  Validation loss = 3.0697  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 3.0495  Validation loss = 3.0692  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 3.0492  Validation loss = 3.0688  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 3.0490  Validation loss = 3.0684  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 3.0488  Validation loss = 3.0680  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 3.0484  Validation loss = 3.0675  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 3.0481  Validation loss = 3.0670  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 3.0478  Validation loss = 3.0666  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 3.0476  Validation loss = 3.0662  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 3.0473  Validation loss = 3.0658  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 3.0471  Validation loss = 3.0655  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 3.0468  Validation loss = 3.0650  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 3.0466  Validation loss = 3.0646  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 3.0462  Validation loss = 3.0640  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 3.0459  Validation loss = 3.0635  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 3.0455  Validation loss = 3.0630  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 3.0452  Validation loss = 3.0626  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 3.0450  Validation loss = 3.0621  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 3.0445  Validation loss = 3.0615  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 3.0443  Validation loss = 3.0611  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 3.0440  Validation loss = 3.0607  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 3.0437  Validation loss = 3.0602  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 3.0434  Validation loss = 3.0597  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 3.0432  Validation loss = 3.0594  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 3.0429  Validation loss = 3.0590  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 3.0427  Validation loss = 3.0586  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 3.0424  Validation loss = 3.0582  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 3.0421  Validation loss = 3.0577  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 3.0418  Validation loss = 3.0573  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 3.0415  Validation loss = 3.0569  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 3.0412  Validation loss = 3.0564  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 3.0409  Validation loss = 3.0559  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 3.0406  Validation loss = 3.0555  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 3.0404  Validation loss = 3.0552  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 3.0401  Validation loss = 3.0548  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 3.0399  Validation loss = 3.0544  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 3.0396  Validation loss = 3.0540  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 3.0394  Validation loss = 3.0536  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 3.0390  Validation loss = 3.0530  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 3.0388  Validation loss = 3.0527  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 3.0386  Validation loss = 3.0523  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 3.0382  Validation loss = 3.0517  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 3.0379  Validation loss = 3.0514  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 3.0376  Validation loss = 3.0509  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 3.0373  Validation loss = 3.0504  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 3.0370  Validation loss = 3.0499  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 3.0368  Validation loss = 3.0495  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 3.0364  Validation loss = 3.0490  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 3.0361  Validation loss = 3.0486  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 3.0359  Validation loss = 3.0483  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 3.0356  Validation loss = 3.0478  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 3.0353  Validation loss = 3.0473  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 3.0351  Validation loss = 3.0469  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 3.0348  Validation loss = 3.0464  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 3.0345  Validation loss = 3.0461  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 3.0343  Validation loss = 3.0457  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 3.0341  Validation loss = 3.0453  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 3.0337  Validation loss = 3.0448  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 3.0335  Validation loss = 3.0444  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 3.0331  Validation loss = 3.0439  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 3.0328  Validation loss = 3.0433  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 3.0325  Validation loss = 3.0429  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 3.0322  Validation loss = 3.0425  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 3.0320  Validation loss = 3.0421  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 3.0317  Validation loss = 3.0416  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 3.0315  Validation loss = 3.0413  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 3.0312  Validation loss = 3.0409  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 3.0310  Validation loss = 3.0405  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 3.0307  Validation loss = 3.0400  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 3.0304  Validation loss = 3.0396  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 3.0301  Validation loss = 3.0392  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 3.0298  Validation loss = 3.0387  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 3.0295  Validation loss = 3.0382  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 3.0292  Validation loss = 3.0377  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 3.0289  Validation loss = 3.0374  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 3.0286  Validation loss = 3.0369  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 3.0284  Validation loss = 3.0365  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 3.0282  Validation loss = 3.0362  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 3.0278  Validation loss = 3.0357  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 3.0276  Validation loss = 3.0353  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 3.0273  Validation loss = 3.0348  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 3.0271  Validation loss = 3.0344  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 3.0268  Validation loss = 3.0340  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 3.0265  Validation loss = 3.0335  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 3.0262  Validation loss = 3.0330  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 3.0259  Validation loss = 3.0325  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 3.0254  Validation loss = 3.0318  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 3.0251  Validation loss = 3.0313  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 3.0247  Validation loss = 3.0308  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 3.0245  Validation loss = 3.0305  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 3.0242  Validation loss = 3.0299  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 3.0238  Validation loss = 3.0293  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 3.0235  Validation loss = 3.0289  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 3.0231  Validation loss = 3.0283  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 3.0229  Validation loss = 3.0279  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 3.0226  Validation loss = 3.0275  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 3.0224  Validation loss = 3.0272  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 3.0222  Validation loss = 3.0268  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 3.0220  Validation loss = 3.0264  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 3.0217  Validation loss = 3.0260  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 3.0215  Validation loss = 3.0256  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 3.0212  Validation loss = 3.0253  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 3.0210  Validation loss = 3.0248  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 3.0207  Validation loss = 3.0244  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 3.0204  Validation loss = 3.0240  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 3.0202  Validation loss = 3.0237  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 3.0200  Validation loss = 3.0233  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 3.0197  Validation loss = 3.0229  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 3.0195  Validation loss = 3.0226  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 3.0192  Validation loss = 3.0221  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 3.0189  Validation loss = 3.0216  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 3.0186  Validation loss = 3.0212  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 3.0183  Validation loss = 3.0207  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 3.0181  Validation loss = 3.0204  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 3.0179  Validation loss = 3.0200  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 3.0176  Validation loss = 3.0195  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 3.0172  Validation loss = 3.0190  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 3.0170  Validation loss = 3.0186  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 3.0167  Validation loss = 3.0182  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 3.0165  Validation loss = 3.0178  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 3.0161  Validation loss = 3.0173  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 3.0159  Validation loss = 3.0169  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 3.0157  Validation loss = 3.0165  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 3.0155  Validation loss = 3.0162  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 3.0152  Validation loss = 3.0158  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 3.0149  Validation loss = 3.0153  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 3.0147  Validation loss = 3.0150  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 3.0145  Validation loss = 3.0146  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 3.0142  Validation loss = 3.0142  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 3.0139  Validation loss = 3.0137  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 3.0136  Validation loss = 3.0133  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 3.0133  Validation loss = 3.0128  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 3.0130  Validation loss = 3.0123  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 3.0126  Validation loss = 3.0118  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 3.0124  Validation loss = 3.0115  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 3.0122  Validation loss = 3.0111  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 3.0120  Validation loss = 3.0107  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 3.0117  Validation loss = 3.0104  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 3.0115  Validation loss = 3.0100  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 3.0113  Validation loss = 3.0097  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 3.0110  Validation loss = 3.0092  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 3.0107  Validation loss = 3.0088  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 3.0104  Validation loss = 3.0083  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 3.0100  Validation loss = 3.0078  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 3.0097  Validation loss = 3.0073  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 3.0094  Validation loss = 3.0068  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 3.0091  Validation loss = 3.0064  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 3.0088  Validation loss = 3.0059  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 3.0086  Validation loss = 3.0056  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 3.0085  Validation loss = 3.0053  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 3.0082  Validation loss = 3.0049  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 3.0079  Validation loss = 3.0044  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 3.0076  Validation loss = 3.0040  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 3.0074  Validation loss = 3.0037  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 3.0071  Validation loss = 3.0032  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 3.0069  Validation loss = 3.0029  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 3.0066  Validation loss = 3.0024  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 3.0064  Validation loss = 3.0020  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 3.0061  Validation loss = 3.0017  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 3.0059  Validation loss = 3.0013  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 3.0057  Validation loss = 3.0010  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 3.0054  Validation loss = 3.0006  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 3.0052  Validation loss = 3.0003  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 3.0050  Validation loss = 3.0000  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 3.0048  Validation loss = 2.9996  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 3.0046  Validation loss = 2.9992  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 3.0044  Validation loss = 2.9989  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 3.0042  Validation loss = 2.9985  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 3.0038  Validation loss = 2.9981  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 3.0036  Validation loss = 2.9977  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 3.0034  Validation loss = 2.9973  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 3.0031  Validation loss = 2.9969  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 3.0029  Validation loss = 2.9965  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 3.0026  Validation loss = 2.9961  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 3.0023  Validation loss = 2.9956  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 3.0021  Validation loss = 2.9952  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 3.0018  Validation loss = 2.9948  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 3.0016  Validation loss = 2.9945  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 3.0014  Validation loss = 2.9941  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 3.0011  Validation loss = 2.9937  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 3.0008  Validation loss = 2.9933  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 3.0006  Validation loss = 2.9929  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 3.0002  Validation loss = 2.9924  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 3.0000  Validation loss = 2.9920  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.9998  Validation loss = 2.9917  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.9995  Validation loss = 2.9913  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.9993  Validation loss = 2.9909  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.9990  Validation loss = 2.9905  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.9988  Validation loss = 2.9900  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.9985  Validation loss = 2.9896  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.9983  Validation loss = 2.9892  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.9980  Validation loss = 2.9889  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.9977  Validation loss = 2.9884  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.9974  Validation loss = 2.9878  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.9971  Validation loss = 2.9874  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.9969  Validation loss = 2.9870  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.9966  Validation loss = 2.9866  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.9964  Validation loss = 2.9862  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.9960  Validation loss = 2.9857  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.9957  Validation loss = 2.9852  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.9954  Validation loss = 2.9848  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.9952  Validation loss = 2.9845  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.9948  Validation loss = 2.9839  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.9945  Validation loss = 2.9834  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.9943  Validation loss = 2.9830  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.9941  Validation loss = 2.9827  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.9939  Validation loss = 2.9824  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.9937  Validation loss = 2.9820  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.9935  Validation loss = 2.9817  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.9932  Validation loss = 2.9813  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.9930  Validation loss = 2.9809  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.9927  Validation loss = 2.9805  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.9925  Validation loss = 2.9802  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.9923  Validation loss = 2.9798  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.9920  Validation loss = 2.9794  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.9917  Validation loss = 2.9789  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.9915  Validation loss = 2.9785  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.9910  Validation loss = 2.9778  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.9907  Validation loss = 2.9773  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.9905  Validation loss = 2.9770  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.9902  Validation loss = 2.9765  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.9900  Validation loss = 2.9761  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.9897  Validation loss = 2.9757  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.9895  Validation loss = 2.9755  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.9893  Validation loss = 2.9751  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.9890  Validation loss = 2.9747  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.9889  Validation loss = 2.9744  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.9886  Validation loss = 2.9739  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.9883  Validation loss = 2.9734  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.9880  Validation loss = 2.9730  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.9878  Validation loss = 2.9727  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.9876  Validation loss = 2.9723  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.9873  Validation loss = 2.9720  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.9871  Validation loss = 2.9715  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.9869  Validation loss = 2.9712  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.9867  Validation loss = 2.9709  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.9863  Validation loss = 2.9703  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.9860  Validation loss = 2.9698  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.9859  Validation loss = 2.9696  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.9857  Validation loss = 2.9693  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.9853  Validation loss = 2.9687  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.9851  Validation loss = 2.9684  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.9849  Validation loss = 2.9680  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.9847  Validation loss = 2.9678  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.9845  Validation loss = 2.9675  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.9842  Validation loss = 2.9670  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.9840  Validation loss = 2.9666  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.9837  Validation loss = 2.9662  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.9835  Validation loss = 2.9659  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.9833  Validation loss = 2.9655  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.9831  Validation loss = 2.9651  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.9828  Validation loss = 2.9647  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.9825  Validation loss = 2.9643  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.9823  Validation loss = 2.9639  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.9820  Validation loss = 2.9635  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.9818  Validation loss = 2.9631  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.9816  Validation loss = 2.9627  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.9812  Validation loss = 2.9621  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.9809  Validation loss = 2.9616  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.9806  Validation loss = 2.9612  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.9804  Validation loss = 2.9608  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.9802  Validation loss = 2.9605  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.9799  Validation loss = 2.9600  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.9797  Validation loss = 2.9597  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.9795  Validation loss = 2.9593  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.9792  Validation loss = 2.9590  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.9790  Validation loss = 2.9585  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.9787  Validation loss = 2.9582  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.9786  Validation loss = 2.9579  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.9783  Validation loss = 2.9575  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.9781  Validation loss = 2.9572  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.9778  Validation loss = 2.9567  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.9776  Validation loss = 2.9563  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.9774  Validation loss = 2.9560  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.9772  Validation loss = 2.9557  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.9769  Validation loss = 2.9552  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.9766  Validation loss = 2.9547  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.9763  Validation loss = 2.9542  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.9761  Validation loss = 2.9539  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.9759  Validation loss = 2.9536  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.9757  Validation loss = 2.9533  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.9755  Validation loss = 2.9530  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.9752  Validation loss = 2.9525  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.9749  Validation loss = 2.9520  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.9746  Validation loss = 2.9516  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.9744  Validation loss = 2.9512  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.9740  Validation loss = 2.9506  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.9739  Validation loss = 2.9503  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.9736  Validation loss = 2.9499  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.9733  Validation loss = 2.9493  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.9729  Validation loss = 2.9488  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.9727  Validation loss = 2.9484  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.9724  Validation loss = 2.9480  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.9722  Validation loss = 2.9476  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.9718  Validation loss = 2.9471  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.9715  Validation loss = 2.9465  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.9712  Validation loss = 2.9461  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.9710  Validation loss = 2.9458  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.9708  Validation loss = 2.9455  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.9706  Validation loss = 2.9451  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.9704  Validation loss = 2.9448  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.9701  Validation loss = 2.9443  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.9699  Validation loss = 2.9440  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.9698  Validation loss = 2.9438  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.9696  Validation loss = 2.9434  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.9694  Validation loss = 2.9431  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.9690  Validation loss = 2.9426  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.9687  Validation loss = 2.9421  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.9684  Validation loss = 2.9415  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.9682  Validation loss = 2.9412  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.9680  Validation loss = 2.9409  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.9677  Validation loss = 2.9405  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.9675  Validation loss = 2.9401  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.9671  Validation loss = 2.9396  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.9668  Validation loss = 2.9391  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.9665  Validation loss = 2.9385  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.9663  Validation loss = 2.9381  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.9661  Validation loss = 2.9378  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.9659  Validation loss = 2.9375  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.9656  Validation loss = 2.9371  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.9654  Validation loss = 2.9368  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.9652  Validation loss = 2.9365  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.9650  Validation loss = 2.9361  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.9648  Validation loss = 2.9359  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.9646  Validation loss = 2.9354  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.9643  Validation loss = 2.9349  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.9640  Validation loss = 2.9345  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.9638  Validation loss = 2.9342  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.9636  Validation loss = 2.9339  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.9782  Validation loss = 4.1867  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.9780  Validation loss = 4.1863  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.9778  Validation loss = 4.1859  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.9776  Validation loss = 4.1856  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.9774  Validation loss = 4.1852  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.9772  Validation loss = 4.1849  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.9770  Validation loss = 4.1846  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.9768  Validation loss = 4.1842  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.9765  Validation loss = 4.1839  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.9763  Validation loss = 4.1834  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.9760  Validation loss = 4.1830  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.9758  Validation loss = 4.1827  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.9756  Validation loss = 4.1823  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.9754  Validation loss = 4.1819  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.9751  Validation loss = 4.1815  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.9749  Validation loss = 4.1811  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.9747  Validation loss = 4.1807  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.9745  Validation loss = 4.1803  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.9742  Validation loss = 4.1800  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.9740  Validation loss = 4.1796  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.9738  Validation loss = 4.1792  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.9735  Validation loss = 4.1787  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.9733  Validation loss = 4.1783  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.9730  Validation loss = 4.1779  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.9728  Validation loss = 4.1775  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.9725  Validation loss = 4.1770  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.9723  Validation loss = 4.1767  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.9721  Validation loss = 4.1763  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.9718  Validation loss = 4.1759  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.9716  Validation loss = 4.1755  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.9714  Validation loss = 4.1751  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.9712  Validation loss = 4.1747  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.9709  Validation loss = 4.1743  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.9707  Validation loss = 4.1739  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.9704  Validation loss = 4.1735  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.9702  Validation loss = 4.1731  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.9700  Validation loss = 4.1727  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.9697  Validation loss = 4.1723  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.9695  Validation loss = 4.1719  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.9693  Validation loss = 4.1715  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.9690  Validation loss = 4.1711  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.9688  Validation loss = 4.1708  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.9686  Validation loss = 4.1704  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.9684  Validation loss = 4.1700  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.9681  Validation loss = 4.1696  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.9679  Validation loss = 4.1691  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.9677  Validation loss = 4.1688  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.9675  Validation loss = 4.1685  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.9673  Validation loss = 4.1682  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.9671  Validation loss = 4.1678  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.9668  Validation loss = 4.1674  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.9666  Validation loss = 4.1670  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.9664  Validation loss = 4.1666  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.9661  Validation loss = 4.1661  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.9659  Validation loss = 4.1658  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.9657  Validation loss = 4.1654  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.9655  Validation loss = 4.1651  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.9653  Validation loss = 4.1647  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.9651  Validation loss = 4.1644  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.9648  Validation loss = 4.1640  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.9646  Validation loss = 4.1635  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.9644  Validation loss = 4.1632  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.9642  Validation loss = 4.1628  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.9639  Validation loss = 4.1623  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.9637  Validation loss = 4.1619  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.9634  Validation loss = 4.1615  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.9632  Validation loss = 4.1611  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.9629  Validation loss = 4.1606  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.9627  Validation loss = 4.1602  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.9624  Validation loss = 4.1598  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.9622  Validation loss = 4.1594  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.9620  Validation loss = 4.1590  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.9617  Validation loss = 4.1586  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.9615  Validation loss = 4.1582  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.9613  Validation loss = 4.1578  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.9610  Validation loss = 4.1573  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.9607  Validation loss = 4.1569  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.9605  Validation loss = 4.1565  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.9603  Validation loss = 4.1562  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.9601  Validation loss = 4.1558  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.9599  Validation loss = 4.1555  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.9596  Validation loss = 4.1551  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.9594  Validation loss = 4.1547  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.9592  Validation loss = 4.1544  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.9590  Validation loss = 4.1539  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.9587  Validation loss = 4.1535  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.9585  Validation loss = 4.1532  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.9583  Validation loss = 4.1527  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.9581  Validation loss = 4.1523  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.9578  Validation loss = 4.1520  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.9576  Validation loss = 4.1516  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.9574  Validation loss = 4.1512  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.9572  Validation loss = 4.1509  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.9570  Validation loss = 4.1506  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.9568  Validation loss = 4.1503  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.9566  Validation loss = 4.1498  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.9563  Validation loss = 4.1495  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.9561  Validation loss = 4.1491  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.9560  Validation loss = 4.1488  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.9557  Validation loss = 4.1484  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.9554  Validation loss = 4.1478  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.9552  Validation loss = 4.1475  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.9550  Validation loss = 4.1471  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.9548  Validation loss = 4.1468  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.9546  Validation loss = 4.1464  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.9543  Validation loss = 4.1459  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.9541  Validation loss = 4.1455  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.9538  Validation loss = 4.1451  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.9536  Validation loss = 4.1447  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.9534  Validation loss = 4.1444  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.9531  Validation loss = 4.1439  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.9529  Validation loss = 4.1435  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.9527  Validation loss = 4.1431  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.9525  Validation loss = 4.1427  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.9523  Validation loss = 4.1424  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.9520  Validation loss = 4.1420  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.9518  Validation loss = 4.1417  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.9516  Validation loss = 4.1412  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.9514  Validation loss = 4.1409  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.9511  Validation loss = 4.1405  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.9509  Validation loss = 4.1400  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.9506  Validation loss = 4.1396  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.9504  Validation loss = 4.1391  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.9501  Validation loss = 4.1387  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.9498  Validation loss = 4.1382  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.9496  Validation loss = 4.1378  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.9493  Validation loss = 4.1373  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.9491  Validation loss = 4.1369  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.9488  Validation loss = 4.1365  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.9486  Validation loss = 4.1360  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.9484  Validation loss = 4.1357  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.9481  Validation loss = 4.1353  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.9480  Validation loss = 4.1350  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.9478  Validation loss = 4.1347  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.9475  Validation loss = 4.1341  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.9473  Validation loss = 4.1338  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.9471  Validation loss = 4.1334  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.9468  Validation loss = 4.1330  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.9466  Validation loss = 4.1327  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.9464  Validation loss = 4.1323  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.9462  Validation loss = 4.1319  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.9459  Validation loss = 4.1315  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.9457  Validation loss = 4.1310  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.9454  Validation loss = 4.1306  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.9452  Validation loss = 4.1301  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.9450  Validation loss = 4.1299  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.9448  Validation loss = 4.1295  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.9446  Validation loss = 4.1292  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.9444  Validation loss = 4.1288  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.9442  Validation loss = 4.1284  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.9440  Validation loss = 4.1281  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.9438  Validation loss = 4.1277  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.9436  Validation loss = 4.1273  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.9433  Validation loss = 4.1268  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.9431  Validation loss = 4.1265  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.9428  Validation loss = 4.1260  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.9426  Validation loss = 4.1256  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.9423  Validation loss = 4.1252  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.9421  Validation loss = 4.1247  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.9419  Validation loss = 4.1244  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.9417  Validation loss = 4.1240  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.9415  Validation loss = 4.1237  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.9413  Validation loss = 4.1234  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.9411  Validation loss = 4.1230  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.9408  Validation loss = 4.1225  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.9405  Validation loss = 4.1221  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.9403  Validation loss = 4.1216  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.9401  Validation loss = 4.1213  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.9399  Validation loss = 4.1209  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.9396  Validation loss = 4.1205  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.9394  Validation loss = 4.1201  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.9392  Validation loss = 4.1198  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.9390  Validation loss = 4.1193  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.9387  Validation loss = 4.1190  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.9384  Validation loss = 4.1185  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.9382  Validation loss = 4.1180  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.9379  Validation loss = 4.1176  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.9377  Validation loss = 4.1172  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.9375  Validation loss = 4.1168  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.9373  Validation loss = 4.1165  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.9371  Validation loss = 4.1161  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.9369  Validation loss = 4.1158  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.9366  Validation loss = 4.1154  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.9364  Validation loss = 4.1149  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.9361  Validation loss = 4.1144  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.9359  Validation loss = 4.1140  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.9357  Validation loss = 4.1138  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.9355  Validation loss = 4.1134  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.9353  Validation loss = 4.1131  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.9351  Validation loss = 4.1127  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.9349  Validation loss = 4.1123  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.9347  Validation loss = 4.1119  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.9345  Validation loss = 4.1115  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.9342  Validation loss = 4.1111  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.9340  Validation loss = 4.1107  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.9337  Validation loss = 4.1102  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.9335  Validation loss = 4.1098  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.9333  Validation loss = 4.1094  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.9331  Validation loss = 4.1090  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.9328  Validation loss = 4.1086  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.9326  Validation loss = 4.1083  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.9324  Validation loss = 4.1079  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.9322  Validation loss = 4.1075  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.9320  Validation loss = 4.1072  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.9317  Validation loss = 4.1067  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.9315  Validation loss = 4.1062  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.9313  Validation loss = 4.1059  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.9311  Validation loss = 4.1056  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.9309  Validation loss = 4.1053  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.9307  Validation loss = 4.1049  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.9305  Validation loss = 4.1045  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.9303  Validation loss = 4.1042  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.9301  Validation loss = 4.1039  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.9300  Validation loss = 4.1036  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.9297  Validation loss = 4.1032  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.9296  Validation loss = 4.1029  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.9293  Validation loss = 4.1025  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.9291  Validation loss = 4.1022  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.9289  Validation loss = 4.1017  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.9286  Validation loss = 4.1013  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.9284  Validation loss = 4.1009  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.9282  Validation loss = 4.1005  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.9280  Validation loss = 4.1002  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.9278  Validation loss = 4.0998  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.9275  Validation loss = 4.0993  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.9273  Validation loss = 4.0989  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.9271  Validation loss = 4.0985  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.9268  Validation loss = 4.0981  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.9266  Validation loss = 4.0977  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.9264  Validation loss = 4.0974  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.9262  Validation loss = 4.0970  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.9260  Validation loss = 4.0967  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.9258  Validation loss = 4.0963  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.9256  Validation loss = 4.0959  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.9253  Validation loss = 4.0955  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.9250  Validation loss = 4.0950  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.9249  Validation loss = 4.0947  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.9246  Validation loss = 4.0942  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.9244  Validation loss = 4.0939  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.9242  Validation loss = 4.0935  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.9239  Validation loss = 4.0930  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.9238  Validation loss = 4.0927  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.9236  Validation loss = 4.0925  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.9234  Validation loss = 4.0921  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.9232  Validation loss = 4.0917  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.9230  Validation loss = 4.0914  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.9228  Validation loss = 4.0910  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.9226  Validation loss = 4.0907  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.9224  Validation loss = 4.0904  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.9222  Validation loss = 4.0899  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.9220  Validation loss = 4.0896  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.9218  Validation loss = 4.0893  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.9216  Validation loss = 4.0889  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.9215  Validation loss = 4.0887  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.9212  Validation loss = 4.0882  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.9211  Validation loss = 4.0880  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.9208  Validation loss = 4.0876  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.9206  Validation loss = 4.0872  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.9204  Validation loss = 4.0868  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.9202  Validation loss = 4.0865  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.9201  Validation loss = 4.0863  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.9199  Validation loss = 4.0859  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.9197  Validation loss = 4.0856  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.9195  Validation loss = 4.0852  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.9193  Validation loss = 4.0849  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.9191  Validation loss = 4.0846  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.9189  Validation loss = 4.0843  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.9188  Validation loss = 4.0840  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.9186  Validation loss = 4.0837  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.9184  Validation loss = 4.0833  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.9182  Validation loss = 4.0829  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.9180  Validation loss = 4.0826  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.9178  Validation loss = 4.0823  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.9175  Validation loss = 4.0818  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.9173  Validation loss = 4.0814  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.9171  Validation loss = 4.0810  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.9169  Validation loss = 4.0806  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.9167  Validation loss = 4.0803  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.9165  Validation loss = 4.0800  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.9163  Validation loss = 4.0797  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.9160  Validation loss = 4.0791  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.9158  Validation loss = 4.0788  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.9156  Validation loss = 4.0784  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.9154  Validation loss = 4.0781  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.9152  Validation loss = 4.0777  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.9150  Validation loss = 4.0773  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.9148  Validation loss = 4.0770  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.9147  Validation loss = 4.0767  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.9144  Validation loss = 4.0763  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.9143  Validation loss = 4.0760  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.9140  Validation loss = 4.0756  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.9139  Validation loss = 4.0753  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.9137  Validation loss = 4.0749  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.9134  Validation loss = 4.0745  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.9132  Validation loss = 4.0741  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.9130  Validation loss = 4.0738  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.9128  Validation loss = 4.0734  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.9126  Validation loss = 4.0731  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.9124  Validation loss = 4.0727  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.9122  Validation loss = 4.0723  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.9120  Validation loss = 4.0719  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.9118  Validation loss = 4.0716  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.9116  Validation loss = 4.0712  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.9113  Validation loss = 4.0708  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.9111  Validation loss = 4.0704  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.9109  Validation loss = 4.0700  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.9108  Validation loss = 4.0697  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.9106  Validation loss = 4.0694  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.9104  Validation loss = 4.0691  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.9102  Validation loss = 4.0687  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.9100  Validation loss = 4.0683  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.9097  Validation loss = 4.0678  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.9095  Validation loss = 4.0675  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.9093  Validation loss = 4.0672  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.9090  Validation loss = 4.0667  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.9088  Validation loss = 4.0663  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.9086  Validation loss = 4.0660  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.9084  Validation loss = 4.0655  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.9082  Validation loss = 4.0652  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.9080  Validation loss = 4.0648  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.9078  Validation loss = 4.0646  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.9077  Validation loss = 4.0643  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.9075  Validation loss = 4.0640  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.9073  Validation loss = 4.0636  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.9071  Validation loss = 4.0633  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.9069  Validation loss = 4.0629  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.9067  Validation loss = 4.0626  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.9065  Validation loss = 4.0622  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.9064  Validation loss = 4.0619  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.9062  Validation loss = 4.0616  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.9059  Validation loss = 4.0611  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.9057  Validation loss = 4.0608  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.9056  Validation loss = 4.0605  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.9054  Validation loss = 4.0601  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.9052  Validation loss = 4.0598  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.9050  Validation loss = 4.0595  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.9048  Validation loss = 4.0591  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.9045  Validation loss = 4.0586  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.9043  Validation loss = 4.0583  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.9041  Validation loss = 4.0579  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.9038  Validation loss = 4.0574  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.9036  Validation loss = 4.0570  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.9034  Validation loss = 4.0566  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.9032  Validation loss = 4.0563  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.9030  Validation loss = 4.0559  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.9029  Validation loss = 4.0556  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.9026  Validation loss = 4.0551  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.9024  Validation loss = 4.0547  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.9022  Validation loss = 4.0545  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.9020  Validation loss = 4.0541  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.9018  Validation loss = 4.0537  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.9016  Validation loss = 4.0534  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.9014  Validation loss = 4.0530  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.9012  Validation loss = 4.0527  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.9010  Validation loss = 4.0524  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.9008  Validation loss = 4.0519  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.9006  Validation loss = 4.0515  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.9003  Validation loss = 4.0511  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.9001  Validation loss = 4.0507  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.9000  Validation loss = 4.0504  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.8997  Validation loss = 4.0500  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.8995  Validation loss = 4.0495  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.8993  Validation loss = 4.0492  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.8992  Validation loss = 4.0490  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.8990  Validation loss = 4.0486  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.8988  Validation loss = 4.0482  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.8986  Validation loss = 4.0479  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.8984  Validation loss = 4.0475  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.8981  Validation loss = 4.0471  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.8980  Validation loss = 4.0468  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.8977  Validation loss = 4.0464  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.8975  Validation loss = 4.0460  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.8973  Validation loss = 4.0456  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.8971  Validation loss = 4.0453  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.8969  Validation loss = 4.0449  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.8967  Validation loss = 4.0446  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.8965  Validation loss = 4.0442  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.8963  Validation loss = 4.0438  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.8961  Validation loss = 4.0435  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.8959  Validation loss = 4.0431  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.8957  Validation loss = 4.0427  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.8955  Validation loss = 4.0423  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.8953  Validation loss = 4.0420  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.8952  Validation loss = 4.0418  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.8949  Validation loss = 4.0413  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.8947  Validation loss = 4.0409  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.8945  Validation loss = 4.0406  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.8943  Validation loss = 4.0402  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.8941  Validation loss = 4.0398  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.8939  Validation loss = 4.0394  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.8937  Validation loss = 4.0391  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.8935  Validation loss = 4.0387  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.8933  Validation loss = 4.0384  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.8931  Validation loss = 4.0380  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.8929  Validation loss = 4.0376  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.8927  Validation loss = 4.0372  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.8924  Validation loss = 4.0368  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.8922  Validation loss = 4.0364  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.8920  Validation loss = 4.0361  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.8918  Validation loss = 4.0357  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.8916  Validation loss = 4.0353  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.8913  Validation loss = 4.0348  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.8911  Validation loss = 4.0344  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.8909  Validation loss = 4.0340  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.8907  Validation loss = 4.0337  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.8905  Validation loss = 4.0334  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.8903  Validation loss = 4.0330  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.8901  Validation loss = 4.0326  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.8899  Validation loss = 4.0322  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.8897  Validation loss = 4.0319  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.8895  Validation loss = 4.0316  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.8893  Validation loss = 4.0313  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.8892  Validation loss = 4.0310  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.8890  Validation loss = 4.0307  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.8888  Validation loss = 4.0303  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.8886  Validation loss = 4.0299  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.8884  Validation loss = 4.0296  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.8882  Validation loss = 4.0293  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.8880  Validation loss = 4.0289  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.8879  Validation loss = 4.0287  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.8877  Validation loss = 4.0283  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.8875  Validation loss = 4.0279  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.8872  Validation loss = 4.0275  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.8870  Validation loss = 4.0270  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.8868  Validation loss = 4.0267  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.8866  Validation loss = 4.0263  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.8864  Validation loss = 4.0259  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.8861  Validation loss = 4.0255  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.8859  Validation loss = 4.0251  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.8858  Validation loss = 4.0249  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.8856  Validation loss = 4.0246  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.8854  Validation loss = 4.0242  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.8852  Validation loss = 4.0239  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.8851  Validation loss = 4.0236  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.8849  Validation loss = 4.0232  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.8847  Validation loss = 4.0229  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.8845  Validation loss = 4.0225  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.8843  Validation loss = 4.0223  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.8841  Validation loss = 4.0218  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.8839  Validation loss = 4.0215  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.8837  Validation loss = 4.0212  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.8835  Validation loss = 4.0207  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.8833  Validation loss = 4.0203  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.8831  Validation loss = 4.0199  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.8828  Validation loss = 4.0195  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.8826  Validation loss = 4.0191  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.8824  Validation loss = 4.0188  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.8822  Validation loss = 4.0184  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.8820  Validation loss = 4.0181  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.8819  Validation loss = 4.0178  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.8817  Validation loss = 4.0174  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.8815  Validation loss = 4.0171  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.8812  Validation loss = 4.0166  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.8811  Validation loss = 4.0163  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.8808  Validation loss = 4.0159  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.8806  Validation loss = 4.0154  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.8804  Validation loss = 4.0151  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.8802  Validation loss = 4.0147  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.8800  Validation loss = 4.0145  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.8798  Validation loss = 4.0140  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.8796  Validation loss = 4.0137  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.8795  Validation loss = 4.0134  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.8793  Validation loss = 4.0131  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.8791  Validation loss = 4.0128  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.8790  Validation loss = 4.0126  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.8788  Validation loss = 4.0122  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.8786  Validation loss = 4.0118  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.8784  Validation loss = 4.0115  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.8782  Validation loss = 4.0111  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.8780  Validation loss = 4.0108  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.8778  Validation loss = 4.0104  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.8776  Validation loss = 4.0101  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.8774  Validation loss = 4.0097  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.8772  Validation loss = 4.0093  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.8771  Validation loss = 4.0091  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.8769  Validation loss = 4.0087  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.8766  Validation loss = 4.0083  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.8764  Validation loss = 4.0079  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.8763  Validation loss = 4.0077  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.8762  Validation loss = 4.0074  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.8760  Validation loss = 4.0070  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.8758  Validation loss = 4.0068  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.8756  Validation loss = 4.0064  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.8755  Validation loss = 4.0061  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.8752  Validation loss = 4.0057  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.8750  Validation loss = 4.0054  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.8749  Validation loss = 4.0051  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.8747  Validation loss = 4.0047  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.8746  Validation loss = 4.0045  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.8744  Validation loss = 4.0042  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.8743  Validation loss = 4.0039  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.8741  Validation loss = 4.0036  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.8738  Validation loss = 4.0031  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.8737  Validation loss = 4.0028  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.8735  Validation loss = 4.0025  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.8733  Validation loss = 4.0022  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.8731  Validation loss = 4.0018  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.8729  Validation loss = 4.0015  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.8727  Validation loss = 4.0011  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.8725  Validation loss = 4.0008  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.9941  Validation loss = 5.1555  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.9939  Validation loss = 5.1551  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.9937  Validation loss = 5.1547  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.9935  Validation loss = 5.1543  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.9932  Validation loss = 5.1539  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.9929  Validation loss = 5.1534  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.9927  Validation loss = 5.1531  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.9925  Validation loss = 5.1527  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.9922  Validation loss = 5.1522  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.9920  Validation loss = 5.1518  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.9917  Validation loss = 5.1514  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.9915  Validation loss = 5.1509  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.9913  Validation loss = 5.1505  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.9911  Validation loss = 5.1502  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.9908  Validation loss = 5.1498  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.9906  Validation loss = 5.1493  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.9903  Validation loss = 5.1489  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.9900  Validation loss = 5.1484  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.9898  Validation loss = 5.1480  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.9896  Validation loss = 5.1476  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.9894  Validation loss = 5.1472  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.9891  Validation loss = 5.1468  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.9890  Validation loss = 5.1465  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.9887  Validation loss = 5.1460  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.9885  Validation loss = 5.1456  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.9883  Validation loss = 5.1453  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.9880  Validation loss = 5.1448  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.9879  Validation loss = 5.1446  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.9876  Validation loss = 5.1440  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.9874  Validation loss = 5.1437  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.9872  Validation loss = 5.1433  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.9870  Validation loss = 5.1430  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.9867  Validation loss = 5.1426  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.9865  Validation loss = 5.1421  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.9862  Validation loss = 5.1417  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.9860  Validation loss = 5.1413  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.9857  Validation loss = 5.1409  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.9854  Validation loss = 5.1403  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.9852  Validation loss = 5.1400  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.9849  Validation loss = 5.1395  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.9847  Validation loss = 5.1391  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.9845  Validation loss = 5.1387  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.9843  Validation loss = 5.1383  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.9841  Validation loss = 5.1379  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.9839  Validation loss = 5.1375  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.9836  Validation loss = 5.1372  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.9835  Validation loss = 5.1369  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.9833  Validation loss = 5.1365  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.9831  Validation loss = 5.1362  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.9829  Validation loss = 5.1359  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.9827  Validation loss = 5.1355  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.9825  Validation loss = 5.1351  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.9822  Validation loss = 5.1347  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.9820  Validation loss = 5.1344  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.9818  Validation loss = 5.1339  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.9815  Validation loss = 5.1335  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.9813  Validation loss = 5.1332  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.9811  Validation loss = 5.1328  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.9809  Validation loss = 5.1325  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.9807  Validation loss = 5.1321  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.9805  Validation loss = 5.1317  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.9802  Validation loss = 5.1313  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.9800  Validation loss = 5.1309  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.9798  Validation loss = 5.1305  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.9796  Validation loss = 5.1301  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.9794  Validation loss = 5.1298  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.9792  Validation loss = 5.1295  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.9789  Validation loss = 5.1291  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.9788  Validation loss = 5.1288  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.9786  Validation loss = 5.1285  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.9784  Validation loss = 5.1281  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.9781  Validation loss = 5.1276  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.9779  Validation loss = 5.1272  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.9777  Validation loss = 5.1269  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.9775  Validation loss = 5.1265  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.9773  Validation loss = 5.1262  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.9771  Validation loss = 5.1259  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.9769  Validation loss = 5.1256  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.9767  Validation loss = 5.1252  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.9765  Validation loss = 5.1248  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.9763  Validation loss = 5.1245  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.9761  Validation loss = 5.1242  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.9759  Validation loss = 5.1237  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.9757  Validation loss = 5.1233  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.9755  Validation loss = 5.1230  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.9752  Validation loss = 5.1225  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.9750  Validation loss = 5.1223  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.9748  Validation loss = 5.1219  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.9746  Validation loss = 5.1215  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.9744  Validation loss = 5.1212  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.9742  Validation loss = 5.1208  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.9740  Validation loss = 5.1204  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.9737  Validation loss = 5.1199  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.9735  Validation loss = 5.1196  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.9733  Validation loss = 5.1192  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.9731  Validation loss = 5.1189  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.9729  Validation loss = 5.1185  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.9728  Validation loss = 5.1182  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.9725  Validation loss = 5.1178  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.9723  Validation loss = 5.1174  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.9720  Validation loss = 5.1169  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.9718  Validation loss = 5.1166  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.9716  Validation loss = 5.1162  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.9714  Validation loss = 5.1159  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.9712  Validation loss = 5.1155  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.9710  Validation loss = 5.1150  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.9707  Validation loss = 5.1147  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.9706  Validation loss = 5.1144  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.9703  Validation loss = 5.1139  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.9700  Validation loss = 5.1134  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.9698  Validation loss = 5.1129  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.9696  Validation loss = 5.1126  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.9694  Validation loss = 5.1122  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.9691  Validation loss = 5.1117  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.9689  Validation loss = 5.1113  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.9686  Validation loss = 5.1107  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.9684  Validation loss = 5.1104  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.9681  Validation loss = 5.1100  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.9680  Validation loss = 5.1097  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.9677  Validation loss = 5.1092  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.9674  Validation loss = 5.1088  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.9672  Validation loss = 5.1083  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.9670  Validation loss = 5.1080  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.9668  Validation loss = 5.1077  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.9666  Validation loss = 5.1073  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.9663  Validation loss = 5.1069  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.9661  Validation loss = 5.1065  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.9659  Validation loss = 5.1060  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.9656  Validation loss = 5.1055  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.9653  Validation loss = 5.1050  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.9651  Validation loss = 5.1046  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.9649  Validation loss = 5.1043  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.9647  Validation loss = 5.1039  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.9645  Validation loss = 5.1036  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.9643  Validation loss = 5.1032  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.9642  Validation loss = 5.1030  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.9639  Validation loss = 5.1026  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.9638  Validation loss = 5.1023  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.9636  Validation loss = 5.1020  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.9634  Validation loss = 5.1016  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.9631  Validation loss = 5.1011  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.9629  Validation loss = 5.1008  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.9626  Validation loss = 5.1003  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.9625  Validation loss = 5.1000  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.9623  Validation loss = 5.0997  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.9620  Validation loss = 5.0992  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.9618  Validation loss = 5.0989  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.9617  Validation loss = 5.0987  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.9615  Validation loss = 5.0983  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.9612  Validation loss = 5.0979  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.9610  Validation loss = 5.0975  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.9608  Validation loss = 5.0972  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.9606  Validation loss = 5.0968  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.9604  Validation loss = 5.0964  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.9602  Validation loss = 5.0960  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.9599  Validation loss = 5.0956  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.9598  Validation loss = 5.0953  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.9595  Validation loss = 5.0948  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.9593  Validation loss = 5.0944  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.9590  Validation loss = 5.0940  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.9588  Validation loss = 5.0936  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.9586  Validation loss = 5.0933  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.9584  Validation loss = 5.0928  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.9581  Validation loss = 5.0924  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.9580  Validation loss = 5.0922  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.9578  Validation loss = 5.0919  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.9576  Validation loss = 5.0914  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.9573  Validation loss = 5.0910  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.9571  Validation loss = 5.0905  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.9568  Validation loss = 5.0900  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.9566  Validation loss = 5.0896  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.9564  Validation loss = 5.0893  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.9562  Validation loss = 5.0889  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.9560  Validation loss = 5.0886  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.9558  Validation loss = 5.0882  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.9556  Validation loss = 5.0879  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.9554  Validation loss = 5.0876  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.9552  Validation loss = 5.0872  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.9551  Validation loss = 5.0869  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.9549  Validation loss = 5.0866  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.9546  Validation loss = 5.0862  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.9545  Validation loss = 5.0859  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.9543  Validation loss = 5.0855  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.9541  Validation loss = 5.0853  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.9539  Validation loss = 5.0849  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.9537  Validation loss = 5.0845  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.9534  Validation loss = 5.0841  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.9532  Validation loss = 5.0837  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.9530  Validation loss = 5.0833  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.9527  Validation loss = 5.0827  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.9525  Validation loss = 5.0824  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.9523  Validation loss = 5.0821  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.9521  Validation loss = 5.0818  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.9519  Validation loss = 5.0814  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.9516  Validation loss = 5.0809  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.9514  Validation loss = 5.0804  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.9512  Validation loss = 5.0801  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.9510  Validation loss = 5.0798  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.9508  Validation loss = 5.0795  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.9506  Validation loss = 5.0791  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.9504  Validation loss = 5.0787  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.9502  Validation loss = 5.0783  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.9499  Validation loss = 5.0779  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.9498  Validation loss = 5.0776  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.9496  Validation loss = 5.0772  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.9493  Validation loss = 5.0768  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.9492  Validation loss = 5.0765  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.9490  Validation loss = 5.0762  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.9488  Validation loss = 5.0758  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.9485  Validation loss = 5.0754  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.9483  Validation loss = 5.0749  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.9481  Validation loss = 5.0746  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.9479  Validation loss = 5.0742  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.9477  Validation loss = 5.0738  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.9475  Validation loss = 5.0735  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.9473  Validation loss = 5.0732  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.9471  Validation loss = 5.0729  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.9469  Validation loss = 5.0725  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.9467  Validation loss = 5.0721  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.9465  Validation loss = 5.0717  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.9462  Validation loss = 5.0712  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.9460  Validation loss = 5.0708  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.9458  Validation loss = 5.0705  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.9456  Validation loss = 5.0701  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.9454  Validation loss = 5.0697  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.9452  Validation loss = 5.0694  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.9449  Validation loss = 5.0689  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.9448  Validation loss = 5.0686  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.9445  Validation loss = 5.0682  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.9443  Validation loss = 5.0677  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.9441  Validation loss = 5.0673  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.9439  Validation loss = 5.0669  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.9437  Validation loss = 5.0666  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.9435  Validation loss = 5.0662  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.9432  Validation loss = 5.0658  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.9430  Validation loss = 5.0654  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.9428  Validation loss = 5.0651  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.9426  Validation loss = 5.0648  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.9424  Validation loss = 5.0644  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.9422  Validation loss = 5.0640  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.9420  Validation loss = 5.0635  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.9417  Validation loss = 5.0631  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.9415  Validation loss = 5.0627  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.9413  Validation loss = 5.0623  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.9412  Validation loss = 5.0621  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.9409  Validation loss = 5.0617  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.9407  Validation loss = 5.0612  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.9405  Validation loss = 5.0609  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.9403  Validation loss = 5.0605  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.9400  Validation loss = 5.0601  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.9398  Validation loss = 5.0597  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.9396  Validation loss = 5.0592  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.9394  Validation loss = 5.0589  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.9391  Validation loss = 5.0584  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.9389  Validation loss = 5.0579  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.9387  Validation loss = 5.0576  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.9385  Validation loss = 5.0573  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.9383  Validation loss = 5.0570  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.9381  Validation loss = 5.0566  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.9379  Validation loss = 5.0562  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.9377  Validation loss = 5.0558  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.9375  Validation loss = 5.0554  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.9372  Validation loss = 5.0549  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.9371  Validation loss = 5.0546  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.9369  Validation loss = 5.0544  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.9367  Validation loss = 5.0539  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.9365  Validation loss = 5.0536  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.9363  Validation loss = 5.0533  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.9361  Validation loss = 5.0529  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.9359  Validation loss = 5.0525  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.9356  Validation loss = 5.0521  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.9354  Validation loss = 5.0516  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.9352  Validation loss = 5.0513  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.9350  Validation loss = 5.0509  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.9348  Validation loss = 5.0505  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.9346  Validation loss = 5.0501  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.9344  Validation loss = 5.0498  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.9342  Validation loss = 5.0494  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.9340  Validation loss = 5.0490  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.9338  Validation loss = 5.0487  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.9336  Validation loss = 5.0484  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.9335  Validation loss = 5.0481  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.9333  Validation loss = 5.0478  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.9331  Validation loss = 5.0475  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.9329  Validation loss = 5.0471  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.9328  Validation loss = 5.0468  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.9325  Validation loss = 5.0464  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.9323  Validation loss = 5.0460  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.9321  Validation loss = 5.0456  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.9319  Validation loss = 5.0453  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.9317  Validation loss = 5.0449  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.9314  Validation loss = 5.0444  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.9312  Validation loss = 5.0441  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.9310  Validation loss = 5.0437  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.9308  Validation loss = 5.0433  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.9306  Validation loss = 5.0429  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.9304  Validation loss = 5.0425  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.9303  Validation loss = 5.0423  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.9301  Validation loss = 5.0419  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.9299  Validation loss = 5.0416  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.9297  Validation loss = 5.0413  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.9295  Validation loss = 5.0409  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.9293  Validation loss = 5.0405  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.9290  Validation loss = 5.0400  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.9288  Validation loss = 5.0395  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.9286  Validation loss = 5.0391  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.9283  Validation loss = 5.0387  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.9281  Validation loss = 5.0383  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.9279  Validation loss = 5.0380  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.9277  Validation loss = 5.0375  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.9274  Validation loss = 5.0370  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.9273  Validation loss = 5.0368  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.9270  Validation loss = 5.0362  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.9268  Validation loss = 5.0358  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.9266  Validation loss = 5.0354  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.9264  Validation loss = 5.0351  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.9262  Validation loss = 5.0347  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.9261  Validation loss = 5.0345  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.9259  Validation loss = 5.0341  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.9256  Validation loss = 5.0337  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.9254  Validation loss = 5.0333  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.9253  Validation loss = 5.0330  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.9251  Validation loss = 5.0328  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.9249  Validation loss = 5.0324  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.9247  Validation loss = 5.0321  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.9246  Validation loss = 5.0318  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.9243  Validation loss = 5.0314  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.9241  Validation loss = 5.0309  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.9239  Validation loss = 5.0305  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.9237  Validation loss = 5.0302  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.9235  Validation loss = 5.0298  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.9233  Validation loss = 5.0295  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.9231  Validation loss = 5.0291  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.9229  Validation loss = 5.0287  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.9227  Validation loss = 5.0284  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.9225  Validation loss = 5.0280  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.9224  Validation loss = 5.0278  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.9222  Validation loss = 5.0275  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.9219  Validation loss = 5.0270  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.9217  Validation loss = 5.0266  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.9215  Validation loss = 5.0262  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.9213  Validation loss = 5.0259  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.9212  Validation loss = 5.0256  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.9210  Validation loss = 5.0253  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.9207  Validation loss = 5.0248  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.9206  Validation loss = 5.0245  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.9204  Validation loss = 5.0242  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.9202  Validation loss = 5.0238  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.9200  Validation loss = 5.0234  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.9198  Validation loss = 5.0231  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.9196  Validation loss = 5.0228  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.9194  Validation loss = 5.0223  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.9192  Validation loss = 5.0219  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.9189  Validation loss = 5.0214  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.9187  Validation loss = 5.0210  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.9185  Validation loss = 5.0207  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.9183  Validation loss = 5.0203  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.9181  Validation loss = 5.0199  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.9179  Validation loss = 5.0195  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.9176  Validation loss = 5.0191  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.9174  Validation loss = 5.0187  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.9172  Validation loss = 5.0183  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.9171  Validation loss = 5.0181  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.9169  Validation loss = 5.0177  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.9167  Validation loss = 5.0173  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.9164  Validation loss = 5.0169  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.9162  Validation loss = 5.0165  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.9160  Validation loss = 5.0161  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.9159  Validation loss = 5.0158  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.9157  Validation loss = 5.0155  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.9155  Validation loss = 5.0151  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.9154  Validation loss = 5.0148  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.9152  Validation loss = 5.0145  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.9150  Validation loss = 5.0141  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.9148  Validation loss = 5.0137  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.9145  Validation loss = 5.0133  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.9143  Validation loss = 5.0129  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.9141  Validation loss = 5.0126  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.9139  Validation loss = 5.0122  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.9137  Validation loss = 5.0118  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.9135  Validation loss = 5.0114  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.9133  Validation loss = 5.0110  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.9131  Validation loss = 5.0107  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.9129  Validation loss = 5.0102  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.9127  Validation loss = 5.0098  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.9125  Validation loss = 5.0095  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.9123  Validation loss = 5.0092  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.9120  Validation loss = 5.0087  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.9118  Validation loss = 5.0083  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.9116  Validation loss = 5.0079  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.9115  Validation loss = 5.0076  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.9113  Validation loss = 5.0073  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.9111  Validation loss = 5.0070  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.9109  Validation loss = 5.0066  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.9108  Validation loss = 5.0063  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.9106  Validation loss = 5.0060  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.9104  Validation loss = 5.0056  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.9102  Validation loss = 5.0052  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.9099  Validation loss = 5.0047  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.9097  Validation loss = 5.0043  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.9096  Validation loss = 5.0040  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.9093  Validation loss = 5.0035  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.9091  Validation loss = 5.0031  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.9089  Validation loss = 5.0028  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.9087  Validation loss = 5.0024  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.9085  Validation loss = 5.0019  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 1.9082  Validation loss = 5.0015  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 1.9080  Validation loss = 5.0010  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 1.9078  Validation loss = 5.0007  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 1.9076  Validation loss = 5.0002  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 1.9074  Validation loss = 4.9999  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 1.9072  Validation loss = 4.9995  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 1.9069  Validation loss = 4.9990  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 1.9067  Validation loss = 4.9986  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 1.9066  Validation loss = 4.9983  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 1.9064  Validation loss = 4.9980  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 1.9062  Validation loss = 4.9977  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 1.9060  Validation loss = 4.9972  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 1.9058  Validation loss = 4.9968  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 1.9056  Validation loss = 4.9966  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 1.9055  Validation loss = 4.9963  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 1.9053  Validation loss = 4.9960  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 1.9051  Validation loss = 4.9957  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 1.9050  Validation loss = 4.9953  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 1.9048  Validation loss = 4.9950  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 1.9046  Validation loss = 4.9947  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 1.9044  Validation loss = 4.9943  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 1.9043  Validation loss = 4.9941  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 1.9040  Validation loss = 4.9936  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 1.9039  Validation loss = 4.9933  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 1.9037  Validation loss = 4.9929  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 1.9034  Validation loss = 4.9925  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 1.9033  Validation loss = 4.9922  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 1.9030  Validation loss = 4.9917  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 1.9028  Validation loss = 4.9913  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 1.9027  Validation loss = 4.9911  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 1.9025  Validation loss = 4.9907  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 1.9023  Validation loss = 4.9904  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 1.9021  Validation loss = 4.9899  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 1.9019  Validation loss = 4.9896  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 1.9017  Validation loss = 4.9892  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 1.9015  Validation loss = 4.9887  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 1.9013  Validation loss = 4.9884  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 1.9011  Validation loss = 4.9880  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 1.9009  Validation loss = 4.9876  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 1.9007  Validation loss = 4.9873  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 1.9006  Validation loss = 4.9871  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 1.9004  Validation loss = 4.9867  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 1.9002  Validation loss = 4.9863  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 1.9000  Validation loss = 4.9860  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 1.8997  Validation loss = 4.9855  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 1.8996  Validation loss = 4.9853  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 1.8995  Validation loss = 4.9850  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 1.8993  Validation loss = 4.9846  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 1.8991  Validation loss = 4.9844  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 1.8989  Validation loss = 4.9840  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 1.8987  Validation loss = 4.9836  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 1.8985  Validation loss = 4.9832  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 1.8983  Validation loss = 4.9829  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 1.8982  Validation loss = 4.9825  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 1.8980  Validation loss = 4.9822  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 1.8978  Validation loss = 4.9817  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 1.8975  Validation loss = 4.9813  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 1.8973  Validation loss = 4.9809  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 1.8971  Validation loss = 4.9804  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 1.8968  Validation loss = 4.9800  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 1.8966  Validation loss = 4.9796  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 1.8964  Validation loss = 4.9792  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 1.8963  Validation loss = 4.9789  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 1.8961  Validation loss = 4.9785  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 1.8959  Validation loss = 4.9782  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 1.8957  Validation loss = 4.9778  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 1.8955  Validation loss = 4.9774  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 1.8954  Validation loss = 4.9772  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 1.8952  Validation loss = 4.9769  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 1.8950  Validation loss = 4.9765  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 1.8949  Validation loss = 4.9762  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 1.8947  Validation loss = 4.9758  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 1.8945  Validation loss = 4.9755  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 1.8943  Validation loss = 4.9752  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 1.8941  Validation loss = 4.9748  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 1.8939  Validation loss = 4.9745  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 1.8938  Validation loss = 4.9741  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 1.8935  Validation loss = 4.9737  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 1.8933  Validation loss = 4.9733  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 1.8932  Validation loss = 4.9730  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 1.8930  Validation loss = 4.9726  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 1.8928  Validation loss = 4.9722  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 1.8926  Validation loss = 4.9719  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 1.8924  Validation loss = 4.9716  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 1.8923  Validation loss = 4.9712  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 1.8921  Validation loss = 4.9709  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 1.8919  Validation loss = 4.9705  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 1.8917  Validation loss = 4.9702  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 1.8915  Validation loss = 4.9698  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 1.8913  Validation loss = 4.9695  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 1.8911  Validation loss = 4.9690  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 1.8909  Validation loss = 4.9686  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 1.8907  Validation loss = 4.9682  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 1.8905  Validation loss = 4.9679  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 500  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 2.2260  Validation loss = 4.8583  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 2.2257  Validation loss = 4.8578  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 2.2255  Validation loss = 4.8573  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 2.2252  Validation loss = 4.8568  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 2.2249  Validation loss = 4.8562  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 2.2246  Validation loss = 4.8556  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 2.2244  Validation loss = 4.8552  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 2.2240  Validation loss = 4.8544  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 2.2238  Validation loss = 4.8540  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 2.2236  Validation loss = 4.8535  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 2.2233  Validation loss = 4.8530  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 2.2229  Validation loss = 4.8523  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 2.2226  Validation loss = 4.8517  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 2.2223  Validation loss = 4.8511  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 2.2221  Validation loss = 4.8507  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 2.2219  Validation loss = 4.8504  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 2.2217  Validation loss = 4.8499  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 2.2214  Validation loss = 4.8493  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 2.2211  Validation loss = 4.8487  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 2.2209  Validation loss = 4.8483  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 2.2206  Validation loss = 4.8477  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 2.2204  Validation loss = 4.8473  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 2.2201  Validation loss = 4.8467  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 2.2198  Validation loss = 4.8462  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 2.2196  Validation loss = 4.8457  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 2.2193  Validation loss = 4.8451  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 2.2190  Validation loss = 4.8445  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 2.2188  Validation loss = 4.8440  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 2.2184  Validation loss = 4.8434  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 2.2182  Validation loss = 4.8430  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 2.2180  Validation loss = 4.8426  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 2.2177  Validation loss = 4.8419  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 2.2174  Validation loss = 4.8414  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 2.2171  Validation loss = 4.8408  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 2.2168  Validation loss = 4.8403  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 2.2165  Validation loss = 4.8397  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 2.2163  Validation loss = 4.8393  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 2.2161  Validation loss = 4.8389  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 2.2158  Validation loss = 4.8383  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 2.2155  Validation loss = 4.8377  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 2.2152  Validation loss = 4.8371  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 2.2150  Validation loss = 4.8368  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 2.2147  Validation loss = 4.8362  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 2.2144  Validation loss = 4.8357  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 2.2142  Validation loss = 4.8354  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 2.2140  Validation loss = 4.8349  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 2.2138  Validation loss = 4.8345  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 2.2135  Validation loss = 4.8339  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 2.2133  Validation loss = 4.8335  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 2.2129  Validation loss = 4.8329  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 2.2127  Validation loss = 4.8324  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 2.2124  Validation loss = 4.8319  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 2.2122  Validation loss = 4.8315  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 2.2120  Validation loss = 4.8310  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 2.2118  Validation loss = 4.8306  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 2.2116  Validation loss = 4.8303  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 2.2114  Validation loss = 4.8299  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 2.2110  Validation loss = 4.8293  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 2.2108  Validation loss = 4.8288  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 2.2105  Validation loss = 4.8283  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 2.2103  Validation loss = 4.8279  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 2.2101  Validation loss = 4.8275  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 2.2099  Validation loss = 4.8271  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 2.2097  Validation loss = 4.8266  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 2.2093  Validation loss = 4.8260  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 2.2090  Validation loss = 4.8253  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 2.2087  Validation loss = 4.8248  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 2.2085  Validation loss = 4.8243  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 2.2083  Validation loss = 4.8239  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 2.2080  Validation loss = 4.8234  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 2.2078  Validation loss = 4.8229  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 2.2074  Validation loss = 4.8222  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 2.2072  Validation loss = 4.8216  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 2.2067  Validation loss = 4.8207  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 2.2065  Validation loss = 4.8202  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 2.2062  Validation loss = 4.8198  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 2.2060  Validation loss = 4.8194  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 2.2058  Validation loss = 4.8189  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 2.2056  Validation loss = 4.8185  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 2.2054  Validation loss = 4.8181  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 2.2052  Validation loss = 4.8177  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 2.2049  Validation loss = 4.8172  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 2.2047  Validation loss = 4.8168  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 2.2044  Validation loss = 4.8163  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 2.2042  Validation loss = 4.8159  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 2.2039  Validation loss = 4.8154  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 2.2037  Validation loss = 4.8149  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 2.2034  Validation loss = 4.8143  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 2.2032  Validation loss = 4.8139  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 2.2030  Validation loss = 4.8135  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 2.2028  Validation loss = 4.8131  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 2.2025  Validation loss = 4.8126  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 2.2022  Validation loss = 4.8120  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 2.2019  Validation loss = 4.8114  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 2.2017  Validation loss = 4.8109  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 2.2014  Validation loss = 4.8102  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 2.2011  Validation loss = 4.8096  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 2.2009  Validation loss = 4.8092  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 2.2005  Validation loss = 4.8085  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 2.2003  Validation loss = 4.8081  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 2.2000  Validation loss = 4.8075  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 2.1997  Validation loss = 4.8069  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 2.1994  Validation loss = 4.8064  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 2.1992  Validation loss = 4.8060  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 2.1989  Validation loss = 4.8053  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 2.1986  Validation loss = 4.8046  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 2.1983  Validation loss = 4.8040  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 2.1980  Validation loss = 4.8035  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 2.1978  Validation loss = 4.8030  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 2.1975  Validation loss = 4.8025  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 2.1971  Validation loss = 4.8018  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 2.1968  Validation loss = 4.8011  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 2.1965  Validation loss = 4.8005  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 2.1963  Validation loss = 4.8002  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 2.1961  Validation loss = 4.7997  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 2.1958  Validation loss = 4.7991  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 2.1956  Validation loss = 4.7987  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 2.1953  Validation loss = 4.7980  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 2.1950  Validation loss = 4.7975  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 2.1948  Validation loss = 4.7970  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 2.1946  Validation loss = 4.7967  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 2.1943  Validation loss = 4.7962  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 2.1941  Validation loss = 4.7958  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 2.1939  Validation loss = 4.7954  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 2.1936  Validation loss = 4.7948  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 2.1934  Validation loss = 4.7944  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 2.1932  Validation loss = 4.7940  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 2.1930  Validation loss = 4.7936  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 2.1928  Validation loss = 4.7932  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 2.1925  Validation loss = 4.7928  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 2.1923  Validation loss = 4.7923  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 2.1921  Validation loss = 4.7920  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 2.1919  Validation loss = 4.7915  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 2.1917  Validation loss = 4.7911  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 2.1914  Validation loss = 4.7907  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 2.1912  Validation loss = 4.7902  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 2.1910  Validation loss = 4.7898  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 2.1908  Validation loss = 4.7895  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 2.1906  Validation loss = 4.7890  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 2.1904  Validation loss = 4.7886  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 2.1901  Validation loss = 4.7880  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 2.1898  Validation loss = 4.7875  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 2.1895  Validation loss = 4.7868  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 2.1892  Validation loss = 4.7861  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 2.1889  Validation loss = 4.7854  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 2.1886  Validation loss = 4.7850  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 2.1884  Validation loss = 4.7844  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 2.1881  Validation loss = 4.7840  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 2.1879  Validation loss = 4.7837  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 2.1877  Validation loss = 4.7833  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 2.1876  Validation loss = 4.7829  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 2.1872  Validation loss = 4.7821  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 2.1870  Validation loss = 4.7816  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 2.1867  Validation loss = 4.7811  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 2.1864  Validation loss = 4.7806  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 2.1861  Validation loss = 4.7800  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 2.1859  Validation loss = 4.7795  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 2.1856  Validation loss = 4.7788  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 2.1853  Validation loss = 4.7782  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 2.1850  Validation loss = 4.7778  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 2.1849  Validation loss = 4.7775  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 2.1846  Validation loss = 4.7770  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 2.1843  Validation loss = 4.7764  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 2.1841  Validation loss = 4.7759  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 2.1838  Validation loss = 4.7753  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 2.1836  Validation loss = 4.7750  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 2.1833  Validation loss = 4.7743  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 2.1830  Validation loss = 4.7739  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 2.1828  Validation loss = 4.7733  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 2.1825  Validation loss = 4.7728  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 2.1823  Validation loss = 4.7724  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 2.1820  Validation loss = 4.7718  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 2.1817  Validation loss = 4.7713  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 2.1816  Validation loss = 4.7710  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 2.1813  Validation loss = 4.7705  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 2.1811  Validation loss = 4.7700  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 2.1809  Validation loss = 4.7697  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 2.1807  Validation loss = 4.7692  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 2.1803  Validation loss = 4.7684  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 2.1800  Validation loss = 4.7678  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 2.1797  Validation loss = 4.7672  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 2.1795  Validation loss = 4.7667  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 2.1792  Validation loss = 4.7663  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 2.1789  Validation loss = 4.7656  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 2.1787  Validation loss = 4.7651  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 2.1785  Validation loss = 4.7647  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 2.1782  Validation loss = 4.7642  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 2.1780  Validation loss = 4.7638  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 2.1778  Validation loss = 4.7633  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 2.1775  Validation loss = 4.7627  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 2.1771  Validation loss = 4.7619  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 2.1769  Validation loss = 4.7615  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 2.1767  Validation loss = 4.7610  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 2.1764  Validation loss = 4.7606  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 2.1761  Validation loss = 4.7600  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 2.1759  Validation loss = 4.7594  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 2.1755  Validation loss = 4.7588  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 2.1753  Validation loss = 4.7583  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 2.1750  Validation loss = 4.7578  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 2.1749  Validation loss = 4.7574  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 2.1746  Validation loss = 4.7568  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 2.1742  Validation loss = 4.7561  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 2.1739  Validation loss = 4.7555  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 2.1736  Validation loss = 4.7549  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 2.1733  Validation loss = 4.7543  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 2.1731  Validation loss = 4.7537  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 2.1729  Validation loss = 4.7534  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 2.1726  Validation loss = 4.7527  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 2.1724  Validation loss = 4.7523  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 2.1721  Validation loss = 4.7517  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 2.1718  Validation loss = 4.7512  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 2.1716  Validation loss = 4.7508  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 2.1714  Validation loss = 4.7503  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 2.1711  Validation loss = 4.7497  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 2.1708  Validation loss = 4.7490  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 2.1704  Validation loss = 4.7483  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 2.1702  Validation loss = 4.7479  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 2.1700  Validation loss = 4.7475  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 2.1697  Validation loss = 4.7468  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 2.1694  Validation loss = 4.7461  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 2.1691  Validation loss = 4.7456  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 2.1688  Validation loss = 4.7450  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 2.1686  Validation loss = 4.7445  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 2.1684  Validation loss = 4.7441  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 2.1681  Validation loss = 4.7434  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 2.1678  Validation loss = 4.7429  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 2.1676  Validation loss = 4.7424  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 2.1673  Validation loss = 4.7418  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 2.1671  Validation loss = 4.7414  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 2.1668  Validation loss = 4.7409  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 2.1665  Validation loss = 4.7403  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 2.1663  Validation loss = 4.7398  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 2.1661  Validation loss = 4.7395  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 2.1658  Validation loss = 4.7389  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 2.1656  Validation loss = 4.7384  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 2.1653  Validation loss = 4.7379  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 2.1650  Validation loss = 4.7371  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 2.1648  Validation loss = 4.7366  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 2.1645  Validation loss = 4.7362  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 2.1643  Validation loss = 4.7357  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 2.1641  Validation loss = 4.7354  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 2.1638  Validation loss = 4.7348  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 2.1635  Validation loss = 4.7343  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 2.1633  Validation loss = 4.7339  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 2.1630  Validation loss = 4.7332  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 2.1628  Validation loss = 4.7328  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 2.1625  Validation loss = 4.7322  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 2.1623  Validation loss = 4.7316  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 2.1620  Validation loss = 4.7312  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 2.1618  Validation loss = 4.7307  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 2.1615  Validation loss = 4.7301  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 2.1612  Validation loss = 4.7294  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 2.1609  Validation loss = 4.7289  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 2.1607  Validation loss = 4.7286  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 2.1605  Validation loss = 4.7280  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 2.1602  Validation loss = 4.7276  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 2.1599  Validation loss = 4.7269  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 2.1597  Validation loss = 4.7264  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 2.1594  Validation loss = 4.7258  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 2.1592  Validation loss = 4.7254  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 2.1589  Validation loss = 4.7249  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 2.1587  Validation loss = 4.7245  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 2.1585  Validation loss = 4.7240  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 2.1583  Validation loss = 4.7235  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 2.1580  Validation loss = 4.7231  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 2.1577  Validation loss = 4.7225  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 2.1575  Validation loss = 4.7219  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 2.1572  Validation loss = 4.7215  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 2.1569  Validation loss = 4.7209  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 2.1567  Validation loss = 4.7203  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 2.1564  Validation loss = 4.7197  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 2.1562  Validation loss = 4.7194  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 2.1560  Validation loss = 4.7190  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 2.1558  Validation loss = 4.7186  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 2.1556  Validation loss = 4.7181  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 2.1553  Validation loss = 4.7174  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 2.1550  Validation loss = 4.7169  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 2.1548  Validation loss = 4.7164  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 2.1545  Validation loss = 4.7158  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 2.1543  Validation loss = 4.7154  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 2.1541  Validation loss = 4.7150  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 2.1538  Validation loss = 4.7146  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 2.1535  Validation loss = 4.7139  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 2.1533  Validation loss = 4.7134  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 2.1531  Validation loss = 4.7130  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 2.1528  Validation loss = 4.7125  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 2.1526  Validation loss = 4.7120  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 2.1523  Validation loss = 4.7114  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 2.1520  Validation loss = 4.7109  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 2.1518  Validation loss = 4.7103  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 2.1516  Validation loss = 4.7099  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 2.1513  Validation loss = 4.7095  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 2.1511  Validation loss = 4.7090  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 2.1509  Validation loss = 4.7086  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 2.1507  Validation loss = 4.7081  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 2.1505  Validation loss = 4.7078  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 2.1503  Validation loss = 4.7075  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 2.1501  Validation loss = 4.7071  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 2.1499  Validation loss = 4.7066  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 2.1497  Validation loss = 4.7063  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 2.1494  Validation loss = 4.7057  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 2.1493  Validation loss = 4.7053  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 2.1490  Validation loss = 4.7047  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 2.1488  Validation loss = 4.7043  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 2.1486  Validation loss = 4.7040  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 2.1483  Validation loss = 4.7033  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 2.1481  Validation loss = 4.7029  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 2.1478  Validation loss = 4.7022  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 2.1475  Validation loss = 4.7017  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 2.1472  Validation loss = 4.7009  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 2.1470  Validation loss = 4.7005  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 2.1468  Validation loss = 4.7001  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 2.1465  Validation loss = 4.6996  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 2.1464  Validation loss = 4.6992  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 2.1461  Validation loss = 4.6986  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 2.1458  Validation loss = 4.6981  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 2.1457  Validation loss = 4.6978  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 2.1455  Validation loss = 4.6974  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 2.1452  Validation loss = 4.6969  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 2.1450  Validation loss = 4.6965  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 2.1447  Validation loss = 4.6959  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 2.1446  Validation loss = 4.6956  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 2.1443  Validation loss = 4.6952  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 2.1441  Validation loss = 4.6948  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 2.1439  Validation loss = 4.6943  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 2.1436  Validation loss = 4.6938  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 2.1434  Validation loss = 4.6931  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 2.1431  Validation loss = 4.6926  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 2.1429  Validation loss = 4.6922  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 2.1426  Validation loss = 4.6917  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 2.1424  Validation loss = 4.6912  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 2.1422  Validation loss = 4.6907  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 2.1419  Validation loss = 4.6902  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 2.1417  Validation loss = 4.6898  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 2.1414  Validation loss = 4.6892  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 2.1413  Validation loss = 4.6889  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 2.1410  Validation loss = 4.6884  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 2.1408  Validation loss = 4.6880  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 2.1406  Validation loss = 4.6875  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 2.1404  Validation loss = 4.6871  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 2.1402  Validation loss = 4.6866  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 2.1399  Validation loss = 4.6860  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 2.1396  Validation loss = 4.6854  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 2.1394  Validation loss = 4.6849  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 2.1391  Validation loss = 4.6844  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 2.1389  Validation loss = 4.6838  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 2.1386  Validation loss = 4.6834  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 2.1385  Validation loss = 4.6832  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 2.1383  Validation loss = 4.6828  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 2.1381  Validation loss = 4.6822  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 2.1378  Validation loss = 4.6818  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 2.1375  Validation loss = 4.6812  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 2.1372  Validation loss = 4.6805  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 2.1369  Validation loss = 4.6798  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 2.1367  Validation loss = 4.6793  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 2.1364  Validation loss = 4.6788  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 2.1361  Validation loss = 4.6782  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 2.1359  Validation loss = 4.6778  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 2.1357  Validation loss = 4.6773  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 2.1355  Validation loss = 4.6769  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 2.1352  Validation loss = 4.6763  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 2.1350  Validation loss = 4.6759  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 2.1347  Validation loss = 4.6753  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 2.1345  Validation loss = 4.6747  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 2.1342  Validation loss = 4.6741  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 2.1340  Validation loss = 4.6737  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 2.1337  Validation loss = 4.6732  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 2.1335  Validation loss = 4.6726  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 2.1332  Validation loss = 4.6721  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 2.1330  Validation loss = 4.6717  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 2.1327  Validation loss = 4.6710  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 2.1324  Validation loss = 4.6705  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 2.1322  Validation loss = 4.6700  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 2.1320  Validation loss = 4.6694  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 2.1317  Validation loss = 4.6689  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 2.1315  Validation loss = 4.6684  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 2.1312  Validation loss = 4.6679  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 2.1310  Validation loss = 4.6674  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 2.1308  Validation loss = 4.6670  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 2.1305  Validation loss = 4.6666  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 2.1304  Validation loss = 4.6663  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 2.1301  Validation loss = 4.6657  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 2.1299  Validation loss = 4.6652  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 2.1297  Validation loss = 4.6647  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 2.1295  Validation loss = 4.6644  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 2.1293  Validation loss = 4.6639  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 2.1291  Validation loss = 4.6634  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 2.1289  Validation loss = 4.6631  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 2.1287  Validation loss = 4.6627  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 2.1284  Validation loss = 4.6622  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 2.1282  Validation loss = 4.6617  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 2.1280  Validation loss = 4.6612  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 2.1277  Validation loss = 4.6605  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 2.1274  Validation loss = 4.6599  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 2.1272  Validation loss = 4.6594  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 2.1269  Validation loss = 4.6588  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 2.1267  Validation loss = 4.6584  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 2.1265  Validation loss = 4.6580  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 2.1263  Validation loss = 4.6575  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 2.1260  Validation loss = 4.6569  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 2.1259  Validation loss = 4.6567  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 2.1257  Validation loss = 4.6563  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 2.1254  Validation loss = 4.6558  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 2.1253  Validation loss = 4.6555  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 2.1250  Validation loss = 4.6549  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 2.1248  Validation loss = 4.6545  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 2.1245  Validation loss = 4.6540  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 2.1243  Validation loss = 4.6534  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 2.1240  Validation loss = 4.6528  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 2.1238  Validation loss = 4.6525  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 2.1235  Validation loss = 4.6518  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 2.1234  Validation loss = 4.6514  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 2.1231  Validation loss = 4.6509  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 2.1229  Validation loss = 4.6505  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 2.1226  Validation loss = 4.6498  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 2.1224  Validation loss = 4.6493  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 2.1221  Validation loss = 4.6488  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 2.1219  Validation loss = 4.6483  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 2.1217  Validation loss = 4.6479  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 2.1215  Validation loss = 4.6475  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 2.1213  Validation loss = 4.6470  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 2.1210  Validation loss = 4.6464  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 2.1208  Validation loss = 4.6458  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 2.1206  Validation loss = 4.6454  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 2.1204  Validation loss = 4.6450  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 2.1201  Validation loss = 4.6445  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 2.1199  Validation loss = 4.6441  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 2.1197  Validation loss = 4.6437  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 2.1195  Validation loss = 4.6432  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 2.1193  Validation loss = 4.6428  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 2.1191  Validation loss = 4.6423  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 2.1188  Validation loss = 4.6418  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 2.1185  Validation loss = 4.6413  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 2.1184  Validation loss = 4.6410  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 2.1181  Validation loss = 4.6404  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 2.1179  Validation loss = 4.6399  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 2.1177  Validation loss = 4.6396  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 2.1175  Validation loss = 4.6392  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 2.1173  Validation loss = 4.6387  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 2.1170  Validation loss = 4.6382  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 2.1168  Validation loss = 4.6377  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 2.1166  Validation loss = 4.6372  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 2.1163  Validation loss = 4.6366  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 2.1161  Validation loss = 4.6363  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 2.1159  Validation loss = 4.6358  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 2.1156  Validation loss = 4.6353  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 2.1154  Validation loss = 4.6347  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 2.1151  Validation loss = 4.6343  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 2.1149  Validation loss = 4.6338  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 2.1146  Validation loss = 4.6331  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 2.1145  Validation loss = 4.6328  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 2.1142  Validation loss = 4.6322  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 2.1140  Validation loss = 4.6318  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 2.1137  Validation loss = 4.6312  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 2.1134  Validation loss = 4.6305  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 2.1131  Validation loss = 4.6298  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 2.1128  Validation loss = 4.6292  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 2.1127  Validation loss = 4.6288  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 2.1124  Validation loss = 4.6282  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 2.1122  Validation loss = 4.6277  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 2.1119  Validation loss = 4.6271  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 2.1117  Validation loss = 4.6267  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 2.1115  Validation loss = 4.6263  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 2.1113  Validation loss = 4.6258  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 2.1110  Validation loss = 4.6253  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 2.1108  Validation loss = 4.6247  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 2.1106  Validation loss = 4.6243  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 2.1104  Validation loss = 4.6240  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 2.1102  Validation loss = 4.6237  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 2.1100  Validation loss = 4.6233  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 2.1099  Validation loss = 4.6229  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 2.1097  Validation loss = 4.6225  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 2.1094  Validation loss = 4.6219  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 2.1092  Validation loss = 4.6215  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 2.1090  Validation loss = 4.6211  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 2.1089  Validation loss = 4.6208  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 2.1087  Validation loss = 4.6204  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 2.1084  Validation loss = 4.6199  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 2.1082  Validation loss = 4.6195  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 2.1079  Validation loss = 4.6190  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 2.1077  Validation loss = 4.6185  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 2.1076  Validation loss = 4.6181  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 2.1074  Validation loss = 4.6177  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 2.1072  Validation loss = 4.6173  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 2.1069  Validation loss = 4.6167  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 2.1068  Validation loss = 4.6164  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 2.1065  Validation loss = 4.6159  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 2.1063  Validation loss = 4.6155  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 2.1061  Validation loss = 4.6151  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 2.1059  Validation loss = 4.6147  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 2.1057  Validation loss = 4.6142  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 2.1056  Validation loss = 4.6138  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 2.1054  Validation loss = 4.6134  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 2.1052  Validation loss = 4.6131  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 2.1050  Validation loss = 4.6125  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 2.1047  Validation loss = 4.6119  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 2.1045  Validation loss = 4.6115  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 2.1043  Validation loss = 4.6111  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 2.1041  Validation loss = 4.6107  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 2.1039  Validation loss = 4.6103  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.3881  Validation loss = 2.3348  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.3877  Validation loss = 2.3340  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.3873  Validation loss = 2.3333  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.3870  Validation loss = 2.3328  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.3868  Validation loss = 2.3324  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.3864  Validation loss = 2.3317  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.3861  Validation loss = 2.3311  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.3857  Validation loss = 2.3304  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.3854  Validation loss = 2.3298  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.3851  Validation loss = 2.3292  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.3847  Validation loss = 2.3286  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.3843  Validation loss = 2.3278  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.3839  Validation loss = 2.3271  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.3836  Validation loss = 2.3266  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.3833  Validation loss = 2.3260  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.3829  Validation loss = 2.3253  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.3825  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.3821  Validation loss = 2.3238  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.3819  Validation loss = 2.3233  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.3816  Validation loss = 2.3228  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.3812  Validation loss = 2.3221  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.3809  Validation loss = 2.3215  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.3805  Validation loss = 2.3209  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.3802  Validation loss = 2.3203  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.3799  Validation loss = 2.3198  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.3795  Validation loss = 2.3190  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.3791  Validation loss = 2.3182  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.3786  Validation loss = 2.3175  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.3783  Validation loss = 2.3169  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.3780  Validation loss = 2.3162  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.3776  Validation loss = 2.3156  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.3772  Validation loss = 2.3149  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.3769  Validation loss = 2.3143  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.3766  Validation loss = 2.3136  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.3762  Validation loss = 2.3130  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.3759  Validation loss = 2.3125  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.3757  Validation loss = 2.3120  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.3752  Validation loss = 2.3112  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.3749  Validation loss = 2.3106  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.3746  Validation loss = 2.3101  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.3742  Validation loss = 2.3094  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.3739  Validation loss = 2.3088  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.3735  Validation loss = 2.3081  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.3732  Validation loss = 2.3075  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.3729  Validation loss = 2.3069  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.3727  Validation loss = 2.3066  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.3723  Validation loss = 2.3059  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.3720  Validation loss = 2.3053  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.3715  Validation loss = 2.3044  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.3711  Validation loss = 2.3036  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.3707  Validation loss = 2.3029  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.3704  Validation loss = 2.3024  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.3700  Validation loss = 2.3016  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.3696  Validation loss = 2.3009  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.3692  Validation loss = 2.3003  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.3689  Validation loss = 2.2997  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.3686  Validation loss = 2.2992  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.3683  Validation loss = 2.2985  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.3679  Validation loss = 2.2978  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.3675  Validation loss = 2.2971  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.3672  Validation loss = 2.2965  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.3669  Validation loss = 2.2960  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.3666  Validation loss = 2.2954  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.3662  Validation loss = 2.2948  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.3660  Validation loss = 2.2943  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.3657  Validation loss = 2.2937  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.3654  Validation loss = 2.2932  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.3650  Validation loss = 2.2925  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.3647  Validation loss = 2.2918  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.3642  Validation loss = 2.2911  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.3639  Validation loss = 2.2905  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.3636  Validation loss = 2.2899  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.3633  Validation loss = 2.2893  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.3629  Validation loss = 2.2886  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.3625  Validation loss = 2.2879  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.3622  Validation loss = 2.2874  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.3619  Validation loss = 2.2868  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.3616  Validation loss = 2.2863  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.3613  Validation loss = 2.2856  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.3610  Validation loss = 2.2851  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.3607  Validation loss = 2.2845  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.3604  Validation loss = 2.2840  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.3600  Validation loss = 2.2833  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.3597  Validation loss = 2.2827  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.3593  Validation loss = 2.2821  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.3591  Validation loss = 2.2816  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.3588  Validation loss = 2.2811  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.3584  Validation loss = 2.2804  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.3581  Validation loss = 2.2799  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.3578  Validation loss = 2.2794  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.3576  Validation loss = 2.2788  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.3571  Validation loss = 2.2781  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.3567  Validation loss = 2.2772  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.3563  Validation loss = 2.2765  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.3559  Validation loss = 2.2757  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.3555  Validation loss = 2.2751  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.3552  Validation loss = 2.2745  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.3548  Validation loss = 2.2738  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.3544  Validation loss = 2.2731  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.3541  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.3538  Validation loss = 2.2718  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.3534  Validation loss = 2.2712  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.3531  Validation loss = 2.2706  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.3527  Validation loss = 2.2699  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.3525  Validation loss = 2.2695  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.3521  Validation loss = 2.2688  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.3517  Validation loss = 2.2682  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.3514  Validation loss = 2.2675  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.3512  Validation loss = 2.2671  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.3509  Validation loss = 2.2665  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.3505  Validation loss = 2.2659  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.3502  Validation loss = 2.2653  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.3498  Validation loss = 2.2646  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.3495  Validation loss = 2.2641  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.3493  Validation loss = 2.2637  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.3491  Validation loss = 2.2632  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.3488  Validation loss = 2.2626  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.3484  Validation loss = 2.2620  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.3481  Validation loss = 2.2614  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.3477  Validation loss = 2.2606  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.3473  Validation loss = 2.2601  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.3470  Validation loss = 2.2594  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.3466  Validation loss = 2.2587  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.3462  Validation loss = 2.2580  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.3459  Validation loss = 2.2574  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.3455  Validation loss = 2.2567  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.3453  Validation loss = 2.2562  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.3450  Validation loss = 2.2558  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.3447  Validation loss = 2.2551  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.3444  Validation loss = 2.2546  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.3441  Validation loss = 2.2540  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.3438  Validation loss = 2.2535  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.3435  Validation loss = 2.2529  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.3430  Validation loss = 2.2521  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.3427  Validation loss = 2.2514  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.3424  Validation loss = 2.2509  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.3421  Validation loss = 2.2503  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.3417  Validation loss = 2.2496  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.3413  Validation loss = 2.2489  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.3410  Validation loss = 2.2483  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.3406  Validation loss = 2.2476  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.3404  Validation loss = 2.2471  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.3400  Validation loss = 2.2465  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.3397  Validation loss = 2.2459  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.3393  Validation loss = 2.2452  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.3391  Validation loss = 2.2447  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.3388  Validation loss = 2.2442  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.3384  Validation loss = 2.2436  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.3382  Validation loss = 2.2432  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.3379  Validation loss = 2.2427  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.3376  Validation loss = 2.2421  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.3373  Validation loss = 2.2415  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.3371  Validation loss = 2.2411  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.3368  Validation loss = 2.2406  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.3365  Validation loss = 2.2399  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.3361  Validation loss = 2.2394  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.3357  Validation loss = 2.2387  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.3354  Validation loss = 2.2381  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.3352  Validation loss = 2.2376  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.3348  Validation loss = 2.2369  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.3345  Validation loss = 2.2364  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.3342  Validation loss = 2.2359  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.3338  Validation loss = 2.2351  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.3335  Validation loss = 2.2345  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.3332  Validation loss = 2.2340  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.3330  Validation loss = 2.2335  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.3327  Validation loss = 2.2329  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.3324  Validation loss = 2.2324  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.3322  Validation loss = 2.2320  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.3319  Validation loss = 2.2315  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.3316  Validation loss = 2.2310  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.3314  Validation loss = 2.2305  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.3310  Validation loss = 2.2298  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.3306  Validation loss = 2.2292  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.3302  Validation loss = 2.2285  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.3300  Validation loss = 2.2280  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.3296  Validation loss = 2.2274  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.3294  Validation loss = 2.2268  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.3290  Validation loss = 2.2262  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.3286  Validation loss = 2.2254  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.3284  Validation loss = 2.2250  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.3280  Validation loss = 2.2243  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.3278  Validation loss = 2.2239  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.3275  Validation loss = 2.2233  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.3272  Validation loss = 2.2229  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.3270  Validation loss = 2.2224  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.3267  Validation loss = 2.2218  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.3262  Validation loss = 2.2210  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.3260  Validation loss = 2.2205  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.3257  Validation loss = 2.2201  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.3254  Validation loss = 2.2196  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.3251  Validation loss = 2.2190  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.3249  Validation loss = 2.2186  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.3246  Validation loss = 2.2180  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.3244  Validation loss = 2.2177  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.3242  Validation loss = 2.2172  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.3238  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.3236  Validation loss = 2.2161  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.3233  Validation loss = 2.2156  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.3230  Validation loss = 2.2151  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.3227  Validation loss = 2.2146  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.3224  Validation loss = 2.2140  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.3221  Validation loss = 2.2134  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.3219  Validation loss = 2.2130  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.3216  Validation loss = 2.2124  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.3213  Validation loss = 2.2119  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 2.3209  Validation loss = 2.2111  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 2.3205  Validation loss = 2.2105  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 2.3202  Validation loss = 2.2099  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 2.3198  Validation loss = 2.2091  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 2.3194  Validation loss = 2.2084  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 2.3191  Validation loss = 2.2078  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 2.3188  Validation loss = 2.2072  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 2.3185  Validation loss = 2.2068  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 2.3182  Validation loss = 2.2061  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 2.3180  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 2.3177  Validation loss = 2.2051  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 2.3173  Validation loss = 2.2045  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 2.3170  Validation loss = 2.2039  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 2.3167  Validation loss = 2.2033  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 2.3164  Validation loss = 2.2027  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 2.3160  Validation loss = 2.2021  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 2.3157  Validation loss = 2.2015  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 2.3153  Validation loss = 2.2008  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 2.3150  Validation loss = 2.2002  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 2.3146  Validation loss = 2.1995  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 2.3144  Validation loss = 2.1990  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 2.3141  Validation loss = 2.1985  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 2.3138  Validation loss = 2.1980  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 2.3136  Validation loss = 2.1975  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 2.3132  Validation loss = 2.1969  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 2.3129  Validation loss = 2.1963  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 2.3126  Validation loss = 2.1957  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 2.3122  Validation loss = 2.1950  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 2.3120  Validation loss = 2.1945  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 2.3117  Validation loss = 2.1940  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 2.3113  Validation loss = 2.1932  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 2.3110  Validation loss = 2.1926  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 2.3106  Validation loss = 2.1920  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 2.3103  Validation loss = 2.1915  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 2.3101  Validation loss = 2.1910  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 2.3097  Validation loss = 2.1903  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 2.3094  Validation loss = 2.1898  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 2.3092  Validation loss = 2.1894  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 2.3088  Validation loss = 2.1887  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 2.3085  Validation loss = 2.1880  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 2.3082  Validation loss = 2.1875  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 2.3078  Validation loss = 2.1868  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 2.3075  Validation loss = 2.1862  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 2.3073  Validation loss = 2.1858  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 2.3070  Validation loss = 2.1852  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 2.3066  Validation loss = 2.1846  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 2.3064  Validation loss = 2.1840  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 2.3061  Validation loss = 2.1835  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 2.3058  Validation loss = 2.1831  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 2.3055  Validation loss = 2.1823  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 2.3053  Validation loss = 2.1820  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 2.3050  Validation loss = 2.1815  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 2.3048  Validation loss = 2.1811  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 2.3045  Validation loss = 2.1805  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 2.3041  Validation loss = 2.1799  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 2.3039  Validation loss = 2.1794  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 2.3036  Validation loss = 2.1788  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 2.3033  Validation loss = 2.1782  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 2.3030  Validation loss = 2.1778  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 2.3028  Validation loss = 2.1773  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 2.3025  Validation loss = 2.1768  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 2.3022  Validation loss = 2.1762  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 2.3018  Validation loss = 2.1756  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 2.3016  Validation loss = 2.1752  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 2.3013  Validation loss = 2.1746  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 2.3009  Validation loss = 2.1739  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 2.3006  Validation loss = 2.1733  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 2.3003  Validation loss = 2.1727  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 2.3000  Validation loss = 2.1721  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 2.2997  Validation loss = 2.1715  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 2.2993  Validation loss = 2.1708  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 2.2989  Validation loss = 2.1701  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 2.2987  Validation loss = 2.1696  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 2.2984  Validation loss = 2.1692  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 2.2981  Validation loss = 2.1685  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 2.2978  Validation loss = 2.1680  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 2.2974  Validation loss = 2.1673  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 2.2971  Validation loss = 2.1667  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 2.2969  Validation loss = 2.1663  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 2.2966  Validation loss = 2.1657  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 2.2963  Validation loss = 2.1651  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 2.2960  Validation loss = 2.1646  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 2.2957  Validation loss = 2.1641  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 2.2954  Validation loss = 2.1634  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 2.2951  Validation loss = 2.1629  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 2.2948  Validation loss = 2.1624  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 2.2945  Validation loss = 2.1618  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 2.2942  Validation loss = 2.1613  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 2.2940  Validation loss = 2.1608  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 2.2936  Validation loss = 2.1601  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 2.2933  Validation loss = 2.1595  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 2.2930  Validation loss = 2.1589  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 2.2927  Validation loss = 2.1584  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 2.2924  Validation loss = 2.1578  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 2.2921  Validation loss = 2.1574  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 2.2919  Validation loss = 2.1569  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 2.2916  Validation loss = 2.1564  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 2.2914  Validation loss = 2.1559  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 2.2911  Validation loss = 2.1554  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 2.2908  Validation loss = 2.1549  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 2.2905  Validation loss = 2.1542  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 2.2901  Validation loss = 2.1536  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 2.2898  Validation loss = 2.1530  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 2.2896  Validation loss = 2.1525  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 2.2892  Validation loss = 2.1519  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 2.2889  Validation loss = 2.1513  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 2.2887  Validation loss = 2.1508  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 2.2882  Validation loss = 2.1500  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 2.2880  Validation loss = 2.1496  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 2.2878  Validation loss = 2.1492  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 2.2874  Validation loss = 2.1485  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 2.2871  Validation loss = 2.1479  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 2.2868  Validation loss = 2.1473  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 2.2864  Validation loss = 2.1466  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 2.2862  Validation loss = 2.1461  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 2.2859  Validation loss = 2.1456  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 2.2856  Validation loss = 2.1450  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 2.2853  Validation loss = 2.1446  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 2.2851  Validation loss = 2.1441  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 2.2848  Validation loss = 2.1435  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 2.2844  Validation loss = 2.1428  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 2.2840  Validation loss = 2.1421  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 2.2837  Validation loss = 2.1415  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 2.2834  Validation loss = 2.1410  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 2.2831  Validation loss = 2.1405  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 2.2829  Validation loss = 2.1400  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 2.2827  Validation loss = 2.1396  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 2.2825  Validation loss = 2.1392  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 2.2822  Validation loss = 2.1386  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 2.2817  Validation loss = 2.1378  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 2.2814  Validation loss = 2.1372  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 2.2811  Validation loss = 2.1367  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 2.2809  Validation loss = 2.1362  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 2.2806  Validation loss = 2.1357  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 2.2804  Validation loss = 2.1352  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 2.2801  Validation loss = 2.1347  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 2.2798  Validation loss = 2.1341  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 2.2795  Validation loss = 2.1337  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 2.2792  Validation loss = 2.1330  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 2.2789  Validation loss = 2.1325  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 2.2787  Validation loss = 2.1321  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 2.2784  Validation loss = 2.1315  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 2.2780  Validation loss = 2.1308  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 2.2777  Validation loss = 2.1303  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 2.2775  Validation loss = 2.1297  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 2.2772  Validation loss = 2.1292  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 2.2768  Validation loss = 2.1285  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 2.2766  Validation loss = 2.1281  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 2.2762  Validation loss = 2.1273  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 2.2759  Validation loss = 2.1268  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 2.2756  Validation loss = 2.1262  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 2.2753  Validation loss = 2.1257  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 2.2751  Validation loss = 2.1253  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 2.2748  Validation loss = 2.1248  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 2.2746  Validation loss = 2.1243  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 2.2743  Validation loss = 2.1238  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 2.2741  Validation loss = 2.1233  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 2.2738  Validation loss = 2.1228  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 2.2734  Validation loss = 2.1221  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 2.2731  Validation loss = 2.1215  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 2.2728  Validation loss = 2.1209  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 2.2725  Validation loss = 2.1204  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 2.2723  Validation loss = 2.1199  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 2.2720  Validation loss = 2.1195  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 2.2718  Validation loss = 2.1190  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 2.2715  Validation loss = 2.1185  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 2.2712  Validation loss = 2.1180  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 2.2709  Validation loss = 2.1174  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 2.2706  Validation loss = 2.1168  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 2.2703  Validation loss = 2.1162  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 2.2700  Validation loss = 2.1157  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 2.2698  Validation loss = 2.1153  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 2.2695  Validation loss = 2.1147  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 2.2692  Validation loss = 2.1141  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 2.2688  Validation loss = 2.1134  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 2.2686  Validation loss = 2.1129  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 2.2683  Validation loss = 2.1124  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 2.2680  Validation loss = 2.1119  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 2.2678  Validation loss = 2.1115  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 2.2675  Validation loss = 2.1108  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 2.2672  Validation loss = 2.1103  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 2.2669  Validation loss = 2.1098  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 2.2666  Validation loss = 2.1093  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 2.2664  Validation loss = 2.1088  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 2.2661  Validation loss = 2.1084  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 2.2658  Validation loss = 2.1078  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 2.2655  Validation loss = 2.1072  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 2.2652  Validation loss = 2.1066  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 2.2650  Validation loss = 2.1061  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 2.2646  Validation loss = 2.1055  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 2.2644  Validation loss = 2.1051  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 2.2641  Validation loss = 2.1045  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 2.2638  Validation loss = 2.1039  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 2.2635  Validation loss = 2.1032  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 2.2631  Validation loss = 2.1026  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 2.2628  Validation loss = 2.1020  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 2.2627  Validation loss = 2.1017  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 2.2624  Validation loss = 2.1013  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 2.2621  Validation loss = 2.1007  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 2.2618  Validation loss = 2.1001  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 2.2617  Validation loss = 2.0999  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 2.2615  Validation loss = 2.0995  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 2.2613  Validation loss = 2.0991  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 2.2609  Validation loss = 2.0984  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 2.2607  Validation loss = 2.0980  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 2.2605  Validation loss = 2.0976  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 2.2602  Validation loss = 2.0970  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 2.2599  Validation loss = 2.0965  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 2.2597  Validation loss = 2.0960  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 2.2595  Validation loss = 2.0957  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 2.2592  Validation loss = 2.0952  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 2.2590  Validation loss = 2.0948  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 2.2588  Validation loss = 2.0942  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 2.2585  Validation loss = 2.0936  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 2.2581  Validation loss = 2.0930  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 2.2579  Validation loss = 2.0926  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 2.2577  Validation loss = 2.0922  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 2.2575  Validation loss = 2.0917  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 2.2571  Validation loss = 2.0911  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 2.2569  Validation loss = 2.0906  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 2.2566  Validation loss = 2.0900  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 2.2563  Validation loss = 2.0895  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 2.2560  Validation loss = 2.0890  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 2.2558  Validation loss = 2.0886  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 2.2555  Validation loss = 2.0881  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 2.2552  Validation loss = 2.0875  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 2.2550  Validation loss = 2.0870  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 2.2548  Validation loss = 2.0866  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 2.2545  Validation loss = 2.0861  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 2.2542  Validation loss = 2.0855  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 2.2540  Validation loss = 2.0850  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 2.2538  Validation loss = 2.0847  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 2.2533  Validation loss = 2.0839  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 2.2531  Validation loss = 2.0834  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 2.2528  Validation loss = 2.0828  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 2.2525  Validation loss = 2.0823  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 2.2522  Validation loss = 2.0816  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 2.2520  Validation loss = 2.0812  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 2.2517  Validation loss = 2.0807  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 2.2515  Validation loss = 2.0803  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 2.2512  Validation loss = 2.0798  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 2.2509  Validation loss = 2.0793  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 2.2507  Validation loss = 2.0788  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 2.2504  Validation loss = 2.0783  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 2.2502  Validation loss = 2.0778  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 2.2499  Validation loss = 2.0772  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 2.2496  Validation loss = 2.0766  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 2.2492  Validation loss = 2.0760  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 2.2489  Validation loss = 2.0755  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 2.2487  Validation loss = 2.0749  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 2.2484  Validation loss = 2.0744  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 2.2481  Validation loss = 2.0738  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 2.2478  Validation loss = 2.0732  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 2.2475  Validation loss = 2.0727  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 2.2472  Validation loss = 2.0722  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 2.2470  Validation loss = 2.0716  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 2.2466  Validation loss = 2.0710  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 2.2464  Validation loss = 2.0705  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 2.2461  Validation loss = 2.0701  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 2.2459  Validation loss = 2.0697  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 2.2457  Validation loss = 2.0694  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 2.2454  Validation loss = 2.0687  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 2.2451  Validation loss = 2.0682  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 2.2450  Validation loss = 2.0678  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 2.2447  Validation loss = 2.0673  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 2.2444  Validation loss = 2.0668  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 2.2441  Validation loss = 2.0662  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 2.2438  Validation loss = 2.0657  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 2.2436  Validation loss = 2.0651  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 2.2433  Validation loss = 2.0646  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 2.2430  Validation loss = 2.0640  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 2.2427  Validation loss = 2.0634  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 2.2424  Validation loss = 2.0630  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 2.2422  Validation loss = 2.0626  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 2.2420  Validation loss = 2.0621  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 2.2417  Validation loss = 2.0615  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 2.2414  Validation loss = 2.0610  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 2.2411  Validation loss = 2.0604  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 2.2409  Validation loss = 2.0600  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 2.2406  Validation loss = 2.0594  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 2.2403  Validation loss = 2.0589  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 2.2401  Validation loss = 2.0584  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 2.2398  Validation loss = 2.0579  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 2.2394  Validation loss = 2.0572  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 2.2391  Validation loss = 2.0566  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 2.2389  Validation loss = 2.0561  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 2.2386  Validation loss = 2.0555  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 2.2382  Validation loss = 2.0549  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 2.2380  Validation loss = 2.0544  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 2.2377  Validation loss = 2.0539  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 2.2375  Validation loss = 2.0534  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 2.2372  Validation loss = 2.0529  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 2.2370  Validation loss = 2.0525  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 2.2368  Validation loss = 2.0521  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 2.2669  Validation loss = 1.9846  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 2.2665  Validation loss = 1.9840  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 2.2661  Validation loss = 1.9835  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 2.2658  Validation loss = 1.9829  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 2.2655  Validation loss = 1.9825  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 2.2653  Validation loss = 1.9821  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 2.2649  Validation loss = 1.9815  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 2.2645  Validation loss = 1.9810  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 2.2641  Validation loss = 1.9804  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 2.2638  Validation loss = 1.9799  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 2.2634  Validation loss = 1.9793  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 2.2631  Validation loss = 1.9788  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 2.2628  Validation loss = 1.9784  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 2.2625  Validation loss = 1.9778  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 2.2621  Validation loss = 1.9772  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 2.2618  Validation loss = 1.9767  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 2.2614  Validation loss = 1.9762  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 2.2611  Validation loss = 1.9757  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 2.2608  Validation loss = 1.9753  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 2.2605  Validation loss = 1.9748  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 2.2602  Validation loss = 1.9743  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 2.2599  Validation loss = 1.9738  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 2.2595  Validation loss = 1.9733  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 2.2592  Validation loss = 1.9728  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 2.2588  Validation loss = 1.9722  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 2.2586  Validation loss = 1.9718  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 2.2582  Validation loss = 1.9712  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 2.2578  Validation loss = 1.9707  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 2.2575  Validation loss = 1.9702  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 2.2572  Validation loss = 1.9696  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 2.2567  Validation loss = 1.9690  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 2.2564  Validation loss = 1.9685  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 2.2561  Validation loss = 1.9680  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 2.2558  Validation loss = 1.9676  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 2.2555  Validation loss = 1.9671  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 2.2553  Validation loss = 1.9667  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 2.2549  Validation loss = 1.9661  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 2.2545  Validation loss = 1.9655  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 2.2542  Validation loss = 1.9650  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 2.2540  Validation loss = 1.9646  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 2.2536  Validation loss = 1.9640  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 2.2533  Validation loss = 1.9636  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 2.2530  Validation loss = 1.9632  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 2.2527  Validation loss = 1.9627  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 2.2524  Validation loss = 1.9623  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 2.2521  Validation loss = 1.9617  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 2.2517  Validation loss = 1.9612  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 2.2515  Validation loss = 1.9608  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 2.2510  Validation loss = 1.9601  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 2.2507  Validation loss = 1.9596  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 2.2504  Validation loss = 1.9591  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 2.2500  Validation loss = 1.9585  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 2.2497  Validation loss = 1.9580  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 2.2493  Validation loss = 1.9574  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 2.2489  Validation loss = 1.9568  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 2.2485  Validation loss = 1.9562  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 2.2482  Validation loss = 1.9556  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 2.2478  Validation loss = 1.9551  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 2.2473  Validation loss = 1.9544  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 2.2470  Validation loss = 1.9538  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 2.2467  Validation loss = 1.9533  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 2.2463  Validation loss = 1.9527  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 2.2459  Validation loss = 1.9521  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 2.2457  Validation loss = 1.9517  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 2.2452  Validation loss = 1.9510  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 2.2449  Validation loss = 1.9505  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 2.2446  Validation loss = 1.9500  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 2.2442  Validation loss = 1.9495  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 2.2440  Validation loss = 1.9492  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 2.2437  Validation loss = 1.9486  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 2.2433  Validation loss = 1.9481  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 2.2430  Validation loss = 1.9475  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 2.2426  Validation loss = 1.9469  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 2.2421  Validation loss = 1.9463  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 2.2418  Validation loss = 1.9457  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 2.2415  Validation loss = 1.9453  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 2.2413  Validation loss = 1.9449  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 2.2409  Validation loss = 1.9444  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 2.2406  Validation loss = 1.9438  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 2.2404  Validation loss = 1.9435  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 2.2401  Validation loss = 1.9431  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 2.2397  Validation loss = 1.9425  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 2.2394  Validation loss = 1.9420  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 2.2392  Validation loss = 1.9416  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 2.2388  Validation loss = 1.9410  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 2.2384  Validation loss = 1.9405  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 2.2381  Validation loss = 1.9399  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 2.2377  Validation loss = 1.9394  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 2.2374  Validation loss = 1.9389  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 2.2370  Validation loss = 1.9383  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 2.2368  Validation loss = 1.9379  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 2.2365  Validation loss = 1.9375  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 2.2363  Validation loss = 1.9371  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 2.2359  Validation loss = 1.9366  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 2.2356  Validation loss = 1.9361  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 2.2353  Validation loss = 1.9356  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 2.2350  Validation loss = 1.9352  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 2.2346  Validation loss = 1.9346  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 2.2343  Validation loss = 1.9340  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 2.2339  Validation loss = 1.9334  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 2.2336  Validation loss = 1.9330  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 2.2332  Validation loss = 1.9324  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 2.2330  Validation loss = 1.9320  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 2.2326  Validation loss = 1.9314  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 2.2323  Validation loss = 1.9309  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 2.2319  Validation loss = 1.9302  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 2.2314  Validation loss = 1.9296  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 2.2312  Validation loss = 1.9292  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 2.2309  Validation loss = 1.9288  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 2.2306  Validation loss = 1.9283  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 2.2303  Validation loss = 1.9278  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 2.2299  Validation loss = 1.9272  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 2.2296  Validation loss = 1.9267  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 2.2293  Validation loss = 1.9262  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 2.2289  Validation loss = 1.9255  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 2.2286  Validation loss = 1.9250  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 2.2282  Validation loss = 1.9245  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 2.2278  Validation loss = 1.9239  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 2.2275  Validation loss = 1.9234  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 2.2272  Validation loss = 1.9229  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 2.2269  Validation loss = 1.9225  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 2.2266  Validation loss = 1.9219  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 2.2263  Validation loss = 1.9215  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 2.2259  Validation loss = 1.9209  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 2.2257  Validation loss = 1.9205  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 2.2253  Validation loss = 1.9200  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 2.2250  Validation loss = 1.9194  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 2.2246  Validation loss = 1.9188  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 2.2243  Validation loss = 1.9183  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 2.2241  Validation loss = 1.9180  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 2.2238  Validation loss = 1.9176  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 2.2236  Validation loss = 1.9172  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 2.2233  Validation loss = 1.9167  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 2.2229  Validation loss = 1.9162  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 2.2225  Validation loss = 1.9156  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 2.2221  Validation loss = 1.9150  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 2.2219  Validation loss = 1.9146  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 2.2217  Validation loss = 1.9142  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 2.2213  Validation loss = 1.9137  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 2.2210  Validation loss = 1.9132  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 2.2207  Validation loss = 1.9128  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 2.2205  Validation loss = 1.9124  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 2.2201  Validation loss = 1.9119  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 2.2198  Validation loss = 1.9114  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 2.2195  Validation loss = 1.9108  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 2.2191  Validation loss = 1.9103  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 2.2188  Validation loss = 1.9098  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 2.2184  Validation loss = 1.9092  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 2.2181  Validation loss = 1.9087  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 2.2178  Validation loss = 1.9081  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 2.2173  Validation loss = 1.9075  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 2.2170  Validation loss = 1.9070  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 2.2167  Validation loss = 1.9065  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 2.2164  Validation loss = 1.9059  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 2.2161  Validation loss = 1.9055  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 2.2157  Validation loss = 1.9048  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 2.2153  Validation loss = 1.9043  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 2.2150  Validation loss = 1.9038  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 2.2146  Validation loss = 1.9032  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 2.2144  Validation loss = 1.9028  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 2.2140  Validation loss = 1.9023  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 2.2137  Validation loss = 1.9018  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 2.2135  Validation loss = 1.9013  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 2.2132  Validation loss = 1.9009  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 2.2128  Validation loss = 1.9003  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 2.2125  Validation loss = 1.8998  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 2.2121  Validation loss = 1.8993  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 2.2119  Validation loss = 1.8988  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 2.2116  Validation loss = 1.8983  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 2.2112  Validation loss = 1.8978  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 2.2109  Validation loss = 1.8973  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 2.2105  Validation loss = 1.8967  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 2.2101  Validation loss = 1.8961  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 2.2098  Validation loss = 1.8956  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 2.2095  Validation loss = 1.8951  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 2.2091  Validation loss = 1.8945  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 2.2088  Validation loss = 1.8940  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 2.2086  Validation loss = 1.8936  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 2.2082  Validation loss = 1.8930  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 2.2079  Validation loss = 1.8926  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 2.2076  Validation loss = 1.8921  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 2.2073  Validation loss = 1.8916  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 2.2069  Validation loss = 1.8910  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 2.2066  Validation loss = 1.8905  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 2.2063  Validation loss = 1.8900  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 2.2060  Validation loss = 1.8896  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 2.2057  Validation loss = 1.8890  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 2.2054  Validation loss = 1.8886  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 2.2052  Validation loss = 1.8882  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 2.2048  Validation loss = 1.8877  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 2.2045  Validation loss = 1.8872  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 2.2042  Validation loss = 1.8867  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 2.2039  Validation loss = 1.8863  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 2.2037  Validation loss = 1.8859  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 2.2034  Validation loss = 1.8855  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 2.2031  Validation loss = 1.8850  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 2.2028  Validation loss = 1.8845  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 2.2024  Validation loss = 1.8838  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 2.2021  Validation loss = 1.8833  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 2.2017  Validation loss = 1.8827  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 2.2014  Validation loss = 1.8822  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 2.2010  Validation loss = 1.8817  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 2.2008  Validation loss = 1.8812  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 2.2003  Validation loss = 1.8806  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 2.2000  Validation loss = 1.8800  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 2.1997  Validation loss = 1.8796  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 2.1994  Validation loss = 1.8790  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 2.1990  Validation loss = 1.8785  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 2.1988  Validation loss = 1.8780  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 2.1985  Validation loss = 1.8776  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 2.1982  Validation loss = 1.8772  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 2.1980  Validation loss = 1.8769  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 2.1978  Validation loss = 1.8765  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 2.1975  Validation loss = 1.8760  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 2.1972  Validation loss = 1.8755  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 2.1970  Validation loss = 1.8752  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 2.1966  Validation loss = 1.8746  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 2.1964  Validation loss = 1.8742  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 2.1961  Validation loss = 1.8738  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 2.1958  Validation loss = 1.8732  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 2.1955  Validation loss = 1.8727  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 2.1952  Validation loss = 1.8723  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 2.1949  Validation loss = 1.8718  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 2.1946  Validation loss = 1.8713  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 2.1943  Validation loss = 1.8709  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 2.1941  Validation loss = 1.8705  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 2.1937  Validation loss = 1.8700  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 2.1934  Validation loss = 1.8693  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 2.1931  Validation loss = 1.8688  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 2.1929  Validation loss = 1.8685  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 2.1924  Validation loss = 1.8679  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 2.1922  Validation loss = 1.8675  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 2.1919  Validation loss = 1.8670  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 2.1915  Validation loss = 1.8663  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 2.1912  Validation loss = 1.8658  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 2.1909  Validation loss = 1.8654  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 2.1907  Validation loss = 1.8650  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 2.1904  Validation loss = 1.8646  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 2.1902  Validation loss = 1.8642  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 2.1899  Validation loss = 1.8637  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 2.1895  Validation loss = 1.8631  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 2.1892  Validation loss = 1.8627  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 2.1888  Validation loss = 1.8620  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 2.1884  Validation loss = 1.8614  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 2.1882  Validation loss = 1.8610  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 2.1879  Validation loss = 1.8604  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 2.1875  Validation loss = 1.8599  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 2.1872  Validation loss = 1.8594  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 2.1870  Validation loss = 1.8590  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 2.1867  Validation loss = 1.8585  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 2.1864  Validation loss = 1.8581  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 2.1860  Validation loss = 1.8574  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 2.1857  Validation loss = 1.8569  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 2.1854  Validation loss = 1.8565  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 2.1851  Validation loss = 1.8559  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 2.1848  Validation loss = 1.8556  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 2.1846  Validation loss = 1.8551  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 2.1843  Validation loss = 1.8547  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 2.1840  Validation loss = 1.8543  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 2.1838  Validation loss = 1.8539  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 2.1835  Validation loss = 1.8534  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 2.1832  Validation loss = 1.8529  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 2.1829  Validation loss = 1.8525  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 2.1826  Validation loss = 1.8520  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 2.1823  Validation loss = 1.8516  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 2.1822  Validation loss = 1.8513  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 2.1818  Validation loss = 1.8508  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 2.1815  Validation loss = 1.8503  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 2.1813  Validation loss = 1.8499  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 2.1811  Validation loss = 1.8496  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 2.1807  Validation loss = 1.8489  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 2.1803  Validation loss = 1.8484  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 2.1800  Validation loss = 1.8478  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 2.1797  Validation loss = 1.8474  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 2.1794  Validation loss = 1.8469  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 2.1791  Validation loss = 1.8465  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 2.1787  Validation loss = 1.8458  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 2.1784  Validation loss = 1.8453  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 2.1781  Validation loss = 1.8448  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 2.1778  Validation loss = 1.8443  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 2.1775  Validation loss = 1.8438  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 2.1771  Validation loss = 1.8433  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 2.1769  Validation loss = 1.8430  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 2.1767  Validation loss = 1.8427  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 2.1764  Validation loss = 1.8422  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 2.1761  Validation loss = 1.8417  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 2.1758  Validation loss = 1.8413  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 2.1755  Validation loss = 1.8407  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 2.1753  Validation loss = 1.8403  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 2.1750  Validation loss = 1.8399  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 2.1747  Validation loss = 1.8395  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 2.1744  Validation loss = 1.8389  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 2.1740  Validation loss = 1.8384  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 2.1737  Validation loss = 1.8379  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 2.1735  Validation loss = 1.8375  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 2.1732  Validation loss = 1.8370  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 2.1729  Validation loss = 1.8366  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 2.1727  Validation loss = 1.8362  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 2.1724  Validation loss = 1.8357  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 2.1721  Validation loss = 1.8353  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 2.1719  Validation loss = 1.8349  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 2.1716  Validation loss = 1.8345  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 2.1713  Validation loss = 1.8340  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 2.1709  Validation loss = 1.8334  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 2.1706  Validation loss = 1.8329  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 2.1703  Validation loss = 1.8324  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 2.1700  Validation loss = 1.8319  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 2.1697  Validation loss = 1.8315  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 2.1694  Validation loss = 1.8310  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 2.1693  Validation loss = 1.8307  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 2.1690  Validation loss = 1.8303  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 2.1686  Validation loss = 1.8297  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 2.1684  Validation loss = 1.8293  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 2.1680  Validation loss = 1.8288  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 2.1678  Validation loss = 1.8283  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 2.1675  Validation loss = 1.8279  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 2.1673  Validation loss = 1.8276  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 2.1670  Validation loss = 1.8271  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 2.1668  Validation loss = 1.8267  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 2.1666  Validation loss = 1.8264  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 2.1663  Validation loss = 1.8260  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 2.1660  Validation loss = 1.8255  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 2.1657  Validation loss = 1.8250  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 2.1654  Validation loss = 1.8245  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 2.1651  Validation loss = 1.8240  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 2.1648  Validation loss = 1.8235  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 2.1645  Validation loss = 1.8230  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 2.1643  Validation loss = 1.8227  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 2.1640  Validation loss = 1.8222  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 2.1637  Validation loss = 1.8218  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 2.1636  Validation loss = 1.8215  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 2.1633  Validation loss = 1.8211  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 2.1631  Validation loss = 1.8208  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 2.1628  Validation loss = 1.8202  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 2.1625  Validation loss = 1.8197  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 2.1622  Validation loss = 1.8193  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 2.1619  Validation loss = 1.8188  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 2.1616  Validation loss = 1.8184  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 2.1614  Validation loss = 1.8179  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 2.1612  Validation loss = 1.8176  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 2.1609  Validation loss = 1.8171  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 2.1606  Validation loss = 1.8166  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 2.1603  Validation loss = 1.8162  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 2.1600  Validation loss = 1.8156  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 2.1597  Validation loss = 1.8152  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 2.1596  Validation loss = 1.8150  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 2.1593  Validation loss = 1.8145  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 2.1590  Validation loss = 1.8140  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 2.1587  Validation loss = 1.8135  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 2.1585  Validation loss = 1.8132  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 2.1582  Validation loss = 1.8128  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 2.1578  Validation loss = 1.8122  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 2.1575  Validation loss = 1.8116  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 2.1573  Validation loss = 1.8112  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 2.1570  Validation loss = 1.8107  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 2.1568  Validation loss = 1.8104  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 2.1565  Validation loss = 1.8099  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 2.1561  Validation loss = 1.8093  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 2.1558  Validation loss = 1.8089  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 2.1555  Validation loss = 1.8084  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 2.1553  Validation loss = 1.8080  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 2.1549  Validation loss = 1.8074  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 2.1546  Validation loss = 1.8069  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 2.1543  Validation loss = 1.8065  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 2.1541  Validation loss = 1.8061  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 2.1539  Validation loss = 1.8057  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 2.1535  Validation loss = 1.8052  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 2.1532  Validation loss = 1.8045  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 2.1528  Validation loss = 1.8039  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 2.1525  Validation loss = 1.8035  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 2.1522  Validation loss = 1.8029  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 2.1519  Validation loss = 1.8025  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 2.1517  Validation loss = 1.8022  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 2.1514  Validation loss = 1.8017  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 2.1512  Validation loss = 1.8013  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 2.1509  Validation loss = 1.8008  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 2.1505  Validation loss = 1.8002  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 2.1503  Validation loss = 1.7999  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 2.1500  Validation loss = 1.7995  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 2.1498  Validation loss = 1.7991  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 2.1495  Validation loss = 1.7986  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 2.1492  Validation loss = 1.7981  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 2.1490  Validation loss = 1.7978  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 2.1487  Validation loss = 1.7973  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 2.1485  Validation loss = 1.7969  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 2.1482  Validation loss = 1.7964  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 2.1477  Validation loss = 1.7957  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 2.1474  Validation loss = 1.7951  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 2.1470  Validation loss = 1.7946  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 2.1468  Validation loss = 1.7942  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 2.1466  Validation loss = 1.7939  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 2.1462  Validation loss = 1.7932  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 2.1460  Validation loss = 1.7928  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 2.1457  Validation loss = 1.7925  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 2.1454  Validation loss = 1.7920  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 2.1451  Validation loss = 1.7915  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 2.1448  Validation loss = 1.7910  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 2.1445  Validation loss = 1.7905  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 2.1442  Validation loss = 1.7900  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 2.1440  Validation loss = 1.7896  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 2.1436  Validation loss = 1.7890  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 2.1433  Validation loss = 1.7885  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 2.1430  Validation loss = 1.7880  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 2.1427  Validation loss = 1.7875  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 2.1424  Validation loss = 1.7870  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 2.1421  Validation loss = 1.7865  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 2.1418  Validation loss = 1.7860  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 2.1415  Validation loss = 1.7855  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 2.1412  Validation loss = 1.7851  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 2.1409  Validation loss = 1.7846  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 2.1406  Validation loss = 1.7841  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 2.1403  Validation loss = 1.7837  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 2.1400  Validation loss = 1.7831  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 2.1396  Validation loss = 1.7825  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 2.1394  Validation loss = 1.7821  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 2.1389  Validation loss = 1.7814  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 2.1386  Validation loss = 1.7809  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 2.1383  Validation loss = 1.7804  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 2.1382  Validation loss = 1.7801  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 2.1379  Validation loss = 1.7796  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 2.1376  Validation loss = 1.7791  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 2.1374  Validation loss = 1.7788  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 2.1372  Validation loss = 1.7785  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 2.1368  Validation loss = 1.7779  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 2.1365  Validation loss = 1.7774  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 2.1363  Validation loss = 1.7771  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 2.1361  Validation loss = 1.7767  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 2.1358  Validation loss = 1.7763  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 2.1355  Validation loss = 1.7758  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 2.1352  Validation loss = 1.7754  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 2.1350  Validation loss = 1.7749  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 2.1347  Validation loss = 1.7744  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 2.1344  Validation loss = 1.7739  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 2.1341  Validation loss = 1.7736  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 2.1338  Validation loss = 1.7731  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 2.1336  Validation loss = 1.7726  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 2.1333  Validation loss = 1.7722  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 2.1331  Validation loss = 1.7718  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 2.1328  Validation loss = 1.7713  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 2.1326  Validation loss = 1.7710  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 2.1323  Validation loss = 1.7705  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 2.1321  Validation loss = 1.7701  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 2.1318  Validation loss = 1.7696  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 2.1315  Validation loss = 1.7692  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 2.1312  Validation loss = 1.7687  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 2.1310  Validation loss = 1.7683  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 2.1307  Validation loss = 1.7679  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 2.1305  Validation loss = 1.7676  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 2.1302  Validation loss = 1.7670  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 2.1299  Validation loss = 1.7665  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 2.1296  Validation loss = 1.7661  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 2.1294  Validation loss = 1.7656  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 2.1291  Validation loss = 1.7652  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 2.1288  Validation loss = 1.7647  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 2.1286  Validation loss = 1.7644  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 2.1283  Validation loss = 1.7639  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 2.1280  Validation loss = 1.7634  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 2.1277  Validation loss = 1.7629  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 2.1274  Validation loss = 1.7624  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 2.1271  Validation loss = 1.7619  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 2.1268  Validation loss = 1.7615  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 2.1265  Validation loss = 1.7609  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 2.1262  Validation loss = 1.7604  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 2.1258  Validation loss = 1.7598  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 2.1255  Validation loss = 1.7594  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 2.1253  Validation loss = 1.7589  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 2.1250  Validation loss = 1.7586  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 2.1247  Validation loss = 1.7581  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 2.1244  Validation loss = 1.7575  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 2.1242  Validation loss = 1.7571  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 2.1239  Validation loss = 1.7567  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 2.1236  Validation loss = 1.7562  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 2.1233  Validation loss = 1.7557  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 2.1230  Validation loss = 1.7553  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 2.1227  Validation loss = 1.7548  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 2.1224  Validation loss = 1.7543  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 2.1222  Validation loss = 1.7539  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 2.1219  Validation loss = 1.7534  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 2.1216  Validation loss = 1.7530  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 2.1214  Validation loss = 1.7527  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 2.1212  Validation loss = 1.7524  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 2.1210  Validation loss = 1.7520  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 2.1207  Validation loss = 1.7515  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 2.1203  Validation loss = 1.7509  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 2.1200  Validation loss = 1.7504  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 2.1198  Validation loss = 1.7501  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 2.1195  Validation loss = 1.7496  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 2.1193  Validation loss = 1.7491  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 2.1190  Validation loss = 1.7487  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 2.1187  Validation loss = 1.7483  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 2.1185  Validation loss = 1.7478  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 2.1182  Validation loss = 1.7474  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 2.1180  Validation loss = 1.7470  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 2.1177  Validation loss = 1.7465  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 2.1174  Validation loss = 1.7460  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 2.1171  Validation loss = 1.7455  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 2.1168  Validation loss = 1.7451  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 2.1165  Validation loss = 1.7446  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 2.1163  Validation loss = 1.7442  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 2.1160  Validation loss = 1.7437  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 500  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 2.1058  Validation loss = 6.8041  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 2.1055  Validation loss = 6.8035  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 2.1051  Validation loss = 6.8030  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 2.1049  Validation loss = 6.8026  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 2.1045  Validation loss = 6.8020  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 2.1043  Validation loss = 6.8016  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 2.1040  Validation loss = 6.8011  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 2.1037  Validation loss = 6.8006  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 2.1034  Validation loss = 6.8002  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 2.1031  Validation loss = 6.7996  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 2.1027  Validation loss = 6.7991  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 2.1024  Validation loss = 6.7986  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 2.1021  Validation loss = 6.7981  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 2.1018  Validation loss = 6.7975  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 2.1015  Validation loss = 6.7970  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 2.1011  Validation loss = 6.7964  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 2.1009  Validation loss = 6.7960  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 2.1006  Validation loss = 6.7956  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 2.1002  Validation loss = 6.7950  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 2.1000  Validation loss = 6.7946  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 2.0998  Validation loss = 6.7942  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 2.0995  Validation loss = 6.7937  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 2.0991  Validation loss = 6.7932  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 2.0989  Validation loss = 6.7928  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 2.0986  Validation loss = 6.7924  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 2.0984  Validation loss = 6.7921  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 2.0982  Validation loss = 6.7917  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 2.0977  Validation loss = 6.7910  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 2.0976  Validation loss = 6.7907  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 2.0972  Validation loss = 6.7901  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 2.0969  Validation loss = 6.7896  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 2.0966  Validation loss = 6.7891  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 2.0962  Validation loss = 6.7885  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 2.0959  Validation loss = 6.7880  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 2.0956  Validation loss = 6.7876  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 2.0953  Validation loss = 6.7871  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 2.0951  Validation loss = 6.7867  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 2.0948  Validation loss = 6.7863  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 2.0946  Validation loss = 6.7859  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 2.0942  Validation loss = 6.7853  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 2.0939  Validation loss = 6.7848  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 2.0936  Validation loss = 6.7843  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 2.0933  Validation loss = 6.7837  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 2.0930  Validation loss = 6.7834  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 2.0928  Validation loss = 6.7829  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 2.0925  Validation loss = 6.7825  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 2.0922  Validation loss = 6.7821  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 2.0919  Validation loss = 6.7815  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 2.0916  Validation loss = 6.7811  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 2.0913  Validation loss = 6.7805  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 2.0911  Validation loss = 6.7802  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 2.0908  Validation loss = 6.7797  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 2.0904  Validation loss = 6.7791  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 2.0902  Validation loss = 6.7787  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 2.0899  Validation loss = 6.7782  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 2.0897  Validation loss = 6.7778  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 2.0893  Validation loss = 6.7773  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 2.0890  Validation loss = 6.7768  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 2.0886  Validation loss = 6.7761  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 2.0883  Validation loss = 6.7756  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 2.0880  Validation loss = 6.7751  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 2.0877  Validation loss = 6.7746  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 2.0874  Validation loss = 6.7742  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 2.0871  Validation loss = 6.7738  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 2.0868  Validation loss = 6.7733  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 2.0865  Validation loss = 6.7728  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 2.0862  Validation loss = 6.7722  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 2.0858  Validation loss = 6.7716  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 2.0856  Validation loss = 6.7713  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 2.0853  Validation loss = 6.7709  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 2.0850  Validation loss = 6.7703  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 2.0847  Validation loss = 6.7699  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 2.0844  Validation loss = 6.7694  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 2.0841  Validation loss = 6.7689  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 2.0838  Validation loss = 6.7685  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 2.0837  Validation loss = 6.7682  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 2.0835  Validation loss = 6.7679  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 2.0832  Validation loss = 6.7675  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 2.0831  Validation loss = 6.7672  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 2.0827  Validation loss = 6.7667  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 2.0825  Validation loss = 6.7664  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 2.0822  Validation loss = 6.7658  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 2.0819  Validation loss = 6.7654  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 2.0817  Validation loss = 6.7650  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 2.0814  Validation loss = 6.7645  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 2.0811  Validation loss = 6.7640  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 2.0809  Validation loss = 6.7637  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 2.0807  Validation loss = 6.7633  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 2.0803  Validation loss = 6.7627  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 2.0800  Validation loss = 6.7623  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 2.0797  Validation loss = 6.7618  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 2.0795  Validation loss = 6.7615  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 2.0792  Validation loss = 6.7609  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 2.0789  Validation loss = 6.7604  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 2.0786  Validation loss = 6.7599  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 2.0784  Validation loss = 6.7596  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 2.0781  Validation loss = 6.7592  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 2.0779  Validation loss = 6.7587  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 2.0775  Validation loss = 6.7582  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 2.0773  Validation loss = 6.7579  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 2.0770  Validation loss = 6.7573  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 2.0768  Validation loss = 6.7570  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 2.0765  Validation loss = 6.7565  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 2.0762  Validation loss = 6.7560  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 2.0759  Validation loss = 6.7556  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 2.0756  Validation loss = 6.7551  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 2.0754  Validation loss = 6.7548  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 2.0750  Validation loss = 6.7541  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 2.0748  Validation loss = 6.7538  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 2.0745  Validation loss = 6.7533  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 2.0743  Validation loss = 6.7529  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 2.0740  Validation loss = 6.7524  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 2.0737  Validation loss = 6.7520  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 2.0735  Validation loss = 6.7516  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 2.0733  Validation loss = 6.7512  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 2.0730  Validation loss = 6.7509  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 2.0728  Validation loss = 6.7505  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 2.0725  Validation loss = 6.7500  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 2.0723  Validation loss = 6.7496  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 2.0720  Validation loss = 6.7492  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 2.0717  Validation loss = 6.7486  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 2.0714  Validation loss = 6.7482  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 2.0710  Validation loss = 6.7475  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 2.0706  Validation loss = 6.7469  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 2.0704  Validation loss = 6.7464  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 2.0701  Validation loss = 6.7461  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 2.0698  Validation loss = 6.7455  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 2.0695  Validation loss = 6.7449  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 2.0691  Validation loss = 6.7444  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 2.0689  Validation loss = 6.7440  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 2.0686  Validation loss = 6.7436  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 2.0684  Validation loss = 6.7433  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 2.0681  Validation loss = 6.7428  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 2.0679  Validation loss = 6.7424  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 2.0676  Validation loss = 6.7419  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 2.0673  Validation loss = 6.7414  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 2.0670  Validation loss = 6.7409  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 2.0668  Validation loss = 6.7406  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 2.0665  Validation loss = 6.7402  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 2.0663  Validation loss = 6.7397  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 2.0661  Validation loss = 6.7393  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 2.0658  Validation loss = 6.7389  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 2.0655  Validation loss = 6.7384  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 2.0652  Validation loss = 6.7379  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 2.0648  Validation loss = 6.7373  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 2.0647  Validation loss = 6.7370  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 2.0644  Validation loss = 6.7366  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 2.0641  Validation loss = 6.7362  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 2.0638  Validation loss = 6.7357  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 2.0635  Validation loss = 6.7351  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 2.0632  Validation loss = 6.7346  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 2.0629  Validation loss = 6.7341  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 2.0626  Validation loss = 6.7336  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 2.0623  Validation loss = 6.7331  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 2.0621  Validation loss = 6.7328  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 2.0618  Validation loss = 6.7323  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 2.0615  Validation loss = 6.7319  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 2.0612  Validation loss = 6.7313  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 2.0609  Validation loss = 6.7308  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 2.0606  Validation loss = 6.7303  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 2.0603  Validation loss = 6.7298  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 2.0601  Validation loss = 6.7294  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 2.0598  Validation loss = 6.7290  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 2.0596  Validation loss = 6.7287  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 2.0594  Validation loss = 6.7283  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 2.0591  Validation loss = 6.7280  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 2.0589  Validation loss = 6.7277  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 2.0587  Validation loss = 6.7273  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 2.0584  Validation loss = 6.7269  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 2.0581  Validation loss = 6.7263  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 2.0578  Validation loss = 6.7258  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 2.0576  Validation loss = 6.7255  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 2.0574  Validation loss = 6.7251  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 2.0571  Validation loss = 6.7247  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 2.0569  Validation loss = 6.7243  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 2.0566  Validation loss = 6.7238  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 2.0562  Validation loss = 6.7232  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 2.0560  Validation loss = 6.7227  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 2.0557  Validation loss = 6.7223  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 2.0554  Validation loss = 6.7219  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 2.0552  Validation loss = 6.7215  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 2.0550  Validation loss = 6.7211  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 2.0546  Validation loss = 6.7206  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 2.0544  Validation loss = 6.7201  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 2.0540  Validation loss = 6.7196  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 2.0538  Validation loss = 6.7192  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 2.0535  Validation loss = 6.7187  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 2.0533  Validation loss = 6.7183  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 2.0530  Validation loss = 6.7178  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 2.0527  Validation loss = 6.7174  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 2.0525  Validation loss = 6.7170  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 2.0522  Validation loss = 6.7165  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 2.0520  Validation loss = 6.7161  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 2.0516  Validation loss = 6.7156  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 2.0513  Validation loss = 6.7151  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 2.0510  Validation loss = 6.7145  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 2.0507  Validation loss = 6.7140  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 2.0504  Validation loss = 6.7135  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 2.0501  Validation loss = 6.7131  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 2.0499  Validation loss = 6.7128  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 2.0497  Validation loss = 6.7124  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 2.0494  Validation loss = 6.7119  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 2.0491  Validation loss = 6.7114  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 2.0488  Validation loss = 6.7109  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 2.0484  Validation loss = 6.7103  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 2.0482  Validation loss = 6.7100  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 2.0480  Validation loss = 6.7095  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 2.0477  Validation loss = 6.7090  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 2.0474  Validation loss = 6.7085  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 2.0471  Validation loss = 6.7081  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 2.0468  Validation loss = 6.7077  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 2.0466  Validation loss = 6.7073  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 2.0464  Validation loss = 6.7069  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 2.0460  Validation loss = 6.7063  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 2.0457  Validation loss = 6.7058  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 2.0455  Validation loss = 6.7054  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 2.0453  Validation loss = 6.7051  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 2.0450  Validation loss = 6.7047  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 2.0447  Validation loss = 6.7041  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 2.0443  Validation loss = 6.7035  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 2.0441  Validation loss = 6.7031  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 2.0438  Validation loss = 6.7026  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 2.0435  Validation loss = 6.7021  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 2.0432  Validation loss = 6.7016  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 2.0429  Validation loss = 6.7012  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 2.0427  Validation loss = 6.7007  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 2.0424  Validation loss = 6.7003  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 2.0422  Validation loss = 6.6999  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 2.0419  Validation loss = 6.6995  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 2.0416  Validation loss = 6.6989  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 2.0412  Validation loss = 6.6982  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 2.0409  Validation loss = 6.6977  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 2.0408  Validation loss = 6.6975  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 2.0405  Validation loss = 6.6971  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 2.0403  Validation loss = 6.6968  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 2.0400  Validation loss = 6.6963  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 2.0398  Validation loss = 6.6959  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 2.0395  Validation loss = 6.6955  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 2.0392  Validation loss = 6.6949  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 2.0389  Validation loss = 6.6944  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 2.0386  Validation loss = 6.6939  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 2.0383  Validation loss = 6.6934  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 2.0379  Validation loss = 6.6928  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 2.0376  Validation loss = 6.6923  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 2.0373  Validation loss = 6.6916  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 2.0371  Validation loss = 6.6913  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 2.0368  Validation loss = 6.6909  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 2.0366  Validation loss = 6.6904  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 2.0363  Validation loss = 6.6901  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 2.0361  Validation loss = 6.6896  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 2.0358  Validation loss = 6.6893  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 2.0356  Validation loss = 6.6888  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 2.0353  Validation loss = 6.6884  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 2.0350  Validation loss = 6.6879  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 2.0347  Validation loss = 6.6874  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 2.0344  Validation loss = 6.6870  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 2.0342  Validation loss = 6.6865  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 2.0340  Validation loss = 6.6861  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 2.0337  Validation loss = 6.6856  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 2.0334  Validation loss = 6.6852  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 2.0331  Validation loss = 6.6847  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 2.0330  Validation loss = 6.6845  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 2.0328  Validation loss = 6.6841  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 2.0325  Validation loss = 6.6836  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 2.0322  Validation loss = 6.6832  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 2.0320  Validation loss = 6.6827  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 2.0317  Validation loss = 6.6824  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 2.0314  Validation loss = 6.6819  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 2.0312  Validation loss = 6.6815  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 2.0309  Validation loss = 6.6809  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 2.0307  Validation loss = 6.6806  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 2.0304  Validation loss = 6.6801  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 2.0301  Validation loss = 6.6796  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 2.0298  Validation loss = 6.6791  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 2.0295  Validation loss = 6.6786  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 2.0293  Validation loss = 6.6782  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 2.0290  Validation loss = 6.6777  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 2.0288  Validation loss = 6.6772  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 2.0285  Validation loss = 6.6767  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 2.0282  Validation loss = 6.6763  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 2.0280  Validation loss = 6.6760  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 2.0277  Validation loss = 6.6755  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 2.0274  Validation loss = 6.6750  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 2.0272  Validation loss = 6.6746  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 2.0269  Validation loss = 6.6741  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 2.0267  Validation loss = 6.6737  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 2.0264  Validation loss = 6.6732  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 2.0262  Validation loss = 6.6728  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 2.0259  Validation loss = 6.6725  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 2.0257  Validation loss = 6.6721  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 2.0254  Validation loss = 6.6717  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 2.0252  Validation loss = 6.6712  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 2.0250  Validation loss = 6.6708  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 2.0247  Validation loss = 6.6704  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 2.0244  Validation loss = 6.6699  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 2.0241  Validation loss = 6.6695  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 2.0239  Validation loss = 6.6690  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 2.0237  Validation loss = 6.6687  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 2.0234  Validation loss = 6.6683  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 2.0231  Validation loss = 6.6678  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 2.0229  Validation loss = 6.6674  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 2.0226  Validation loss = 6.6669  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 2.0223  Validation loss = 6.6664  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 2.0221  Validation loss = 6.6661  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 2.0219  Validation loss = 6.6657  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 2.0217  Validation loss = 6.6653  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 2.0215  Validation loss = 6.6650  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 2.0212  Validation loss = 6.6645  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 2.0209  Validation loss = 6.6640  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 2.0206  Validation loss = 6.6636  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 2.0204  Validation loss = 6.6631  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 2.0201  Validation loss = 6.6626  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 2.0197  Validation loss = 6.6621  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 2.0195  Validation loss = 6.6616  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 2.0193  Validation loss = 6.6613  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 2.0190  Validation loss = 6.6609  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 2.0188  Validation loss = 6.6605  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 2.0185  Validation loss = 6.6599  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 2.0183  Validation loss = 6.6596  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 2.0180  Validation loss = 6.6592  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 2.0178  Validation loss = 6.6588  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 2.0175  Validation loss = 6.6582  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 2.0173  Validation loss = 6.6579  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 2.0171  Validation loss = 6.6575  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 2.0168  Validation loss = 6.6570  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 2.0164  Validation loss = 6.6564  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 2.0161  Validation loss = 6.6558  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 2.0158  Validation loss = 6.6554  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 2.0155  Validation loss = 6.6549  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 2.0153  Validation loss = 6.6545  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 2.0150  Validation loss = 6.6541  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 2.0147  Validation loss = 6.6535  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 2.0144  Validation loss = 6.6529  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 2.0140  Validation loss = 6.6524  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 2.0138  Validation loss = 6.6520  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 2.0136  Validation loss = 6.6516  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 2.0134  Validation loss = 6.6512  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 2.0132  Validation loss = 6.6509  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 2.0130  Validation loss = 6.6505  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 2.0127  Validation loss = 6.6500  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 2.0125  Validation loss = 6.6496  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 2.0122  Validation loss = 6.6492  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 2.0118  Validation loss = 6.6486  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 2.0116  Validation loss = 6.6482  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 2.0113  Validation loss = 6.6477  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 2.0111  Validation loss = 6.6473  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 2.0108  Validation loss = 6.6468  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 2.0105  Validation loss = 6.6463  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 2.0102  Validation loss = 6.6458  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 2.0100  Validation loss = 6.6454  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 2.0097  Validation loss = 6.6451  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 2.0095  Validation loss = 6.6446  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 2.0092  Validation loss = 6.6440  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 2.0089  Validation loss = 6.6437  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 2.0087  Validation loss = 6.6432  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 2.0084  Validation loss = 6.6427  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 2.0082  Validation loss = 6.6424  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 2.0079  Validation loss = 6.6419  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 2.0076  Validation loss = 6.6414  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 2.0074  Validation loss = 6.6409  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 2.0072  Validation loss = 6.6407  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 2.0069  Validation loss = 6.6402  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 2.0067  Validation loss = 6.6398  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 2.0064  Validation loss = 6.6394  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 2.0062  Validation loss = 6.6390  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 2.0059  Validation loss = 6.6384  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 2.0056  Validation loss = 6.6379  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 2.0053  Validation loss = 6.6375  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 2.0051  Validation loss = 6.6372  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 2.0049  Validation loss = 6.6368  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 2.0047  Validation loss = 6.6364  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 2.0044  Validation loss = 6.6359  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 2.0041  Validation loss = 6.6354  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 2.0039  Validation loss = 6.6350  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 2.0036  Validation loss = 6.6346  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 2.0033  Validation loss = 6.6341  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 2.0032  Validation loss = 6.6338  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 2.0029  Validation loss = 6.6334  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 2.0026  Validation loss = 6.6329  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 2.0023  Validation loss = 6.6324  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 2.0020  Validation loss = 6.6319  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 2.0019  Validation loss = 6.6316  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 2.0015  Validation loss = 6.6311  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 2.0013  Validation loss = 6.6306  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 2.0010  Validation loss = 6.6301  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 2.0007  Validation loss = 6.6296  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 2.0004  Validation loss = 6.6292  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 2.0002  Validation loss = 6.6287  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 1.9999  Validation loss = 6.6283  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 1.9997  Validation loss = 6.6279  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 1.9994  Validation loss = 6.6273  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 1.9991  Validation loss = 6.6268  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 1.9988  Validation loss = 6.6264  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 1.9985  Validation loss = 6.6258  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 1.9982  Validation loss = 6.6253  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 1.9979  Validation loss = 6.6247  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 1.9977  Validation loss = 6.6245  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 1.9975  Validation loss = 6.6241  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 1.9972  Validation loss = 6.6236  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 1.9970  Validation loss = 6.6232  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 1.9967  Validation loss = 6.6228  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 1.9965  Validation loss = 6.6224  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 1.9963  Validation loss = 6.6221  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 1.9961  Validation loss = 6.6217  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 1.9959  Validation loss = 6.6214  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 1.9957  Validation loss = 6.6210  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 1.9954  Validation loss = 6.6205  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 1.9951  Validation loss = 6.6200  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 1.9949  Validation loss = 6.6197  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 1.9946  Validation loss = 6.6191  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 1.9945  Validation loss = 6.6189  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 1.9941  Validation loss = 6.6183  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 1.9939  Validation loss = 6.6180  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 1.9937  Validation loss = 6.6176  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 1.9934  Validation loss = 6.6172  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 1.9931  Validation loss = 6.6166  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 1.9929  Validation loss = 6.6162  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 1.9927  Validation loss = 6.6158  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 1.9924  Validation loss = 6.6155  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 1.9923  Validation loss = 6.6151  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 1.9920  Validation loss = 6.6146  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 1.9916  Validation loss = 6.6141  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 1.9914  Validation loss = 6.6137  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 1.9912  Validation loss = 6.6134  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 1.9910  Validation loss = 6.6130  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 1.9908  Validation loss = 6.6127  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 1.9906  Validation loss = 6.6123  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 1.9904  Validation loss = 6.6119  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 1.9901  Validation loss = 6.6114  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 1.9899  Validation loss = 6.6109  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 1.9896  Validation loss = 6.6104  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 1.9893  Validation loss = 6.6100  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 1.9890  Validation loss = 6.6095  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 1.9888  Validation loss = 6.6092  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 1.9886  Validation loss = 6.6088  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 1.9883  Validation loss = 6.6083  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 1.9880  Validation loss = 6.6078  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 1.9878  Validation loss = 6.6073  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 1.9875  Validation loss = 6.6068  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 1.9873  Validation loss = 6.6065  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 1.9870  Validation loss = 6.6060  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 1.9867  Validation loss = 6.6056  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 1.9865  Validation loss = 6.6051  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 1.9862  Validation loss = 6.6047  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 1.9860  Validation loss = 6.6043  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 1.9857  Validation loss = 6.6039  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 1.9854  Validation loss = 6.6032  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 1.9851  Validation loss = 6.6029  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 1.9849  Validation loss = 6.6025  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 1.9846  Validation loss = 6.6020  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 1.9844  Validation loss = 6.6016  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 1.9842  Validation loss = 6.6012  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 1.9839  Validation loss = 6.6008  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 1.9837  Validation loss = 6.6004  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 1.9834  Validation loss = 6.5999  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 1.9832  Validation loss = 6.5994  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 1.9829  Validation loss = 6.5989  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 1.9827  Validation loss = 6.5987  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 1.9825  Validation loss = 6.5983  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 1.9823  Validation loss = 6.5978  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 1.9820  Validation loss = 6.5974  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 1.9818  Validation loss = 6.5971  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 1.9816  Validation loss = 6.5967  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 1.9814  Validation loss = 6.5963  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 1.9811  Validation loss = 6.5959  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 1.9810  Validation loss = 6.5956  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 1.9807  Validation loss = 6.5951  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 1.9804  Validation loss = 6.5947  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 1.9802  Validation loss = 6.5943  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 1.9799  Validation loss = 6.5938  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 1.9797  Validation loss = 6.5933  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 1.9794  Validation loss = 6.5929  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 1.9792  Validation loss = 6.5925  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 1.9790  Validation loss = 6.5921  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 1.9787  Validation loss = 6.5916  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 1.9784  Validation loss = 6.5912  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 1.9782  Validation loss = 6.5907  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 1.9779  Validation loss = 6.5902  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 1.9776  Validation loss = 6.5898  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 1.9774  Validation loss = 6.5894  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 1.9772  Validation loss = 6.5889  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 1.9769  Validation loss = 6.5886  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 1.9766  Validation loss = 6.5880  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 1.9764  Validation loss = 6.5877  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 1.9762  Validation loss = 6.5873  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 1.9760  Validation loss = 6.5868  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 1.9756  Validation loss = 6.5863  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 1.9754  Validation loss = 6.5859  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 1.9752  Validation loss = 6.5856  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 1.9749  Validation loss = 6.5851  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 1.9746  Validation loss = 6.5845  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 1.9744  Validation loss = 6.5841  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 1.9742  Validation loss = 6.5838  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 1.9740  Validation loss = 6.5834  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 1.9738  Validation loss = 6.5831  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 1.9735  Validation loss = 6.5826  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 1.9733  Validation loss = 6.5822  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 1.9730  Validation loss = 6.5817  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 1.9728  Validation loss = 6.5814  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 1.9726  Validation loss = 6.5810  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 500  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.5188  Validation loss = 10.3995  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.5185  Validation loss = 10.3987  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.5182  Validation loss = 10.3979  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.5179  Validation loss = 10.3970  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.5177  Validation loss = 10.3965  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.5174  Validation loss = 10.3958  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.5171  Validation loss = 10.3948  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.5168  Validation loss = 10.3939  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.5165  Validation loss = 10.3930  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.5161  Validation loss = 10.3921  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.5158  Validation loss = 10.3913  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.5155  Validation loss = 10.3904  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.5152  Validation loss = 10.3897  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.5148  Validation loss = 10.3887  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.5145  Validation loss = 10.3880  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.5142  Validation loss = 10.3872  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.5138  Validation loss = 10.3863  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.5135  Validation loss = 10.3855  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.5132  Validation loss = 10.3848  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.5127  Validation loss = 10.3839  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.5124  Validation loss = 10.3830  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.5121  Validation loss = 10.3824  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.5118  Validation loss = 10.3817  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.5115  Validation loss = 10.3810  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.5111  Validation loss = 10.3802  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.5108  Validation loss = 10.3793  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.5103  Validation loss = 10.3782  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.5100  Validation loss = 10.3776  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.5098  Validation loss = 10.3771  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.5094  Validation loss = 10.3763  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.5090  Validation loss = 10.3755  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.5088  Validation loss = 10.3749  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.5085  Validation loss = 10.3744  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.5082  Validation loss = 10.3736  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.5079  Validation loss = 10.3730  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.5076  Validation loss = 10.3724  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.5073  Validation loss = 10.3718  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.5070  Validation loss = 10.3712  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.5067  Validation loss = 10.3706  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.5064  Validation loss = 10.3701  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.5061  Validation loss = 10.3694  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.5058  Validation loss = 10.3687  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.5055  Validation loss = 10.3680  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.5053  Validation loss = 10.3677  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.5050  Validation loss = 10.3670  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.5047  Validation loss = 10.3665  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.5043  Validation loss = 10.3658  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.5041  Validation loss = 10.3652  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.5038  Validation loss = 10.3645  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.5034  Validation loss = 10.3638  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.5031  Validation loss = 10.3630  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.5028  Validation loss = 10.3625  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.5025  Validation loss = 10.3619  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.5023  Validation loss = 10.3612  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.5020  Validation loss = 10.3606  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.5016  Validation loss = 10.3597  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.5013  Validation loss = 10.3590  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.5009  Validation loss = 10.3581  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.5007  Validation loss = 10.3576  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.5004  Validation loss = 10.3570  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.5000  Validation loss = 10.3561  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.4997  Validation loss = 10.3555  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.4994  Validation loss = 10.3548  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.4991  Validation loss = 10.3541  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.4988  Validation loss = 10.3534  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.4985  Validation loss = 10.3527  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.4983  Validation loss = 10.3523  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.4979  Validation loss = 10.3515  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.4976  Validation loss = 10.3510  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.4974  Validation loss = 10.3506  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.4972  Validation loss = 10.3501  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.4968  Validation loss = 10.3492  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.4965  Validation loss = 10.3486  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.4962  Validation loss = 10.3481  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.4960  Validation loss = 10.3475  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.4957  Validation loss = 10.3470  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.4955  Validation loss = 10.3464  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.4953  Validation loss = 10.3460  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.4950  Validation loss = 10.3455  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.4946  Validation loss = 10.3447  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.4944  Validation loss = 10.3441  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.4941  Validation loss = 10.3434  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.4937  Validation loss = 10.3426  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.4933  Validation loss = 10.3417  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.4931  Validation loss = 10.3413  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.4928  Validation loss = 10.3408  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.4926  Validation loss = 10.3403  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.4922  Validation loss = 10.3396  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.4920  Validation loss = 10.3392  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.4916  Validation loss = 10.3383  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.4913  Validation loss = 10.3378  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.4910  Validation loss = 10.3372  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.4907  Validation loss = 10.3366  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.4904  Validation loss = 10.3359  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.4901  Validation loss = 10.3352  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.4898  Validation loss = 10.3346  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.4895  Validation loss = 10.3341  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.4892  Validation loss = 10.3334  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.4889  Validation loss = 10.3327  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.4886  Validation loss = 10.3321  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.4883  Validation loss = 10.3315  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.4880  Validation loss = 10.3309  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.4878  Validation loss = 10.3304  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.4876  Validation loss = 10.3301  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.4873  Validation loss = 10.3295  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.4870  Validation loss = 10.3288  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.4866  Validation loss = 10.3282  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.4863  Validation loss = 10.3274  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.4860  Validation loss = 10.3267  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.4856  Validation loss = 10.3258  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.4853  Validation loss = 10.3252  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.4851  Validation loss = 10.3246  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.4848  Validation loss = 10.3240  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.4844  Validation loss = 10.3233  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.4842  Validation loss = 10.3227  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.4839  Validation loss = 10.3221  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.4836  Validation loss = 10.3215  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 2.4833  Validation loss = 10.3208  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 2.4830  Validation loss = 10.3203  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 2.4826  Validation loss = 10.3196  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 2.4824  Validation loss = 10.3190  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 2.4820  Validation loss = 10.3181  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 2.4817  Validation loss = 10.3173  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 2.4815  Validation loss = 10.3169  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 2.4812  Validation loss = 10.3164  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 2.4810  Validation loss = 10.3158  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 2.4807  Validation loss = 10.3151  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 2.4803  Validation loss = 10.3143  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 2.4799  Validation loss = 10.3135  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 2.4796  Validation loss = 10.3127  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 2.4792  Validation loss = 10.3119  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 2.4789  Validation loss = 10.3111  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 2.4787  Validation loss = 10.3106  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 2.4784  Validation loss = 10.3099  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 2.4782  Validation loss = 10.3095  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 2.4779  Validation loss = 10.3088  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 2.4775  Validation loss = 10.3081  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 2.4772  Validation loss = 10.3076  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 2.4769  Validation loss = 10.3069  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 2.4766  Validation loss = 10.3063  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 2.4763  Validation loss = 10.3056  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 2.4760  Validation loss = 10.3049  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 2.4758  Validation loss = 10.3043  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 2.4755  Validation loss = 10.3036  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 2.4751  Validation loss = 10.3028  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 2.4748  Validation loss = 10.3023  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 2.4746  Validation loss = 10.3018  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 2.4743  Validation loss = 10.3012  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 2.4740  Validation loss = 10.3005  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 2.4736  Validation loss = 10.2999  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 2.4733  Validation loss = 10.2992  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 2.4730  Validation loss = 10.2985  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 2.4726  Validation loss = 10.2977  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 2.4725  Validation loss = 10.2974  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 2.4723  Validation loss = 10.2970  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 2.4719  Validation loss = 10.2962  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 2.4715  Validation loss = 10.2954  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 2.4712  Validation loss = 10.2948  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 2.4709  Validation loss = 10.2941  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 2.4707  Validation loss = 10.2936  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 2.4704  Validation loss = 10.2929  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 2.4702  Validation loss = 10.2926  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 2.4699  Validation loss = 10.2919  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 2.4697  Validation loss = 10.2915  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 2.4694  Validation loss = 10.2908  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 2.4690  Validation loss = 10.2900  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 2.4687  Validation loss = 10.2894  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 2.4685  Validation loss = 10.2888  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 2.4682  Validation loss = 10.2885  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 2.4679  Validation loss = 10.2878  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 2.4676  Validation loss = 10.2873  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 2.4673  Validation loss = 10.2865  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 2.4670  Validation loss = 10.2859  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 2.4669  Validation loss = 10.2855  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 2.4666  Validation loss = 10.2849  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 2.4662  Validation loss = 10.2842  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 2.4658  Validation loss = 10.2833  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 2.4655  Validation loss = 10.2826  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 2.4652  Validation loss = 10.2818  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 2.4649  Validation loss = 10.2812  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 2.4646  Validation loss = 10.2805  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 2.4643  Validation loss = 10.2798  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 2.4641  Validation loss = 10.2793  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 2.4639  Validation loss = 10.2787  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 2.4635  Validation loss = 10.2780  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 2.4632  Validation loss = 10.2774  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 2.4630  Validation loss = 10.2769  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 2.4627  Validation loss = 10.2763  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 2.4624  Validation loss = 10.2757  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 2.4622  Validation loss = 10.2752  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 2.4618  Validation loss = 10.2744  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 2.4615  Validation loss = 10.2737  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 2.4612  Validation loss = 10.2732  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 2.4609  Validation loss = 10.2724  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 2.4606  Validation loss = 10.2717  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 2.4603  Validation loss = 10.2711  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 2.4599  Validation loss = 10.2703  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 2.4596  Validation loss = 10.2697  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 2.4593  Validation loss = 10.2689  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 2.4590  Validation loss = 10.2683  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 2.4587  Validation loss = 10.2675  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 2.4584  Validation loss = 10.2666  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 2.4581  Validation loss = 10.2661  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 2.4578  Validation loss = 10.2656  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 2.4575  Validation loss = 10.2649  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 2.4573  Validation loss = 10.2644  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 2.4571  Validation loss = 10.2638  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 2.4567  Validation loss = 10.2632  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 2.4565  Validation loss = 10.2626  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 2.4563  Validation loss = 10.2621  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 2.4560  Validation loss = 10.2614  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 2.4557  Validation loss = 10.2608  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 2.4555  Validation loss = 10.2603  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 2.4552  Validation loss = 10.2596  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 2.4549  Validation loss = 10.2591  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 2.4547  Validation loss = 10.2586  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 2.4544  Validation loss = 10.2581  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 2.4542  Validation loss = 10.2576  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 2.4538  Validation loss = 10.2568  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 2.4535  Validation loss = 10.2562  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 2.4532  Validation loss = 10.2554  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 2.4529  Validation loss = 10.2549  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 2.4526  Validation loss = 10.2542  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 2.4524  Validation loss = 10.2537  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 2.4520  Validation loss = 10.2529  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 2.4517  Validation loss = 10.2523  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 2.4514  Validation loss = 10.2517  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 2.4512  Validation loss = 10.2511  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 2.4508  Validation loss = 10.2505  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 2.4506  Validation loss = 10.2501  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 2.4503  Validation loss = 10.2494  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 2.4500  Validation loss = 10.2488  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 2.4498  Validation loss = 10.2482  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 2.4495  Validation loss = 10.2477  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 2.4493  Validation loss = 10.2473  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 2.4490  Validation loss = 10.2467  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 2.4487  Validation loss = 10.2461  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 2.4486  Validation loss = 10.2458  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 2.4482  Validation loss = 10.2451  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 2.4479  Validation loss = 10.2443  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 2.4476  Validation loss = 10.2438  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 2.4473  Validation loss = 10.2430  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 2.4472  Validation loss = 10.2427  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 2.4469  Validation loss = 10.2421  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 2.4466  Validation loss = 10.2414  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 2.4464  Validation loss = 10.2409  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 2.4461  Validation loss = 10.2404  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 2.4458  Validation loss = 10.2399  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 2.4456  Validation loss = 10.2394  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 2.4452  Validation loss = 10.2385  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 2.4450  Validation loss = 10.2380  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 2.4447  Validation loss = 10.2374  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 2.4444  Validation loss = 10.2368  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 2.4442  Validation loss = 10.2362  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 2.4440  Validation loss = 10.2357  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 2.4437  Validation loss = 10.2351  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 2.4434  Validation loss = 10.2345  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 2.4432  Validation loss = 10.2340  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 2.4429  Validation loss = 10.2334  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 2.4426  Validation loss = 10.2327  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 2.4424  Validation loss = 10.2322  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 2.4421  Validation loss = 10.2316  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 2.4418  Validation loss = 10.2310  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 2.4415  Validation loss = 10.2305  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 2.4412  Validation loss = 10.2298  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 2.4411  Validation loss = 10.2295  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 2.4408  Validation loss = 10.2289  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 2.4405  Validation loss = 10.2283  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 2.4403  Validation loss = 10.2277  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 2.4400  Validation loss = 10.2271  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 2.4398  Validation loss = 10.2267  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 2.4395  Validation loss = 10.2261  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 2.4392  Validation loss = 10.2256  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 2.4390  Validation loss = 10.2250  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 2.4386  Validation loss = 10.2242  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 2.4384  Validation loss = 10.2236  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 2.4381  Validation loss = 10.2232  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 2.4379  Validation loss = 10.2228  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 2.4378  Validation loss = 10.2224  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 2.4375  Validation loss = 10.2218  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 2.4372  Validation loss = 10.2212  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 2.4369  Validation loss = 10.2206  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 2.4367  Validation loss = 10.2201  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 2.4364  Validation loss = 10.2196  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 2.4362  Validation loss = 10.2191  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 2.4358  Validation loss = 10.2182  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 2.4355  Validation loss = 10.2174  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 2.4352  Validation loss = 10.2168  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 2.4350  Validation loss = 10.2162  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 2.4348  Validation loss = 10.2157  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 2.4345  Validation loss = 10.2152  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 2.4342  Validation loss = 10.2145  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 2.4340  Validation loss = 10.2140  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 2.4337  Validation loss = 10.2135  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 2.4335  Validation loss = 10.2129  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 2.4332  Validation loss = 10.2123  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 2.4330  Validation loss = 10.2117  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 2.4327  Validation loss = 10.2111  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 2.4323  Validation loss = 10.2104  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 2.4320  Validation loss = 10.2096  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 2.4317  Validation loss = 10.2088  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 2.4314  Validation loss = 10.2082  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 2.4311  Validation loss = 10.2075  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 2.4309  Validation loss = 10.2070  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 2.4305  Validation loss = 10.2062  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 2.4303  Validation loss = 10.2056  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 2.4300  Validation loss = 10.2049  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 2.4297  Validation loss = 10.2044  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 2.4294  Validation loss = 10.2037  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 2.4291  Validation loss = 10.2031  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 2.4288  Validation loss = 10.2023  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 2.4284  Validation loss = 10.2015  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 2.4282  Validation loss = 10.2009  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 2.4279  Validation loss = 10.2002  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 2.4276  Validation loss = 10.1996  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 2.4274  Validation loss = 10.1991  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 2.4272  Validation loss = 10.1986  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 2.4269  Validation loss = 10.1980  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 2.4266  Validation loss = 10.1974  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 2.4263  Validation loss = 10.1967  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 2.4261  Validation loss = 10.1962  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 2.4258  Validation loss = 10.1955  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 2.4255  Validation loss = 10.1948  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 2.4252  Validation loss = 10.1943  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 2.4250  Validation loss = 10.1939  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 2.4248  Validation loss = 10.1933  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 2.4245  Validation loss = 10.1928  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 2.4242  Validation loss = 10.1920  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 2.4239  Validation loss = 10.1914  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 2.4237  Validation loss = 10.1910  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 2.4234  Validation loss = 10.1905  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 2.4231  Validation loss = 10.1898  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 2.4229  Validation loss = 10.1893  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 2.4227  Validation loss = 10.1889  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 2.4225  Validation loss = 10.1884  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 2.4221  Validation loss = 10.1876  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 2.4219  Validation loss = 10.1872  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 2.4216  Validation loss = 10.1865  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 2.4213  Validation loss = 10.1858  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 2.4210  Validation loss = 10.1853  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 2.4208  Validation loss = 10.1848  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 2.4205  Validation loss = 10.1841  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 2.4202  Validation loss = 10.1836  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 2.4200  Validation loss = 10.1830  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 2.4197  Validation loss = 10.1823  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 2.4194  Validation loss = 10.1815  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 2.4191  Validation loss = 10.1809  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 2.4188  Validation loss = 10.1803  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 2.4185  Validation loss = 10.1798  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 2.4183  Validation loss = 10.1794  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 2.4181  Validation loss = 10.1789  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 2.4178  Validation loss = 10.1781  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 2.4175  Validation loss = 10.1775  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 2.4174  Validation loss = 10.1771  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 2.4171  Validation loss = 10.1765  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 2.4169  Validation loss = 10.1761  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 2.4167  Validation loss = 10.1756  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 2.4163  Validation loss = 10.1747  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 2.4159  Validation loss = 10.1738  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 2.4157  Validation loss = 10.1734  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 2.4154  Validation loss = 10.1726  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 2.4152  Validation loss = 10.1722  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 2.4148  Validation loss = 10.1713  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 2.4146  Validation loss = 10.1708  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 2.4143  Validation loss = 10.1703  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 2.4142  Validation loss = 10.1699  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 2.4140  Validation loss = 10.1695  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 2.4137  Validation loss = 10.1689  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 2.4135  Validation loss = 10.1683  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 2.4133  Validation loss = 10.1679  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 2.4130  Validation loss = 10.1673  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 2.4128  Validation loss = 10.1670  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 2.4126  Validation loss = 10.1664  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 2.4124  Validation loss = 10.1659  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 2.4121  Validation loss = 10.1653  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 2.4119  Validation loss = 10.1647  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 2.4115  Validation loss = 10.1639  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 2.4113  Validation loss = 10.1634  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 2.4110  Validation loss = 10.1627  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 2.4107  Validation loss = 10.1621  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 2.4105  Validation loss = 10.1617  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 2.4103  Validation loss = 10.1611  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 2.4100  Validation loss = 10.1606  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 2.4097  Validation loss = 10.1598  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 2.4094  Validation loss = 10.1591  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 2.4092  Validation loss = 10.1586  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 2.4089  Validation loss = 10.1580  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 2.4086  Validation loss = 10.1573  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 2.4084  Validation loss = 10.1569  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 2.4081  Validation loss = 10.1563  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 2.4079  Validation loss = 10.1559  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 2.4077  Validation loss = 10.1555  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 2.4074  Validation loss = 10.1548  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 2.4072  Validation loss = 10.1544  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 2.4069  Validation loss = 10.1538  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 2.4066  Validation loss = 10.1532  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 2.4064  Validation loss = 10.1526  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 2.4062  Validation loss = 10.1522  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 2.4059  Validation loss = 10.1515  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 2.4056  Validation loss = 10.1508  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 2.4054  Validation loss = 10.1503  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 2.4052  Validation loss = 10.1499  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 2.4048  Validation loss = 10.1489  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 2.4045  Validation loss = 10.1484  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 2.4043  Validation loss = 10.1481  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 2.4042  Validation loss = 10.1477  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 2.4039  Validation loss = 10.1470  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 2.4036  Validation loss = 10.1462  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 2.4033  Validation loss = 10.1454  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 2.4030  Validation loss = 10.1448  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 2.4027  Validation loss = 10.1441  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 2.4024  Validation loss = 10.1433  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 2.4021  Validation loss = 10.1428  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 2.4019  Validation loss = 10.1423  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 2.4016  Validation loss = 10.1414  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 2.4013  Validation loss = 10.1407  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 2.4010  Validation loss = 10.1401  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 2.4008  Validation loss = 10.1397  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 2.4006  Validation loss = 10.1392  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 2.4004  Validation loss = 10.1387  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 2.4002  Validation loss = 10.1383  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 2.4000  Validation loss = 10.1378  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 2.3998  Validation loss = 10.1374  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 2.3996  Validation loss = 10.1370  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 2.3994  Validation loss = 10.1363  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 2.3992  Validation loss = 10.1359  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 2.3989  Validation loss = 10.1354  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 2.3986  Validation loss = 10.1347  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 2.3984  Validation loss = 10.1340  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 2.3981  Validation loss = 10.1335  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 2.3979  Validation loss = 10.1330  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 2.3977  Validation loss = 10.1325  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 2.3975  Validation loss = 10.1320  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 2.3973  Validation loss = 10.1318  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 2.3970  Validation loss = 10.1311  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 2.3968  Validation loss = 10.1306  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 2.3965  Validation loss = 10.1300  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 2.3963  Validation loss = 10.1294  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 2.3961  Validation loss = 10.1291  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 2.3960  Validation loss = 10.1288  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 2.3957  Validation loss = 10.1281  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 2.3954  Validation loss = 10.1276  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 2.3952  Validation loss = 10.1271  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 2.3950  Validation loss = 10.1266  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 2.3947  Validation loss = 10.1259  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 2.3943  Validation loss = 10.1250  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 2.3941  Validation loss = 10.1245  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 2.3939  Validation loss = 10.1240  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 2.3937  Validation loss = 10.1235  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 2.3934  Validation loss = 10.1230  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 2.3933  Validation loss = 10.1226  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 2.3930  Validation loss = 10.1221  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 2.3928  Validation loss = 10.1216  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 2.3926  Validation loss = 10.1210  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 2.3923  Validation loss = 10.1203  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 2.3920  Validation loss = 10.1198  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 2.3918  Validation loss = 10.1192  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 2.3915  Validation loss = 10.1187  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 2.3913  Validation loss = 10.1181  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 2.3911  Validation loss = 10.1177  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 2.3909  Validation loss = 10.1172  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 2.3905  Validation loss = 10.1162  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 2.3903  Validation loss = 10.1158  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 2.3901  Validation loss = 10.1153  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 2.3899  Validation loss = 10.1148  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 2.3896  Validation loss = 10.1141  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 2.3894  Validation loss = 10.1136  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 2.3891  Validation loss = 10.1130  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 2.3889  Validation loss = 10.1126  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 2.3887  Validation loss = 10.1121  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 2.3885  Validation loss = 10.1116  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 2.3883  Validation loss = 10.1109  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 2.3880  Validation loss = 10.1104  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 2.3878  Validation loss = 10.1099  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 2.3876  Validation loss = 10.1094  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 2.3874  Validation loss = 10.1090  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 2.3872  Validation loss = 10.1086  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 2.3869  Validation loss = 10.1080  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 2.3867  Validation loss = 10.1072  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 2.3864  Validation loss = 10.1066  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 2.3861  Validation loss = 10.1060  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 2.3859  Validation loss = 10.1054  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 2.3856  Validation loss = 10.1047  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 2.3854  Validation loss = 10.1042  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 2.3851  Validation loss = 10.1035  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 2.3848  Validation loss = 10.1028  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 2.3846  Validation loss = 10.1022  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 2.3842  Validation loss = 10.1015  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 2.3840  Validation loss = 10.1009  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 2.3836  Validation loss = 10.1001  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 2.3833  Validation loss = 10.0995  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 2.3830  Validation loss = 10.0988  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 2.3827  Validation loss = 10.0981  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 2.3825  Validation loss = 10.0976  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 2.3823  Validation loss = 10.0970  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 2.3821  Validation loss = 10.0965  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 2.3817  Validation loss = 10.0956  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 2.3815  Validation loss = 10.0950  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 2.3812  Validation loss = 10.0943  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 2.3809  Validation loss = 10.0935  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 3.4271  Validation loss = 5.3337  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 3.4267  Validation loss = 5.3328  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 3.4264  Validation loss = 5.3321  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 3.4260  Validation loss = 5.3315  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 3.4256  Validation loss = 5.3307  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 3.4252  Validation loss = 5.3302  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 3.4244  Validation loss = 5.3288  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 3.4238  Validation loss = 5.3275  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 3.4232  Validation loss = 5.3267  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 3.4227  Validation loss = 5.3257  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 3.4221  Validation loss = 5.3244  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 3.4215  Validation loss = 5.3235  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 3.4211  Validation loss = 5.3227  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 3.4206  Validation loss = 5.3215  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 3.4201  Validation loss = 5.3206  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 3.4197  Validation loss = 5.3201  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 3.4192  Validation loss = 5.3193  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 3.4187  Validation loss = 5.3186  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 3.4184  Validation loss = 5.3179  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 3.4178  Validation loss = 5.3167  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 3.4172  Validation loss = 5.3156  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 3.4168  Validation loss = 5.3150  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 3.4163  Validation loss = 5.3139  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 3.4159  Validation loss = 5.3133  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 3.4152  Validation loss = 5.3119  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 3.4147  Validation loss = 5.3113  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 3.4141  Validation loss = 5.3102  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 3.4138  Validation loss = 5.3097  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 3.4134  Validation loss = 5.3090  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 3.4128  Validation loss = 5.3078  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 3.4124  Validation loss = 5.3070  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 3.4119  Validation loss = 5.3058  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 3.4114  Validation loss = 5.3049  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 3.4111  Validation loss = 5.3043  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 3.4106  Validation loss = 5.3034  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 3.4103  Validation loss = 5.3029  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 3.4098  Validation loss = 5.3018  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 3.4092  Validation loss = 5.3005  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 3.4087  Validation loss = 5.2998  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 3.4083  Validation loss = 5.2991  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 3.4079  Validation loss = 5.2984  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 3.4073  Validation loss = 5.2973  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 3.4067  Validation loss = 5.2964  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 3.4065  Validation loss = 5.2960  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 3.4061  Validation loss = 5.2951  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 3.4056  Validation loss = 5.2942  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 3.4052  Validation loss = 5.2936  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 3.4048  Validation loss = 5.2927  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 3.4045  Validation loss = 5.2920  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 3.4040  Validation loss = 5.2909  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 3.4033  Validation loss = 5.2899  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 3.4029  Validation loss = 5.2888  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 3.4024  Validation loss = 5.2881  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 3.4019  Validation loss = 5.2870  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 3.4014  Validation loss = 5.2863  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 3.4011  Validation loss = 5.2857  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 3.4006  Validation loss = 5.2845  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 3.4002  Validation loss = 5.2836  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 3.3997  Validation loss = 5.2825  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 3.3993  Validation loss = 5.2817  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 3.3987  Validation loss = 5.2803  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 3.3982  Validation loss = 5.2792  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 3.3977  Validation loss = 5.2782  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 3.3972  Validation loss = 5.2772  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 3.3966  Validation loss = 5.2760  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 3.3958  Validation loss = 5.2742  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 3.3954  Validation loss = 5.2734  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 3.3947  Validation loss = 5.2722  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 3.3943  Validation loss = 5.2712  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 3.3937  Validation loss = 5.2702  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 3.3934  Validation loss = 5.2698  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 3.3932  Validation loss = 5.2694  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 3.3927  Validation loss = 5.2683  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 3.3922  Validation loss = 5.2674  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 3.3917  Validation loss = 5.2662  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 3.3913  Validation loss = 5.2654  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 3.3909  Validation loss = 5.2646  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 3.3905  Validation loss = 5.2637  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 3.3900  Validation loss = 5.2628  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 3.3895  Validation loss = 5.2618  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 3.3890  Validation loss = 5.2607  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 3.3885  Validation loss = 5.2595  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 3.3881  Validation loss = 5.2588  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 3.3876  Validation loss = 5.2576  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 3.3871  Validation loss = 5.2569  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 3.3867  Validation loss = 5.2560  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 3.3864  Validation loss = 5.2554  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 3.3857  Validation loss = 5.2538  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 3.3854  Validation loss = 5.2532  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 3.3850  Validation loss = 5.2523  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 3.3844  Validation loss = 5.2511  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 3.3840  Validation loss = 5.2502  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 3.3838  Validation loss = 5.2498  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 3.3833  Validation loss = 5.2488  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 3.3829  Validation loss = 5.2478  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 3.3823  Validation loss = 5.2468  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 3.3819  Validation loss = 5.2461  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 3.3814  Validation loss = 5.2450  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 3.3809  Validation loss = 5.2440  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 3.3805  Validation loss = 5.2431  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 3.3798  Validation loss = 5.2414  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 3.3794  Validation loss = 5.2408  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 3.3790  Validation loss = 5.2398  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 3.3787  Validation loss = 5.2392  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 3.3780  Validation loss = 5.2381  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 3.3776  Validation loss = 5.2373  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 3.3772  Validation loss = 5.2365  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 3.3768  Validation loss = 5.2355  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 3.3765  Validation loss = 5.2348  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 3.3759  Validation loss = 5.2336  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 3.3756  Validation loss = 5.2328  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 3.3750  Validation loss = 5.2315  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 3.3746  Validation loss = 5.2308  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 3.3741  Validation loss = 5.2298  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 3.3737  Validation loss = 5.2289  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 3.3733  Validation loss = 5.2278  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 3.3730  Validation loss = 5.2272  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 3.3724  Validation loss = 5.2260  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 3.3719  Validation loss = 5.2248  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 3.3713  Validation loss = 5.2237  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 3.3706  Validation loss = 5.2224  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 3.3702  Validation loss = 5.2214  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 3.3697  Validation loss = 5.2205  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 3.3692  Validation loss = 5.2194  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 3.3686  Validation loss = 5.2184  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 3.3682  Validation loss = 5.2174  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 3.3680  Validation loss = 5.2169  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 3.3676  Validation loss = 5.2161  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 3.3672  Validation loss = 5.2149  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 3.3666  Validation loss = 5.2138  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 3.3662  Validation loss = 5.2129  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 3.3658  Validation loss = 5.2119  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 3.3654  Validation loss = 5.2110  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 3.3649  Validation loss = 5.2096  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 3.3647  Validation loss = 5.2092  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 3.3643  Validation loss = 5.2084  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 3.3638  Validation loss = 5.2075  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 3.3635  Validation loss = 5.2068  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 3.3629  Validation loss = 5.2058  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 3.3625  Validation loss = 5.2049  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 3.3620  Validation loss = 5.2038  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 3.3616  Validation loss = 5.2029  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 3.3611  Validation loss = 5.2020  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 3.3607  Validation loss = 5.2014  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 3.3601  Validation loss = 5.2000  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 3.3596  Validation loss = 5.1992  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 3.3592  Validation loss = 5.1984  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 3.3588  Validation loss = 5.1974  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 3.3585  Validation loss = 5.1966  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 3.3580  Validation loss = 5.1954  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 3.3574  Validation loss = 5.1942  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 3.3568  Validation loss = 5.1930  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 3.3557  Validation loss = 5.1897  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 3.3521  Validation loss = 5.1764  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 3.3485  Validation loss = 5.1630  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 3.3479  Validation loss = 5.1625  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 3.3476  Validation loss = 5.1620  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 3.3471  Validation loss = 5.1612  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 3.3466  Validation loss = 5.1604  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 3.3462  Validation loss = 5.1601  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 3.3456  Validation loss = 5.1591  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 3.3451  Validation loss = 5.1580  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 3.3446  Validation loss = 5.1572  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 3.3443  Validation loss = 5.1563  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 3.3438  Validation loss = 5.1553  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 3.3434  Validation loss = 5.1545  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 3.3430  Validation loss = 5.1540  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 3.3427  Validation loss = 5.1533  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 3.3422  Validation loss = 5.1522  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 3.3419  Validation loss = 5.1519  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 3.3413  Validation loss = 5.1510  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 3.3407  Validation loss = 5.1493  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 3.3401  Validation loss = 5.1479  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 3.3394  Validation loss = 5.1448  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 3.3389  Validation loss = 5.1441  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 3.3382  Validation loss = 5.1428  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 3.3377  Validation loss = 5.1417  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 3.3373  Validation loss = 5.1409  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 3.3369  Validation loss = 5.1400  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 3.3363  Validation loss = 5.1390  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 3.3357  Validation loss = 5.1379  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 3.3351  Validation loss = 5.1361  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 3.3345  Validation loss = 5.1347  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 3.3338  Validation loss = 5.1308  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 3.3324  Validation loss = 5.1118  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 3.3317  Validation loss = 5.1015  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 3.3302  Validation loss = 5.0840  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 3.3297  Validation loss = 5.0823  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 3.3293  Validation loss = 5.0813  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 3.3287  Validation loss = 5.0798  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 3.3283  Validation loss = 5.0789  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 3.3280  Validation loss = 5.0782  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 3.3275  Validation loss = 5.0772  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 3.3271  Validation loss = 5.0764  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 3.3267  Validation loss = 5.0755  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 3.3264  Validation loss = 5.0748  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 3.3258  Validation loss = 5.0735  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 3.3253  Validation loss = 5.0727  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 3.3250  Validation loss = 5.0719  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 3.3245  Validation loss = 5.0709  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 3.3242  Validation loss = 5.0702  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 3.3238  Validation loss = 5.0694  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 3.3233  Validation loss = 5.0682  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 3.3227  Validation loss = 5.0669  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 3.3222  Validation loss = 5.0659  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 3.3217  Validation loss = 5.0648  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 3.3213  Validation loss = 5.0639  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 3.3210  Validation loss = 5.0632  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 3.3207  Validation loss = 5.0626  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 3.3205  Validation loss = 5.0622  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 3.3202  Validation loss = 5.0616  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 3.3196  Validation loss = 5.0603  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 3.3191  Validation loss = 5.0592  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 3.3186  Validation loss = 5.0582  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 3.3181  Validation loss = 5.0572  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 3.3178  Validation loss = 5.0564  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 3.3172  Validation loss = 5.0553  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 3.3169  Validation loss = 5.0545  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 3.3165  Validation loss = 5.0537  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 3.3160  Validation loss = 5.0526  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 3.3155  Validation loss = 5.0513  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 3.3150  Validation loss = 5.0503  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 3.3146  Validation loss = 5.0494  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 3.3141  Validation loss = 5.0485  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 3.3138  Validation loss = 5.0478  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 3.3133  Validation loss = 5.0469  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 3.3128  Validation loss = 5.0457  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 3.3125  Validation loss = 5.0451  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 3.3120  Validation loss = 5.0440  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 3.3116  Validation loss = 5.0432  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 3.3113  Validation loss = 5.0424  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 3.3108  Validation loss = 5.0414  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 3.3103  Validation loss = 5.0403  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 3.3099  Validation loss = 5.0394  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 3.3095  Validation loss = 5.0383  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 3.3091  Validation loss = 5.0375  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 3.3089  Validation loss = 5.0370  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 3.3083  Validation loss = 5.0359  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 3.3077  Validation loss = 5.0343  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 3.3073  Validation loss = 5.0334  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 3.3069  Validation loss = 5.0324  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 3.3064  Validation loss = 5.0316  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 3.3058  Validation loss = 5.0302  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 3.3053  Validation loss = 5.0290  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 3.3048  Validation loss = 5.0279  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 3.3044  Validation loss = 5.0269  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 3.3040  Validation loss = 5.0262  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 3.3037  Validation loss = 5.0255  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 3.3033  Validation loss = 5.0245  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 3.3028  Validation loss = 5.0234  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 3.3025  Validation loss = 5.0228  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 3.3019  Validation loss = 5.0215  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 3.3014  Validation loss = 5.0204  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 3.3010  Validation loss = 5.0193  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 3.3006  Validation loss = 5.0185  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 3.3003  Validation loss = 5.0178  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 3.2999  Validation loss = 5.0169  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 3.2996  Validation loss = 5.0161  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 3.2991  Validation loss = 5.0150  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 3.2986  Validation loss = 5.0140  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 3.2982  Validation loss = 5.0133  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 3.2979  Validation loss = 5.0125  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 3.2974  Validation loss = 5.0116  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 3.2970  Validation loss = 5.0107  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 3.2966  Validation loss = 5.0098  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 3.2962  Validation loss = 5.0090  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 3.2958  Validation loss = 5.0080  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 3.2955  Validation loss = 5.0073  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 3.2951  Validation loss = 5.0064  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 3.2946  Validation loss = 5.0052  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 3.2943  Validation loss = 5.0044  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 3.2938  Validation loss = 5.0031  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 3.2932  Validation loss = 5.0021  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 3.2929  Validation loss = 5.0014  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 3.2924  Validation loss = 5.0004  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 3.2920  Validation loss = 4.9995  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 3.2916  Validation loss = 4.9986  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 3.2912  Validation loss = 4.9976  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 3.2909  Validation loss = 4.9970  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 3.2906  Validation loss = 4.9962  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 3.2902  Validation loss = 4.9952  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 3.2896  Validation loss = 4.9941  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 3.2893  Validation loss = 4.9935  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 3.2888  Validation loss = 4.9922  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 3.2886  Validation loss = 4.9916  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 3.2880  Validation loss = 4.9902  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 3.2875  Validation loss = 4.9889  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 3.2871  Validation loss = 4.9881  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 3.2867  Validation loss = 4.9871  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 3.2863  Validation loss = 4.9863  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 3.2858  Validation loss = 4.9851  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 3.2855  Validation loss = 4.9844  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 3.2851  Validation loss = 4.9833  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 3.2845  Validation loss = 4.9822  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 3.2841  Validation loss = 4.9812  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 3.2835  Validation loss = 4.9797  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 3.2831  Validation loss = 4.9787  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 3.2826  Validation loss = 4.9777  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 3.2820  Validation loss = 4.9762  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 3.2816  Validation loss = 4.9754  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 3.2810  Validation loss = 4.9742  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 3.2805  Validation loss = 4.9728  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 3.2800  Validation loss = 4.9715  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 3.2795  Validation loss = 4.9704  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 3.2791  Validation loss = 4.9695  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 3.2789  Validation loss = 4.9689  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 3.2787  Validation loss = 4.9684  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 3.2784  Validation loss = 4.9676  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 3.2782  Validation loss = 4.9671  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 3.2777  Validation loss = 4.9661  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 3.2774  Validation loss = 4.9651  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 3.2770  Validation loss = 4.9644  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 3.2767  Validation loss = 4.9637  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 3.2764  Validation loss = 4.9629  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 3.2760  Validation loss = 4.9618  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 3.2755  Validation loss = 4.9608  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 3.2750  Validation loss = 4.9596  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 3.2746  Validation loss = 4.9588  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 3.2743  Validation loss = 4.9581  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 3.2740  Validation loss = 4.9575  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 3.2735  Validation loss = 4.9562  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 3.2731  Validation loss = 4.9554  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 3.2728  Validation loss = 4.9545  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 3.2723  Validation loss = 4.9535  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 3.2717  Validation loss = 4.9518  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 3.2714  Validation loss = 4.9511  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 3.2711  Validation loss = 4.9504  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 3.2707  Validation loss = 4.9493  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 3.2703  Validation loss = 4.9485  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 3.2700  Validation loss = 4.9476  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 3.2697  Validation loss = 4.9470  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 3.2695  Validation loss = 4.9464  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 3.2689  Validation loss = 4.9449  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 3.2686  Validation loss = 4.9442  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 3.2680  Validation loss = 4.9426  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 3.2677  Validation loss = 4.9419  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 3.2673  Validation loss = 4.9411  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 3.2670  Validation loss = 4.9402  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 3.2665  Validation loss = 4.9387  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 3.2661  Validation loss = 4.9375  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 3.2656  Validation loss = 4.9361  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 3.2652  Validation loss = 4.9349  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 3.2649  Validation loss = 4.9341  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 3.2647  Validation loss = 4.9333  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 3.2644  Validation loss = 4.9323  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 3.2639  Validation loss = 4.9309  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 3.2635  Validation loss = 4.9295  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 3.2630  Validation loss = 4.9279  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 3.2627  Validation loss = 4.9267  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 3.2623  Validation loss = 4.9256  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 3.2620  Validation loss = 4.9245  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 3.2617  Validation loss = 4.9232  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 3.2610  Validation loss = 4.9200  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 3.2607  Validation loss = 4.9191  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 3.2603  Validation loss = 4.9181  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 3.2596  Validation loss = 4.9145  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 3.2585  Validation loss = 4.9037  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 3.2580  Validation loss = 4.9000  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 3.2576  Validation loss = 4.8974  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 3.2565  Validation loss = 4.8787  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 3.2560  Validation loss = 4.8706  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 3.2554  Validation loss = 4.8640  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 3.2548  Validation loss = 4.8580  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 3.2544  Validation loss = 4.8566  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 3.2538  Validation loss = 4.8531  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 3.2521  Validation loss = 4.8442  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 3.2500  Validation loss = 4.8358  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 3.2492  Validation loss = 4.8324  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 3.2488  Validation loss = 4.8312  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 3.2486  Validation loss = 4.8300  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 3.2482  Validation loss = 4.8285  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 3.2479  Validation loss = 4.8268  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 3.2475  Validation loss = 4.8251  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 3.2471  Validation loss = 4.8238  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 3.2468  Validation loss = 4.8223  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 3.2465  Validation loss = 4.8212  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 3.2461  Validation loss = 4.8193  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 3.2457  Validation loss = 4.8179  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 3.2453  Validation loss = 4.8157  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 3.2450  Validation loss = 4.8145  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 3.2447  Validation loss = 4.8132  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 3.2442  Validation loss = 4.8112  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 3.2438  Validation loss = 4.8091  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 3.2436  Validation loss = 4.8084  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 3.2434  Validation loss = 4.8075  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 3.2430  Validation loss = 4.8062  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 3.2427  Validation loss = 4.8049  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 3.2423  Validation loss = 4.8033  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 3.2418  Validation loss = 4.8011  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 3.2415  Validation loss = 4.7997  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 3.2410  Validation loss = 4.7981  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 3.2407  Validation loss = 4.7966  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 3.2401  Validation loss = 4.7942  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 3.2398  Validation loss = 4.7927  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 3.2394  Validation loss = 4.7913  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 3.2390  Validation loss = 4.7894  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 3.2386  Validation loss = 4.7881  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 3.2383  Validation loss = 4.7863  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 3.2379  Validation loss = 4.7850  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 3.2374  Validation loss = 4.7833  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 3.2371  Validation loss = 4.7824  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 3.2367  Validation loss = 4.7807  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 3.2364  Validation loss = 4.7796  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 3.2359  Validation loss = 4.7780  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 3.2356  Validation loss = 4.7771  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 3.2352  Validation loss = 4.7757  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 3.2348  Validation loss = 4.7729  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 3.2343  Validation loss = 4.7707  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 3.2339  Validation loss = 4.7693  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 3.2336  Validation loss = 4.7682  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 3.2333  Validation loss = 4.7675  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 3.2329  Validation loss = 4.7657  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 3.2327  Validation loss = 4.7647  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 3.2324  Validation loss = 4.7636  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 3.2321  Validation loss = 4.7626  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 3.2316  Validation loss = 4.7611  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 3.2312  Validation loss = 4.7595  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 3.2308  Validation loss = 4.7580  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 3.2305  Validation loss = 4.7568  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 3.2301  Validation loss = 4.7552  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 3.2298  Validation loss = 4.7539  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 3.2295  Validation loss = 4.7529  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 3.2292  Validation loss = 4.7518  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 3.2289  Validation loss = 4.7504  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 3.2285  Validation loss = 4.7491  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 3.2280  Validation loss = 4.7471  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 3.2276  Validation loss = 4.7454  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 3.2274  Validation loss = 4.7449  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 3.2270  Validation loss = 4.7434  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 3.2265  Validation loss = 4.7416  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 3.2262  Validation loss = 4.7403  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 3.2258  Validation loss = 4.7392  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 3.2255  Validation loss = 4.7380  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 3.2252  Validation loss = 4.7371  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 3.2248  Validation loss = 4.7356  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 3.2245  Validation loss = 4.7346  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 3.2242  Validation loss = 4.7336  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 3.2239  Validation loss = 4.7324  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 3.2235  Validation loss = 4.7308  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 3.2231  Validation loss = 4.7295  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 3.2228  Validation loss = 4.7286  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 3.2222  Validation loss = 4.7263  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 3.2218  Validation loss = 4.7250  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 3.2215  Validation loss = 4.7236  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 3.2211  Validation loss = 4.7225  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 3.2208  Validation loss = 4.7216  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 3.2205  Validation loss = 4.7204  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 3.2201  Validation loss = 4.7189  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 3.2198  Validation loss = 4.7179  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 3.2194  Validation loss = 4.7167  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 3.2191  Validation loss = 4.7160  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 3.2189  Validation loss = 4.7149  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 3.2184  Validation loss = 4.7132  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 3.2178  Validation loss = 4.7116  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 3.2176  Validation loss = 4.7111  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 3.2173  Validation loss = 4.7100  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 3.2170  Validation loss = 4.7090  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 3.2167  Validation loss = 4.7080  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 3.2163  Validation loss = 4.7068  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 3.2158  Validation loss = 4.7053  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 3.2156  Validation loss = 4.7046  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 3.2153  Validation loss = 4.7038  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 3.2151  Validation loss = 4.7030  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 3.2148  Validation loss = 4.7018  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 3.2144  Validation loss = 4.7008  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 3.2141  Validation loss = 4.6996  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 3.2138  Validation loss = 4.6990  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 3.2135  Validation loss = 4.6980  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 3.2131  Validation loss = 4.6967  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 3.2127  Validation loss = 4.6956  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 3.2125  Validation loss = 4.6945  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 3.2120  Validation loss = 4.6930  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 3.2117  Validation loss = 4.6920  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 3.2112  Validation loss = 4.6904  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 3.2108  Validation loss = 4.6891  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 3.2106  Validation loss = 4.6884  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 3.2101  Validation loss = 4.6867  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 3.2099  Validation loss = 4.6861  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 3.2096  Validation loss = 4.6851  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 3.2092  Validation loss = 4.6838  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 3.2087  Validation loss = 4.6820  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 3.2084  Validation loss = 4.6806  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 3.2081  Validation loss = 4.6797  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 3.2077  Validation loss = 4.6784  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 3.2073  Validation loss = 4.6771  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 3.2069  Validation loss = 4.6762  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 3.2067  Validation loss = 4.6756  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 3.2064  Validation loss = 4.6747  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 3.2061  Validation loss = 4.6737  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 3.2056  Validation loss = 4.6721  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 3.2051  Validation loss = 4.6706  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 3.2047  Validation loss = 4.6694  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 3.2044  Validation loss = 4.6684  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 3.2040  Validation loss = 4.6674  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 3.2038  Validation loss = 4.6669  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 3.2034  Validation loss = 4.6654  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 3.2028  Validation loss = 4.6634  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 3.2025  Validation loss = 4.6621  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 3.2021  Validation loss = 4.6612  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 3.2017  Validation loss = 4.6595  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 3.3829  Validation loss = 2.4641  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 3.3808  Validation loss = 2.4634  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 3.3798  Validation loss = 2.4625  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 3.3789  Validation loss = 2.4616  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 3.3785  Validation loss = 2.4609  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 3.3778  Validation loss = 2.4598  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 3.3769  Validation loss = 2.4586  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 3.3763  Validation loss = 2.4576  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 3.3756  Validation loss = 2.4566  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 3.3751  Validation loss = 2.4557  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 3.3747  Validation loss = 2.4551  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 3.3741  Validation loss = 2.4542  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 3.3734  Validation loss = 2.4533  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 3.3726  Validation loss = 2.4521  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 3.3719  Validation loss = 2.4511  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 3.3709  Validation loss = 2.4501  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 3.3702  Validation loss = 2.4492  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 3.3696  Validation loss = 2.4484  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 3.3690  Validation loss = 2.4474  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 3.3681  Validation loss = 2.4461  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 3.3675  Validation loss = 2.4451  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 3.3668  Validation loss = 2.4441  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 3.3662  Validation loss = 2.4430  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 3.3656  Validation loss = 2.4421  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 3.3651  Validation loss = 2.4412  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 3.3645  Validation loss = 2.4403  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 3.3638  Validation loss = 2.4394  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 3.3635  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 3.3630  Validation loss = 2.4379  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 3.3625  Validation loss = 2.4372  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 3.3620  Validation loss = 2.4363  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 3.3616  Validation loss = 2.4356  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 3.3611  Validation loss = 2.4347  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 3.3606  Validation loss = 2.4339  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 3.3599  Validation loss = 2.4329  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 3.3594  Validation loss = 2.4321  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 3.3589  Validation loss = 2.4311  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 3.3584  Validation loss = 2.4303  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 3.3580  Validation loss = 2.4297  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 3.3576  Validation loss = 2.4291  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 3.3571  Validation loss = 2.4282  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 3.3564  Validation loss = 2.4272  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 3.3557  Validation loss = 2.4262  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 3.3550  Validation loss = 2.4251  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 3.3544  Validation loss = 2.4244  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 3.3540  Validation loss = 2.4237  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 3.3534  Validation loss = 2.4227  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 3.3529  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 3.3523  Validation loss = 2.4208  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 3.3517  Validation loss = 2.4199  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 3.3513  Validation loss = 2.4191  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 3.3510  Validation loss = 2.4186  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 3.3503  Validation loss = 2.4175  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 3.3498  Validation loss = 2.4166  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 3.3490  Validation loss = 2.4155  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 3.3486  Validation loss = 2.4147  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 3.3481  Validation loss = 2.4138  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 3.3475  Validation loss = 2.4129  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 3.3469  Validation loss = 2.4118  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 3.3462  Validation loss = 2.4108  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 3.3457  Validation loss = 2.4100  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 3.3453  Validation loss = 2.4093  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 3.3449  Validation loss = 2.4086  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 3.3443  Validation loss = 2.4077  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 3.3437  Validation loss = 2.4065  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 3.3432  Validation loss = 2.4057  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 3.3428  Validation loss = 2.4050  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 3.3423  Validation loss = 2.4042  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 3.3416  Validation loss = 2.4031  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 3.3412  Validation loss = 2.4025  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 3.3406  Validation loss = 2.4015  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 3.3399  Validation loss = 2.4005  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 3.3394  Validation loss = 2.3997  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 3.3387  Validation loss = 2.3986  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 3.3384  Validation loss = 2.3981  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 3.3380  Validation loss = 2.3974  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 3.3374  Validation loss = 2.3964  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 3.3370  Validation loss = 2.3956  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 3.3363  Validation loss = 2.3947  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 3.3358  Validation loss = 2.3937  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 3.3352  Validation loss = 2.3927  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 3.3346  Validation loss = 2.3917  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 3.3342  Validation loss = 2.3910  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 3.3337  Validation loss = 2.3901  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 3.3330  Validation loss = 2.3891  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 3.3324  Validation loss = 2.3881  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 3.3319  Validation loss = 2.3873  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 3.3313  Validation loss = 2.3864  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 3.3308  Validation loss = 2.3856  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 3.3303  Validation loss = 2.3849  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 3.3298  Validation loss = 2.3840  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 3.3293  Validation loss = 2.3833  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 3.3288  Validation loss = 2.3823  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 3.3284  Validation loss = 2.3817  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 3.3278  Validation loss = 2.3807  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 3.3273  Validation loss = 2.3798  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 3.3269  Validation loss = 2.3791  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 3.3265  Validation loss = 2.3784  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 3.3258  Validation loss = 2.3774  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 3.3253  Validation loss = 2.3766  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 3.3247  Validation loss = 2.3758  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 3.3242  Validation loss = 2.3750  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 3.3235  Validation loss = 2.3739  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 3.3228  Validation loss = 2.3730  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 3.3224  Validation loss = 2.3723  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 3.3215  Validation loss = 2.3713  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 3.3210  Validation loss = 2.3705  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 3.3202  Validation loss = 2.3696  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 3.3193  Validation loss = 2.3685  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 3.3184  Validation loss = 2.3679  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 3.3166  Validation loss = 2.3669  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 3.3160  Validation loss = 2.3660  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 3.3126  Validation loss = 2.3649  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 3.3120  Validation loss = 2.3641  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 3.3113  Validation loss = 2.3634  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 3.3106  Validation loss = 2.3624  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 3.3099  Validation loss = 2.3617  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 3.3092  Validation loss = 2.3607  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 3.3083  Validation loss = 2.3596  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 3.3078  Validation loss = 2.3587  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 3.3074  Validation loss = 2.3582  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 3.3067  Validation loss = 2.3571  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 3.3063  Validation loss = 2.3565  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 3.3055  Validation loss = 2.3553  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 3.3049  Validation loss = 2.3544  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 3.3044  Validation loss = 2.3535  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 3.3039  Validation loss = 2.3527  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 3.3033  Validation loss = 2.3518  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 3.3028  Validation loss = 2.3510  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 3.3022  Validation loss = 2.3501  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 3.3015  Validation loss = 2.3489  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 3.3011  Validation loss = 2.3483  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 3.3005  Validation loss = 2.3474  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 3.3001  Validation loss = 2.3467  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 3.2995  Validation loss = 2.3458  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 3.2990  Validation loss = 2.3449  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 3.2984  Validation loss = 2.3439  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 3.2978  Validation loss = 2.3429  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 3.2973  Validation loss = 2.3419  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 3.2966  Validation loss = 2.3409  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 3.2961  Validation loss = 2.3400  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 3.2958  Validation loss = 2.3394  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 3.2953  Validation loss = 2.3386  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 3.2948  Validation loss = 2.3378  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 3.2944  Validation loss = 2.3371  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 3.2937  Validation loss = 2.3361  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 3.2933  Validation loss = 2.3354  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 3.2928  Validation loss = 2.3344  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 3.2922  Validation loss = 2.3335  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 3.2918  Validation loss = 2.3328  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 3.2914  Validation loss = 2.3321  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 3.2911  Validation loss = 2.3315  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 3.2906  Validation loss = 2.3308  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 3.2901  Validation loss = 2.3300  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 3.2896  Validation loss = 2.3292  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 3.2890  Validation loss = 2.3282  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 3.2887  Validation loss = 2.3276  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 3.2881  Validation loss = 2.3267  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 3.2875  Validation loss = 2.3258  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 3.2871  Validation loss = 2.3252  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 3.2868  Validation loss = 2.3246  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 3.2863  Validation loss = 2.3237  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 3.2856  Validation loss = 2.3228  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 3.2853  Validation loss = 2.3222  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 3.2849  Validation loss = 2.3214  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 3.2844  Validation loss = 2.3207  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 3.2840  Validation loss = 2.3199  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 3.2836  Validation loss = 2.3192  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 3.2830  Validation loss = 2.3182  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 3.2826  Validation loss = 2.3175  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 3.2820  Validation loss = 2.3167  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 3.2815  Validation loss = 2.3157  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 3.2808  Validation loss = 2.3147  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 3.2804  Validation loss = 2.3139  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 3.2798  Validation loss = 2.3129  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 3.2792  Validation loss = 2.3119  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 3.2787  Validation loss = 2.3109  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 3.2781  Validation loss = 2.3100  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 3.2776  Validation loss = 2.3092  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 3.2773  Validation loss = 2.3086  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 3.2768  Validation loss = 2.3078  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 3.2763  Validation loss = 2.3070  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 3.2758  Validation loss = 2.3062  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 3.2752  Validation loss = 2.3052  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 3.2746  Validation loss = 2.3044  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 3.2742  Validation loss = 2.3036  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 3.2737  Validation loss = 2.3028  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 3.2730  Validation loss = 2.3017  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 3.2724  Validation loss = 2.3005  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 3.2719  Validation loss = 2.2998  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 3.2712  Validation loss = 2.2988  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 3.2709  Validation loss = 2.2983  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 3.2703  Validation loss = 2.2972  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 3.2697  Validation loss = 2.2964  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 3.2692  Validation loss = 2.2956  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 3.2688  Validation loss = 2.2949  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 3.2682  Validation loss = 2.2941  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 3.2677  Validation loss = 2.2933  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 3.2671  Validation loss = 2.2922  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 3.2665  Validation loss = 2.2913  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 3.2660  Validation loss = 2.2906  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 3.2657  Validation loss = 2.2901  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 3.2653  Validation loss = 2.2895  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 3.2648  Validation loss = 2.2887  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 3.2644  Validation loss = 2.2880  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 3.2639  Validation loss = 2.2871  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 3.2633  Validation loss = 2.2861  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 3.2628  Validation loss = 2.2853  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 3.2625  Validation loss = 2.2849  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 3.2619  Validation loss = 2.2839  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 3.2614  Validation loss = 2.2831  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 3.2610  Validation loss = 2.2823  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 3.2605  Validation loss = 2.2816  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 3.2600  Validation loss = 2.2807  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 3.2595  Validation loss = 2.2798  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 3.2589  Validation loss = 2.2789  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 3.2584  Validation loss = 2.2781  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 3.2578  Validation loss = 2.2772  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 3.2576  Validation loss = 2.2767  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 3.2571  Validation loss = 2.2760  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 3.2566  Validation loss = 2.2752  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 3.2561  Validation loss = 2.2744  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 3.2555  Validation loss = 2.2733  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 3.2550  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 3.2542  Validation loss = 2.2712  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 3.2536  Validation loss = 2.2704  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 3.2528  Validation loss = 2.2692  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 3.2523  Validation loss = 2.2683  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 3.2519  Validation loss = 2.2676  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 3.2512  Validation loss = 2.2667  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 3.2508  Validation loss = 2.2660  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 3.2503  Validation loss = 2.2653  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 3.2500  Validation loss = 2.2647  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 3.2495  Validation loss = 2.2639  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 3.2491  Validation loss = 2.2632  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 3.2485  Validation loss = 2.2623  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 3.2479  Validation loss = 2.2612  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 3.2473  Validation loss = 2.2603  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 3.2466  Validation loss = 2.2592  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 3.2461  Validation loss = 2.2584  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 3.2455  Validation loss = 2.2575  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 3.2449  Validation loss = 2.2566  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 3.2445  Validation loss = 2.2560  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 3.2442  Validation loss = 2.2555  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 3.2437  Validation loss = 2.2548  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 3.2431  Validation loss = 2.2537  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 3.2426  Validation loss = 2.2528  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 3.2422  Validation loss = 2.2523  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 3.2417  Validation loss = 2.2515  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 3.2413  Validation loss = 2.2509  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 3.2409  Validation loss = 2.2501  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 3.2404  Validation loss = 2.2492  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 3.2399  Validation loss = 2.2483  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 3.2393  Validation loss = 2.2475  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 3.2388  Validation loss = 2.2466  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 3.2381  Validation loss = 2.2454  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 3.2377  Validation loss = 2.2448  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 3.2371  Validation loss = 2.2439  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 3.2365  Validation loss = 2.2431  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 3.2361  Validation loss = 2.2424  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 3.2355  Validation loss = 2.2415  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 3.2350  Validation loss = 2.2407  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 3.2344  Validation loss = 2.2398  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 3.2340  Validation loss = 2.2391  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 3.2335  Validation loss = 2.2383  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 3.2329  Validation loss = 2.2374  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 3.2326  Validation loss = 2.2369  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 3.2322  Validation loss = 2.2361  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 3.2315  Validation loss = 2.2349  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 3.2309  Validation loss = 2.2340  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 3.2303  Validation loss = 2.2330  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 3.2299  Validation loss = 2.2324  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 3.2294  Validation loss = 2.2316  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 3.2289  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 3.2285  Validation loss = 2.2301  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 3.2281  Validation loss = 2.2294  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 3.2275  Validation loss = 2.2286  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 3.2270  Validation loss = 2.2278  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 3.2266  Validation loss = 2.2271  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 3.2263  Validation loss = 2.2265  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 3.2259  Validation loss = 2.2260  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 3.2253  Validation loss = 2.2250  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 3.2246  Validation loss = 2.2240  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 3.2241  Validation loss = 2.2232  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 3.2236  Validation loss = 2.2225  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 3.2231  Validation loss = 2.2217  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 3.2227  Validation loss = 2.2210  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 3.2223  Validation loss = 2.2204  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 3.2218  Validation loss = 2.2196  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 3.2214  Validation loss = 2.2189  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 3.2210  Validation loss = 2.2183  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 3.2206  Validation loss = 2.2176  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 3.2202  Validation loss = 2.2169  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 3.2197  Validation loss = 2.2162  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 3.2188  Validation loss = 2.2150  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 3.2180  Validation loss = 2.2141  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 3.2176  Validation loss = 2.2136  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 3.2171  Validation loss = 2.2129  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 3.2166  Validation loss = 2.2123  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 3.2158  Validation loss = 2.2112  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 3.2153  Validation loss = 2.2102  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 3.2147  Validation loss = 2.2095  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 3.2138  Validation loss = 2.2083  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 3.2133  Validation loss = 2.2077  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 3.2129  Validation loss = 2.2070  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 3.2125  Validation loss = 2.2063  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 3.2121  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 3.2117  Validation loss = 2.2051  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 3.2111  Validation loss = 2.2042  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 3.2104  Validation loss = 2.2033  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 3.2099  Validation loss = 2.2024  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 3.2096  Validation loss = 2.2018  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 3.2090  Validation loss = 2.2009  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 3.2087  Validation loss = 2.2003  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 3.2080  Validation loss = 2.1993  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 3.2074  Validation loss = 2.1983  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 3.2070  Validation loss = 2.1977  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 3.2064  Validation loss = 2.1968  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 3.2057  Validation loss = 2.1959  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 3.2053  Validation loss = 2.1953  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 3.2050  Validation loss = 2.1947  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 3.2046  Validation loss = 2.1941  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 3.2040  Validation loss = 2.1933  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 3.2036  Validation loss = 2.1925  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 3.2031  Validation loss = 2.1916  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 3.2027  Validation loss = 2.1909  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 3.2020  Validation loss = 2.1902  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 3.2015  Validation loss = 2.1894  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 3.2010  Validation loss = 2.1888  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 3.2007  Validation loss = 2.1884  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 3.2003  Validation loss = 2.1876  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 3.1998  Validation loss = 2.1869  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 3.1993  Validation loss = 2.1864  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 3.1988  Validation loss = 2.1858  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 3.1984  Validation loss = 2.1852  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 3.1981  Validation loss = 2.1847  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 3.1976  Validation loss = 2.1840  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 3.1971  Validation loss = 2.1832  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 3.1966  Validation loss = 2.1824  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 3.1961  Validation loss = 2.1817  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 3.1955  Validation loss = 2.1808  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 3.1950  Validation loss = 2.1801  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 3.1945  Validation loss = 2.1794  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 3.1938  Validation loss = 2.1783  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 3.1934  Validation loss = 2.1775  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 3.1928  Validation loss = 2.1767  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 3.1921  Validation loss = 2.1759  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 3.1915  Validation loss = 2.1751  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 3.1908  Validation loss = 2.1742  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 3.1902  Validation loss = 2.1734  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 3.1897  Validation loss = 2.1726  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 3.1892  Validation loss = 2.1717  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 3.1888  Validation loss = 2.1712  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 3.1883  Validation loss = 2.1703  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 3.1877  Validation loss = 2.1693  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 3.1871  Validation loss = 2.1686  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 3.1864  Validation loss = 2.1676  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 3.1858  Validation loss = 2.1667  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 3.1854  Validation loss = 2.1660  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 3.1848  Validation loss = 2.1652  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 3.1843  Validation loss = 2.1643  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 3.1840  Validation loss = 2.1638  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 3.1835  Validation loss = 2.1631  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 3.1830  Validation loss = 2.1624  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 3.1824  Validation loss = 2.1615  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 3.1817  Validation loss = 2.1605  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 3.1811  Validation loss = 2.1595  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 3.1804  Validation loss = 2.1584  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 3.1800  Validation loss = 2.1578  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 3.1795  Validation loss = 2.1571  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 3.1790  Validation loss = 2.1564  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 3.1783  Validation loss = 2.1554  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 3.1777  Validation loss = 2.1545  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 3.1771  Validation loss = 2.1538  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 3.1766  Validation loss = 2.1531  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 3.1742  Validation loss = 2.1520  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 3.1734  Validation loss = 2.1514  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 3.1722  Validation loss = 2.1505  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 3.1717  Validation loss = 2.1498  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 3.1714  Validation loss = 2.1493  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 3.1707  Validation loss = 2.1483  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 3.1701  Validation loss = 2.1475  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 3.1697  Validation loss = 2.1468  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 3.1691  Validation loss = 2.1459  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 3.1686  Validation loss = 2.1451  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 3.1680  Validation loss = 2.1442  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 3.1676  Validation loss = 2.1435  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 3.1672  Validation loss = 2.1427  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 3.1665  Validation loss = 2.1417  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 3.1659  Validation loss = 2.1407  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 3.1655  Validation loss = 2.1401  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 3.1651  Validation loss = 2.1395  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 3.1646  Validation loss = 2.1387  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 3.1642  Validation loss = 2.1381  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 3.1635  Validation loss = 2.1371  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 3.1633  Validation loss = 2.1367  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 3.1629  Validation loss = 2.1360  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 3.1624  Validation loss = 2.1353  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 3.1620  Validation loss = 2.1345  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 3.1614  Validation loss = 2.1338  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 3.1610  Validation loss = 2.1332  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 3.1603  Validation loss = 2.1322  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 3.1597  Validation loss = 2.1313  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 3.1592  Validation loss = 2.1306  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 3.1588  Validation loss = 2.1299  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 3.1584  Validation loss = 2.1294  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 3.1580  Validation loss = 2.1287  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 3.1574  Validation loss = 2.1278  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 3.1569  Validation loss = 2.1271  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 3.1567  Validation loss = 2.1268  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 3.1564  Validation loss = 2.1263  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 3.1560  Validation loss = 2.1258  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 3.1555  Validation loss = 2.1250  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 3.1552  Validation loss = 2.1244  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 3.1550  Validation loss = 2.1240  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 3.1546  Validation loss = 2.1234  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 3.1542  Validation loss = 2.1228  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 3.1539  Validation loss = 2.1222  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 3.1533  Validation loss = 2.1212  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 3.1528  Validation loss = 2.1205  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 3.1525  Validation loss = 2.1199  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 3.1521  Validation loss = 2.1193  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 3.1516  Validation loss = 2.1186  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 3.1513  Validation loss = 2.1181  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 3.1508  Validation loss = 2.1174  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 3.1502  Validation loss = 2.1164  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 3.1497  Validation loss = 2.1155  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 3.1492  Validation loss = 2.1149  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 3.1490  Validation loss = 2.1144  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 3.1486  Validation loss = 2.1139  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 3.1481  Validation loss = 2.1131  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 3.1476  Validation loss = 2.1123  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 3.1474  Validation loss = 2.1119  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 3.1470  Validation loss = 2.1113  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 3.1467  Validation loss = 2.1108  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 3.1461  Validation loss = 2.1101  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 3.1457  Validation loss = 2.1094  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 3.1451  Validation loss = 2.1084  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 3.1448  Validation loss = 2.1079  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 3.1445  Validation loss = 2.1076  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 3.1441  Validation loss = 2.1069  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 3.1439  Validation loss = 2.1064  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 3.1434  Validation loss = 2.1059  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 3.1429  Validation loss = 2.1050  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 3.1423  Validation loss = 2.1040  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 3.1418  Validation loss = 2.1033  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 3.1413  Validation loss = 2.1024  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 3.1408  Validation loss = 2.1016  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 3.1404  Validation loss = 2.1010  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 3.1400  Validation loss = 2.1003  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 3.1395  Validation loss = 2.0995  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 3.1390  Validation loss = 2.0986  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 3.1387  Validation loss = 2.0980  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 3.1380  Validation loss = 2.0970  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 3.1376  Validation loss = 2.0964  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 3.1371  Validation loss = 2.0956  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 3.1367  Validation loss = 2.0950  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 3.1361  Validation loss = 2.0942  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 3.1357  Validation loss = 2.0936  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 3.1353  Validation loss = 2.0929  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 3.1350  Validation loss = 2.0924  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 3.1347  Validation loss = 2.0920  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 3.1343  Validation loss = 2.0913  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 3.1338  Validation loss = 2.0907  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 3.1333  Validation loss = 2.0899  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 3.1330  Validation loss = 2.0893  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 3.1326  Validation loss = 2.0887  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 3.1321  Validation loss = 2.0880  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 3.1316  Validation loss = 2.0872  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 3.1312  Validation loss = 2.0866  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 3.1306  Validation loss = 2.0856  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 3.1303  Validation loss = 2.0850  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 3.1299  Validation loss = 2.0843  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 3.1293  Validation loss = 2.0835  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 3.1289  Validation loss = 2.0828  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 3.1284  Validation loss = 2.0820  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 3.1280  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 3.1275  Validation loss = 2.0807  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 3.1272  Validation loss = 2.0801  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 3.1267  Validation loss = 2.0793  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 3.1263  Validation loss = 2.0787  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 3.1258  Validation loss = 2.0778  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 3.1254  Validation loss = 2.0771  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 3.1250  Validation loss = 2.0764  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 3.1245  Validation loss = 2.0757  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 3.1242  Validation loss = 2.0751  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 3.1239  Validation loss = 2.0746  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 3.1234  Validation loss = 2.0737  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 3.1229  Validation loss = 2.0729  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 3.1226  Validation loss = 2.0724  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 3.1222  Validation loss = 2.0717  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 3.1218  Validation loss = 2.0710  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 3.1215  Validation loss = 2.0704  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 3.1208  Validation loss = 2.0693  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 3.1204  Validation loss = 2.0687  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 3.1200  Validation loss = 2.0679  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 3.1195  Validation loss = 2.0671  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 3.1191  Validation loss = 2.0665  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 3.1186  Validation loss = 2.0656  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 3.1181  Validation loss = 2.0649  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 500  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 3.1404  Validation loss = 3.0612  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 3.1399  Validation loss = 3.0601  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 3.1394  Validation loss = 3.0588  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 3.1388  Validation loss = 3.0574  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 3.1384  Validation loss = 3.0565  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 3.1377  Validation loss = 3.0548  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 3.1374  Validation loss = 3.0541  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 3.1370  Validation loss = 3.0532  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 3.1366  Validation loss = 3.0522  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 3.1361  Validation loss = 3.0510  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 3.1356  Validation loss = 3.0497  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 3.1352  Validation loss = 3.0489  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 3.1348  Validation loss = 3.0478  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 3.1342  Validation loss = 3.0463  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 3.1337  Validation loss = 3.0452  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 3.1332  Validation loss = 3.0439  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 3.1328  Validation loss = 3.0431  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 3.1320  Validation loss = 3.0412  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 3.1316  Validation loss = 3.0400  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 3.1310  Validation loss = 3.0386  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 3.1303  Validation loss = 3.0370  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 3.1298  Validation loss = 3.0358  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 3.1292  Validation loss = 3.0344  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 3.1286  Validation loss = 3.0328  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 3.1280  Validation loss = 3.0314  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 3.1273  Validation loss = 3.0298  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 3.1267  Validation loss = 3.0283  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 3.1261  Validation loss = 3.0270  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 3.1256  Validation loss = 3.0257  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 3.1252  Validation loss = 3.0248  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 3.1245  Validation loss = 3.0232  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 3.1241  Validation loss = 3.0223  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 3.1237  Validation loss = 3.0211  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 3.1232  Validation loss = 3.0200  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 3.1228  Validation loss = 3.0192  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 3.1222  Validation loss = 3.0179  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 3.1217  Validation loss = 3.0168  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 3.1213  Validation loss = 3.0158  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 3.1210  Validation loss = 3.0152  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 3.1205  Validation loss = 3.0138  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 3.1201  Validation loss = 3.0130  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 3.1196  Validation loss = 3.0117  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 3.1190  Validation loss = 3.0103  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 3.1185  Validation loss = 3.0091  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 3.1181  Validation loss = 3.0079  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 3.1176  Validation loss = 3.0069  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 3.1173  Validation loss = 3.0062  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 3.1167  Validation loss = 3.0049  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 3.1162  Validation loss = 3.0037  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 3.1158  Validation loss = 3.0028  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 3.1155  Validation loss = 3.0020  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 3.1151  Validation loss = 3.0010  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 3.1146  Validation loss = 2.9998  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 3.1138  Validation loss = 2.9980  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 3.1134  Validation loss = 2.9969  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 3.1129  Validation loss = 2.9956  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 3.1124  Validation loss = 2.9947  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 3.1119  Validation loss = 2.9933  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 3.1113  Validation loss = 2.9919  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 3.1106  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 3.1100  Validation loss = 2.9885  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 3.1095  Validation loss = 2.9874  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 3.1090  Validation loss = 2.9863  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 3.1085  Validation loss = 2.9849  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 3.1080  Validation loss = 2.9839  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 3.1077  Validation loss = 2.9830  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 3.1073  Validation loss = 2.9821  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 3.1069  Validation loss = 2.9812  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 3.1065  Validation loss = 2.9803  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 3.1062  Validation loss = 2.9796  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 3.1056  Validation loss = 2.9781  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 3.1051  Validation loss = 2.9770  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 3.1047  Validation loss = 2.9761  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 3.1044  Validation loss = 2.9753  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 3.1040  Validation loss = 2.9744  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 3.1037  Validation loss = 2.9738  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 3.1033  Validation loss = 2.9729  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 3.1030  Validation loss = 2.9722  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 3.1026  Validation loss = 2.9713  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 3.1022  Validation loss = 2.9701  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 3.1017  Validation loss = 2.9692  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 3.1014  Validation loss = 2.9683  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 3.1011  Validation loss = 2.9676  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 3.1006  Validation loss = 2.9665  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 3.1001  Validation loss = 2.9655  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 3.0996  Validation loss = 2.9642  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 3.0993  Validation loss = 2.9634  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 3.0989  Validation loss = 2.9626  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 3.0983  Validation loss = 2.9611  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 3.0979  Validation loss = 2.9600  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 3.0976  Validation loss = 2.9592  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 3.0970  Validation loss = 2.9578  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 3.0966  Validation loss = 2.9568  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 3.0961  Validation loss = 2.9557  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 3.0956  Validation loss = 2.9543  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 3.0950  Validation loss = 2.9530  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 3.0947  Validation loss = 2.9522  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 3.0940  Validation loss = 2.9507  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 3.0936  Validation loss = 2.9499  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 3.0932  Validation loss = 2.9489  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 3.0928  Validation loss = 2.9481  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 3.0923  Validation loss = 2.9468  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 3.0919  Validation loss = 2.9458  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 3.0916  Validation loss = 2.9450  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 3.0911  Validation loss = 2.9441  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 3.0908  Validation loss = 2.9432  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 3.0904  Validation loss = 2.9423  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 3.0900  Validation loss = 2.9414  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 3.0896  Validation loss = 2.9404  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 3.0895  Validation loss = 2.9400  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 3.0891  Validation loss = 2.9393  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 3.0887  Validation loss = 2.9382  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 3.0883  Validation loss = 2.9372  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 3.0876  Validation loss = 2.9357  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 3.0873  Validation loss = 2.9349  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 3.0870  Validation loss = 2.9343  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 3.0864  Validation loss = 2.9327  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 3.0859  Validation loss = 2.9316  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 3.0852  Validation loss = 2.9300  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 3.0847  Validation loss = 2.9288  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 3.0844  Validation loss = 2.9279  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 3.0840  Validation loss = 2.9270  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 3.0835  Validation loss = 2.9259  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 3.0829  Validation loss = 2.9243  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 3.0825  Validation loss = 2.9233  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 3.0820  Validation loss = 2.9223  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 3.0815  Validation loss = 2.9210  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 3.0810  Validation loss = 2.9199  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 3.0804  Validation loss = 2.9187  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 3.0799  Validation loss = 2.9175  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 3.0796  Validation loss = 2.9167  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 3.0791  Validation loss = 2.9155  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 3.0786  Validation loss = 2.9144  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 3.0782  Validation loss = 2.9135  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 3.0779  Validation loss = 2.9129  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 3.0775  Validation loss = 2.9119  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 3.0769  Validation loss = 2.9107  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 3.0767  Validation loss = 2.9101  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 3.0762  Validation loss = 2.9092  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 3.0758  Validation loss = 2.9082  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 3.0752  Validation loss = 2.9069  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 3.0747  Validation loss = 2.9061  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 3.0740  Validation loss = 2.9050  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 3.0734  Validation loss = 2.9040  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 3.0730  Validation loss = 2.9033  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 3.0717  Validation loss = 2.9017  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 3.0709  Validation loss = 2.9007  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 3.0700  Validation loss = 2.8995  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 3.0694  Validation loss = 2.8986  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 3.0690  Validation loss = 2.8979  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 3.0683  Validation loss = 2.8964  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 3.0679  Validation loss = 2.8953  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 3.0673  Validation loss = 2.8941  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 3.0669  Validation loss = 2.8931  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 3.0664  Validation loss = 2.8919  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 3.0658  Validation loss = 2.8906  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 3.0654  Validation loss = 2.8896  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 3.0649  Validation loss = 2.8885  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 3.0644  Validation loss = 2.8873  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 3.0641  Validation loss = 2.8866  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 3.0637  Validation loss = 2.8858  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 3.0634  Validation loss = 2.8850  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 3.0629  Validation loss = 2.8838  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 3.0622  Validation loss = 2.8821  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 3.0616  Validation loss = 2.8806  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 3.0613  Validation loss = 2.8800  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 3.0608  Validation loss = 2.8789  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 3.0605  Validation loss = 2.8781  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 3.0600  Validation loss = 2.8769  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 3.0594  Validation loss = 2.8756  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 3.0589  Validation loss = 2.8744  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 3.0582  Validation loss = 2.8727  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 3.0577  Validation loss = 2.8718  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 3.0571  Validation loss = 2.8708  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 3.0565  Validation loss = 2.8694  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 3.0560  Validation loss = 2.8686  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 3.0557  Validation loss = 2.8679  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 3.0553  Validation loss = 2.8672  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 3.0541  Validation loss = 2.8656  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 3.0534  Validation loss = 2.8646  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 3.0524  Validation loss = 2.8636  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 3.0520  Validation loss = 2.8627  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 3.0515  Validation loss = 2.8617  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 3.0507  Validation loss = 2.8603  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 3.0505  Validation loss = 2.8599  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 3.0499  Validation loss = 2.8587  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 3.0494  Validation loss = 2.8577  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 3.0490  Validation loss = 2.8569  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 3.0485  Validation loss = 2.8556  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 3.0482  Validation loss = 2.8551  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 3.0479  Validation loss = 2.8542  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 3.0474  Validation loss = 2.8531  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 3.0471  Validation loss = 2.8523  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 3.0465  Validation loss = 2.8508  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 3.0460  Validation loss = 2.8497  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 3.0456  Validation loss = 2.8488  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 3.0453  Validation loss = 2.8480  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 3.0450  Validation loss = 2.8472  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 3.0445  Validation loss = 2.8459  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 3.0439  Validation loss = 2.8443  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 3.0432  Validation loss = 2.8427  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 3.0428  Validation loss = 2.8416  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 3.0424  Validation loss = 2.8404  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 3.0419  Validation loss = 2.8394  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 3.0416  Validation loss = 2.8386  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 3.0411  Validation loss = 2.8373  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 3.0407  Validation loss = 2.8364  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 3.0404  Validation loss = 2.8356  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 3.0399  Validation loss = 2.8345  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 3.0395  Validation loss = 2.8334  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 3.0390  Validation loss = 2.8323  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 3.0387  Validation loss = 2.8315  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 3.0382  Validation loss = 2.8303  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 3.0377  Validation loss = 2.8290  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 3.0373  Validation loss = 2.8280  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 3.0368  Validation loss = 2.8270  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 3.0362  Validation loss = 2.8256  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 3.0357  Validation loss = 2.8244  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 3.0351  Validation loss = 2.8227  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 3.0346  Validation loss = 2.8214  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 3.0341  Validation loss = 2.8202  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 3.0337  Validation loss = 2.8192  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 3.0334  Validation loss = 2.8183  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 3.0329  Validation loss = 2.8170  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 3.0324  Validation loss = 2.8158  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 3.0321  Validation loss = 2.8151  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 3.0318  Validation loss = 2.8145  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 3.0314  Validation loss = 2.8135  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 3.0311  Validation loss = 2.8129  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 3.0310  Validation loss = 2.8126  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 3.0307  Validation loss = 2.8119  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 3.0302  Validation loss = 2.8108  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 3.0296  Validation loss = 2.8093  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 3.0293  Validation loss = 2.8085  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 3.0287  Validation loss = 2.8071  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 3.0284  Validation loss = 2.8063  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 3.0279  Validation loss = 2.8052  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 3.0274  Validation loss = 2.8040  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 3.0269  Validation loss = 2.8026  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 3.0264  Validation loss = 2.8013  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 3.0260  Validation loss = 2.8001  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 3.0257  Validation loss = 2.7995  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 3.0254  Validation loss = 2.7986  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 3.0250  Validation loss = 2.7977  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 3.0245  Validation loss = 2.7964  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 3.0239  Validation loss = 2.7950  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 3.0236  Validation loss = 2.7940  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 3.0231  Validation loss = 2.7929  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 3.0228  Validation loss = 2.7920  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 3.0222  Validation loss = 2.7906  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 3.0218  Validation loss = 2.7896  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 3.0213  Validation loss = 2.7885  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 3.0210  Validation loss = 2.7878  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 3.0205  Validation loss = 2.7866  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 3.0204  Validation loss = 2.7862  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 3.0199  Validation loss = 2.7850  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 3.0194  Validation loss = 2.7839  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 3.0190  Validation loss = 2.7828  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 3.0186  Validation loss = 2.7818  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 3.0182  Validation loss = 2.7809  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 3.0177  Validation loss = 2.7797  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 3.0174  Validation loss = 2.7788  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 3.0170  Validation loss = 2.7778  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 3.0166  Validation loss = 2.7768  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 3.0162  Validation loss = 2.7759  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 3.0158  Validation loss = 2.7746  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 3.0154  Validation loss = 2.7737  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 3.0151  Validation loss = 2.7730  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 3.0148  Validation loss = 2.7723  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 3.0144  Validation loss = 2.7714  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 3.0142  Validation loss = 2.7709  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 3.0137  Validation loss = 2.7698  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 3.0132  Validation loss = 2.7685  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 3.0128  Validation loss = 2.7676  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 3.0122  Validation loss = 2.7661  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 3.0118  Validation loss = 2.7651  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 3.0115  Validation loss = 2.7642  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 3.0111  Validation loss = 2.7633  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 3.0108  Validation loss = 2.7627  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 3.0102  Validation loss = 2.7613  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 3.0098  Validation loss = 2.7606  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 3.0093  Validation loss = 2.7595  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 3.0083  Validation loss = 2.7585  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 3.0051  Validation loss = 2.7575  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 3.0008  Validation loss = 2.7555  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 3.0005  Validation loss = 2.7548  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 3.0002  Validation loss = 2.7541  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 3.0000  Validation loss = 2.7537  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 2.9997  Validation loss = 2.7528  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 2.9992  Validation loss = 2.7516  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 2.9989  Validation loss = 2.7506  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 2.9984  Validation loss = 2.7493  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 2.9978  Validation loss = 2.7478  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 2.9974  Validation loss = 2.7468  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 2.9971  Validation loss = 2.7462  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 2.9967  Validation loss = 2.7453  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 2.9963  Validation loss = 2.7444  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 2.9960  Validation loss = 2.7434  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 2.9957  Validation loss = 2.7429  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 2.9953  Validation loss = 2.7417  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 2.9948  Validation loss = 2.7405  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 2.9942  Validation loss = 2.7391  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 2.9938  Validation loss = 2.7380  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 2.9933  Validation loss = 2.7368  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 2.9930  Validation loss = 2.7360  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 2.9928  Validation loss = 2.7355  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 2.9923  Validation loss = 2.7343  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 2.9918  Validation loss = 2.7329  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 2.9916  Validation loss = 2.7325  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 2.9912  Validation loss = 2.7316  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 2.9909  Validation loss = 2.7308  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 2.9905  Validation loss = 2.7296  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 2.9900  Validation loss = 2.7285  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 2.9899  Validation loss = 2.7282  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 2.9895  Validation loss = 2.7272  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 2.9891  Validation loss = 2.7263  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 2.9887  Validation loss = 2.7254  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 2.9884  Validation loss = 2.7245  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 2.9881  Validation loss = 2.7238  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 2.9878  Validation loss = 2.7232  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 2.9874  Validation loss = 2.7220  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 2.9870  Validation loss = 2.7211  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 2.9866  Validation loss = 2.7199  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 2.9860  Validation loss = 2.7185  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 2.9857  Validation loss = 2.7177  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 2.9854  Validation loss = 2.7169  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 2.9849  Validation loss = 2.7157  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 2.9846  Validation loss = 2.7147  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 2.9841  Validation loss = 2.7136  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 2.9838  Validation loss = 2.7128  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 2.9836  Validation loss = 2.7123  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 2.9833  Validation loss = 2.7116  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 2.9829  Validation loss = 2.7107  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 2.9827  Validation loss = 2.7099  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 2.9823  Validation loss = 2.7089  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 2.9819  Validation loss = 2.7079  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 2.9815  Validation loss = 2.7069  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 2.9811  Validation loss = 2.7059  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 2.9808  Validation loss = 2.7051  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 2.9804  Validation loss = 2.7041  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 2.9802  Validation loss = 2.7035  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 2.9797  Validation loss = 2.7024  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 2.9795  Validation loss = 2.7018  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 2.9792  Validation loss = 2.7010  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 2.9787  Validation loss = 2.6999  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 2.9784  Validation loss = 2.6991  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 2.9780  Validation loss = 2.6980  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 2.9777  Validation loss = 2.6971  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 2.9773  Validation loss = 2.6962  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 2.9768  Validation loss = 2.6950  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 2.9764  Validation loss = 2.6940  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 2.9760  Validation loss = 2.6928  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 2.9757  Validation loss = 2.6920  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 2.9754  Validation loss = 2.6911  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 2.9751  Validation loss = 2.6905  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 2.9748  Validation loss = 2.6897  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 2.9745  Validation loss = 2.6890  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 2.9740  Validation loss = 2.6877  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 2.9735  Validation loss = 2.6864  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 2.9730  Validation loss = 2.6852  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 2.9727  Validation loss = 2.6843  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 2.9721  Validation loss = 2.6829  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 2.9716  Validation loss = 2.6814  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 2.9711  Validation loss = 2.6800  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 2.9707  Validation loss = 2.6789  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 2.9703  Validation loss = 2.6781  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 2.9700  Validation loss = 2.6771  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 2.9695  Validation loss = 2.6760  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 2.9692  Validation loss = 2.6750  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 2.9687  Validation loss = 2.6738  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 2.9684  Validation loss = 2.6730  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 2.9680  Validation loss = 2.6721  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 2.9678  Validation loss = 2.6714  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 2.9675  Validation loss = 2.6708  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 2.9671  Validation loss = 2.6697  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 2.9666  Validation loss = 2.6685  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 2.9661  Validation loss = 2.6673  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 2.9657  Validation loss = 2.6663  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 2.9656  Validation loss = 2.6660  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 2.9653  Validation loss = 2.6652  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 2.9647  Validation loss = 2.6636  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 2.9642  Validation loss = 2.6625  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 2.9637  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 2.9633  Validation loss = 2.6602  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 2.9630  Validation loss = 2.6593  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 2.9625  Validation loss = 2.6583  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 2.9622  Validation loss = 2.6574  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 2.9618  Validation loss = 2.6565  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 2.9615  Validation loss = 2.6555  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 2.9611  Validation loss = 2.6546  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 2.9607  Validation loss = 2.6536  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 2.9603  Validation loss = 2.6528  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 2.9600  Validation loss = 2.6519  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 2.9594  Validation loss = 2.6504  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 2.9591  Validation loss = 2.6497  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 2.9587  Validation loss = 2.6488  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 2.9583  Validation loss = 2.6477  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 2.9578  Validation loss = 2.6466  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 2.9574  Validation loss = 2.6455  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 2.9571  Validation loss = 2.6447  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 2.9567  Validation loss = 2.6436  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 2.9562  Validation loss = 2.6425  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 2.9555  Validation loss = 2.6409  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 2.9548  Validation loss = 2.6395  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 2.9530  Validation loss = 2.6383  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 2.9509  Validation loss = 2.6369  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 2.9504  Validation loss = 2.6358  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 2.9499  Validation loss = 2.6346  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 2.9495  Validation loss = 2.6337  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 2.9491  Validation loss = 2.6328  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 2.9488  Validation loss = 2.6321  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 2.9485  Validation loss = 2.6313  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 2.9482  Validation loss = 2.6305  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 2.9478  Validation loss = 2.6295  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 2.9474  Validation loss = 2.6285  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 2.9470  Validation loss = 2.6275  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 2.9465  Validation loss = 2.6261  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 2.9462  Validation loss = 2.6253  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 2.9458  Validation loss = 2.6243  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 2.9453  Validation loss = 2.6232  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 2.9450  Validation loss = 2.6222  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 2.9448  Validation loss = 2.6217  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 2.9442  Validation loss = 2.6200  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 2.9438  Validation loss = 2.6192  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 2.9435  Validation loss = 2.6184  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 2.9432  Validation loss = 2.6176  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 2.9429  Validation loss = 2.6169  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 2.9424  Validation loss = 2.6157  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 2.9420  Validation loss = 2.6146  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 2.9417  Validation loss = 2.6139  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 2.9414  Validation loss = 2.6131  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 2.9410  Validation loss = 2.6120  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 2.9405  Validation loss = 2.6108  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 2.9402  Validation loss = 2.6099  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 2.9398  Validation loss = 2.6089  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 2.9393  Validation loss = 2.6078  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 2.9389  Validation loss = 2.6067  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 2.9386  Validation loss = 2.6059  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 2.9383  Validation loss = 2.6050  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 2.9378  Validation loss = 2.6040  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 2.9375  Validation loss = 2.6031  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 2.9371  Validation loss = 2.6021  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 2.9367  Validation loss = 2.6012  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 2.9364  Validation loss = 2.6005  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 2.9359  Validation loss = 2.5993  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 2.9357  Validation loss = 2.5986  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 2.9353  Validation loss = 2.5975  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 2.9349  Validation loss = 2.5965  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 2.9345  Validation loss = 2.5955  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 2.9340  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 2.9337  Validation loss = 2.5935  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 2.9333  Validation loss = 2.5925  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 2.9329  Validation loss = 2.5916  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 2.9324  Validation loss = 2.5903  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 2.9321  Validation loss = 2.5895  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 2.9319  Validation loss = 2.5890  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 2.9314  Validation loss = 2.5877  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 2.9312  Validation loss = 2.5871  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 2.9308  Validation loss = 2.5862  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 2.9303  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 2.9300  Validation loss = 2.5841  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 2.9297  Validation loss = 2.5835  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 2.9295  Validation loss = 2.5828  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 2.9291  Validation loss = 2.5818  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 2.9288  Validation loss = 2.5812  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 2.9285  Validation loss = 2.5803  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 2.9280  Validation loss = 2.5791  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 2.9276  Validation loss = 2.5780  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 2.9271  Validation loss = 2.5768  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 2.9268  Validation loss = 2.5760  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 2.9265  Validation loss = 2.5753  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 2.9261  Validation loss = 2.5743  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 2.9257  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 2.9254  Validation loss = 2.5724  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 2.9248  Validation loss = 2.5711  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 2.9244  Validation loss = 2.5700  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 2.9240  Validation loss = 2.5689  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 2.9236  Validation loss = 2.5677  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 2.9231  Validation loss = 2.5666  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 2.9228  Validation loss = 2.5658  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 2.9224  Validation loss = 2.5650  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 2.9221  Validation loss = 2.5643  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 2.9218  Validation loss = 2.5636  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 2.9214  Validation loss = 2.5625  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 2.9211  Validation loss = 2.5617  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 2.9206  Validation loss = 2.5604  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 2.9203  Validation loss = 2.5595  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 2.9199  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 2.9195  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 2.9193  Validation loss = 2.5570  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 2.9189  Validation loss = 2.5560  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 2.9185  Validation loss = 2.5551  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 2.9181  Validation loss = 2.5541  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 2.9178  Validation loss = 2.5533  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 2.9174  Validation loss = 2.5524  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 2.9170  Validation loss = 2.5511  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 2.9166  Validation loss = 2.5501  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 2.9161  Validation loss = 2.5490  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 2.9157  Validation loss = 2.5481  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 2.9154  Validation loss = 2.5472  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 500  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 2.9496  Validation loss = 5.0038  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 2.9491  Validation loss = 5.0029  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 2.9485  Validation loss = 5.0018  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 2.9478  Validation loss = 5.0007  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 2.9470  Validation loss = 4.9996  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 2.9465  Validation loss = 4.9989  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 2.9451  Validation loss = 4.9978  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 2.9444  Validation loss = 4.9968  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 2.9438  Validation loss = 4.9960  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 2.9429  Validation loss = 4.9949  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 2.9424  Validation loss = 4.9943  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 2.9413  Validation loss = 4.9931  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 2.9406  Validation loss = 4.9922  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 2.9400  Validation loss = 4.9914  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 2.9395  Validation loss = 4.9906  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 2.9392  Validation loss = 4.9899  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 2.9386  Validation loss = 4.9889  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 2.9380  Validation loss = 4.9877  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 2.9374  Validation loss = 4.9866  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 2.9369  Validation loss = 4.9856  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 2.9364  Validation loss = 4.9846  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 2.9357  Validation loss = 4.9833  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 2.9352  Validation loss = 4.9822  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 2.9347  Validation loss = 4.9812  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 2.9341  Validation loss = 4.9800  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 2.9336  Validation loss = 4.9790  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 2.9330  Validation loss = 4.9777  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 2.9327  Validation loss = 4.9772  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 2.9321  Validation loss = 4.9761  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 2.9317  Validation loss = 4.9751  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 2.9312  Validation loss = 4.9741  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 2.9306  Validation loss = 4.9731  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 2.9301  Validation loss = 4.9721  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 2.9297  Validation loss = 4.9711  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 2.9292  Validation loss = 4.9702  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 2.9287  Validation loss = 4.9692  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 2.9280  Validation loss = 4.9678  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 2.9277  Validation loss = 4.9670  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 2.9272  Validation loss = 4.9660  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 2.9267  Validation loss = 4.9650  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 2.9259  Validation loss = 4.9635  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 2.9253  Validation loss = 4.9623  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 2.9248  Validation loss = 4.9612  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 2.9242  Validation loss = 4.9601  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 2.9237  Validation loss = 4.9591  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 2.9231  Validation loss = 4.9578  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 2.9226  Validation loss = 4.9568  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 2.9221  Validation loss = 4.9559  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 2.9217  Validation loss = 4.9550  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 2.9213  Validation loss = 4.9541  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 2.9208  Validation loss = 4.9531  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 2.9202  Validation loss = 4.9519  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 2.9193  Validation loss = 4.9502  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 2.9188  Validation loss = 4.9492  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 2.9184  Validation loss = 4.9483  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 2.9178  Validation loss = 4.9470  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 2.9174  Validation loss = 4.9461  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 2.9169  Validation loss = 4.9452  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 2.9165  Validation loss = 4.9443  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 2.9161  Validation loss = 4.9435  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 2.9157  Validation loss = 4.9427  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 2.9151  Validation loss = 4.9415  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 2.9145  Validation loss = 4.9402  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 2.9141  Validation loss = 4.9393  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 2.9135  Validation loss = 4.9383  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 2.9131  Validation loss = 4.9373  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 2.9127  Validation loss = 4.9365  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 2.9122  Validation loss = 4.9354  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 2.9118  Validation loss = 4.9347  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 2.9115  Validation loss = 4.9340  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 2.9109  Validation loss = 4.9328  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 2.9104  Validation loss = 4.9318  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 2.9099  Validation loss = 4.9308  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 2.9094  Validation loss = 4.9298  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 2.9086  Validation loss = 4.9282  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 2.9082  Validation loss = 4.9274  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 2.9078  Validation loss = 4.9265  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 2.9074  Validation loss = 4.9256  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 2.9069  Validation loss = 4.9246  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 2.9063  Validation loss = 4.9234  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 2.9060  Validation loss = 4.9227  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 2.9056  Validation loss = 4.9219  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 2.9050  Validation loss = 4.9207  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 2.9045  Validation loss = 4.9197  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 2.9041  Validation loss = 4.9188  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 2.9037  Validation loss = 4.9181  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 2.9033  Validation loss = 4.9172  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 2.9029  Validation loss = 4.9162  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 2.9024  Validation loss = 4.9153  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 2.9020  Validation loss = 4.9145  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 2.9015  Validation loss = 4.9134  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 2.9011  Validation loss = 4.9125  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 2.9005  Validation loss = 4.9113  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 2.9000  Validation loss = 4.9102  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 2.8997  Validation loss = 4.9097  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 2.8991  Validation loss = 4.9085  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 2.8988  Validation loss = 4.9077  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 2.8981  Validation loss = 4.9064  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 2.8976  Validation loss = 4.9054  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 2.8971  Validation loss = 4.9043  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 2.8969  Validation loss = 4.9038  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 2.8964  Validation loss = 4.9029  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 2.8961  Validation loss = 4.9023  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 2.8956  Validation loss = 4.9012  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 2.8952  Validation loss = 4.9004  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 2.8946  Validation loss = 4.8991  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 2.8944  Validation loss = 4.8986  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 2.8939  Validation loss = 4.8976  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 2.8935  Validation loss = 4.8967  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 2.8928  Validation loss = 4.8953  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 2.8923  Validation loss = 4.8943  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 2.8920  Validation loss = 4.8936  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 2.8915  Validation loss = 4.8927  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 2.8912  Validation loss = 4.8919  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 2.8907  Validation loss = 4.8910  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 2.8902  Validation loss = 4.8900  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 2.8898  Validation loss = 4.8892  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 2.8894  Validation loss = 4.8883  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 2.8889  Validation loss = 4.8872  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 2.8883  Validation loss = 4.8860  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 2.8879  Validation loss = 4.8852  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 2.8874  Validation loss = 4.8842  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 2.8869  Validation loss = 4.8831  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 2.8865  Validation loss = 4.8821  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 2.8862  Validation loss = 4.8816  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 2.8858  Validation loss = 4.8807  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 2.8854  Validation loss = 4.8798  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 2.8850  Validation loss = 4.8790  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 2.8845  Validation loss = 4.8779  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 2.8841  Validation loss = 4.8770  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 2.8838  Validation loss = 4.8765  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 2.8833  Validation loss = 4.8754  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 2.8827  Validation loss = 4.8742  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 2.8821  Validation loss = 4.8730  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 2.8817  Validation loss = 4.8720  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 2.8811  Validation loss = 4.8709  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 2.8806  Validation loss = 4.8699  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 2.8801  Validation loss = 4.8686  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 2.8797  Validation loss = 4.8678  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 2.8791  Validation loss = 4.8666  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 2.8786  Validation loss = 4.8655  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 2.8781  Validation loss = 4.8646  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 2.8776  Validation loss = 4.8636  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 2.8771  Validation loss = 4.8625  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 2.8768  Validation loss = 4.8618  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 2.8762  Validation loss = 4.8606  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 2.8758  Validation loss = 4.8597  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 2.8754  Validation loss = 4.8589  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 2.8749  Validation loss = 4.8579  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 2.8744  Validation loss = 4.8568  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 2.8738  Validation loss = 4.8557  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 2.8734  Validation loss = 4.8547  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 2.8730  Validation loss = 4.8539  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 2.8726  Validation loss = 4.8530  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 2.8720  Validation loss = 4.8518  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 2.8717  Validation loss = 4.8511  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 2.8713  Validation loss = 4.8503  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 2.8707  Validation loss = 4.8492  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 2.8704  Validation loss = 4.8483  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 2.8698  Validation loss = 4.8472  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 2.8693  Validation loss = 4.8461  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 2.8690  Validation loss = 4.8455  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 2.8686  Validation loss = 4.8445  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 2.8683  Validation loss = 4.8439  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 2.8678  Validation loss = 4.8430  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 2.8675  Validation loss = 4.8423  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 2.8671  Validation loss = 4.8414  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 2.8667  Validation loss = 4.8406  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 2.8662  Validation loss = 4.8395  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 2.8658  Validation loss = 4.8387  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 2.8655  Validation loss = 4.8380  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 2.8649  Validation loss = 4.8369  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 2.8646  Validation loss = 4.8362  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 2.8641  Validation loss = 4.8352  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 2.8636  Validation loss = 4.8340  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 2.8630  Validation loss = 4.8328  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 2.8625  Validation loss = 4.8318  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 2.8622  Validation loss = 4.8311  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 2.8618  Validation loss = 4.8303  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 2.8615  Validation loss = 4.8296  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 2.8610  Validation loss = 4.8286  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 2.8604  Validation loss = 4.8275  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 2.8600  Validation loss = 4.8266  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 2.8596  Validation loss = 4.8257  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 2.8589  Validation loss = 4.8243  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 2.8585  Validation loss = 4.8234  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 2.8582  Validation loss = 4.8227  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 2.8576  Validation loss = 4.8215  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 2.8572  Validation loss = 4.8207  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 2.8568  Validation loss = 4.8198  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 2.8565  Validation loss = 4.8191  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 2.8560  Validation loss = 4.8180  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 2.8555  Validation loss = 4.8171  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 2.8552  Validation loss = 4.8164  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 2.8547  Validation loss = 4.8155  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 2.8543  Validation loss = 4.8146  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 2.8538  Validation loss = 4.8134  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 2.8533  Validation loss = 4.8123  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 2.8529  Validation loss = 4.8115  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 2.8523  Validation loss = 4.8101  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 2.8518  Validation loss = 4.8092  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 2.8513  Validation loss = 4.8082  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 2.8507  Validation loss = 4.8069  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 2.8502  Validation loss = 4.8058  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 2.8497  Validation loss = 4.8048  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 2.8492  Validation loss = 4.8037  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 2.8488  Validation loss = 4.8030  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 2.8485  Validation loss = 4.8022  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 2.8481  Validation loss = 4.8013  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 2.8475  Validation loss = 4.8001  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 2.8469  Validation loss = 4.7989  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 2.8465  Validation loss = 4.7980  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 2.8462  Validation loss = 4.7973  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 2.8457  Validation loss = 4.7964  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 2.8452  Validation loss = 4.7953  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 2.8448  Validation loss = 4.7944  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 2.8443  Validation loss = 4.7934  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 2.8438  Validation loss = 4.7923  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 2.8435  Validation loss = 4.7916  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 2.8431  Validation loss = 4.7908  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 2.8427  Validation loss = 4.7899  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 2.8423  Validation loss = 4.7891  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 2.8419  Validation loss = 4.7882  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 2.8415  Validation loss = 4.7874  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 2.8409  Validation loss = 4.7860  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 2.8405  Validation loss = 4.7852  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 2.8401  Validation loss = 4.7843  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 2.8396  Validation loss = 4.7833  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 2.8392  Validation loss = 4.7825  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 2.8388  Validation loss = 4.7815  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 2.8383  Validation loss = 4.7806  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 2.8380  Validation loss = 4.7798  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 2.8376  Validation loss = 4.7791  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 2.8373  Validation loss = 4.7784  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 2.8368  Validation loss = 4.7773  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 2.8362  Validation loss = 4.7760  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 2.8359  Validation loss = 4.7753  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 2.8354  Validation loss = 4.7743  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 2.8351  Validation loss = 4.7735  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 2.8348  Validation loss = 4.7729  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 2.8344  Validation loss = 4.7722  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 2.8340  Validation loss = 4.7712  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 2.8336  Validation loss = 4.7704  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 2.8333  Validation loss = 4.7698  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 2.8329  Validation loss = 4.7689  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 2.8325  Validation loss = 4.7680  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 2.8320  Validation loss = 4.7670  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 2.8317  Validation loss = 4.7662  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 2.8312  Validation loss = 4.7653  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 2.8309  Validation loss = 4.7645  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 2.8303  Validation loss = 4.7634  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 2.8300  Validation loss = 4.7627  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 2.8296  Validation loss = 4.7618  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 2.8292  Validation loss = 4.7609  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 2.8288  Validation loss = 4.7602  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 2.8285  Validation loss = 4.7596  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 2.8281  Validation loss = 4.7585  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 2.8278  Validation loss = 4.7578  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 2.8273  Validation loss = 4.7570  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 2.8269  Validation loss = 4.7560  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 2.8263  Validation loss = 4.7549  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 2.8260  Validation loss = 4.7541  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 2.8255  Validation loss = 4.7531  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 2.8250  Validation loss = 4.7520  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 2.8244  Validation loss = 4.7507  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 2.8240  Validation loss = 4.7499  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 2.8236  Validation loss = 4.7491  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 2.8232  Validation loss = 4.7482  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 2.8226  Validation loss = 4.7469  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 2.8222  Validation loss = 4.7462  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 2.8220  Validation loss = 4.7457  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 2.8214  Validation loss = 4.7445  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 2.8210  Validation loss = 4.7435  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 2.8205  Validation loss = 4.7424  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 2.8201  Validation loss = 4.7415  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 2.8196  Validation loss = 4.7406  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 2.8193  Validation loss = 4.7399  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 2.8189  Validation loss = 4.7390  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 2.8184  Validation loss = 4.7381  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 2.8181  Validation loss = 4.7374  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 2.8179  Validation loss = 4.7369  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 2.8176  Validation loss = 4.7363  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 2.8170  Validation loss = 4.7350  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 2.8165  Validation loss = 4.7338  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 2.8161  Validation loss = 4.7331  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 2.8157  Validation loss = 4.7322  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 2.8153  Validation loss = 4.7313  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 2.8150  Validation loss = 4.7307  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 2.8147  Validation loss = 4.7299  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 2.8142  Validation loss = 4.7288  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 2.8138  Validation loss = 4.7279  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 2.8132  Validation loss = 4.7266  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 2.8128  Validation loss = 4.7258  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 2.8124  Validation loss = 4.7250  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 2.8119  Validation loss = 4.7239  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 2.8115  Validation loss = 4.7231  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 2.8111  Validation loss = 4.7221  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 2.8106  Validation loss = 4.7210  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 2.8103  Validation loss = 4.7203  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 2.8099  Validation loss = 4.7194  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 2.8095  Validation loss = 4.7186  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 2.8090  Validation loss = 4.7175  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 2.8085  Validation loss = 4.7164  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 2.8082  Validation loss = 4.7157  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 2.8078  Validation loss = 4.7148  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 2.8075  Validation loss = 4.7141  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 2.8070  Validation loss = 4.7131  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 2.8067  Validation loss = 4.7125  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 2.8064  Validation loss = 4.7118  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 2.8061  Validation loss = 4.7111  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 2.8056  Validation loss = 4.7100  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 2.8051  Validation loss = 4.7090  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 2.8047  Validation loss = 4.7081  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 2.8043  Validation loss = 4.7073  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 2.8040  Validation loss = 4.7066  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 2.8033  Validation loss = 4.7051  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 2.8029  Validation loss = 4.7042  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 2.8025  Validation loss = 4.7034  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 2.8021  Validation loss = 4.7026  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 2.8015  Validation loss = 4.7013  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 2.8011  Validation loss = 4.7004  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 2.8007  Validation loss = 4.6995  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 2.8000  Validation loss = 4.6981  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 2.7998  Validation loss = 4.6975  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 2.7994  Validation loss = 4.6966  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 2.7989  Validation loss = 4.6956  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 2.7986  Validation loss = 4.6949  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 2.7982  Validation loss = 4.6940  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 2.7978  Validation loss = 4.6931  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 2.7973  Validation loss = 4.6922  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 2.7971  Validation loss = 4.6916  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 2.7968  Validation loss = 4.6909  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 2.7963  Validation loss = 4.6899  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 2.7960  Validation loss = 4.6893  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 2.7957  Validation loss = 4.6886  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 2.7953  Validation loss = 4.6879  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 2.7949  Validation loss = 4.6870  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 2.7944  Validation loss = 4.6859  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 2.7940  Validation loss = 4.6851  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 2.7937  Validation loss = 4.6843  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 2.7932  Validation loss = 4.6832  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 2.7927  Validation loss = 4.6823  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 2.7923  Validation loss = 4.6814  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 2.7918  Validation loss = 4.6802  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 2.7914  Validation loss = 4.6793  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 2.7911  Validation loss = 4.6786  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 2.7907  Validation loss = 4.6778  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 2.7904  Validation loss = 4.6770  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 2.7898  Validation loss = 4.6757  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 2.7896  Validation loss = 4.6754  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 2.7892  Validation loss = 4.6744  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 2.7889  Validation loss = 4.6737  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 2.7883  Validation loss = 4.6724  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 2.7879  Validation loss = 4.6715  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 2.7877  Validation loss = 4.6711  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 2.7873  Validation loss = 4.6702  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 2.7869  Validation loss = 4.6694  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 2.7865  Validation loss = 4.6685  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 2.7860  Validation loss = 4.6674  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 2.7856  Validation loss = 4.6666  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 2.7851  Validation loss = 4.6654  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 2.7847  Validation loss = 4.6646  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 2.7843  Validation loss = 4.6637  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 2.7839  Validation loss = 4.6629  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 2.7837  Validation loss = 4.6624  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 2.7832  Validation loss = 4.6614  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 2.7828  Validation loss = 4.6604  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 2.7822  Validation loss = 4.6592  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 2.7818  Validation loss = 4.6583  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 2.7815  Validation loss = 4.6577  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 2.7811  Validation loss = 4.6568  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 2.7809  Validation loss = 4.6562  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 2.7806  Validation loss = 4.6556  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 2.7801  Validation loss = 4.6545  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 2.7797  Validation loss = 4.6537  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 2.7795  Validation loss = 4.6532  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 2.7793  Validation loss = 4.6527  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 2.7788  Validation loss = 4.6517  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 2.7785  Validation loss = 4.6509  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 2.7780  Validation loss = 4.6498  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 2.7776  Validation loss = 4.6490  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 2.7772  Validation loss = 4.6481  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 2.7769  Validation loss = 4.6474  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 2.7765  Validation loss = 4.6466  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 2.7761  Validation loss = 4.6458  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 2.7758  Validation loss = 4.6450  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 2.7754  Validation loss = 4.6441  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 2.7749  Validation loss = 4.6430  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 2.7745  Validation loss = 4.6420  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 2.7740  Validation loss = 4.6411  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 2.7737  Validation loss = 4.6402  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 2.7733  Validation loss = 4.6395  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 2.7729  Validation loss = 4.6386  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 2.7725  Validation loss = 4.6378  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 2.7722  Validation loss = 4.6370  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 2.7717  Validation loss = 4.6359  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 2.7714  Validation loss = 4.6353  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 2.7711  Validation loss = 4.6346  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 2.7707  Validation loss = 4.6337  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 2.7702  Validation loss = 4.6328  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 2.7699  Validation loss = 4.6321  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 2.7696  Validation loss = 4.6314  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 2.7692  Validation loss = 4.6305  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 2.7687  Validation loss = 4.6296  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 2.7683  Validation loss = 4.6286  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 2.7679  Validation loss = 4.6278  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 2.7675  Validation loss = 4.6269  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 2.7672  Validation loss = 4.6262  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 2.7667  Validation loss = 4.6253  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 2.7664  Validation loss = 4.6246  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 2.7661  Validation loss = 4.6240  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 2.7656  Validation loss = 4.6233  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 2.7650  Validation loss = 4.6223  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 2.7646  Validation loss = 4.6216  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 2.7643  Validation loss = 4.6208  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 2.7637  Validation loss = 4.6198  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 2.7634  Validation loss = 4.6191  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 2.7627  Validation loss = 4.6181  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 2.7624  Validation loss = 4.6174  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 2.7618  Validation loss = 4.6163  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 2.7613  Validation loss = 4.6155  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 2.7610  Validation loss = 4.6149  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 2.7606  Validation loss = 4.6140  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 2.7601  Validation loss = 4.6132  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 2.7595  Validation loss = 4.6121  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 2.7593  Validation loss = 4.6116  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 2.7590  Validation loss = 4.6111  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 2.7584  Validation loss = 4.6098  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 2.7580  Validation loss = 4.6090  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 2.7576  Validation loss = 4.6081  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 2.7571  Validation loss = 4.6070  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 2.7569  Validation loss = 4.6065  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 2.7565  Validation loss = 4.6056  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 2.7561  Validation loss = 4.6048  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 2.7557  Validation loss = 4.6039  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 2.7554  Validation loss = 4.6032  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 2.7550  Validation loss = 4.6024  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 2.7545  Validation loss = 4.6013  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 2.7541  Validation loss = 4.6005  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 2.7538  Validation loss = 4.5998  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 2.7536  Validation loss = 4.5992  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 2.7531  Validation loss = 4.5982  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 2.7527  Validation loss = 4.5974  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 2.7523  Validation loss = 4.5965  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 2.7519  Validation loss = 4.5956  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 2.7516  Validation loss = 4.5948  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 2.7513  Validation loss = 4.5941  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 2.7510  Validation loss = 4.5936  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 2.7506  Validation loss = 4.5925  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 2.7500  Validation loss = 4.5913  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 2.7498  Validation loss = 4.5908  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 2.7496  Validation loss = 4.5902  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 2.7492  Validation loss = 4.5894  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 2.7489  Validation loss = 4.5889  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 2.7485  Validation loss = 4.5879  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 2.7480  Validation loss = 4.5868  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 2.7477  Validation loss = 4.5861  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 2.7473  Validation loss = 4.5853  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 2.7470  Validation loss = 4.5846  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 2.7465  Validation loss = 4.5834  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 2.7461  Validation loss = 4.5825  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 2.7456  Validation loss = 4.5815  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 2.7452  Validation loss = 4.5805  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 2.7447  Validation loss = 4.5796  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 2.7445  Validation loss = 4.5789  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 2.7442  Validation loss = 4.5783  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 2.7437  Validation loss = 4.5775  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 2.7430  Validation loss = 4.5764  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 2.7427  Validation loss = 4.5758  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 2.7397  Validation loss = 4.5748  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 2.7387  Validation loss = 4.5739  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 2.7382  Validation loss = 4.5729  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 2.7378  Validation loss = 4.5723  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 2.7375  Validation loss = 4.5716  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 2.7371  Validation loss = 4.5708  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 2.7367  Validation loss = 4.5698  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 2.7365  Validation loss = 4.5693  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 2.7362  Validation loss = 4.5686  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 2.7358  Validation loss = 4.5679  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 2.7355  Validation loss = 4.5671  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 2.7349  Validation loss = 4.5659  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 2.7346  Validation loss = 4.5650  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 2.7341  Validation loss = 4.5641  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 2.7335  Validation loss = 4.5627  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 2.7332  Validation loss = 4.5619  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 2.7327  Validation loss = 4.5608  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 2.7324  Validation loss = 4.5603  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 2.7320  Validation loss = 4.5593  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 2.7316  Validation loss = 4.5583  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 2.7310  Validation loss = 4.5571  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 2.7307  Validation loss = 4.5563  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 2.7304  Validation loss = 4.5557  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 2.7298  Validation loss = 4.5543  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 2.7294  Validation loss = 4.5534  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 2.7291  Validation loss = 4.5528  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 2.7288  Validation loss = 4.5522  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 2.7283  Validation loss = 4.5509  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 2.7278  Validation loss = 4.5498  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 2.7274  Validation loss = 4.5488  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 2.7270  Validation loss = 4.5480  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 500  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.9255  Validation loss = 8.4088  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.9249  Validation loss = 8.4076  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.9240  Validation loss = 8.4061  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.9236  Validation loss = 8.4054  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.9231  Validation loss = 8.4044  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 2.9225  Validation loss = 8.4032  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.9218  Validation loss = 8.4020  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.9212  Validation loss = 8.4007  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.9207  Validation loss = 8.3998  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.9204  Validation loss = 8.3991  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.9198  Validation loss = 8.3981  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.9194  Validation loss = 8.3973  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.9189  Validation loss = 8.3964  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 2.9184  Validation loss = 8.3954  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.9179  Validation loss = 8.3944  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.9173  Validation loss = 8.3933  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 2.9169  Validation loss = 8.3926  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 2.9165  Validation loss = 8.3918  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 2.9160  Validation loss = 8.3908  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.9154  Validation loss = 8.3897  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 2.9149  Validation loss = 8.3888  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 2.9143  Validation loss = 8.3877  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 2.9137  Validation loss = 8.3865  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 2.9132  Validation loss = 8.3856  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 2.9127  Validation loss = 8.3846  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 2.9120  Validation loss = 8.3833  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 2.9116  Validation loss = 8.3824  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 2.9111  Validation loss = 8.3815  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 2.9107  Validation loss = 8.3806  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 2.9103  Validation loss = 8.3799  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 2.9097  Validation loss = 8.3789  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 2.9092  Validation loss = 8.3779  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 2.9086  Validation loss = 8.3768  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 2.9079  Validation loss = 8.3755  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 2.9072  Validation loss = 8.3744  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 2.9067  Validation loss = 8.3734  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 2.9060  Validation loss = 8.3721  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 2.9056  Validation loss = 8.3713  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 2.9049  Validation loss = 8.3700  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 2.9043  Validation loss = 8.3688  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 2.9038  Validation loss = 8.3679  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 2.9032  Validation loss = 8.3669  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 2.9026  Validation loss = 8.3658  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 2.9020  Validation loss = 8.3648  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 2.9014  Validation loss = 8.3637  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 2.9007  Validation loss = 8.3624  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 2.9003  Validation loss = 8.3615  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 2.8998  Validation loss = 8.3605  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 2.8993  Validation loss = 8.3596  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 2.8986  Validation loss = 8.3584  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 2.8981  Validation loss = 8.3575  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 2.8976  Validation loss = 8.3564  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 2.8968  Validation loss = 8.3550  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 2.8965  Validation loss = 8.3544  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 2.8961  Validation loss = 8.3535  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 2.8955  Validation loss = 8.3524  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 2.8950  Validation loss = 8.3513  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 2.8944  Validation loss = 8.3502  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 2.8939  Validation loss = 8.3492  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 2.8933  Validation loss = 8.3481  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 2.8929  Validation loss = 8.3475  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 2.8924  Validation loss = 8.3466  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 2.8917  Validation loss = 8.3453  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 2.8913  Validation loss = 8.3444  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 2.8906  Validation loss = 8.3432  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 2.8901  Validation loss = 8.3422  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 2.8894  Validation loss = 8.3408  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 2.8888  Validation loss = 8.3397  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 2.8883  Validation loss = 8.3388  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 2.8879  Validation loss = 8.3379  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 2.8873  Validation loss = 8.3368  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 2.8868  Validation loss = 8.3357  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 2.8862  Validation loss = 8.3347  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 2.8858  Validation loss = 8.3339  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 2.8853  Validation loss = 8.3329  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 2.8849  Validation loss = 8.3322  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 2.8844  Validation loss = 8.3312  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 2.8839  Validation loss = 8.3303  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 2.8833  Validation loss = 8.3290  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 2.8828  Validation loss = 8.3281  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 2.8823  Validation loss = 8.3270  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 2.8818  Validation loss = 8.3260  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 2.8813  Validation loss = 8.3251  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 2.8808  Validation loss = 8.3240  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 2.8803  Validation loss = 8.3232  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 2.8798  Validation loss = 8.3221  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 2.8793  Validation loss = 8.3211  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 2.8787  Validation loss = 8.3201  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 2.8784  Validation loss = 8.3195  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 2.8779  Validation loss = 8.3185  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 2.8773  Validation loss = 8.3173  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 2.8769  Validation loss = 8.3165  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 2.8764  Validation loss = 8.3155  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 2.8759  Validation loss = 8.3145  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 2.8755  Validation loss = 8.3136  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 2.8749  Validation loss = 8.3126  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 2.8745  Validation loss = 8.3118  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 2.8741  Validation loss = 8.3110  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 2.8738  Validation loss = 8.3105  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 2.8735  Validation loss = 8.3100  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 2.8730  Validation loss = 8.3090  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 2.8726  Validation loss = 8.3082  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 2.8721  Validation loss = 8.3074  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 2.8716  Validation loss = 8.3064  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 2.8713  Validation loss = 8.3056  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 2.8707  Validation loss = 8.3046  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 2.8702  Validation loss = 8.3037  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 2.8697  Validation loss = 8.3027  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 2.8692  Validation loss = 8.3017  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 2.8688  Validation loss = 8.3010  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 2.8685  Validation loss = 8.3004  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 2.8680  Validation loss = 8.2993  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 2.8676  Validation loss = 8.2984  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 2.8670  Validation loss = 8.2973  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 2.8664  Validation loss = 8.2963  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 2.8660  Validation loss = 8.2956  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 2.8656  Validation loss = 8.2947  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 2.8651  Validation loss = 8.2936  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 2.8646  Validation loss = 8.2926  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 2.8641  Validation loss = 8.2917  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 2.8636  Validation loss = 8.2907  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 2.8631  Validation loss = 8.2898  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 2.8627  Validation loss = 8.2889  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 2.8621  Validation loss = 8.2877  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 2.8616  Validation loss = 8.2869  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 2.8611  Validation loss = 8.2859  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 2.8605  Validation loss = 8.2847  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 2.8601  Validation loss = 8.2839  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 2.8597  Validation loss = 8.2830  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 2.8593  Validation loss = 8.2822  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 2.8586  Validation loss = 8.2809  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 2.8581  Validation loss = 8.2799  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 2.8576  Validation loss = 8.2789  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 2.8571  Validation loss = 8.2779  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 2.8566  Validation loss = 8.2770  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 2.8562  Validation loss = 8.2763  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 2.8558  Validation loss = 8.2754  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 2.8552  Validation loss = 8.2744  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 2.8548  Validation loss = 8.2735  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 2.8542  Validation loss = 8.2724  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 2.8535  Validation loss = 8.2711  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 2.8529  Validation loss = 8.2698  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 2.8524  Validation loss = 8.2689  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 2.8521  Validation loss = 8.2681  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 2.8517  Validation loss = 8.2674  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 2.8511  Validation loss = 8.2663  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 2.8507  Validation loss = 8.2654  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 2.8503  Validation loss = 8.2646  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 2.8497  Validation loss = 8.2635  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 2.8494  Validation loss = 8.2629  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 2.8489  Validation loss = 8.2617  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 2.8484  Validation loss = 8.2608  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 2.8478  Validation loss = 8.2598  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 2.8474  Validation loss = 8.2589  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 2.8469  Validation loss = 8.2580  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 2.8465  Validation loss = 8.2571  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 2.8458  Validation loss = 8.2558  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 2.8454  Validation loss = 8.2551  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 2.8450  Validation loss = 8.2543  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 2.8446  Validation loss = 8.2535  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 2.8441  Validation loss = 8.2527  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 2.8436  Validation loss = 8.2516  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 2.8433  Validation loss = 8.2510  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 2.8427  Validation loss = 8.2500  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 2.8423  Validation loss = 8.2491  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 2.8417  Validation loss = 8.2480  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 2.8413  Validation loss = 8.2472  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 2.8409  Validation loss = 8.2464  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 2.8405  Validation loss = 8.2454  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 2.8398  Validation loss = 8.2442  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 2.8394  Validation loss = 8.2433  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 2.8388  Validation loss = 8.2421  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 2.8382  Validation loss = 8.2411  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 2.8379  Validation loss = 8.2405  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 2.8374  Validation loss = 8.2395  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 2.8369  Validation loss = 8.2384  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 2.8363  Validation loss = 8.2372  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 2.8358  Validation loss = 8.2361  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 2.8351  Validation loss = 8.2347  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 2.8344  Validation loss = 8.2334  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 2.8340  Validation loss = 8.2325  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 2.8336  Validation loss = 8.2317  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 2.8332  Validation loss = 8.2310  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 2.8327  Validation loss = 8.2299  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 2.8320  Validation loss = 8.2286  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 2.8316  Validation loss = 8.2277  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 2.8310  Validation loss = 8.2265  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 2.8304  Validation loss = 8.2254  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 2.8301  Validation loss = 8.2247  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 2.8296  Validation loss = 8.2237  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 2.8291  Validation loss = 8.2228  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 2.8287  Validation loss = 8.2219  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 2.8284  Validation loss = 8.2213  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 2.8280  Validation loss = 8.2205  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 2.8275  Validation loss = 8.2197  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 2.8271  Validation loss = 8.2190  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 2.8266  Validation loss = 8.2181  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 2.8262  Validation loss = 8.2172  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 2.8257  Validation loss = 8.2163  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 2.8254  Validation loss = 8.2155  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 2.8249  Validation loss = 8.2146  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 2.8246  Validation loss = 8.2140  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 2.8239  Validation loss = 8.2127  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 2.8234  Validation loss = 8.2115  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 2.8230  Validation loss = 8.2108  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 2.8225  Validation loss = 8.2097  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 2.8222  Validation loss = 8.2093  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 2.8217  Validation loss = 8.2083  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 2.8214  Validation loss = 8.2075  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 2.8209  Validation loss = 8.2066  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 2.8205  Validation loss = 8.2058  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 2.8200  Validation loss = 8.2048  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 2.8196  Validation loss = 8.2040  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 2.8192  Validation loss = 8.2033  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 2.8187  Validation loss = 8.2023  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 2.8185  Validation loss = 8.2020  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 2.8180  Validation loss = 8.2009  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 2.8175  Validation loss = 8.1998  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 2.8169  Validation loss = 8.1986  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 2.8165  Validation loss = 8.1979  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 2.8160  Validation loss = 8.1968  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 2.8156  Validation loss = 8.1959  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 2.8150  Validation loss = 8.1948  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 2.8146  Validation loss = 8.1940  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 2.8141  Validation loss = 8.1929  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 2.8136  Validation loss = 8.1918  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 2.8130  Validation loss = 8.1906  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 2.8126  Validation loss = 8.1898  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 2.8123  Validation loss = 8.1891  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 2.8118  Validation loss = 8.1883  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 2.8114  Validation loss = 8.1874  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 2.8108  Validation loss = 8.1864  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 2.8105  Validation loss = 8.1857  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 2.8102  Validation loss = 8.1850  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 2.8098  Validation loss = 8.1844  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 2.8094  Validation loss = 8.1834  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 2.8090  Validation loss = 8.1827  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 2.8087  Validation loss = 8.1821  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 2.8084  Validation loss = 8.1814  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 2.8079  Validation loss = 8.1805  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 2.8074  Validation loss = 8.1794  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 2.8069  Validation loss = 8.1785  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 2.8066  Validation loss = 8.1777  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 2.8061  Validation loss = 8.1767  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 2.8056  Validation loss = 8.1758  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 2.8050  Validation loss = 8.1747  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 2.8046  Validation loss = 8.1739  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 2.8041  Validation loss = 8.1729  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 2.8037  Validation loss = 8.1721  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 2.8032  Validation loss = 8.1711  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 2.8026  Validation loss = 8.1700  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 2.8022  Validation loss = 8.1692  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 2.8017  Validation loss = 8.1681  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 2.8013  Validation loss = 8.1674  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 2.8009  Validation loss = 8.1665  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 2.8003  Validation loss = 8.1652  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 2.7998  Validation loss = 8.1643  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 2.7995  Validation loss = 8.1636  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 2.7990  Validation loss = 8.1627  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 2.7985  Validation loss = 8.1615  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 2.7980  Validation loss = 8.1607  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 2.7976  Validation loss = 8.1597  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 2.7971  Validation loss = 8.1589  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 2.7966  Validation loss = 8.1579  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 2.7963  Validation loss = 8.1572  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 2.7959  Validation loss = 8.1562  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 2.7953  Validation loss = 8.1551  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 2.7948  Validation loss = 8.1541  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 2.7944  Validation loss = 8.1532  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 2.7938  Validation loss = 8.1521  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 2.7936  Validation loss = 8.1515  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 2.7931  Validation loss = 8.1507  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 2.7927  Validation loss = 8.1500  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 2.7920  Validation loss = 8.1485  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 2.7916  Validation loss = 8.1478  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 2.7911  Validation loss = 8.1469  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 2.7906  Validation loss = 8.1459  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 2.7902  Validation loss = 8.1451  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 2.7898  Validation loss = 8.1441  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 2.7894  Validation loss = 8.1434  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 2.7888  Validation loss = 8.1422  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 2.7884  Validation loss = 8.1413  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 2.7877  Validation loss = 8.1400  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 2.7872  Validation loss = 8.1389  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 2.7869  Validation loss = 8.1384  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 2.7865  Validation loss = 8.1375  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 2.7859  Validation loss = 8.1364  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 2.7854  Validation loss = 8.1354  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 2.7850  Validation loss = 8.1345  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 2.7847  Validation loss = 8.1339  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 2.7841  Validation loss = 8.1326  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 2.7838  Validation loss = 8.1320  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 2.7833  Validation loss = 8.1311  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 2.7830  Validation loss = 8.1303  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 2.7825  Validation loss = 8.1293  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 2.7820  Validation loss = 8.1283  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 2.7815  Validation loss = 8.1273  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 2.7810  Validation loss = 8.1262  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 2.7805  Validation loss = 8.1252  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 2.7801  Validation loss = 8.1243  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 2.7793  Validation loss = 8.1229  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 2.7789  Validation loss = 8.1219  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 2.7784  Validation loss = 8.1210  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 2.7779  Validation loss = 8.1201  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 2.7775  Validation loss = 8.1191  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 2.7771  Validation loss = 8.1183  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 2.7766  Validation loss = 8.1173  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 2.7761  Validation loss = 8.1161  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 2.7756  Validation loss = 8.1151  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 2.7753  Validation loss = 8.1143  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 2.7747  Validation loss = 8.1132  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 2.7742  Validation loss = 8.1120  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 2.7739  Validation loss = 8.1114  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 2.7736  Validation loss = 8.1108  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 2.7732  Validation loss = 8.1101  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 2.7726  Validation loss = 8.1088  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 2.7722  Validation loss = 8.1081  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 2.7717  Validation loss = 8.1071  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 2.7713  Validation loss = 8.1064  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 2.7709  Validation loss = 8.1055  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 2.7704  Validation loss = 8.1045  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 2.7700  Validation loss = 8.1037  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 2.7697  Validation loss = 8.1030  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 2.7693  Validation loss = 8.1023  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 2.7687  Validation loss = 8.1011  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 2.7681  Validation loss = 8.0999  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 2.7675  Validation loss = 8.0988  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 2.7669  Validation loss = 8.0980  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 2.7663  Validation loss = 8.0972  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 2.7654  Validation loss = 8.0958  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 2.7645  Validation loss = 8.0948  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 2.7640  Validation loss = 8.0939  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 2.7632  Validation loss = 8.0929  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 2.7625  Validation loss = 8.0922  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 2.7618  Validation loss = 8.0909  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 2.7613  Validation loss = 8.0900  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 2.7605  Validation loss = 8.0887  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 2.7600  Validation loss = 8.0880  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 2.7595  Validation loss = 8.0872  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 2.7589  Validation loss = 8.0860  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 2.7583  Validation loss = 8.0849  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 2.7580  Validation loss = 8.0844  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 2.7576  Validation loss = 8.0837  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 2.7572  Validation loss = 8.0828  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 2.7568  Validation loss = 8.0821  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 2.7563  Validation loss = 8.0809  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 2.7558  Validation loss = 8.0798  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 2.7553  Validation loss = 8.0788  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 2.7548  Validation loss = 8.0780  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 2.7544  Validation loss = 8.0773  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 2.7540  Validation loss = 8.0766  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 2.7536  Validation loss = 8.0758  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 2.7533  Validation loss = 8.0753  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 2.7530  Validation loss = 8.0746  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 2.7524  Validation loss = 8.0736  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 2.7519  Validation loss = 8.0727  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 2.7514  Validation loss = 8.0719  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 2.7506  Validation loss = 8.0708  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 2.7499  Validation loss = 8.0696  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 2.7488  Validation loss = 8.0684  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 2.7480  Validation loss = 8.0671  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 2.7476  Validation loss = 8.0664  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 2.7468  Validation loss = 8.0652  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 2.7463  Validation loss = 8.0643  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 2.7456  Validation loss = 8.0631  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 2.7452  Validation loss = 8.0623  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 2.7446  Validation loss = 8.0610  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 2.7439  Validation loss = 8.0596  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 2.7435  Validation loss = 8.0589  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 2.7431  Validation loss = 8.0579  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 2.7428  Validation loss = 8.0574  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 2.7425  Validation loss = 8.0568  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 2.7421  Validation loss = 8.0560  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 2.7416  Validation loss = 8.0549  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 2.7412  Validation loss = 8.0541  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 2.7408  Validation loss = 8.0533  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 2.7404  Validation loss = 8.0525  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 2.7400  Validation loss = 8.0516  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 2.7395  Validation loss = 8.0505  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 2.7390  Validation loss = 8.0495  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 2.7384  Validation loss = 8.0482  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 2.7380  Validation loss = 8.0474  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 2.7376  Validation loss = 8.0464  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 2.7372  Validation loss = 8.0456  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 2.7367  Validation loss = 8.0447  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 2.7362  Validation loss = 8.0435  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 2.7357  Validation loss = 8.0425  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 2.7352  Validation loss = 8.0415  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 2.7347  Validation loss = 8.0405  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 2.7343  Validation loss = 8.0397  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 2.7339  Validation loss = 8.0389  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 2.7336  Validation loss = 8.0382  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 2.7332  Validation loss = 8.0373  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 2.7329  Validation loss = 8.0366  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 2.7325  Validation loss = 8.0359  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 2.7320  Validation loss = 8.0349  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 2.7316  Validation loss = 8.0341  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 2.7313  Validation loss = 8.0334  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 2.7308  Validation loss = 8.0323  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 2.7304  Validation loss = 8.0314  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 2.7299  Validation loss = 8.0304  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 2.7295  Validation loss = 8.0296  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 2.7292  Validation loss = 8.0290  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 2.7287  Validation loss = 8.0280  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 2.7284  Validation loss = 8.0272  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 2.7280  Validation loss = 8.0264  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 2.7276  Validation loss = 8.0256  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 2.7270  Validation loss = 8.0242  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 2.7266  Validation loss = 8.0235  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 2.7262  Validation loss = 8.0226  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 2.7259  Validation loss = 8.0217  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 2.7255  Validation loss = 8.0210  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 2.7249  Validation loss = 8.0199  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 2.7246  Validation loss = 8.0191  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 2.7242  Validation loss = 8.0183  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 2.7237  Validation loss = 8.0173  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 2.7231  Validation loss = 8.0161  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 2.7226  Validation loss = 8.0151  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 2.7222  Validation loss = 8.0141  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 2.7219  Validation loss = 8.0135  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 2.7214  Validation loss = 8.0125  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 2.7210  Validation loss = 8.0114  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 2.7205  Validation loss = 8.0105  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 2.7201  Validation loss = 8.0096  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 2.7197  Validation loss = 8.0087  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 2.7192  Validation loss = 8.0074  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 2.7187  Validation loss = 8.0065  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 2.7182  Validation loss = 8.0054  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 2.7178  Validation loss = 8.0044  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 2.7174  Validation loss = 8.0035  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 2.7168  Validation loss = 8.0022  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 2.7163  Validation loss = 8.0011  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 2.7160  Validation loss = 8.0003  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 2.7157  Validation loss = 7.9998  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 2.7153  Validation loss = 7.9989  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 2.7152  Validation loss = 7.9986  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 2.7147  Validation loss = 7.9976  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 2.7144  Validation loss = 7.9970  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 2.7139  Validation loss = 7.9960  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 2.7136  Validation loss = 7.9953  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 2.7133  Validation loss = 7.9945  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 2.7128  Validation loss = 7.9934  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 2.7124  Validation loss = 7.9926  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 2.7121  Validation loss = 7.9922  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 2.7118  Validation loss = 7.9916  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 2.7115  Validation loss = 7.9908  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 2.7111  Validation loss = 7.9900  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 2.7104  Validation loss = 7.9886  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 2.7099  Validation loss = 7.9878  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 2.7094  Validation loss = 7.9868  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 2.7089  Validation loss = 7.9860  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 2.7078  Validation loss = 7.9847  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 2.7070  Validation loss = 7.9837  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 2.7051  Validation loss = 7.9830  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 2.7040  Validation loss = 7.9823  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 2.7027  Validation loss = 7.9810  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 2.7019  Validation loss = 7.9801  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 2.7013  Validation loss = 7.9792  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 2.7008  Validation loss = 7.9783  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 2.7004  Validation loss = 7.9775  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 2.7000  Validation loss = 7.9768  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 2.6996  Validation loss = 7.9759  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 2.6991  Validation loss = 7.9749  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 2.6987  Validation loss = 7.9739  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 2.6983  Validation loss = 7.9731  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 2.6979  Validation loss = 7.9721  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 2.6974  Validation loss = 7.9712  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 2.6970  Validation loss = 7.9703  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 2.6966  Validation loss = 7.9695  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 2.6963  Validation loss = 7.9688  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 2.6957  Validation loss = 7.9676  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 2.6952  Validation loss = 7.9666  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 2.6947  Validation loss = 7.9656  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 2.6942  Validation loss = 7.9645  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 2.6936  Validation loss = 7.9631  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 2.6932  Validation loss = 7.9623  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 2.6927  Validation loss = 7.9612  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 2.6923  Validation loss = 7.9604  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 2.6918  Validation loss = 7.9594  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 2.6913  Validation loss = 7.9583  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 2.6909  Validation loss = 7.9574  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 2.6903  Validation loss = 7.9562  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 2.6899  Validation loss = 7.9554  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 2.6894  Validation loss = 7.9543  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 2.6891  Validation loss = 7.9537  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 2.6888  Validation loss = 7.9529  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 2.6882  Validation loss = 7.9516  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 2.6879  Validation loss = 7.9509  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 2.6873  Validation loss = 7.9495  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 2.6869  Validation loss = 7.9486  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 2.6865  Validation loss = 7.9477  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 2.6861  Validation loss = 7.9468  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 2.6856  Validation loss = 7.9457  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 2.6852  Validation loss = 7.9449  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 2.6848  Validation loss = 7.9440  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 2.6845  Validation loss = 7.9433  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 2.6841  Validation loss = 7.9424  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 2.6837  Validation loss = 7.9417  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 2.6833  Validation loss = 7.9410  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 2.6831  Validation loss = 7.9405  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 500  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 3.3024  Validation loss = 8.0639  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 3.3017  Validation loss = 8.0622  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 3.3012  Validation loss = 8.0612  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 3.3007  Validation loss = 8.0601  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 3.3000  Validation loss = 8.0588  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 3.2994  Validation loss = 8.0573  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 3.2984  Validation loss = 8.0548  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 3.2979  Validation loss = 8.0538  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 3.2974  Validation loss = 8.0524  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 3.2969  Validation loss = 8.0515  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 3.2962  Validation loss = 8.0495  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 3.2954  Validation loss = 8.0477  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 3.2946  Validation loss = 8.0461  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 3.2938  Validation loss = 8.0442  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 3.2926  Validation loss = 8.0419  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 3.2917  Validation loss = 8.0405  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 3.2906  Validation loss = 8.0385  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 3.2901  Validation loss = 8.0373  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 3.2892  Validation loss = 8.0358  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 3.2876  Validation loss = 8.0329  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 3.2866  Validation loss = 8.0310  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 3.2860  Validation loss = 8.0298  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 3.2852  Validation loss = 8.0283  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 3.2844  Validation loss = 8.0263  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 3.2839  Validation loss = 8.0251  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 3.2831  Validation loss = 8.0233  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 3.2825  Validation loss = 8.0218  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 3.2818  Validation loss = 8.0201  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 3.2811  Validation loss = 8.0182  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 3.2804  Validation loss = 8.0168  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 3.2799  Validation loss = 8.0156  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 3.2790  Validation loss = 8.0137  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 3.2782  Validation loss = 8.0120  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 3.2776  Validation loss = 8.0108  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 3.2770  Validation loss = 8.0094  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 3.2761  Validation loss = 8.0076  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 3.2756  Validation loss = 8.0065  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 3.2750  Validation loss = 8.0050  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 3.2745  Validation loss = 8.0040  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 3.2738  Validation loss = 8.0021  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 3.2732  Validation loss = 8.0008  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 3.2726  Validation loss = 7.9995  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 3.2720  Validation loss = 7.9981  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 3.2714  Validation loss = 7.9969  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 3.2707  Validation loss = 7.9950  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 3.2701  Validation loss = 7.9940  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 3.2695  Validation loss = 7.9928  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 3.2687  Validation loss = 7.9910  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 3.2682  Validation loss = 7.9899  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 3.2677  Validation loss = 7.9886  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 3.2670  Validation loss = 7.9871  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 3.2663  Validation loss = 7.9855  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 3.2658  Validation loss = 7.9844  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 3.2652  Validation loss = 7.9828  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 3.2646  Validation loss = 7.9817  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 3.2639  Validation loss = 7.9802  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 3.2632  Validation loss = 7.9786  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 3.2626  Validation loss = 7.9772  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 3.2619  Validation loss = 7.9758  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 3.2615  Validation loss = 7.9748  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 3.2608  Validation loss = 7.9733  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 3.2601  Validation loss = 7.9717  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 3.2593  Validation loss = 7.9700  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 3.2588  Validation loss = 7.9691  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 3.2582  Validation loss = 7.9677  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 3.2577  Validation loss = 7.9666  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 3.2571  Validation loss = 7.9654  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 3.2563  Validation loss = 7.9640  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 3.2556  Validation loss = 7.9625  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 3.2548  Validation loss = 7.9608  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 3.2541  Validation loss = 7.9595  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 3.2536  Validation loss = 7.9586  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 3.2529  Validation loss = 7.9568  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 3.2523  Validation loss = 7.9556  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 3.2516  Validation loss = 7.9541  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 3.2510  Validation loss = 7.9527  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 3.2504  Validation loss = 7.9515  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 3.2500  Validation loss = 7.9506  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 3.2492  Validation loss = 7.9487  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 3.2484  Validation loss = 7.9468  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 3.2477  Validation loss = 7.9454  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 3.2470  Validation loss = 7.9440  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 3.2463  Validation loss = 7.9426  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 3.2460  Validation loss = 7.9418  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 3.2455  Validation loss = 7.9408  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 3.2450  Validation loss = 7.9393  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 3.2443  Validation loss = 7.9381  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 3.2436  Validation loss = 7.9365  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 3.2431  Validation loss = 7.9353  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 3.2425  Validation loss = 7.9337  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 3.2420  Validation loss = 7.9326  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 3.2414  Validation loss = 7.9309  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 3.2407  Validation loss = 7.9295  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 3.2400  Validation loss = 7.9277  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 3.2395  Validation loss = 7.9266  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 3.2391  Validation loss = 7.9257  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 3.2383  Validation loss = 7.9241  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 3.2376  Validation loss = 7.9224  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 3.2370  Validation loss = 7.9212  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 3.2365  Validation loss = 7.9201  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 3.2359  Validation loss = 7.9185  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 3.2354  Validation loss = 7.9172  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 3.2350  Validation loss = 7.9162  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 3.2341  Validation loss = 7.9144  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 3.2336  Validation loss = 7.9130  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 3.2329  Validation loss = 7.9117  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 3.2324  Validation loss = 7.9104  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 3.2318  Validation loss = 7.9089  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 3.2311  Validation loss = 7.9075  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 3.2304  Validation loss = 7.9061  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 3.2297  Validation loss = 7.9039  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 3.2292  Validation loss = 7.9028  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 3.2286  Validation loss = 7.9016  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 3.2280  Validation loss = 7.9000  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 3.2277  Validation loss = 7.8992  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 3.2271  Validation loss = 7.8974  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 3.2266  Validation loss = 7.8961  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 3.2259  Validation loss = 7.8947  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 3.2252  Validation loss = 7.8932  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 3.2244  Validation loss = 7.8913  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 3.2237  Validation loss = 7.8899  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 3.2230  Validation loss = 7.8881  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 3.2222  Validation loss = 7.8864  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 3.2217  Validation loss = 7.8856  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 3.2209  Validation loss = 7.8836  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 3.2206  Validation loss = 7.8830  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 3.2199  Validation loss = 7.8816  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 3.2191  Validation loss = 7.8796  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 3.2185  Validation loss = 7.8785  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 3.2179  Validation loss = 7.8771  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 3.2174  Validation loss = 7.8758  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 3.2166  Validation loss = 7.8740  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 3.2160  Validation loss = 7.8727  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 3.2155  Validation loss = 7.8715  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 3.2151  Validation loss = 7.8706  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 3.2143  Validation loss = 7.8687  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 3.2138  Validation loss = 7.8678  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 3.2134  Validation loss = 7.8668  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 3.2130  Validation loss = 7.8659  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 3.2122  Validation loss = 7.8644  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 3.2118  Validation loss = 7.8631  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 3.2112  Validation loss = 7.8619  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 3.2106  Validation loss = 7.8606  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 3.2100  Validation loss = 7.8592  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 3.2095  Validation loss = 7.8583  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 3.2090  Validation loss = 7.8571  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 3.2086  Validation loss = 7.8564  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 3.2081  Validation loss = 7.8551  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 3.2075  Validation loss = 7.8537  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 3.2069  Validation loss = 7.8526  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 3.2064  Validation loss = 7.8515  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 3.2058  Validation loss = 7.8503  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 3.2051  Validation loss = 7.8487  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 3.2046  Validation loss = 7.8475  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 3.2043  Validation loss = 7.8468  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 3.2036  Validation loss = 7.8453  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 3.2033  Validation loss = 7.8445  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 3.2027  Validation loss = 7.8430  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 3.2022  Validation loss = 7.8417  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 3.2016  Validation loss = 7.8400  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 3.2008  Validation loss = 7.8381  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 3.2001  Validation loss = 7.8368  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 3.1994  Validation loss = 7.8350  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 3.1988  Validation loss = 7.8339  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 3.1983  Validation loss = 7.8324  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 3.1978  Validation loss = 7.8314  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 3.1972  Validation loss = 7.8301  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 3.1967  Validation loss = 7.8290  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 3.1961  Validation loss = 7.8275  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 3.1956  Validation loss = 7.8264  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 3.1949  Validation loss = 7.8249  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 3.1945  Validation loss = 7.8240  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 3.1938  Validation loss = 7.8223  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 3.1933  Validation loss = 7.8209  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 3.1926  Validation loss = 7.8195  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 3.1922  Validation loss = 7.8186  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 3.1916  Validation loss = 7.8173  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 3.1912  Validation loss = 7.8160  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 3.1907  Validation loss = 7.8149  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 3.1903  Validation loss = 7.8138  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 3.1896  Validation loss = 7.8123  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 3.1890  Validation loss = 7.8110  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 3.1884  Validation loss = 7.8097  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 3.1881  Validation loss = 7.8090  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 3.1876  Validation loss = 7.8074  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 3.1871  Validation loss = 7.8063  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 3.1865  Validation loss = 7.8047  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 3.1860  Validation loss = 7.8036  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 3.1854  Validation loss = 7.8025  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 3.1851  Validation loss = 7.8019  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 3.1845  Validation loss = 7.8006  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 3.1839  Validation loss = 7.7994  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 3.1835  Validation loss = 7.7982  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 3.1829  Validation loss = 7.7970  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 3.1822  Validation loss = 7.7954  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 3.1817  Validation loss = 7.7943  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 3.1811  Validation loss = 7.7930  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 3.1806  Validation loss = 7.7920  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 3.1800  Validation loss = 7.7906  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 3.1794  Validation loss = 7.7889  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 3.1789  Validation loss = 7.7876  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 3.1784  Validation loss = 7.7863  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 3.1779  Validation loss = 7.7850  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 3.1775  Validation loss = 7.7842  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 3.1769  Validation loss = 7.7826  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 3.1765  Validation loss = 7.7817  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 3.1759  Validation loss = 7.7804  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 3.1754  Validation loss = 7.7792  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 3.1751  Validation loss = 7.7784  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 3.1744  Validation loss = 7.7770  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 3.1736  Validation loss = 7.7752  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 3.1732  Validation loss = 7.7741  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 3.1727  Validation loss = 7.7730  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 3.1723  Validation loss = 7.7720  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 3.1718  Validation loss = 7.7705  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 3.1714  Validation loss = 7.7697  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 3.1708  Validation loss = 7.7684  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 3.1703  Validation loss = 7.7669  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 3.1695  Validation loss = 7.7651  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 3.1689  Validation loss = 7.7640  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 3.1684  Validation loss = 7.7630  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 3.1676  Validation loss = 7.7613  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 3.1674  Validation loss = 7.7607  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 3.1668  Validation loss = 7.7595  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 3.1661  Validation loss = 7.7582  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 3.1656  Validation loss = 7.7569  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 3.1652  Validation loss = 7.7563  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 3.1646  Validation loss = 7.7550  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 3.1641  Validation loss = 7.7539  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 3.1636  Validation loss = 7.7528  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 3.1631  Validation loss = 7.7518  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 3.1625  Validation loss = 7.7505  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 3.1618  Validation loss = 7.7486  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 3.1612  Validation loss = 7.7472  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 3.1607  Validation loss = 7.7462  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 3.1603  Validation loss = 7.7452  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 3.1597  Validation loss = 7.7440  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 3.1591  Validation loss = 7.7425  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 3.1586  Validation loss = 7.7416  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 3.1583  Validation loss = 7.7409  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 3.1578  Validation loss = 7.7397  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 3.1575  Validation loss = 7.7389  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 3.1570  Validation loss = 7.7376  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 3.1564  Validation loss = 7.7363  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 3.1559  Validation loss = 7.7351  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 3.1550  Validation loss = 7.7328  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 3.1542  Validation loss = 7.7307  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 3.1535  Validation loss = 7.7294  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 3.1529  Validation loss = 7.7277  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 3.1523  Validation loss = 7.7264  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 3.1519  Validation loss = 7.7254  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 3.1514  Validation loss = 7.7242  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 3.1509  Validation loss = 7.7229  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 3.1504  Validation loss = 7.7219  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 3.1497  Validation loss = 7.7201  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 3.1492  Validation loss = 7.7192  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 3.1485  Validation loss = 7.7171  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 3.1479  Validation loss = 7.7157  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 3.1472  Validation loss = 7.7143  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 3.1464  Validation loss = 7.7125  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 3.1458  Validation loss = 7.7110  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 3.1452  Validation loss = 7.7095  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 3.1446  Validation loss = 7.7082  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 3.1441  Validation loss = 7.7067  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 3.1436  Validation loss = 7.7058  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 3.1432  Validation loss = 7.7047  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 3.1425  Validation loss = 7.7034  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 3.1421  Validation loss = 7.7024  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 3.1417  Validation loss = 7.7015  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 3.1411  Validation loss = 7.7000  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 3.1406  Validation loss = 7.6988  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 3.1402  Validation loss = 7.6975  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 3.1396  Validation loss = 7.6962  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 3.1391  Validation loss = 7.6951  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 3.1386  Validation loss = 7.6938  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 3.1382  Validation loss = 7.6930  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 3.1380  Validation loss = 7.6924  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 3.1373  Validation loss = 7.6907  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 3.1369  Validation loss = 7.6895  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 3.1364  Validation loss = 7.6887  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 3.1359  Validation loss = 7.6877  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 3.1356  Validation loss = 7.6871  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 3.1351  Validation loss = 7.6857  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 3.1345  Validation loss = 7.6844  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 3.1340  Validation loss = 7.6832  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 3.1335  Validation loss = 7.6816  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 3.1329  Validation loss = 7.6800  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 3.1321  Validation loss = 7.6782  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 3.1315  Validation loss = 7.6765  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 3.1312  Validation loss = 7.6757  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 3.1308  Validation loss = 7.6748  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 3.1303  Validation loss = 7.6735  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 3.1296  Validation loss = 7.6718  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 3.1290  Validation loss = 7.6705  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 3.1282  Validation loss = 7.6684  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 3.1276  Validation loss = 7.6669  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 3.1272  Validation loss = 7.6659  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 3.1266  Validation loss = 7.6645  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 3.1261  Validation loss = 7.6633  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 3.1258  Validation loss = 7.6624  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 3.1253  Validation loss = 7.6613  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 3.1247  Validation loss = 7.6598  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 3.1243  Validation loss = 7.6589  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 3.1240  Validation loss = 7.6583  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 3.1235  Validation loss = 7.6571  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 3.1233  Validation loss = 7.6565  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 3.1227  Validation loss = 7.6550  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 3.1222  Validation loss = 7.6538  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 3.1217  Validation loss = 7.6526  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 3.1213  Validation loss = 7.6518  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 3.1210  Validation loss = 7.6509  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 3.1205  Validation loss = 7.6498  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 3.1201  Validation loss = 7.6490  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 3.1194  Validation loss = 7.6472  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 3.1188  Validation loss = 7.6453  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 3.1183  Validation loss = 7.6440  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 3.1175  Validation loss = 7.6424  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 3.1171  Validation loss = 7.6416  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 3.1167  Validation loss = 7.6406  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 3.1163  Validation loss = 7.6397  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 3.1156  Validation loss = 7.6380  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 3.1152  Validation loss = 7.6371  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 3.1147  Validation loss = 7.6360  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 3.1143  Validation loss = 7.6347  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 3.1137  Validation loss = 7.6335  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 3.1131  Validation loss = 7.6321  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 3.1126  Validation loss = 7.6308  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 3.1121  Validation loss = 7.6296  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 3.1115  Validation loss = 7.6281  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 3.1110  Validation loss = 7.6271  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 3.1105  Validation loss = 7.6258  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 3.1100  Validation loss = 7.6246  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 3.1093  Validation loss = 7.6230  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 3.1089  Validation loss = 7.6224  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 3.1083  Validation loss = 7.6209  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 3.1079  Validation loss = 7.6198  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 3.1075  Validation loss = 7.6188  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 3.1068  Validation loss = 7.6171  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 3.1063  Validation loss = 7.6157  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 3.1057  Validation loss = 7.6145  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 3.1051  Validation loss = 7.6132  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 3.1047  Validation loss = 7.6119  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 3.1043  Validation loss = 7.6110  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 3.1039  Validation loss = 7.6100  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 3.1033  Validation loss = 7.6086  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 3.1029  Validation loss = 7.6075  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 3.1025  Validation loss = 7.6062  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 3.1021  Validation loss = 7.6049  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 3.1016  Validation loss = 7.6040  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 3.1011  Validation loss = 7.6032  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 3.1007  Validation loss = 7.6021  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 3.1004  Validation loss = 7.6012  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 3.0999  Validation loss = 7.6002  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 3.0991  Validation loss = 7.5986  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 3.0988  Validation loss = 7.5977  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 3.0983  Validation loss = 7.5967  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 3.0979  Validation loss = 7.5954  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 3.0973  Validation loss = 7.5938  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 3.0969  Validation loss = 7.5929  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 3.0965  Validation loss = 7.5922  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 3.0960  Validation loss = 7.5906  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 3.0955  Validation loss = 7.5896  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 3.0950  Validation loss = 7.5882  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 3.0947  Validation loss = 7.5875  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 3.0943  Validation loss = 7.5868  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 3.0939  Validation loss = 7.5856  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 3.0933  Validation loss = 7.5844  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 3.0927  Validation loss = 7.5827  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 3.0923  Validation loss = 7.5816  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 3.0918  Validation loss = 7.5804  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 3.0913  Validation loss = 7.5793  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 3.0908  Validation loss = 7.5778  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 3.0903  Validation loss = 7.5763  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 3.0896  Validation loss = 7.5747  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 3.0892  Validation loss = 7.5736  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 3.0885  Validation loss = 7.5720  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 3.0877  Validation loss = 7.5702  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 3.0875  Validation loss = 7.5696  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 3.0873  Validation loss = 7.5688  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 3.0868  Validation loss = 7.5673  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 3.0863  Validation loss = 7.5662  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 3.0857  Validation loss = 7.5649  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 3.0853  Validation loss = 7.5639  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 3.0848  Validation loss = 7.5626  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 3.0843  Validation loss = 7.5614  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 3.0839  Validation loss = 7.5604  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 3.0835  Validation loss = 7.5593  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 3.0831  Validation loss = 7.5584  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 3.0825  Validation loss = 7.5569  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 3.0820  Validation loss = 7.5557  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 3.0815  Validation loss = 7.5546  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 3.0810  Validation loss = 7.5531  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 3.0804  Validation loss = 7.5519  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 3.0799  Validation loss = 7.5508  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 3.0794  Validation loss = 7.5496  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 3.0789  Validation loss = 7.5482  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 3.0784  Validation loss = 7.5470  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 3.0781  Validation loss = 7.5460  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 3.0778  Validation loss = 7.5453  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 3.0771  Validation loss = 7.5438  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 3.0765  Validation loss = 7.5420  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 3.0761  Validation loss = 7.5411  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 3.0756  Validation loss = 7.5399  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 3.0751  Validation loss = 7.5388  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 3.0748  Validation loss = 7.5379  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 3.0744  Validation loss = 7.5371  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 3.0738  Validation loss = 7.5349  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 3.0735  Validation loss = 7.5344  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 3.0733  Validation loss = 7.5338  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 3.0730  Validation loss = 7.5332  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 3.0727  Validation loss = 7.5323  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 3.0723  Validation loss = 7.5313  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 3.0720  Validation loss = 7.5304  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 3.0714  Validation loss = 7.5290  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 3.0712  Validation loss = 7.5283  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 3.0705  Validation loss = 7.5265  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 3.0700  Validation loss = 7.5252  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 3.0694  Validation loss = 7.5238  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 3.0690  Validation loss = 7.5225  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 3.0685  Validation loss = 7.5214  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 3.0678  Validation loss = 7.5196  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 3.0675  Validation loss = 7.5185  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 3.0671  Validation loss = 7.5177  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 3.0667  Validation loss = 7.5167  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 3.0660  Validation loss = 7.5152  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 3.0656  Validation loss = 7.5142  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 3.0653  Validation loss = 7.5133  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 3.0647  Validation loss = 7.5120  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 3.0644  Validation loss = 7.5112  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 3.0639  Validation loss = 7.5100  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 3.0634  Validation loss = 7.5087  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 3.0629  Validation loss = 7.5077  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 3.0624  Validation loss = 7.5062  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 3.0621  Validation loss = 7.5055  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 3.0617  Validation loss = 7.5047  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 3.0614  Validation loss = 7.5038  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 3.0608  Validation loss = 7.5021  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 3.0602  Validation loss = 7.5008  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 3.0598  Validation loss = 7.4998  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 3.0596  Validation loss = 7.4994  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 3.0592  Validation loss = 7.4983  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 3.0588  Validation loss = 7.4974  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 3.0583  Validation loss = 7.4961  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 3.0577  Validation loss = 7.4947  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 3.0575  Validation loss = 7.4941  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 3.0571  Validation loss = 7.4931  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 3.0568  Validation loss = 7.4926  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 3.0563  Validation loss = 7.4911  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 3.0558  Validation loss = 7.4901  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 3.0554  Validation loss = 7.4888  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 3.0550  Validation loss = 7.4877  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 3.0546  Validation loss = 7.4866  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 3.0540  Validation loss = 7.4849  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 3.0535  Validation loss = 7.4834  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 3.0530  Validation loss = 7.4822  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 3.0522  Validation loss = 7.4804  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 3.0510  Validation loss = 7.4782  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 3.0504  Validation loss = 7.4774  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 3.0491  Validation loss = 7.4757  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 3.0472  Validation loss = 7.4731  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 3.0466  Validation loss = 7.4717  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 3.0460  Validation loss = 7.4704  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 3.0452  Validation loss = 7.4686  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 3.0449  Validation loss = 7.4680  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 3.0446  Validation loss = 7.4672  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 3.0440  Validation loss = 7.4656  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 3.0435  Validation loss = 7.4644  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 3.0431  Validation loss = 7.4632  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 3.0426  Validation loss = 7.4618  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 3.0422  Validation loss = 7.4610  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 3.0418  Validation loss = 7.4599  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 3.0414  Validation loss = 7.4586  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 3.0409  Validation loss = 7.4574  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 3.0404  Validation loss = 7.4565  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 3.0400  Validation loss = 7.4555  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 3.0397  Validation loss = 7.4544  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 3.0393  Validation loss = 7.4534  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 3.0390  Validation loss = 7.4527  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 3.0386  Validation loss = 7.4514  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 3.0382  Validation loss = 7.4503  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 3.0376  Validation loss = 7.4491  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 3.0370  Validation loss = 7.4474  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 3.0364  Validation loss = 7.4462  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 3.0358  Validation loss = 7.4449  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 3.0353  Validation loss = 7.4436  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 3.0350  Validation loss = 7.4425  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 3.0345  Validation loss = 7.4414  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 3.0341  Validation loss = 7.4407  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 3.0337  Validation loss = 7.4399  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 3.0334  Validation loss = 7.4391  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 3.0330  Validation loss = 7.4382  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 3.0326  Validation loss = 7.4371  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 3.0321  Validation loss = 7.4360  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 3.0317  Validation loss = 7.4349  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 3.0313  Validation loss = 7.4337  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 3.0309  Validation loss = 7.4326  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 3.0305  Validation loss = 7.4316  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 3.0300  Validation loss = 7.4302  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 3.0295  Validation loss = 7.4291  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 3.0291  Validation loss = 7.4280  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 3.5022  Validation loss = 5.2472  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 3.5016  Validation loss = 5.2463  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 3.5009  Validation loss = 5.2453  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 3.5002  Validation loss = 5.2443  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 3.4994  Validation loss = 5.2431  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 3.4985  Validation loss = 5.2418  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 3.4975  Validation loss = 5.2406  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 3.4968  Validation loss = 5.2394  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 3.4959  Validation loss = 5.2381  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 3.4953  Validation loss = 5.2372  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 3.4946  Validation loss = 5.2361  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 3.4938  Validation loss = 5.2351  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 3.4930  Validation loss = 5.2339  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 3.4924  Validation loss = 5.2330  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 3.4918  Validation loss = 5.2321  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 3.4910  Validation loss = 5.2310  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 3.4902  Validation loss = 5.2297  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 3.4894  Validation loss = 5.2286  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 3.4885  Validation loss = 5.2274  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 3.4876  Validation loss = 5.2261  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 3.4871  Validation loss = 5.2253  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 3.4865  Validation loss = 5.2243  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 3.4855  Validation loss = 5.2228  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 3.4845  Validation loss = 5.2214  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 3.4838  Validation loss = 5.2204  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 3.4834  Validation loss = 5.2197  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 3.4826  Validation loss = 5.2186  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 3.4818  Validation loss = 5.2175  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 3.4812  Validation loss = 5.2167  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 3.4807  Validation loss = 5.2158  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 3.4800  Validation loss = 5.2148  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 3.4794  Validation loss = 5.2139  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 3.4786  Validation loss = 5.2128  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 3.4780  Validation loss = 5.2120  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 3.4771  Validation loss = 5.2107  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 3.4765  Validation loss = 5.2098  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 3.4755  Validation loss = 5.2084  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 3.4746  Validation loss = 5.2071  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 3.4741  Validation loss = 5.2065  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 3.4735  Validation loss = 5.2055  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 3.4731  Validation loss = 5.2049  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 3.4722  Validation loss = 5.2036  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 3.4711  Validation loss = 5.2021  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 3.4703  Validation loss = 5.2008  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 3.4696  Validation loss = 5.1998  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 3.4687  Validation loss = 5.1985  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 3.4678  Validation loss = 5.1971  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 3.4671  Validation loss = 5.1960  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 3.4662  Validation loss = 5.1948  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 3.4656  Validation loss = 5.1940  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 3.4648  Validation loss = 5.1927  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 3.4642  Validation loss = 5.1919  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 3.4635  Validation loss = 5.1908  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 3.4630  Validation loss = 5.1900  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 3.4623  Validation loss = 5.1890  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 3.4615  Validation loss = 5.1877  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 3.4609  Validation loss = 5.1869  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 3.4602  Validation loss = 5.1857  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 3.4595  Validation loss = 5.1848  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 3.4590  Validation loss = 5.1840  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 3.4582  Validation loss = 5.1828  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 3.4574  Validation loss = 5.1816  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 3.4567  Validation loss = 5.1806  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 3.4559  Validation loss = 5.1795  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 3.4552  Validation loss = 5.1785  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 3.4546  Validation loss = 5.1776  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 3.4538  Validation loss = 5.1765  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 3.4529  Validation loss = 5.1752  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 3.4522  Validation loss = 5.1741  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 3.4517  Validation loss = 5.1734  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 3.4511  Validation loss = 5.1725  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 3.4503  Validation loss = 5.1713  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 3.4495  Validation loss = 5.1703  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 3.4491  Validation loss = 5.1695  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 3.4485  Validation loss = 5.1686  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 3.4476  Validation loss = 5.1673  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 3.4466  Validation loss = 5.1659  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 3.4454  Validation loss = 5.1642  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 3.4447  Validation loss = 5.1631  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 3.4437  Validation loss = 5.1616  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 3.4430  Validation loss = 5.1606  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 3.4421  Validation loss = 5.1594  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 3.4416  Validation loss = 5.1585  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 3.4409  Validation loss = 5.1575  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 3.4398  Validation loss = 5.1559  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 3.4391  Validation loss = 5.1549  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 3.4383  Validation loss = 5.1536  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 3.4374  Validation loss = 5.1523  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 3.4363  Validation loss = 5.1506  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 3.4352  Validation loss = 5.1491  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 3.4347  Validation loss = 5.1484  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 3.4342  Validation loss = 5.1476  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 3.4337  Validation loss = 5.1469  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 3.4330  Validation loss = 5.1457  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 3.4323  Validation loss = 5.1447  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 3.4316  Validation loss = 5.1435  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 3.4308  Validation loss = 5.1422  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 3.4301  Validation loss = 5.1412  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 3.4292  Validation loss = 5.1399  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 3.4286  Validation loss = 5.1390  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 3.4280  Validation loss = 5.1382  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 3.4273  Validation loss = 5.1372  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 3.4265  Validation loss = 5.1359  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 3.4256  Validation loss = 5.1346  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 3.4248  Validation loss = 5.1334  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 3.4239  Validation loss = 5.1320  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 3.4230  Validation loss = 5.1308  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 3.4224  Validation loss = 5.1298  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 3.4215  Validation loss = 5.1286  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 3.4208  Validation loss = 5.1275  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 3.4199  Validation loss = 5.1261  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 3.4192  Validation loss = 5.1251  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 3.4184  Validation loss = 5.1239  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 3.4177  Validation loss = 5.1227  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 3.4168  Validation loss = 5.1214  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 3.4160  Validation loss = 5.1203  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 3.4151  Validation loss = 5.1190  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 3.4140  Validation loss = 5.1173  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 3.4132  Validation loss = 5.1161  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 3.4124  Validation loss = 5.1148  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 3.4118  Validation loss = 5.1139  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 3.4109  Validation loss = 5.1126  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 3.4105  Validation loss = 5.1121  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 3.4098  Validation loss = 5.1110  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 3.4091  Validation loss = 5.1100  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 3.4087  Validation loss = 5.1094  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 3.4078  Validation loss = 5.1080  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 3.4067  Validation loss = 5.1065  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 3.4059  Validation loss = 5.1054  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 3.4054  Validation loss = 5.1046  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 3.4046  Validation loss = 5.1034  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 3.4039  Validation loss = 5.1023  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 3.4035  Validation loss = 5.1017  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 3.4027  Validation loss = 5.1005  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 3.4021  Validation loss = 5.0995  \n",
      "\n",
      "Fold: 16  Epoch: 136  Training loss = 3.4013  Validation loss = 5.0984  \n",
      "\n",
      "Fold: 16  Epoch: 137  Training loss = 3.4005  Validation loss = 5.0972  \n",
      "\n",
      "Fold: 16  Epoch: 138  Training loss = 3.3995  Validation loss = 5.0958  \n",
      "\n",
      "Fold: 16  Epoch: 139  Training loss = 3.3987  Validation loss = 5.0947  \n",
      "\n",
      "Fold: 16  Epoch: 140  Training loss = 3.3980  Validation loss = 5.0936  \n",
      "\n",
      "Fold: 16  Epoch: 141  Training loss = 3.3972  Validation loss = 5.0924  \n",
      "\n",
      "Fold: 16  Epoch: 142  Training loss = 3.3967  Validation loss = 5.0917  \n",
      "\n",
      "Fold: 16  Epoch: 143  Training loss = 3.3960  Validation loss = 5.0907  \n",
      "\n",
      "Fold: 16  Epoch: 144  Training loss = 3.3953  Validation loss = 5.0897  \n",
      "\n",
      "Fold: 16  Epoch: 145  Training loss = 3.3948  Validation loss = 5.0891  \n",
      "\n",
      "Fold: 16  Epoch: 146  Training loss = 3.3941  Validation loss = 5.0881  \n",
      "\n",
      "Fold: 16  Epoch: 147  Training loss = 3.3936  Validation loss = 5.0874  \n",
      "\n",
      "Fold: 16  Epoch: 148  Training loss = 3.3927  Validation loss = 5.0862  \n",
      "\n",
      "Fold: 16  Epoch: 149  Training loss = 3.3918  Validation loss = 5.0851  \n",
      "\n",
      "Fold: 16  Epoch: 150  Training loss = 3.3907  Validation loss = 5.0838  \n",
      "\n",
      "Fold: 16  Epoch: 151  Training loss = 3.3899  Validation loss = 5.0828  \n",
      "\n",
      "Fold: 16  Epoch: 152  Training loss = 3.3890  Validation loss = 5.0819  \n",
      "\n",
      "Fold: 16  Epoch: 153  Training loss = 3.3884  Validation loss = 5.0811  \n",
      "\n",
      "Fold: 16  Epoch: 154  Training loss = 3.3879  Validation loss = 5.0805  \n",
      "\n",
      "Fold: 16  Epoch: 155  Training loss = 3.3871  Validation loss = 5.0793  \n",
      "\n",
      "Fold: 16  Epoch: 156  Training loss = 3.3863  Validation loss = 5.0781  \n",
      "\n",
      "Fold: 16  Epoch: 157  Training loss = 3.3854  Validation loss = 5.0768  \n",
      "\n",
      "Fold: 16  Epoch: 158  Training loss = 3.3847  Validation loss = 5.0758  \n",
      "\n",
      "Fold: 16  Epoch: 159  Training loss = 3.3837  Validation loss = 5.0743  \n",
      "\n",
      "Fold: 16  Epoch: 160  Training loss = 3.3833  Validation loss = 5.0737  \n",
      "\n",
      "Fold: 16  Epoch: 161  Training loss = 3.3828  Validation loss = 5.0729  \n",
      "\n",
      "Fold: 16  Epoch: 162  Training loss = 3.3822  Validation loss = 5.0721  \n",
      "\n",
      "Fold: 16  Epoch: 163  Training loss = 3.3816  Validation loss = 5.0712  \n",
      "\n",
      "Fold: 16  Epoch: 164  Training loss = 3.3807  Validation loss = 5.0700  \n",
      "\n",
      "Fold: 16  Epoch: 165  Training loss = 3.3798  Validation loss = 5.0686  \n",
      "\n",
      "Fold: 16  Epoch: 166  Training loss = 3.3793  Validation loss = 5.0678  \n",
      "\n",
      "Fold: 16  Epoch: 167  Training loss = 3.3786  Validation loss = 5.0669  \n",
      "\n",
      "Fold: 16  Epoch: 168  Training loss = 3.3779  Validation loss = 5.0657  \n",
      "\n",
      "Fold: 16  Epoch: 169  Training loss = 3.3771  Validation loss = 5.0645  \n",
      "\n",
      "Fold: 16  Epoch: 170  Training loss = 3.3766  Validation loss = 5.0638  \n",
      "\n",
      "Fold: 16  Epoch: 171  Training loss = 3.3754  Validation loss = 5.0620  \n",
      "\n",
      "Fold: 16  Epoch: 172  Training loss = 3.3746  Validation loss = 5.0606  \n",
      "\n",
      "Fold: 16  Epoch: 173  Training loss = 3.3740  Validation loss = 5.0598  \n",
      "\n",
      "Fold: 16  Epoch: 174  Training loss = 3.3733  Validation loss = 5.0588  \n",
      "\n",
      "Fold: 16  Epoch: 175  Training loss = 3.3728  Validation loss = 5.0580  \n",
      "\n",
      "Fold: 16  Epoch: 176  Training loss = 3.3721  Validation loss = 5.0572  \n",
      "\n",
      "Fold: 16  Epoch: 177  Training loss = 3.3716  Validation loss = 5.0563  \n",
      "\n",
      "Fold: 16  Epoch: 178  Training loss = 3.3710  Validation loss = 5.0553  \n",
      "\n",
      "Fold: 16  Epoch: 179  Training loss = 3.3705  Validation loss = 5.0545  \n",
      "\n",
      "Fold: 16  Epoch: 180  Training loss = 3.3700  Validation loss = 5.0538  \n",
      "\n",
      "Fold: 16  Epoch: 181  Training loss = 3.3692  Validation loss = 5.0526  \n",
      "\n",
      "Fold: 16  Epoch: 182  Training loss = 3.3686  Validation loss = 5.0518  \n",
      "\n",
      "Fold: 16  Epoch: 183  Training loss = 3.3680  Validation loss = 5.0509  \n",
      "\n",
      "Fold: 16  Epoch: 184  Training loss = 3.3674  Validation loss = 5.0500  \n",
      "\n",
      "Fold: 16  Epoch: 185  Training loss = 3.3667  Validation loss = 5.0489  \n",
      "\n",
      "Fold: 16  Epoch: 186  Training loss = 3.3659  Validation loss = 5.0478  \n",
      "\n",
      "Fold: 16  Epoch: 187  Training loss = 3.3653  Validation loss = 5.0469  \n",
      "\n",
      "Fold: 16  Epoch: 188  Training loss = 3.3647  Validation loss = 5.0460  \n",
      "\n",
      "Fold: 16  Epoch: 189  Training loss = 3.3643  Validation loss = 5.0453  \n",
      "\n",
      "Fold: 16  Epoch: 190  Training loss = 3.3640  Validation loss = 5.0448  \n",
      "\n",
      "Fold: 16  Epoch: 191  Training loss = 3.3632  Validation loss = 5.0437  \n",
      "\n",
      "Fold: 16  Epoch: 192  Training loss = 3.3623  Validation loss = 5.0424  \n",
      "\n",
      "Fold: 16  Epoch: 193  Training loss = 3.3617  Validation loss = 5.0415  \n",
      "\n",
      "Fold: 16  Epoch: 194  Training loss = 3.3608  Validation loss = 5.0401  \n",
      "\n",
      "Fold: 16  Epoch: 195  Training loss = 3.3603  Validation loss = 5.0393  \n",
      "\n",
      "Fold: 16  Epoch: 196  Training loss = 3.3596  Validation loss = 5.0382  \n",
      "\n",
      "Fold: 16  Epoch: 197  Training loss = 3.3588  Validation loss = 5.0370  \n",
      "\n",
      "Fold: 16  Epoch: 198  Training loss = 3.3580  Validation loss = 5.0358  \n",
      "\n",
      "Fold: 16  Epoch: 199  Training loss = 3.3576  Validation loss = 5.0352  \n",
      "\n",
      "Fold: 16  Epoch: 200  Training loss = 3.3569  Validation loss = 5.0342  \n",
      "\n",
      "Fold: 16  Epoch: 201  Training loss = 3.3564  Validation loss = 5.0335  \n",
      "\n",
      "Fold: 16  Epoch: 202  Training loss = 3.3556  Validation loss = 5.0323  \n",
      "\n",
      "Fold: 16  Epoch: 203  Training loss = 3.3551  Validation loss = 5.0315  \n",
      "\n",
      "Fold: 16  Epoch: 204  Training loss = 3.3547  Validation loss = 5.0310  \n",
      "\n",
      "Fold: 16  Epoch: 205  Training loss = 3.3540  Validation loss = 5.0300  \n",
      "\n",
      "Fold: 16  Epoch: 206  Training loss = 3.3533  Validation loss = 5.0290  \n",
      "\n",
      "Fold: 16  Epoch: 207  Training loss = 3.3524  Validation loss = 5.0276  \n",
      "\n",
      "Fold: 16  Epoch: 208  Training loss = 3.3518  Validation loss = 5.0268  \n",
      "\n",
      "Fold: 16  Epoch: 209  Training loss = 3.3510  Validation loss = 5.0257  \n",
      "\n",
      "Fold: 16  Epoch: 210  Training loss = 3.3502  Validation loss = 5.0245  \n",
      "\n",
      "Fold: 16  Epoch: 211  Training loss = 3.3495  Validation loss = 5.0234  \n",
      "\n",
      "Fold: 16  Epoch: 212  Training loss = 3.3491  Validation loss = 5.0228  \n",
      "\n",
      "Fold: 16  Epoch: 213  Training loss = 3.3483  Validation loss = 5.0217  \n",
      "\n",
      "Fold: 16  Epoch: 214  Training loss = 3.3475  Validation loss = 5.0205  \n",
      "\n",
      "Fold: 16  Epoch: 215  Training loss = 3.3467  Validation loss = 5.0194  \n",
      "\n",
      "Fold: 16  Epoch: 216  Training loss = 3.3460  Validation loss = 5.0186  \n",
      "\n",
      "Fold: 16  Epoch: 217  Training loss = 3.3451  Validation loss = 5.0173  \n",
      "\n",
      "Fold: 16  Epoch: 218  Training loss = 3.3444  Validation loss = 5.0164  \n",
      "\n",
      "Fold: 16  Epoch: 219  Training loss = 3.3428  Validation loss = 5.0145  \n",
      "\n",
      "Fold: 16  Epoch: 220  Training loss = 3.3416  Validation loss = 5.0130  \n",
      "\n",
      "Fold: 16  Epoch: 221  Training loss = 3.3411  Validation loss = 5.0123  \n",
      "\n",
      "Fold: 16  Epoch: 222  Training loss = 3.3405  Validation loss = 5.0114  \n",
      "\n",
      "Fold: 16  Epoch: 223  Training loss = 3.3395  Validation loss = 5.0102  \n",
      "\n",
      "Fold: 16  Epoch: 224  Training loss = 3.3385  Validation loss = 5.0087  \n",
      "\n",
      "Fold: 16  Epoch: 225  Training loss = 3.3380  Validation loss = 5.0079  \n",
      "\n",
      "Fold: 16  Epoch: 226  Training loss = 3.3372  Validation loss = 5.0068  \n",
      "\n",
      "Fold: 16  Epoch: 227  Training loss = 3.3362  Validation loss = 5.0054  \n",
      "\n",
      "Fold: 16  Epoch: 228  Training loss = 3.3357  Validation loss = 5.0047  \n",
      "\n",
      "Fold: 16  Epoch: 229  Training loss = 3.3352  Validation loss = 5.0039  \n",
      "\n",
      "Fold: 16  Epoch: 230  Training loss = 3.3345  Validation loss = 5.0028  \n",
      "\n",
      "Fold: 16  Epoch: 231  Training loss = 3.3337  Validation loss = 5.0016  \n",
      "\n",
      "Fold: 16  Epoch: 232  Training loss = 3.3330  Validation loss = 5.0005  \n",
      "\n",
      "Fold: 16  Epoch: 233  Training loss = 3.3324  Validation loss = 4.9996  \n",
      "\n",
      "Fold: 16  Epoch: 234  Training loss = 3.3316  Validation loss = 4.9984  \n",
      "\n",
      "Fold: 16  Epoch: 235  Training loss = 3.3309  Validation loss = 4.9975  \n",
      "\n",
      "Fold: 16  Epoch: 236  Training loss = 3.3300  Validation loss = 4.9961  \n",
      "\n",
      "Fold: 16  Epoch: 237  Training loss = 3.3295  Validation loss = 4.9953  \n",
      "\n",
      "Fold: 16  Epoch: 238  Training loss = 3.3289  Validation loss = 4.9944  \n",
      "\n",
      "Fold: 16  Epoch: 239  Training loss = 3.3286  Validation loss = 4.9938  \n",
      "\n",
      "Fold: 16  Epoch: 240  Training loss = 3.3279  Validation loss = 4.9928  \n",
      "\n",
      "Fold: 16  Epoch: 241  Training loss = 3.3271  Validation loss = 4.9916  \n",
      "\n",
      "Fold: 16  Epoch: 242  Training loss = 3.3265  Validation loss = 4.9906  \n",
      "\n",
      "Fold: 16  Epoch: 243  Training loss = 3.3262  Validation loss = 4.9901  \n",
      "\n",
      "Fold: 16  Epoch: 244  Training loss = 3.3254  Validation loss = 4.9890  \n",
      "\n",
      "Fold: 16  Epoch: 245  Training loss = 3.3249  Validation loss = 4.9882  \n",
      "\n",
      "Fold: 16  Epoch: 246  Training loss = 3.3242  Validation loss = 4.9871  \n",
      "\n",
      "Fold: 16  Epoch: 247  Training loss = 3.3236  Validation loss = 4.9861  \n",
      "\n",
      "Fold: 16  Epoch: 248  Training loss = 3.3232  Validation loss = 4.9856  \n",
      "\n",
      "Fold: 16  Epoch: 249  Training loss = 3.3227  Validation loss = 4.9848  \n",
      "\n",
      "Fold: 16  Epoch: 250  Training loss = 3.3220  Validation loss = 4.9836  \n",
      "\n",
      "Fold: 16  Epoch: 251  Training loss = 3.3213  Validation loss = 4.9825  \n",
      "\n",
      "Fold: 16  Epoch: 252  Training loss = 3.3206  Validation loss = 4.9815  \n",
      "\n",
      "Fold: 16  Epoch: 253  Training loss = 3.3200  Validation loss = 4.9806  \n",
      "\n",
      "Fold: 16  Epoch: 254  Training loss = 3.3195  Validation loss = 4.9797  \n",
      "\n",
      "Fold: 16  Epoch: 255  Training loss = 3.3189  Validation loss = 4.9789  \n",
      "\n",
      "Fold: 16  Epoch: 256  Training loss = 3.3183  Validation loss = 4.9778  \n",
      "\n",
      "Fold: 16  Epoch: 257  Training loss = 3.3176  Validation loss = 4.9769  \n",
      "\n",
      "Fold: 16  Epoch: 258  Training loss = 3.3170  Validation loss = 4.9759  \n",
      "\n",
      "Fold: 16  Epoch: 259  Training loss = 3.3164  Validation loss = 4.9749  \n",
      "\n",
      "Fold: 16  Epoch: 260  Training loss = 3.3158  Validation loss = 4.9739  \n",
      "\n",
      "Fold: 16  Epoch: 261  Training loss = 3.3152  Validation loss = 4.9730  \n",
      "\n",
      "Fold: 16  Epoch: 262  Training loss = 3.3148  Validation loss = 4.9725  \n",
      "\n",
      "Fold: 16  Epoch: 263  Training loss = 3.3142  Validation loss = 4.9716  \n",
      "\n",
      "Fold: 16  Epoch: 264  Training loss = 3.3136  Validation loss = 4.9706  \n",
      "\n",
      "Fold: 16  Epoch: 265  Training loss = 3.3130  Validation loss = 4.9698  \n",
      "\n",
      "Fold: 16  Epoch: 266  Training loss = 3.3124  Validation loss = 4.9688  \n",
      "\n",
      "Fold: 16  Epoch: 267  Training loss = 3.3121  Validation loss = 4.9683  \n",
      "\n",
      "Fold: 16  Epoch: 268  Training loss = 3.3113  Validation loss = 4.9671  \n",
      "\n",
      "Fold: 16  Epoch: 269  Training loss = 3.3107  Validation loss = 4.9661  \n",
      "\n",
      "Fold: 16  Epoch: 270  Training loss = 3.3102  Validation loss = 4.9652  \n",
      "\n",
      "Fold: 16  Epoch: 271  Training loss = 3.3093  Validation loss = 4.9640  \n",
      "\n",
      "Fold: 16  Epoch: 272  Training loss = 3.3088  Validation loss = 4.9634  \n",
      "\n",
      "Fold: 16  Epoch: 273  Training loss = 3.3081  Validation loss = 4.9622  \n",
      "\n",
      "Fold: 16  Epoch: 274  Training loss = 3.3076  Validation loss = 4.9615  \n",
      "\n",
      "Fold: 16  Epoch: 275  Training loss = 3.3071  Validation loss = 4.9608  \n",
      "\n",
      "Fold: 16  Epoch: 276  Training loss = 3.3065  Validation loss = 4.9598  \n",
      "\n",
      "Fold: 16  Epoch: 277  Training loss = 3.3059  Validation loss = 4.9588  \n",
      "\n",
      "Fold: 16  Epoch: 278  Training loss = 3.3055  Validation loss = 4.9580  \n",
      "\n",
      "Fold: 16  Epoch: 279  Training loss = 3.3051  Validation loss = 4.9574  \n",
      "\n",
      "Fold: 16  Epoch: 280  Training loss = 3.3048  Validation loss = 4.9569  \n",
      "\n",
      "Fold: 16  Epoch: 281  Training loss = 3.3041  Validation loss = 4.9557  \n",
      "\n",
      "Fold: 16  Epoch: 282  Training loss = 3.3036  Validation loss = 4.9550  \n",
      "\n",
      "Fold: 16  Epoch: 283  Training loss = 3.3031  Validation loss = 4.9543  \n",
      "\n",
      "Fold: 16  Epoch: 284  Training loss = 3.3026  Validation loss = 4.9535  \n",
      "\n",
      "Fold: 16  Epoch: 285  Training loss = 3.3020  Validation loss = 4.9525  \n",
      "\n",
      "Fold: 16  Epoch: 286  Training loss = 3.3013  Validation loss = 4.9516  \n",
      "\n",
      "Fold: 16  Epoch: 287  Training loss = 3.3007  Validation loss = 4.9506  \n",
      "\n",
      "Fold: 16  Epoch: 288  Training loss = 3.3001  Validation loss = 4.9497  \n",
      "\n",
      "Fold: 16  Epoch: 289  Training loss = 3.2994  Validation loss = 4.9485  \n",
      "\n",
      "Fold: 16  Epoch: 290  Training loss = 3.2990  Validation loss = 4.9478  \n",
      "\n",
      "Fold: 16  Epoch: 291  Training loss = 3.2984  Validation loss = 4.9467  \n",
      "\n",
      "Fold: 16  Epoch: 292  Training loss = 3.2979  Validation loss = 4.9461  \n",
      "\n",
      "Fold: 16  Epoch: 293  Training loss = 3.2973  Validation loss = 4.9450  \n",
      "\n",
      "Fold: 16  Epoch: 294  Training loss = 3.2968  Validation loss = 4.9443  \n",
      "\n",
      "Fold: 16  Epoch: 295  Training loss = 3.2961  Validation loss = 4.9433  \n",
      "\n",
      "Fold: 16  Epoch: 296  Training loss = 3.2949  Validation loss = 4.9416  \n",
      "\n",
      "Fold: 16  Epoch: 297  Training loss = 3.2943  Validation loss = 4.9406  \n",
      "\n",
      "Fold: 16  Epoch: 298  Training loss = 3.2937  Validation loss = 4.9397  \n",
      "\n",
      "Fold: 16  Epoch: 299  Training loss = 3.2931  Validation loss = 4.9388  \n",
      "\n",
      "Fold: 16  Epoch: 300  Training loss = 3.2926  Validation loss = 4.9380  \n",
      "\n",
      "Fold: 16  Epoch: 301  Training loss = 3.2922  Validation loss = 4.9374  \n",
      "\n",
      "Fold: 16  Epoch: 302  Training loss = 3.2916  Validation loss = 4.9365  \n",
      "\n",
      "Fold: 16  Epoch: 303  Training loss = 3.2908  Validation loss = 4.9352  \n",
      "\n",
      "Fold: 16  Epoch: 304  Training loss = 3.2902  Validation loss = 4.9343  \n",
      "\n",
      "Fold: 16  Epoch: 305  Training loss = 3.2896  Validation loss = 4.9334  \n",
      "\n",
      "Fold: 16  Epoch: 306  Training loss = 3.2891  Validation loss = 4.9327  \n",
      "\n",
      "Fold: 16  Epoch: 307  Training loss = 3.2885  Validation loss = 4.9317  \n",
      "\n",
      "Fold: 16  Epoch: 308  Training loss = 3.2880  Validation loss = 4.9310  \n",
      "\n",
      "Fold: 16  Epoch: 309  Training loss = 3.2877  Validation loss = 4.9304  \n",
      "\n",
      "Fold: 16  Epoch: 310  Training loss = 3.2869  Validation loss = 4.9293  \n",
      "\n",
      "Fold: 16  Epoch: 311  Training loss = 3.2864  Validation loss = 4.9285  \n",
      "\n",
      "Fold: 16  Epoch: 312  Training loss = 3.2856  Validation loss = 4.9273  \n",
      "\n",
      "Fold: 16  Epoch: 313  Training loss = 3.2852  Validation loss = 4.9266  \n",
      "\n",
      "Fold: 16  Epoch: 314  Training loss = 3.2845  Validation loss = 4.9257  \n",
      "\n",
      "Fold: 16  Epoch: 315  Training loss = 3.2841  Validation loss = 4.9250  \n",
      "\n",
      "Fold: 16  Epoch: 316  Training loss = 3.2835  Validation loss = 4.9241  \n",
      "\n",
      "Fold: 16  Epoch: 317  Training loss = 3.2829  Validation loss = 4.9232  \n",
      "\n",
      "Fold: 16  Epoch: 318  Training loss = 3.2823  Validation loss = 4.9223  \n",
      "\n",
      "Fold: 16  Epoch: 319  Training loss = 3.2817  Validation loss = 4.9214  \n",
      "\n",
      "Fold: 16  Epoch: 320  Training loss = 3.2810  Validation loss = 4.9203  \n",
      "\n",
      "Fold: 16  Epoch: 321  Training loss = 3.2804  Validation loss = 4.9194  \n",
      "\n",
      "Fold: 16  Epoch: 322  Training loss = 3.2797  Validation loss = 4.9184  \n",
      "\n",
      "Fold: 16  Epoch: 323  Training loss = 3.2793  Validation loss = 4.9178  \n",
      "\n",
      "Fold: 16  Epoch: 324  Training loss = 3.2787  Validation loss = 4.9169  \n",
      "\n",
      "Fold: 16  Epoch: 325  Training loss = 3.2779  Validation loss = 4.9157  \n",
      "\n",
      "Fold: 16  Epoch: 326  Training loss = 3.2773  Validation loss = 4.9148  \n",
      "\n",
      "Fold: 16  Epoch: 327  Training loss = 3.2766  Validation loss = 4.9136  \n",
      "\n",
      "Fold: 16  Epoch: 328  Training loss = 3.2762  Validation loss = 4.9131  \n",
      "\n",
      "Fold: 16  Epoch: 329  Training loss = 3.2760  Validation loss = 4.9128  \n",
      "\n",
      "Fold: 16  Epoch: 330  Training loss = 3.2752  Validation loss = 4.9116  \n",
      "\n",
      "Fold: 16  Epoch: 331  Training loss = 3.2747  Validation loss = 4.9107  \n",
      "\n",
      "Fold: 16  Epoch: 332  Training loss = 3.2739  Validation loss = 4.9096  \n",
      "\n",
      "Fold: 16  Epoch: 333  Training loss = 3.2735  Validation loss = 4.9091  \n",
      "\n",
      "Fold: 16  Epoch: 334  Training loss = 3.2727  Validation loss = 4.9079  \n",
      "\n",
      "Fold: 16  Epoch: 335  Training loss = 3.2721  Validation loss = 4.9069  \n",
      "\n",
      "Fold: 16  Epoch: 336  Training loss = 3.2716  Validation loss = 4.9061  \n",
      "\n",
      "Fold: 16  Epoch: 337  Training loss = 3.2711  Validation loss = 4.9054  \n",
      "\n",
      "Fold: 16  Epoch: 338  Training loss = 3.2703  Validation loss = 4.9043  \n",
      "\n",
      "Fold: 16  Epoch: 339  Training loss = 3.2697  Validation loss = 4.9035  \n",
      "\n",
      "Fold: 16  Epoch: 340  Training loss = 3.2690  Validation loss = 4.9025  \n",
      "\n",
      "Fold: 16  Epoch: 341  Training loss = 3.2685  Validation loss = 4.9019  \n",
      "\n",
      "Fold: 16  Epoch: 342  Training loss = 3.2681  Validation loss = 4.9012  \n",
      "\n",
      "Fold: 16  Epoch: 343  Training loss = 3.2676  Validation loss = 4.9005  \n",
      "\n",
      "Fold: 16  Epoch: 344  Training loss = 3.2670  Validation loss = 4.8997  \n",
      "\n",
      "Fold: 16  Epoch: 345  Training loss = 3.2664  Validation loss = 4.8988  \n",
      "\n",
      "Fold: 16  Epoch: 346  Training loss = 3.2659  Validation loss = 4.8982  \n",
      "\n",
      "Fold: 16  Epoch: 347  Training loss = 3.2653  Validation loss = 4.8974  \n",
      "\n",
      "Fold: 16  Epoch: 348  Training loss = 3.2646  Validation loss = 4.8964  \n",
      "\n",
      "Fold: 16  Epoch: 349  Training loss = 3.2639  Validation loss = 4.8955  \n",
      "\n",
      "Fold: 16  Epoch: 350  Training loss = 3.2632  Validation loss = 4.8946  \n",
      "\n",
      "Fold: 16  Epoch: 351  Training loss = 3.2625  Validation loss = 4.8936  \n",
      "\n",
      "Fold: 16  Epoch: 352  Training loss = 3.2616  Validation loss = 4.8923  \n",
      "\n",
      "Fold: 16  Epoch: 353  Training loss = 3.2610  Validation loss = 4.8915  \n",
      "\n",
      "Fold: 16  Epoch: 354  Training loss = 3.2603  Validation loss = 4.8906  \n",
      "\n",
      "Fold: 16  Epoch: 355  Training loss = 3.2597  Validation loss = 4.8896  \n",
      "\n",
      "Fold: 16  Epoch: 356  Training loss = 3.2589  Validation loss = 4.8885  \n",
      "\n",
      "Fold: 16  Epoch: 357  Training loss = 3.2580  Validation loss = 4.8873  \n",
      "\n",
      "Fold: 16  Epoch: 358  Training loss = 3.2571  Validation loss = 4.8859  \n",
      "\n",
      "Fold: 16  Epoch: 359  Training loss = 3.2562  Validation loss = 4.8847  \n",
      "\n",
      "Fold: 16  Epoch: 360  Training loss = 3.2557  Validation loss = 4.8839  \n",
      "\n",
      "Fold: 16  Epoch: 361  Training loss = 3.2546  Validation loss = 4.8826  \n",
      "\n",
      "Fold: 16  Epoch: 362  Training loss = 3.2538  Validation loss = 4.8817  \n",
      "\n",
      "Fold: 16  Epoch: 363  Training loss = 3.2529  Validation loss = 4.8806  \n",
      "\n",
      "Fold: 16  Epoch: 364  Training loss = 3.2526  Validation loss = 4.8800  \n",
      "\n",
      "Fold: 16  Epoch: 365  Training loss = 3.2515  Validation loss = 4.8787  \n",
      "\n",
      "Fold: 16  Epoch: 366  Training loss = 3.2508  Validation loss = 4.8779  \n",
      "\n",
      "Fold: 16  Epoch: 367  Training loss = 3.2502  Validation loss = 4.8771  \n",
      "\n",
      "Fold: 16  Epoch: 368  Training loss = 3.2494  Validation loss = 4.8760  \n",
      "\n",
      "Fold: 16  Epoch: 369  Training loss = 3.2488  Validation loss = 4.8751  \n",
      "\n",
      "Fold: 16  Epoch: 370  Training loss = 3.2485  Validation loss = 4.8746  \n",
      "\n",
      "Fold: 16  Epoch: 371  Training loss = 3.2482  Validation loss = 4.8741  \n",
      "\n",
      "Fold: 16  Epoch: 372  Training loss = 3.2474  Validation loss = 4.8731  \n",
      "\n",
      "Fold: 16  Epoch: 373  Training loss = 3.2468  Validation loss = 4.8721  \n",
      "\n",
      "Fold: 16  Epoch: 374  Training loss = 3.2463  Validation loss = 4.8714  \n",
      "\n",
      "Fold: 16  Epoch: 375  Training loss = 3.2459  Validation loss = 4.8707  \n",
      "\n",
      "Fold: 16  Epoch: 376  Training loss = 3.2454  Validation loss = 4.8699  \n",
      "\n",
      "Fold: 16  Epoch: 377  Training loss = 3.2450  Validation loss = 4.8694  \n",
      "\n",
      "Fold: 16  Epoch: 378  Training loss = 3.2443  Validation loss = 4.8684  \n",
      "\n",
      "Fold: 16  Epoch: 379  Training loss = 3.2438  Validation loss = 4.8676  \n",
      "\n",
      "Fold: 16  Epoch: 380  Training loss = 3.2433  Validation loss = 4.8669  \n",
      "\n",
      "Fold: 16  Epoch: 381  Training loss = 3.2428  Validation loss = 4.8661  \n",
      "\n",
      "Fold: 16  Epoch: 382  Training loss = 3.2423  Validation loss = 4.8653  \n",
      "\n",
      "Fold: 16  Epoch: 383  Training loss = 3.2414  Validation loss = 4.8639  \n",
      "\n",
      "Fold: 16  Epoch: 384  Training loss = 3.2405  Validation loss = 4.8626  \n",
      "\n",
      "Fold: 16  Epoch: 385  Training loss = 3.2400  Validation loss = 4.8618  \n",
      "\n",
      "Fold: 16  Epoch: 386  Training loss = 3.2393  Validation loss = 4.8607  \n",
      "\n",
      "Fold: 16  Epoch: 387  Training loss = 3.2385  Validation loss = 4.8595  \n",
      "\n",
      "Fold: 16  Epoch: 388  Training loss = 3.2381  Validation loss = 4.8590  \n",
      "\n",
      "Fold: 16  Epoch: 389  Training loss = 3.2379  Validation loss = 4.8587  \n",
      "\n",
      "Fold: 16  Epoch: 390  Training loss = 3.2375  Validation loss = 4.8581  \n",
      "\n",
      "Fold: 16  Epoch: 391  Training loss = 3.2367  Validation loss = 4.8569  \n",
      "\n",
      "Fold: 16  Epoch: 392  Training loss = 3.2361  Validation loss = 4.8559  \n",
      "\n",
      "Fold: 16  Epoch: 393  Training loss = 3.2352  Validation loss = 4.8546  \n",
      "\n",
      "Fold: 16  Epoch: 394  Training loss = 3.2348  Validation loss = 4.8540  \n",
      "\n",
      "Fold: 16  Epoch: 395  Training loss = 3.2345  Validation loss = 4.8534  \n",
      "\n",
      "Fold: 16  Epoch: 396  Training loss = 3.2341  Validation loss = 4.8529  \n",
      "\n",
      "Fold: 16  Epoch: 397  Training loss = 3.2334  Validation loss = 4.8519  \n",
      "\n",
      "Fold: 16  Epoch: 398  Training loss = 3.2329  Validation loss = 4.8510  \n",
      "\n",
      "Fold: 16  Epoch: 399  Training loss = 3.2324  Validation loss = 4.8503  \n",
      "\n",
      "Fold: 16  Epoch: 400  Training loss = 3.2320  Validation loss = 4.8496  \n",
      "\n",
      "Fold: 16  Epoch: 401  Training loss = 3.2314  Validation loss = 4.8488  \n",
      "\n",
      "Fold: 16  Epoch: 402  Training loss = 3.2310  Validation loss = 4.8482  \n",
      "\n",
      "Fold: 16  Epoch: 403  Training loss = 3.2306  Validation loss = 4.8474  \n",
      "\n",
      "Fold: 16  Epoch: 404  Training loss = 3.2301  Validation loss = 4.8467  \n",
      "\n",
      "Fold: 16  Epoch: 405  Training loss = 3.2294  Validation loss = 4.8456  \n",
      "\n",
      "Fold: 16  Epoch: 406  Training loss = 3.2289  Validation loss = 4.8447  \n",
      "\n",
      "Fold: 16  Epoch: 407  Training loss = 3.2283  Validation loss = 4.8439  \n",
      "\n",
      "Fold: 16  Epoch: 408  Training loss = 3.2276  Validation loss = 4.8428  \n",
      "\n",
      "Fold: 16  Epoch: 409  Training loss = 3.2270  Validation loss = 4.8417  \n",
      "\n",
      "Fold: 16  Epoch: 410  Training loss = 3.2264  Validation loss = 4.8407  \n",
      "\n",
      "Fold: 16  Epoch: 411  Training loss = 3.2258  Validation loss = 4.8398  \n",
      "\n",
      "Fold: 16  Epoch: 412  Training loss = 3.2253  Validation loss = 4.8390  \n",
      "\n",
      "Fold: 16  Epoch: 413  Training loss = 3.2245  Validation loss = 4.8379  \n",
      "\n",
      "Fold: 16  Epoch: 414  Training loss = 3.2238  Validation loss = 4.8368  \n",
      "\n",
      "Fold: 16  Epoch: 415  Training loss = 3.2230  Validation loss = 4.8355  \n",
      "\n",
      "Fold: 16  Epoch: 416  Training loss = 3.2228  Validation loss = 4.8352  \n",
      "\n",
      "Fold: 16  Epoch: 417  Training loss = 3.2222  Validation loss = 4.8342  \n",
      "\n",
      "Fold: 16  Epoch: 418  Training loss = 3.2216  Validation loss = 4.8333  \n",
      "\n",
      "Fold: 16  Epoch: 419  Training loss = 3.2213  Validation loss = 4.8328  \n",
      "\n",
      "Fold: 16  Epoch: 420  Training loss = 3.2207  Validation loss = 4.8319  \n",
      "\n",
      "Fold: 16  Epoch: 421  Training loss = 3.2203  Validation loss = 4.8313  \n",
      "\n",
      "Fold: 16  Epoch: 422  Training loss = 3.2196  Validation loss = 4.8303  \n",
      "\n",
      "Fold: 16  Epoch: 423  Training loss = 3.2189  Validation loss = 4.8292  \n",
      "\n",
      "Fold: 16  Epoch: 424  Training loss = 3.2184  Validation loss = 4.8284  \n",
      "\n",
      "Fold: 16  Epoch: 425  Training loss = 3.2176  Validation loss = 4.8273  \n",
      "\n",
      "Fold: 16  Epoch: 426  Training loss = 3.2170  Validation loss = 4.8262  \n",
      "\n",
      "Fold: 16  Epoch: 427  Training loss = 3.2166  Validation loss = 4.8258  \n",
      "\n",
      "Fold: 16  Epoch: 428  Training loss = 3.2161  Validation loss = 4.8250  \n",
      "\n",
      "Fold: 16  Epoch: 429  Training loss = 3.2155  Validation loss = 4.8241  \n",
      "\n",
      "Fold: 16  Epoch: 430  Training loss = 3.2150  Validation loss = 4.8234  \n",
      "\n",
      "Fold: 16  Epoch: 431  Training loss = 3.2146  Validation loss = 4.8227  \n",
      "\n",
      "Fold: 16  Epoch: 432  Training loss = 3.2142  Validation loss = 4.8220  \n",
      "\n",
      "Fold: 16  Epoch: 433  Training loss = 3.2137  Validation loss = 4.8214  \n",
      "\n",
      "Fold: 16  Epoch: 434  Training loss = 3.2132  Validation loss = 4.8205  \n",
      "\n",
      "Fold: 16  Epoch: 435  Training loss = 3.2124  Validation loss = 4.8195  \n",
      "\n",
      "Fold: 16  Epoch: 436  Training loss = 3.2117  Validation loss = 4.8185  \n",
      "\n",
      "Fold: 16  Epoch: 437  Training loss = 3.2110  Validation loss = 4.8173  \n",
      "\n",
      "Fold: 16  Epoch: 438  Training loss = 3.2105  Validation loss = 4.8166  \n",
      "\n",
      "Fold: 16  Epoch: 439  Training loss = 3.2098  Validation loss = 4.8155  \n",
      "\n",
      "Fold: 16  Epoch: 440  Training loss = 3.2091  Validation loss = 4.8143  \n",
      "\n",
      "Fold: 16  Epoch: 441  Training loss = 3.2084  Validation loss = 4.8135  \n",
      "\n",
      "Fold: 16  Epoch: 442  Training loss = 3.2078  Validation loss = 4.8127  \n",
      "\n",
      "Fold: 16  Epoch: 443  Training loss = 3.2073  Validation loss = 4.8119  \n",
      "\n",
      "Fold: 16  Epoch: 444  Training loss = 3.2069  Validation loss = 4.8114  \n",
      "\n",
      "Fold: 16  Epoch: 445  Training loss = 3.2064  Validation loss = 4.8107  \n",
      "\n",
      "Fold: 16  Epoch: 446  Training loss = 3.2060  Validation loss = 4.8103  \n",
      "\n",
      "Fold: 16  Epoch: 447  Training loss = 3.2055  Validation loss = 4.8097  \n",
      "\n",
      "Fold: 16  Epoch: 448  Training loss = 3.2049  Validation loss = 4.8089  \n",
      "\n",
      "Fold: 16  Epoch: 449  Training loss = 3.2042  Validation loss = 4.8080  \n",
      "\n",
      "Fold: 16  Epoch: 450  Training loss = 3.2033  Validation loss = 4.8069  \n",
      "\n",
      "Fold: 16  Epoch: 451  Training loss = 3.2027  Validation loss = 4.8062  \n",
      "\n",
      "Fold: 16  Epoch: 452  Training loss = 3.2021  Validation loss = 4.8056  \n",
      "\n",
      "Fold: 16  Epoch: 453  Training loss = 3.2015  Validation loss = 4.8046  \n",
      "\n",
      "Fold: 16  Epoch: 454  Training loss = 3.2008  Validation loss = 4.8038  \n",
      "\n",
      "Fold: 16  Epoch: 455  Training loss = 3.2000  Validation loss = 4.8027  \n",
      "\n",
      "Fold: 16  Epoch: 456  Training loss = 3.1995  Validation loss = 4.8020  \n",
      "\n",
      "Fold: 16  Epoch: 457  Training loss = 3.1987  Validation loss = 4.8010  \n",
      "\n",
      "Fold: 16  Epoch: 458  Training loss = 3.1981  Validation loss = 4.8002  \n",
      "\n",
      "Fold: 16  Epoch: 459  Training loss = 3.1969  Validation loss = 4.7985  \n",
      "\n",
      "Fold: 16  Epoch: 460  Training loss = 3.1966  Validation loss = 4.7980  \n",
      "\n",
      "Fold: 16  Epoch: 461  Training loss = 3.1962  Validation loss = 4.7975  \n",
      "\n",
      "Fold: 16  Epoch: 462  Training loss = 3.1959  Validation loss = 4.7969  \n",
      "\n",
      "Fold: 16  Epoch: 463  Training loss = 3.1952  Validation loss = 4.7958  \n",
      "\n",
      "Fold: 16  Epoch: 464  Training loss = 3.1945  Validation loss = 4.7949  \n",
      "\n",
      "Fold: 16  Epoch: 465  Training loss = 3.1941  Validation loss = 4.7942  \n",
      "\n",
      "Fold: 16  Epoch: 466  Training loss = 3.1933  Validation loss = 4.7931  \n",
      "\n",
      "Fold: 16  Epoch: 467  Training loss = 3.1925  Validation loss = 4.7918  \n",
      "\n",
      "Fold: 16  Epoch: 468  Training loss = 3.1920  Validation loss = 4.7910  \n",
      "\n",
      "Fold: 16  Epoch: 469  Training loss = 3.1916  Validation loss = 4.7904  \n",
      "\n",
      "Fold: 16  Epoch: 470  Training loss = 3.1910  Validation loss = 4.7895  \n",
      "\n",
      "Fold: 16  Epoch: 471  Training loss = 3.1903  Validation loss = 4.7887  \n",
      "\n",
      "Fold: 16  Epoch: 472  Training loss = 3.1889  Validation loss = 4.7875  \n",
      "\n",
      "Fold: 16  Epoch: 473  Training loss = 3.1883  Validation loss = 4.7870  \n",
      "\n",
      "Fold: 16  Epoch: 474  Training loss = 3.1875  Validation loss = 4.7861  \n",
      "\n",
      "Fold: 16  Epoch: 475  Training loss = 3.1871  Validation loss = 4.7855  \n",
      "\n",
      "Fold: 16  Epoch: 476  Training loss = 3.1867  Validation loss = 4.7849  \n",
      "\n",
      "Fold: 16  Epoch: 477  Training loss = 3.1861  Validation loss = 4.7840  \n",
      "\n",
      "Fold: 16  Epoch: 478  Training loss = 3.1855  Validation loss = 4.7832  \n",
      "\n",
      "Fold: 16  Epoch: 479  Training loss = 3.1850  Validation loss = 4.7823  \n",
      "\n",
      "Fold: 16  Epoch: 480  Training loss = 3.1846  Validation loss = 4.7817  \n",
      "\n",
      "Fold: 16  Epoch: 481  Training loss = 3.1843  Validation loss = 4.7812  \n",
      "\n",
      "Fold: 16  Epoch: 482  Training loss = 3.1841  Validation loss = 4.7809  \n",
      "\n",
      "Fold: 16  Epoch: 483  Training loss = 3.1838  Validation loss = 4.7804  \n",
      "\n",
      "Fold: 16  Epoch: 484  Training loss = 3.1832  Validation loss = 4.7795  \n",
      "\n",
      "Fold: 16  Epoch: 485  Training loss = 3.1828  Validation loss = 4.7787  \n",
      "\n",
      "Fold: 16  Epoch: 486  Training loss = 3.1824  Validation loss = 4.7780  \n",
      "\n",
      "Fold: 16  Epoch: 487  Training loss = 3.1816  Validation loss = 4.7769  \n",
      "\n",
      "Fold: 16  Epoch: 488  Training loss = 3.1810  Validation loss = 4.7759  \n",
      "\n",
      "Fold: 16  Epoch: 489  Training loss = 3.1804  Validation loss = 4.7749  \n",
      "\n",
      "Fold: 16  Epoch: 490  Training loss = 3.1798  Validation loss = 4.7740  \n",
      "\n",
      "Fold: 16  Epoch: 491  Training loss = 3.1794  Validation loss = 4.7733  \n",
      "\n",
      "Fold: 16  Epoch: 492  Training loss = 3.1788  Validation loss = 4.7725  \n",
      "\n",
      "Fold: 16  Epoch: 493  Training loss = 3.1785  Validation loss = 4.7719  \n",
      "\n",
      "Fold: 16  Epoch: 494  Training loss = 3.1781  Validation loss = 4.7713  \n",
      "\n",
      "Fold: 16  Epoch: 495  Training loss = 3.1777  Validation loss = 4.7706  \n",
      "\n",
      "Fold: 16  Epoch: 496  Training loss = 3.1772  Validation loss = 4.7698  \n",
      "\n",
      "Fold: 16  Epoch: 497  Training loss = 3.1764  Validation loss = 4.7687  \n",
      "\n",
      "Fold: 16  Epoch: 498  Training loss = 3.1762  Validation loss = 4.7684  \n",
      "\n",
      "Fold: 16  Epoch: 499  Training loss = 3.1758  Validation loss = 4.7677  \n",
      "\n",
      "Fold: 16  Epoch: 500  Training loss = 3.1751  Validation loss = 4.7666  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 500  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 3.3728  Validation loss = 2.8794  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 3.3723  Validation loss = 2.8795  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 3.3716  Validation loss = 2.8797  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 3.3710  Validation loss = 2.8799  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 3.3704  Validation loss = 2.8798  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 3.3698  Validation loss = 2.8799  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 3.3690  Validation loss = 2.8799  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 3.3683  Validation loss = 2.8801  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 3.3679  Validation loss = 2.8801  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 3.3675  Validation loss = 2.8802  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 3.3669  Validation loss = 2.8803  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 1  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.4392  Validation loss = 1.3839  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 3.4384  Validation loss = 1.3846  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.4379  Validation loss = 1.3849  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.4374  Validation loss = 1.3853  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.4367  Validation loss = 1.3859  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.4363  Validation loss = 1.3862  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 3.4356  Validation loss = 1.3867  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 3.4350  Validation loss = 1.3872  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 3.4344  Validation loss = 1.3877  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 3.4339  Validation loss = 1.3881  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.4333  Validation loss = 1.3886  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 1  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 3.4112  Validation loss = 2.5683  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 3.4106  Validation loss = 2.5686  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 3.4102  Validation loss = 2.5688  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 3.4094  Validation loss = 2.5693  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 3.4086  Validation loss = 2.5698  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 3.4081  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 3.4075  Validation loss = 2.5705  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 3.4068  Validation loss = 2.5710  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 3.4060  Validation loss = 2.5714  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 3.4055  Validation loss = 2.5718  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 3.4049  Validation loss = 2.5721  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 1  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 3.4618  Validation loss = 1.0284  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 3.4611  Validation loss = 1.0283  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 3.4602  Validation loss = 1.0280  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 3.4596  Validation loss = 1.0278  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 3.4589  Validation loss = 1.0277  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 3.4583  Validation loss = 1.0273  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 3.4577  Validation loss = 1.0272  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 3.4574  Validation loss = 1.0270  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 3.4566  Validation loss = 1.0265  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 3.4559  Validation loss = 1.0261  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 3.4556  Validation loss = 1.0261  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 3.4550  Validation loss = 1.0258  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 3.4545  Validation loss = 1.0255  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 3.4538  Validation loss = 1.0254  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 3.4530  Validation loss = 1.0251  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 3.4526  Validation loss = 1.0248  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 3.4522  Validation loss = 1.0247  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 3.4517  Validation loss = 1.0245  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 3.4510  Validation loss = 1.0242  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 3.4504  Validation loss = 1.0239  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 3.4498  Validation loss = 1.0235  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 3.4493  Validation loss = 1.0232  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 3.4487  Validation loss = 1.0231  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 3.4480  Validation loss = 1.0229  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 3.4474  Validation loss = 1.0225  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 3.4468  Validation loss = 1.0223  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 3.4463  Validation loss = 1.0221  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 3.4461  Validation loss = 1.0219  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 3.4456  Validation loss = 1.0216  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 3.4450  Validation loss = 1.0214  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 3.4444  Validation loss = 1.0213  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 3.4441  Validation loss = 1.0210  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 3.4436  Validation loss = 1.0209  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 3.4430  Validation loss = 1.0207  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 3.4425  Validation loss = 1.0205  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 3.4419  Validation loss = 1.0202  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 3.4415  Validation loss = 1.0199  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 3.4410  Validation loss = 1.0198  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 3.4404  Validation loss = 1.0196  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 3.4399  Validation loss = 1.0194  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 3.4397  Validation loss = 1.0193  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 3.4392  Validation loss = 1.0192  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 3.4384  Validation loss = 1.0188  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 3.4377  Validation loss = 1.0186  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 3.4372  Validation loss = 1.0184  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 3.4368  Validation loss = 1.0182  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 3.4362  Validation loss = 1.0181  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 3.4357  Validation loss = 1.0180  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 3.4354  Validation loss = 1.0179  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 3.4348  Validation loss = 1.0177  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 3.4343  Validation loss = 1.0175  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 3.4338  Validation loss = 1.0174  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 3.4333  Validation loss = 1.0173  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 3.4324  Validation loss = 1.0168  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 3.4320  Validation loss = 1.0167  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 3.4314  Validation loss = 1.0163  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 3.4309  Validation loss = 1.0161  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 3.4303  Validation loss = 1.0159  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 3.4295  Validation loss = 1.0158  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 3.4287  Validation loss = 1.0155  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 3.4282  Validation loss = 1.0153  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 3.4275  Validation loss = 1.0152  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 3.4267  Validation loss = 1.0151  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 3.4260  Validation loss = 1.0148  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 3.4255  Validation loss = 1.0146  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 3.4251  Validation loss = 1.0144  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 3.4243  Validation loss = 1.0142  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 3.4237  Validation loss = 1.0141  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 3.4232  Validation loss = 1.0138  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 3.4227  Validation loss = 1.0137  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 3.4222  Validation loss = 1.0135  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 3.4216  Validation loss = 1.0134  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 3.4210  Validation loss = 1.0132  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 3.4204  Validation loss = 1.0129  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 3.4202  Validation loss = 1.0129  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 3.4199  Validation loss = 1.0126  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 3.4194  Validation loss = 1.0124  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 3.4190  Validation loss = 1.0122  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 3.4184  Validation loss = 1.0122  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 3.4178  Validation loss = 1.0119  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 3.4176  Validation loss = 1.0118  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 3.4167  Validation loss = 1.0117  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 3.4163  Validation loss = 1.0114  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 3.4156  Validation loss = 1.0112  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 3.4152  Validation loss = 1.0110  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 3.4146  Validation loss = 1.0109  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 3.4141  Validation loss = 1.0106  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 3.4137  Validation loss = 1.0106  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 3.4130  Validation loss = 1.0105  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 3.4124  Validation loss = 1.0104  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 3.4119  Validation loss = 1.0101  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 3.4113  Validation loss = 1.0100  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 3.4106  Validation loss = 1.0099  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 3.4101  Validation loss = 1.0096  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 3.4093  Validation loss = 1.0093  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 3.4087  Validation loss = 1.0092  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 3.4084  Validation loss = 1.0091  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 3.4080  Validation loss = 1.0088  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 3.4074  Validation loss = 1.0087  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 3.4070  Validation loss = 1.0086  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 3.4066  Validation loss = 1.0084  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 3.4059  Validation loss = 1.0080  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 3.4055  Validation loss = 1.0077  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 3.4050  Validation loss = 1.0076  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 3.4047  Validation loss = 1.0073  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 3.4039  Validation loss = 1.0071  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 3.4032  Validation loss = 1.0070  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 3.4026  Validation loss = 1.0067  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 3.4022  Validation loss = 1.0066  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 3.4017  Validation loss = 1.0065  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 3.4012  Validation loss = 1.0065  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 3.4007  Validation loss = 1.0063  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 3.4004  Validation loss = 1.0060  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 3.4002  Validation loss = 1.0060  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 3.3996  Validation loss = 1.0058  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 3.3989  Validation loss = 1.0057  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 3.3983  Validation loss = 1.0056  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 3.3978  Validation loss = 1.0053  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 3.3974  Validation loss = 1.0053  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 3.3970  Validation loss = 1.0052  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 3.3966  Validation loss = 1.0050  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 3.3962  Validation loss = 1.0051  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 3.3956  Validation loss = 1.0051  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 3.3950  Validation loss = 1.0050  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 3.3946  Validation loss = 1.0047  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 3.3943  Validation loss = 1.0045  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 3.3940  Validation loss = 1.0042  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 3.3936  Validation loss = 1.0041  \n",
      "\n",
      "Fold: 20  Epoch: 129  Training loss = 3.3932  Validation loss = 1.0039  \n",
      "\n",
      "Fold: 20  Epoch: 130  Training loss = 3.3928  Validation loss = 1.0037  \n",
      "\n",
      "Fold: 20  Epoch: 131  Training loss = 3.3922  Validation loss = 1.0035  \n",
      "\n",
      "Fold: 20  Epoch: 132  Training loss = 3.3917  Validation loss = 1.0033  \n",
      "\n",
      "Fold: 20  Epoch: 133  Training loss = 3.3912  Validation loss = 1.0032  \n",
      "\n",
      "Fold: 20  Epoch: 134  Training loss = 3.3905  Validation loss = 1.0030  \n",
      "\n",
      "Fold: 20  Epoch: 135  Training loss = 3.3901  Validation loss = 1.0030  \n",
      "\n",
      "Fold: 20  Epoch: 136  Training loss = 3.3895  Validation loss = 1.0029  \n",
      "\n",
      "Fold: 20  Epoch: 137  Training loss = 3.3888  Validation loss = 1.0026  \n",
      "\n",
      "Fold: 20  Epoch: 138  Training loss = 3.3883  Validation loss = 1.0025  \n",
      "\n",
      "Fold: 20  Epoch: 139  Training loss = 3.3878  Validation loss = 1.0025  \n",
      "\n",
      "Fold: 20  Epoch: 140  Training loss = 3.3873  Validation loss = 1.0025  \n",
      "\n",
      "Fold: 20  Epoch: 141  Training loss = 3.3867  Validation loss = 1.0023  \n",
      "\n",
      "Fold: 20  Epoch: 142  Training loss = 3.3864  Validation loss = 1.0021  \n",
      "\n",
      "Fold: 20  Epoch: 143  Training loss = 3.3859  Validation loss = 1.0022  \n",
      "\n",
      "Fold: 20  Epoch: 144  Training loss = 3.3857  Validation loss = 1.0019  \n",
      "\n",
      "Fold: 20  Epoch: 145  Training loss = 3.3851  Validation loss = 1.0017  \n",
      "\n",
      "Fold: 20  Epoch: 146  Training loss = 3.3844  Validation loss = 1.0014  \n",
      "\n",
      "Fold: 20  Epoch: 147  Training loss = 3.3838  Validation loss = 1.0014  \n",
      "\n",
      "Fold: 20  Epoch: 148  Training loss = 3.3832  Validation loss = 1.0013  \n",
      "\n",
      "Fold: 20  Epoch: 149  Training loss = 3.3826  Validation loss = 1.0011  \n",
      "\n",
      "Fold: 20  Epoch: 150  Training loss = 3.3819  Validation loss = 1.0009  \n",
      "\n",
      "Fold: 20  Epoch: 151  Training loss = 3.3815  Validation loss = 1.0009  \n",
      "\n",
      "Fold: 20  Epoch: 152  Training loss = 3.3809  Validation loss = 1.0007  \n",
      "\n",
      "Fold: 20  Epoch: 153  Training loss = 3.3803  Validation loss = 1.0006  \n",
      "\n",
      "Fold: 20  Epoch: 154  Training loss = 3.3798  Validation loss = 1.0004  \n",
      "\n",
      "Fold: 20  Epoch: 155  Training loss = 3.3793  Validation loss = 1.0004  \n",
      "\n",
      "Fold: 20  Epoch: 156  Training loss = 3.3788  Validation loss = 1.0003  \n",
      "\n",
      "Fold: 20  Epoch: 157  Training loss = 3.3784  Validation loss = 1.0001  \n",
      "\n",
      "Fold: 20  Epoch: 158  Training loss = 3.3779  Validation loss = 0.9999  \n",
      "\n",
      "Fold: 20  Epoch: 159  Training loss = 3.3775  Validation loss = 0.9997  \n",
      "\n",
      "Fold: 20  Epoch: 160  Training loss = 3.3770  Validation loss = 0.9996  \n",
      "\n",
      "Fold: 20  Epoch: 161  Training loss = 3.3767  Validation loss = 0.9995  \n",
      "\n",
      "Fold: 20  Epoch: 162  Training loss = 3.3762  Validation loss = 0.9990  \n",
      "\n",
      "Fold: 20  Epoch: 163  Training loss = 3.3758  Validation loss = 0.9989  \n",
      "\n",
      "Fold: 20  Epoch: 164  Training loss = 3.3752  Validation loss = 0.9986  \n",
      "\n",
      "Fold: 20  Epoch: 165  Training loss = 3.3745  Validation loss = 0.9987  \n",
      "\n",
      "Fold: 20  Epoch: 166  Training loss = 3.3741  Validation loss = 0.9988  \n",
      "\n",
      "Fold: 20  Epoch: 167  Training loss = 3.3736  Validation loss = 0.9988  \n",
      "\n",
      "Fold: 20  Epoch: 168  Training loss = 3.3732  Validation loss = 0.9986  \n",
      "\n",
      "Fold: 20  Epoch: 169  Training loss = 3.3727  Validation loss = 0.9985  \n",
      "\n",
      "Fold: 20  Epoch: 170  Training loss = 3.3721  Validation loss = 0.9982  \n",
      "\n",
      "Fold: 20  Epoch: 171  Training loss = 3.3719  Validation loss = 0.9982  \n",
      "\n",
      "Fold: 20  Epoch: 172  Training loss = 3.3712  Validation loss = 0.9981  \n",
      "\n",
      "Fold: 20  Epoch: 173  Training loss = 3.3708  Validation loss = 0.9978  \n",
      "\n",
      "Fold: 20  Epoch: 174  Training loss = 3.3703  Validation loss = 0.9977  \n",
      "\n",
      "Fold: 20  Epoch: 175  Training loss = 3.3700  Validation loss = 0.9977  \n",
      "\n",
      "Fold: 20  Epoch: 176  Training loss = 3.3696  Validation loss = 0.9975  \n",
      "\n",
      "Fold: 20  Epoch: 177  Training loss = 3.3693  Validation loss = 0.9974  \n",
      "\n",
      "Fold: 20  Epoch: 178  Training loss = 3.3688  Validation loss = 0.9972  \n",
      "\n",
      "Fold: 20  Epoch: 179  Training loss = 3.3683  Validation loss = 0.9972  \n",
      "\n",
      "Fold: 20  Epoch: 180  Training loss = 3.3681  Validation loss = 0.9972  \n",
      "\n",
      "Fold: 20  Epoch: 181  Training loss = 3.3676  Validation loss = 0.9972  \n",
      "\n",
      "Fold: 20  Epoch: 182  Training loss = 3.3671  Validation loss = 0.9971  \n",
      "\n",
      "Fold: 20  Epoch: 183  Training loss = 3.3666  Validation loss = 0.9970  \n",
      "\n",
      "Fold: 20  Epoch: 184  Training loss = 3.3663  Validation loss = 0.9968  \n",
      "\n",
      "Fold: 20  Epoch: 185  Training loss = 3.3659  Validation loss = 0.9967  \n",
      "\n",
      "Fold: 20  Epoch: 186  Training loss = 3.3652  Validation loss = 0.9964  \n",
      "\n",
      "Fold: 20  Epoch: 187  Training loss = 3.3646  Validation loss = 0.9962  \n",
      "\n",
      "Fold: 20  Epoch: 188  Training loss = 3.3643  Validation loss = 0.9961  \n",
      "\n",
      "Fold: 20  Epoch: 189  Training loss = 3.3638  Validation loss = 0.9959  \n",
      "\n",
      "Fold: 20  Epoch: 190  Training loss = 3.3634  Validation loss = 0.9957  \n",
      "\n",
      "Fold: 20  Epoch: 191  Training loss = 3.3630  Validation loss = 0.9958  \n",
      "\n",
      "Fold: 20  Epoch: 192  Training loss = 3.3626  Validation loss = 0.9956  \n",
      "\n",
      "Fold: 20  Epoch: 193  Training loss = 3.3620  Validation loss = 0.9955  \n",
      "\n",
      "Fold: 20  Epoch: 194  Training loss = 3.3614  Validation loss = 0.9954  \n",
      "\n",
      "Fold: 20  Epoch: 195  Training loss = 3.3608  Validation loss = 0.9953  \n",
      "\n",
      "Fold: 20  Epoch: 196  Training loss = 3.3605  Validation loss = 0.9951  \n",
      "\n",
      "Fold: 20  Epoch: 197  Training loss = 3.3602  Validation loss = 0.9951  \n",
      "\n",
      "Fold: 20  Epoch: 198  Training loss = 3.3598  Validation loss = 0.9949  \n",
      "\n",
      "Fold: 20  Epoch: 199  Training loss = 3.3592  Validation loss = 0.9948  \n",
      "\n",
      "Fold: 20  Epoch: 200  Training loss = 3.3585  Validation loss = 0.9947  \n",
      "\n",
      "Fold: 20  Epoch: 201  Training loss = 3.3580  Validation loss = 0.9946  \n",
      "\n",
      "Fold: 20  Epoch: 202  Training loss = 3.3574  Validation loss = 0.9944  \n",
      "\n",
      "Fold: 20  Epoch: 203  Training loss = 3.3571  Validation loss = 0.9942  \n",
      "\n",
      "Fold: 20  Epoch: 204  Training loss = 3.3568  Validation loss = 0.9939  \n",
      "\n",
      "Fold: 20  Epoch: 205  Training loss = 3.3563  Validation loss = 0.9938  \n",
      "\n",
      "Fold: 20  Epoch: 206  Training loss = 3.3556  Validation loss = 0.9939  \n",
      "\n",
      "Fold: 20  Epoch: 207  Training loss = 3.3553  Validation loss = 0.9937  \n",
      "\n",
      "Fold: 20  Epoch: 208  Training loss = 3.3550  Validation loss = 0.9934  \n",
      "\n",
      "Fold: 20  Epoch: 209  Training loss = 3.3547  Validation loss = 0.9933  \n",
      "\n",
      "Fold: 20  Epoch: 210  Training loss = 3.3542  Validation loss = 0.9931  \n",
      "\n",
      "Fold: 20  Epoch: 211  Training loss = 3.3536  Validation loss = 0.9931  \n",
      "\n",
      "Fold: 20  Epoch: 212  Training loss = 3.3534  Validation loss = 0.9931  \n",
      "\n",
      "Fold: 20  Epoch: 213  Training loss = 3.3530  Validation loss = 0.9928  \n",
      "\n",
      "Fold: 20  Epoch: 214  Training loss = 3.3524  Validation loss = 0.9926  \n",
      "\n",
      "Fold: 20  Epoch: 215  Training loss = 3.3522  Validation loss = 0.9927  \n",
      "\n",
      "Fold: 20  Epoch: 216  Training loss = 3.3519  Validation loss = 0.9927  \n",
      "\n",
      "Fold: 20  Epoch: 217  Training loss = 3.3517  Validation loss = 0.9925  \n",
      "\n",
      "Fold: 20  Epoch: 218  Training loss = 3.3514  Validation loss = 0.9923  \n",
      "\n",
      "Fold: 20  Epoch: 219  Training loss = 3.3509  Validation loss = 0.9922  \n",
      "\n",
      "Fold: 20  Epoch: 220  Training loss = 3.3504  Validation loss = 0.9922  \n",
      "\n",
      "Fold: 20  Epoch: 221  Training loss = 3.3498  Validation loss = 0.9921  \n",
      "\n",
      "Fold: 20  Epoch: 222  Training loss = 3.3493  Validation loss = 0.9920  \n",
      "\n",
      "Fold: 20  Epoch: 223  Training loss = 3.3488  Validation loss = 0.9919  \n",
      "\n",
      "Fold: 20  Epoch: 224  Training loss = 3.3485  Validation loss = 0.9918  \n",
      "\n",
      "Fold: 20  Epoch: 225  Training loss = 3.3481  Validation loss = 0.9917  \n",
      "\n",
      "Fold: 20  Epoch: 226  Training loss = 3.3475  Validation loss = 0.9917  \n",
      "\n",
      "Fold: 20  Epoch: 227  Training loss = 3.3471  Validation loss = 0.9914  \n",
      "\n",
      "Fold: 20  Epoch: 228  Training loss = 3.3466  Validation loss = 0.9913  \n",
      "\n",
      "Fold: 20  Epoch: 229  Training loss = 3.3463  Validation loss = 0.9912  \n",
      "\n",
      "Fold: 20  Epoch: 230  Training loss = 3.3459  Validation loss = 0.9911  \n",
      "\n",
      "Fold: 20  Epoch: 231  Training loss = 3.3453  Validation loss = 0.9910  \n",
      "\n",
      "Fold: 20  Epoch: 232  Training loss = 3.3447  Validation loss = 0.9909  \n",
      "\n",
      "Fold: 20  Epoch: 233  Training loss = 3.3443  Validation loss = 0.9907  \n",
      "\n",
      "Fold: 20  Epoch: 234  Training loss = 3.3439  Validation loss = 0.9905  \n",
      "\n",
      "Fold: 20  Epoch: 235  Training loss = 3.3435  Validation loss = 0.9904  \n",
      "\n",
      "Fold: 20  Epoch: 236  Training loss = 3.3430  Validation loss = 0.9901  \n",
      "\n",
      "Fold: 20  Epoch: 237  Training loss = 3.3425  Validation loss = 0.9899  \n",
      "\n",
      "Fold: 20  Epoch: 238  Training loss = 3.3421  Validation loss = 0.9898  \n",
      "\n",
      "Fold: 20  Epoch: 239  Training loss = 3.3417  Validation loss = 0.9898  \n",
      "\n",
      "Fold: 20  Epoch: 240  Training loss = 3.3412  Validation loss = 0.9895  \n",
      "\n",
      "Fold: 20  Epoch: 241  Training loss = 3.3408  Validation loss = 0.9895  \n",
      "\n",
      "Fold: 20  Epoch: 242  Training loss = 3.3405  Validation loss = 0.9895  \n",
      "\n",
      "Fold: 20  Epoch: 243  Training loss = 3.3403  Validation loss = 0.9894  \n",
      "\n",
      "Fold: 20  Epoch: 244  Training loss = 3.3399  Validation loss = 0.9893  \n",
      "\n",
      "Fold: 20  Epoch: 245  Training loss = 3.3391  Validation loss = 0.9894  \n",
      "\n",
      "Fold: 20  Epoch: 246  Training loss = 3.3385  Validation loss = 0.9894  \n",
      "\n",
      "Fold: 20  Epoch: 247  Training loss = 3.3379  Validation loss = 0.9893  \n",
      "\n",
      "Fold: 20  Epoch: 248  Training loss = 3.3375  Validation loss = 0.9892  \n",
      "\n",
      "Fold: 20  Epoch: 249  Training loss = 3.3373  Validation loss = 0.9889  \n",
      "\n",
      "Fold: 20  Epoch: 250  Training loss = 3.3369  Validation loss = 0.9888  \n",
      "\n",
      "Fold: 20  Epoch: 251  Training loss = 3.3365  Validation loss = 0.9889  \n",
      "\n",
      "Fold: 20  Epoch: 252  Training loss = 3.3360  Validation loss = 0.9888  \n",
      "\n",
      "Fold: 20  Epoch: 253  Training loss = 3.3358  Validation loss = 0.9887  \n",
      "\n",
      "Fold: 20  Epoch: 254  Training loss = 3.3353  Validation loss = 0.9884  \n",
      "\n",
      "Fold: 20  Epoch: 255  Training loss = 3.3348  Validation loss = 0.9884  \n",
      "\n",
      "Fold: 20  Epoch: 256  Training loss = 3.3344  Validation loss = 0.9884  \n",
      "\n",
      "Fold: 20  Epoch: 257  Training loss = 3.3342  Validation loss = 0.9884  \n",
      "\n",
      "Fold: 20  Epoch: 258  Training loss = 3.3338  Validation loss = 0.9883  \n",
      "\n",
      "Fold: 20  Epoch: 259  Training loss = 3.3335  Validation loss = 0.9882  \n",
      "\n",
      "Fold: 20  Epoch: 260  Training loss = 3.3328  Validation loss = 0.9882  \n",
      "\n",
      "Fold: 20  Epoch: 261  Training loss = 3.3325  Validation loss = 0.9881  \n",
      "\n",
      "Fold: 20  Epoch: 262  Training loss = 3.3322  Validation loss = 0.9879  \n",
      "\n",
      "Fold: 20  Epoch: 263  Training loss = 3.3319  Validation loss = 0.9877  \n",
      "\n",
      "Fold: 20  Epoch: 264  Training loss = 3.3314  Validation loss = 0.9876  \n",
      "\n",
      "Fold: 20  Epoch: 265  Training loss = 3.3310  Validation loss = 0.9876  \n",
      "\n",
      "Fold: 20  Epoch: 266  Training loss = 3.3309  Validation loss = 0.9873  \n",
      "\n",
      "Fold: 20  Epoch: 267  Training loss = 3.3307  Validation loss = 0.9872  \n",
      "\n",
      "Fold: 20  Epoch: 268  Training loss = 3.3303  Validation loss = 0.9871  \n",
      "\n",
      "Fold: 20  Epoch: 269  Training loss = 3.3299  Validation loss = 0.9871  \n",
      "\n",
      "Fold: 20  Epoch: 270  Training loss = 3.3294  Validation loss = 0.9870  \n",
      "\n",
      "Fold: 20  Epoch: 271  Training loss = 3.3288  Validation loss = 0.9869  \n",
      "\n",
      "Fold: 20  Epoch: 272  Training loss = 3.3284  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 20  Epoch: 273  Training loss = 3.3280  Validation loss = 0.9868  \n",
      "\n",
      "Fold: 20  Epoch: 274  Training loss = 3.3272  Validation loss = 0.9868  \n",
      "\n",
      "Fold: 20  Epoch: 275  Training loss = 3.3270  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 20  Epoch: 276  Training loss = 3.3265  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 20  Epoch: 277  Training loss = 3.3261  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 20  Epoch: 278  Training loss = 3.3253  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 20  Epoch: 279  Training loss = 3.3250  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 20  Epoch: 280  Training loss = 3.3245  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 20  Epoch: 281  Training loss = 3.3237  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 20  Epoch: 282  Training loss = 3.3232  Validation loss = 0.9864  \n",
      "\n",
      "Fold: 20  Epoch: 283  Training loss = 3.3230  Validation loss = 0.9864  \n",
      "\n",
      "Fold: 20  Epoch: 284  Training loss = 3.3224  Validation loss = 0.9862  \n",
      "\n",
      "Fold: 20  Epoch: 285  Training loss = 3.3221  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 20  Epoch: 286  Training loss = 3.3216  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 20  Epoch: 287  Training loss = 3.3213  Validation loss = 0.9859  \n",
      "\n",
      "Fold: 20  Epoch: 288  Training loss = 3.3208  Validation loss = 0.9857  \n",
      "\n",
      "Fold: 20  Epoch: 289  Training loss = 3.3203  Validation loss = 0.9856  \n",
      "\n",
      "Fold: 20  Epoch: 290  Training loss = 3.3201  Validation loss = 0.9854  \n",
      "\n",
      "Fold: 20  Epoch: 291  Training loss = 3.3197  Validation loss = 0.9853  \n",
      "\n",
      "Fold: 20  Epoch: 292  Training loss = 3.3193  Validation loss = 0.9853  \n",
      "\n",
      "Fold: 20  Epoch: 293  Training loss = 3.3189  Validation loss = 0.9853  \n",
      "\n",
      "Fold: 20  Epoch: 294  Training loss = 3.3183  Validation loss = 0.9852  \n",
      "\n",
      "Fold: 20  Epoch: 295  Training loss = 3.3177  Validation loss = 0.9850  \n",
      "\n",
      "Fold: 20  Epoch: 296  Training loss = 3.3173  Validation loss = 0.9849  \n",
      "\n",
      "Fold: 20  Epoch: 297  Training loss = 3.3168  Validation loss = 0.9849  \n",
      "\n",
      "Fold: 20  Epoch: 298  Training loss = 3.3163  Validation loss = 0.9849  \n",
      "\n",
      "Fold: 20  Epoch: 299  Training loss = 3.3158  Validation loss = 0.9848  \n",
      "\n",
      "Fold: 20  Epoch: 300  Training loss = 3.3154  Validation loss = 0.9848  \n",
      "\n",
      "Fold: 20  Epoch: 301  Training loss = 3.3145  Validation loss = 0.9847  \n",
      "\n",
      "Fold: 20  Epoch: 302  Training loss = 3.3141  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 20  Epoch: 303  Training loss = 3.3135  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 20  Epoch: 304  Training loss = 3.3129  Validation loss = 0.9847  \n",
      "\n",
      "Fold: 20  Epoch: 305  Training loss = 3.3124  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 20  Epoch: 306  Training loss = 3.3120  Validation loss = 0.9846  \n",
      "\n",
      "Fold: 20  Epoch: 307  Training loss = 3.3117  Validation loss = 0.9844  \n",
      "\n",
      "Fold: 20  Epoch: 308  Training loss = 3.3112  Validation loss = 0.9844  \n",
      "\n",
      "Fold: 20  Epoch: 309  Training loss = 3.3110  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 20  Epoch: 310  Training loss = 3.3105  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 20  Epoch: 311  Training loss = 3.3100  Validation loss = 0.9844  \n",
      "\n",
      "Fold: 20  Epoch: 312  Training loss = 3.3095  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 20  Epoch: 313  Training loss = 3.3092  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 20  Epoch: 314  Training loss = 3.3089  Validation loss = 0.9841  \n",
      "\n",
      "Fold: 20  Epoch: 315  Training loss = 3.3084  Validation loss = 0.9840  \n",
      "\n",
      "Fold: 20  Epoch: 316  Training loss = 3.3080  Validation loss = 0.9839  \n",
      "\n",
      "Fold: 20  Epoch: 317  Training loss = 3.3075  Validation loss = 0.9839  \n",
      "\n",
      "Fold: 20  Epoch: 318  Training loss = 3.3072  Validation loss = 0.9839  \n",
      "\n",
      "Fold: 20  Epoch: 319  Training loss = 3.3068  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 20  Epoch: 320  Training loss = 3.3063  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 20  Epoch: 321  Training loss = 3.3060  Validation loss = 0.9838  \n",
      "\n",
      "Fold: 20  Epoch: 322  Training loss = 3.3054  Validation loss = 0.9837  \n",
      "\n",
      "Fold: 20  Epoch: 323  Training loss = 3.3051  Validation loss = 0.9836  \n",
      "\n",
      "Fold: 20  Epoch: 324  Training loss = 3.3047  Validation loss = 0.9835  \n",
      "\n",
      "Fold: 20  Epoch: 325  Training loss = 3.3041  Validation loss = 0.9836  \n",
      "\n",
      "Fold: 20  Epoch: 326  Training loss = 3.3036  Validation loss = 0.9836  \n",
      "\n",
      "Fold: 20  Epoch: 327  Training loss = 3.3034  Validation loss = 0.9835  \n",
      "\n",
      "Fold: 20  Epoch: 328  Training loss = 3.3030  Validation loss = 0.9834  \n",
      "\n",
      "Fold: 20  Epoch: 329  Training loss = 3.3025  Validation loss = 0.9834  \n",
      "\n",
      "Fold: 20  Epoch: 330  Training loss = 3.3020  Validation loss = 0.9832  \n",
      "\n",
      "Fold: 20  Epoch: 331  Training loss = 3.3015  Validation loss = 0.9832  \n",
      "\n",
      "Fold: 20  Epoch: 332  Training loss = 3.3013  Validation loss = 0.9831  \n",
      "\n",
      "Fold: 20  Epoch: 333  Training loss = 3.3007  Validation loss = 0.9829  \n",
      "\n",
      "Fold: 20  Epoch: 334  Training loss = 3.3004  Validation loss = 0.9829  \n",
      "\n",
      "Fold: 20  Epoch: 335  Training loss = 3.3000  Validation loss = 0.9827  \n",
      "\n",
      "Fold: 20  Epoch: 336  Training loss = 3.2995  Validation loss = 0.9825  \n",
      "\n",
      "Fold: 20  Epoch: 337  Training loss = 3.2990  Validation loss = 0.9824  \n",
      "\n",
      "Fold: 20  Epoch: 338  Training loss = 3.2988  Validation loss = 0.9823  \n",
      "\n",
      "Fold: 20  Epoch: 339  Training loss = 3.2982  Validation loss = 0.9821  \n",
      "\n",
      "Fold: 20  Epoch: 340  Training loss = 3.2977  Validation loss = 0.9821  \n",
      "\n",
      "Fold: 20  Epoch: 341  Training loss = 3.2973  Validation loss = 0.9821  \n",
      "\n",
      "Fold: 20  Epoch: 342  Training loss = 3.2967  Validation loss = 0.9821  \n",
      "\n",
      "Fold: 20  Epoch: 343  Training loss = 3.2964  Validation loss = 0.9820  \n",
      "\n",
      "Fold: 20  Epoch: 344  Training loss = 3.2959  Validation loss = 0.9820  \n",
      "\n",
      "Fold: 20  Epoch: 345  Training loss = 3.2954  Validation loss = 0.9820  \n",
      "\n",
      "Fold: 20  Epoch: 346  Training loss = 3.2950  Validation loss = 0.9819  \n",
      "\n",
      "Fold: 20  Epoch: 347  Training loss = 3.2944  Validation loss = 0.9819  \n",
      "\n",
      "Fold: 20  Epoch: 348  Training loss = 3.2940  Validation loss = 0.9819  \n",
      "\n",
      "Fold: 20  Epoch: 349  Training loss = 3.2937  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 20  Epoch: 350  Training loss = 3.2934  Validation loss = 0.9817  \n",
      "\n",
      "Fold: 20  Epoch: 351  Training loss = 3.2929  Validation loss = 0.9819  \n",
      "\n",
      "Fold: 20  Epoch: 352  Training loss = 3.2924  Validation loss = 0.9817  \n",
      "\n",
      "Fold: 20  Epoch: 353  Training loss = 3.2920  Validation loss = 0.9815  \n",
      "\n",
      "Fold: 20  Epoch: 354  Training loss = 3.2916  Validation loss = 0.9814  \n",
      "\n",
      "Fold: 20  Epoch: 355  Training loss = 3.2912  Validation loss = 0.9815  \n",
      "\n",
      "Fold: 20  Epoch: 356  Training loss = 3.2908  Validation loss = 0.9814  \n",
      "\n",
      "Fold: 20  Epoch: 357  Training loss = 3.2904  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 20  Epoch: 358  Training loss = 3.2900  Validation loss = 0.9812  \n",
      "\n",
      "Fold: 20  Epoch: 359  Training loss = 3.2896  Validation loss = 0.9811  \n",
      "\n",
      "Fold: 20  Epoch: 360  Training loss = 3.2890  Validation loss = 0.9810  \n",
      "\n",
      "Fold: 20  Epoch: 361  Training loss = 3.2886  Validation loss = 0.9810  \n",
      "\n",
      "Fold: 20  Epoch: 362  Training loss = 3.2882  Validation loss = 0.9809  \n",
      "\n",
      "Fold: 20  Epoch: 363  Training loss = 3.2879  Validation loss = 0.9809  \n",
      "\n",
      "Fold: 20  Epoch: 364  Training loss = 3.2874  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 20  Epoch: 365  Training loss = 3.2870  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 20  Epoch: 366  Training loss = 3.2866  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 20  Epoch: 367  Training loss = 3.2862  Validation loss = 0.9807  \n",
      "\n",
      "Fold: 20  Epoch: 368  Training loss = 3.2858  Validation loss = 0.9807  \n",
      "\n",
      "Fold: 20  Epoch: 369  Training loss = 3.2855  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 20  Epoch: 370  Training loss = 3.2850  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 20  Epoch: 371  Training loss = 3.2845  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 20  Epoch: 372  Training loss = 3.2842  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 20  Epoch: 373  Training loss = 3.2838  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 20  Epoch: 374  Training loss = 3.2833  Validation loss = 0.9806  \n",
      "\n",
      "Fold: 20  Epoch: 375  Training loss = 3.2830  Validation loss = 0.9804  \n",
      "\n",
      "Fold: 20  Epoch: 376  Training loss = 3.2827  Validation loss = 0.9805  \n",
      "\n",
      "Fold: 20  Epoch: 377  Training loss = 3.2821  Validation loss = 0.9805  \n",
      "\n",
      "Fold: 20  Epoch: 378  Training loss = 3.2817  Validation loss = 0.9805  \n",
      "\n",
      "Fold: 20  Epoch: 379  Training loss = 3.2814  Validation loss = 0.9804  \n",
      "\n",
      "Fold: 20  Epoch: 380  Training loss = 3.2811  Validation loss = 0.9804  \n",
      "\n",
      "Fold: 20  Epoch: 381  Training loss = 3.2807  Validation loss = 0.9803  \n",
      "\n",
      "Fold: 20  Epoch: 382  Training loss = 3.2803  Validation loss = 0.9802  \n",
      "\n",
      "Fold: 20  Epoch: 383  Training loss = 3.2799  Validation loss = 0.9801  \n",
      "\n",
      "Fold: 20  Epoch: 384  Training loss = 3.2794  Validation loss = 0.9800  \n",
      "\n",
      "Fold: 20  Epoch: 385  Training loss = 3.2792  Validation loss = 0.9800  \n",
      "\n",
      "Fold: 20  Epoch: 386  Training loss = 3.2789  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 20  Epoch: 387  Training loss = 3.2786  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 20  Epoch: 388  Training loss = 3.2782  Validation loss = 0.9798  \n",
      "\n",
      "Fold: 20  Epoch: 389  Training loss = 3.2780  Validation loss = 0.9798  \n",
      "\n",
      "Fold: 20  Epoch: 390  Training loss = 3.2776  Validation loss = 0.9798  \n",
      "\n",
      "Fold: 20  Epoch: 391  Training loss = 3.2774  Validation loss = 0.9796  \n",
      "\n",
      "Fold: 20  Epoch: 392  Training loss = 3.2770  Validation loss = 0.9796  \n",
      "\n",
      "Fold: 20  Epoch: 393  Training loss = 3.2769  Validation loss = 0.9794  \n",
      "\n",
      "Fold: 20  Epoch: 394  Training loss = 3.2767  Validation loss = 0.9793  \n",
      "\n",
      "Fold: 20  Epoch: 395  Training loss = 3.2764  Validation loss = 0.9793  \n",
      "\n",
      "Fold: 20  Epoch: 396  Training loss = 3.2762  Validation loss = 0.9793  \n",
      "\n",
      "Fold: 20  Epoch: 397  Training loss = 3.2759  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 20  Epoch: 398  Training loss = 3.2756  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 20  Epoch: 399  Training loss = 3.2753  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 20  Epoch: 400  Training loss = 3.2749  Validation loss = 0.9792  \n",
      "\n",
      "Fold: 20  Epoch: 401  Training loss = 3.2746  Validation loss = 0.9790  \n",
      "\n",
      "Fold: 20  Epoch: 402  Training loss = 3.2741  Validation loss = 0.9792  \n",
      "\n",
      "Fold: 20  Epoch: 403  Training loss = 3.2738  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 20  Epoch: 404  Training loss = 3.2735  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 20  Epoch: 405  Training loss = 3.2732  Validation loss = 0.9791  \n",
      "\n",
      "Fold: 20  Epoch: 406  Training loss = 3.2727  Validation loss = 0.9790  \n",
      "\n",
      "Fold: 20  Epoch: 407  Training loss = 3.2722  Validation loss = 0.9788  \n",
      "\n",
      "Fold: 20  Epoch: 408  Training loss = 3.2720  Validation loss = 0.9787  \n",
      "\n",
      "Fold: 20  Epoch: 409  Training loss = 3.2717  Validation loss = 0.9785  \n",
      "\n",
      "Fold: 20  Epoch: 410  Training loss = 3.2713  Validation loss = 0.9785  \n",
      "\n",
      "Fold: 20  Epoch: 411  Training loss = 3.2710  Validation loss = 0.9784  \n",
      "\n",
      "Fold: 20  Epoch: 412  Training loss = 3.2706  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 413  Training loss = 3.2703  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 414  Training loss = 3.2700  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 415  Training loss = 3.2696  Validation loss = 0.9784  \n",
      "\n",
      "Fold: 20  Epoch: 416  Training loss = 3.2691  Validation loss = 0.9784  \n",
      "\n",
      "Fold: 20  Epoch: 417  Training loss = 3.2690  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 418  Training loss = 3.2688  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 419  Training loss = 3.2684  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 20  Epoch: 420  Training loss = 3.2681  Validation loss = 0.9782  \n",
      "\n",
      "Fold: 20  Epoch: 421  Training loss = 3.2678  Validation loss = 0.9781  \n",
      "\n",
      "Fold: 20  Epoch: 422  Training loss = 3.2674  Validation loss = 0.9781  \n",
      "\n",
      "Fold: 20  Epoch: 423  Training loss = 3.2670  Validation loss = 0.9781  \n",
      "\n",
      "Fold: 20  Epoch: 424  Training loss = 3.2665  Validation loss = 0.9781  \n",
      "\n",
      "Fold: 20  Epoch: 425  Training loss = 3.2662  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 20  Epoch: 426  Training loss = 3.2658  Validation loss = 0.9779  \n",
      "\n",
      "Fold: 20  Epoch: 427  Training loss = 3.2655  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 20  Epoch: 428  Training loss = 3.2653  Validation loss = 0.9779  \n",
      "\n",
      "Fold: 20  Epoch: 429  Training loss = 3.2649  Validation loss = 0.9779  \n",
      "\n",
      "Fold: 20  Epoch: 430  Training loss = 3.2646  Validation loss = 0.9778  \n",
      "\n",
      "Fold: 20  Epoch: 431  Training loss = 3.2642  Validation loss = 0.9779  \n",
      "\n",
      "Fold: 20  Epoch: 432  Training loss = 3.2638  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 20  Epoch: 433  Training loss = 3.2634  Validation loss = 0.9781  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 430  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 3.2666  Validation loss = 4.4743  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 3.2664  Validation loss = 4.4747  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 3.2659  Validation loss = 4.4755  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 3.2657  Validation loss = 4.4760  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 3.2652  Validation loss = 4.4769  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 3.2647  Validation loss = 4.4780  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 3.2644  Validation loss = 4.4784  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 3.2641  Validation loss = 4.4789  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 3.2636  Validation loss = 4.4798  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 3.2631  Validation loss = 4.4808  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 3.2629  Validation loss = 4.4813  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 3.4391  Validation loss = 3.2558  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 3.4389  Validation loss = 3.2559  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 3.4387  Validation loss = 3.2562  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 3.4384  Validation loss = 3.2563  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 3.4381  Validation loss = 3.2567  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 3.4380  Validation loss = 3.2569  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 3.4379  Validation loss = 3.2567  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 3.4376  Validation loss = 3.2569  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 3.4375  Validation loss = 3.2570  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 3.4373  Validation loss = 3.2573  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 3.4370  Validation loss = 3.2578  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 1  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 3.5072  Validation loss = 2.9494  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 3.5071  Validation loss = 2.9489  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 3.5070  Validation loss = 2.9484  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 3.5068  Validation loss = 2.9489  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 3.5066  Validation loss = 2.9492  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 3.5064  Validation loss = 2.9497  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 3.5062  Validation loss = 2.9499  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 3.5059  Validation loss = 2.9498  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 3.5057  Validation loss = 2.9500  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 3.5053  Validation loss = 2.9501  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 3.5050  Validation loss = 2.9506  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 3  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 3.5107  Validation loss = 1.8255  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 3.5103  Validation loss = 1.8248  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 3.5100  Validation loss = 1.8242  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 3.5098  Validation loss = 1.8238  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 3.5094  Validation loss = 1.8229  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 3.5093  Validation loss = 1.8226  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 3.5091  Validation loss = 1.8220  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 3.5090  Validation loss = 1.8218  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 3.5087  Validation loss = 1.8214  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 3.5085  Validation loss = 1.8212  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 3.5081  Validation loss = 1.8205  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 3.5076  Validation loss = 1.8198  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 3.5073  Validation loss = 1.8192  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 3.5070  Validation loss = 1.8184  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 3.5067  Validation loss = 1.8175  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 3.5064  Validation loss = 1.8170  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 3.5061  Validation loss = 1.8165  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 3.5059  Validation loss = 1.8161  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 3.5057  Validation loss = 1.8159  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 3.5055  Validation loss = 1.8154  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 3.5052  Validation loss = 1.8147  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 3.5048  Validation loss = 1.8140  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 3.5046  Validation loss = 1.8137  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 3.5044  Validation loss = 1.8132  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 3.5041  Validation loss = 1.8126  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 3.5038  Validation loss = 1.8120  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 3.5035  Validation loss = 1.8115  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 3.5032  Validation loss = 1.8107  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 3.5029  Validation loss = 1.8102  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 3.5025  Validation loss = 1.8094  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 3.5022  Validation loss = 1.8089  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 3.5019  Validation loss = 1.8080  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 3.5017  Validation loss = 1.8077  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 3.5014  Validation loss = 1.8074  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 3.5012  Validation loss = 1.8069  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 3.5010  Validation loss = 1.8064  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 3.5007  Validation loss = 1.8060  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 3.5004  Validation loss = 1.8055  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 3.5002  Validation loss = 1.8051  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 3.5000  Validation loss = 1.8047  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 3.4998  Validation loss = 1.8042  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 3.4996  Validation loss = 1.8038  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 3.4994  Validation loss = 1.8033  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 3.4990  Validation loss = 1.8029  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 3.4988  Validation loss = 1.8028  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 3.4985  Validation loss = 1.8021  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 3.4984  Validation loss = 1.8018  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 3.4981  Validation loss = 1.8009  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 3.4977  Validation loss = 1.8002  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 3.4974  Validation loss = 1.7996  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 3.4970  Validation loss = 1.7989  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 3.4967  Validation loss = 1.7980  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 3.4963  Validation loss = 1.7976  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 3.4962  Validation loss = 1.7972  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 3.4958  Validation loss = 1.7966  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 3.4955  Validation loss = 1.7960  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 3.4952  Validation loss = 1.7956  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 3.4950  Validation loss = 1.7952  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 3.4947  Validation loss = 1.7946  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 3.4945  Validation loss = 1.7941  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 3.4943  Validation loss = 1.7937  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 3.4939  Validation loss = 1.7928  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 3.4937  Validation loss = 1.7924  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 3.4934  Validation loss = 1.7918  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 3.4930  Validation loss = 1.7912  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 3.4928  Validation loss = 1.7907  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 3.4925  Validation loss = 1.7902  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 3.4921  Validation loss = 1.7894  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 3.4918  Validation loss = 1.7891  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 3.4916  Validation loss = 1.7886  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 3.4913  Validation loss = 1.7883  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 3.4911  Validation loss = 1.7879  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 3.4908  Validation loss = 1.7873  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 3.4906  Validation loss = 1.7869  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 3.4904  Validation loss = 1.7863  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 3.4901  Validation loss = 1.7857  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 3.4897  Validation loss = 1.7849  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 3.4894  Validation loss = 1.7847  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 3.4892  Validation loss = 1.7842  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 3.4889  Validation loss = 1.7834  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 3.4884  Validation loss = 1.7827  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 3.4881  Validation loss = 1.7822  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 3.4879  Validation loss = 1.7818  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 3.4877  Validation loss = 1.7814  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 3.4874  Validation loss = 1.7808  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 3.4871  Validation loss = 1.7804  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 3.4868  Validation loss = 1.7800  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 3.4867  Validation loss = 1.7796  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 3.4864  Validation loss = 1.7791  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 3.4863  Validation loss = 1.7788  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 3.4860  Validation loss = 1.7784  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 3.4859  Validation loss = 1.7781  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 3.4855  Validation loss = 1.7774  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 3.4852  Validation loss = 1.7768  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 3.4850  Validation loss = 1.7765  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 3.4848  Validation loss = 1.7759  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 3.4843  Validation loss = 1.7751  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 3.4840  Validation loss = 1.7741  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 3.4837  Validation loss = 1.7734  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 3.4836  Validation loss = 1.7732  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 3.4835  Validation loss = 1.7729  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 3.4834  Validation loss = 1.7726  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 3.4832  Validation loss = 1.7722  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 3.4828  Validation loss = 1.7716  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 3.4825  Validation loss = 1.7709  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 3.4822  Validation loss = 1.7705  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 3.4819  Validation loss = 1.7701  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 3.4816  Validation loss = 1.7696  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 3.4815  Validation loss = 1.7694  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 3.4811  Validation loss = 1.7687  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 3.4810  Validation loss = 1.7684  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 3.4808  Validation loss = 1.7680  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 3.4804  Validation loss = 1.7673  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 3.4801  Validation loss = 1.7670  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 3.4798  Validation loss = 1.7664  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 3.4796  Validation loss = 1.7658  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 3.4793  Validation loss = 1.7653  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 3.4792  Validation loss = 1.7652  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 3.4790  Validation loss = 1.7645  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 3.4788  Validation loss = 1.7642  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 3.4786  Validation loss = 1.7636  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 3.4783  Validation loss = 1.7630  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 3.4779  Validation loss = 1.7624  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 3.4777  Validation loss = 1.7619  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 3.4775  Validation loss = 1.7616  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 3.4772  Validation loss = 1.7614  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 3.4771  Validation loss = 1.7611  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 3.4769  Validation loss = 1.7605  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 3.4767  Validation loss = 1.7603  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 3.4765  Validation loss = 1.7600  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 3.4761  Validation loss = 1.7593  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 3.4758  Validation loss = 1.7585  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 3.4755  Validation loss = 1.7579  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 3.4753  Validation loss = 1.7572  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 3.4751  Validation loss = 1.7570  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 3.4748  Validation loss = 1.7566  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 3.4745  Validation loss = 1.7559  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 3.4743  Validation loss = 1.7554  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 3.4741  Validation loss = 1.7549  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 3.4739  Validation loss = 1.7547  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 3.4738  Validation loss = 1.7546  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 3.4736  Validation loss = 1.7540  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 3.4734  Validation loss = 1.7538  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 3.4732  Validation loss = 1.7534  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 3.4730  Validation loss = 1.7531  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 3.4727  Validation loss = 1.7528  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 3.4724  Validation loss = 1.7520  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 3.4723  Validation loss = 1.7518  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 3.4721  Validation loss = 1.7514  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 3.4719  Validation loss = 1.7507  \n",
      "\n",
      "Fold: 24  Epoch: 151  Training loss = 3.4716  Validation loss = 1.7504  \n",
      "\n",
      "Fold: 24  Epoch: 152  Training loss = 3.4716  Validation loss = 1.7502  \n",
      "\n",
      "Fold: 24  Epoch: 153  Training loss = 3.4712  Validation loss = 1.7494  \n",
      "\n",
      "Fold: 24  Epoch: 154  Training loss = 3.4710  Validation loss = 1.7490  \n",
      "\n",
      "Fold: 24  Epoch: 155  Training loss = 3.4708  Validation loss = 1.7484  \n",
      "\n",
      "Fold: 24  Epoch: 156  Training loss = 3.4706  Validation loss = 1.7481  \n",
      "\n",
      "Fold: 24  Epoch: 157  Training loss = 3.4704  Validation loss = 1.7479  \n",
      "\n",
      "Fold: 24  Epoch: 158  Training loss = 3.4702  Validation loss = 1.7476  \n",
      "\n",
      "Fold: 24  Epoch: 159  Training loss = 3.4700  Validation loss = 1.7475  \n",
      "\n",
      "Fold: 24  Epoch: 160  Training loss = 3.4697  Validation loss = 1.7469  \n",
      "\n",
      "Fold: 24  Epoch: 161  Training loss = 3.4694  Validation loss = 1.7466  \n",
      "\n",
      "Fold: 24  Epoch: 162  Training loss = 3.4691  Validation loss = 1.7460  \n",
      "\n",
      "Fold: 24  Epoch: 163  Training loss = 3.4689  Validation loss = 1.7457  \n",
      "\n",
      "Fold: 24  Epoch: 164  Training loss = 3.4685  Validation loss = 1.7451  \n",
      "\n",
      "Fold: 24  Epoch: 165  Training loss = 3.4682  Validation loss = 1.7444  \n",
      "\n",
      "Fold: 24  Epoch: 166  Training loss = 3.4680  Validation loss = 1.7440  \n",
      "\n",
      "Fold: 24  Epoch: 167  Training loss = 3.4678  Validation loss = 1.7435  \n",
      "\n",
      "Fold: 24  Epoch: 168  Training loss = 3.4676  Validation loss = 1.7432  \n",
      "\n",
      "Fold: 24  Epoch: 169  Training loss = 3.4674  Validation loss = 1.7428  \n",
      "\n",
      "Fold: 24  Epoch: 170  Training loss = 3.4671  Validation loss = 1.7424  \n",
      "\n",
      "Fold: 24  Epoch: 171  Training loss = 3.4669  Validation loss = 1.7420  \n",
      "\n",
      "Fold: 24  Epoch: 172  Training loss = 3.4667  Validation loss = 1.7413  \n",
      "\n",
      "Fold: 24  Epoch: 173  Training loss = 3.4664  Validation loss = 1.7408  \n",
      "\n",
      "Fold: 24  Epoch: 174  Training loss = 3.4662  Validation loss = 1.7406  \n",
      "\n",
      "Fold: 24  Epoch: 175  Training loss = 3.4659  Validation loss = 1.7401  \n",
      "\n",
      "Fold: 24  Epoch: 176  Training loss = 3.4657  Validation loss = 1.7394  \n",
      "\n",
      "Fold: 24  Epoch: 177  Training loss = 3.4654  Validation loss = 1.7393  \n",
      "\n",
      "Fold: 24  Epoch: 178  Training loss = 3.4652  Validation loss = 1.7388  \n",
      "\n",
      "Fold: 24  Epoch: 179  Training loss = 3.4650  Validation loss = 1.7381  \n",
      "\n",
      "Fold: 24  Epoch: 180  Training loss = 3.4647  Validation loss = 1.7372  \n",
      "\n",
      "Fold: 24  Epoch: 181  Training loss = 3.4644  Validation loss = 1.7367  \n",
      "\n",
      "Fold: 24  Epoch: 182  Training loss = 3.4642  Validation loss = 1.7363  \n",
      "\n",
      "Fold: 24  Epoch: 183  Training loss = 3.4640  Validation loss = 1.7360  \n",
      "\n",
      "Fold: 24  Epoch: 184  Training loss = 3.4638  Validation loss = 1.7360  \n",
      "\n",
      "Fold: 24  Epoch: 185  Training loss = 3.4637  Validation loss = 1.7358  \n",
      "\n",
      "Fold: 24  Epoch: 186  Training loss = 3.4634  Validation loss = 1.7352  \n",
      "\n",
      "Fold: 24  Epoch: 187  Training loss = 3.4632  Validation loss = 1.7348  \n",
      "\n",
      "Fold: 24  Epoch: 188  Training loss = 3.4630  Validation loss = 1.7343  \n",
      "\n",
      "Fold: 24  Epoch: 189  Training loss = 3.4626  Validation loss = 1.7336  \n",
      "\n",
      "Fold: 24  Epoch: 190  Training loss = 3.4627  Validation loss = 1.7336  \n",
      "\n",
      "Fold: 24  Epoch: 191  Training loss = 3.4625  Validation loss = 1.7334  \n",
      "\n",
      "Fold: 24  Epoch: 192  Training loss = 3.4622  Validation loss = 1.7330  \n",
      "\n",
      "Fold: 24  Epoch: 193  Training loss = 3.4619  Validation loss = 1.7322  \n",
      "\n",
      "Fold: 24  Epoch: 194  Training loss = 3.4616  Validation loss = 1.7316  \n",
      "\n",
      "Fold: 24  Epoch: 195  Training loss = 3.4613  Validation loss = 1.7312  \n",
      "\n",
      "Fold: 24  Epoch: 196  Training loss = 3.4612  Validation loss = 1.7311  \n",
      "\n",
      "Fold: 24  Epoch: 197  Training loss = 3.4609  Validation loss = 1.7305  \n",
      "\n",
      "Fold: 24  Epoch: 198  Training loss = 3.4607  Validation loss = 1.7299  \n",
      "\n",
      "Fold: 24  Epoch: 199  Training loss = 3.4603  Validation loss = 1.7294  \n",
      "\n",
      "Fold: 24  Epoch: 200  Training loss = 3.4602  Validation loss = 1.7290  \n",
      "\n",
      "Fold: 24  Epoch: 201  Training loss = 3.4599  Validation loss = 1.7286  \n",
      "\n",
      "Fold: 24  Epoch: 202  Training loss = 3.4597  Validation loss = 1.7281  \n",
      "\n",
      "Fold: 24  Epoch: 203  Training loss = 3.4594  Validation loss = 1.7277  \n",
      "\n",
      "Fold: 24  Epoch: 204  Training loss = 3.4590  Validation loss = 1.7273  \n",
      "\n",
      "Fold: 24  Epoch: 205  Training loss = 3.4587  Validation loss = 1.7269  \n",
      "\n",
      "Fold: 24  Epoch: 206  Training loss = 3.4585  Validation loss = 1.7265  \n",
      "\n",
      "Fold: 24  Epoch: 207  Training loss = 3.4582  Validation loss = 1.7259  \n",
      "\n",
      "Fold: 24  Epoch: 208  Training loss = 3.4579  Validation loss = 1.7254  \n",
      "\n",
      "Fold: 24  Epoch: 209  Training loss = 3.4577  Validation loss = 1.7252  \n",
      "\n",
      "Fold: 24  Epoch: 210  Training loss = 3.4575  Validation loss = 1.7248  \n",
      "\n",
      "Fold: 24  Epoch: 211  Training loss = 3.4572  Validation loss = 1.7245  \n",
      "\n",
      "Fold: 24  Epoch: 212  Training loss = 3.4570  Validation loss = 1.7239  \n",
      "\n",
      "Fold: 24  Epoch: 213  Training loss = 3.4567  Validation loss = 1.7234  \n",
      "\n",
      "Fold: 24  Epoch: 214  Training loss = 3.4565  Validation loss = 1.7231  \n",
      "\n",
      "Fold: 24  Epoch: 215  Training loss = 3.4562  Validation loss = 1.7227  \n",
      "\n",
      "Fold: 24  Epoch: 216  Training loss = 3.4561  Validation loss = 1.7228  \n",
      "\n",
      "Fold: 24  Epoch: 217  Training loss = 3.4559  Validation loss = 1.7224  \n",
      "\n",
      "Fold: 24  Epoch: 218  Training loss = 3.4557  Validation loss = 1.7221  \n",
      "\n",
      "Fold: 24  Epoch: 219  Training loss = 3.4553  Validation loss = 1.7215  \n",
      "\n",
      "Fold: 24  Epoch: 220  Training loss = 3.4551  Validation loss = 1.7211  \n",
      "\n",
      "Fold: 24  Epoch: 221  Training loss = 3.4549  Validation loss = 1.7208  \n",
      "\n",
      "Fold: 24  Epoch: 222  Training loss = 3.4546  Validation loss = 1.7202  \n",
      "\n",
      "Fold: 24  Epoch: 223  Training loss = 3.4545  Validation loss = 1.7199  \n",
      "\n",
      "Fold: 24  Epoch: 224  Training loss = 3.4540  Validation loss = 1.7193  \n",
      "\n",
      "Fold: 24  Epoch: 225  Training loss = 3.4539  Validation loss = 1.7191  \n",
      "\n",
      "Fold: 24  Epoch: 226  Training loss = 3.4537  Validation loss = 1.7187  \n",
      "\n",
      "Fold: 24  Epoch: 227  Training loss = 3.4535  Validation loss = 1.7184  \n",
      "\n",
      "Fold: 24  Epoch: 228  Training loss = 3.4532  Validation loss = 1.7177  \n",
      "\n",
      "Fold: 24  Epoch: 229  Training loss = 3.4529  Validation loss = 1.7171  \n",
      "\n",
      "Fold: 24  Epoch: 230  Training loss = 3.4525  Validation loss = 1.7165  \n",
      "\n",
      "Fold: 24  Epoch: 231  Training loss = 3.4522  Validation loss = 1.7163  \n",
      "\n",
      "Fold: 24  Epoch: 232  Training loss = 3.4520  Validation loss = 1.7158  \n",
      "\n",
      "Fold: 24  Epoch: 233  Training loss = 3.4517  Validation loss = 1.7154  \n",
      "\n",
      "Fold: 24  Epoch: 234  Training loss = 3.4514  Validation loss = 1.7149  \n",
      "\n",
      "Fold: 24  Epoch: 235  Training loss = 3.4512  Validation loss = 1.7145  \n",
      "\n",
      "Fold: 24  Epoch: 236  Training loss = 3.4509  Validation loss = 1.7142  \n",
      "\n",
      "Fold: 24  Epoch: 237  Training loss = 3.4507  Validation loss = 1.7137  \n",
      "\n",
      "Fold: 24  Epoch: 238  Training loss = 3.4504  Validation loss = 1.7133  \n",
      "\n",
      "Fold: 24  Epoch: 239  Training loss = 3.4501  Validation loss = 1.7129  \n",
      "\n",
      "Fold: 24  Epoch: 240  Training loss = 3.4498  Validation loss = 1.7124  \n",
      "\n",
      "Fold: 24  Epoch: 241  Training loss = 3.4496  Validation loss = 1.7119  \n",
      "\n",
      "Fold: 24  Epoch: 242  Training loss = 3.4494  Validation loss = 1.7118  \n",
      "\n",
      "Fold: 24  Epoch: 243  Training loss = 3.4492  Validation loss = 1.7112  \n",
      "\n",
      "Fold: 24  Epoch: 244  Training loss = 3.4490  Validation loss = 1.7110  \n",
      "\n",
      "Fold: 24  Epoch: 245  Training loss = 3.4487  Validation loss = 1.7105  \n",
      "\n",
      "Fold: 24  Epoch: 246  Training loss = 3.4485  Validation loss = 1.7101  \n",
      "\n",
      "Fold: 24  Epoch: 247  Training loss = 3.4483  Validation loss = 1.7096  \n",
      "\n",
      "Fold: 24  Epoch: 248  Training loss = 3.4480  Validation loss = 1.7090  \n",
      "\n",
      "Fold: 24  Epoch: 249  Training loss = 3.4477  Validation loss = 1.7087  \n",
      "\n",
      "Fold: 24  Epoch: 250  Training loss = 3.4474  Validation loss = 1.7083  \n",
      "\n",
      "Fold: 24  Epoch: 251  Training loss = 3.4472  Validation loss = 1.7079  \n",
      "\n",
      "Fold: 24  Epoch: 252  Training loss = 3.4469  Validation loss = 1.7075  \n",
      "\n",
      "Fold: 24  Epoch: 253  Training loss = 3.4466  Validation loss = 1.7073  \n",
      "\n",
      "Fold: 24  Epoch: 254  Training loss = 3.4465  Validation loss = 1.7070  \n",
      "\n",
      "Fold: 24  Epoch: 255  Training loss = 3.4463  Validation loss = 1.7064  \n",
      "\n",
      "Fold: 24  Epoch: 256  Training loss = 3.4461  Validation loss = 1.7061  \n",
      "\n",
      "Fold: 24  Epoch: 257  Training loss = 3.4458  Validation loss = 1.7057  \n",
      "\n",
      "Fold: 24  Epoch: 258  Training loss = 3.4456  Validation loss = 1.7053  \n",
      "\n",
      "Fold: 24  Epoch: 259  Training loss = 3.4452  Validation loss = 1.7045  \n",
      "\n",
      "Fold: 24  Epoch: 260  Training loss = 3.4449  Validation loss = 1.7041  \n",
      "\n",
      "Fold: 24  Epoch: 261  Training loss = 3.4446  Validation loss = 1.7037  \n",
      "\n",
      "Fold: 24  Epoch: 262  Training loss = 3.4445  Validation loss = 1.7033  \n",
      "\n",
      "Fold: 24  Epoch: 263  Training loss = 3.4443  Validation loss = 1.7032  \n",
      "\n",
      "Fold: 24  Epoch: 264  Training loss = 3.4440  Validation loss = 1.7025  \n",
      "\n",
      "Fold: 24  Epoch: 265  Training loss = 3.4438  Validation loss = 1.7023  \n",
      "\n",
      "Fold: 24  Epoch: 266  Training loss = 3.4436  Validation loss = 1.7018  \n",
      "\n",
      "Fold: 24  Epoch: 267  Training loss = 3.4434  Validation loss = 1.7013  \n",
      "\n",
      "Fold: 24  Epoch: 268  Training loss = 3.4433  Validation loss = 1.7010  \n",
      "\n",
      "Fold: 24  Epoch: 269  Training loss = 3.4432  Validation loss = 1.7008  \n",
      "\n",
      "Fold: 24  Epoch: 270  Training loss = 3.4430  Validation loss = 1.7005  \n",
      "\n",
      "Fold: 24  Epoch: 271  Training loss = 3.4429  Validation loss = 1.7003  \n",
      "\n",
      "Fold: 24  Epoch: 272  Training loss = 3.4427  Validation loss = 1.7002  \n",
      "\n",
      "Fold: 24  Epoch: 273  Training loss = 3.4425  Validation loss = 1.7000  \n",
      "\n",
      "Fold: 24  Epoch: 274  Training loss = 3.4422  Validation loss = 1.6996  \n",
      "\n",
      "Fold: 24  Epoch: 275  Training loss = 3.4420  Validation loss = 1.6996  \n",
      "\n",
      "Fold: 24  Epoch: 276  Training loss = 3.4418  Validation loss = 1.6992  \n",
      "\n",
      "Fold: 24  Epoch: 277  Training loss = 3.4414  Validation loss = 1.6986  \n",
      "\n",
      "Fold: 24  Epoch: 278  Training loss = 3.4414  Validation loss = 1.6987  \n",
      "\n",
      "Fold: 24  Epoch: 279  Training loss = 3.4412  Validation loss = 1.6984  \n",
      "\n",
      "Fold: 24  Epoch: 280  Training loss = 3.4410  Validation loss = 1.6981  \n",
      "\n",
      "Fold: 24  Epoch: 281  Training loss = 3.4409  Validation loss = 1.6981  \n",
      "\n",
      "Fold: 24  Epoch: 282  Training loss = 3.4405  Validation loss = 1.6974  \n",
      "\n",
      "Fold: 24  Epoch: 283  Training loss = 3.4403  Validation loss = 1.6971  \n",
      "\n",
      "Fold: 24  Epoch: 284  Training loss = 3.4401  Validation loss = 1.6966  \n",
      "\n",
      "Fold: 24  Epoch: 285  Training loss = 3.4400  Validation loss = 1.6966  \n",
      "\n",
      "Fold: 24  Epoch: 286  Training loss = 3.4397  Validation loss = 1.6959  \n",
      "\n",
      "Fold: 24  Epoch: 287  Training loss = 3.4394  Validation loss = 1.6954  \n",
      "\n",
      "Fold: 24  Epoch: 288  Training loss = 3.4391  Validation loss = 1.6950  \n",
      "\n",
      "Fold: 24  Epoch: 289  Training loss = 3.4390  Validation loss = 1.6949  \n",
      "\n",
      "Fold: 24  Epoch: 290  Training loss = 3.4388  Validation loss = 1.6943  \n",
      "\n",
      "Fold: 24  Epoch: 291  Training loss = 3.4385  Validation loss = 1.6937  \n",
      "\n",
      "Fold: 24  Epoch: 292  Training loss = 3.4385  Validation loss = 1.6936  \n",
      "\n",
      "Fold: 24  Epoch: 293  Training loss = 3.4382  Validation loss = 1.6932  \n",
      "\n",
      "Fold: 24  Epoch: 294  Training loss = 3.4380  Validation loss = 1.6929  \n",
      "\n",
      "Fold: 24  Epoch: 295  Training loss = 3.4377  Validation loss = 1.6922  \n",
      "\n",
      "Fold: 24  Epoch: 296  Training loss = 3.4375  Validation loss = 1.6921  \n",
      "\n",
      "Fold: 24  Epoch: 297  Training loss = 3.4373  Validation loss = 1.6918  \n",
      "\n",
      "Fold: 24  Epoch: 298  Training loss = 3.4370  Validation loss = 1.6912  \n",
      "\n",
      "Fold: 24  Epoch: 299  Training loss = 3.4367  Validation loss = 1.6909  \n",
      "\n",
      "Fold: 24  Epoch: 300  Training loss = 3.4365  Validation loss = 1.6902  \n",
      "\n",
      "Fold: 24  Epoch: 301  Training loss = 3.4361  Validation loss = 1.6898  \n",
      "\n",
      "Fold: 24  Epoch: 302  Training loss = 3.4360  Validation loss = 1.6895  \n",
      "\n",
      "Fold: 24  Epoch: 303  Training loss = 3.4359  Validation loss = 1.6892  \n",
      "\n",
      "Fold: 24  Epoch: 304  Training loss = 3.4357  Validation loss = 1.6890  \n",
      "\n",
      "Fold: 24  Epoch: 305  Training loss = 3.4354  Validation loss = 1.6888  \n",
      "\n",
      "Fold: 24  Epoch: 306  Training loss = 3.4352  Validation loss = 1.6882  \n",
      "\n",
      "Fold: 24  Epoch: 307  Training loss = 3.4348  Validation loss = 1.6878  \n",
      "\n",
      "Fold: 24  Epoch: 308  Training loss = 3.4346  Validation loss = 1.6875  \n",
      "\n",
      "Fold: 24  Epoch: 309  Training loss = 3.4343  Validation loss = 1.6868  \n",
      "\n",
      "Fold: 24  Epoch: 310  Training loss = 3.4340  Validation loss = 1.6863  \n",
      "\n",
      "Fold: 24  Epoch: 311  Training loss = 3.4339  Validation loss = 1.6860  \n",
      "\n",
      "Fold: 24  Epoch: 312  Training loss = 3.4338  Validation loss = 1.6858  \n",
      "\n",
      "Fold: 24  Epoch: 313  Training loss = 3.4334  Validation loss = 1.6853  \n",
      "\n",
      "Fold: 24  Epoch: 314  Training loss = 3.4334  Validation loss = 1.6851  \n",
      "\n",
      "Fold: 24  Epoch: 315  Training loss = 3.4332  Validation loss = 1.6847  \n",
      "\n",
      "Fold: 24  Epoch: 316  Training loss = 3.4330  Validation loss = 1.6842  \n",
      "\n",
      "Fold: 24  Epoch: 317  Training loss = 3.4328  Validation loss = 1.6835  \n",
      "\n",
      "Fold: 24  Epoch: 318  Training loss = 3.4326  Validation loss = 1.6830  \n",
      "\n",
      "Fold: 24  Epoch: 319  Training loss = 3.4324  Validation loss = 1.6824  \n",
      "\n",
      "Fold: 24  Epoch: 320  Training loss = 3.4322  Validation loss = 1.6822  \n",
      "\n",
      "Fold: 24  Epoch: 321  Training loss = 3.4320  Validation loss = 1.6817  \n",
      "\n",
      "Fold: 24  Epoch: 322  Training loss = 3.4316  Validation loss = 1.6811  \n",
      "\n",
      "Fold: 24  Epoch: 323  Training loss = 3.4314  Validation loss = 1.6805  \n",
      "\n",
      "Fold: 24  Epoch: 324  Training loss = 3.4312  Validation loss = 1.6803  \n",
      "\n",
      "Fold: 24  Epoch: 325  Training loss = 3.4309  Validation loss = 1.6795  \n",
      "\n",
      "Fold: 24  Epoch: 326  Training loss = 3.4308  Validation loss = 1.6792  \n",
      "\n",
      "Fold: 24  Epoch: 327  Training loss = 3.4305  Validation loss = 1.6787  \n",
      "\n",
      "Fold: 24  Epoch: 328  Training loss = 3.4303  Validation loss = 1.6781  \n",
      "\n",
      "Fold: 24  Epoch: 329  Training loss = 3.4302  Validation loss = 1.6780  \n",
      "\n",
      "Fold: 24  Epoch: 330  Training loss = 3.4300  Validation loss = 1.6776  \n",
      "\n",
      "Fold: 24  Epoch: 331  Training loss = 3.4298  Validation loss = 1.6773  \n",
      "\n",
      "Fold: 24  Epoch: 332  Training loss = 3.4295  Validation loss = 1.6769  \n",
      "\n",
      "Fold: 24  Epoch: 333  Training loss = 3.4294  Validation loss = 1.6764  \n",
      "\n",
      "Fold: 24  Epoch: 334  Training loss = 3.4292  Validation loss = 1.6761  \n",
      "\n",
      "Fold: 24  Epoch: 335  Training loss = 3.4291  Validation loss = 1.6758  \n",
      "\n",
      "Fold: 24  Epoch: 336  Training loss = 3.4289  Validation loss = 1.6757  \n",
      "\n",
      "Fold: 24  Epoch: 337  Training loss = 3.4285  Validation loss = 1.6750  \n",
      "\n",
      "Fold: 24  Epoch: 338  Training loss = 3.4282  Validation loss = 1.6744  \n",
      "\n",
      "Fold: 24  Epoch: 339  Training loss = 3.4279  Validation loss = 1.6741  \n",
      "\n",
      "Fold: 24  Epoch: 340  Training loss = 3.4277  Validation loss = 1.6735  \n",
      "\n",
      "Fold: 24  Epoch: 341  Training loss = 3.4273  Validation loss = 1.6730  \n",
      "\n",
      "Fold: 24  Epoch: 342  Training loss = 3.4270  Validation loss = 1.6724  \n",
      "\n",
      "Fold: 24  Epoch: 343  Training loss = 3.4268  Validation loss = 1.6720  \n",
      "\n",
      "Fold: 24  Epoch: 344  Training loss = 3.4267  Validation loss = 1.6719  \n",
      "\n",
      "Fold: 24  Epoch: 345  Training loss = 3.4264  Validation loss = 1.6714  \n",
      "\n",
      "Fold: 24  Epoch: 346  Training loss = 3.4262  Validation loss = 1.6712  \n",
      "\n",
      "Fold: 24  Epoch: 347  Training loss = 3.4260  Validation loss = 1.6709  \n",
      "\n",
      "Fold: 24  Epoch: 348  Training loss = 3.4257  Validation loss = 1.6703  \n",
      "\n",
      "Fold: 24  Epoch: 349  Training loss = 3.4254  Validation loss = 1.6698  \n",
      "\n",
      "Fold: 24  Epoch: 350  Training loss = 3.4252  Validation loss = 1.6697  \n",
      "\n",
      "Fold: 24  Epoch: 351  Training loss = 3.4252  Validation loss = 1.6694  \n",
      "\n",
      "Fold: 24  Epoch: 352  Training loss = 3.4249  Validation loss = 1.6689  \n",
      "\n",
      "Fold: 24  Epoch: 353  Training loss = 3.4247  Validation loss = 1.6688  \n",
      "\n",
      "Fold: 24  Epoch: 354  Training loss = 3.4245  Validation loss = 1.6682  \n",
      "\n",
      "Fold: 24  Epoch: 355  Training loss = 3.4242  Validation loss = 1.6679  \n",
      "\n",
      "Fold: 24  Epoch: 356  Training loss = 3.4240  Validation loss = 1.6676  \n",
      "\n",
      "Fold: 24  Epoch: 357  Training loss = 3.4238  Validation loss = 1.6673  \n",
      "\n",
      "Fold: 24  Epoch: 358  Training loss = 3.4238  Validation loss = 1.6673  \n",
      "\n",
      "Fold: 24  Epoch: 359  Training loss = 3.4236  Validation loss = 1.6669  \n",
      "\n",
      "Fold: 24  Epoch: 360  Training loss = 3.4235  Validation loss = 1.6667  \n",
      "\n",
      "Fold: 24  Epoch: 361  Training loss = 3.4233  Validation loss = 1.6663  \n",
      "\n",
      "Fold: 24  Epoch: 362  Training loss = 3.4232  Validation loss = 1.6659  \n",
      "\n",
      "Fold: 24  Epoch: 363  Training loss = 3.4230  Validation loss = 1.6655  \n",
      "\n",
      "Fold: 24  Epoch: 364  Training loss = 3.4228  Validation loss = 1.6653  \n",
      "\n",
      "Fold: 24  Epoch: 365  Training loss = 3.4226  Validation loss = 1.6650  \n",
      "\n",
      "Fold: 24  Epoch: 366  Training loss = 3.4224  Validation loss = 1.6646  \n",
      "\n",
      "Fold: 24  Epoch: 367  Training loss = 3.4223  Validation loss = 1.6643  \n",
      "\n",
      "Fold: 24  Epoch: 368  Training loss = 3.4222  Validation loss = 1.6641  \n",
      "\n",
      "Fold: 24  Epoch: 369  Training loss = 3.4219  Validation loss = 1.6633  \n",
      "\n",
      "Fold: 24  Epoch: 370  Training loss = 3.4216  Validation loss = 1.6626  \n",
      "\n",
      "Fold: 24  Epoch: 371  Training loss = 3.4213  Validation loss = 1.6622  \n",
      "\n",
      "Fold: 24  Epoch: 372  Training loss = 3.4211  Validation loss = 1.6621  \n",
      "\n",
      "Fold: 24  Epoch: 373  Training loss = 3.4208  Validation loss = 1.6615  \n",
      "\n",
      "Fold: 24  Epoch: 374  Training loss = 3.4206  Validation loss = 1.6612  \n",
      "\n",
      "Fold: 24  Epoch: 375  Training loss = 3.4204  Validation loss = 1.6608  \n",
      "\n",
      "Fold: 24  Epoch: 376  Training loss = 3.4202  Validation loss = 1.6605  \n",
      "\n",
      "Fold: 24  Epoch: 377  Training loss = 3.4200  Validation loss = 1.6602  \n",
      "\n",
      "Fold: 24  Epoch: 378  Training loss = 3.4198  Validation loss = 1.6600  \n",
      "\n",
      "Fold: 24  Epoch: 379  Training loss = 3.4197  Validation loss = 1.6597  \n",
      "\n",
      "Fold: 24  Epoch: 380  Training loss = 3.4194  Validation loss = 1.6592  \n",
      "\n",
      "Fold: 24  Epoch: 381  Training loss = 3.4191  Validation loss = 1.6588  \n",
      "\n",
      "Fold: 24  Epoch: 382  Training loss = 3.4189  Validation loss = 1.6585  \n",
      "\n",
      "Fold: 24  Epoch: 383  Training loss = 3.4188  Validation loss = 1.6582  \n",
      "\n",
      "Fold: 24  Epoch: 384  Training loss = 3.4185  Validation loss = 1.6579  \n",
      "\n",
      "Fold: 24  Epoch: 385  Training loss = 3.4184  Validation loss = 1.6576  \n",
      "\n",
      "Fold: 24  Epoch: 386  Training loss = 3.4181  Validation loss = 1.6574  \n",
      "\n",
      "Fold: 24  Epoch: 387  Training loss = 3.4180  Validation loss = 1.6570  \n",
      "\n",
      "Fold: 24  Epoch: 388  Training loss = 3.4178  Validation loss = 1.6567  \n",
      "\n",
      "Fold: 24  Epoch: 389  Training loss = 3.4176  Validation loss = 1.6561  \n",
      "\n",
      "Fold: 24  Epoch: 390  Training loss = 3.4172  Validation loss = 1.6556  \n",
      "\n",
      "Fold: 24  Epoch: 391  Training loss = 3.4170  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 24  Epoch: 392  Training loss = 3.4168  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 24  Epoch: 393  Training loss = 3.4166  Validation loss = 1.6549  \n",
      "\n",
      "Fold: 24  Epoch: 394  Training loss = 3.4164  Validation loss = 1.6548  \n",
      "\n",
      "Fold: 24  Epoch: 395  Training loss = 3.4162  Validation loss = 1.6547  \n",
      "\n",
      "Fold: 24  Epoch: 396  Training loss = 3.4159  Validation loss = 1.6542  \n",
      "\n",
      "Fold: 24  Epoch: 397  Training loss = 3.4159  Validation loss = 1.6542  \n",
      "\n",
      "Fold: 24  Epoch: 398  Training loss = 3.4157  Validation loss = 1.6541  \n",
      "\n",
      "Fold: 24  Epoch: 399  Training loss = 3.4156  Validation loss = 1.6538  \n",
      "\n",
      "Fold: 24  Epoch: 400  Training loss = 3.4155  Validation loss = 1.6538  \n",
      "\n",
      "Fold: 24  Epoch: 401  Training loss = 3.4151  Validation loss = 1.6532  \n",
      "\n",
      "Fold: 24  Epoch: 402  Training loss = 3.4148  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 24  Epoch: 403  Training loss = 3.4145  Validation loss = 1.6519  \n",
      "\n",
      "Fold: 24  Epoch: 404  Training loss = 3.4142  Validation loss = 1.6514  \n",
      "\n",
      "Fold: 24  Epoch: 405  Training loss = 3.4140  Validation loss = 1.6510  \n",
      "\n",
      "Fold: 24  Epoch: 406  Training loss = 3.4137  Validation loss = 1.6504  \n",
      "\n",
      "Fold: 24  Epoch: 407  Training loss = 3.4135  Validation loss = 1.6500  \n",
      "\n",
      "Fold: 24  Epoch: 408  Training loss = 3.4134  Validation loss = 1.6498  \n",
      "\n",
      "Fold: 24  Epoch: 409  Training loss = 3.4131  Validation loss = 1.6494  \n",
      "\n",
      "Fold: 24  Epoch: 410  Training loss = 3.4130  Validation loss = 1.6492  \n",
      "\n",
      "Fold: 24  Epoch: 411  Training loss = 3.4127  Validation loss = 1.6488  \n",
      "\n",
      "Fold: 24  Epoch: 412  Training loss = 3.4126  Validation loss = 1.6484  \n",
      "\n",
      "Fold: 24  Epoch: 413  Training loss = 3.4125  Validation loss = 1.6480  \n",
      "\n",
      "Fold: 24  Epoch: 414  Training loss = 3.4123  Validation loss = 1.6477  \n",
      "\n",
      "Fold: 24  Epoch: 415  Training loss = 3.4121  Validation loss = 1.6474  \n",
      "\n",
      "Fold: 24  Epoch: 416  Training loss = 3.4118  Validation loss = 1.6468  \n",
      "\n",
      "Fold: 24  Epoch: 417  Training loss = 3.4116  Validation loss = 1.6462  \n",
      "\n",
      "Fold: 24  Epoch: 418  Training loss = 3.4114  Validation loss = 1.6460  \n",
      "\n",
      "Fold: 24  Epoch: 419  Training loss = 3.4112  Validation loss = 1.6455  \n",
      "\n",
      "Fold: 24  Epoch: 420  Training loss = 3.4110  Validation loss = 1.6451  \n",
      "\n",
      "Fold: 24  Epoch: 421  Training loss = 3.4107  Validation loss = 1.6445  \n",
      "\n",
      "Fold: 24  Epoch: 422  Training loss = 3.4104  Validation loss = 1.6439  \n",
      "\n",
      "Fold: 24  Epoch: 423  Training loss = 3.4101  Validation loss = 1.6436  \n",
      "\n",
      "Fold: 24  Epoch: 424  Training loss = 3.4100  Validation loss = 1.6432  \n",
      "\n",
      "Fold: 24  Epoch: 425  Training loss = 3.4098  Validation loss = 1.6429  \n",
      "\n",
      "Fold: 24  Epoch: 426  Training loss = 3.4095  Validation loss = 1.6425  \n",
      "\n",
      "Fold: 24  Epoch: 427  Training loss = 3.4094  Validation loss = 1.6422  \n",
      "\n",
      "Fold: 24  Epoch: 428  Training loss = 3.4091  Validation loss = 1.6418  \n",
      "\n",
      "Fold: 24  Epoch: 429  Training loss = 3.4088  Validation loss = 1.6412  \n",
      "\n",
      "Fold: 24  Epoch: 430  Training loss = 3.4086  Validation loss = 1.6408  \n",
      "\n",
      "Fold: 24  Epoch: 431  Training loss = 3.4084  Validation loss = 1.6407  \n",
      "\n",
      "Fold: 24  Epoch: 432  Training loss = 3.4081  Validation loss = 1.6400  \n",
      "\n",
      "Fold: 24  Epoch: 433  Training loss = 3.4080  Validation loss = 1.6401  \n",
      "\n",
      "Fold: 24  Epoch: 434  Training loss = 3.4079  Validation loss = 1.6400  \n",
      "\n",
      "Fold: 24  Epoch: 435  Training loss = 3.4078  Validation loss = 1.6398  \n",
      "\n",
      "Fold: 24  Epoch: 436  Training loss = 3.4075  Validation loss = 1.6393  \n",
      "\n",
      "Fold: 24  Epoch: 437  Training loss = 3.4073  Validation loss = 1.6390  \n",
      "\n",
      "Fold: 24  Epoch: 438  Training loss = 3.4071  Validation loss = 1.6385  \n",
      "\n",
      "Fold: 24  Epoch: 439  Training loss = 3.4069  Validation loss = 1.6383  \n",
      "\n",
      "Fold: 24  Epoch: 440  Training loss = 3.4068  Validation loss = 1.6381  \n",
      "\n",
      "Fold: 24  Epoch: 441  Training loss = 3.4065  Validation loss = 1.6376  \n",
      "\n",
      "Fold: 24  Epoch: 442  Training loss = 3.4063  Validation loss = 1.6373  \n",
      "\n",
      "Fold: 24  Epoch: 443  Training loss = 3.4061  Validation loss = 1.6371  \n",
      "\n",
      "Fold: 24  Epoch: 444  Training loss = 3.4061  Validation loss = 1.6369  \n",
      "\n",
      "Fold: 24  Epoch: 445  Training loss = 3.4059  Validation loss = 1.6367  \n",
      "\n",
      "Fold: 24  Epoch: 446  Training loss = 3.4057  Validation loss = 1.6362  \n",
      "\n",
      "Fold: 24  Epoch: 447  Training loss = 3.4055  Validation loss = 1.6359  \n",
      "\n",
      "Fold: 24  Epoch: 448  Training loss = 3.4054  Validation loss = 1.6356  \n",
      "\n",
      "Fold: 24  Epoch: 449  Training loss = 3.4052  Validation loss = 1.6354  \n",
      "\n",
      "Fold: 24  Epoch: 450  Training loss = 3.4051  Validation loss = 1.6351  \n",
      "\n",
      "Fold: 24  Epoch: 451  Training loss = 3.4048  Validation loss = 1.6348  \n",
      "\n",
      "Fold: 24  Epoch: 452  Training loss = 3.4047  Validation loss = 1.6347  \n",
      "\n",
      "Fold: 24  Epoch: 453  Training loss = 3.4045  Validation loss = 1.6345  \n",
      "\n",
      "Fold: 24  Epoch: 454  Training loss = 3.4043  Validation loss = 1.6342  \n",
      "\n",
      "Fold: 24  Epoch: 455  Training loss = 3.4042  Validation loss = 1.6342  \n",
      "\n",
      "Fold: 24  Epoch: 456  Training loss = 3.4039  Validation loss = 1.6338  \n",
      "\n",
      "Fold: 24  Epoch: 457  Training loss = 3.4037  Validation loss = 1.6334  \n",
      "\n",
      "Fold: 24  Epoch: 458  Training loss = 3.4034  Validation loss = 1.6329  \n",
      "\n",
      "Fold: 24  Epoch: 459  Training loss = 3.4031  Validation loss = 1.6325  \n",
      "\n",
      "Fold: 24  Epoch: 460  Training loss = 3.4028  Validation loss = 1.6320  \n",
      "\n",
      "Fold: 24  Epoch: 461  Training loss = 3.4026  Validation loss = 1.6317  \n",
      "\n",
      "Fold: 24  Epoch: 462  Training loss = 3.4025  Validation loss = 1.6315  \n",
      "\n",
      "Fold: 24  Epoch: 463  Training loss = 3.4024  Validation loss = 1.6314  \n",
      "\n",
      "Fold: 24  Epoch: 464  Training loss = 3.4021  Validation loss = 1.6310  \n",
      "\n",
      "Fold: 24  Epoch: 465  Training loss = 3.4020  Validation loss = 1.6308  \n",
      "\n",
      "Fold: 24  Epoch: 466  Training loss = 3.4019  Validation loss = 1.6307  \n",
      "\n",
      "Fold: 24  Epoch: 467  Training loss = 3.4016  Validation loss = 1.6302  \n",
      "\n",
      "Fold: 24  Epoch: 468  Training loss = 3.4014  Validation loss = 1.6298  \n",
      "\n",
      "Fold: 24  Epoch: 469  Training loss = 3.4012  Validation loss = 1.6295  \n",
      "\n",
      "Fold: 24  Epoch: 470  Training loss = 3.4012  Validation loss = 1.6293  \n",
      "\n",
      "Fold: 24  Epoch: 471  Training loss = 3.4009  Validation loss = 1.6289  \n",
      "\n",
      "Fold: 24  Epoch: 472  Training loss = 3.4007  Validation loss = 1.6288  \n",
      "\n",
      "Fold: 24  Epoch: 473  Training loss = 3.4005  Validation loss = 1.6285  \n",
      "\n",
      "Fold: 24  Epoch: 474  Training loss = 3.4004  Validation loss = 1.6284  \n",
      "\n",
      "Fold: 24  Epoch: 475  Training loss = 3.4001  Validation loss = 1.6282  \n",
      "\n",
      "Fold: 24  Epoch: 476  Training loss = 3.3999  Validation loss = 1.6279  \n",
      "\n",
      "Fold: 24  Epoch: 477  Training loss = 3.3997  Validation loss = 1.6275  \n",
      "\n",
      "Fold: 24  Epoch: 478  Training loss = 3.3994  Validation loss = 1.6270  \n",
      "\n",
      "Fold: 24  Epoch: 479  Training loss = 3.3992  Validation loss = 1.6266  \n",
      "\n",
      "Fold: 24  Epoch: 480  Training loss = 3.3990  Validation loss = 1.6262  \n",
      "\n",
      "Fold: 24  Epoch: 481  Training loss = 3.3988  Validation loss = 1.6259  \n",
      "\n",
      "Fold: 24  Epoch: 482  Training loss = 3.3985  Validation loss = 1.6255  \n",
      "\n",
      "Fold: 24  Epoch: 483  Training loss = 3.3982  Validation loss = 1.6248  \n",
      "\n",
      "Fold: 24  Epoch: 484  Training loss = 3.3981  Validation loss = 1.6248  \n",
      "\n",
      "Fold: 24  Epoch: 485  Training loss = 3.3978  Validation loss = 1.6242  \n",
      "\n",
      "Fold: 24  Epoch: 486  Training loss = 3.3976  Validation loss = 1.6239  \n",
      "\n",
      "Fold: 24  Epoch: 487  Training loss = 3.3973  Validation loss = 1.6233  \n",
      "\n",
      "Fold: 24  Epoch: 488  Training loss = 3.3971  Validation loss = 1.6231  \n",
      "\n",
      "Fold: 24  Epoch: 489  Training loss = 3.3969  Validation loss = 1.6227  \n",
      "\n",
      "Fold: 24  Epoch: 490  Training loss = 3.3967  Validation loss = 1.6226  \n",
      "\n",
      "Fold: 24  Epoch: 491  Training loss = 3.3965  Validation loss = 1.6220  \n",
      "\n",
      "Fold: 24  Epoch: 492  Training loss = 3.3963  Validation loss = 1.6216  \n",
      "\n",
      "Fold: 24  Epoch: 493  Training loss = 3.3961  Validation loss = 1.6213  \n",
      "\n",
      "Fold: 24  Epoch: 494  Training loss = 3.3958  Validation loss = 1.6207  \n",
      "\n",
      "Fold: 24  Epoch: 495  Training loss = 3.3955  Validation loss = 1.6202  \n",
      "\n",
      "Fold: 24  Epoch: 496  Training loss = 3.3954  Validation loss = 1.6202  \n",
      "\n",
      "Fold: 24  Epoch: 497  Training loss = 3.3952  Validation loss = 1.6201  \n",
      "\n",
      "Fold: 24  Epoch: 498  Training loss = 3.3950  Validation loss = 1.6197  \n",
      "\n",
      "Fold: 24  Epoch: 499  Training loss = 3.3949  Validation loss = 1.6194  \n",
      "\n",
      "Fold: 24  Epoch: 500  Training loss = 3.3946  Validation loss = 1.6189  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 500  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 3.3683  Validation loss = 2.5153  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 3.3682  Validation loss = 2.5151  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 3.3681  Validation loss = 2.5147  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 3.3680  Validation loss = 2.5142  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 3.3678  Validation loss = 2.5143  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 3.3676  Validation loss = 2.5141  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 3.3674  Validation loss = 2.5139  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 3.3671  Validation loss = 2.5133  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 3.3671  Validation loss = 2.5132  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 3.3668  Validation loss = 2.5130  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 3.3666  Validation loss = 2.5127  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 3.3665  Validation loss = 2.5126  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 3.3663  Validation loss = 2.5123  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 3.3662  Validation loss = 2.5115  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 3.3660  Validation loss = 2.5114  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 3.3657  Validation loss = 2.5115  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 3.3656  Validation loss = 2.5113  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 3.3654  Validation loss = 2.5112  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 3.3651  Validation loss = 2.5114  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 3.3649  Validation loss = 2.5111  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 3.3647  Validation loss = 2.5108  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 3.3645  Validation loss = 2.5108  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 3.3643  Validation loss = 2.5109  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 3.3640  Validation loss = 2.5106  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 3.3637  Validation loss = 2.5104  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 3.3634  Validation loss = 2.5106  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 3.3632  Validation loss = 2.5102  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 3.3630  Validation loss = 2.5104  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 3.3628  Validation loss = 2.5103  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 3.3626  Validation loss = 2.5103  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 3.3625  Validation loss = 2.5101  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 3.3624  Validation loss = 2.5103  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 3.3623  Validation loss = 2.5101  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 3.3621  Validation loss = 2.5100  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 3.3620  Validation loss = 2.5099  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 3.3618  Validation loss = 2.5100  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 3.3615  Validation loss = 2.5099  \n",
      "\n",
      "Fold: 25  Epoch: 38  Training loss = 3.3614  Validation loss = 2.5099  \n",
      "\n",
      "Fold: 25  Epoch: 39  Training loss = 3.3612  Validation loss = 2.5102  \n",
      "\n",
      "Fold: 25  Epoch: 40  Training loss = 3.3612  Validation loss = 2.5099  \n",
      "\n",
      "Fold: 25  Epoch: 41  Training loss = 3.3609  Validation loss = 2.5100  \n",
      "\n",
      "Fold: 25  Epoch: 42  Training loss = 3.3606  Validation loss = 2.5101  \n",
      "\n",
      "Fold: 25  Epoch: 43  Training loss = 3.3604  Validation loss = 2.5098  \n",
      "\n",
      "Fold: 25  Epoch: 44  Training loss = 3.3603  Validation loss = 2.5098  \n",
      "\n",
      "Fold: 25  Epoch: 45  Training loss = 3.3601  Validation loss = 2.5098  \n",
      "\n",
      "Fold: 25  Epoch: 46  Training loss = 3.3598  Validation loss = 2.5100  \n",
      "\n",
      "Fold: 25  Epoch: 47  Training loss = 3.3595  Validation loss = 2.5099  \n",
      "\n",
      "Fold: 25  Epoch: 48  Training loss = 3.3593  Validation loss = 2.5098  \n",
      "\n",
      "Fold: 25  Epoch: 49  Training loss = 3.3592  Validation loss = 2.5095  \n",
      "\n",
      "Fold: 25  Epoch: 50  Training loss = 3.3590  Validation loss = 2.5093  \n",
      "\n",
      "Fold: 25  Epoch: 51  Training loss = 3.3588  Validation loss = 2.5092  \n",
      "\n",
      "Fold: 25  Epoch: 52  Training loss = 3.3585  Validation loss = 2.5089  \n",
      "\n",
      "Fold: 25  Epoch: 53  Training loss = 3.3583  Validation loss = 2.5089  \n",
      "\n",
      "Fold: 25  Epoch: 54  Training loss = 3.3580  Validation loss = 2.5084  \n",
      "\n",
      "Fold: 25  Epoch: 55  Training loss = 3.3579  Validation loss = 2.5085  \n",
      "\n",
      "Fold: 25  Epoch: 56  Training loss = 3.3576  Validation loss = 2.5086  \n",
      "\n",
      "Fold: 25  Epoch: 57  Training loss = 3.3574  Validation loss = 2.5083  \n",
      "\n",
      "Fold: 25  Epoch: 58  Training loss = 3.3572  Validation loss = 2.5083  \n",
      "\n",
      "Fold: 25  Epoch: 59  Training loss = 3.3571  Validation loss = 2.5081  \n",
      "\n",
      "Fold: 25  Epoch: 60  Training loss = 3.3568  Validation loss = 2.5077  \n",
      "\n",
      "Fold: 25  Epoch: 61  Training loss = 3.3566  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 25  Epoch: 62  Training loss = 3.3564  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 25  Epoch: 63  Training loss = 3.3562  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 25  Epoch: 64  Training loss = 3.3560  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 25  Epoch: 65  Training loss = 3.3559  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 25  Epoch: 66  Training loss = 3.3557  Validation loss = 2.5072  \n",
      "\n",
      "Fold: 25  Epoch: 67  Training loss = 3.3556  Validation loss = 2.5069  \n",
      "\n",
      "Fold: 25  Epoch: 68  Training loss = 3.3555  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 25  Epoch: 69  Training loss = 3.3553  Validation loss = 2.5074  \n",
      "\n",
      "Fold: 25  Epoch: 70  Training loss = 3.3551  Validation loss = 2.5076  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 67  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.2228  Validation loss = 3.2716  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.2227  Validation loss = 3.2710  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.2226  Validation loss = 3.2703  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.2225  Validation loss = 3.2711  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.2224  Validation loss = 3.2712  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.2223  Validation loss = 3.2707  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.2222  Validation loss = 3.2706  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.2220  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.2219  Validation loss = 3.2696  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.2217  Validation loss = 3.2691  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 3.2215  Validation loss = 3.2680  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 3.2214  Validation loss = 3.2681  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 3.2213  Validation loss = 3.2675  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 3.2211  Validation loss = 3.2665  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 3.2210  Validation loss = 3.2659  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 3.2208  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 3.2207  Validation loss = 3.2651  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 3.2205  Validation loss = 3.2646  \n",
      "\n",
      "Fold: 26  Epoch: 19  Training loss = 3.2204  Validation loss = 3.2652  \n",
      "\n",
      "Fold: 26  Epoch: 20  Training loss = 3.2202  Validation loss = 3.2646  \n",
      "\n",
      "Fold: 26  Epoch: 21  Training loss = 3.2200  Validation loss = 3.2638  \n",
      "\n",
      "Fold: 26  Epoch: 22  Training loss = 3.2199  Validation loss = 3.2632  \n",
      "\n",
      "Fold: 26  Epoch: 23  Training loss = 3.2198  Validation loss = 3.2626  \n",
      "\n",
      "Fold: 26  Epoch: 24  Training loss = 3.2196  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 26  Epoch: 25  Training loss = 3.2194  Validation loss = 3.2621  \n",
      "\n",
      "Fold: 26  Epoch: 26  Training loss = 3.2192  Validation loss = 3.2611  \n",
      "\n",
      "Fold: 26  Epoch: 27  Training loss = 3.2191  Validation loss = 3.2615  \n",
      "\n",
      "Fold: 26  Epoch: 28  Training loss = 3.2190  Validation loss = 3.2608  \n",
      "\n",
      "Fold: 26  Epoch: 29  Training loss = 3.2188  Validation loss = 3.2604  \n",
      "\n",
      "Fold: 26  Epoch: 30  Training loss = 3.2186  Validation loss = 3.2597  \n",
      "\n",
      "Fold: 26  Epoch: 31  Training loss = 3.2185  Validation loss = 3.2592  \n",
      "\n",
      "Fold: 26  Epoch: 32  Training loss = 3.2182  Validation loss = 3.2584  \n",
      "\n",
      "Fold: 26  Epoch: 33  Training loss = 3.2181  Validation loss = 3.2583  \n",
      "\n",
      "Fold: 26  Epoch: 34  Training loss = 3.2180  Validation loss = 3.2582  \n",
      "\n",
      "Fold: 26  Epoch: 35  Training loss = 3.2178  Validation loss = 3.2568  \n",
      "\n",
      "Fold: 26  Epoch: 36  Training loss = 3.2176  Validation loss = 3.2559  \n",
      "\n",
      "Fold: 26  Epoch: 37  Training loss = 3.2175  Validation loss = 3.2562  \n",
      "\n",
      "Fold: 26  Epoch: 38  Training loss = 3.2173  Validation loss = 3.2560  \n",
      "\n",
      "Fold: 26  Epoch: 39  Training loss = 3.2172  Validation loss = 3.2555  \n",
      "\n",
      "Fold: 26  Epoch: 40  Training loss = 3.2171  Validation loss = 3.2558  \n",
      "\n",
      "Fold: 26  Epoch: 41  Training loss = 3.2169  Validation loss = 3.2562  \n",
      "\n",
      "Fold: 26  Epoch: 42  Training loss = 3.2168  Validation loss = 3.2554  \n",
      "\n",
      "Fold: 26  Epoch: 43  Training loss = 3.2167  Validation loss = 3.2544  \n",
      "\n",
      "Fold: 26  Epoch: 44  Training loss = 3.2166  Validation loss = 3.2539  \n",
      "\n",
      "Fold: 26  Epoch: 45  Training loss = 3.2164  Validation loss = 3.2534  \n",
      "\n",
      "Fold: 26  Epoch: 46  Training loss = 3.2163  Validation loss = 3.2534  \n",
      "\n",
      "Fold: 26  Epoch: 47  Training loss = 3.2161  Validation loss = 3.2539  \n",
      "\n",
      "Fold: 26  Epoch: 48  Training loss = 3.2160  Validation loss = 3.2535  \n",
      "\n",
      "Fold: 26  Epoch: 49  Training loss = 3.2158  Validation loss = 3.2538  \n",
      "\n",
      "Fold: 26  Epoch: 50  Training loss = 3.2157  Validation loss = 3.2534  \n",
      "\n",
      "Fold: 26  Epoch: 51  Training loss = 3.2155  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 26  Epoch: 52  Training loss = 3.2154  Validation loss = 3.2520  \n",
      "\n",
      "Fold: 26  Epoch: 53  Training loss = 3.2152  Validation loss = 3.2521  \n",
      "\n",
      "Fold: 26  Epoch: 54  Training loss = 3.2151  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 26  Epoch: 55  Training loss = 3.2149  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 26  Epoch: 56  Training loss = 3.2148  Validation loss = 3.2529  \n",
      "\n",
      "Fold: 26  Epoch: 57  Training loss = 3.2146  Validation loss = 3.2526  \n",
      "\n",
      "Fold: 26  Epoch: 58  Training loss = 3.2145  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 26  Epoch: 59  Training loss = 3.2144  Validation loss = 3.2511  \n",
      "\n",
      "Fold: 26  Epoch: 60  Training loss = 3.2142  Validation loss = 3.2498  \n",
      "\n",
      "Fold: 26  Epoch: 61  Training loss = 3.2140  Validation loss = 3.2490  \n",
      "\n",
      "Fold: 26  Epoch: 62  Training loss = 3.2139  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 26  Epoch: 63  Training loss = 3.2137  Validation loss = 3.2472  \n",
      "\n",
      "Fold: 26  Epoch: 64  Training loss = 3.2135  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 26  Epoch: 65  Training loss = 3.2134  Validation loss = 3.2458  \n",
      "\n",
      "Fold: 26  Epoch: 66  Training loss = 3.2131  Validation loss = 3.2443  \n",
      "\n",
      "Fold: 26  Epoch: 67  Training loss = 3.2130  Validation loss = 3.2433  \n",
      "\n",
      "Fold: 26  Epoch: 68  Training loss = 3.2129  Validation loss = 3.2424  \n",
      "\n",
      "Fold: 26  Epoch: 69  Training loss = 3.2128  Validation loss = 3.2416  \n",
      "\n",
      "Fold: 26  Epoch: 70  Training loss = 3.2127  Validation loss = 3.2406  \n",
      "\n",
      "Fold: 26  Epoch: 71  Training loss = 3.2125  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 26  Epoch: 72  Training loss = 3.2123  Validation loss = 3.2394  \n",
      "\n",
      "Fold: 26  Epoch: 73  Training loss = 3.2122  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 26  Epoch: 74  Training loss = 3.2120  Validation loss = 3.2393  \n",
      "\n",
      "Fold: 26  Epoch: 75  Training loss = 3.2119  Validation loss = 3.2389  \n",
      "\n",
      "Fold: 26  Epoch: 76  Training loss = 3.2117  Validation loss = 3.2380  \n",
      "\n",
      "Fold: 26  Epoch: 77  Training loss = 3.2116  Validation loss = 3.2383  \n",
      "\n",
      "Fold: 26  Epoch: 78  Training loss = 3.2115  Validation loss = 3.2388  \n",
      "\n",
      "Fold: 26  Epoch: 79  Training loss = 3.2114  Validation loss = 3.2387  \n",
      "\n",
      "Fold: 26  Epoch: 80  Training loss = 3.2113  Validation loss = 3.2377  \n",
      "\n",
      "Fold: 26  Epoch: 81  Training loss = 3.2111  Validation loss = 3.2372  \n",
      "\n",
      "Fold: 26  Epoch: 82  Training loss = 3.2109  Validation loss = 3.2369  \n",
      "\n",
      "Fold: 26  Epoch: 83  Training loss = 3.2108  Validation loss = 3.2355  \n",
      "\n",
      "Fold: 26  Epoch: 84  Training loss = 3.2106  Validation loss = 3.2349  \n",
      "\n",
      "Fold: 26  Epoch: 85  Training loss = 3.2105  Validation loss = 3.2346  \n",
      "\n",
      "Fold: 26  Epoch: 86  Training loss = 3.2103  Validation loss = 3.2326  \n",
      "\n",
      "Fold: 26  Epoch: 87  Training loss = 3.2101  Validation loss = 3.2330  \n",
      "\n",
      "Fold: 26  Epoch: 88  Training loss = 3.2100  Validation loss = 3.2320  \n",
      "\n",
      "Fold: 26  Epoch: 89  Training loss = 3.2098  Validation loss = 3.2316  \n",
      "\n",
      "Fold: 26  Epoch: 90  Training loss = 3.2096  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 26  Epoch: 91  Training loss = 3.2095  Validation loss = 3.2311  \n",
      "\n",
      "Fold: 26  Epoch: 92  Training loss = 3.2093  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 26  Epoch: 93  Training loss = 3.2092  Validation loss = 3.2300  \n",
      "\n",
      "Fold: 26  Epoch: 94  Training loss = 3.2090  Validation loss = 3.2289  \n",
      "\n",
      "Fold: 26  Epoch: 95  Training loss = 3.2088  Validation loss = 3.2284  \n",
      "\n",
      "Fold: 26  Epoch: 96  Training loss = 3.2087  Validation loss = 3.2280  \n",
      "\n",
      "Fold: 26  Epoch: 97  Training loss = 3.2085  Validation loss = 3.2282  \n",
      "\n",
      "Fold: 26  Epoch: 98  Training loss = 3.2083  Validation loss = 3.2272  \n",
      "\n",
      "Fold: 26  Epoch: 99  Training loss = 3.2082  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 26  Epoch: 100  Training loss = 3.2081  Validation loss = 3.2264  \n",
      "\n",
      "Fold: 26  Epoch: 101  Training loss = 3.2079  Validation loss = 3.2264  \n",
      "\n",
      "Fold: 26  Epoch: 102  Training loss = 3.2078  Validation loss = 3.2259  \n",
      "\n",
      "Fold: 26  Epoch: 103  Training loss = 3.2077  Validation loss = 3.2249  \n",
      "\n",
      "Fold: 26  Epoch: 104  Training loss = 3.2075  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 26  Epoch: 105  Training loss = 3.2073  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 26  Epoch: 106  Training loss = 3.2071  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 26  Epoch: 107  Training loss = 3.2069  Validation loss = 3.2249  \n",
      "\n",
      "Fold: 26  Epoch: 108  Training loss = 3.2069  Validation loss = 3.2241  \n",
      "\n",
      "Fold: 26  Epoch: 109  Training loss = 3.2066  Validation loss = 3.2234  \n",
      "\n",
      "Fold: 26  Epoch: 110  Training loss = 3.2065  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 26  Epoch: 111  Training loss = 3.2065  Validation loss = 3.2225  \n",
      "\n",
      "Fold: 26  Epoch: 112  Training loss = 3.2063  Validation loss = 3.2211  \n",
      "\n",
      "Fold: 26  Epoch: 113  Training loss = 3.2061  Validation loss = 3.2198  \n",
      "\n",
      "Fold: 26  Epoch: 114  Training loss = 3.2060  Validation loss = 3.2192  \n",
      "\n",
      "Fold: 26  Epoch: 115  Training loss = 3.2058  Validation loss = 3.2182  \n",
      "\n",
      "Fold: 26  Epoch: 116  Training loss = 3.2056  Validation loss = 3.2174  \n",
      "\n",
      "Fold: 26  Epoch: 117  Training loss = 3.2054  Validation loss = 3.2175  \n",
      "\n",
      "Fold: 26  Epoch: 118  Training loss = 3.2053  Validation loss = 3.2168  \n",
      "\n",
      "Fold: 26  Epoch: 119  Training loss = 3.2051  Validation loss = 3.2165  \n",
      "\n",
      "Fold: 26  Epoch: 120  Training loss = 3.2049  Validation loss = 3.2169  \n",
      "\n",
      "Fold: 26  Epoch: 121  Training loss = 3.2048  Validation loss = 3.2168  \n",
      "\n",
      "Fold: 26  Epoch: 122  Training loss = 3.2046  Validation loss = 3.2153  \n",
      "\n",
      "Fold: 26  Epoch: 123  Training loss = 3.2044  Validation loss = 3.2145  \n",
      "\n",
      "Fold: 26  Epoch: 124  Training loss = 3.2043  Validation loss = 3.2137  \n",
      "\n",
      "Fold: 26  Epoch: 125  Training loss = 3.2042  Validation loss = 3.2139  \n",
      "\n",
      "Fold: 26  Epoch: 126  Training loss = 3.2041  Validation loss = 3.2139  \n",
      "\n",
      "Fold: 26  Epoch: 127  Training loss = 3.2039  Validation loss = 3.2148  \n",
      "\n",
      "Fold: 26  Epoch: 128  Training loss = 3.2038  Validation loss = 3.2139  \n",
      "\n",
      "Fold: 26  Epoch: 129  Training loss = 3.2036  Validation loss = 3.2141  \n",
      "\n",
      "Fold: 26  Epoch: 130  Training loss = 3.2035  Validation loss = 3.2138  \n",
      "\n",
      "Fold: 26  Epoch: 131  Training loss = 3.2034  Validation loss = 3.2141  \n",
      "\n",
      "Fold: 26  Epoch: 132  Training loss = 3.2033  Validation loss = 3.2129  \n",
      "\n",
      "Fold: 26  Epoch: 133  Training loss = 3.2031  Validation loss = 3.2126  \n",
      "\n",
      "Fold: 26  Epoch: 134  Training loss = 3.2029  Validation loss = 3.2123  \n",
      "\n",
      "Fold: 26  Epoch: 135  Training loss = 3.2028  Validation loss = 3.2110  \n",
      "\n",
      "Fold: 26  Epoch: 136  Training loss = 3.2026  Validation loss = 3.2112  \n",
      "\n",
      "Fold: 26  Epoch: 137  Training loss = 3.2025  Validation loss = 3.2111  \n",
      "\n",
      "Fold: 26  Epoch: 138  Training loss = 3.2022  Validation loss = 3.2112  \n",
      "\n",
      "Fold: 26  Epoch: 139  Training loss = 3.2021  Validation loss = 3.2111  \n",
      "\n",
      "Fold: 26  Epoch: 140  Training loss = 3.2020  Validation loss = 3.2102  \n",
      "\n",
      "Fold: 26  Epoch: 141  Training loss = 3.2019  Validation loss = 3.2096  \n",
      "\n",
      "Fold: 26  Epoch: 142  Training loss = 3.2017  Validation loss = 3.2100  \n",
      "\n",
      "Fold: 26  Epoch: 143  Training loss = 3.2015  Validation loss = 3.2100  \n",
      "\n",
      "Fold: 26  Epoch: 144  Training loss = 3.2014  Validation loss = 3.2094  \n",
      "\n",
      "Fold: 26  Epoch: 145  Training loss = 3.2013  Validation loss = 3.2079  \n",
      "\n",
      "Fold: 26  Epoch: 146  Training loss = 3.2011  Validation loss = 3.2069  \n",
      "\n",
      "Fold: 26  Epoch: 147  Training loss = 3.2009  Validation loss = 3.2070  \n",
      "\n",
      "Fold: 26  Epoch: 148  Training loss = 3.2008  Validation loss = 3.2067  \n",
      "\n",
      "Fold: 26  Epoch: 149  Training loss = 3.2006  Validation loss = 3.2065  \n",
      "\n",
      "Fold: 26  Epoch: 150  Training loss = 3.2005  Validation loss = 3.2057  \n",
      "\n",
      "Fold: 26  Epoch: 151  Training loss = 3.2003  Validation loss = 3.2048  \n",
      "\n",
      "Fold: 26  Epoch: 152  Training loss = 3.2001  Validation loss = 3.2037  \n",
      "\n",
      "Fold: 26  Epoch: 153  Training loss = 3.2000  Validation loss = 3.2031  \n",
      "\n",
      "Fold: 26  Epoch: 154  Training loss = 3.1999  Validation loss = 3.2022  \n",
      "\n",
      "Fold: 26  Epoch: 155  Training loss = 3.1997  Validation loss = 3.2030  \n",
      "\n",
      "Fold: 26  Epoch: 156  Training loss = 3.1996  Validation loss = 3.2030  \n",
      "\n",
      "Fold: 26  Epoch: 157  Training loss = 3.1995  Validation loss = 3.2031  \n",
      "\n",
      "Fold: 26  Epoch: 158  Training loss = 3.1994  Validation loss = 3.2025  \n",
      "\n",
      "Fold: 26  Epoch: 159  Training loss = 3.1993  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 26  Epoch: 160  Training loss = 3.1992  Validation loss = 3.2002  \n",
      "\n",
      "Fold: 26  Epoch: 161  Training loss = 3.1989  Validation loss = 3.1995  \n",
      "\n",
      "Fold: 26  Epoch: 162  Training loss = 3.1987  Validation loss = 3.1985  \n",
      "\n",
      "Fold: 26  Epoch: 163  Training loss = 3.1986  Validation loss = 3.1969  \n",
      "\n",
      "Fold: 26  Epoch: 164  Training loss = 3.1984  Validation loss = 3.1963  \n",
      "\n",
      "Fold: 26  Epoch: 165  Training loss = 3.1983  Validation loss = 3.1955  \n",
      "\n",
      "Fold: 26  Epoch: 166  Training loss = 3.1981  Validation loss = 3.1944  \n",
      "\n",
      "Fold: 26  Epoch: 167  Training loss = 3.1980  Validation loss = 3.1936  \n",
      "\n",
      "Fold: 26  Epoch: 168  Training loss = 3.1978  Validation loss = 3.1935  \n",
      "\n",
      "Fold: 26  Epoch: 169  Training loss = 3.1977  Validation loss = 3.1923  \n",
      "\n",
      "Fold: 26  Epoch: 170  Training loss = 3.1976  Validation loss = 3.1916  \n",
      "\n",
      "Fold: 26  Epoch: 171  Training loss = 3.1974  Validation loss = 3.1922  \n",
      "\n",
      "Fold: 26  Epoch: 172  Training loss = 3.1972  Validation loss = 3.1914  \n",
      "\n",
      "Fold: 26  Epoch: 173  Training loss = 3.1970  Validation loss = 3.1928  \n",
      "\n",
      "Fold: 26  Epoch: 174  Training loss = 3.1969  Validation loss = 3.1937  \n",
      "\n",
      "Fold: 26  Epoch: 175  Training loss = 3.1968  Validation loss = 3.1935  \n",
      "\n",
      "Fold: 26  Epoch: 176  Training loss = 3.1968  Validation loss = 3.1928  \n",
      "\n",
      "Fold: 26  Epoch: 177  Training loss = 3.1966  Validation loss = 3.1920  \n",
      "\n",
      "Fold: 26  Epoch: 178  Training loss = 3.1964  Validation loss = 3.1922  \n",
      "\n",
      "Fold: 26  Epoch: 179  Training loss = 3.1963  Validation loss = 3.1914  \n",
      "\n",
      "Fold: 26  Epoch: 180  Training loss = 3.1961  Validation loss = 3.1900  \n",
      "\n",
      "Fold: 26  Epoch: 181  Training loss = 3.1960  Validation loss = 3.1889  \n",
      "\n",
      "Fold: 26  Epoch: 182  Training loss = 3.1959  Validation loss = 3.1894  \n",
      "\n",
      "Fold: 26  Epoch: 183  Training loss = 3.1958  Validation loss = 3.1903  \n",
      "\n",
      "Fold: 26  Epoch: 184  Training loss = 3.1956  Validation loss = 3.1892  \n",
      "\n",
      "Fold: 26  Epoch: 185  Training loss = 3.1956  Validation loss = 3.1903  \n",
      "\n",
      "Fold: 26  Epoch: 186  Training loss = 3.1954  Validation loss = 3.1890  \n",
      "\n",
      "Fold: 26  Epoch: 187  Training loss = 3.1953  Validation loss = 3.1890  \n",
      "\n",
      "Fold: 26  Epoch: 188  Training loss = 3.1951  Validation loss = 3.1887  \n",
      "\n",
      "Fold: 26  Epoch: 189  Training loss = 3.1949  Validation loss = 3.1889  \n",
      "\n",
      "Fold: 26  Epoch: 190  Training loss = 3.1947  Validation loss = 3.1873  \n",
      "\n",
      "Fold: 26  Epoch: 191  Training loss = 3.1945  Validation loss = 3.1859  \n",
      "\n",
      "Fold: 26  Epoch: 192  Training loss = 3.1943  Validation loss = 3.1857  \n",
      "\n",
      "Fold: 26  Epoch: 193  Training loss = 3.1941  Validation loss = 3.1855  \n",
      "\n",
      "Fold: 26  Epoch: 194  Training loss = 3.1939  Validation loss = 3.1858  \n",
      "\n",
      "Fold: 26  Epoch: 195  Training loss = 3.1938  Validation loss = 3.1866  \n",
      "\n",
      "Fold: 26  Epoch: 196  Training loss = 3.1937  Validation loss = 3.1858  \n",
      "\n",
      "Fold: 26  Epoch: 197  Training loss = 3.1936  Validation loss = 3.1849  \n",
      "\n",
      "Fold: 26  Epoch: 198  Training loss = 3.1935  Validation loss = 3.1832  \n",
      "\n",
      "Fold: 26  Epoch: 199  Training loss = 3.1934  Validation loss = 3.1832  \n",
      "\n",
      "Fold: 26  Epoch: 200  Training loss = 3.1933  Validation loss = 3.1835  \n",
      "\n",
      "Fold: 26  Epoch: 201  Training loss = 3.1931  Validation loss = 3.1829  \n",
      "\n",
      "Fold: 26  Epoch: 202  Training loss = 3.1929  Validation loss = 3.1824  \n",
      "\n",
      "Fold: 26  Epoch: 203  Training loss = 3.1928  Validation loss = 3.1818  \n",
      "\n",
      "Fold: 26  Epoch: 204  Training loss = 3.1926  Validation loss = 3.1816  \n",
      "\n",
      "Fold: 26  Epoch: 205  Training loss = 3.1925  Validation loss = 3.1817  \n",
      "\n",
      "Fold: 26  Epoch: 206  Training loss = 3.1924  Validation loss = 3.1820  \n",
      "\n",
      "Fold: 26  Epoch: 207  Training loss = 3.1923  Validation loss = 3.1809  \n",
      "\n",
      "Fold: 26  Epoch: 208  Training loss = 3.1921  Validation loss = 3.1802  \n",
      "\n",
      "Fold: 26  Epoch: 209  Training loss = 3.1919  Validation loss = 3.1806  \n",
      "\n",
      "Fold: 26  Epoch: 210  Training loss = 3.1917  Validation loss = 3.1794  \n",
      "\n",
      "Fold: 26  Epoch: 211  Training loss = 3.1915  Validation loss = 3.1789  \n",
      "\n",
      "Fold: 26  Epoch: 212  Training loss = 3.1914  Validation loss = 3.1782  \n",
      "\n",
      "Fold: 26  Epoch: 213  Training loss = 3.1913  Validation loss = 3.1769  \n",
      "\n",
      "Fold: 26  Epoch: 214  Training loss = 3.1911  Validation loss = 3.1762  \n",
      "\n",
      "Fold: 26  Epoch: 215  Training loss = 3.1909  Validation loss = 3.1754  \n",
      "\n",
      "Fold: 26  Epoch: 216  Training loss = 3.1907  Validation loss = 3.1747  \n",
      "\n",
      "Fold: 26  Epoch: 217  Training loss = 3.1906  Validation loss = 3.1755  \n",
      "\n",
      "Fold: 26  Epoch: 218  Training loss = 3.1905  Validation loss = 3.1753  \n",
      "\n",
      "Fold: 26  Epoch: 219  Training loss = 3.1903  Validation loss = 3.1751  \n",
      "\n",
      "Fold: 26  Epoch: 220  Training loss = 3.1902  Validation loss = 3.1754  \n",
      "\n",
      "Fold: 26  Epoch: 221  Training loss = 3.1900  Validation loss = 3.1746  \n",
      "\n",
      "Fold: 26  Epoch: 222  Training loss = 3.1899  Validation loss = 3.1748  \n",
      "\n",
      "Fold: 26  Epoch: 223  Training loss = 3.1898  Validation loss = 3.1738  \n",
      "\n",
      "Fold: 26  Epoch: 224  Training loss = 3.1896  Validation loss = 3.1734  \n",
      "\n",
      "Fold: 26  Epoch: 225  Training loss = 3.1895  Validation loss = 3.1733  \n",
      "\n",
      "Fold: 26  Epoch: 226  Training loss = 3.1894  Validation loss = 3.1715  \n",
      "\n",
      "Fold: 26  Epoch: 227  Training loss = 3.1892  Validation loss = 3.1714  \n",
      "\n",
      "Fold: 26  Epoch: 228  Training loss = 3.1890  Validation loss = 3.1703  \n",
      "\n",
      "Fold: 26  Epoch: 229  Training loss = 3.1888  Validation loss = 3.1692  \n",
      "\n",
      "Fold: 26  Epoch: 230  Training loss = 3.1886  Validation loss = 3.1681  \n",
      "\n",
      "Fold: 26  Epoch: 231  Training loss = 3.1885  Validation loss = 3.1689  \n",
      "\n",
      "Fold: 26  Epoch: 232  Training loss = 3.1884  Validation loss = 3.1693  \n",
      "\n",
      "Fold: 26  Epoch: 233  Training loss = 3.1882  Validation loss = 3.1686  \n",
      "\n",
      "Fold: 26  Epoch: 234  Training loss = 3.1881  Validation loss = 3.1697  \n",
      "\n",
      "Fold: 26  Epoch: 235  Training loss = 3.1879  Validation loss = 3.1686  \n",
      "\n",
      "Fold: 26  Epoch: 236  Training loss = 3.1878  Validation loss = 3.1681  \n",
      "\n",
      "Fold: 26  Epoch: 237  Training loss = 3.1877  Validation loss = 3.1680  \n",
      "\n",
      "Fold: 26  Epoch: 238  Training loss = 3.1876  Validation loss = 3.1674  \n",
      "\n",
      "Fold: 26  Epoch: 239  Training loss = 3.1874  Validation loss = 3.1679  \n",
      "\n",
      "Fold: 26  Epoch: 240  Training loss = 3.1873  Validation loss = 3.1679  \n",
      "\n",
      "Fold: 26  Epoch: 241  Training loss = 3.1872  Validation loss = 3.1677  \n",
      "\n",
      "Fold: 26  Epoch: 242  Training loss = 3.1871  Validation loss = 3.1668  \n",
      "\n",
      "Fold: 26  Epoch: 243  Training loss = 3.1870  Validation loss = 3.1671  \n",
      "\n",
      "Fold: 26  Epoch: 244  Training loss = 3.1868  Validation loss = 3.1663  \n",
      "\n",
      "Fold: 26  Epoch: 245  Training loss = 3.1867  Validation loss = 3.1652  \n",
      "\n",
      "Fold: 26  Epoch: 246  Training loss = 3.1865  Validation loss = 3.1641  \n",
      "\n",
      "Fold: 26  Epoch: 247  Training loss = 3.1865  Validation loss = 3.1632  \n",
      "\n",
      "Fold: 26  Epoch: 248  Training loss = 3.1864  Validation loss = 3.1628  \n",
      "\n",
      "Fold: 26  Epoch: 249  Training loss = 3.1862  Validation loss = 3.1619  \n",
      "\n",
      "Fold: 26  Epoch: 250  Training loss = 3.1862  Validation loss = 3.1628  \n",
      "\n",
      "Fold: 26  Epoch: 251  Training loss = 3.1860  Validation loss = 3.1616  \n",
      "\n",
      "Fold: 26  Epoch: 252  Training loss = 3.1859  Validation loss = 3.1619  \n",
      "\n",
      "Fold: 26  Epoch: 253  Training loss = 3.1857  Validation loss = 3.1610  \n",
      "\n",
      "Fold: 26  Epoch: 254  Training loss = 3.1856  Validation loss = 3.1597  \n",
      "\n",
      "Fold: 26  Epoch: 255  Training loss = 3.1855  Validation loss = 3.1602  \n",
      "\n",
      "Fold: 26  Epoch: 256  Training loss = 3.1854  Validation loss = 3.1603  \n",
      "\n",
      "Fold: 26  Epoch: 257  Training loss = 3.1852  Validation loss = 3.1592  \n",
      "\n",
      "Fold: 26  Epoch: 258  Training loss = 3.1851  Validation loss = 3.1596  \n",
      "\n",
      "Fold: 26  Epoch: 259  Training loss = 3.1850  Validation loss = 3.1579  \n",
      "\n",
      "Fold: 26  Epoch: 260  Training loss = 3.1848  Validation loss = 3.1574  \n",
      "\n",
      "Fold: 26  Epoch: 261  Training loss = 3.1846  Validation loss = 3.1575  \n",
      "\n",
      "Fold: 26  Epoch: 262  Training loss = 3.1845  Validation loss = 3.1574  \n",
      "\n",
      "Fold: 26  Epoch: 263  Training loss = 3.1843  Validation loss = 3.1583  \n",
      "\n",
      "Fold: 26  Epoch: 264  Training loss = 3.1841  Validation loss = 3.1570  \n",
      "\n",
      "Fold: 26  Epoch: 265  Training loss = 3.1839  Validation loss = 3.1564  \n",
      "\n",
      "Fold: 26  Epoch: 266  Training loss = 3.1838  Validation loss = 3.1566  \n",
      "\n",
      "Fold: 26  Epoch: 267  Training loss = 3.1837  Validation loss = 3.1578  \n",
      "\n",
      "Fold: 26  Epoch: 268  Training loss = 3.1835  Validation loss = 3.1580  \n",
      "\n",
      "Fold: 26  Epoch: 269  Training loss = 3.1834  Validation loss = 3.1568  \n",
      "\n",
      "Fold: 26  Epoch: 270  Training loss = 3.1833  Validation loss = 3.1569  \n",
      "\n",
      "Fold: 26  Epoch: 271  Training loss = 3.1831  Validation loss = 3.1555  \n",
      "\n",
      "Fold: 26  Epoch: 272  Training loss = 3.1830  Validation loss = 3.1546  \n",
      "\n",
      "Fold: 26  Epoch: 273  Training loss = 3.1829  Validation loss = 3.1540  \n",
      "\n",
      "Fold: 26  Epoch: 274  Training loss = 3.1828  Validation loss = 3.1545  \n",
      "\n",
      "Fold: 26  Epoch: 275  Training loss = 3.1827  Validation loss = 3.1541  \n",
      "\n",
      "Fold: 26  Epoch: 276  Training loss = 3.1826  Validation loss = 3.1551  \n",
      "\n",
      "Fold: 26  Epoch: 277  Training loss = 3.1824  Validation loss = 3.1539  \n",
      "\n",
      "Fold: 26  Epoch: 278  Training loss = 3.1823  Validation loss = 3.1521  \n",
      "\n",
      "Fold: 26  Epoch: 279  Training loss = 3.1822  Validation loss = 3.1506  \n",
      "\n",
      "Fold: 26  Epoch: 280  Training loss = 3.1820  Validation loss = 3.1492  \n",
      "\n",
      "Fold: 26  Epoch: 281  Training loss = 3.1819  Validation loss = 3.1488  \n",
      "\n",
      "Fold: 26  Epoch: 282  Training loss = 3.1818  Validation loss = 3.1495  \n",
      "\n",
      "Fold: 26  Epoch: 283  Training loss = 3.1816  Validation loss = 3.1496  \n",
      "\n",
      "Fold: 26  Epoch: 284  Training loss = 3.1814  Validation loss = 3.1491  \n",
      "\n",
      "Fold: 26  Epoch: 285  Training loss = 3.1813  Validation loss = 3.1492  \n",
      "\n",
      "Fold: 26  Epoch: 286  Training loss = 3.1812  Validation loss = 3.1491  \n",
      "\n",
      "Fold: 26  Epoch: 287  Training loss = 3.1811  Validation loss = 3.1505  \n",
      "\n",
      "Fold: 26  Epoch: 288  Training loss = 3.1809  Validation loss = 3.1494  \n",
      "\n",
      "Fold: 26  Epoch: 289  Training loss = 3.1808  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 26  Epoch: 290  Training loss = 3.1808  Validation loss = 3.1481  \n",
      "\n",
      "Fold: 26  Epoch: 291  Training loss = 3.1806  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 26  Epoch: 292  Training loss = 3.1805  Validation loss = 3.1469  \n",
      "\n",
      "Fold: 26  Epoch: 293  Training loss = 3.1804  Validation loss = 3.1471  \n",
      "\n",
      "Fold: 26  Epoch: 294  Training loss = 3.1802  Validation loss = 3.1458  \n",
      "\n",
      "Fold: 26  Epoch: 295  Training loss = 3.1801  Validation loss = 3.1449  \n",
      "\n",
      "Fold: 26  Epoch: 296  Training loss = 3.1800  Validation loss = 3.1445  \n",
      "\n",
      "Fold: 26  Epoch: 297  Training loss = 3.1799  Validation loss = 3.1462  \n",
      "\n",
      "Fold: 26  Epoch: 298  Training loss = 3.1798  Validation loss = 3.1467  \n",
      "\n",
      "Fold: 26  Epoch: 299  Training loss = 3.1797  Validation loss = 3.1459  \n",
      "\n",
      "Fold: 26  Epoch: 300  Training loss = 3.1796  Validation loss = 3.1462  \n",
      "\n",
      "Fold: 26  Epoch: 301  Training loss = 3.1794  Validation loss = 3.1461  \n",
      "\n",
      "Fold: 26  Epoch: 302  Training loss = 3.1792  Validation loss = 3.1447  \n",
      "\n",
      "Fold: 26  Epoch: 303  Training loss = 3.1790  Validation loss = 3.1455  \n",
      "\n",
      "Fold: 26  Epoch: 304  Training loss = 3.1790  Validation loss = 3.1455  \n",
      "\n",
      "Fold: 26  Epoch: 305  Training loss = 3.1788  Validation loss = 3.1461  \n",
      "\n",
      "Fold: 26  Epoch: 306  Training loss = 3.1787  Validation loss = 3.1457  \n",
      "\n",
      "Fold: 26  Epoch: 307  Training loss = 3.1785  Validation loss = 3.1466  \n",
      "\n",
      "Fold: 26  Epoch: 308  Training loss = 3.1784  Validation loss = 3.1470  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 296  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.2008  Validation loss = 1.7954  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.2003  Validation loss = 1.7945  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.2002  Validation loss = 1.7944  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.1998  Validation loss = 1.7939  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.1994  Validation loss = 1.7937  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.1988  Validation loss = 1.7927  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.1984  Validation loss = 1.7921  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.1979  Validation loss = 1.7914  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.1974  Validation loss = 1.7905  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.1968  Validation loss = 1.7895  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.1964  Validation loss = 1.7890  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 3.1957  Validation loss = 1.7877  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 3.1955  Validation loss = 1.7876  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 3.1952  Validation loss = 1.7873  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 3.1950  Validation loss = 1.7870  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 3.1940  Validation loss = 1.7857  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 3.1936  Validation loss = 1.7849  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 3.1934  Validation loss = 1.7850  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 3.1932  Validation loss = 1.7850  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 3.1924  Validation loss = 1.7842  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 3.1922  Validation loss = 1.7842  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 3.1916  Validation loss = 1.7834  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 3.1911  Validation loss = 1.7825  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 3.1904  Validation loss = 1.7821  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 3.1898  Validation loss = 1.7815  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 3.1895  Validation loss = 1.7813  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 3.1892  Validation loss = 1.7810  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 3.1887  Validation loss = 1.7802  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 3.1878  Validation loss = 1.7792  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 3.1875  Validation loss = 1.7788  \n",
      "\n",
      "Fold: 27  Epoch: 31  Training loss = 3.1873  Validation loss = 1.7781  \n",
      "\n",
      "Fold: 27  Epoch: 32  Training loss = 3.1863  Validation loss = 1.7775  \n",
      "\n",
      "Fold: 27  Epoch: 33  Training loss = 3.1850  Validation loss = 1.7761  \n",
      "\n",
      "Fold: 27  Epoch: 34  Training loss = 3.1840  Validation loss = 1.7752  \n",
      "\n",
      "Fold: 27  Epoch: 35  Training loss = 3.1821  Validation loss = 1.7738  \n",
      "\n",
      "Fold: 27  Epoch: 36  Training loss = 3.1818  Validation loss = 1.7738  \n",
      "\n",
      "Fold: 27  Epoch: 37  Training loss = 3.1813  Validation loss = 1.7732  \n",
      "\n",
      "Fold: 27  Epoch: 38  Training loss = 3.1806  Validation loss = 1.7722  \n",
      "\n",
      "Fold: 27  Epoch: 39  Training loss = 3.1803  Validation loss = 1.7718  \n",
      "\n",
      "Fold: 27  Epoch: 40  Training loss = 3.1778  Validation loss = 1.7695  \n",
      "\n",
      "Fold: 27  Epoch: 41  Training loss = 3.1775  Validation loss = 1.7692  \n",
      "\n",
      "Fold: 27  Epoch: 42  Training loss = 3.1771  Validation loss = 1.7692  \n",
      "\n",
      "Fold: 27  Epoch: 43  Training loss = 3.1768  Validation loss = 1.7687  \n",
      "\n",
      "Fold: 27  Epoch: 44  Training loss = 3.1767  Validation loss = 1.7687  \n",
      "\n",
      "Fold: 27  Epoch: 45  Training loss = 3.1765  Validation loss = 1.7688  \n",
      "\n",
      "Fold: 27  Epoch: 46  Training loss = 3.1762  Validation loss = 1.7682  \n",
      "\n",
      "Fold: 27  Epoch: 47  Training loss = 3.1753  Validation loss = 1.7668  \n",
      "\n",
      "Fold: 27  Epoch: 48  Training loss = 3.1748  Validation loss = 1.7664  \n",
      "\n",
      "Fold: 27  Epoch: 49  Training loss = 3.1738  Validation loss = 1.7658  \n",
      "\n",
      "Fold: 27  Epoch: 50  Training loss = 3.1732  Validation loss = 1.7648  \n",
      "\n",
      "Fold: 27  Epoch: 51  Training loss = 3.1727  Validation loss = 1.7645  \n",
      "\n",
      "Fold: 27  Epoch: 52  Training loss = 3.1721  Validation loss = 1.7638  \n",
      "\n",
      "Fold: 27  Epoch: 53  Training loss = 3.1713  Validation loss = 1.7630  \n",
      "\n",
      "Fold: 27  Epoch: 54  Training loss = 3.1709  Validation loss = 1.7623  \n",
      "\n",
      "Fold: 27  Epoch: 55  Training loss = 3.1700  Validation loss = 1.7612  \n",
      "\n",
      "Fold: 27  Epoch: 56  Training loss = 3.1696  Validation loss = 1.7609  \n",
      "\n",
      "Fold: 27  Epoch: 57  Training loss = 3.1690  Validation loss = 1.7599  \n",
      "\n",
      "Fold: 27  Epoch: 58  Training loss = 3.1689  Validation loss = 1.7598  \n",
      "\n",
      "Fold: 27  Epoch: 59  Training loss = 3.1687  Validation loss = 1.7596  \n",
      "\n",
      "Fold: 27  Epoch: 60  Training loss = 3.1684  Validation loss = 1.7591  \n",
      "\n",
      "Fold: 27  Epoch: 61  Training loss = 3.1680  Validation loss = 1.7586  \n",
      "\n",
      "Fold: 27  Epoch: 62  Training loss = 3.1673  Validation loss = 1.7586  \n",
      "\n",
      "Fold: 27  Epoch: 63  Training loss = 3.1669  Validation loss = 1.7581  \n",
      "\n",
      "Fold: 27  Epoch: 64  Training loss = 3.1667  Validation loss = 1.7582  \n",
      "\n",
      "Fold: 27  Epoch: 65  Training loss = 3.1660  Validation loss = 1.7577  \n",
      "\n",
      "Fold: 27  Epoch: 66  Training loss = 3.1658  Validation loss = 1.7572  \n",
      "\n",
      "Fold: 27  Epoch: 67  Training loss = 3.1654  Validation loss = 1.7567  \n",
      "\n",
      "Fold: 27  Epoch: 68  Training loss = 3.1650  Validation loss = 1.7558  \n",
      "\n",
      "Fold: 27  Epoch: 69  Training loss = 3.1646  Validation loss = 1.7545  \n",
      "\n",
      "Fold: 27  Epoch: 70  Training loss = 3.1644  Validation loss = 1.7540  \n",
      "\n",
      "Fold: 27  Epoch: 71  Training loss = 3.1636  Validation loss = 1.7527  \n",
      "\n",
      "Fold: 27  Epoch: 72  Training loss = 3.1632  Validation loss = 1.7524  \n",
      "\n",
      "Fold: 27  Epoch: 73  Training loss = 3.1630  Validation loss = 1.7522  \n",
      "\n",
      "Fold: 27  Epoch: 74  Training loss = 3.1625  Validation loss = 1.7513  \n",
      "\n",
      "Fold: 27  Epoch: 75  Training loss = 3.1622  Validation loss = 1.7507  \n",
      "\n",
      "Fold: 27  Epoch: 76  Training loss = 3.1620  Validation loss = 1.7503  \n",
      "\n",
      "Fold: 27  Epoch: 77  Training loss = 3.1611  Validation loss = 1.7491  \n",
      "\n",
      "Fold: 27  Epoch: 78  Training loss = 3.1608  Validation loss = 1.7492  \n",
      "\n",
      "Fold: 27  Epoch: 79  Training loss = 3.1607  Validation loss = 1.7499  \n",
      "\n",
      "Fold: 27  Epoch: 80  Training loss = 3.1604  Validation loss = 1.7501  \n",
      "\n",
      "Fold: 27  Epoch: 81  Training loss = 3.1599  Validation loss = 1.7495  \n",
      "\n",
      "Fold: 27  Epoch: 82  Training loss = 3.1591  Validation loss = 1.7484  \n",
      "\n",
      "Fold: 27  Epoch: 83  Training loss = 3.1589  Validation loss = 1.7483  \n",
      "\n",
      "Fold: 27  Epoch: 84  Training loss = 3.1582  Validation loss = 1.7471  \n",
      "\n",
      "Fold: 27  Epoch: 85  Training loss = 3.1582  Validation loss = 1.7470  \n",
      "\n",
      "Fold: 27  Epoch: 86  Training loss = 3.1578  Validation loss = 1.7469  \n",
      "\n",
      "Fold: 27  Epoch: 87  Training loss = 3.1576  Validation loss = 1.7464  \n",
      "\n",
      "Fold: 27  Epoch: 88  Training loss = 3.1572  Validation loss = 1.7462  \n",
      "\n",
      "Fold: 27  Epoch: 89  Training loss = 3.1567  Validation loss = 1.7453  \n",
      "\n",
      "Fold: 27  Epoch: 90  Training loss = 3.1557  Validation loss = 1.7438  \n",
      "\n",
      "Fold: 27  Epoch: 91  Training loss = 3.1551  Validation loss = 1.7430  \n",
      "\n",
      "Fold: 27  Epoch: 92  Training loss = 3.1547  Validation loss = 1.7420  \n",
      "\n",
      "Fold: 27  Epoch: 93  Training loss = 3.1543  Validation loss = 1.7415  \n",
      "\n",
      "Fold: 27  Epoch: 94  Training loss = 3.1540  Validation loss = 1.7409  \n",
      "\n",
      "Fold: 27  Epoch: 95  Training loss = 3.1536  Validation loss = 1.7403  \n",
      "\n",
      "Fold: 27  Epoch: 96  Training loss = 3.1532  Validation loss = 1.7388  \n",
      "\n",
      "Fold: 27  Epoch: 97  Training loss = 3.1529  Validation loss = 1.7388  \n",
      "\n",
      "Fold: 27  Epoch: 98  Training loss = 3.1526  Validation loss = 1.7383  \n",
      "\n",
      "Fold: 27  Epoch: 99  Training loss = 3.1521  Validation loss = 1.7377  \n",
      "\n",
      "Fold: 27  Epoch: 100  Training loss = 3.1514  Validation loss = 1.7360  \n",
      "\n",
      "Fold: 27  Epoch: 101  Training loss = 3.1510  Validation loss = 1.7354  \n",
      "\n",
      "Fold: 27  Epoch: 102  Training loss = 3.1509  Validation loss = 1.7355  \n",
      "\n",
      "Fold: 27  Epoch: 103  Training loss = 3.1509  Validation loss = 1.7360  \n",
      "\n",
      "Fold: 27  Epoch: 104  Training loss = 3.1507  Validation loss = 1.7358  \n",
      "\n",
      "Fold: 27  Epoch: 105  Training loss = 3.1506  Validation loss = 1.7361  \n",
      "\n",
      "Fold: 27  Epoch: 106  Training loss = 3.1504  Validation loss = 1.7358  \n",
      "\n",
      "Fold: 27  Epoch: 107  Training loss = 3.1502  Validation loss = 1.7356  \n",
      "\n",
      "Fold: 27  Epoch: 108  Training loss = 3.1501  Validation loss = 1.7356  \n",
      "\n",
      "Fold: 27  Epoch: 109  Training loss = 3.1499  Validation loss = 1.7356  \n",
      "\n",
      "Fold: 27  Epoch: 110  Training loss = 3.1496  Validation loss = 1.7349  \n",
      "\n",
      "Fold: 27  Epoch: 111  Training loss = 3.1493  Validation loss = 1.7345  \n",
      "\n",
      "Fold: 27  Epoch: 112  Training loss = 3.1491  Validation loss = 1.7346  \n",
      "\n",
      "Fold: 27  Epoch: 113  Training loss = 3.1488  Validation loss = 1.7338  \n",
      "\n",
      "Fold: 27  Epoch: 114  Training loss = 3.1485  Validation loss = 1.7327  \n",
      "\n",
      "Fold: 27  Epoch: 115  Training loss = 3.1480  Validation loss = 1.7316  \n",
      "\n",
      "Fold: 27  Epoch: 116  Training loss = 3.1478  Validation loss = 1.7313  \n",
      "\n",
      "Fold: 27  Epoch: 117  Training loss = 3.1476  Validation loss = 1.7310  \n",
      "\n",
      "Fold: 27  Epoch: 118  Training loss = 3.1474  Validation loss = 1.7309  \n",
      "\n",
      "Fold: 27  Epoch: 119  Training loss = 3.1471  Validation loss = 1.7301  \n",
      "\n",
      "Fold: 27  Epoch: 120  Training loss = 3.1468  Validation loss = 1.7295  \n",
      "\n",
      "Fold: 27  Epoch: 121  Training loss = 3.1467  Validation loss = 1.7294  \n",
      "\n",
      "Fold: 27  Epoch: 122  Training loss = 3.1465  Validation loss = 1.7291  \n",
      "\n",
      "Fold: 27  Epoch: 123  Training loss = 3.1463  Validation loss = 1.7286  \n",
      "\n",
      "Fold: 27  Epoch: 124  Training loss = 3.1461  Validation loss = 1.7281  \n",
      "\n",
      "Fold: 27  Epoch: 125  Training loss = 3.1458  Validation loss = 1.7278  \n",
      "\n",
      "Fold: 27  Epoch: 126  Training loss = 3.1457  Validation loss = 1.7279  \n",
      "\n",
      "Fold: 27  Epoch: 127  Training loss = 3.1454  Validation loss = 1.7269  \n",
      "\n",
      "Fold: 27  Epoch: 128  Training loss = 3.1452  Validation loss = 1.7268  \n",
      "\n",
      "Fold: 27  Epoch: 129  Training loss = 3.1450  Validation loss = 1.7265  \n",
      "\n",
      "Fold: 27  Epoch: 130  Training loss = 3.1448  Validation loss = 1.7261  \n",
      "\n",
      "Fold: 27  Epoch: 131  Training loss = 3.1447  Validation loss = 1.7261  \n",
      "\n",
      "Fold: 27  Epoch: 132  Training loss = 3.1445  Validation loss = 1.7257  \n",
      "\n",
      "Fold: 27  Epoch: 133  Training loss = 3.1443  Validation loss = 1.7256  \n",
      "\n",
      "Fold: 27  Epoch: 134  Training loss = 3.1440  Validation loss = 1.7252  \n",
      "\n",
      "Fold: 27  Epoch: 135  Training loss = 3.1439  Validation loss = 1.7252  \n",
      "\n",
      "Fold: 27  Epoch: 136  Training loss = 3.1439  Validation loss = 1.7252  \n",
      "\n",
      "Fold: 27  Epoch: 137  Training loss = 3.1436  Validation loss = 1.7246  \n",
      "\n",
      "Fold: 27  Epoch: 138  Training loss = 3.1434  Validation loss = 1.7244  \n",
      "\n",
      "Fold: 27  Epoch: 139  Training loss = 3.1432  Validation loss = 1.7237  \n",
      "\n",
      "Fold: 27  Epoch: 140  Training loss = 3.1430  Validation loss = 1.7236  \n",
      "\n",
      "Fold: 27  Epoch: 141  Training loss = 3.1426  Validation loss = 1.7227  \n",
      "\n",
      "Fold: 27  Epoch: 142  Training loss = 3.1425  Validation loss = 1.7229  \n",
      "\n",
      "Fold: 27  Epoch: 143  Training loss = 3.1421  Validation loss = 1.7217  \n",
      "\n",
      "Fold: 27  Epoch: 144  Training loss = 3.1418  Validation loss = 1.7211  \n",
      "\n",
      "Fold: 27  Epoch: 145  Training loss = 3.1415  Validation loss = 1.7201  \n",
      "\n",
      "Fold: 27  Epoch: 146  Training loss = 3.1412  Validation loss = 1.7198  \n",
      "\n",
      "Fold: 27  Epoch: 147  Training loss = 3.1409  Validation loss = 1.7192  \n",
      "\n",
      "Fold: 27  Epoch: 148  Training loss = 3.1407  Validation loss = 1.7193  \n",
      "\n",
      "Fold: 27  Epoch: 149  Training loss = 3.1404  Validation loss = 1.7188  \n",
      "\n",
      "Fold: 27  Epoch: 150  Training loss = 3.1402  Validation loss = 1.7180  \n",
      "\n",
      "Fold: 27  Epoch: 151  Training loss = 3.1400  Validation loss = 1.7183  \n",
      "\n",
      "Fold: 27  Epoch: 152  Training loss = 3.1398  Validation loss = 1.7180  \n",
      "\n",
      "Fold: 27  Epoch: 153  Training loss = 3.1397  Validation loss = 1.7176  \n",
      "\n",
      "Fold: 27  Epoch: 154  Training loss = 3.1396  Validation loss = 1.7180  \n",
      "\n",
      "Fold: 27  Epoch: 155  Training loss = 3.1394  Validation loss = 1.7175  \n",
      "\n",
      "Fold: 27  Epoch: 156  Training loss = 3.1392  Validation loss = 1.7174  \n",
      "\n",
      "Fold: 27  Epoch: 157  Training loss = 3.1389  Validation loss = 1.7169  \n",
      "\n",
      "Fold: 27  Epoch: 158  Training loss = 3.1389  Validation loss = 1.7175  \n",
      "\n",
      "Fold: 27  Epoch: 159  Training loss = 3.1386  Validation loss = 1.7171  \n",
      "\n",
      "Fold: 27  Epoch: 160  Training loss = 3.1382  Validation loss = 1.7160  \n",
      "\n",
      "Fold: 27  Epoch: 161  Training loss = 3.1381  Validation loss = 1.7160  \n",
      "\n",
      "Fold: 27  Epoch: 162  Training loss = 3.1379  Validation loss = 1.7156  \n",
      "\n",
      "Fold: 27  Epoch: 163  Training loss = 3.1376  Validation loss = 1.7152  \n",
      "\n",
      "Fold: 27  Epoch: 164  Training loss = 3.1375  Validation loss = 1.7151  \n",
      "\n",
      "Fold: 27  Epoch: 165  Training loss = 3.1373  Validation loss = 1.7147  \n",
      "\n",
      "Fold: 27  Epoch: 166  Training loss = 3.1371  Validation loss = 1.7146  \n",
      "\n",
      "Fold: 27  Epoch: 167  Training loss = 3.1369  Validation loss = 1.7143  \n",
      "\n",
      "Fold: 27  Epoch: 168  Training loss = 3.1367  Validation loss = 1.7141  \n",
      "\n",
      "Fold: 27  Epoch: 169  Training loss = 3.1366  Validation loss = 1.7136  \n",
      "\n",
      "Fold: 27  Epoch: 170  Training loss = 3.1364  Validation loss = 1.7131  \n",
      "\n",
      "Fold: 27  Epoch: 171  Training loss = 3.1360  Validation loss = 1.7119  \n",
      "\n",
      "Fold: 27  Epoch: 172  Training loss = 3.1358  Validation loss = 1.7111  \n",
      "\n",
      "Fold: 27  Epoch: 173  Training loss = 3.1355  Validation loss = 1.7105  \n",
      "\n",
      "Fold: 27  Epoch: 174  Training loss = 3.1354  Validation loss = 1.7110  \n",
      "\n",
      "Fold: 27  Epoch: 175  Training loss = 3.1353  Validation loss = 1.7112  \n",
      "\n",
      "Fold: 27  Epoch: 176  Training loss = 3.1350  Validation loss = 1.7111  \n",
      "\n",
      "Fold: 27  Epoch: 177  Training loss = 3.1349  Validation loss = 1.7113  \n",
      "\n",
      "Fold: 27  Epoch: 178  Training loss = 3.1347  Validation loss = 1.7108  \n",
      "\n",
      "Fold: 27  Epoch: 179  Training loss = 3.1345  Validation loss = 1.7104  \n",
      "\n",
      "Fold: 27  Epoch: 180  Training loss = 3.1343  Validation loss = 1.7100  \n",
      "\n",
      "Fold: 27  Epoch: 181  Training loss = 3.1341  Validation loss = 1.7095  \n",
      "\n",
      "Fold: 27  Epoch: 182  Training loss = 3.1338  Validation loss = 1.7093  \n",
      "\n",
      "Fold: 27  Epoch: 183  Training loss = 3.1336  Validation loss = 1.7092  \n",
      "\n",
      "Fold: 27  Epoch: 184  Training loss = 3.1333  Validation loss = 1.7083  \n",
      "\n",
      "Fold: 27  Epoch: 185  Training loss = 3.1331  Validation loss = 1.7076  \n",
      "\n",
      "Fold: 27  Epoch: 186  Training loss = 3.1329  Validation loss = 1.7070  \n",
      "\n",
      "Fold: 27  Epoch: 187  Training loss = 3.1328  Validation loss = 1.7067  \n",
      "\n",
      "Fold: 27  Epoch: 188  Training loss = 3.1326  Validation loss = 1.7069  \n",
      "\n",
      "Fold: 27  Epoch: 189  Training loss = 3.1325  Validation loss = 1.7067  \n",
      "\n",
      "Fold: 27  Epoch: 190  Training loss = 3.1321  Validation loss = 1.7054  \n",
      "\n",
      "Fold: 27  Epoch: 191  Training loss = 3.1320  Validation loss = 1.7052  \n",
      "\n",
      "Fold: 27  Epoch: 192  Training loss = 3.1319  Validation loss = 1.7054  \n",
      "\n",
      "Fold: 27  Epoch: 193  Training loss = 3.1318  Validation loss = 1.7054  \n",
      "\n",
      "Fold: 27  Epoch: 194  Training loss = 3.1316  Validation loss = 1.7052  \n",
      "\n",
      "Fold: 27  Epoch: 195  Training loss = 3.1315  Validation loss = 1.7048  \n",
      "\n",
      "Fold: 27  Epoch: 196  Training loss = 3.1312  Validation loss = 1.7036  \n",
      "\n",
      "Fold: 27  Epoch: 197  Training loss = 3.1311  Validation loss = 1.7037  \n",
      "\n",
      "Fold: 27  Epoch: 198  Training loss = 3.1310  Validation loss = 1.7035  \n",
      "\n",
      "Fold: 27  Epoch: 199  Training loss = 3.1309  Validation loss = 1.7037  \n",
      "\n",
      "Fold: 27  Epoch: 200  Training loss = 3.1308  Validation loss = 1.7037  \n",
      "\n",
      "Fold: 27  Epoch: 201  Training loss = 3.1306  Validation loss = 1.7034  \n",
      "\n",
      "Fold: 27  Epoch: 202  Training loss = 3.1304  Validation loss = 1.7028  \n",
      "\n",
      "Fold: 27  Epoch: 203  Training loss = 3.1301  Validation loss = 1.7021  \n",
      "\n",
      "Fold: 27  Epoch: 204  Training loss = 3.1299  Validation loss = 1.7015  \n",
      "\n",
      "Fold: 27  Epoch: 205  Training loss = 3.1296  Validation loss = 1.7006  \n",
      "\n",
      "Fold: 27  Epoch: 206  Training loss = 3.1295  Validation loss = 1.7009  \n",
      "\n",
      "Fold: 27  Epoch: 207  Training loss = 3.1294  Validation loss = 1.7010  \n",
      "\n",
      "Fold: 27  Epoch: 208  Training loss = 3.1291  Validation loss = 1.7002  \n",
      "\n",
      "Fold: 27  Epoch: 209  Training loss = 3.1289  Validation loss = 1.6998  \n",
      "\n",
      "Fold: 27  Epoch: 210  Training loss = 3.1288  Validation loss = 1.6993  \n",
      "\n",
      "Fold: 27  Epoch: 211  Training loss = 3.1286  Validation loss = 1.6987  \n",
      "\n",
      "Fold: 27  Epoch: 212  Training loss = 3.1285  Validation loss = 1.6982  \n",
      "\n",
      "Fold: 27  Epoch: 213  Training loss = 3.1282  Validation loss = 1.6975  \n",
      "\n",
      "Fold: 27  Epoch: 214  Training loss = 3.1281  Validation loss = 1.6973  \n",
      "\n",
      "Fold: 27  Epoch: 215  Training loss = 3.1278  Validation loss = 1.6962  \n",
      "\n",
      "Fold: 27  Epoch: 216  Training loss = 3.1277  Validation loss = 1.6962  \n",
      "\n",
      "Fold: 27  Epoch: 217  Training loss = 3.1274  Validation loss = 1.6951  \n",
      "\n",
      "Fold: 27  Epoch: 218  Training loss = 3.1272  Validation loss = 1.6951  \n",
      "\n",
      "Fold: 27  Epoch: 219  Training loss = 3.1270  Validation loss = 1.6946  \n",
      "\n",
      "Fold: 27  Epoch: 220  Training loss = 3.1268  Validation loss = 1.6946  \n",
      "\n",
      "Fold: 27  Epoch: 221  Training loss = 3.1267  Validation loss = 1.6952  \n",
      "\n",
      "Fold: 27  Epoch: 222  Training loss = 3.1265  Validation loss = 1.6948  \n",
      "\n",
      "Fold: 27  Epoch: 223  Training loss = 3.1263  Validation loss = 1.6945  \n",
      "\n",
      "Fold: 27  Epoch: 224  Training loss = 3.1261  Validation loss = 1.6941  \n",
      "\n",
      "Fold: 27  Epoch: 225  Training loss = 3.1259  Validation loss = 1.6938  \n",
      "\n",
      "Fold: 27  Epoch: 226  Training loss = 3.1257  Validation loss = 1.6935  \n",
      "\n",
      "Fold: 27  Epoch: 227  Training loss = 3.1254  Validation loss = 1.6928  \n",
      "\n",
      "Fold: 27  Epoch: 228  Training loss = 3.1252  Validation loss = 1.6925  \n",
      "\n",
      "Fold: 27  Epoch: 229  Training loss = 3.1250  Validation loss = 1.6921  \n",
      "\n",
      "Fold: 27  Epoch: 230  Training loss = 3.1249  Validation loss = 1.6919  \n",
      "\n",
      "Fold: 27  Epoch: 231  Training loss = 3.1247  Validation loss = 1.6915  \n",
      "\n",
      "Fold: 27  Epoch: 232  Training loss = 3.1245  Validation loss = 1.6907  \n",
      "\n",
      "Fold: 27  Epoch: 233  Training loss = 3.1243  Validation loss = 1.6906  \n",
      "\n",
      "Fold: 27  Epoch: 234  Training loss = 3.1241  Validation loss = 1.6898  \n",
      "\n",
      "Fold: 27  Epoch: 235  Training loss = 3.1240  Validation loss = 1.6890  \n",
      "\n",
      "Fold: 27  Epoch: 236  Training loss = 3.1238  Validation loss = 1.6884  \n",
      "\n",
      "Fold: 27  Epoch: 237  Training loss = 3.1236  Validation loss = 1.6879  \n",
      "\n",
      "Fold: 27  Epoch: 238  Training loss = 3.1234  Validation loss = 1.6869  \n",
      "\n",
      "Fold: 27  Epoch: 239  Training loss = 3.1232  Validation loss = 1.6860  \n",
      "\n",
      "Fold: 27  Epoch: 240  Training loss = 3.1229  Validation loss = 1.6853  \n",
      "\n",
      "Fold: 27  Epoch: 241  Training loss = 3.1227  Validation loss = 1.6844  \n",
      "\n",
      "Fold: 27  Epoch: 242  Training loss = 3.1226  Validation loss = 1.6851  \n",
      "\n",
      "Fold: 27  Epoch: 243  Training loss = 3.1224  Validation loss = 1.6848  \n",
      "\n",
      "Fold: 27  Epoch: 244  Training loss = 3.1222  Validation loss = 1.6841  \n",
      "\n",
      "Fold: 27  Epoch: 245  Training loss = 3.1219  Validation loss = 1.6826  \n",
      "\n",
      "Fold: 27  Epoch: 246  Training loss = 3.1218  Validation loss = 1.6825  \n",
      "\n",
      "Fold: 27  Epoch: 247  Training loss = 3.1217  Validation loss = 1.6821  \n",
      "\n",
      "Fold: 27  Epoch: 248  Training loss = 3.1215  Validation loss = 1.6817  \n",
      "\n",
      "Fold: 27  Epoch: 249  Training loss = 3.1213  Validation loss = 1.6812  \n",
      "\n",
      "Fold: 27  Epoch: 250  Training loss = 3.1211  Validation loss = 1.6802  \n",
      "\n",
      "Fold: 27  Epoch: 251  Training loss = 3.1209  Validation loss = 1.6792  \n",
      "\n",
      "Fold: 27  Epoch: 252  Training loss = 3.1207  Validation loss = 1.6785  \n",
      "\n",
      "Fold: 27  Epoch: 253  Training loss = 3.1205  Validation loss = 1.6774  \n",
      "\n",
      "Fold: 27  Epoch: 254  Training loss = 3.1203  Validation loss = 1.6767  \n",
      "\n",
      "Fold: 27  Epoch: 255  Training loss = 3.1201  Validation loss = 1.6753  \n",
      "\n",
      "Fold: 27  Epoch: 256  Training loss = 3.1199  Validation loss = 1.6749  \n",
      "\n",
      "Fold: 27  Epoch: 257  Training loss = 3.1197  Validation loss = 1.6750  \n",
      "\n",
      "Fold: 27  Epoch: 258  Training loss = 3.1195  Validation loss = 1.6743  \n",
      "\n",
      "Fold: 27  Epoch: 259  Training loss = 3.1192  Validation loss = 1.6735  \n",
      "\n",
      "Fold: 27  Epoch: 260  Training loss = 3.1189  Validation loss = 1.6734  \n",
      "\n",
      "Fold: 27  Epoch: 261  Training loss = 3.1187  Validation loss = 1.6737  \n",
      "\n",
      "Fold: 27  Epoch: 262  Training loss = 3.1185  Validation loss = 1.6738  \n",
      "\n",
      "Fold: 27  Epoch: 263  Training loss = 3.1183  Validation loss = 1.6728  \n",
      "\n",
      "Fold: 27  Epoch: 264  Training loss = 3.1182  Validation loss = 1.6718  \n",
      "\n",
      "Fold: 27  Epoch: 265  Training loss = 3.1179  Validation loss = 1.6718  \n",
      "\n",
      "Fold: 27  Epoch: 266  Training loss = 3.1178  Validation loss = 1.6720  \n",
      "\n",
      "Fold: 27  Epoch: 267  Training loss = 3.1176  Validation loss = 1.6710  \n",
      "\n",
      "Fold: 27  Epoch: 268  Training loss = 3.1173  Validation loss = 1.6708  \n",
      "\n",
      "Fold: 27  Epoch: 269  Training loss = 3.1171  Validation loss = 1.6703  \n",
      "\n",
      "Fold: 27  Epoch: 270  Training loss = 3.1168  Validation loss = 1.6698  \n",
      "\n",
      "Fold: 27  Epoch: 271  Training loss = 3.1166  Validation loss = 1.6702  \n",
      "\n",
      "Fold: 27  Epoch: 272  Training loss = 3.1163  Validation loss = 1.6697  \n",
      "\n",
      "Fold: 27  Epoch: 273  Training loss = 3.1161  Validation loss = 1.6687  \n",
      "\n",
      "Fold: 27  Epoch: 274  Training loss = 3.1158  Validation loss = 1.6690  \n",
      "\n",
      "Fold: 27  Epoch: 275  Training loss = 3.1155  Validation loss = 1.6688  \n",
      "\n",
      "Fold: 27  Epoch: 276  Training loss = 3.1153  Validation loss = 1.6687  \n",
      "\n",
      "Fold: 27  Epoch: 277  Training loss = 3.1149  Validation loss = 1.6678  \n",
      "\n",
      "Fold: 27  Epoch: 278  Training loss = 3.1146  Validation loss = 1.6674  \n",
      "\n",
      "Fold: 27  Epoch: 279  Training loss = 3.1144  Validation loss = 1.6676  \n",
      "\n",
      "Fold: 27  Epoch: 280  Training loss = 3.1143  Validation loss = 1.6679  \n",
      "\n",
      "Fold: 27  Epoch: 281  Training loss = 3.1139  Validation loss = 1.6677  \n",
      "\n",
      "Fold: 27  Epoch: 282  Training loss = 3.1138  Validation loss = 1.6678  \n",
      "\n",
      "Fold: 27  Epoch: 283  Training loss = 3.1134  Validation loss = 1.6673  \n",
      "\n",
      "Fold: 27  Epoch: 284  Training loss = 3.1131  Validation loss = 1.6674  \n",
      "\n",
      "Fold: 27  Epoch: 285  Training loss = 3.1128  Validation loss = 1.6670  \n",
      "\n",
      "Fold: 27  Epoch: 286  Training loss = 3.1125  Validation loss = 1.6671  \n",
      "\n",
      "Fold: 27  Epoch: 287  Training loss = 3.1123  Validation loss = 1.6673  \n",
      "\n",
      "Fold: 27  Epoch: 288  Training loss = 3.1119  Validation loss = 1.6665  \n",
      "\n",
      "Fold: 27  Epoch: 289  Training loss = 3.1115  Validation loss = 1.6651  \n",
      "\n",
      "Fold: 27  Epoch: 290  Training loss = 3.1113  Validation loss = 1.6640  \n",
      "\n",
      "Fold: 27  Epoch: 291  Training loss = 3.1112  Validation loss = 1.6646  \n",
      "\n",
      "Fold: 27  Epoch: 292  Training loss = 3.1111  Validation loss = 1.6647  \n",
      "\n",
      "Fold: 27  Epoch: 293  Training loss = 3.1109  Validation loss = 1.6647  \n",
      "\n",
      "Fold: 27  Epoch: 294  Training loss = 3.1108  Validation loss = 1.6651  \n",
      "\n",
      "Fold: 27  Epoch: 295  Training loss = 3.1106  Validation loss = 1.6647  \n",
      "\n",
      "Fold: 27  Epoch: 296  Training loss = 3.1107  Validation loss = 1.6657  \n",
      "\n",
      "Fold: 27  Epoch: 297  Training loss = 3.1104  Validation loss = 1.6650  \n",
      "\n",
      "Fold: 27  Epoch: 298  Training loss = 3.1102  Validation loss = 1.6644  \n",
      "\n",
      "Fold: 27  Epoch: 299  Training loss = 3.1101  Validation loss = 1.6646  \n",
      "\n",
      "Fold: 27  Epoch: 300  Training loss = 3.1098  Validation loss = 1.6638  \n",
      "\n",
      "Fold: 27  Epoch: 301  Training loss = 3.1096  Validation loss = 1.6635  \n",
      "\n",
      "Fold: 27  Epoch: 302  Training loss = 3.1094  Validation loss = 1.6635  \n",
      "\n",
      "Fold: 27  Epoch: 303  Training loss = 3.1091  Validation loss = 1.6626  \n",
      "\n",
      "Fold: 27  Epoch: 304  Training loss = 3.1090  Validation loss = 1.6623  \n",
      "\n",
      "Fold: 27  Epoch: 305  Training loss = 3.1088  Validation loss = 1.6616  \n",
      "\n",
      "Fold: 27  Epoch: 306  Training loss = 3.1086  Validation loss = 1.6610  \n",
      "\n",
      "Fold: 27  Epoch: 307  Training loss = 3.1083  Validation loss = 1.6598  \n",
      "\n",
      "Fold: 27  Epoch: 308  Training loss = 3.1081  Validation loss = 1.6590  \n",
      "\n",
      "Fold: 27  Epoch: 309  Training loss = 3.1079  Validation loss = 1.6588  \n",
      "\n",
      "Fold: 27  Epoch: 310  Training loss = 3.1077  Validation loss = 1.6575  \n",
      "\n",
      "Fold: 27  Epoch: 311  Training loss = 3.1076  Validation loss = 1.6580  \n",
      "\n",
      "Fold: 27  Epoch: 312  Training loss = 3.1074  Validation loss = 1.6573  \n",
      "\n",
      "Fold: 27  Epoch: 313  Training loss = 3.1073  Validation loss = 1.6572  \n",
      "\n",
      "Fold: 27  Epoch: 314  Training loss = 3.1072  Validation loss = 1.6577  \n",
      "\n",
      "Fold: 27  Epoch: 315  Training loss = 3.1070  Validation loss = 1.6568  \n",
      "\n",
      "Fold: 27  Epoch: 316  Training loss = 3.1068  Validation loss = 1.6575  \n",
      "\n",
      "Fold: 27  Epoch: 317  Training loss = 3.1067  Validation loss = 1.6576  \n",
      "\n",
      "Fold: 27  Epoch: 318  Training loss = 3.1065  Validation loss = 1.6574  \n",
      "\n",
      "Fold: 27  Epoch: 319  Training loss = 3.1064  Validation loss = 1.6571  \n",
      "\n",
      "Fold: 27  Epoch: 320  Training loss = 3.1063  Validation loss = 1.6565  \n",
      "\n",
      "Fold: 27  Epoch: 321  Training loss = 3.1061  Validation loss = 1.6562  \n",
      "\n",
      "Fold: 27  Epoch: 322  Training loss = 3.1060  Validation loss = 1.6566  \n",
      "\n",
      "Fold: 27  Epoch: 323  Training loss = 3.1058  Validation loss = 1.6563  \n",
      "\n",
      "Fold: 27  Epoch: 324  Training loss = 3.1056  Validation loss = 1.6557  \n",
      "\n",
      "Fold: 27  Epoch: 325  Training loss = 3.1054  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 27  Epoch: 326  Training loss = 3.1053  Validation loss = 1.6552  \n",
      "\n",
      "Fold: 27  Epoch: 327  Training loss = 3.1051  Validation loss = 1.6549  \n",
      "\n",
      "Fold: 27  Epoch: 328  Training loss = 3.1049  Validation loss = 1.6535  \n",
      "\n",
      "Fold: 27  Epoch: 329  Training loss = 3.1047  Validation loss = 1.6533  \n",
      "\n",
      "Fold: 27  Epoch: 330  Training loss = 3.1045  Validation loss = 1.6529  \n",
      "\n",
      "Fold: 27  Epoch: 331  Training loss = 3.1043  Validation loss = 1.6527  \n",
      "\n",
      "Fold: 27  Epoch: 332  Training loss = 3.1041  Validation loss = 1.6521  \n",
      "\n",
      "Fold: 27  Epoch: 333  Training loss = 3.1040  Validation loss = 1.6517  \n",
      "\n",
      "Fold: 27  Epoch: 334  Training loss = 3.1038  Validation loss = 1.6516  \n",
      "\n",
      "Fold: 27  Epoch: 335  Training loss = 3.1037  Validation loss = 1.6512  \n",
      "\n",
      "Fold: 27  Epoch: 336  Training loss = 3.1035  Validation loss = 1.6506  \n",
      "\n",
      "Fold: 27  Epoch: 337  Training loss = 3.1033  Validation loss = 1.6498  \n",
      "\n",
      "Fold: 27  Epoch: 338  Training loss = 3.1032  Validation loss = 1.6491  \n",
      "\n",
      "Fold: 27  Epoch: 339  Training loss = 3.1030  Validation loss = 1.6490  \n",
      "\n",
      "Fold: 27  Epoch: 340  Training loss = 3.1028  Validation loss = 1.6477  \n",
      "\n",
      "Fold: 27  Epoch: 341  Training loss = 3.1026  Validation loss = 1.6479  \n",
      "\n",
      "Fold: 27  Epoch: 342  Training loss = 3.1025  Validation loss = 1.6477  \n",
      "\n",
      "Fold: 27  Epoch: 343  Training loss = 3.1023  Validation loss = 1.6469  \n",
      "\n",
      "Fold: 27  Epoch: 344  Training loss = 3.1022  Validation loss = 1.6467  \n",
      "\n",
      "Fold: 27  Epoch: 345  Training loss = 3.1020  Validation loss = 1.6454  \n",
      "\n",
      "Fold: 27  Epoch: 346  Training loss = 3.1018  Validation loss = 1.6449  \n",
      "\n",
      "Fold: 27  Epoch: 347  Training loss = 3.1016  Validation loss = 1.6462  \n",
      "\n",
      "Fold: 27  Epoch: 348  Training loss = 3.1015  Validation loss = 1.6463  \n",
      "\n",
      "Fold: 27  Epoch: 349  Training loss = 3.1012  Validation loss = 1.6451  \n",
      "\n",
      "Fold: 27  Epoch: 350  Training loss = 3.1011  Validation loss = 1.6451  \n",
      "\n",
      "Fold: 27  Epoch: 351  Training loss = 3.1009  Validation loss = 1.6446  \n",
      "\n",
      "Fold: 27  Epoch: 352  Training loss = 3.1007  Validation loss = 1.6441  \n",
      "\n",
      "Fold: 27  Epoch: 353  Training loss = 3.1005  Validation loss = 1.6444  \n",
      "\n",
      "Fold: 27  Epoch: 354  Training loss = 3.1004  Validation loss = 1.6450  \n",
      "\n",
      "Fold: 27  Epoch: 355  Training loss = 3.1003  Validation loss = 1.6461  \n",
      "\n",
      "Fold: 27  Epoch: 356  Training loss = 3.1002  Validation loss = 1.6461  \n",
      "\n",
      "Fold: 27  Epoch: 357  Training loss = 3.1000  Validation loss = 1.6452  \n",
      "\n",
      "Fold: 27  Epoch: 358  Training loss = 3.0997  Validation loss = 1.6442  \n",
      "\n",
      "Fold: 27  Epoch: 359  Training loss = 3.0996  Validation loss = 1.6435  \n",
      "\n",
      "Fold: 27  Epoch: 360  Training loss = 3.0995  Validation loss = 1.6435  \n",
      "\n",
      "Fold: 27  Epoch: 361  Training loss = 3.0993  Validation loss = 1.6422  \n",
      "\n",
      "Fold: 27  Epoch: 362  Training loss = 3.0991  Validation loss = 1.6419  \n",
      "\n",
      "Fold: 27  Epoch: 363  Training loss = 3.0989  Validation loss = 1.6415  \n",
      "\n",
      "Fold: 27  Epoch: 364  Training loss = 3.0988  Validation loss = 1.6408  \n",
      "\n",
      "Fold: 27  Epoch: 365  Training loss = 3.0987  Validation loss = 1.6407  \n",
      "\n",
      "Fold: 27  Epoch: 366  Training loss = 3.0985  Validation loss = 1.6406  \n",
      "\n",
      "Fold: 27  Epoch: 367  Training loss = 3.0984  Validation loss = 1.6406  \n",
      "\n",
      "Fold: 27  Epoch: 368  Training loss = 3.0983  Validation loss = 1.6401  \n",
      "\n",
      "Fold: 27  Epoch: 369  Training loss = 3.0981  Validation loss = 1.6397  \n",
      "\n",
      "Fold: 27  Epoch: 370  Training loss = 3.0979  Validation loss = 1.6392  \n",
      "\n",
      "Fold: 27  Epoch: 371  Training loss = 3.0979  Validation loss = 1.6399  \n",
      "\n",
      "Fold: 27  Epoch: 372  Training loss = 3.0977  Validation loss = 1.6396  \n",
      "\n",
      "Fold: 27  Epoch: 373  Training loss = 3.0975  Validation loss = 1.6392  \n",
      "\n",
      "Fold: 27  Epoch: 374  Training loss = 3.0973  Validation loss = 1.6391  \n",
      "\n",
      "Fold: 27  Epoch: 375  Training loss = 3.0971  Validation loss = 1.6382  \n",
      "\n",
      "Fold: 27  Epoch: 376  Training loss = 3.0970  Validation loss = 1.6377  \n",
      "\n",
      "Fold: 27  Epoch: 377  Training loss = 3.0967  Validation loss = 1.6362  \n",
      "\n",
      "Fold: 27  Epoch: 378  Training loss = 3.0965  Validation loss = 1.6356  \n",
      "\n",
      "Fold: 27  Epoch: 379  Training loss = 3.0964  Validation loss = 1.6366  \n",
      "\n",
      "Fold: 27  Epoch: 380  Training loss = 3.0961  Validation loss = 1.6358  \n",
      "\n",
      "Fold: 27  Epoch: 381  Training loss = 3.0960  Validation loss = 1.6361  \n",
      "\n",
      "Fold: 27  Epoch: 382  Training loss = 3.0959  Validation loss = 1.6359  \n",
      "\n",
      "Fold: 27  Epoch: 383  Training loss = 3.0957  Validation loss = 1.6351  \n",
      "\n",
      "Fold: 27  Epoch: 384  Training loss = 3.0955  Validation loss = 1.6352  \n",
      "\n",
      "Fold: 27  Epoch: 385  Training loss = 3.0953  Validation loss = 1.6345  \n",
      "\n",
      "Fold: 27  Epoch: 386  Training loss = 3.0951  Validation loss = 1.6333  \n",
      "\n",
      "Fold: 27  Epoch: 387  Training loss = 3.0949  Validation loss = 1.6330  \n",
      "\n",
      "Fold: 27  Epoch: 388  Training loss = 3.0947  Validation loss = 1.6320  \n",
      "\n",
      "Fold: 27  Epoch: 389  Training loss = 3.0945  Validation loss = 1.6316  \n",
      "\n",
      "Fold: 27  Epoch: 390  Training loss = 3.0944  Validation loss = 1.6311  \n",
      "\n",
      "Fold: 27  Epoch: 391  Training loss = 3.0943  Validation loss = 1.6317  \n",
      "\n",
      "Fold: 27  Epoch: 392  Training loss = 3.0941  Validation loss = 1.6317  \n",
      "\n",
      "Fold: 27  Epoch: 393  Training loss = 3.0940  Validation loss = 1.6314  \n",
      "\n",
      "Fold: 27  Epoch: 394  Training loss = 3.0938  Validation loss = 1.6306  \n",
      "\n",
      "Fold: 27  Epoch: 395  Training loss = 3.0937  Validation loss = 1.6306  \n",
      "\n",
      "Fold: 27  Epoch: 396  Training loss = 3.0934  Validation loss = 1.6296  \n",
      "\n",
      "Fold: 27  Epoch: 397  Training loss = 3.0933  Validation loss = 1.6288  \n",
      "\n",
      "Fold: 27  Epoch: 398  Training loss = 3.0931  Validation loss = 1.6291  \n",
      "\n",
      "Fold: 27  Epoch: 399  Training loss = 3.0930  Validation loss = 1.6287  \n",
      "\n",
      "Fold: 27  Epoch: 400  Training loss = 3.0928  Validation loss = 1.6287  \n",
      "\n",
      "Fold: 27  Epoch: 401  Training loss = 3.0926  Validation loss = 1.6286  \n",
      "\n",
      "Fold: 27  Epoch: 402  Training loss = 3.0924  Validation loss = 1.6279  \n",
      "\n",
      "Fold: 27  Epoch: 403  Training loss = 3.0922  Validation loss = 1.6273  \n",
      "\n",
      "Fold: 27  Epoch: 404  Training loss = 3.0920  Validation loss = 1.6278  \n",
      "\n",
      "Fold: 27  Epoch: 405  Training loss = 3.0918  Validation loss = 1.6275  \n",
      "\n",
      "Fold: 27  Epoch: 406  Training loss = 3.0916  Validation loss = 1.6264  \n",
      "\n",
      "Fold: 27  Epoch: 407  Training loss = 3.0915  Validation loss = 1.6251  \n",
      "\n",
      "Fold: 27  Epoch: 408  Training loss = 3.0913  Validation loss = 1.6246  \n",
      "\n",
      "Fold: 27  Epoch: 409  Training loss = 3.0911  Validation loss = 1.6249  \n",
      "\n",
      "Fold: 27  Epoch: 410  Training loss = 3.0910  Validation loss = 1.6245  \n",
      "\n",
      "Fold: 27  Epoch: 411  Training loss = 3.0908  Validation loss = 1.6242  \n",
      "\n",
      "Fold: 27  Epoch: 412  Training loss = 3.0907  Validation loss = 1.6233  \n",
      "\n",
      "Fold: 27  Epoch: 413  Training loss = 3.0905  Validation loss = 1.6227  \n",
      "\n",
      "Fold: 27  Epoch: 414  Training loss = 3.0902  Validation loss = 1.6226  \n",
      "\n",
      "Fold: 27  Epoch: 415  Training loss = 3.0900  Validation loss = 1.6222  \n",
      "\n",
      "Fold: 27  Epoch: 416  Training loss = 3.0899  Validation loss = 1.6217  \n",
      "\n",
      "Fold: 27  Epoch: 417  Training loss = 3.0897  Validation loss = 1.6208  \n",
      "\n",
      "Fold: 27  Epoch: 418  Training loss = 3.0895  Validation loss = 1.6204  \n",
      "\n",
      "Fold: 27  Epoch: 419  Training loss = 3.0892  Validation loss = 1.6199  \n",
      "\n",
      "Fold: 27  Epoch: 420  Training loss = 3.0891  Validation loss = 1.6189  \n",
      "\n",
      "Fold: 27  Epoch: 421  Training loss = 3.0888  Validation loss = 1.6195  \n",
      "\n",
      "Fold: 27  Epoch: 422  Training loss = 3.0887  Validation loss = 1.6177  \n",
      "\n",
      "Fold: 27  Epoch: 423  Training loss = 3.0884  Validation loss = 1.6178  \n",
      "\n",
      "Fold: 27  Epoch: 424  Training loss = 3.0882  Validation loss = 1.6181  \n",
      "\n",
      "Fold: 27  Epoch: 425  Training loss = 3.0881  Validation loss = 1.6183  \n",
      "\n",
      "Fold: 27  Epoch: 426  Training loss = 3.0879  Validation loss = 1.6177  \n",
      "\n",
      "Fold: 27  Epoch: 427  Training loss = 3.0878  Validation loss = 1.6173  \n",
      "\n",
      "Fold: 27  Epoch: 428  Training loss = 3.0877  Validation loss = 1.6165  \n",
      "\n",
      "Fold: 27  Epoch: 429  Training loss = 3.0875  Validation loss = 1.6166  \n",
      "\n",
      "Fold: 27  Epoch: 430  Training loss = 3.0873  Validation loss = 1.6158  \n",
      "\n",
      "Fold: 27  Epoch: 431  Training loss = 3.0870  Validation loss = 1.6164  \n",
      "\n",
      "Fold: 27  Epoch: 432  Training loss = 3.0869  Validation loss = 1.6153  \n",
      "\n",
      "Fold: 27  Epoch: 433  Training loss = 3.0868  Validation loss = 1.6159  \n",
      "\n",
      "Fold: 27  Epoch: 434  Training loss = 3.0865  Validation loss = 1.6160  \n",
      "\n",
      "Fold: 27  Epoch: 435  Training loss = 3.0864  Validation loss = 1.6163  \n",
      "\n",
      "Fold: 27  Epoch: 436  Training loss = 3.0862  Validation loss = 1.6160  \n",
      "\n",
      "Fold: 27  Epoch: 437  Training loss = 3.0861  Validation loss = 1.6157  \n",
      "\n",
      "Fold: 27  Epoch: 438  Training loss = 3.0859  Validation loss = 1.6164  \n",
      "\n",
      "Fold: 27  Epoch: 439  Training loss = 3.0858  Validation loss = 1.6163  \n",
      "\n",
      "Fold: 27  Epoch: 440  Training loss = 3.0857  Validation loss = 1.6156  \n",
      "\n",
      "Fold: 27  Epoch: 441  Training loss = 3.0855  Validation loss = 1.6147  \n",
      "\n",
      "Fold: 27  Epoch: 442  Training loss = 3.0853  Validation loss = 1.6147  \n",
      "\n",
      "Fold: 27  Epoch: 443  Training loss = 3.0852  Validation loss = 1.6145  \n",
      "\n",
      "Fold: 27  Epoch: 444  Training loss = 3.0850  Validation loss = 1.6145  \n",
      "\n",
      "Fold: 27  Epoch: 445  Training loss = 3.0847  Validation loss = 1.6142  \n",
      "\n",
      "Fold: 27  Epoch: 446  Training loss = 3.0846  Validation loss = 1.6142  \n",
      "\n",
      "Fold: 27  Epoch: 447  Training loss = 3.0844  Validation loss = 1.6131  \n",
      "\n",
      "Fold: 27  Epoch: 448  Training loss = 3.0842  Validation loss = 1.6121  \n",
      "\n",
      "Fold: 27  Epoch: 449  Training loss = 3.0840  Validation loss = 1.6116  \n",
      "\n",
      "Fold: 27  Epoch: 450  Training loss = 3.0838  Validation loss = 1.6115  \n",
      "\n",
      "Fold: 27  Epoch: 451  Training loss = 3.0837  Validation loss = 1.6107  \n",
      "\n",
      "Fold: 27  Epoch: 452  Training loss = 3.0836  Validation loss = 1.6122  \n",
      "\n",
      "Fold: 27  Epoch: 453  Training loss = 3.0835  Validation loss = 1.6119  \n",
      "\n",
      "Fold: 27  Epoch: 454  Training loss = 3.0834  Validation loss = 1.6128  \n",
      "\n",
      "Fold: 27  Epoch: 455  Training loss = 3.0832  Validation loss = 1.6118  \n",
      "\n",
      "Fold: 27  Epoch: 456  Training loss = 3.0830  Validation loss = 1.6112  \n",
      "\n",
      "Fold: 27  Epoch: 457  Training loss = 3.0829  Validation loss = 1.6106  \n",
      "\n",
      "Fold: 27  Epoch: 458  Training loss = 3.0827  Validation loss = 1.6105  \n",
      "\n",
      "Fold: 27  Epoch: 459  Training loss = 3.0825  Validation loss = 1.6100  \n",
      "\n",
      "Fold: 27  Epoch: 460  Training loss = 3.0823  Validation loss = 1.6098  \n",
      "\n",
      "Fold: 27  Epoch: 461  Training loss = 3.0822  Validation loss = 1.6093  \n",
      "\n",
      "Fold: 27  Epoch: 462  Training loss = 3.0820  Validation loss = 1.6087  \n",
      "\n",
      "Fold: 27  Epoch: 463  Training loss = 3.0819  Validation loss = 1.6088  \n",
      "\n",
      "Fold: 27  Epoch: 464  Training loss = 3.0817  Validation loss = 1.6085  \n",
      "\n",
      "Fold: 27  Epoch: 465  Training loss = 3.0815  Validation loss = 1.6076  \n",
      "\n",
      "Fold: 27  Epoch: 466  Training loss = 3.0813  Validation loss = 1.6071  \n",
      "\n",
      "Fold: 27  Epoch: 467  Training loss = 3.0811  Validation loss = 1.6068  \n",
      "\n",
      "Fold: 27  Epoch: 468  Training loss = 3.0810  Validation loss = 1.6062  \n",
      "\n",
      "Fold: 27  Epoch: 469  Training loss = 3.0809  Validation loss = 1.6058  \n",
      "\n",
      "Fold: 27  Epoch: 470  Training loss = 3.0807  Validation loss = 1.6057  \n",
      "\n",
      "Fold: 27  Epoch: 471  Training loss = 3.0806  Validation loss = 1.6058  \n",
      "\n",
      "Fold: 27  Epoch: 472  Training loss = 3.0805  Validation loss = 1.6052  \n",
      "\n",
      "Fold: 27  Epoch: 473  Training loss = 3.0803  Validation loss = 1.6048  \n",
      "\n",
      "Fold: 27  Epoch: 474  Training loss = 3.0801  Validation loss = 1.6040  \n",
      "\n",
      "Fold: 27  Epoch: 475  Training loss = 3.0799  Validation loss = 1.6030  \n",
      "\n",
      "Fold: 27  Epoch: 476  Training loss = 3.0797  Validation loss = 1.6027  \n",
      "\n",
      "Fold: 27  Epoch: 477  Training loss = 3.0794  Validation loss = 1.6014  \n",
      "\n",
      "Fold: 27  Epoch: 478  Training loss = 3.0793  Validation loss = 1.5998  \n",
      "\n",
      "Fold: 27  Epoch: 479  Training loss = 3.0791  Validation loss = 1.6001  \n",
      "\n",
      "Fold: 27  Epoch: 480  Training loss = 3.0789  Validation loss = 1.5998  \n",
      "\n",
      "Fold: 27  Epoch: 481  Training loss = 3.0788  Validation loss = 1.5996  \n",
      "\n",
      "Fold: 27  Epoch: 482  Training loss = 3.0786  Validation loss = 1.5990  \n",
      "\n",
      "Fold: 27  Epoch: 483  Training loss = 3.0784  Validation loss = 1.5986  \n",
      "\n",
      "Fold: 27  Epoch: 484  Training loss = 3.0782  Validation loss = 1.5983  \n",
      "\n",
      "Fold: 27  Epoch: 485  Training loss = 3.0780  Validation loss = 1.5977  \n",
      "\n",
      "Fold: 27  Epoch: 486  Training loss = 3.0777  Validation loss = 1.5968  \n",
      "\n",
      "Fold: 27  Epoch: 487  Training loss = 3.0776  Validation loss = 1.5966  \n",
      "\n",
      "Fold: 27  Epoch: 488  Training loss = 3.0774  Validation loss = 1.5964  \n",
      "\n",
      "Fold: 27  Epoch: 489  Training loss = 3.0773  Validation loss = 1.5962  \n",
      "\n",
      "Fold: 27  Epoch: 490  Training loss = 3.0772  Validation loss = 1.5957  \n",
      "\n",
      "Fold: 27  Epoch: 491  Training loss = 3.0770  Validation loss = 1.5960  \n",
      "\n",
      "Fold: 27  Epoch: 492  Training loss = 3.0768  Validation loss = 1.5956  \n",
      "\n",
      "Fold: 27  Epoch: 493  Training loss = 3.0766  Validation loss = 1.5947  \n",
      "\n",
      "Fold: 27  Epoch: 494  Training loss = 3.0764  Validation loss = 1.5945  \n",
      "\n",
      "Fold: 27  Epoch: 495  Training loss = 3.0762  Validation loss = 1.5938  \n",
      "\n",
      "Fold: 27  Epoch: 496  Training loss = 3.0760  Validation loss = 1.5933  \n",
      "\n",
      "Fold: 27  Epoch: 497  Training loss = 3.0759  Validation loss = 1.5929  \n",
      "\n",
      "Fold: 27  Epoch: 498  Training loss = 3.0757  Validation loss = 1.5928  \n",
      "\n",
      "Fold: 27  Epoch: 499  Training loss = 3.0755  Validation loss = 1.5930  \n",
      "\n",
      "Fold: 27  Epoch: 500  Training loss = 3.0754  Validation loss = 1.5926  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 500  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.0627  Validation loss = 2.3627  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.0625  Validation loss = 2.3630  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.0623  Validation loss = 2.3630  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.0622  Validation loss = 2.3602  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.0620  Validation loss = 2.3602  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.0617  Validation loss = 2.3610  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.0615  Validation loss = 2.3607  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.0613  Validation loss = 2.3585  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.0611  Validation loss = 2.3573  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.0609  Validation loss = 2.3562  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.0607  Validation loss = 2.3559  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 3.0605  Validation loss = 2.3557  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 3.0604  Validation loss = 2.3558  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 3.0601  Validation loss = 2.3561  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 3.0598  Validation loss = 2.3547  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 3.0596  Validation loss = 2.3548  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 3.0594  Validation loss = 2.3547  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 3.0592  Validation loss = 2.3537  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 3.0589  Validation loss = 2.3525  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 3.0587  Validation loss = 2.3514  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 3.0584  Validation loss = 2.3510  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 3.0583  Validation loss = 2.3518  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 3.0580  Validation loss = 2.3505  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 3.0579  Validation loss = 2.3491  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 3.0577  Validation loss = 2.3490  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 3.0574  Validation loss = 2.3493  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 3.0572  Validation loss = 2.3500  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 3.0571  Validation loss = 2.3499  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 3.0569  Validation loss = 2.3500  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 3.0567  Validation loss = 2.3507  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 3.0564  Validation loss = 2.3499  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 3.0562  Validation loss = 2.3489  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 3.0560  Validation loss = 2.3492  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 3.0558  Validation loss = 2.3495  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 3.0557  Validation loss = 2.3498  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 3.0554  Validation loss = 2.3488  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 3.0552  Validation loss = 2.3498  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 3.0551  Validation loss = 2.3488  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 3.0547  Validation loss = 2.3481  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 3.0546  Validation loss = 2.3482  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 3.0544  Validation loss = 2.3474  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 3.0542  Validation loss = 2.3457  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 3.0540  Validation loss = 2.3454  \n",
      "\n",
      "Fold: 28  Epoch: 44  Training loss = 3.0538  Validation loss = 2.3457  \n",
      "\n",
      "Fold: 28  Epoch: 45  Training loss = 3.0536  Validation loss = 2.3455  \n",
      "\n",
      "Fold: 28  Epoch: 46  Training loss = 3.0533  Validation loss = 2.3439  \n",
      "\n",
      "Fold: 28  Epoch: 47  Training loss = 3.0531  Validation loss = 2.3442  \n",
      "\n",
      "Fold: 28  Epoch: 48  Training loss = 3.0530  Validation loss = 2.3436  \n",
      "\n",
      "Fold: 28  Epoch: 49  Training loss = 3.0528  Validation loss = 2.3438  \n",
      "\n",
      "Fold: 28  Epoch: 50  Training loss = 3.0526  Validation loss = 2.3436  \n",
      "\n",
      "Fold: 28  Epoch: 51  Training loss = 3.0524  Validation loss = 2.3436  \n",
      "\n",
      "Fold: 28  Epoch: 52  Training loss = 3.0521  Validation loss = 2.3424  \n",
      "\n",
      "Fold: 28  Epoch: 53  Training loss = 3.0518  Validation loss = 2.3403  \n",
      "\n",
      "Fold: 28  Epoch: 54  Training loss = 3.0516  Validation loss = 2.3398  \n",
      "\n",
      "Fold: 28  Epoch: 55  Training loss = 3.0514  Validation loss = 2.3397  \n",
      "\n",
      "Fold: 28  Epoch: 56  Training loss = 3.0512  Validation loss = 2.3382  \n",
      "\n",
      "Fold: 28  Epoch: 57  Training loss = 3.0510  Validation loss = 2.3382  \n",
      "\n",
      "Fold: 28  Epoch: 58  Training loss = 3.0508  Validation loss = 2.3373  \n",
      "\n",
      "Fold: 28  Epoch: 59  Training loss = 3.0506  Validation loss = 2.3362  \n",
      "\n",
      "Fold: 28  Epoch: 60  Training loss = 3.0503  Validation loss = 2.3361  \n",
      "\n",
      "Fold: 28  Epoch: 61  Training loss = 3.0500  Validation loss = 2.3367  \n",
      "\n",
      "Fold: 28  Epoch: 62  Training loss = 3.0498  Validation loss = 2.3362  \n",
      "\n",
      "Fold: 28  Epoch: 63  Training loss = 3.0497  Validation loss = 2.3357  \n",
      "\n",
      "Fold: 28  Epoch: 64  Training loss = 3.0494  Validation loss = 2.3349  \n",
      "\n",
      "Fold: 28  Epoch: 65  Training loss = 3.0491  Validation loss = 2.3344  \n",
      "\n",
      "Fold: 28  Epoch: 66  Training loss = 3.0488  Validation loss = 2.3347  \n",
      "\n",
      "Fold: 28  Epoch: 67  Training loss = 3.0486  Validation loss = 2.3348  \n",
      "\n",
      "Fold: 28  Epoch: 68  Training loss = 3.0484  Validation loss = 2.3347  \n",
      "\n",
      "Fold: 28  Epoch: 69  Training loss = 3.0482  Validation loss = 2.3340  \n",
      "\n",
      "Fold: 28  Epoch: 70  Training loss = 3.0479  Validation loss = 2.3331  \n",
      "\n",
      "Fold: 28  Epoch: 71  Training loss = 3.0477  Validation loss = 2.3320  \n",
      "\n",
      "Fold: 28  Epoch: 72  Training loss = 3.0474  Validation loss = 2.3312  \n",
      "\n",
      "Fold: 28  Epoch: 73  Training loss = 3.0473  Validation loss = 2.3324  \n",
      "\n",
      "Fold: 28  Epoch: 74  Training loss = 3.0470  Validation loss = 2.3311  \n",
      "\n",
      "Fold: 28  Epoch: 75  Training loss = 3.0468  Validation loss = 2.3308  \n",
      "\n",
      "Fold: 28  Epoch: 76  Training loss = 3.0467  Validation loss = 2.3310  \n",
      "\n",
      "Fold: 28  Epoch: 77  Training loss = 3.0464  Validation loss = 2.3288  \n",
      "\n",
      "Fold: 28  Epoch: 78  Training loss = 3.0462  Validation loss = 2.3271  \n",
      "\n",
      "Fold: 28  Epoch: 79  Training loss = 3.0460  Validation loss = 2.3260  \n",
      "\n",
      "Fold: 28  Epoch: 80  Training loss = 3.0457  Validation loss = 2.3242  \n",
      "\n",
      "Fold: 28  Epoch: 81  Training loss = 3.0455  Validation loss = 2.3246  \n",
      "\n",
      "Fold: 28  Epoch: 82  Training loss = 3.0452  Validation loss = 2.3241  \n",
      "\n",
      "Fold: 28  Epoch: 83  Training loss = 3.0449  Validation loss = 2.3232  \n",
      "\n",
      "Fold: 28  Epoch: 84  Training loss = 3.0446  Validation loss = 2.3232  \n",
      "\n",
      "Fold: 28  Epoch: 85  Training loss = 3.0444  Validation loss = 2.3226  \n",
      "\n",
      "Fold: 28  Epoch: 86  Training loss = 3.0441  Validation loss = 2.3217  \n",
      "\n",
      "Fold: 28  Epoch: 87  Training loss = 3.0438  Validation loss = 2.3223  \n",
      "\n",
      "Fold: 28  Epoch: 88  Training loss = 3.0435  Validation loss = 2.3218  \n",
      "\n",
      "Fold: 28  Epoch: 89  Training loss = 3.0432  Validation loss = 2.3214  \n",
      "\n",
      "Fold: 28  Epoch: 90  Training loss = 3.0429  Validation loss = 2.3204  \n",
      "\n",
      "Fold: 28  Epoch: 91  Training loss = 3.0427  Validation loss = 2.3190  \n",
      "\n",
      "Fold: 28  Epoch: 92  Training loss = 3.0424  Validation loss = 2.3189  \n",
      "\n",
      "Fold: 28  Epoch: 93  Training loss = 3.0421  Validation loss = 2.3174  \n",
      "\n",
      "Fold: 28  Epoch: 94  Training loss = 3.0417  Validation loss = 2.3162  \n",
      "\n",
      "Fold: 28  Epoch: 95  Training loss = 3.0413  Validation loss = 2.3163  \n",
      "\n",
      "Fold: 28  Epoch: 96  Training loss = 3.0411  Validation loss = 2.3177  \n",
      "\n",
      "Fold: 28  Epoch: 97  Training loss = 3.0407  Validation loss = 2.3170  \n",
      "\n",
      "Fold: 28  Epoch: 98  Training loss = 3.0404  Validation loss = 2.3165  \n",
      "\n",
      "Fold: 28  Epoch: 99  Training loss = 3.0400  Validation loss = 2.3153  \n",
      "\n",
      "Fold: 28  Epoch: 100  Training loss = 3.0396  Validation loss = 2.3143  \n",
      "\n",
      "Fold: 28  Epoch: 101  Training loss = 3.0391  Validation loss = 2.3122  \n",
      "\n",
      "Fold: 28  Epoch: 102  Training loss = 3.0385  Validation loss = 2.3120  \n",
      "\n",
      "Fold: 28  Epoch: 103  Training loss = 3.0382  Validation loss = 2.3127  \n",
      "\n",
      "Fold: 28  Epoch: 104  Training loss = 3.0375  Validation loss = 2.3108  \n",
      "\n",
      "Fold: 28  Epoch: 105  Training loss = 3.0372  Validation loss = 2.3105  \n",
      "\n",
      "Fold: 28  Epoch: 106  Training loss = 3.0370  Validation loss = 2.3105  \n",
      "\n",
      "Fold: 28  Epoch: 107  Training loss = 3.0366  Validation loss = 2.3106  \n",
      "\n",
      "Fold: 28  Epoch: 108  Training loss = 3.0362  Validation loss = 2.3100  \n",
      "\n",
      "Fold: 28  Epoch: 109  Training loss = 3.0359  Validation loss = 2.3099  \n",
      "\n",
      "Fold: 28  Epoch: 110  Training loss = 3.0354  Validation loss = 2.3094  \n",
      "\n",
      "Fold: 28  Epoch: 111  Training loss = 3.0349  Validation loss = 2.3079  \n",
      "\n",
      "Fold: 28  Epoch: 112  Training loss = 3.0346  Validation loss = 2.3065  \n",
      "\n",
      "Fold: 28  Epoch: 113  Training loss = 3.0343  Validation loss = 2.3076  \n",
      "\n",
      "Fold: 28  Epoch: 114  Training loss = 3.0339  Validation loss = 2.3060  \n",
      "\n",
      "Fold: 28  Epoch: 115  Training loss = 3.0336  Validation loss = 2.3068  \n",
      "\n",
      "Fold: 28  Epoch: 116  Training loss = 3.0333  Validation loss = 2.3064  \n",
      "\n",
      "Fold: 28  Epoch: 117  Training loss = 3.0331  Validation loss = 2.3057  \n",
      "\n",
      "Fold: 28  Epoch: 118  Training loss = 3.0329  Validation loss = 2.3051  \n",
      "\n",
      "Fold: 28  Epoch: 119  Training loss = 3.0326  Validation loss = 2.3037  \n",
      "\n",
      "Fold: 28  Epoch: 120  Training loss = 3.0323  Validation loss = 2.3026  \n",
      "\n",
      "Fold: 28  Epoch: 121  Training loss = 3.0320  Validation loss = 2.3024  \n",
      "\n",
      "Fold: 28  Epoch: 122  Training loss = 3.0317  Validation loss = 2.3036  \n",
      "\n",
      "Fold: 28  Epoch: 123  Training loss = 3.0314  Validation loss = 2.3045  \n",
      "\n",
      "Fold: 28  Epoch: 124  Training loss = 3.0313  Validation loss = 2.3041  \n",
      "\n",
      "Fold: 28  Epoch: 125  Training loss = 3.0311  Validation loss = 2.3028  \n",
      "\n",
      "Fold: 28  Epoch: 126  Training loss = 3.0309  Validation loss = 2.3030  \n",
      "\n",
      "Fold: 28  Epoch: 127  Training loss = 3.0306  Validation loss = 2.3026  \n",
      "\n",
      "Fold: 28  Epoch: 128  Training loss = 3.0304  Validation loss = 2.3020  \n",
      "\n",
      "Fold: 28  Epoch: 129  Training loss = 3.0301  Validation loss = 2.3006  \n",
      "\n",
      "Fold: 28  Epoch: 130  Training loss = 3.0299  Validation loss = 2.2996  \n",
      "\n",
      "Fold: 28  Epoch: 131  Training loss = 3.0297  Validation loss = 2.2992  \n",
      "\n",
      "Fold: 28  Epoch: 132  Training loss = 3.0294  Validation loss = 2.2992  \n",
      "\n",
      "Fold: 28  Epoch: 133  Training loss = 3.0292  Validation loss = 2.2990  \n",
      "\n",
      "Fold: 28  Epoch: 134  Training loss = 3.0291  Validation loss = 2.2999  \n",
      "\n",
      "Fold: 28  Epoch: 135  Training loss = 3.0288  Validation loss = 2.2992  \n",
      "\n",
      "Fold: 28  Epoch: 136  Training loss = 3.0287  Validation loss = 2.3004  \n",
      "\n",
      "Fold: 28  Epoch: 137  Training loss = 3.0285  Validation loss = 2.2990  \n",
      "\n",
      "Fold: 28  Epoch: 138  Training loss = 3.0284  Validation loss = 2.3004  \n",
      "\n",
      "Fold: 28  Epoch: 139  Training loss = 3.0281  Validation loss = 2.3008  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 133  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.0682  Validation loss = 0.9626  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.0678  Validation loss = 0.9625  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.0677  Validation loss = 0.9624  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.0675  Validation loss = 0.9622  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.0672  Validation loss = 0.9621  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.0668  Validation loss = 0.9619  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.0665  Validation loss = 0.9618  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.0663  Validation loss = 0.9619  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.0663  Validation loss = 0.9620  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.0660  Validation loss = 0.9619  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.0658  Validation loss = 0.9622  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 3.0655  Validation loss = 0.9619  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.0653  Validation loss = 0.9618  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 3.0650  Validation loss = 0.9617  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 3.0647  Validation loss = 0.9614  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 3.0646  Validation loss = 0.9612  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 3.0642  Validation loss = 0.9609  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 3.0640  Validation loss = 0.9606  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 3.0637  Validation loss = 0.9606  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 3.0633  Validation loss = 0.9605  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 3.0632  Validation loss = 0.9604  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 3.0629  Validation loss = 0.9605  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 3.0627  Validation loss = 0.9604  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 3.0625  Validation loss = 0.9604  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 3.0622  Validation loss = 0.9601  \n",
      "\n",
      "Fold: 29  Epoch: 26  Training loss = 3.0620  Validation loss = 0.9599  \n",
      "\n",
      "Fold: 29  Epoch: 27  Training loss = 3.0617  Validation loss = 0.9599  \n",
      "\n",
      "Fold: 29  Epoch: 28  Training loss = 3.0616  Validation loss = 0.9598  \n",
      "\n",
      "Fold: 29  Epoch: 29  Training loss = 3.0613  Validation loss = 0.9598  \n",
      "\n",
      "Fold: 29  Epoch: 30  Training loss = 3.0611  Validation loss = 0.9597  \n",
      "\n",
      "Fold: 29  Epoch: 31  Training loss = 3.0609  Validation loss = 0.9601  \n",
      "\n",
      "Fold: 29  Epoch: 32  Training loss = 3.0605  Validation loss = 0.9601  \n",
      "\n",
      "Fold: 29  Epoch: 33  Training loss = 3.0603  Validation loss = 0.9597  \n",
      "\n",
      "Fold: 29  Epoch: 34  Training loss = 3.0600  Validation loss = 0.9597  \n",
      "\n",
      "Fold: 29  Epoch: 35  Training loss = 3.0598  Validation loss = 0.9595  \n",
      "\n",
      "Fold: 29  Epoch: 36  Training loss = 3.0595  Validation loss = 0.9592  \n",
      "\n",
      "Fold: 29  Epoch: 37  Training loss = 3.0593  Validation loss = 0.9593  \n",
      "\n",
      "Fold: 29  Epoch: 38  Training loss = 3.0591  Validation loss = 0.9591  \n",
      "\n",
      "Fold: 29  Epoch: 39  Training loss = 3.0589  Validation loss = 0.9589  \n",
      "\n",
      "Fold: 29  Epoch: 40  Training loss = 3.0587  Validation loss = 0.9589  \n",
      "\n",
      "Fold: 29  Epoch: 41  Training loss = 3.0584  Validation loss = 0.9589  \n",
      "\n",
      "Fold: 29  Epoch: 42  Training loss = 3.0581  Validation loss = 0.9586  \n",
      "\n",
      "Fold: 29  Epoch: 43  Training loss = 3.0579  Validation loss = 0.9583  \n",
      "\n",
      "Fold: 29  Epoch: 44  Training loss = 3.0577  Validation loss = 0.9581  \n",
      "\n",
      "Fold: 29  Epoch: 45  Training loss = 3.0575  Validation loss = 0.9581  \n",
      "\n",
      "Fold: 29  Epoch: 46  Training loss = 3.0574  Validation loss = 0.9583  \n",
      "\n",
      "Fold: 29  Epoch: 47  Training loss = 3.0572  Validation loss = 0.9580  \n",
      "\n",
      "Fold: 29  Epoch: 48  Training loss = 3.0569  Validation loss = 0.9580  \n",
      "\n",
      "Fold: 29  Epoch: 49  Training loss = 3.0566  Validation loss = 0.9576  \n",
      "\n",
      "Fold: 29  Epoch: 50  Training loss = 3.0563  Validation loss = 0.9579  \n",
      "\n",
      "Fold: 29  Epoch: 51  Training loss = 3.0561  Validation loss = 0.9577  \n",
      "\n",
      "Fold: 29  Epoch: 52  Training loss = 3.0559  Validation loss = 0.9576  \n",
      "\n",
      "Fold: 29  Epoch: 53  Training loss = 3.0556  Validation loss = 0.9574  \n",
      "\n",
      "Fold: 29  Epoch: 54  Training loss = 3.0552  Validation loss = 0.9571  \n",
      "\n",
      "Fold: 29  Epoch: 55  Training loss = 3.0550  Validation loss = 0.9567  \n",
      "\n",
      "Fold: 29  Epoch: 56  Training loss = 3.0547  Validation loss = 0.9567  \n",
      "\n",
      "Fold: 29  Epoch: 57  Training loss = 3.0545  Validation loss = 0.9567  \n",
      "\n",
      "Fold: 29  Epoch: 58  Training loss = 3.0543  Validation loss = 0.9566  \n",
      "\n",
      "Fold: 29  Epoch: 59  Training loss = 3.0540  Validation loss = 0.9564  \n",
      "\n",
      "Fold: 29  Epoch: 60  Training loss = 3.0538  Validation loss = 0.9561  \n",
      "\n",
      "Fold: 29  Epoch: 61  Training loss = 3.0536  Validation loss = 0.9560  \n",
      "\n",
      "Fold: 29  Epoch: 62  Training loss = 3.0533  Validation loss = 0.9557  \n",
      "\n",
      "Fold: 29  Epoch: 63  Training loss = 3.0531  Validation loss = 0.9557  \n",
      "\n",
      "Fold: 29  Epoch: 64  Training loss = 3.0528  Validation loss = 0.9555  \n",
      "\n",
      "Fold: 29  Epoch: 65  Training loss = 3.0526  Validation loss = 0.9552  \n",
      "\n",
      "Fold: 29  Epoch: 66  Training loss = 3.0524  Validation loss = 0.9551  \n",
      "\n",
      "Fold: 29  Epoch: 67  Training loss = 3.0523  Validation loss = 0.9551  \n",
      "\n",
      "Fold: 29  Epoch: 68  Training loss = 3.0520  Validation loss = 0.9548  \n",
      "\n",
      "Fold: 29  Epoch: 69  Training loss = 3.0518  Validation loss = 0.9549  \n",
      "\n",
      "Fold: 29  Epoch: 70  Training loss = 3.0515  Validation loss = 0.9547  \n",
      "\n",
      "Fold: 29  Epoch: 71  Training loss = 3.0513  Validation loss = 0.9543  \n",
      "\n",
      "Fold: 29  Epoch: 72  Training loss = 3.0511  Validation loss = 0.9543  \n",
      "\n",
      "Fold: 29  Epoch: 73  Training loss = 3.0508  Validation loss = 0.9543  \n",
      "\n",
      "Fold: 29  Epoch: 74  Training loss = 3.0507  Validation loss = 0.9543  \n",
      "\n",
      "Fold: 29  Epoch: 75  Training loss = 3.0505  Validation loss = 0.9539  \n",
      "\n",
      "Fold: 29  Epoch: 76  Training loss = 3.0503  Validation loss = 0.9539  \n",
      "\n",
      "Fold: 29  Epoch: 77  Training loss = 3.0501  Validation loss = 0.9538  \n",
      "\n",
      "Fold: 29  Epoch: 78  Training loss = 3.0498  Validation loss = 0.9538  \n",
      "\n",
      "Fold: 29  Epoch: 79  Training loss = 3.0495  Validation loss = 0.9540  \n",
      "\n",
      "Fold: 29  Epoch: 80  Training loss = 3.0494  Validation loss = 0.9539  \n",
      "\n",
      "Fold: 29  Epoch: 81  Training loss = 3.0492  Validation loss = 0.9537  \n",
      "\n",
      "Fold: 29  Epoch: 82  Training loss = 3.0490  Validation loss = 0.9532  \n",
      "\n",
      "Fold: 29  Epoch: 83  Training loss = 3.0487  Validation loss = 0.9529  \n",
      "\n",
      "Fold: 29  Epoch: 84  Training loss = 3.0486  Validation loss = 0.9528  \n",
      "\n",
      "Fold: 29  Epoch: 85  Training loss = 3.0484  Validation loss = 0.9527  \n",
      "\n",
      "Fold: 29  Epoch: 86  Training loss = 3.0483  Validation loss = 0.9525  \n",
      "\n",
      "Fold: 29  Epoch: 87  Training loss = 3.0480  Validation loss = 0.9521  \n",
      "\n",
      "Fold: 29  Epoch: 88  Training loss = 3.0478  Validation loss = 0.9520  \n",
      "\n",
      "Fold: 29  Epoch: 89  Training loss = 3.0476  Validation loss = 0.9519  \n",
      "\n",
      "Fold: 29  Epoch: 90  Training loss = 3.0474  Validation loss = 0.9519  \n",
      "\n",
      "Fold: 29  Epoch: 91  Training loss = 3.0472  Validation loss = 0.9519  \n",
      "\n",
      "Fold: 29  Epoch: 92  Training loss = 3.0469  Validation loss = 0.9519  \n",
      "\n",
      "Fold: 29  Epoch: 93  Training loss = 3.0467  Validation loss = 0.9520  \n",
      "\n",
      "Fold: 29  Epoch: 94  Training loss = 3.0465  Validation loss = 0.9520  \n",
      "\n",
      "Fold: 29  Epoch: 95  Training loss = 3.0463  Validation loss = 0.9521  \n",
      "\n",
      "Fold: 29  Epoch: 96  Training loss = 3.0459  Validation loss = 0.9518  \n",
      "\n",
      "Fold: 29  Epoch: 97  Training loss = 3.0457  Validation loss = 0.9517  \n",
      "\n",
      "Fold: 29  Epoch: 98  Training loss = 3.0455  Validation loss = 0.9516  \n",
      "\n",
      "Fold: 29  Epoch: 99  Training loss = 3.0454  Validation loss = 0.9513  \n",
      "\n",
      "Fold: 29  Epoch: 100  Training loss = 3.0452  Validation loss = 0.9509  \n",
      "\n",
      "Fold: 29  Epoch: 101  Training loss = 3.0450  Validation loss = 0.9510  \n",
      "\n",
      "Fold: 29  Epoch: 102  Training loss = 3.0448  Validation loss = 0.9508  \n",
      "\n",
      "Fold: 29  Epoch: 103  Training loss = 3.0447  Validation loss = 0.9506  \n",
      "\n",
      "Fold: 29  Epoch: 104  Training loss = 3.0444  Validation loss = 0.9508  \n",
      "\n",
      "Fold: 29  Epoch: 105  Training loss = 3.0442  Validation loss = 0.9507  \n",
      "\n",
      "Fold: 29  Epoch: 106  Training loss = 3.0440  Validation loss = 0.9505  \n",
      "\n",
      "Fold: 29  Epoch: 107  Training loss = 3.0438  Validation loss = 0.9506  \n",
      "\n",
      "Fold: 29  Epoch: 108  Training loss = 3.0436  Validation loss = 0.9507  \n",
      "\n",
      "Fold: 29  Epoch: 109  Training loss = 3.0434  Validation loss = 0.9505  \n",
      "\n",
      "Fold: 29  Epoch: 110  Training loss = 3.0431  Validation loss = 0.9503  \n",
      "\n",
      "Fold: 29  Epoch: 111  Training loss = 3.0429  Validation loss = 0.9502  \n",
      "\n",
      "Fold: 29  Epoch: 112  Training loss = 3.0426  Validation loss = 0.9500  \n",
      "\n",
      "Fold: 29  Epoch: 113  Training loss = 3.0424  Validation loss = 0.9500  \n",
      "\n",
      "Fold: 29  Epoch: 114  Training loss = 3.0423  Validation loss = 0.9499  \n",
      "\n",
      "Fold: 29  Epoch: 115  Training loss = 3.0420  Validation loss = 0.9496  \n",
      "\n",
      "Fold: 29  Epoch: 116  Training loss = 3.0418  Validation loss = 0.9495  \n",
      "\n",
      "Fold: 29  Epoch: 117  Training loss = 3.0416  Validation loss = 0.9495  \n",
      "\n",
      "Fold: 29  Epoch: 118  Training loss = 3.0414  Validation loss = 0.9492  \n",
      "\n",
      "Fold: 29  Epoch: 119  Training loss = 3.0411  Validation loss = 0.9491  \n",
      "\n",
      "Fold: 29  Epoch: 120  Training loss = 3.0410  Validation loss = 0.9489  \n",
      "\n",
      "Fold: 29  Epoch: 121  Training loss = 3.0407  Validation loss = 0.9485  \n",
      "\n",
      "Fold: 29  Epoch: 122  Training loss = 3.0404  Validation loss = 0.9486  \n",
      "\n",
      "Fold: 29  Epoch: 123  Training loss = 3.0403  Validation loss = 0.9486  \n",
      "\n",
      "Fold: 29  Epoch: 124  Training loss = 3.0400  Validation loss = 0.9483  \n",
      "\n",
      "Fold: 29  Epoch: 125  Training loss = 3.0398  Validation loss = 0.9480  \n",
      "\n",
      "Fold: 29  Epoch: 126  Training loss = 3.0396  Validation loss = 0.9478  \n",
      "\n",
      "Fold: 29  Epoch: 127  Training loss = 3.0393  Validation loss = 0.9477  \n",
      "\n",
      "Fold: 29  Epoch: 128  Training loss = 3.0391  Validation loss = 0.9474  \n",
      "\n",
      "Fold: 29  Epoch: 129  Training loss = 3.0389  Validation loss = 0.9473  \n",
      "\n",
      "Fold: 29  Epoch: 130  Training loss = 3.0386  Validation loss = 0.9472  \n",
      "\n",
      "Fold: 29  Epoch: 131  Training loss = 3.0385  Validation loss = 0.9471  \n",
      "\n",
      "Fold: 29  Epoch: 132  Training loss = 3.0384  Validation loss = 0.9470  \n",
      "\n",
      "Fold: 29  Epoch: 133  Training loss = 3.0383  Validation loss = 0.9470  \n",
      "\n",
      "Fold: 29  Epoch: 134  Training loss = 3.0381  Validation loss = 0.9467  \n",
      "\n",
      "Fold: 29  Epoch: 135  Training loss = 3.0378  Validation loss = 0.9466  \n",
      "\n",
      "Fold: 29  Epoch: 136  Training loss = 3.0375  Validation loss = 0.9463  \n",
      "\n",
      "Fold: 29  Epoch: 137  Training loss = 3.0371  Validation loss = 0.9459  \n",
      "\n",
      "Fold: 29  Epoch: 138  Training loss = 3.0368  Validation loss = 0.9458  \n",
      "\n",
      "Fold: 29  Epoch: 139  Training loss = 3.0365  Validation loss = 0.9457  \n",
      "\n",
      "Fold: 29  Epoch: 140  Training loss = 3.0363  Validation loss = 0.9457  \n",
      "\n",
      "Fold: 29  Epoch: 141  Training loss = 3.0360  Validation loss = 0.9456  \n",
      "\n",
      "Fold: 29  Epoch: 142  Training loss = 3.0357  Validation loss = 0.9456  \n",
      "\n",
      "Fold: 29  Epoch: 143  Training loss = 3.0355  Validation loss = 0.9454  \n",
      "\n",
      "Fold: 29  Epoch: 144  Training loss = 3.0352  Validation loss = 0.9451  \n",
      "\n",
      "Fold: 29  Epoch: 145  Training loss = 3.0350  Validation loss = 0.9451  \n",
      "\n",
      "Fold: 29  Epoch: 146  Training loss = 3.0348  Validation loss = 0.9451  \n",
      "\n",
      "Fold: 29  Epoch: 147  Training loss = 3.0345  Validation loss = 0.9451  \n",
      "\n",
      "Fold: 29  Epoch: 148  Training loss = 3.0343  Validation loss = 0.9451  \n",
      "\n",
      "Fold: 29  Epoch: 149  Training loss = 3.0341  Validation loss = 0.9450  \n",
      "\n",
      "Fold: 29  Epoch: 150  Training loss = 3.0338  Validation loss = 0.9449  \n",
      "\n",
      "Fold: 29  Epoch: 151  Training loss = 3.0336  Validation loss = 0.9447  \n",
      "\n",
      "Fold: 29  Epoch: 152  Training loss = 3.0334  Validation loss = 0.9445  \n",
      "\n",
      "Fold: 29  Epoch: 153  Training loss = 3.0332  Validation loss = 0.9444  \n",
      "\n",
      "Fold: 29  Epoch: 154  Training loss = 3.0330  Validation loss = 0.9441  \n",
      "\n",
      "Fold: 29  Epoch: 155  Training loss = 3.0326  Validation loss = 0.9443  \n",
      "\n",
      "Fold: 29  Epoch: 156  Training loss = 3.0324  Validation loss = 0.9444  \n",
      "\n",
      "Fold: 29  Epoch: 157  Training loss = 3.0322  Validation loss = 0.9444  \n",
      "\n",
      "Fold: 29  Epoch: 158  Training loss = 3.0320  Validation loss = 0.9444  \n",
      "\n",
      "Fold: 29  Epoch: 159  Training loss = 3.0318  Validation loss = 0.9444  \n",
      "\n",
      "Fold: 29  Epoch: 160  Training loss = 3.0316  Validation loss = 0.9445  \n",
      "\n",
      "Fold: 29  Epoch: 161  Training loss = 3.0314  Validation loss = 0.9445  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 154  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.0054  Validation loss = 2.6644  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.0052  Validation loss = 2.6621  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.0050  Validation loss = 2.6604  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.0047  Validation loss = 2.6592  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.0045  Validation loss = 2.6589  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.0043  Validation loss = 2.6572  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.0040  Validation loss = 2.6592  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.0038  Validation loss = 2.6599  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.0036  Validation loss = 2.6567  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.0033  Validation loss = 2.6571  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.0031  Validation loss = 2.6555  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 3.0028  Validation loss = 2.6544  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 3.0026  Validation loss = 2.6532  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 3.0024  Validation loss = 2.6549  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 3.0022  Validation loss = 2.6558  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 3.0019  Validation loss = 2.6556  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 3.0017  Validation loss = 2.6536  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 3.0014  Validation loss = 2.6518  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 3.0012  Validation loss = 2.6545  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 3.0009  Validation loss = 2.6539  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 3.0006  Validation loss = 2.6502  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 3.0003  Validation loss = 2.6484  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 3.0001  Validation loss = 2.6474  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 2.9998  Validation loss = 2.6482  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 2.9996  Validation loss = 2.6485  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 2.9994  Validation loss = 2.6489  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 2.9991  Validation loss = 2.6514  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 2.9988  Validation loss = 2.6512  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 2.9986  Validation loss = 2.6519  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 2.9984  Validation loss = 2.6523  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 23  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.8239  Validation loss = 2.0494  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.8234  Validation loss = 2.0472  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.8231  Validation loss = 2.0466  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.8226  Validation loss = 2.0454  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.8220  Validation loss = 2.0418  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.8216  Validation loss = 2.0409  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.8214  Validation loss = 2.0415  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.8209  Validation loss = 2.0385  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.8207  Validation loss = 2.0386  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.8202  Validation loss = 2.0367  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.8196  Validation loss = 2.0340  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.8190  Validation loss = 2.0320  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.8187  Validation loss = 2.0311  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.8183  Validation loss = 2.0297  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.8180  Validation loss = 2.0288  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.8178  Validation loss = 2.0291  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 2.8172  Validation loss = 2.0264  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 2.8170  Validation loss = 2.0257  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 2.8166  Validation loss = 2.0255  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 2.8159  Validation loss = 2.0214  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 2.8154  Validation loss = 2.0189  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 2.8150  Validation loss = 2.0177  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 2.8145  Validation loss = 2.0166  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 2.8140  Validation loss = 2.0146  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 2.8136  Validation loss = 2.0130  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 2.8131  Validation loss = 2.0118  \n",
      "\n",
      "Fold: 31  Epoch: 27  Training loss = 2.8126  Validation loss = 2.0100  \n",
      "\n",
      "Fold: 31  Epoch: 28  Training loss = 2.8120  Validation loss = 2.0057  \n",
      "\n",
      "Fold: 31  Epoch: 29  Training loss = 2.8117  Validation loss = 2.0049  \n",
      "\n",
      "Fold: 31  Epoch: 30  Training loss = 2.8112  Validation loss = 2.0039  \n",
      "\n",
      "Fold: 31  Epoch: 31  Training loss = 2.8106  Validation loss = 1.9999  \n",
      "\n",
      "Fold: 31  Epoch: 32  Training loss = 2.8101  Validation loss = 1.9971  \n",
      "\n",
      "Fold: 31  Epoch: 33  Training loss = 2.8098  Validation loss = 1.9965  \n",
      "\n",
      "Fold: 31  Epoch: 34  Training loss = 2.8094  Validation loss = 1.9966  \n",
      "\n",
      "Fold: 31  Epoch: 35  Training loss = 2.8089  Validation loss = 1.9952  \n",
      "\n",
      "Fold: 31  Epoch: 36  Training loss = 2.8084  Validation loss = 1.9937  \n",
      "\n",
      "Fold: 31  Epoch: 37  Training loss = 2.8081  Validation loss = 1.9935  \n",
      "\n",
      "Fold: 31  Epoch: 38  Training loss = 2.8074  Validation loss = 1.9897  \n",
      "\n",
      "Fold: 31  Epoch: 39  Training loss = 2.8068  Validation loss = 1.9875  \n",
      "\n",
      "Fold: 31  Epoch: 40  Training loss = 2.8062  Validation loss = 1.9840  \n",
      "\n",
      "Fold: 31  Epoch: 41  Training loss = 2.8056  Validation loss = 1.9808  \n",
      "\n",
      "Fold: 31  Epoch: 42  Training loss = 2.8051  Validation loss = 1.9785  \n",
      "\n",
      "Fold: 31  Epoch: 43  Training loss = 2.8047  Validation loss = 1.9794  \n",
      "\n",
      "Fold: 31  Epoch: 44  Training loss = 2.8042  Validation loss = 1.9774  \n",
      "\n",
      "Fold: 31  Epoch: 45  Training loss = 2.8035  Validation loss = 1.9737  \n",
      "\n",
      "Fold: 31  Epoch: 46  Training loss = 2.8031  Validation loss = 1.9752  \n",
      "\n",
      "Fold: 31  Epoch: 47  Training loss = 2.8028  Validation loss = 1.9773  \n",
      "\n",
      "Fold: 31  Epoch: 48  Training loss = 2.8024  Validation loss = 1.9780  \n",
      "\n",
      "Fold: 31  Epoch: 49  Training loss = 2.8017  Validation loss = 1.9738  \n",
      "\n",
      "Fold: 31  Epoch: 50  Training loss = 2.8011  Validation loss = 1.9717  \n",
      "\n",
      "Fold: 31  Epoch: 51  Training loss = 2.8005  Validation loss = 1.9684  \n",
      "\n",
      "Fold: 31  Epoch: 52  Training loss = 2.8002  Validation loss = 1.9690  \n",
      "\n",
      "Fold: 31  Epoch: 53  Training loss = 2.7998  Validation loss = 1.9701  \n",
      "\n",
      "Fold: 31  Epoch: 54  Training loss = 2.7994  Validation loss = 1.9707  \n",
      "\n",
      "Fold: 31  Epoch: 55  Training loss = 2.7991  Validation loss = 1.9700  \n",
      "\n",
      "Fold: 31  Epoch: 56  Training loss = 2.7985  Validation loss = 1.9673  \n",
      "\n",
      "Fold: 31  Epoch: 57  Training loss = 2.7979  Validation loss = 1.9647  \n",
      "\n",
      "Fold: 31  Epoch: 58  Training loss = 2.7974  Validation loss = 1.9631  \n",
      "\n",
      "Fold: 31  Epoch: 59  Training loss = 2.7969  Validation loss = 1.9611  \n",
      "\n",
      "Fold: 31  Epoch: 60  Training loss = 2.7965  Validation loss = 1.9607  \n",
      "\n",
      "Fold: 31  Epoch: 61  Training loss = 2.7963  Validation loss = 1.9621  \n",
      "\n",
      "Fold: 31  Epoch: 62  Training loss = 2.7959  Validation loss = 1.9624  \n",
      "\n",
      "Fold: 31  Epoch: 63  Training loss = 2.7956  Validation loss = 1.9613  \n",
      "\n",
      "Fold: 31  Epoch: 64  Training loss = 2.7953  Validation loss = 1.9604  \n",
      "\n",
      "Fold: 31  Epoch: 65  Training loss = 2.7949  Validation loss = 1.9606  \n",
      "\n",
      "Fold: 31  Epoch: 66  Training loss = 2.7944  Validation loss = 1.9579  \n",
      "\n",
      "Fold: 31  Epoch: 67  Training loss = 2.7940  Validation loss = 1.9562  \n",
      "\n",
      "Fold: 31  Epoch: 68  Training loss = 2.7935  Validation loss = 1.9540  \n",
      "\n",
      "Fold: 31  Epoch: 69  Training loss = 2.7930  Validation loss = 1.9509  \n",
      "\n",
      "Fold: 31  Epoch: 70  Training loss = 2.7927  Validation loss = 1.9503  \n",
      "\n",
      "Fold: 31  Epoch: 71  Training loss = 2.7924  Validation loss = 1.9488  \n",
      "\n",
      "Fold: 31  Epoch: 72  Training loss = 2.7920  Validation loss = 1.9464  \n",
      "\n",
      "Fold: 31  Epoch: 73  Training loss = 2.7917  Validation loss = 1.9438  \n",
      "\n",
      "Fold: 31  Epoch: 74  Training loss = 2.7914  Validation loss = 1.9429  \n",
      "\n",
      "Fold: 31  Epoch: 75  Training loss = 2.7910  Validation loss = 1.9410  \n",
      "\n",
      "Fold: 31  Epoch: 76  Training loss = 2.7908  Validation loss = 1.9386  \n",
      "\n",
      "Fold: 31  Epoch: 77  Training loss = 2.7905  Validation loss = 1.9377  \n",
      "\n",
      "Fold: 31  Epoch: 78  Training loss = 2.7902  Validation loss = 1.9379  \n",
      "\n",
      "Fold: 31  Epoch: 79  Training loss = 2.7901  Validation loss = 1.9396  \n",
      "\n",
      "Fold: 31  Epoch: 80  Training loss = 2.7898  Validation loss = 1.9371  \n",
      "\n",
      "Fold: 31  Epoch: 81  Training loss = 2.7896  Validation loss = 1.9389  \n",
      "\n",
      "Fold: 31  Epoch: 82  Training loss = 2.7894  Validation loss = 1.9380  \n",
      "\n",
      "Fold: 31  Epoch: 83  Training loss = 2.7890  Validation loss = 1.9357  \n",
      "\n",
      "Fold: 31  Epoch: 84  Training loss = 2.7888  Validation loss = 1.9369  \n",
      "\n",
      "Fold: 31  Epoch: 85  Training loss = 2.7885  Validation loss = 1.9349  \n",
      "\n",
      "Fold: 31  Epoch: 86  Training loss = 2.7882  Validation loss = 1.9333  \n",
      "\n",
      "Fold: 31  Epoch: 87  Training loss = 2.7880  Validation loss = 1.9323  \n",
      "\n",
      "Fold: 31  Epoch: 88  Training loss = 2.7877  Validation loss = 1.9305  \n",
      "\n",
      "Fold: 31  Epoch: 89  Training loss = 2.7873  Validation loss = 1.9307  \n",
      "\n",
      "Fold: 31  Epoch: 90  Training loss = 2.7871  Validation loss = 1.9326  \n",
      "\n",
      "Fold: 31  Epoch: 91  Training loss = 2.7868  Validation loss = 1.9314  \n",
      "\n",
      "Fold: 31  Epoch: 92  Training loss = 2.7867  Validation loss = 1.9344  \n",
      "\n",
      "Fold: 31  Epoch: 93  Training loss = 2.7864  Validation loss = 1.9334  \n",
      "\n",
      "Fold: 31  Epoch: 94  Training loss = 2.7862  Validation loss = 1.9336  \n",
      "\n",
      "Fold: 31  Epoch: 95  Training loss = 2.7862  Validation loss = 1.9367  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 88  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.3375  Validation loss = 3.7782  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.3358  Validation loss = 3.7716  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.3345  Validation loss = 3.7664  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.3329  Validation loss = 3.7601  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.3319  Validation loss = 3.7563  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.3299  Validation loss = 3.7481  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.3289  Validation loss = 3.7441  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.3270  Validation loss = 3.7359  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.3248  Validation loss = 3.7266  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.3233  Validation loss = 3.7202  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.3209  Validation loss = 3.7094  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.3195  Validation loss = 3.7032  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.3180  Validation loss = 3.6968  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.3154  Validation loss = 3.6844  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.3136  Validation loss = 3.6756  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.3118  Validation loss = 3.6668  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.3101  Validation loss = 3.6589  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.3086  Validation loss = 3.6514  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.3072  Validation loss = 3.6447  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.3061  Validation loss = 3.6392  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 2.3046  Validation loss = 3.6315  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 2.3030  Validation loss = 3.6234  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.3019  Validation loss = 3.6183  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 2.3007  Validation loss = 3.6119  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 2.2995  Validation loss = 3.6060  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 2.2987  Validation loss = 3.6022  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 2.2974  Validation loss = 3.5957  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 2.2956  Validation loss = 3.5861  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 2.2944  Validation loss = 3.5796  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 2.2939  Validation loss = 3.5767  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 2.2926  Validation loss = 3.5700  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 2.2918  Validation loss = 3.5660  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 2.2903  Validation loss = 3.5579  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 2.2891  Validation loss = 3.5509  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 2.2876  Validation loss = 3.5424  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 2.2860  Validation loss = 3.5335  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 2.2847  Validation loss = 3.5256  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 2.2839  Validation loss = 3.5219  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 2.2826  Validation loss = 3.5144  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 2.2825  Validation loss = 3.5148  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 2.2812  Validation loss = 3.5078  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 2.2802  Validation loss = 3.5020  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 2.2787  Validation loss = 3.4936  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 2.2779  Validation loss = 3.4886  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 2.2765  Validation loss = 3.4803  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 2.2752  Validation loss = 3.4729  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 2.2745  Validation loss = 3.4690  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 2.2734  Validation loss = 3.4620  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 2.2721  Validation loss = 3.4542  \n",
      "\n",
      "Fold: 32  Epoch: 50  Training loss = 2.2707  Validation loss = 3.4451  \n",
      "\n",
      "Fold: 32  Epoch: 51  Training loss = 2.2694  Validation loss = 3.4370  \n",
      "\n",
      "Fold: 32  Epoch: 52  Training loss = 2.2688  Validation loss = 3.4338  \n",
      "\n",
      "Fold: 32  Epoch: 53  Training loss = 2.2679  Validation loss = 3.4288  \n",
      "\n",
      "Fold: 32  Epoch: 54  Training loss = 2.2674  Validation loss = 3.4260  \n",
      "\n",
      "Fold: 32  Epoch: 55  Training loss = 2.2659  Validation loss = 3.4162  \n",
      "\n",
      "Fold: 32  Epoch: 56  Training loss = 2.2646  Validation loss = 3.4086  \n",
      "\n",
      "Fold: 32  Epoch: 57  Training loss = 2.2644  Validation loss = 3.4087  \n",
      "\n",
      "Fold: 32  Epoch: 58  Training loss = 2.2638  Validation loss = 3.4047  \n",
      "\n",
      "Fold: 32  Epoch: 59  Training loss = 2.2631  Validation loss = 3.4008  \n",
      "\n",
      "Fold: 32  Epoch: 60  Training loss = 2.2615  Validation loss = 3.3899  \n",
      "\n",
      "Fold: 32  Epoch: 61  Training loss = 2.2602  Validation loss = 3.3818  \n",
      "\n",
      "Fold: 32  Epoch: 62  Training loss = 2.2588  Validation loss = 3.3729  \n",
      "\n",
      "Fold: 32  Epoch: 63  Training loss = 2.2578  Validation loss = 3.3660  \n",
      "\n",
      "Fold: 32  Epoch: 64  Training loss = 2.2573  Validation loss = 3.3636  \n",
      "\n",
      "Fold: 32  Epoch: 65  Training loss = 2.2556  Validation loss = 3.3520  \n",
      "\n",
      "Fold: 32  Epoch: 66  Training loss = 2.2541  Validation loss = 3.3410  \n",
      "\n",
      "Fold: 32  Epoch: 67  Training loss = 2.2528  Validation loss = 3.3317  \n",
      "\n",
      "Fold: 32  Epoch: 68  Training loss = 2.2517  Validation loss = 3.3245  \n",
      "\n",
      "Fold: 32  Epoch: 69  Training loss = 2.2498  Validation loss = 3.3093  \n",
      "\n",
      "Fold: 32  Epoch: 70  Training loss = 2.2489  Validation loss = 3.3039  \n",
      "\n",
      "Fold: 32  Epoch: 71  Training loss = 2.2486  Validation loss = 3.3024  \n",
      "\n",
      "Fold: 32  Epoch: 72  Training loss = 2.2477  Validation loss = 3.2969  \n",
      "\n",
      "Fold: 32  Epoch: 73  Training loss = 2.2468  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 32  Epoch: 74  Training loss = 2.2461  Validation loss = 3.2855  \n",
      "\n",
      "Fold: 32  Epoch: 75  Training loss = 2.2447  Validation loss = 3.2743  \n",
      "\n",
      "Fold: 32  Epoch: 76  Training loss = 2.2435  Validation loss = 3.2652  \n",
      "\n",
      "Fold: 32  Epoch: 77  Training loss = 2.2426  Validation loss = 3.2586  \n",
      "\n",
      "Fold: 32  Epoch: 78  Training loss = 2.2414  Validation loss = 3.2494  \n",
      "\n",
      "Fold: 32  Epoch: 79  Training loss = 2.2402  Validation loss = 3.2403  \n",
      "\n",
      "Fold: 32  Epoch: 80  Training loss = 2.2394  Validation loss = 3.2343  \n",
      "\n",
      "Fold: 32  Epoch: 81  Training loss = 2.2386  Validation loss = 3.2285  \n",
      "\n",
      "Fold: 32  Epoch: 82  Training loss = 2.2378  Validation loss = 3.2230  \n",
      "\n",
      "Fold: 32  Epoch: 83  Training loss = 2.2368  Validation loss = 3.2157  \n",
      "\n",
      "Fold: 32  Epoch: 84  Training loss = 2.2362  Validation loss = 3.2114  \n",
      "\n",
      "Fold: 32  Epoch: 85  Training loss = 2.2357  Validation loss = 3.2082  \n",
      "\n",
      "Fold: 32  Epoch: 86  Training loss = 2.2351  Validation loss = 3.2042  \n",
      "\n",
      "Fold: 32  Epoch: 87  Training loss = 2.2337  Validation loss = 3.1927  \n",
      "\n",
      "Fold: 32  Epoch: 88  Training loss = 2.2326  Validation loss = 3.1828  \n",
      "\n",
      "Fold: 32  Epoch: 89  Training loss = 2.2318  Validation loss = 3.1771  \n",
      "\n",
      "Fold: 32  Epoch: 90  Training loss = 2.2310  Validation loss = 3.1700  \n",
      "\n",
      "Fold: 32  Epoch: 91  Training loss = 2.2303  Validation loss = 3.1645  \n",
      "\n",
      "Fold: 32  Epoch: 92  Training loss = 2.2303  Validation loss = 3.1671  \n",
      "\n",
      "Fold: 32  Epoch: 93  Training loss = 2.2296  Validation loss = 3.1628  \n",
      "\n",
      "Fold: 32  Epoch: 94  Training loss = 2.2278  Validation loss = 3.1461  \n",
      "\n",
      "Fold: 32  Epoch: 95  Training loss = 2.2274  Validation loss = 3.1444  \n",
      "\n",
      "Fold: 32  Epoch: 96  Training loss = 2.2265  Validation loss = 3.1369  \n",
      "\n",
      "Fold: 32  Epoch: 97  Training loss = 2.2248  Validation loss = 3.1202  \n",
      "\n",
      "Fold: 32  Epoch: 98  Training loss = 2.2240  Validation loss = 3.1132  \n",
      "\n",
      "Fold: 32  Epoch: 99  Training loss = 2.2230  Validation loss = 3.1029  \n",
      "\n",
      "Fold: 32  Epoch: 100  Training loss = 2.2222  Validation loss = 3.0957  \n",
      "\n",
      "Fold: 32  Epoch: 101  Training loss = 2.2213  Validation loss = 3.0883  \n",
      "\n",
      "Fold: 32  Epoch: 102  Training loss = 2.2208  Validation loss = 3.0850  \n",
      "\n",
      "Fold: 32  Epoch: 103  Training loss = 2.2200  Validation loss = 3.0773  \n",
      "\n",
      "Fold: 32  Epoch: 104  Training loss = 2.2199  Validation loss = 3.0777  \n",
      "\n",
      "Fold: 32  Epoch: 105  Training loss = 2.2190  Validation loss = 3.0700  \n",
      "\n",
      "Fold: 32  Epoch: 106  Training loss = 2.2185  Validation loss = 3.0664  \n",
      "\n",
      "Fold: 32  Epoch: 107  Training loss = 2.2172  Validation loss = 3.0539  \n",
      "\n",
      "Fold: 32  Epoch: 108  Training loss = 2.2169  Validation loss = 3.0526  \n",
      "\n",
      "Fold: 32  Epoch: 109  Training loss = 2.2161  Validation loss = 3.0466  \n",
      "\n",
      "Fold: 32  Epoch: 110  Training loss = 2.2147  Validation loss = 3.0319  \n",
      "\n",
      "Fold: 32  Epoch: 111  Training loss = 2.2138  Validation loss = 3.0231  \n",
      "\n",
      "Fold: 32  Epoch: 112  Training loss = 2.2138  Validation loss = 3.0281  \n",
      "\n",
      "Fold: 32  Epoch: 113  Training loss = 2.2135  Validation loss = 3.0275  \n",
      "\n",
      "Fold: 32  Epoch: 114  Training loss = 2.2132  Validation loss = 3.0272  \n",
      "\n",
      "Fold: 32  Epoch: 115  Training loss = 2.2130  Validation loss = 3.0286  \n",
      "\n",
      "Fold: 32  Epoch: 116  Training loss = 2.2124  Validation loss = 3.0238  \n",
      "\n",
      "Fold: 32  Epoch: 117  Training loss = 2.2117  Validation loss = 3.0188  \n",
      "\n",
      "Fold: 32  Epoch: 118  Training loss = 2.2109  Validation loss = 3.0107  \n",
      "\n",
      "Fold: 32  Epoch: 119  Training loss = 2.2098  Validation loss = 3.0000  \n",
      "\n",
      "Fold: 32  Epoch: 120  Training loss = 2.2096  Validation loss = 2.9999  \n",
      "\n",
      "Fold: 32  Epoch: 121  Training loss = 2.2090  Validation loss = 2.9964  \n",
      "\n",
      "Fold: 32  Epoch: 122  Training loss = 2.2085  Validation loss = 2.9926  \n",
      "\n",
      "Fold: 32  Epoch: 123  Training loss = 2.2075  Validation loss = 2.9817  \n",
      "\n",
      "Fold: 32  Epoch: 124  Training loss = 2.2070  Validation loss = 2.9776  \n",
      "\n",
      "Fold: 32  Epoch: 125  Training loss = 2.2066  Validation loss = 2.9755  \n",
      "\n",
      "Fold: 32  Epoch: 126  Training loss = 2.2061  Validation loss = 2.9717  \n",
      "\n",
      "Fold: 32  Epoch: 127  Training loss = 2.2052  Validation loss = 2.9608  \n",
      "\n",
      "Fold: 32  Epoch: 128  Training loss = 2.2043  Validation loss = 2.9506  \n",
      "\n",
      "Fold: 32  Epoch: 129  Training loss = 2.2039  Validation loss = 2.9466  \n",
      "\n",
      "Fold: 32  Epoch: 130  Training loss = 2.2037  Validation loss = 2.9472  \n",
      "\n",
      "Fold: 32  Epoch: 131  Training loss = 2.2036  Validation loss = 2.9489  \n",
      "\n",
      "Fold: 32  Epoch: 132  Training loss = 2.2035  Validation loss = 2.9500  \n",
      "\n",
      "Fold: 32  Epoch: 133  Training loss = 2.2031  Validation loss = 2.9485  \n",
      "\n",
      "Fold: 32  Epoch: 134  Training loss = 2.2022  Validation loss = 2.9374  \n",
      "\n",
      "Fold: 32  Epoch: 135  Training loss = 2.2016  Validation loss = 2.9325  \n",
      "\n",
      "Fold: 32  Epoch: 136  Training loss = 2.2012  Validation loss = 2.9306  \n",
      "\n",
      "Fold: 32  Epoch: 137  Training loss = 2.2005  Validation loss = 2.9216  \n",
      "\n",
      "Fold: 32  Epoch: 138  Training loss = 2.2003  Validation loss = 2.9225  \n",
      "\n",
      "Fold: 32  Epoch: 139  Training loss = 2.2000  Validation loss = 2.9221  \n",
      "\n",
      "Fold: 32  Epoch: 140  Training loss = 2.1994  Validation loss = 2.9166  \n",
      "\n",
      "Fold: 32  Epoch: 141  Training loss = 2.1985  Validation loss = 2.9082  \n",
      "\n",
      "Fold: 32  Epoch: 142  Training loss = 2.1980  Validation loss = 2.9010  \n",
      "\n",
      "Fold: 32  Epoch: 143  Training loss = 2.1975  Validation loss = 2.8963  \n",
      "\n",
      "Fold: 32  Epoch: 144  Training loss = 2.1970  Validation loss = 2.8931  \n",
      "\n",
      "Fold: 32  Epoch: 145  Training loss = 2.1966  Validation loss = 2.8925  \n",
      "\n",
      "Fold: 32  Epoch: 146  Training loss = 2.1963  Validation loss = 2.8890  \n",
      "\n",
      "Fold: 32  Epoch: 147  Training loss = 2.1957  Validation loss = 2.8820  \n",
      "\n",
      "Fold: 32  Epoch: 148  Training loss = 2.1952  Validation loss = 2.8766  \n",
      "\n",
      "Fold: 32  Epoch: 149  Training loss = 2.1948  Validation loss = 2.8737  \n",
      "\n",
      "Fold: 32  Epoch: 150  Training loss = 2.1945  Validation loss = 2.8713  \n",
      "\n",
      "Fold: 32  Epoch: 151  Training loss = 2.1936  Validation loss = 2.8595  \n",
      "\n",
      "Fold: 32  Epoch: 152  Training loss = 2.1928  Validation loss = 2.8487  \n",
      "\n",
      "Fold: 32  Epoch: 153  Training loss = 2.1921  Validation loss = 2.8421  \n",
      "\n",
      "Fold: 32  Epoch: 154  Training loss = 2.1917  Validation loss = 2.8371  \n",
      "\n",
      "Fold: 32  Epoch: 155  Training loss = 2.1914  Validation loss = 2.8344  \n",
      "\n",
      "Fold: 32  Epoch: 156  Training loss = 2.1909  Validation loss = 2.8295  \n",
      "\n",
      "Fold: 32  Epoch: 157  Training loss = 2.1903  Validation loss = 2.8228  \n",
      "\n",
      "Fold: 32  Epoch: 158  Training loss = 2.1895  Validation loss = 2.8134  \n",
      "\n",
      "Fold: 32  Epoch: 159  Training loss = 2.1893  Validation loss = 2.8165  \n",
      "\n",
      "Fold: 32  Epoch: 160  Training loss = 2.1889  Validation loss = 2.8109  \n",
      "\n",
      "Fold: 32  Epoch: 161  Training loss = 2.1880  Validation loss = 2.7992  \n",
      "\n",
      "Fold: 32  Epoch: 162  Training loss = 2.1877  Validation loss = 2.7954  \n",
      "\n",
      "Fold: 32  Epoch: 163  Training loss = 2.1874  Validation loss = 2.7948  \n",
      "\n",
      "Fold: 32  Epoch: 164  Training loss = 2.1870  Validation loss = 2.7919  \n",
      "\n",
      "Fold: 32  Epoch: 165  Training loss = 2.1863  Validation loss = 2.7845  \n",
      "\n",
      "Fold: 32  Epoch: 166  Training loss = 2.1856  Validation loss = 2.7758  \n",
      "\n",
      "Fold: 32  Epoch: 167  Training loss = 2.1853  Validation loss = 2.7738  \n",
      "\n",
      "Fold: 32  Epoch: 168  Training loss = 2.1849  Validation loss = 2.7726  \n",
      "\n",
      "Fold: 32  Epoch: 169  Training loss = 2.1843  Validation loss = 2.7649  \n",
      "\n",
      "Fold: 32  Epoch: 170  Training loss = 2.1839  Validation loss = 2.7636  \n",
      "\n",
      "Fold: 32  Epoch: 171  Training loss = 2.1836  Validation loss = 2.7606  \n",
      "\n",
      "Fold: 32  Epoch: 172  Training loss = 2.1837  Validation loss = 2.7653  \n",
      "\n",
      "Fold: 32  Epoch: 173  Training loss = 2.1833  Validation loss = 2.7592  \n",
      "\n",
      "Fold: 32  Epoch: 174  Training loss = 2.1829  Validation loss = 2.7543  \n",
      "\n",
      "Fold: 32  Epoch: 175  Training loss = 2.1824  Validation loss = 2.7486  \n",
      "\n",
      "Fold: 32  Epoch: 176  Training loss = 2.1820  Validation loss = 2.7438  \n",
      "\n",
      "Fold: 32  Epoch: 177  Training loss = 2.1818  Validation loss = 2.7467  \n",
      "\n",
      "Fold: 32  Epoch: 178  Training loss = 2.1813  Validation loss = 2.7400  \n",
      "\n",
      "Fold: 32  Epoch: 179  Training loss = 2.1809  Validation loss = 2.7333  \n",
      "\n",
      "Fold: 32  Epoch: 180  Training loss = 2.1806  Validation loss = 2.7378  \n",
      "\n",
      "Fold: 32  Epoch: 181  Training loss = 2.1801  Validation loss = 2.7308  \n",
      "\n",
      "Fold: 32  Epoch: 182  Training loss = 2.1796  Validation loss = 2.7244  \n",
      "\n",
      "Fold: 32  Epoch: 183  Training loss = 2.1793  Validation loss = 2.7204  \n",
      "\n",
      "Fold: 32  Epoch: 184  Training loss = 2.1789  Validation loss = 2.7181  \n",
      "\n",
      "Fold: 32  Epoch: 185  Training loss = 2.1788  Validation loss = 2.7206  \n",
      "\n",
      "Fold: 32  Epoch: 186  Training loss = 2.1782  Validation loss = 2.7142  \n",
      "\n",
      "Fold: 32  Epoch: 187  Training loss = 2.1779  Validation loss = 2.7110  \n",
      "\n",
      "Fold: 32  Epoch: 188  Training loss = 2.1773  Validation loss = 2.7058  \n",
      "\n",
      "Fold: 32  Epoch: 189  Training loss = 2.1769  Validation loss = 2.6999  \n",
      "\n",
      "Fold: 32  Epoch: 190  Training loss = 2.1768  Validation loss = 2.7071  \n",
      "\n",
      "Fold: 32  Epoch: 191  Training loss = 2.1763  Validation loss = 2.7040  \n",
      "\n",
      "Fold: 32  Epoch: 192  Training loss = 2.1761  Validation loss = 2.7075  \n",
      "\n",
      "Fold: 32  Epoch: 193  Training loss = 2.1756  Validation loss = 2.7013  \n",
      "\n",
      "Fold: 32  Epoch: 194  Training loss = 2.1752  Validation loss = 2.6994  \n",
      "\n",
      "Fold: 32  Epoch: 195  Training loss = 2.1747  Validation loss = 2.6902  \n",
      "\n",
      "Fold: 32  Epoch: 196  Training loss = 2.1745  Validation loss = 2.6900  \n",
      "\n",
      "Fold: 32  Epoch: 197  Training loss = 2.1743  Validation loss = 2.6905  \n",
      "\n",
      "Fold: 32  Epoch: 198  Training loss = 2.1741  Validation loss = 2.6927  \n",
      "\n",
      "Fold: 32  Epoch: 199  Training loss = 2.1738  Validation loss = 2.6908  \n",
      "\n",
      "Fold: 32  Epoch: 200  Training loss = 2.1735  Validation loss = 2.6857  \n",
      "\n",
      "Fold: 32  Epoch: 201  Training loss = 2.1732  Validation loss = 2.6851  \n",
      "\n",
      "Fold: 32  Epoch: 202  Training loss = 2.1732  Validation loss = 2.6893  \n",
      "\n",
      "Fold: 32  Epoch: 203  Training loss = 2.1727  Validation loss = 2.6851  \n",
      "\n",
      "Fold: 32  Epoch: 204  Training loss = 2.1726  Validation loss = 2.6882  \n",
      "\n",
      "Fold: 32  Epoch: 205  Training loss = 2.1723  Validation loss = 2.6870  \n",
      "\n",
      "Fold: 32  Epoch: 206  Training loss = 2.1717  Validation loss = 2.6775  \n",
      "\n",
      "Fold: 32  Epoch: 207  Training loss = 2.1713  Validation loss = 2.6711  \n",
      "\n",
      "Fold: 32  Epoch: 208  Training loss = 2.1711  Validation loss = 2.6713  \n",
      "\n",
      "Fold: 32  Epoch: 209  Training loss = 2.1707  Validation loss = 2.6716  \n",
      "\n",
      "Fold: 32  Epoch: 210  Training loss = 2.1704  Validation loss = 2.6704  \n",
      "\n",
      "Fold: 32  Epoch: 211  Training loss = 2.1699  Validation loss = 2.6626  \n",
      "\n",
      "Fold: 32  Epoch: 212  Training loss = 2.1695  Validation loss = 2.6548  \n",
      "\n",
      "Fold: 32  Epoch: 213  Training loss = 2.1692  Validation loss = 2.6497  \n",
      "\n",
      "Fold: 32  Epoch: 214  Training loss = 2.1688  Validation loss = 2.6483  \n",
      "\n",
      "Fold: 32  Epoch: 215  Training loss = 2.1687  Validation loss = 2.6514  \n",
      "\n",
      "Fold: 32  Epoch: 216  Training loss = 2.1682  Validation loss = 2.6426  \n",
      "\n",
      "Fold: 32  Epoch: 217  Training loss = 2.1678  Validation loss = 2.6403  \n",
      "\n",
      "Fold: 32  Epoch: 218  Training loss = 2.1674  Validation loss = 2.6356  \n",
      "\n",
      "Fold: 32  Epoch: 219  Training loss = 2.1671  Validation loss = 2.6336  \n",
      "\n",
      "Fold: 32  Epoch: 220  Training loss = 2.1669  Validation loss = 2.6320  \n",
      "\n",
      "Fold: 32  Epoch: 221  Training loss = 2.1664  Validation loss = 2.6262  \n",
      "\n",
      "Fold: 32  Epoch: 222  Training loss = 2.1662  Validation loss = 2.6267  \n",
      "\n",
      "Fold: 32  Epoch: 223  Training loss = 2.1660  Validation loss = 2.6218  \n",
      "\n",
      "Fold: 32  Epoch: 224  Training loss = 2.1656  Validation loss = 2.6179  \n",
      "\n",
      "Fold: 32  Epoch: 225  Training loss = 2.1653  Validation loss = 2.6105  \n",
      "\n",
      "Fold: 32  Epoch: 226  Training loss = 2.1651  Validation loss = 2.6079  \n",
      "\n",
      "Fold: 32  Epoch: 227  Training loss = 2.1648  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 32  Epoch: 228  Training loss = 2.1646  Validation loss = 2.6107  \n",
      "\n",
      "Fold: 32  Epoch: 229  Training loss = 2.1644  Validation loss = 2.6108  \n",
      "\n",
      "Fold: 32  Epoch: 230  Training loss = 2.1642  Validation loss = 2.6132  \n",
      "\n",
      "Fold: 32  Epoch: 231  Training loss = 2.1640  Validation loss = 2.6140  \n",
      "\n",
      "Fold: 32  Epoch: 232  Training loss = 2.1638  Validation loss = 2.6140  \n",
      "\n",
      "Fold: 32  Epoch: 233  Training loss = 2.1635  Validation loss = 2.6093  \n",
      "\n",
      "Fold: 32  Epoch: 234  Training loss = 2.1633  Validation loss = 2.6093  \n",
      "\n",
      "Fold: 32  Epoch: 235  Training loss = 2.1630  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 32  Epoch: 236  Training loss = 2.1628  Validation loss = 2.6115  \n",
      "\n",
      "Fold: 32  Epoch: 237  Training loss = 2.1625  Validation loss = 2.6084  \n",
      "\n",
      "Fold: 32  Epoch: 238  Training loss = 2.1622  Validation loss = 2.6039  \n",
      "\n",
      "Fold: 32  Epoch: 239  Training loss = 2.1618  Validation loss = 2.5986  \n",
      "\n",
      "Fold: 32  Epoch: 240  Training loss = 2.1616  Validation loss = 2.5975  \n",
      "\n",
      "Fold: 32  Epoch: 241  Training loss = 2.1614  Validation loss = 2.5980  \n",
      "\n",
      "Fold: 32  Epoch: 242  Training loss = 2.1611  Validation loss = 2.5929  \n",
      "\n",
      "Fold: 32  Epoch: 243  Training loss = 2.1607  Validation loss = 2.5916  \n",
      "\n",
      "Fold: 32  Epoch: 244  Training loss = 2.1605  Validation loss = 2.5891  \n",
      "\n",
      "Fold: 32  Epoch: 245  Training loss = 2.1603  Validation loss = 2.5863  \n",
      "\n",
      "Fold: 32  Epoch: 246  Training loss = 2.1600  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 32  Epoch: 247  Training loss = 2.1596  Validation loss = 2.5789  \n",
      "\n",
      "Fold: 32  Epoch: 248  Training loss = 2.1594  Validation loss = 2.5792  \n",
      "\n",
      "Fold: 32  Epoch: 249  Training loss = 2.1591  Validation loss = 2.5773  \n",
      "\n",
      "Fold: 32  Epoch: 250  Training loss = 2.1589  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 32  Epoch: 251  Training loss = 2.1587  Validation loss = 2.5753  \n",
      "\n",
      "Fold: 32  Epoch: 252  Training loss = 2.1584  Validation loss = 2.5766  \n",
      "\n",
      "Fold: 32  Epoch: 253  Training loss = 2.1581  Validation loss = 2.5768  \n",
      "\n",
      "Fold: 32  Epoch: 254  Training loss = 2.1578  Validation loss = 2.5670  \n",
      "\n",
      "Fold: 32  Epoch: 255  Training loss = 2.1576  Validation loss = 2.5706  \n",
      "\n",
      "Fold: 32  Epoch: 256  Training loss = 2.1573  Validation loss = 2.5678  \n",
      "\n",
      "Fold: 32  Epoch: 257  Training loss = 2.1571  Validation loss = 2.5692  \n",
      "\n",
      "Fold: 32  Epoch: 258  Training loss = 2.1568  Validation loss = 2.5596  \n",
      "\n",
      "Fold: 32  Epoch: 259  Training loss = 2.1566  Validation loss = 2.5569  \n",
      "\n",
      "Fold: 32  Epoch: 260  Training loss = 2.1563  Validation loss = 2.5556  \n",
      "\n",
      "Fold: 32  Epoch: 261  Training loss = 2.1561  Validation loss = 2.5513  \n",
      "\n",
      "Fold: 32  Epoch: 262  Training loss = 2.1558  Validation loss = 2.5442  \n",
      "\n",
      "Fold: 32  Epoch: 263  Training loss = 2.1556  Validation loss = 2.5390  \n",
      "\n",
      "Fold: 32  Epoch: 264  Training loss = 2.1555  Validation loss = 2.5363  \n",
      "\n",
      "Fold: 32  Epoch: 265  Training loss = 2.1553  Validation loss = 2.5351  \n",
      "\n",
      "Fold: 32  Epoch: 266  Training loss = 2.1550  Validation loss = 2.5316  \n",
      "\n",
      "Fold: 32  Epoch: 267  Training loss = 2.1548  Validation loss = 2.5324  \n",
      "\n",
      "Fold: 32  Epoch: 268  Training loss = 2.1546  Validation loss = 2.5400  \n",
      "\n",
      "Fold: 32  Epoch: 269  Training loss = 2.1544  Validation loss = 2.5373  \n",
      "\n",
      "Fold: 32  Epoch: 270  Training loss = 2.1541  Validation loss = 2.5321  \n",
      "\n",
      "Fold: 32  Epoch: 271  Training loss = 2.1540  Validation loss = 2.5272  \n",
      "\n",
      "Fold: 32  Epoch: 272  Training loss = 2.1537  Validation loss = 2.5244  \n",
      "\n",
      "Fold: 32  Epoch: 273  Training loss = 2.1535  Validation loss = 2.5309  \n",
      "\n",
      "Fold: 32  Epoch: 274  Training loss = 2.1534  Validation loss = 2.5350  \n",
      "\n",
      "Fold: 32  Epoch: 275  Training loss = 2.1531  Validation loss = 2.5313  \n",
      "\n",
      "Fold: 32  Epoch: 276  Training loss = 2.1529  Validation loss = 2.5399  \n",
      "\n",
      "Fold: 32  Epoch: 277  Training loss = 2.1525  Validation loss = 2.5311  \n",
      "\n",
      "Fold: 32  Epoch: 278  Training loss = 2.1523  Validation loss = 2.5272  \n",
      "\n",
      "Fold: 32  Epoch: 279  Training loss = 2.1521  Validation loss = 2.5263  \n",
      "\n",
      "Fold: 32  Epoch: 280  Training loss = 2.1519  Validation loss = 2.5224  \n",
      "\n",
      "Fold: 32  Epoch: 281  Training loss = 2.1517  Validation loss = 2.5226  \n",
      "\n",
      "Fold: 32  Epoch: 282  Training loss = 2.1515  Validation loss = 2.5228  \n",
      "\n",
      "Fold: 32  Epoch: 283  Training loss = 2.1513  Validation loss = 2.5222  \n",
      "\n",
      "Fold: 32  Epoch: 284  Training loss = 2.1512  Validation loss = 2.5277  \n",
      "\n",
      "Fold: 32  Epoch: 285  Training loss = 2.1510  Validation loss = 2.5295  \n",
      "\n",
      "Fold: 32  Epoch: 286  Training loss = 2.1508  Validation loss = 2.5294  \n",
      "\n",
      "Fold: 32  Epoch: 287  Training loss = 2.1506  Validation loss = 2.5327  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 283  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 327\n",
      "Average validation error: 3.49696\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.9537  Test loss = 2.5831  \n",
      "\n",
      "Epoch: 2  Training loss = 1.9535  Test loss = 2.5830  \n",
      "\n",
      "Epoch: 3  Training loss = 1.9534  Test loss = 2.5828  \n",
      "\n",
      "Epoch: 4  Training loss = 1.9533  Test loss = 2.5826  \n",
      "\n",
      "Epoch: 5  Training loss = 1.9531  Test loss = 2.5824  \n",
      "\n",
      "Epoch: 6  Training loss = 1.9530  Test loss = 2.5822  \n",
      "\n",
      "Epoch: 7  Training loss = 1.9529  Test loss = 2.5820  \n",
      "\n",
      "Epoch: 8  Training loss = 1.9527  Test loss = 2.5818  \n",
      "\n",
      "Epoch: 9  Training loss = 1.9526  Test loss = 2.5816  \n",
      "\n",
      "Epoch: 10  Training loss = 1.9525  Test loss = 2.5814  \n",
      "\n",
      "Epoch: 11  Training loss = 1.9523  Test loss = 2.5812  \n",
      "\n",
      "Epoch: 12  Training loss = 1.9522  Test loss = 2.5810  \n",
      "\n",
      "Epoch: 13  Training loss = 1.9521  Test loss = 2.5808  \n",
      "\n",
      "Epoch: 14  Training loss = 1.9519  Test loss = 2.5806  \n",
      "\n",
      "Epoch: 15  Training loss = 1.9518  Test loss = 2.5804  \n",
      "\n",
      "Epoch: 16  Training loss = 1.9517  Test loss = 2.5802  \n",
      "\n",
      "Epoch: 17  Training loss = 1.9515  Test loss = 2.5800  \n",
      "\n",
      "Epoch: 18  Training loss = 1.9514  Test loss = 2.5798  \n",
      "\n",
      "Epoch: 19  Training loss = 1.9513  Test loss = 2.5796  \n",
      "\n",
      "Epoch: 20  Training loss = 1.9511  Test loss = 2.5794  \n",
      "\n",
      "Epoch: 21  Training loss = 1.9510  Test loss = 2.5792  \n",
      "\n",
      "Epoch: 22  Training loss = 1.9509  Test loss = 2.5790  \n",
      "\n",
      "Epoch: 23  Training loss = 1.9507  Test loss = 2.5789  \n",
      "\n",
      "Epoch: 24  Training loss = 1.9506  Test loss = 2.5787  \n",
      "\n",
      "Epoch: 25  Training loss = 1.9505  Test loss = 2.5785  \n",
      "\n",
      "Epoch: 26  Training loss = 1.9504  Test loss = 2.5783  \n",
      "\n",
      "Epoch: 27  Training loss = 1.9502  Test loss = 2.5781  \n",
      "\n",
      "Epoch: 28  Training loss = 1.9501  Test loss = 2.5779  \n",
      "\n",
      "Epoch: 29  Training loss = 1.9500  Test loss = 2.5777  \n",
      "\n",
      "Epoch: 30  Training loss = 1.9498  Test loss = 2.5775  \n",
      "\n",
      "Epoch: 31  Training loss = 1.9497  Test loss = 2.5773  \n",
      "\n",
      "Epoch: 32  Training loss = 1.9496  Test loss = 2.5771  \n",
      "\n",
      "Epoch: 33  Training loss = 1.9494  Test loss = 2.5769  \n",
      "\n",
      "Epoch: 34  Training loss = 1.9493  Test loss = 2.5768  \n",
      "\n",
      "Epoch: 35  Training loss = 1.9492  Test loss = 2.5766  \n",
      "\n",
      "Epoch: 36  Training loss = 1.9491  Test loss = 2.5764  \n",
      "\n",
      "Epoch: 37  Training loss = 1.9489  Test loss = 2.5762  \n",
      "\n",
      "Epoch: 38  Training loss = 1.9488  Test loss = 2.5760  \n",
      "\n",
      "Epoch: 39  Training loss = 1.9487  Test loss = 2.5758  \n",
      "\n",
      "Epoch: 40  Training loss = 1.9485  Test loss = 2.5756  \n",
      "\n",
      "Epoch: 41  Training loss = 1.9484  Test loss = 2.5754  \n",
      "\n",
      "Epoch: 42  Training loss = 1.9483  Test loss = 2.5753  \n",
      "\n",
      "Epoch: 43  Training loss = 1.9482  Test loss = 2.5751  \n",
      "\n",
      "Epoch: 44  Training loss = 1.9480  Test loss = 2.5749  \n",
      "\n",
      "Epoch: 45  Training loss = 1.9479  Test loss = 2.5747  \n",
      "\n",
      "Epoch: 46  Training loss = 1.9478  Test loss = 2.5745  \n",
      "\n",
      "Epoch: 47  Training loss = 1.9476  Test loss = 2.5743  \n",
      "\n",
      "Epoch: 48  Training loss = 1.9475  Test loss = 2.5741  \n",
      "\n",
      "Epoch: 49  Training loss = 1.9474  Test loss = 2.5740  \n",
      "\n",
      "Epoch: 50  Training loss = 1.9473  Test loss = 2.5738  \n",
      "\n",
      "Epoch: 51  Training loss = 1.9471  Test loss = 2.5736  \n",
      "\n",
      "Epoch: 52  Training loss = 1.9470  Test loss = 2.5734  \n",
      "\n",
      "Epoch: 53  Training loss = 1.9469  Test loss = 2.5732  \n",
      "\n",
      "Epoch: 54  Training loss = 1.9468  Test loss = 2.5730  \n",
      "\n",
      "Epoch: 55  Training loss = 1.9466  Test loss = 2.5729  \n",
      "\n",
      "Epoch: 56  Training loss = 1.9465  Test loss = 2.5727  \n",
      "\n",
      "Epoch: 57  Training loss = 1.9464  Test loss = 2.5725  \n",
      "\n",
      "Epoch: 58  Training loss = 1.9463  Test loss = 2.5723  \n",
      "\n",
      "Epoch: 59  Training loss = 1.9461  Test loss = 2.5721  \n",
      "\n",
      "Epoch: 60  Training loss = 1.9460  Test loss = 2.5719  \n",
      "\n",
      "Epoch: 61  Training loss = 1.9459  Test loss = 2.5718  \n",
      "\n",
      "Epoch: 62  Training loss = 1.9458  Test loss = 2.5716  \n",
      "\n",
      "Epoch: 63  Training loss = 1.9456  Test loss = 2.5714  \n",
      "\n",
      "Epoch: 64  Training loss = 1.9455  Test loss = 2.5712  \n",
      "\n",
      "Epoch: 65  Training loss = 1.9454  Test loss = 2.5710  \n",
      "\n",
      "Epoch: 66  Training loss = 1.9453  Test loss = 2.5709  \n",
      "\n",
      "Epoch: 67  Training loss = 1.9451  Test loss = 2.5707  \n",
      "\n",
      "Epoch: 68  Training loss = 1.9450  Test loss = 2.5705  \n",
      "\n",
      "Epoch: 69  Training loss = 1.9449  Test loss = 2.5703  \n",
      "\n",
      "Epoch: 70  Training loss = 1.9448  Test loss = 2.5701  \n",
      "\n",
      "Epoch: 71  Training loss = 1.9446  Test loss = 2.5700  \n",
      "\n",
      "Epoch: 72  Training loss = 1.9445  Test loss = 2.5698  \n",
      "\n",
      "Epoch: 73  Training loss = 1.9444  Test loss = 2.5696  \n",
      "\n",
      "Epoch: 74  Training loss = 1.9443  Test loss = 2.5694  \n",
      "\n",
      "Epoch: 75  Training loss = 1.9442  Test loss = 2.5693  \n",
      "\n",
      "Epoch: 76  Training loss = 1.9440  Test loss = 2.5691  \n",
      "\n",
      "Epoch: 77  Training loss = 1.9439  Test loss = 2.5689  \n",
      "\n",
      "Epoch: 78  Training loss = 1.9438  Test loss = 2.5687  \n",
      "\n",
      "Epoch: 79  Training loss = 1.9437  Test loss = 2.5685  \n",
      "\n",
      "Epoch: 80  Training loss = 1.9435  Test loss = 2.5684  \n",
      "\n",
      "Epoch: 81  Training loss = 1.9434  Test loss = 2.5682  \n",
      "\n",
      "Epoch: 82  Training loss = 1.9433  Test loss = 2.5680  \n",
      "\n",
      "Epoch: 83  Training loss = 1.9432  Test loss = 2.5678  \n",
      "\n",
      "Epoch: 84  Training loss = 1.9431  Test loss = 2.5677  \n",
      "\n",
      "Epoch: 85  Training loss = 1.9429  Test loss = 2.5675  \n",
      "\n",
      "Epoch: 86  Training loss = 1.9428  Test loss = 2.5673  \n",
      "\n",
      "Epoch: 87  Training loss = 1.9427  Test loss = 2.5671  \n",
      "\n",
      "Epoch: 88  Training loss = 1.9426  Test loss = 2.5670  \n",
      "\n",
      "Epoch: 89  Training loss = 1.9425  Test loss = 2.5668  \n",
      "\n",
      "Epoch: 90  Training loss = 1.9423  Test loss = 2.5666  \n",
      "\n",
      "Epoch: 91  Training loss = 1.9422  Test loss = 2.5665  \n",
      "\n",
      "Epoch: 92  Training loss = 1.9421  Test loss = 2.5663  \n",
      "\n",
      "Epoch: 93  Training loss = 1.9420  Test loss = 2.5661  \n",
      "\n",
      "Epoch: 94  Training loss = 1.9419  Test loss = 2.5659  \n",
      "\n",
      "Epoch: 95  Training loss = 1.9417  Test loss = 2.5658  \n",
      "\n",
      "Epoch: 96  Training loss = 1.9416  Test loss = 2.5656  \n",
      "\n",
      "Epoch: 97  Training loss = 1.9415  Test loss = 2.5654  \n",
      "\n",
      "Epoch: 98  Training loss = 1.9414  Test loss = 2.5652  \n",
      "\n",
      "Epoch: 99  Training loss = 1.9413  Test loss = 2.5651  \n",
      "\n",
      "Epoch: 100  Training loss = 1.9411  Test loss = 2.5649  \n",
      "\n",
      "Epoch: 101  Training loss = 1.9410  Test loss = 2.5647  \n",
      "\n",
      "Epoch: 102  Training loss = 1.9409  Test loss = 2.5646  \n",
      "\n",
      "Epoch: 103  Training loss = 1.9408  Test loss = 2.5644  \n",
      "\n",
      "Epoch: 104  Training loss = 1.9407  Test loss = 2.5642  \n",
      "\n",
      "Epoch: 105  Training loss = 1.9406  Test loss = 2.5641  \n",
      "\n",
      "Epoch: 106  Training loss = 1.9404  Test loss = 2.5639  \n",
      "\n",
      "Epoch: 107  Training loss = 1.9403  Test loss = 2.5637  \n",
      "\n",
      "Epoch: 108  Training loss = 1.9402  Test loss = 2.5635  \n",
      "\n",
      "Epoch: 109  Training loss = 1.9401  Test loss = 2.5634  \n",
      "\n",
      "Epoch: 110  Training loss = 1.9400  Test loss = 2.5632  \n",
      "\n",
      "Epoch: 111  Training loss = 1.9398  Test loss = 2.5630  \n",
      "\n",
      "Epoch: 112  Training loss = 1.9397  Test loss = 2.5629  \n",
      "\n",
      "Epoch: 113  Training loss = 1.9396  Test loss = 2.5627  \n",
      "\n",
      "Epoch: 114  Training loss = 1.9395  Test loss = 2.5625  \n",
      "\n",
      "Epoch: 115  Training loss = 1.9394  Test loss = 2.5624  \n",
      "\n",
      "Epoch: 116  Training loss = 1.9393  Test loss = 2.5622  \n",
      "\n",
      "Epoch: 117  Training loss = 1.9391  Test loss = 2.5620  \n",
      "\n",
      "Epoch: 118  Training loss = 1.9390  Test loss = 2.5619  \n",
      "\n",
      "Epoch: 119  Training loss = 1.9389  Test loss = 2.5617  \n",
      "\n",
      "Epoch: 120  Training loss = 1.9388  Test loss = 2.5615  \n",
      "\n",
      "Epoch: 121  Training loss = 1.9387  Test loss = 2.5614  \n",
      "\n",
      "Epoch: 122  Training loss = 1.9386  Test loss = 2.5612  \n",
      "\n",
      "Epoch: 123  Training loss = 1.9385  Test loss = 2.5610  \n",
      "\n",
      "Epoch: 124  Training loss = 1.9383  Test loss = 2.5609  \n",
      "\n",
      "Epoch: 125  Training loss = 1.9382  Test loss = 2.5607  \n",
      "\n",
      "Epoch: 126  Training loss = 1.9381  Test loss = 2.5605  \n",
      "\n",
      "Epoch: 127  Training loss = 1.9380  Test loss = 2.5604  \n",
      "\n",
      "Epoch: 128  Training loss = 1.9379  Test loss = 2.5602  \n",
      "\n",
      "Epoch: 129  Training loss = 1.9378  Test loss = 2.5601  \n",
      "\n",
      "Epoch: 130  Training loss = 1.9376  Test loss = 2.5599  \n",
      "\n",
      "Epoch: 131  Training loss = 1.9375  Test loss = 2.5597  \n",
      "\n",
      "Epoch: 132  Training loss = 1.9374  Test loss = 2.5596  \n",
      "\n",
      "Epoch: 133  Training loss = 1.9373  Test loss = 2.5594  \n",
      "\n",
      "Epoch: 134  Training loss = 1.9372  Test loss = 2.5592  \n",
      "\n",
      "Epoch: 135  Training loss = 1.9371  Test loss = 2.5591  \n",
      "\n",
      "Epoch: 136  Training loss = 1.9370  Test loss = 2.5589  \n",
      "\n",
      "Epoch: 137  Training loss = 1.9369  Test loss = 2.5588  \n",
      "\n",
      "Epoch: 138  Training loss = 1.9367  Test loss = 2.5586  \n",
      "\n",
      "Epoch: 139  Training loss = 1.9366  Test loss = 2.5584  \n",
      "\n",
      "Epoch: 140  Training loss = 1.9365  Test loss = 2.5583  \n",
      "\n",
      "Epoch: 141  Training loss = 1.9364  Test loss = 2.5581  \n",
      "\n",
      "Epoch: 142  Training loss = 1.9363  Test loss = 2.5579  \n",
      "\n",
      "Epoch: 143  Training loss = 1.9362  Test loss = 2.5578  \n",
      "\n",
      "Epoch: 144  Training loss = 1.9361  Test loss = 2.5576  \n",
      "\n",
      "Epoch: 145  Training loss = 1.9360  Test loss = 2.5575  \n",
      "\n",
      "Epoch: 146  Training loss = 1.9358  Test loss = 2.5573  \n",
      "\n",
      "Epoch: 147  Training loss = 1.9357  Test loss = 2.5571  \n",
      "\n",
      "Epoch: 148  Training loss = 1.9356  Test loss = 2.5570  \n",
      "\n",
      "Epoch: 149  Training loss = 1.9355  Test loss = 2.5568  \n",
      "\n",
      "Epoch: 150  Training loss = 1.9354  Test loss = 2.5567  \n",
      "\n",
      "Epoch: 151  Training loss = 1.9353  Test loss = 2.5565  \n",
      "\n",
      "Epoch: 152  Training loss = 1.9352  Test loss = 2.5563  \n",
      "\n",
      "Epoch: 153  Training loss = 1.9351  Test loss = 2.5562  \n",
      "\n",
      "Epoch: 154  Training loss = 1.9349  Test loss = 2.5560  \n",
      "\n",
      "Epoch: 155  Training loss = 1.9348  Test loss = 2.5559  \n",
      "\n",
      "Epoch: 156  Training loss = 1.9347  Test loss = 2.5557  \n",
      "\n",
      "Epoch: 157  Training loss = 1.9346  Test loss = 2.5556  \n",
      "\n",
      "Epoch: 158  Training loss = 1.9345  Test loss = 2.5554  \n",
      "\n",
      "Epoch: 159  Training loss = 1.9344  Test loss = 2.5552  \n",
      "\n",
      "Epoch: 160  Training loss = 1.9343  Test loss = 2.5551  \n",
      "\n",
      "Epoch: 161  Training loss = 1.9342  Test loss = 2.5549  \n",
      "\n",
      "Epoch: 162  Training loss = 1.9341  Test loss = 2.5548  \n",
      "\n",
      "Epoch: 163  Training loss = 1.9340  Test loss = 2.5546  \n",
      "\n",
      "Epoch: 164  Training loss = 1.9338  Test loss = 2.5545  \n",
      "\n",
      "Epoch: 165  Training loss = 1.9337  Test loss = 2.5543  \n",
      "\n",
      "Epoch: 166  Training loss = 1.9336  Test loss = 2.5542  \n",
      "\n",
      "Epoch: 167  Training loss = 1.9335  Test loss = 2.5540  \n",
      "\n",
      "Epoch: 168  Training loss = 1.9334  Test loss = 2.5538  \n",
      "\n",
      "Epoch: 169  Training loss = 1.9333  Test loss = 2.5537  \n",
      "\n",
      "Epoch: 170  Training loss = 1.9332  Test loss = 2.5535  \n",
      "\n",
      "Epoch: 171  Training loss = 1.9331  Test loss = 2.5534  \n",
      "\n",
      "Epoch: 172  Training loss = 1.9330  Test loss = 2.5532  \n",
      "\n",
      "Epoch: 173  Training loss = 1.9329  Test loss = 2.5531  \n",
      "\n",
      "Epoch: 174  Training loss = 1.9328  Test loss = 2.5529  \n",
      "\n",
      "Epoch: 175  Training loss = 1.9326  Test loss = 2.5528  \n",
      "\n",
      "Epoch: 176  Training loss = 1.9325  Test loss = 2.5526  \n",
      "\n",
      "Epoch: 177  Training loss = 1.9324  Test loss = 2.5525  \n",
      "\n",
      "Epoch: 178  Training loss = 1.9323  Test loss = 2.5523  \n",
      "\n",
      "Epoch: 179  Training loss = 1.9322  Test loss = 2.5521  \n",
      "\n",
      "Epoch: 180  Training loss = 1.9321  Test loss = 2.5520  \n",
      "\n",
      "Epoch: 181  Training loss = 1.9320  Test loss = 2.5518  \n",
      "\n",
      "Epoch: 182  Training loss = 1.9319  Test loss = 2.5517  \n",
      "\n",
      "Epoch: 183  Training loss = 1.9318  Test loss = 2.5515  \n",
      "\n",
      "Epoch: 184  Training loss = 1.9317  Test loss = 2.5514  \n",
      "\n",
      "Epoch: 185  Training loss = 1.9316  Test loss = 2.5512  \n",
      "\n",
      "Epoch: 186  Training loss = 1.9315  Test loss = 2.5511  \n",
      "\n",
      "Epoch: 187  Training loss = 1.9314  Test loss = 2.5509  \n",
      "\n",
      "Epoch: 188  Training loss = 1.9313  Test loss = 2.5508  \n",
      "\n",
      "Epoch: 189  Training loss = 1.9311  Test loss = 2.5506  \n",
      "\n",
      "Epoch: 190  Training loss = 1.9310  Test loss = 2.5505  \n",
      "\n",
      "Epoch: 191  Training loss = 1.9309  Test loss = 2.5503  \n",
      "\n",
      "Epoch: 192  Training loss = 1.9308  Test loss = 2.5502  \n",
      "\n",
      "Epoch: 193  Training loss = 1.9307  Test loss = 2.5500  \n",
      "\n",
      "Epoch: 194  Training loss = 1.9306  Test loss = 2.5499  \n",
      "\n",
      "Epoch: 195  Training loss = 1.9305  Test loss = 2.5497  \n",
      "\n",
      "Epoch: 196  Training loss = 1.9304  Test loss = 2.5496  \n",
      "\n",
      "Epoch: 197  Training loss = 1.9303  Test loss = 2.5494  \n",
      "\n",
      "Epoch: 198  Training loss = 1.9302  Test loss = 2.5493  \n",
      "\n",
      "Epoch: 199  Training loss = 1.9301  Test loss = 2.5491  \n",
      "\n",
      "Epoch: 200  Training loss = 1.9300  Test loss = 2.5490  \n",
      "\n",
      "Epoch: 201  Training loss = 1.9299  Test loss = 2.5488  \n",
      "\n",
      "Epoch: 202  Training loss = 1.9298  Test loss = 2.5487  \n",
      "\n",
      "Epoch: 203  Training loss = 1.9297  Test loss = 2.5485  \n",
      "\n",
      "Epoch: 204  Training loss = 1.9296  Test loss = 2.5484  \n",
      "\n",
      "Epoch: 205  Training loss = 1.9295  Test loss = 2.5483  \n",
      "\n",
      "Epoch: 206  Training loss = 1.9294  Test loss = 2.5481  \n",
      "\n",
      "Epoch: 207  Training loss = 1.9292  Test loss = 2.5480  \n",
      "\n",
      "Epoch: 208  Training loss = 1.9291  Test loss = 2.5478  \n",
      "\n",
      "Epoch: 209  Training loss = 1.9290  Test loss = 2.5477  \n",
      "\n",
      "Epoch: 210  Training loss = 1.9289  Test loss = 2.5475  \n",
      "\n",
      "Epoch: 211  Training loss = 1.9288  Test loss = 2.5474  \n",
      "\n",
      "Epoch: 212  Training loss = 1.9287  Test loss = 2.5472  \n",
      "\n",
      "Epoch: 213  Training loss = 1.9286  Test loss = 2.5471  \n",
      "\n",
      "Epoch: 214  Training loss = 1.9285  Test loss = 2.5469  \n",
      "\n",
      "Epoch: 215  Training loss = 1.9284  Test loss = 2.5468  \n",
      "\n",
      "Epoch: 216  Training loss = 1.9283  Test loss = 2.5466  \n",
      "\n",
      "Epoch: 217  Training loss = 1.9282  Test loss = 2.5465  \n",
      "\n",
      "Epoch: 218  Training loss = 1.9281  Test loss = 2.5464  \n",
      "\n",
      "Epoch: 219  Training loss = 1.9280  Test loss = 2.5462  \n",
      "\n",
      "Epoch: 220  Training loss = 1.9279  Test loss = 2.5461  \n",
      "\n",
      "Epoch: 221  Training loss = 1.9278  Test loss = 2.5459  \n",
      "\n",
      "Epoch: 222  Training loss = 1.9277  Test loss = 2.5458  \n",
      "\n",
      "Epoch: 223  Training loss = 1.9276  Test loss = 2.5456  \n",
      "\n",
      "Epoch: 224  Training loss = 1.9275  Test loss = 2.5455  \n",
      "\n",
      "Epoch: 225  Training loss = 1.9274  Test loss = 2.5453  \n",
      "\n",
      "Epoch: 226  Training loss = 1.9273  Test loss = 2.5452  \n",
      "\n",
      "Epoch: 227  Training loss = 1.9272  Test loss = 2.5451  \n",
      "\n",
      "Epoch: 228  Training loss = 1.9271  Test loss = 2.5449  \n",
      "\n",
      "Epoch: 229  Training loss = 1.9270  Test loss = 2.5448  \n",
      "\n",
      "Epoch: 230  Training loss = 1.9269  Test loss = 2.5446  \n",
      "\n",
      "Epoch: 231  Training loss = 1.9268  Test loss = 2.5445  \n",
      "\n",
      "Epoch: 232  Training loss = 1.9267  Test loss = 2.5443  \n",
      "\n",
      "Epoch: 233  Training loss = 1.9266  Test loss = 2.5442  \n",
      "\n",
      "Epoch: 234  Training loss = 1.9265  Test loss = 2.5441  \n",
      "\n",
      "Epoch: 235  Training loss = 1.9264  Test loss = 2.5439  \n",
      "\n",
      "Epoch: 236  Training loss = 1.9263  Test loss = 2.5438  \n",
      "\n",
      "Epoch: 237  Training loss = 1.9262  Test loss = 2.5436  \n",
      "\n",
      "Epoch: 238  Training loss = 1.9261  Test loss = 2.5435  \n",
      "\n",
      "Epoch: 239  Training loss = 1.9260  Test loss = 2.5434  \n",
      "\n",
      "Epoch: 240  Training loss = 1.9259  Test loss = 2.5432  \n",
      "\n",
      "Epoch: 241  Training loss = 1.9258  Test loss = 2.5431  \n",
      "\n",
      "Epoch: 242  Training loss = 1.9257  Test loss = 2.5429  \n",
      "\n",
      "Epoch: 243  Training loss = 1.9256  Test loss = 2.5428  \n",
      "\n",
      "Epoch: 244  Training loss = 1.9255  Test loss = 2.5427  \n",
      "\n",
      "Epoch: 245  Training loss = 1.9254  Test loss = 2.5425  \n",
      "\n",
      "Epoch: 246  Training loss = 1.9253  Test loss = 2.5424  \n",
      "\n",
      "Epoch: 247  Training loss = 1.9252  Test loss = 2.5422  \n",
      "\n",
      "Epoch: 248  Training loss = 1.9251  Test loss = 2.5421  \n",
      "\n",
      "Epoch: 249  Training loss = 1.9250  Test loss = 2.5420  \n",
      "\n",
      "Epoch: 250  Training loss = 1.9249  Test loss = 2.5418  \n",
      "\n",
      "Epoch: 251  Training loss = 1.9248  Test loss = 2.5417  \n",
      "\n",
      "Epoch: 252  Training loss = 1.9247  Test loss = 2.5415  \n",
      "\n",
      "Epoch: 253  Training loss = 1.9246  Test loss = 2.5414  \n",
      "\n",
      "Epoch: 254  Training loss = 1.9245  Test loss = 2.5413  \n",
      "\n",
      "Epoch: 255  Training loss = 1.9244  Test loss = 2.5411  \n",
      "\n",
      "Epoch: 256  Training loss = 1.9243  Test loss = 2.5410  \n",
      "\n",
      "Epoch: 257  Training loss = 1.9242  Test loss = 2.5409  \n",
      "\n",
      "Epoch: 258  Training loss = 1.9241  Test loss = 2.5407  \n",
      "\n",
      "Epoch: 259  Training loss = 1.9240  Test loss = 2.5406  \n",
      "\n",
      "Epoch: 260  Training loss = 1.9239  Test loss = 2.5404  \n",
      "\n",
      "Epoch: 261  Training loss = 1.9238  Test loss = 2.5403  \n",
      "\n",
      "Epoch: 262  Training loss = 1.9237  Test loss = 2.5402  \n",
      "\n",
      "Epoch: 263  Training loss = 1.9236  Test loss = 2.5400  \n",
      "\n",
      "Epoch: 264  Training loss = 1.9235  Test loss = 2.5399  \n",
      "\n",
      "Epoch: 265  Training loss = 1.9234  Test loss = 2.5398  \n",
      "\n",
      "Epoch: 266  Training loss = 1.9233  Test loss = 2.5396  \n",
      "\n",
      "Epoch: 267  Training loss = 1.9232  Test loss = 2.5395  \n",
      "\n",
      "Epoch: 268  Training loss = 1.9231  Test loss = 2.5394  \n",
      "\n",
      "Epoch: 269  Training loss = 1.9230  Test loss = 2.5392  \n",
      "\n",
      "Epoch: 270  Training loss = 1.9229  Test loss = 2.5391  \n",
      "\n",
      "Epoch: 271  Training loss = 1.9228  Test loss = 2.5389  \n",
      "\n",
      "Epoch: 272  Training loss = 1.9227  Test loss = 2.5388  \n",
      "\n",
      "Epoch: 273  Training loss = 1.9226  Test loss = 2.5387  \n",
      "\n",
      "Epoch: 274  Training loss = 1.9225  Test loss = 2.5385  \n",
      "\n",
      "Epoch: 275  Training loss = 1.9224  Test loss = 2.5384  \n",
      "\n",
      "Epoch: 276  Training loss = 1.9223  Test loss = 2.5383  \n",
      "\n",
      "Epoch: 277  Training loss = 1.9222  Test loss = 2.5381  \n",
      "\n",
      "Epoch: 278  Training loss = 1.9221  Test loss = 2.5380  \n",
      "\n",
      "Epoch: 279  Training loss = 1.9220  Test loss = 2.5379  \n",
      "\n",
      "Epoch: 280  Training loss = 1.9219  Test loss = 2.5377  \n",
      "\n",
      "Epoch: 281  Training loss = 1.9218  Test loss = 2.5376  \n",
      "\n",
      "Epoch: 282  Training loss = 1.9218  Test loss = 2.5375  \n",
      "\n",
      "Epoch: 283  Training loss = 1.9217  Test loss = 2.5373  \n",
      "\n",
      "Epoch: 284  Training loss = 1.9216  Test loss = 2.5372  \n",
      "\n",
      "Epoch: 285  Training loss = 1.9215  Test loss = 2.5371  \n",
      "\n",
      "Epoch: 286  Training loss = 1.9214  Test loss = 2.5369  \n",
      "\n",
      "Epoch: 287  Training loss = 1.9213  Test loss = 2.5368  \n",
      "\n",
      "Epoch: 288  Training loss = 1.9212  Test loss = 2.5367  \n",
      "\n",
      "Epoch: 289  Training loss = 1.9211  Test loss = 2.5365  \n",
      "\n",
      "Epoch: 290  Training loss = 1.9210  Test loss = 2.5364  \n",
      "\n",
      "Epoch: 291  Training loss = 1.9209  Test loss = 2.5363  \n",
      "\n",
      "Epoch: 292  Training loss = 1.9208  Test loss = 2.5361  \n",
      "\n",
      "Epoch: 293  Training loss = 1.9207  Test loss = 2.5360  \n",
      "\n",
      "Epoch: 294  Training loss = 1.9206  Test loss = 2.5359  \n",
      "\n",
      "Epoch: 295  Training loss = 1.9205  Test loss = 2.5358  \n",
      "\n",
      "Epoch: 296  Training loss = 1.9204  Test loss = 2.5356  \n",
      "\n",
      "Epoch: 297  Training loss = 1.9203  Test loss = 2.5355  \n",
      "\n",
      "Epoch: 298  Training loss = 1.9202  Test loss = 2.5354  \n",
      "\n",
      "Epoch: 299  Training loss = 1.9201  Test loss = 2.5352  \n",
      "\n",
      "Epoch: 300  Training loss = 1.9200  Test loss = 2.5351  \n",
      "\n",
      "Epoch: 301  Training loss = 1.9199  Test loss = 2.5350  \n",
      "\n",
      "Epoch: 302  Training loss = 1.9199  Test loss = 2.5348  \n",
      "\n",
      "Epoch: 303  Training loss = 1.9198  Test loss = 2.5347  \n",
      "\n",
      "Epoch: 304  Training loss = 1.9197  Test loss = 2.5346  \n",
      "\n",
      "Epoch: 305  Training loss = 1.9196  Test loss = 2.5345  \n",
      "\n",
      "Epoch: 306  Training loss = 1.9195  Test loss = 2.5343  \n",
      "\n",
      "Epoch: 307  Training loss = 1.9194  Test loss = 2.5342  \n",
      "\n",
      "Epoch: 308  Training loss = 1.9193  Test loss = 2.5341  \n",
      "\n",
      "Epoch: 309  Training loss = 1.9192  Test loss = 2.5339  \n",
      "\n",
      "Epoch: 310  Training loss = 1.9191  Test loss = 2.5338  \n",
      "\n",
      "Epoch: 311  Training loss = 1.9190  Test loss = 2.5337  \n",
      "\n",
      "Epoch: 312  Training loss = 1.9189  Test loss = 2.5336  \n",
      "\n",
      "Epoch: 313  Training loss = 1.9188  Test loss = 2.5334  \n",
      "\n",
      "Epoch: 314  Training loss = 1.9187  Test loss = 2.5333  \n",
      "\n",
      "Epoch: 315  Training loss = 1.9186  Test loss = 2.5332  \n",
      "\n",
      "Epoch: 316  Training loss = 1.9185  Test loss = 2.5330  \n",
      "\n",
      "Epoch: 317  Training loss = 1.9185  Test loss = 2.5329  \n",
      "\n",
      "Epoch: 318  Training loss = 1.9184  Test loss = 2.5328  \n",
      "\n",
      "Epoch: 319  Training loss = 1.9183  Test loss = 2.5327  \n",
      "\n",
      "Epoch: 320  Training loss = 1.9182  Test loss = 2.5325  \n",
      "\n",
      "Epoch: 321  Training loss = 1.9181  Test loss = 2.5324  \n",
      "\n",
      "Epoch: 322  Training loss = 1.9180  Test loss = 2.5323  \n",
      "\n",
      "Epoch: 323  Training loss = 1.9179  Test loss = 2.5322  \n",
      "\n",
      "Epoch: 324  Training loss = 1.9178  Test loss = 2.5320  \n",
      "\n",
      "Epoch: 325  Training loss = 1.9177  Test loss = 2.5319  \n",
      "\n",
      "Epoch: 326  Training loss = 1.9176  Test loss = 2.5318  \n",
      "\n",
      "Epoch: 327  Training loss = 1.9175  Test loss = 2.5316  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+8jwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc1cc080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xce04f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.53164704591 \n",
      "Fixed scheme MAE:  1.69231013967\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.9175  Test loss = 0.8615  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.9194  Test loss = 0.4884  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.8674  Test loss = 0.0927  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.8619  Test loss = 0.4735  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.6973  Test loss = 0.4480  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.6543  Test loss = 1.5907  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.6218  Test loss = 0.4718  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.6228  Test loss = 0.3491  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.5669  Test loss = 1.1634  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.5717  Test loss = 0.0236  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.5442  Test loss = 0.2740  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.5306  Test loss = 0.5803  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.4906  Test loss = 0.1091  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.4895  Test loss = 0.8663  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.4871  Test loss = 2.0316  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.5082  Test loss = 2.3665  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.5135  Test loss = 0.0238  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.5126  Test loss = 1.0175  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.4796  Test loss = 0.5100  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.2654  Test loss = 0.3921  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.2505  Test loss = 0.9686  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.2559  Test loss = 4.1965  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.3409  Test loss = 0.2566  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.3279  Test loss = 1.7204  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.3335  Test loss = 0.5583  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.3342  Test loss = 0.0560  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.3330  Test loss = 0.9767  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.3327  Test loss = 1.2706  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.3200  Test loss = 1.1802  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.3102  Test loss = 0.4748  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.2961  Test loss = 2.9407  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.3020  Test loss = 0.3558  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.2939  Test loss = 1.2596  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.3004  Test loss = 0.4616  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.2232  Test loss = 0.4449  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.2241  Test loss = 5.2214  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.3050  Test loss = 0.9011  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2429  Test loss = 1.9939  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.2658  Test loss = 0.4658  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2662  Test loss = 2.1030  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.2738  Test loss = 1.3244  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.2805  Test loss = 2.2406  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.3096  Test loss = 3.3730  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.3747  Test loss = 12.1759  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0454  Test loss = 5.8322  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1695  Test loss = 0.3997  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1701  Test loss = 0.7828  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1716  Test loss = 0.7613  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.1010  Test loss = 1.5787  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.1060  Test loss = 2.8933  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.1362  Test loss = 1.8682  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.1481  Test loss = 0.0899  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.1192  Test loss = 1.1590  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.1229  Test loss = 1.6809  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.1328  Test loss = 0.2532  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.1309  Test loss = 0.7348  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.1142  Test loss = 0.3778  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.1119  Test loss = 1.7311  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.1217  Test loss = 1.2592  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.1260  Test loss = 0.0482  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.1148  Test loss = 0.1386  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.1140  Test loss = 3.1894  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.1502  Test loss = 0.8757  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.1429  Test loss = 1.4076  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.1406  Test loss = 0.1620  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.1392  Test loss = 0.5988  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.1354  Test loss = 1.1610  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.1379  Test loss = 3.5887  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.1754  Test loss = 5.2742  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.2704  Test loss = 1.0235  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.2738  Test loss = 0.6843  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.2692  Test loss = 2.3395  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.2728  Test loss = 2.2319  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.2887  Test loss = 1.5450  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.2878  Test loss = 0.8324  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.2830  Test loss = 0.6743  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.2532  Test loss = 1.4419  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZ1zYzcx6xoXdzKxnXNjNzHrmL7EFSm5+IqPcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd11b668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.25088134431 \n",
      "Updating scheme MAE:  1.42432821096\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
