{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/64_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-6\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 64 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 64 \n",
      "Learning rate = 1e-06 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-06\n",
      "Fold: 1  Epoch: 1  Training loss = 3.2588  Validation loss = 3.4764  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.2585  Validation loss = 3.4760  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.2582  Validation loss = 3.4754  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.2580  Validation loss = 3.4750  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.2577  Validation loss = 3.4746  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.2575  Validation loss = 3.4741  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.2572  Validation loss = 3.4737  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.2570  Validation loss = 3.4733  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.2568  Validation loss = 3.4729  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.2566  Validation loss = 3.4725  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.2563  Validation loss = 3.4721  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.2561  Validation loss = 3.4717  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.2559  Validation loss = 3.4714  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.2556  Validation loss = 3.4708  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.2554  Validation loss = 3.4704  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.2551  Validation loss = 3.4699  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.2549  Validation loss = 3.4696  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.2547  Validation loss = 3.4692  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.2545  Validation loss = 3.4688  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.2542  Validation loss = 3.4682  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.2539  Validation loss = 3.4677  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.2537  Validation loss = 3.4673  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.2534  Validation loss = 3.4668  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.2532  Validation loss = 3.4664  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.2530  Validation loss = 3.4660  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.2527  Validation loss = 3.4655  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.2525  Validation loss = 3.4652  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.2522  Validation loss = 3.4647  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.2519  Validation loss = 3.4642  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.2517  Validation loss = 3.4639  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.2515  Validation loss = 3.4635  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.2512  Validation loss = 3.4629  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.2510  Validation loss = 3.4625  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.2508  Validation loss = 3.4622  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.2506  Validation loss = 3.4618  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.2502  Validation loss = 3.4612  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.2500  Validation loss = 3.4608  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.2498  Validation loss = 3.4605  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.2496  Validation loss = 3.4600  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.2493  Validation loss = 3.4595  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.2491  Validation loss = 3.4590  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.2488  Validation loss = 3.4587  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.2486  Validation loss = 3.4583  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.2484  Validation loss = 3.4579  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.2482  Validation loss = 3.4574  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.2479  Validation loss = 3.4570  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.2476  Validation loss = 3.4565  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.2474  Validation loss = 3.4561  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.2472  Validation loss = 3.4557  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.2470  Validation loss = 3.4553  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.2467  Validation loss = 3.4549  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.2465  Validation loss = 3.4545  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.2463  Validation loss = 3.4541  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.2461  Validation loss = 3.4538  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.2459  Validation loss = 3.4534  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.2456  Validation loss = 3.4529  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.2454  Validation loss = 3.4525  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.2451  Validation loss = 3.4520  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.2449  Validation loss = 3.4517  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.2448  Validation loss = 3.4514  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.2445  Validation loss = 3.4510  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.2443  Validation loss = 3.4505  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.2440  Validation loss = 3.4501  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.2438  Validation loss = 3.4496  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.2436  Validation loss = 3.4493  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.2433  Validation loss = 3.4488  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.2431  Validation loss = 3.4484  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.2428  Validation loss = 3.4479  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.2426  Validation loss = 3.4475  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.2424  Validation loss = 3.4471  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.2421  Validation loss = 3.4467  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.2419  Validation loss = 3.4462  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.2417  Validation loss = 3.4458  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.2414  Validation loss = 3.4453  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.2411  Validation loss = 3.4448  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.2410  Validation loss = 3.4445  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.2406  Validation loss = 3.4440  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.2405  Validation loss = 3.4437  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.2402  Validation loss = 3.4432  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.2400  Validation loss = 3.4428  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.2397  Validation loss = 3.4422  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.2394  Validation loss = 3.4418  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.2391  Validation loss = 3.4413  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.2389  Validation loss = 3.4409  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.2386  Validation loss = 3.4403  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.2384  Validation loss = 3.4399  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.2381  Validation loss = 3.4394  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.2379  Validation loss = 3.4390  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.2376  Validation loss = 3.4385  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.2374  Validation loss = 3.4382  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.2372  Validation loss = 3.4378  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.2369  Validation loss = 3.4373  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.2367  Validation loss = 3.4369  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.2364  Validation loss = 3.4364  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.2361  Validation loss = 3.4358  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.2359  Validation loss = 3.4354  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.2357  Validation loss = 3.4350  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.2355  Validation loss = 3.4346  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.2352  Validation loss = 3.4342  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.2350  Validation loss = 3.4339  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.2348  Validation loss = 3.4335  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.2345  Validation loss = 3.4329  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.2342  Validation loss = 3.4324  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.2339  Validation loss = 3.4318  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.2337  Validation loss = 3.4315  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.2335  Validation loss = 3.4311  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.2333  Validation loss = 3.4308  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.2330  Validation loss = 3.4302  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.2327  Validation loss = 3.4297  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.2324  Validation loss = 3.4292  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.2322  Validation loss = 3.4287  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.2320  Validation loss = 3.4284  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.2318  Validation loss = 3.4280  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.2315  Validation loss = 3.4275  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.2313  Validation loss = 3.4271  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.2310  Validation loss = 3.4266  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.2308  Validation loss = 3.4263  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.2305  Validation loss = 3.4257  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.2302  Validation loss = 3.4251  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.2299  Validation loss = 3.4246  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.2297  Validation loss = 3.4243  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.2295  Validation loss = 3.4238  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.2292  Validation loss = 3.4234  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.2290  Validation loss = 3.4230  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.2288  Validation loss = 3.4226  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.2286  Validation loss = 3.4222  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.2284  Validation loss = 3.4219  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.2282  Validation loss = 3.4214  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.2280  Validation loss = 3.4211  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.2278  Validation loss = 3.4208  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.2276  Validation loss = 3.4204  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.2274  Validation loss = 3.4200  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.2271  Validation loss = 3.4195  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.2270  Validation loss = 3.4192  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.2267  Validation loss = 3.4188  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.2264  Validation loss = 3.4183  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.2262  Validation loss = 3.4179  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.2260  Validation loss = 3.4174  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.2258  Validation loss = 3.4171  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.2255  Validation loss = 3.4166  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.2253  Validation loss = 3.4162  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.2251  Validation loss = 3.4158  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.2248  Validation loss = 3.4153  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.2246  Validation loss = 3.4149  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.2244  Validation loss = 3.4145  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.2241  Validation loss = 3.4141  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.2239  Validation loss = 3.4137  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.2236  Validation loss = 3.4132  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.2234  Validation loss = 3.4128  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.2231  Validation loss = 3.4123  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.2230  Validation loss = 3.4120  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.2226  Validation loss = 3.4114  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.2224  Validation loss = 3.4109  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.2221  Validation loss = 3.4105  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.2219  Validation loss = 3.4100  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.2216  Validation loss = 3.4095  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.2214  Validation loss = 3.4091  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.2212  Validation loss = 3.4088  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.2210  Validation loss = 3.4083  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.2208  Validation loss = 3.4080  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.2206  Validation loss = 3.4076  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.2204  Validation loss = 3.4073  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.2201  Validation loss = 3.4068  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.2198  Validation loss = 3.4063  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.2196  Validation loss = 3.4059  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.2193  Validation loss = 3.4054  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.2191  Validation loss = 3.4050  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.2188  Validation loss = 3.4045  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.2186  Validation loss = 3.4040  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.2183  Validation loss = 3.4034  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.2180  Validation loss = 3.4029  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.2177  Validation loss = 3.4025  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.2175  Validation loss = 3.4020  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.2173  Validation loss = 3.4016  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.2170  Validation loss = 3.4012  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.2169  Validation loss = 3.4009  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.2167  Validation loss = 3.4005  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.2164  Validation loss = 3.4000  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.2161  Validation loss = 3.3995  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.2159  Validation loss = 3.3990  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.2157  Validation loss = 3.3987  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.2155  Validation loss = 3.3983  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.2153  Validation loss = 3.3979  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.2151  Validation loss = 3.3976  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.2149  Validation loss = 3.3972  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.2147  Validation loss = 3.3968  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.2145  Validation loss = 3.3965  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.2143  Validation loss = 3.3961  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.2140  Validation loss = 3.3956  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.2139  Validation loss = 3.3954  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.2137  Validation loss = 3.3950  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.2135  Validation loss = 3.3947  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.2133  Validation loss = 3.3943  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.2131  Validation loss = 3.3939  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.2129  Validation loss = 3.3936  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.2127  Validation loss = 3.3931  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.2125  Validation loss = 3.3928  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.2122  Validation loss = 3.3923  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.2120  Validation loss = 3.3920  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.2118  Validation loss = 3.3915  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.2116  Validation loss = 3.3911  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.2114  Validation loss = 3.3909  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.2112  Validation loss = 3.3905  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.2110  Validation loss = 3.3901  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.2109  Validation loss = 3.3899  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.2107  Validation loss = 3.3895  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.2104  Validation loss = 3.3891  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.2102  Validation loss = 3.3886  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.2099  Validation loss = 3.3881  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.2098  Validation loss = 3.3878  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.2095  Validation loss = 3.3874  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.2093  Validation loss = 3.3869  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.2091  Validation loss = 3.3865  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.2089  Validation loss = 3.3862  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.2086  Validation loss = 3.3858  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.2084  Validation loss = 3.3854  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.2082  Validation loss = 3.3850  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.2079  Validation loss = 3.3844  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.2076  Validation loss = 3.3839  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.2074  Validation loss = 3.3835  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.2072  Validation loss = 3.3831  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.2070  Validation loss = 3.3827  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.2067  Validation loss = 3.3822  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.2065  Validation loss = 3.3818  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.2063  Validation loss = 3.3815  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.2061  Validation loss = 3.3810  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.2059  Validation loss = 3.3807  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.2056  Validation loss = 3.3802  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.2054  Validation loss = 3.3797  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.2051  Validation loss = 3.3792  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.2048  Validation loss = 3.3787  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.2047  Validation loss = 3.3784  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.2044  Validation loss = 3.3779  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.2042  Validation loss = 3.3775  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.2040  Validation loss = 3.3772  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.2037  Validation loss = 3.3767  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.2035  Validation loss = 3.3763  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.2033  Validation loss = 3.3759  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.2031  Validation loss = 3.3755  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.2028  Validation loss = 3.3750  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.2026  Validation loss = 3.3746  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.2023  Validation loss = 3.3741  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.2021  Validation loss = 3.3737  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.2019  Validation loss = 3.3733  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.2017  Validation loss = 3.3730  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.2015  Validation loss = 3.3726  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.2013  Validation loss = 3.3722  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.2011  Validation loss = 3.3718  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.2008  Validation loss = 3.3712  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.2006  Validation loss = 3.3709  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.2004  Validation loss = 3.3705  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.2001  Validation loss = 3.3700  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.2000  Validation loss = 3.3697  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.1998  Validation loss = 3.3693  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.1996  Validation loss = 3.3690  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.1993  Validation loss = 3.3685  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.1992  Validation loss = 3.3683  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.1990  Validation loss = 3.3679  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.1988  Validation loss = 3.3676  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.1986  Validation loss = 3.3671  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.1983  Validation loss = 3.3666  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.1981  Validation loss = 3.3662  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.1979  Validation loss = 3.3658  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.1977  Validation loss = 3.3654  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.1974  Validation loss = 3.3649  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.1971  Validation loss = 3.3644  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.1969  Validation loss = 3.3641  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.1967  Validation loss = 3.3637  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.1965  Validation loss = 3.3633  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.1963  Validation loss = 3.3628  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.1960  Validation loss = 3.3624  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.1959  Validation loss = 3.3621  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.1957  Validation loss = 3.3618  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.1955  Validation loss = 3.3613  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.1952  Validation loss = 3.3609  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.1950  Validation loss = 3.3605  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.1948  Validation loss = 3.3600  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.1945  Validation loss = 3.3596  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.1943  Validation loss = 3.3591  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.1941  Validation loss = 3.3587  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.1939  Validation loss = 3.3584  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.1938  Validation loss = 3.3582  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.1935  Validation loss = 3.3577  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.1931  Validation loss = 3.3570  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.1930  Validation loss = 3.3567  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.1928  Validation loss = 3.3564  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.1927  Validation loss = 3.3561  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.1925  Validation loss = 3.3557  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.1923  Validation loss = 3.3554  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.1920  Validation loss = 3.3549  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.1918  Validation loss = 3.3545  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.1916  Validation loss = 3.3542  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.1914  Validation loss = 3.3537  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.1911  Validation loss = 3.3533  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.1909  Validation loss = 3.3529  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.1906  Validation loss = 3.3523  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.1904  Validation loss = 3.3519  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.1901  Validation loss = 3.3513  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.1899  Validation loss = 3.3510  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.1898  Validation loss = 3.3507  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.1896  Validation loss = 3.3503  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.1894  Validation loss = 3.3500  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.1891  Validation loss = 3.3495  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.1890  Validation loss = 3.3492  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.1887  Validation loss = 3.3488  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.1885  Validation loss = 3.3483  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.1883  Validation loss = 3.3479  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.1880  Validation loss = 3.3475  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.1877  Validation loss = 3.3469  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.1875  Validation loss = 3.3464  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.1873  Validation loss = 3.3461  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.1871  Validation loss = 3.3457  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.1870  Validation loss = 3.3454  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.1868  Validation loss = 3.3451  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.1866  Validation loss = 3.3448  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.1863  Validation loss = 3.3443  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.1861  Validation loss = 3.3439  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.1859  Validation loss = 3.3436  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.1857  Validation loss = 3.3432  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.1855  Validation loss = 3.3427  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.1853  Validation loss = 3.3423  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.1851  Validation loss = 3.3420  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.1850  Validation loss = 3.3418  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.1848  Validation loss = 3.3415  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.1846  Validation loss = 3.3410  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.1844  Validation loss = 3.3407  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.1842  Validation loss = 3.3403  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.1840  Validation loss = 3.3399  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.1838  Validation loss = 3.3395  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.1836  Validation loss = 3.3392  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.1834  Validation loss = 3.3388  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.1832  Validation loss = 3.3384  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.1829  Validation loss = 3.3379  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.1827  Validation loss = 3.3375  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.1825  Validation loss = 3.3371  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.1823  Validation loss = 3.3367  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.1821  Validation loss = 3.3363  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.1819  Validation loss = 3.3359  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 3.1816  Validation loss = 3.3355  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 3.1814  Validation loss = 3.3350  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 3.1811  Validation loss = 3.3345  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 3.1810  Validation loss = 3.3343  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 3.1807  Validation loss = 3.3337  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 3.1805  Validation loss = 3.3334  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 3.1803  Validation loss = 3.3330  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 3.1801  Validation loss = 3.3326  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 3.1799  Validation loss = 3.3323  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 3.1798  Validation loss = 3.3320  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 3.1795  Validation loss = 3.3315  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 3.1793  Validation loss = 3.3311  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 3.1792  Validation loss = 3.3308  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 3.1790  Validation loss = 3.3306  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 3.1789  Validation loss = 3.3303  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 3.1786  Validation loss = 3.3298  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 3.1784  Validation loss = 3.3294  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 3.1782  Validation loss = 3.3291  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 3.1781  Validation loss = 3.3287  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 3.1779  Validation loss = 3.3284  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 3.1777  Validation loss = 3.3280  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 3.1775  Validation loss = 3.3277  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 3.1773  Validation loss = 3.3274  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 3.1770  Validation loss = 3.3268  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 3.1768  Validation loss = 3.3264  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 3.1767  Validation loss = 3.3261  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 3.1765  Validation loss = 3.3258  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 3.1763  Validation loss = 3.3254  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 3.1761  Validation loss = 3.3250  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 3.1759  Validation loss = 3.3247  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 3.1758  Validation loss = 3.3244  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 3.1755  Validation loss = 3.3239  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 3.1752  Validation loss = 3.3234  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 3.1750  Validation loss = 3.3229  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 3.1748  Validation loss = 3.3225  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 3.1745  Validation loss = 3.3220  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 3.1742  Validation loss = 3.3215  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 3.1740  Validation loss = 3.3211  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 3.1738  Validation loss = 3.3207  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 3.1736  Validation loss = 3.3203  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 3.1734  Validation loss = 3.3199  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 3.1731  Validation loss = 3.3194  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 3.1729  Validation loss = 3.3190  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 3.1727  Validation loss = 3.3186  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 3.1726  Validation loss = 3.3183  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 3.1723  Validation loss = 3.3178  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 3.1721  Validation loss = 3.3175  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 3.1719  Validation loss = 3.3171  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 3.1717  Validation loss = 3.3167  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 3.1715  Validation loss = 3.3162  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 3.1712  Validation loss = 3.3157  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 3.1710  Validation loss = 3.3153  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 3.1708  Validation loss = 3.3150  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 3.1706  Validation loss = 3.3146  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 3.1705  Validation loss = 3.3143  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 3.1702  Validation loss = 3.3139  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 3.1701  Validation loss = 3.3136  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 3.1699  Validation loss = 3.3131  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 3.1696  Validation loss = 3.3127  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 3.1693  Validation loss = 3.3121  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 3.1692  Validation loss = 3.3119  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 3.1690  Validation loss = 3.3115  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 3.1689  Validation loss = 3.3113  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 3.1687  Validation loss = 3.3109  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 3.1684  Validation loss = 3.3104  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 3.1683  Validation loss = 3.3102  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 3.1681  Validation loss = 3.3098  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 3.1679  Validation loss = 3.3095  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 3.1677  Validation loss = 3.3091  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 3.1675  Validation loss = 3.3087  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 3.1672  Validation loss = 3.3081  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 3.1670  Validation loss = 3.3076  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 3.1668  Validation loss = 3.3073  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 3.1666  Validation loss = 3.3069  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 3.1664  Validation loss = 3.3065  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 3.1662  Validation loss = 3.3062  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 3.1661  Validation loss = 3.3059  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 3.1659  Validation loss = 3.3056  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 3.1657  Validation loss = 3.3052  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 3.1654  Validation loss = 3.3047  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 3.1652  Validation loss = 3.3043  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 3.1651  Validation loss = 3.3040  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 3.1649  Validation loss = 3.3036  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 3.1647  Validation loss = 3.3033  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 3.1645  Validation loss = 3.3030  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 3.1643  Validation loss = 3.3025  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 3.1641  Validation loss = 3.3020  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 3.1638  Validation loss = 3.3017  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 3.1636  Validation loss = 3.3013  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 3.1634  Validation loss = 3.3007  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 3.1631  Validation loss = 3.3001  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 3.1628  Validation loss = 3.2997  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 3.1626  Validation loss = 3.2992  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 3.1623  Validation loss = 3.2987  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 3.1621  Validation loss = 3.2983  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 3.1618  Validation loss = 3.2978  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 3.1616  Validation loss = 3.2973  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 3.1613  Validation loss = 3.2968  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 3.1612  Validation loss = 3.2965  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 3.1610  Validation loss = 3.2961  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 3.1607  Validation loss = 3.2957  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 3.1605  Validation loss = 3.2951  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 3.1603  Validation loss = 3.2948  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 3.1600  Validation loss = 3.2943  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 3.1598  Validation loss = 3.2940  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 3.1596  Validation loss = 3.2936  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 3.1595  Validation loss = 3.2932  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 3.1592  Validation loss = 3.2928  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 3.1591  Validation loss = 3.2925  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 3.1589  Validation loss = 3.2922  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 3.1587  Validation loss = 3.2918  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 3.1585  Validation loss = 3.2914  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 3.1583  Validation loss = 3.2910  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 3.1581  Validation loss = 3.2906  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 3.1579  Validation loss = 3.2902  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 3.1577  Validation loss = 3.2898  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 3.1575  Validation loss = 3.2895  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 3.1573  Validation loss = 3.2891  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 3.1570  Validation loss = 3.2886  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 3.1568  Validation loss = 3.2881  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 3.1566  Validation loss = 3.2877  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 3.1563  Validation loss = 3.2872  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 3.1560  Validation loss = 3.2866  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 3.1557  Validation loss = 3.2861  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 3.1555  Validation loss = 3.2857  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 3.1553  Validation loss = 3.2852  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 3.1551  Validation loss = 3.2850  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 3.1549  Validation loss = 3.2845  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 3.1547  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 3.1545  Validation loss = 3.2837  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 3.1543  Validation loss = 3.2834  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 3.1541  Validation loss = 3.2830  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 3.1539  Validation loss = 3.2826  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 3.1537  Validation loss = 3.2822  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 3.1535  Validation loss = 3.2818  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 3.1533  Validation loss = 3.2814  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 3.1530  Validation loss = 3.2809  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 3.1528  Validation loss = 3.2805  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 3.1527  Validation loss = 3.2802  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 3.1525  Validation loss = 3.2798  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 3.1523  Validation loss = 3.2795  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 3.1521  Validation loss = 3.2792  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 3.1520  Validation loss = 3.2789  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 3.1517  Validation loss = 3.2784  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 3.1515  Validation loss = 3.2779  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 3.1513  Validation loss = 3.2776  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 3.1511  Validation loss = 3.2773  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 3.1510  Validation loss = 3.2770  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 3.1508  Validation loss = 3.2765  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 3.1506  Validation loss = 3.2762  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 3.1503  Validation loss = 3.2757  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 3.1501  Validation loss = 3.2752  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 3.1499  Validation loss = 3.2749  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 3.1498  Validation loss = 3.2746  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 3.1496  Validation loss = 3.2743  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 3.1495  Validation loss = 3.2740  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 3.1492  Validation loss = 3.2736  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 3.1491  Validation loss = 3.2732  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 3.1489  Validation loss = 3.2729  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 3.1486  Validation loss = 3.2724  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 3.1484  Validation loss = 3.2719  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 3.1481  Validation loss = 3.2715  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 3.0927  Validation loss = 2.9740  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 3.0924  Validation loss = 2.9737  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 3.0923  Validation loss = 2.9734  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 3.0921  Validation loss = 2.9731  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 3.0919  Validation loss = 2.9728  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 3.0916  Validation loss = 2.9724  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 3.0914  Validation loss = 2.9720  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 3.0911  Validation loss = 2.9717  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 3.0910  Validation loss = 2.9714  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 3.0908  Validation loss = 2.9711  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 3.0906  Validation loss = 2.9707  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 3.0902  Validation loss = 2.9702  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 3.0899  Validation loss = 2.9698  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 3.0897  Validation loss = 2.9694  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 3.0895  Validation loss = 2.9691  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 3.0892  Validation loss = 2.9688  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 3.0890  Validation loss = 2.9685  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 3.0888  Validation loss = 2.9682  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 3.0886  Validation loss = 2.9679  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 3.0884  Validation loss = 2.9675  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 3.0881  Validation loss = 2.9670  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 3.0879  Validation loss = 2.9667  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 3.0876  Validation loss = 2.9664  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 3.0875  Validation loss = 2.9661  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 3.0873  Validation loss = 2.9658  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 3.0870  Validation loss = 2.9654  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 3.0868  Validation loss = 2.9651  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 3.0866  Validation loss = 2.9648  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 3.0864  Validation loss = 2.9644  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 3.0862  Validation loss = 2.9641  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 3.0860  Validation loss = 2.9638  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 3.0858  Validation loss = 2.9636  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 3.0856  Validation loss = 2.9632  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 3.0853  Validation loss = 2.9628  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 3.0852  Validation loss = 2.9625  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 3.0849  Validation loss = 2.9622  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 3.0847  Validation loss = 2.9619  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 3.0845  Validation loss = 2.9615  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 3.0843  Validation loss = 2.9612  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 3.0840  Validation loss = 2.9608  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 3.0838  Validation loss = 2.9605  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 3.0836  Validation loss = 2.9602  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 3.0834  Validation loss = 2.9598  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 3.0832  Validation loss = 2.9595  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 3.0830  Validation loss = 2.9593  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 3.0828  Validation loss = 2.9589  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 3.0825  Validation loss = 2.9586  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 3.0823  Validation loss = 2.9583  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 3.0821  Validation loss = 2.9579  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 3.0819  Validation loss = 2.9576  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 3.0817  Validation loss = 2.9573  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 3.0815  Validation loss = 2.9569  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 3.0812  Validation loss = 2.9566  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 3.0810  Validation loss = 2.9562  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 3.0807  Validation loss = 2.9559  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 3.0805  Validation loss = 2.9554  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 3.0803  Validation loss = 2.9551  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 3.0801  Validation loss = 2.9548  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 3.0799  Validation loss = 2.9545  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 3.0797  Validation loss = 2.9542  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 3.0795  Validation loss = 2.9539  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 3.0793  Validation loss = 2.9536  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 3.0791  Validation loss = 2.9533  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 3.0789  Validation loss = 2.9530  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 3.0787  Validation loss = 2.9527  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 3.0784  Validation loss = 2.9522  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 3.0782  Validation loss = 2.9519  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 3.0780  Validation loss = 2.9515  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 3.0777  Validation loss = 2.9511  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 3.0774  Validation loss = 2.9507  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 3.0772  Validation loss = 2.9503  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 3.0770  Validation loss = 2.9501  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 3.0768  Validation loss = 2.9498  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 3.0766  Validation loss = 2.9495  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 3.0764  Validation loss = 2.9491  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 3.0762  Validation loss = 2.9488  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 3.0759  Validation loss = 2.9485  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 3.0757  Validation loss = 2.9481  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 3.0756  Validation loss = 2.9479  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 3.0753  Validation loss = 2.9475  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 3.0750  Validation loss = 2.9470  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 3.0748  Validation loss = 2.9467  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 3.0746  Validation loss = 2.9464  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 3.0743  Validation loss = 2.9459  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 3.0741  Validation loss = 2.9456  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 3.0739  Validation loss = 2.9452  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 3.0736  Validation loss = 2.9448  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 3.0733  Validation loss = 2.9444  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 3.0730  Validation loss = 2.9439  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 3.0727  Validation loss = 2.9435  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 3.0725  Validation loss = 2.9433  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 3.0723  Validation loss = 2.9429  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 3.0721  Validation loss = 2.9426  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 3.0720  Validation loss = 2.9423  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 3.0718  Validation loss = 2.9420  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 3.0715  Validation loss = 2.9416  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 3.0713  Validation loss = 2.9413  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 3.0711  Validation loss = 2.9410  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 3.0709  Validation loss = 2.9407  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 3.0707  Validation loss = 2.9403  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 3.0705  Validation loss = 2.9400  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 3.0703  Validation loss = 2.9397  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 3.0701  Validation loss = 2.9393  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 3.0698  Validation loss = 2.9390  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 3.0695  Validation loss = 2.9385  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 3.0694  Validation loss = 2.9382  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 3.0691  Validation loss = 2.9378  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 3.0689  Validation loss = 2.9375  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 3.0687  Validation loss = 2.9372  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 3.0685  Validation loss = 2.9369  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 3.0682  Validation loss = 2.9365  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 3.0680  Validation loss = 2.9362  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 3.0678  Validation loss = 2.9358  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 3.0676  Validation loss = 2.9355  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 3.0674  Validation loss = 2.9352  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 3.0671  Validation loss = 2.9348  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 3.0670  Validation loss = 2.9345  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 3.0667  Validation loss = 2.9341  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 3.0665  Validation loss = 2.9338  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 3.0663  Validation loss = 2.9334  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 3.0661  Validation loss = 2.9332  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 3.0660  Validation loss = 2.9330  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 3.0658  Validation loss = 2.9327  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 3.0656  Validation loss = 2.9324  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 3.0655  Validation loss = 2.9321  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 3.0653  Validation loss = 2.9318  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 3.0650  Validation loss = 2.9314  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 3.0647  Validation loss = 2.9310  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 3.0646  Validation loss = 2.9307  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 3.0643  Validation loss = 2.9304  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 3.0640  Validation loss = 2.9300  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 3.0638  Validation loss = 2.9296  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 3.0635  Validation loss = 2.9292  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 3.0632  Validation loss = 2.9287  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 3.0630  Validation loss = 2.9284  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 3.0628  Validation loss = 2.9281  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 3.0626  Validation loss = 2.9277  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 3.0623  Validation loss = 2.9273  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 3.0622  Validation loss = 2.9270  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 3.0620  Validation loss = 2.9267  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 3.0618  Validation loss = 2.9264  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 3.0615  Validation loss = 2.9260  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 3.0614  Validation loss = 2.9258  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 3.0612  Validation loss = 2.9254  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 3.0610  Validation loss = 2.9252  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 3.0608  Validation loss = 2.9250  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 3.0606  Validation loss = 2.9245  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 3.0603  Validation loss = 2.9241  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 3.0601  Validation loss = 2.9238  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 3.0599  Validation loss = 2.9236  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 3.0597  Validation loss = 2.9231  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 3.0594  Validation loss = 2.9228  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 3.0592  Validation loss = 2.9224  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 3.0589  Validation loss = 2.9219  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 3.0587  Validation loss = 2.9215  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 3.0585  Validation loss = 2.9212  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 3.0583  Validation loss = 2.9210  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 3.0581  Validation loss = 2.9207  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 3.0579  Validation loss = 2.9204  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 3.0577  Validation loss = 2.9201  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 3.0576  Validation loss = 2.9199  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 3.0574  Validation loss = 2.9195  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 3.0571  Validation loss = 2.9192  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 3.0569  Validation loss = 2.9188  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 3.0568  Validation loss = 2.9186  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 3.0566  Validation loss = 2.9183  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 3.0564  Validation loss = 2.9180  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 3.0562  Validation loss = 2.9176  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 3.0560  Validation loss = 2.9173  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 3.0557  Validation loss = 2.9169  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 3.0555  Validation loss = 2.9166  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 3.0553  Validation loss = 2.9162  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 3.0551  Validation loss = 2.9159  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 3.0548  Validation loss = 2.9156  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 3.0547  Validation loss = 2.9153  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 3.0545  Validation loss = 2.9150  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 3.0543  Validation loss = 2.9148  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 3.0542  Validation loss = 2.9145  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 3.0539  Validation loss = 2.9141  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 3.0537  Validation loss = 2.9138  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 3.0535  Validation loss = 2.9135  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 3.0532  Validation loss = 2.9131  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 3.0531  Validation loss = 2.9128  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 3.0529  Validation loss = 2.9125  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 3.0527  Validation loss = 2.9123  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 3.0525  Validation loss = 2.9118  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 3.0522  Validation loss = 2.9115  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 3.0520  Validation loss = 2.9112  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 3.0518  Validation loss = 2.9108  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 3.0516  Validation loss = 2.9105  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 3.0514  Validation loss = 2.9101  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 3.0511  Validation loss = 2.9098  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 3.0510  Validation loss = 2.9095  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 3.0507  Validation loss = 2.9091  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 3.0505  Validation loss = 2.9087  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 3.0503  Validation loss = 2.9084  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 3.0501  Validation loss = 2.9081  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 3.0497  Validation loss = 2.9076  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 3.0495  Validation loss = 2.9073  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 3.0493  Validation loss = 2.9070  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 3.0491  Validation loss = 2.9066  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 3.0488  Validation loss = 2.9062  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 3.0486  Validation loss = 2.9058  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 3.0484  Validation loss = 2.9055  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 3.0482  Validation loss = 2.9052  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 3.0480  Validation loss = 2.9049  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 3.0478  Validation loss = 2.9047  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 3.0475  Validation loss = 2.9042  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 3.0473  Validation loss = 2.9038  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 3.0471  Validation loss = 2.9035  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 3.0468  Validation loss = 2.9031  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 3.0466  Validation loss = 2.9028  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 3.0464  Validation loss = 2.9024  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 3.0461  Validation loss = 2.9020  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 3.0458  Validation loss = 2.9015  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 3.0456  Validation loss = 2.9012  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 3.0454  Validation loss = 2.9009  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 3.0452  Validation loss = 2.9006  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 3.0450  Validation loss = 2.9003  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 3.0448  Validation loss = 2.9000  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 3.0446  Validation loss = 2.8997  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 3.0444  Validation loss = 2.8993  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 3.0442  Validation loss = 2.8990  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 3.0440  Validation loss = 2.8986  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 3.0438  Validation loss = 2.8984  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 3.0436  Validation loss = 2.8981  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 3.0434  Validation loss = 2.8978  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 3.0432  Validation loss = 2.8975  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 3.0431  Validation loss = 2.8973  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 3.0428  Validation loss = 2.8969  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 3.0426  Validation loss = 2.8966  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 3.0425  Validation loss = 2.8963  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 3.0423  Validation loss = 2.8961  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 3.0421  Validation loss = 2.8957  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 3.0418  Validation loss = 2.8953  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 3.0416  Validation loss = 2.8949  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 3.0414  Validation loss = 2.8946  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 3.0411  Validation loss = 2.8943  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 3.0409  Validation loss = 2.8940  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 3.0408  Validation loss = 2.8937  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 3.0405  Validation loss = 2.8933  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 3.0403  Validation loss = 2.8930  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 3.0401  Validation loss = 2.8927  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 3.0399  Validation loss = 2.8924  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 3.0397  Validation loss = 2.8920  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 3.0395  Validation loss = 2.8918  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 3.0393  Validation loss = 2.8915  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 3.0392  Validation loss = 2.8912  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 3.0390  Validation loss = 2.8909  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 3.0388  Validation loss = 2.8907  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 3.0387  Validation loss = 2.8904  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 3.0385  Validation loss = 2.8902  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 3.0383  Validation loss = 2.8899  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 3.0381  Validation loss = 2.8896  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 3.0379  Validation loss = 2.8893  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 3.0378  Validation loss = 2.8891  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 3.0376  Validation loss = 2.8888  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 3.0374  Validation loss = 2.8884  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 3.0371  Validation loss = 2.8880  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 3.0369  Validation loss = 2.8878  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 3.0367  Validation loss = 2.8874  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 3.0364  Validation loss = 2.8870  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 3.0362  Validation loss = 2.8866  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 3.0360  Validation loss = 2.8863  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 3.0358  Validation loss = 2.8860  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 3.0356  Validation loss = 2.8857  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 3.0355  Validation loss = 2.8855  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 3.0354  Validation loss = 2.8853  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 3.0352  Validation loss = 2.8850  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 3.0350  Validation loss = 2.8847  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 3.0348  Validation loss = 2.8844  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 3.0346  Validation loss = 2.8841  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 3.0344  Validation loss = 2.8837  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 3.0342  Validation loss = 2.8835  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 3.0340  Validation loss = 2.8831  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 3.0338  Validation loss = 2.8828  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 3.0336  Validation loss = 2.8826  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 3.0334  Validation loss = 2.8823  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 3.0332  Validation loss = 2.8820  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 3.0331  Validation loss = 2.8817  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 3.0329  Validation loss = 2.8814  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 3.0327  Validation loss = 2.8811  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 3.0325  Validation loss = 2.8808  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 3.0323  Validation loss = 2.8805  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 3.0321  Validation loss = 2.8803  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 3.0320  Validation loss = 2.8800  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 3.0318  Validation loss = 2.8797  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 3.0316  Validation loss = 2.8794  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 3.0314  Validation loss = 2.8791  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 3.0312  Validation loss = 2.8787  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 3.0310  Validation loss = 2.8785  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 3.0308  Validation loss = 2.8782  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 3.0306  Validation loss = 2.8779  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 3.0304  Validation loss = 2.8776  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 3.0303  Validation loss = 2.8774  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 3.0301  Validation loss = 2.8771  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 3.0299  Validation loss = 2.8768  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 3.0297  Validation loss = 2.8764  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 3.0294  Validation loss = 2.8760  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 3.0292  Validation loss = 2.8757  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 3.0289  Validation loss = 2.8753  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 3.0287  Validation loss = 2.8749  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 3.0285  Validation loss = 2.8746  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 3.0283  Validation loss = 2.8743  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 3.0281  Validation loss = 2.8740  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 3.0280  Validation loss = 2.8737  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 3.0278  Validation loss = 2.8735  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 3.0276  Validation loss = 2.8732  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 3.0275  Validation loss = 2.8729  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 3.0273  Validation loss = 2.8727  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 3.0272  Validation loss = 2.8724  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 3.0269  Validation loss = 2.8720  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 3.0267  Validation loss = 2.8717  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 3.0265  Validation loss = 2.8715  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 3.0264  Validation loss = 2.8712  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 3.0262  Validation loss = 2.8709  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 3.0259  Validation loss = 2.8705  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 3.0258  Validation loss = 2.8702  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 3.0256  Validation loss = 2.8700  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 3.0254  Validation loss = 2.8697  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 3.0252  Validation loss = 2.8694  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 3.0250  Validation loss = 2.8691  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 3.0248  Validation loss = 2.8687  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 3.0246  Validation loss = 2.8684  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 3.0244  Validation loss = 2.8682  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 3.0243  Validation loss = 2.8679  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 3.0241  Validation loss = 2.8676  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 3.0239  Validation loss = 2.8674  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 3.0237  Validation loss = 2.8671  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 3.0236  Validation loss = 2.8669  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 3.0234  Validation loss = 2.8665  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 3.0232  Validation loss = 2.8662  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 3.0230  Validation loss = 2.8659  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 3.0228  Validation loss = 2.8656  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 3.0226  Validation loss = 2.8653  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 3.0224  Validation loss = 2.8650  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 3.0222  Validation loss = 2.8648  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 3.0220  Validation loss = 2.8643  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 3.0218  Validation loss = 2.8640  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 3.0216  Validation loss = 2.8638  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 3.0215  Validation loss = 2.8635  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 3.0212  Validation loss = 2.8631  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 3.0210  Validation loss = 2.8628  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 3.0208  Validation loss = 2.8625  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 3.0206  Validation loss = 2.8622  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 3.0203  Validation loss = 2.8618  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 3.0201  Validation loss = 2.8615  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 3.0199  Validation loss = 2.8611  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 3.0197  Validation loss = 2.8607  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 3.0195  Validation loss = 2.8604  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 3.0193  Validation loss = 2.8601  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 3.0192  Validation loss = 2.8599  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 3.0190  Validation loss = 2.8596  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 3.0188  Validation loss = 2.8594  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 3.0186  Validation loss = 2.8590  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 3.0184  Validation loss = 2.8587  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 3.0182  Validation loss = 2.8583  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 3.0180  Validation loss = 2.8581  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 3.0178  Validation loss = 2.8578  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 3.0176  Validation loss = 2.8575  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 3.0175  Validation loss = 2.8573  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 3.0173  Validation loss = 2.8570  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 3.0171  Validation loss = 2.8567  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 3.0169  Validation loss = 2.8563  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 3.0167  Validation loss = 2.8561  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 3.0166  Validation loss = 2.8558  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 3.0164  Validation loss = 2.8556  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 3.0162  Validation loss = 2.8553  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 3.0159  Validation loss = 2.8548  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 3.0157  Validation loss = 2.8545  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 3.0155  Validation loss = 2.8542  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 3.0154  Validation loss = 2.8539  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 3.0152  Validation loss = 2.8536  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 3.0149  Validation loss = 2.8532  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 3.0147  Validation loss = 2.8529  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 3.0145  Validation loss = 2.8526  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 3.0143  Validation loss = 2.8522  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 3.0141  Validation loss = 2.8519  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 3.0139  Validation loss = 2.8515  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 3.0137  Validation loss = 2.8512  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 3.0134  Validation loss = 2.8508  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 3.0133  Validation loss = 2.8506  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 3.0131  Validation loss = 2.8502  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 3.0128  Validation loss = 2.8498  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 3.0127  Validation loss = 2.8496  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 3.0125  Validation loss = 2.8493  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 3.0123  Validation loss = 2.8490  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 3.0121  Validation loss = 2.8486  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 3.0119  Validation loss = 2.8483  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 3.0117  Validation loss = 2.8480  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 3.0114  Validation loss = 2.8476  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 3.0112  Validation loss = 2.8473  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 3.0110  Validation loss = 2.8470  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 3.0109  Validation loss = 2.8467  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 3.0106  Validation loss = 2.8464  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 3.0105  Validation loss = 2.8461  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 3.0103  Validation loss = 2.8458  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 3.0101  Validation loss = 2.8455  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 3.0100  Validation loss = 2.8453  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 3.0098  Validation loss = 2.8450  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 3.0097  Validation loss = 2.8449  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 3.0095  Validation loss = 2.8446  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 3.0094  Validation loss = 2.8443  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 3.0091  Validation loss = 2.8439  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 3.0089  Validation loss = 2.8436  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 3.0087  Validation loss = 2.8433  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 3.0085  Validation loss = 2.8430  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 3.0083  Validation loss = 2.8426  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 3.0081  Validation loss = 2.8424  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 3.0079  Validation loss = 2.8420  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 3.0077  Validation loss = 2.8418  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 3.0075  Validation loss = 2.8415  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 3.0073  Validation loss = 2.8410  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 3.0072  Validation loss = 2.8409  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 3.0070  Validation loss = 2.8406  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 3.0069  Validation loss = 2.8404  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 3.0067  Validation loss = 2.8401  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 3.0066  Validation loss = 2.8399  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 3.0064  Validation loss = 2.8396  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 3.0062  Validation loss = 2.8393  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 3.0060  Validation loss = 2.8390  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 3.0058  Validation loss = 2.8387  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 3.0057  Validation loss = 2.8385  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 3.0055  Validation loss = 2.8382  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 3.0053  Validation loss = 2.8378  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 3.0051  Validation loss = 2.8376  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 3.0050  Validation loss = 2.8373  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 3.0048  Validation loss = 2.8370  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 3.0046  Validation loss = 2.8368  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 3.0044  Validation loss = 2.8365  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 3.0043  Validation loss = 2.8362  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 3.0041  Validation loss = 2.8360  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 3.0040  Validation loss = 2.8357  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 3.0037  Validation loss = 2.8354  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 3.0035  Validation loss = 2.8350  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 3.0032  Validation loss = 2.8346  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 3.0031  Validation loss = 2.8343  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 3.0029  Validation loss = 2.8341  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 3.0027  Validation loss = 2.8337  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 3.0026  Validation loss = 2.8335  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 3.0024  Validation loss = 2.8333  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 3.0023  Validation loss = 2.8330  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 3.0021  Validation loss = 2.8328  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 3.0019  Validation loss = 2.8324  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 3.0017  Validation loss = 2.8321  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 3.0015  Validation loss = 2.8319  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 3.0014  Validation loss = 2.8316  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 3.0012  Validation loss = 2.8314  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 3.0011  Validation loss = 2.8312  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 3.0009  Validation loss = 2.8309  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 3.0007  Validation loss = 2.8306  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 3.0005  Validation loss = 2.8302  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 3.0003  Validation loss = 2.8300  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 3.0001  Validation loss = 2.8296  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.9998  Validation loss = 2.8291  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.9997  Validation loss = 2.8289  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.9995  Validation loss = 2.8287  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.9994  Validation loss = 2.8284  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.9992  Validation loss = 2.8280  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.9989  Validation loss = 2.8276  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.9987  Validation loss = 2.8273  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.9985  Validation loss = 2.8270  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.9983  Validation loss = 2.8266  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.9981  Validation loss = 2.8264  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.9980  Validation loss = 2.8261  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.9978  Validation loss = 2.8258  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.9976  Validation loss = 2.8255  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.9974  Validation loss = 2.8253  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.9973  Validation loss = 2.8250  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.9971  Validation loss = 2.8247  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.9969  Validation loss = 2.8244  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.9967  Validation loss = 2.8241  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.9965  Validation loss = 2.8238  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.9964  Validation loss = 2.8235  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.9962  Validation loss = 2.8233  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.9959  Validation loss = 2.8229  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.9957  Validation loss = 2.8225  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.9955  Validation loss = 2.8222  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.9954  Validation loss = 2.8219  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.9952  Validation loss = 2.8216  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.9950  Validation loss = 2.8213  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.9947  Validation loss = 2.8209  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.9945  Validation loss = 2.8206  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.9943  Validation loss = 2.8203  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.9941  Validation loss = 2.8200  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.9939  Validation loss = 2.8196  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.9936  Validation loss = 2.8192  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.9934  Validation loss = 2.8188  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.9932  Validation loss = 2.8185  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.9930  Validation loss = 2.8181  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.9928  Validation loss = 2.8179  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.9926  Validation loss = 2.8175  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.9923  Validation loss = 2.8171  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.9922  Validation loss = 2.8168  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.9920  Validation loss = 2.8166  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.9918  Validation loss = 2.8163  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.9916  Validation loss = 2.8160  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.9915  Validation loss = 2.8157  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.9913  Validation loss = 2.8155  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.9912  Validation loss = 2.8153  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.9694  Validation loss = 4.1759  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.9692  Validation loss = 4.1756  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.9690  Validation loss = 4.1753  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.9688  Validation loss = 4.1750  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.9687  Validation loss = 4.1747  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.9685  Validation loss = 4.1744  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.9683  Validation loss = 4.1741  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.9682  Validation loss = 4.1739  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.9680  Validation loss = 4.1736  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.9678  Validation loss = 4.1732  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.9677  Validation loss = 4.1730  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.9675  Validation loss = 4.1727  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.9673  Validation loss = 4.1724  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.9671  Validation loss = 4.1720  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.9670  Validation loss = 4.1718  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.9668  Validation loss = 4.1715  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.9667  Validation loss = 4.1712  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.9665  Validation loss = 4.1709  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.9663  Validation loss = 4.1705  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.9661  Validation loss = 4.1703  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.9659  Validation loss = 4.1700  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.9658  Validation loss = 4.1697  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.9656  Validation loss = 4.1693  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.9654  Validation loss = 4.1691  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.9652  Validation loss = 4.1687  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.9650  Validation loss = 4.1684  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.9649  Validation loss = 4.1682  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.9647  Validation loss = 4.1679  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.9646  Validation loss = 4.1676  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.9644  Validation loss = 4.1673  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.9642  Validation loss = 4.1671  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.9641  Validation loss = 4.1668  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.9639  Validation loss = 4.1665  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.9637  Validation loss = 4.1661  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.9635  Validation loss = 4.1658  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.9633  Validation loss = 4.1655  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.9631  Validation loss = 4.1652  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.9629  Validation loss = 4.1648  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.9628  Validation loss = 4.1645  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.9626  Validation loss = 4.1642  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.9624  Validation loss = 4.1638  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.9622  Validation loss = 4.1636  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.9620  Validation loss = 4.1632  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.9619  Validation loss = 4.1630  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.9617  Validation loss = 4.1626  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.9615  Validation loss = 4.1623  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.9612  Validation loss = 4.1619  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.9610  Validation loss = 4.1615  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.9609  Validation loss = 4.1612  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.9606  Validation loss = 4.1608  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.9605  Validation loss = 4.1605  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.9603  Validation loss = 4.1603  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.9602  Validation loss = 4.1600  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.9600  Validation loss = 4.1597  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.9599  Validation loss = 4.1595  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.9597  Validation loss = 4.1592  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.9596  Validation loss = 4.1590  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.9594  Validation loss = 4.1587  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.9592  Validation loss = 4.1583  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.9590  Validation loss = 4.1580  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.9588  Validation loss = 4.1577  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.9587  Validation loss = 4.1574  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.9585  Validation loss = 4.1571  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.9583  Validation loss = 4.1568  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.9582  Validation loss = 4.1565  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.9580  Validation loss = 4.1563  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.9578  Validation loss = 4.1559  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.9576  Validation loss = 4.1556  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.9575  Validation loss = 4.1554  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.9573  Validation loss = 4.1551  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.9572  Validation loss = 4.1548  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.9570  Validation loss = 4.1546  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.9569  Validation loss = 4.1543  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.9567  Validation loss = 4.1540  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.9565  Validation loss = 4.1537  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.9563  Validation loss = 4.1534  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.9562  Validation loss = 4.1532  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.9560  Validation loss = 4.1529  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.9559  Validation loss = 4.1526  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.9557  Validation loss = 4.1523  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.9555  Validation loss = 4.1520  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.9553  Validation loss = 4.1516  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.9551  Validation loss = 4.1513  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.9549  Validation loss = 4.1510  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.9547  Validation loss = 4.1506  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.9546  Validation loss = 4.1504  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.9544  Validation loss = 4.1501  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.9543  Validation loss = 4.1498  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.9540  Validation loss = 4.1495  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.9539  Validation loss = 4.1492  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.9537  Validation loss = 4.1489  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.9536  Validation loss = 4.1486  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.9534  Validation loss = 4.1483  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.9532  Validation loss = 4.1480  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.9530  Validation loss = 4.1476  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.9528  Validation loss = 4.1473  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.9527  Validation loss = 4.1471  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.9526  Validation loss = 4.1469  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.9525  Validation loss = 4.1467  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.9523  Validation loss = 4.1463  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.9521  Validation loss = 4.1461  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.9519  Validation loss = 4.1457  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.9517  Validation loss = 4.1454  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.9515  Validation loss = 4.1450  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.9513  Validation loss = 4.1447  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.9512  Validation loss = 4.1444  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.9510  Validation loss = 4.1441  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.9508  Validation loss = 4.1438  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.9507  Validation loss = 4.1435  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.9505  Validation loss = 4.1433  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.9504  Validation loss = 4.1430  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.9503  Validation loss = 4.1429  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.9501  Validation loss = 4.1426  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.9499  Validation loss = 4.1422  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.9497  Validation loss = 4.1419  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.9496  Validation loss = 4.1416  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.9495  Validation loss = 4.1414  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.9493  Validation loss = 4.1410  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.9491  Validation loss = 4.1407  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.9489  Validation loss = 4.1403  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.9487  Validation loss = 4.1401  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.9486  Validation loss = 4.1398  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.9484  Validation loss = 4.1395  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.9482  Validation loss = 4.1391  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.9480  Validation loss = 4.1388  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.9478  Validation loss = 4.1384  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.9476  Validation loss = 4.1382  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.9475  Validation loss = 4.1379  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.9473  Validation loss = 4.1375  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.9471  Validation loss = 4.1373  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.9470  Validation loss = 4.1370  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.9468  Validation loss = 4.1367  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.9467  Validation loss = 4.1365  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.9465  Validation loss = 4.1362  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.9463  Validation loss = 4.1359  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.9461  Validation loss = 4.1355  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.9460  Validation loss = 4.1352  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.9458  Validation loss = 4.1350  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.9456  Validation loss = 4.1347  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.9455  Validation loss = 4.1344  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.9453  Validation loss = 4.1342  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.9452  Validation loss = 4.1339  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.9450  Validation loss = 4.1335  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.9448  Validation loss = 4.1332  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.9446  Validation loss = 4.1328  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.9444  Validation loss = 4.1326  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.9443  Validation loss = 4.1323  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.9441  Validation loss = 4.1320  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.9439  Validation loss = 4.1316  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.9437  Validation loss = 4.1313  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.9436  Validation loss = 4.1310  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.9434  Validation loss = 4.1307  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.9432  Validation loss = 4.1304  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.9431  Validation loss = 4.1301  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.9429  Validation loss = 4.1298  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.9427  Validation loss = 4.1294  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.9425  Validation loss = 4.1291  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.9423  Validation loss = 4.1288  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.9422  Validation loss = 4.1286  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.9420  Validation loss = 4.1283  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.9419  Validation loss = 4.1280  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.9417  Validation loss = 4.1278  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.9416  Validation loss = 4.1275  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.9414  Validation loss = 4.1271  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.9412  Validation loss = 4.1268  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.9410  Validation loss = 4.1264  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.9408  Validation loss = 4.1261  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.9406  Validation loss = 4.1258  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.9405  Validation loss = 4.1255  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.9403  Validation loss = 4.1252  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.9401  Validation loss = 4.1249  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.9400  Validation loss = 4.1247  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.9399  Validation loss = 4.1244  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.9397  Validation loss = 4.1241  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.9395  Validation loss = 4.1239  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.9394  Validation loss = 4.1236  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.9392  Validation loss = 4.1233  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.9390  Validation loss = 4.1229  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.9388  Validation loss = 4.1226  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.9386  Validation loss = 4.1223  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.9385  Validation loss = 4.1220  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.9383  Validation loss = 4.1216  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.9381  Validation loss = 4.1214  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.9380  Validation loss = 4.1211  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.9378  Validation loss = 4.1208  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.9376  Validation loss = 4.1205  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.9374  Validation loss = 4.1202  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.9373  Validation loss = 4.1199  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.9371  Validation loss = 4.1196  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.9370  Validation loss = 4.1194  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.9368  Validation loss = 4.1191  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.9367  Validation loss = 4.1188  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.9365  Validation loss = 4.1186  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.9364  Validation loss = 4.1183  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.9362  Validation loss = 4.1180  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.9361  Validation loss = 4.1178  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.9359  Validation loss = 4.1175  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.9358  Validation loss = 4.1172  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.9356  Validation loss = 4.1169  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.9354  Validation loss = 4.1167  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.9353  Validation loss = 4.1164  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.9351  Validation loss = 4.1161  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.9350  Validation loss = 4.1159  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.9349  Validation loss = 4.1157  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.9347  Validation loss = 4.1154  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.9346  Validation loss = 4.1151  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.9344  Validation loss = 4.1148  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.9342  Validation loss = 4.1145  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.9341  Validation loss = 4.1142  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.9339  Validation loss = 4.1139  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.9337  Validation loss = 4.1135  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.9335  Validation loss = 4.1132  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.9333  Validation loss = 4.1128  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.9332  Validation loss = 4.1126  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.9330  Validation loss = 4.1122  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.9329  Validation loss = 4.1120  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.9327  Validation loss = 4.1118  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.9326  Validation loss = 4.1115  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.9324  Validation loss = 4.1113  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.9322  Validation loss = 4.1109  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.9321  Validation loss = 4.1107  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.9320  Validation loss = 4.1105  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.9317  Validation loss = 4.1101  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.9315  Validation loss = 4.1097  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.9314  Validation loss = 4.1095  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.9313  Validation loss = 4.1092  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.9311  Validation loss = 4.1089  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.9309  Validation loss = 4.1085  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.9307  Validation loss = 4.1083  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.9306  Validation loss = 4.1080  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.9304  Validation loss = 4.1078  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.9303  Validation loss = 4.1075  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.9302  Validation loss = 4.1072  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.9300  Validation loss = 4.1069  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.9299  Validation loss = 4.1067  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.9297  Validation loss = 4.1064  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.9295  Validation loss = 4.1061  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.9294  Validation loss = 4.1058  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.9292  Validation loss = 4.1055  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.9290  Validation loss = 4.1052  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.9289  Validation loss = 4.1049  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.9287  Validation loss = 4.1046  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.9286  Validation loss = 4.1044  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.9284  Validation loss = 4.1041  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.9282  Validation loss = 4.1038  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.9281  Validation loss = 4.1036  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.9279  Validation loss = 4.1033  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.9278  Validation loss = 4.1030  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.9276  Validation loss = 4.1027  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.9275  Validation loss = 4.1024  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.9273  Validation loss = 4.1022  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.9272  Validation loss = 4.1019  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.9271  Validation loss = 4.1017  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.9269  Validation loss = 4.1014  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.9267  Validation loss = 4.1011  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.9265  Validation loss = 4.1008  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.9264  Validation loss = 4.1005  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.9262  Validation loss = 4.1002  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.9260  Validation loss = 4.0998  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.9259  Validation loss = 4.0996  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.9257  Validation loss = 4.0993  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.9256  Validation loss = 4.0990  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.9254  Validation loss = 4.0987  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.9252  Validation loss = 4.0984  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.9251  Validation loss = 4.0982  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.9250  Validation loss = 4.0980  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.9248  Validation loss = 4.0978  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.9247  Validation loss = 4.0976  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.9246  Validation loss = 4.0973  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.9244  Validation loss = 4.0971  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.9243  Validation loss = 4.0968  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.9241  Validation loss = 4.0965  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.9240  Validation loss = 4.0963  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.9238  Validation loss = 4.0960  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.9237  Validation loss = 4.0957  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.9236  Validation loss = 4.0955  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.9234  Validation loss = 4.0952  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.9233  Validation loss = 4.0950  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.9231  Validation loss = 4.0947  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.9229  Validation loss = 4.0944  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.9228  Validation loss = 4.0941  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.9227  Validation loss = 4.0939  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.9225  Validation loss = 4.0936  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.9223  Validation loss = 4.0933  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.9221  Validation loss = 4.0930  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.9220  Validation loss = 4.0927  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.9218  Validation loss = 4.0924  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.9217  Validation loss = 4.0921  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.9215  Validation loss = 4.0919  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.9213  Validation loss = 4.0915  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.9212  Validation loss = 4.0912  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.9210  Validation loss = 4.0909  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.9208  Validation loss = 4.0905  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.9206  Validation loss = 4.0901  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.9204  Validation loss = 4.0898  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.9203  Validation loss = 4.0896  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.9201  Validation loss = 4.0893  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.9199  Validation loss = 4.0890  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.9198  Validation loss = 4.0887  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.9197  Validation loss = 4.0885  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.9195  Validation loss = 4.0882  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.9193  Validation loss = 4.0878  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.9192  Validation loss = 4.0875  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.9190  Validation loss = 4.0872  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.9188  Validation loss = 4.0869  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.9187  Validation loss = 4.0866  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.9185  Validation loss = 4.0864  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.9184  Validation loss = 4.0861  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.9182  Validation loss = 4.0859  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.9181  Validation loss = 4.0856  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.9180  Validation loss = 4.0854  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.9178  Validation loss = 4.0851  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.9177  Validation loss = 4.0848  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.9175  Validation loss = 4.0845  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.9173  Validation loss = 4.0842  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.9172  Validation loss = 4.0840  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.9171  Validation loss = 4.0838  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.9170  Validation loss = 4.0836  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.9168  Validation loss = 4.0832  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.9166  Validation loss = 4.0829  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.9165  Validation loss = 4.0827  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.9164  Validation loss = 4.0825  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.9162  Validation loss = 4.0822  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.9161  Validation loss = 4.0820  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.9159  Validation loss = 4.0818  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.9157  Validation loss = 4.0814  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.9156  Validation loss = 4.0811  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.9154  Validation loss = 4.0808  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.9152  Validation loss = 4.0805  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.9151  Validation loss = 4.0802  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.9149  Validation loss = 4.0799  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.9148  Validation loss = 4.0796  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.9146  Validation loss = 4.0794  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.9145  Validation loss = 4.0791  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.9143  Validation loss = 4.0788  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.9141  Validation loss = 4.0785  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.9140  Validation loss = 4.0782  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.9138  Validation loss = 4.0779  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.9136  Validation loss = 4.0775  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.9135  Validation loss = 4.0772  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.9133  Validation loss = 4.0769  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.9132  Validation loss = 4.0767  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.9130  Validation loss = 4.0763  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.9128  Validation loss = 4.0760  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.9127  Validation loss = 4.0758  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.9126  Validation loss = 4.0756  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.9124  Validation loss = 4.0752  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.9122  Validation loss = 4.0749  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.9120  Validation loss = 4.0747  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.9119  Validation loss = 4.0744  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.9117  Validation loss = 4.0741  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.9115  Validation loss = 4.0737  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.9114  Validation loss = 4.0735  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.9112  Validation loss = 4.0732  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.9111  Validation loss = 4.0729  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.9109  Validation loss = 4.0726  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.9107  Validation loss = 4.0723  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.9106  Validation loss = 4.0720  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.9104  Validation loss = 4.0717  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.9103  Validation loss = 4.0715  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.9101  Validation loss = 4.0712  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.9100  Validation loss = 4.0710  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.9099  Validation loss = 4.0708  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.9097  Validation loss = 4.0705  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.9096  Validation loss = 4.0702  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.9094  Validation loss = 4.0699  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.9092  Validation loss = 4.0696  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.9091  Validation loss = 4.0693  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.9089  Validation loss = 4.0690  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.9087  Validation loss = 4.0686  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.9086  Validation loss = 4.0684  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.9085  Validation loss = 4.0682  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.9083  Validation loss = 4.0679  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.9081  Validation loss = 4.0676  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.9080  Validation loss = 4.0673  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.9079  Validation loss = 4.0671  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.9077  Validation loss = 4.0668  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.9075  Validation loss = 4.0665  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.9073  Validation loss = 4.0661  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.9071  Validation loss = 4.0657  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.9070  Validation loss = 4.0655  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.9069  Validation loss = 4.0653  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.9068  Validation loss = 4.0651  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.9066  Validation loss = 4.0649  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.9065  Validation loss = 4.0646  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.9063  Validation loss = 4.0643  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.9062  Validation loss = 4.0640  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.9060  Validation loss = 4.0637  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.9059  Validation loss = 4.0635  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.9057  Validation loss = 4.0632  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.9056  Validation loss = 4.0630  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.9054  Validation loss = 4.0627  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.9052  Validation loss = 4.0624  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.9051  Validation loss = 4.0621  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.9049  Validation loss = 4.0618  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.9048  Validation loss = 4.0615  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.9047  Validation loss = 4.0614  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.9045  Validation loss = 4.0611  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.9043  Validation loss = 4.0608  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.9042  Validation loss = 4.0605  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.9040  Validation loss = 4.0602  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.9038  Validation loss = 4.0598  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.9037  Validation loss = 4.0596  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.9035  Validation loss = 4.0593  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.9034  Validation loss = 4.0590  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.9033  Validation loss = 4.0588  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.9031  Validation loss = 4.0585  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.9029  Validation loss = 4.0582  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.9028  Validation loss = 4.0579  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.9026  Validation loss = 4.0576  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.9025  Validation loss = 4.0573  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.9023  Validation loss = 4.0571  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.9022  Validation loss = 4.0568  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.9020  Validation loss = 4.0564  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.9019  Validation loss = 4.0562  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.9017  Validation loss = 4.0559  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.9015  Validation loss = 4.0556  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.9014  Validation loss = 4.0553  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.9013  Validation loss = 4.0551  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.9011  Validation loss = 4.0548  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.9010  Validation loss = 4.0546  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.9009  Validation loss = 4.0544  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.9007  Validation loss = 4.0541  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.9005  Validation loss = 4.0538  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.9004  Validation loss = 4.0535  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.9002  Validation loss = 4.0532  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.9001  Validation loss = 4.0530  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.8999  Validation loss = 4.0527  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.8998  Validation loss = 4.0524  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.8996  Validation loss = 4.0521  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.8995  Validation loss = 4.0518  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.8993  Validation loss = 4.0515  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.8991  Validation loss = 4.0512  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.8990  Validation loss = 4.0509  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.8988  Validation loss = 4.0506  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.8986  Validation loss = 4.0503  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.8985  Validation loss = 4.0500  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.8984  Validation loss = 4.0498  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.8982  Validation loss = 4.0495  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.8981  Validation loss = 4.0492  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.8979  Validation loss = 4.0488  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.8977  Validation loss = 4.0486  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.8976  Validation loss = 4.0483  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.8975  Validation loss = 4.0481  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.8973  Validation loss = 4.0479  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.8972  Validation loss = 4.0476  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.8970  Validation loss = 4.0473  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.8969  Validation loss = 4.0470  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.8967  Validation loss = 4.0468  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.8966  Validation loss = 4.0464  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.8964  Validation loss = 4.0462  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.8963  Validation loss = 4.0459  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.8961  Validation loss = 4.0456  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.8961  Validation loss = 4.0455  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.8959  Validation loss = 4.0452  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.8957  Validation loss = 4.0449  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.8956  Validation loss = 4.0445  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.8954  Validation loss = 4.0443  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.8953  Validation loss = 4.0440  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.8951  Validation loss = 4.0438  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.8950  Validation loss = 4.0435  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.8949  Validation loss = 4.0433  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.8948  Validation loss = 4.0431  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.8946  Validation loss = 4.0428  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.8945  Validation loss = 4.0425  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.8943  Validation loss = 4.0422  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.8941  Validation loss = 4.0419  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.8940  Validation loss = 4.0417  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.8938  Validation loss = 4.0413  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.8937  Validation loss = 4.0411  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.8935  Validation loss = 4.0408  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.8934  Validation loss = 4.0405  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.8932  Validation loss = 4.0402  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.8930  Validation loss = 4.0399  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.8929  Validation loss = 4.0395  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.8927  Validation loss = 4.0392  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.8926  Validation loss = 4.0390  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.8924  Validation loss = 4.0387  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.8923  Validation loss = 4.0384  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.8921  Validation loss = 4.0381  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.8919  Validation loss = 4.0378  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.8918  Validation loss = 4.0375  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.8916  Validation loss = 4.0373  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.8915  Validation loss = 4.0370  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.8914  Validation loss = 4.0369  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.8913  Validation loss = 4.0366  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.8911  Validation loss = 4.0363  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.8909  Validation loss = 4.0359  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.8908  Validation loss = 4.0357  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.8907  Validation loss = 4.0354  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.8905  Validation loss = 4.0351  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.8903  Validation loss = 4.0348  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.8902  Validation loss = 4.0346  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.8900  Validation loss = 4.0342  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.8899  Validation loss = 4.0339  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.8897  Validation loss = 4.0336  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.8896  Validation loss = 4.0334  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.8894  Validation loss = 4.0331  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.8893  Validation loss = 4.0329  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.8892  Validation loss = 4.0327  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.9878  Validation loss = 5.1809  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.9877  Validation loss = 5.1806  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.9875  Validation loss = 5.1803  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.9873  Validation loss = 5.1800  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.9872  Validation loss = 5.1797  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.9870  Validation loss = 5.1795  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.9868  Validation loss = 5.1791  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.9867  Validation loss = 5.1789  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.9865  Validation loss = 5.1787  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.9863  Validation loss = 5.1784  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.9862  Validation loss = 5.1782  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.9860  Validation loss = 5.1779  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.9858  Validation loss = 5.1776  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.9857  Validation loss = 5.1774  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.9855  Validation loss = 5.1771  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.9853  Validation loss = 5.1768  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.9852  Validation loss = 5.1766  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.9850  Validation loss = 5.1763  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.9848  Validation loss = 5.1759  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.9847  Validation loss = 5.1758  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.9845  Validation loss = 5.1755  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.9844  Validation loss = 5.1753  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.9842  Validation loss = 5.1750  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.9840  Validation loss = 5.1747  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.9838  Validation loss = 5.1745  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.9837  Validation loss = 5.1742  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.9835  Validation loss = 5.1739  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.9834  Validation loss = 5.1737  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.9832  Validation loss = 5.1733  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.9830  Validation loss = 5.1730  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.9828  Validation loss = 5.1728  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.9827  Validation loss = 5.1726  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.9826  Validation loss = 5.1724  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.9824  Validation loss = 5.1720  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.9821  Validation loss = 5.1717  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.9820  Validation loss = 5.1714  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.9819  Validation loss = 5.1712  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.9817  Validation loss = 5.1709  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.9815  Validation loss = 5.1707  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.9814  Validation loss = 5.1705  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.9812  Validation loss = 5.1702  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.9811  Validation loss = 5.1699  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.9809  Validation loss = 5.1696  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.9807  Validation loss = 5.1693  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.9805  Validation loss = 5.1691  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.9803  Validation loss = 5.1687  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.9802  Validation loss = 5.1685  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.9800  Validation loss = 5.1682  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.9797  Validation loss = 5.1677  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.9796  Validation loss = 5.1674  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.9794  Validation loss = 5.1672  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.9792  Validation loss = 5.1669  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.9790  Validation loss = 5.1666  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.9789  Validation loss = 5.1664  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.9787  Validation loss = 5.1661  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.9785  Validation loss = 5.1658  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.9783  Validation loss = 5.1655  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.9782  Validation loss = 5.1652  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.9779  Validation loss = 5.1648  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.9778  Validation loss = 5.1646  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.9776  Validation loss = 5.1643  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.9774  Validation loss = 5.1639  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.9773  Validation loss = 5.1638  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.9771  Validation loss = 5.1635  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.9769  Validation loss = 5.1632  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.9767  Validation loss = 5.1629  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.9766  Validation loss = 5.1626  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.9763  Validation loss = 5.1622  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.9761  Validation loss = 5.1619  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.9760  Validation loss = 5.1617  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.9758  Validation loss = 5.1614  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.9756  Validation loss = 5.1611  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.9754  Validation loss = 5.1608  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.9753  Validation loss = 5.1605  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.9751  Validation loss = 5.1602  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.9749  Validation loss = 5.1599  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.9747  Validation loss = 5.1596  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.9745  Validation loss = 5.1593  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.9744  Validation loss = 5.1591  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.9742  Validation loss = 5.1588  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.9740  Validation loss = 5.1585  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.9739  Validation loss = 5.1583  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.9737  Validation loss = 5.1580  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.9735  Validation loss = 5.1577  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.9734  Validation loss = 5.1574  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.9732  Validation loss = 5.1571  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.9730  Validation loss = 5.1568  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.9728  Validation loss = 5.1565  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.9727  Validation loss = 5.1563  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.9725  Validation loss = 5.1561  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.9724  Validation loss = 5.1558  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.9722  Validation loss = 5.1556  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.9720  Validation loss = 5.1553  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.9719  Validation loss = 5.1550  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.9717  Validation loss = 5.1547  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.9715  Validation loss = 5.1544  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.9713  Validation loss = 5.1541  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.9712  Validation loss = 5.1539  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.9710  Validation loss = 5.1535  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.9708  Validation loss = 5.1533  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.9707  Validation loss = 5.1531  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.9705  Validation loss = 5.1528  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.9704  Validation loss = 5.1525  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.9702  Validation loss = 5.1523  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.9700  Validation loss = 5.1520  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.9698  Validation loss = 5.1516  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.9696  Validation loss = 5.1514  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.9695  Validation loss = 5.1511  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.9693  Validation loss = 5.1508  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.9691  Validation loss = 5.1505  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.9690  Validation loss = 5.1502  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.9688  Validation loss = 5.1500  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.9686  Validation loss = 5.1497  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.9685  Validation loss = 5.1495  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.9683  Validation loss = 5.1492  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.9682  Validation loss = 5.1490  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.9680  Validation loss = 5.1487  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.9679  Validation loss = 5.1484  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.9677  Validation loss = 5.1482  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.9675  Validation loss = 5.1479  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.9674  Validation loss = 5.1477  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.9672  Validation loss = 5.1475  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.9671  Validation loss = 5.1472  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.9669  Validation loss = 5.1470  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.9668  Validation loss = 5.1468  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.9666  Validation loss = 5.1465  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.9665  Validation loss = 5.1462  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.9663  Validation loss = 5.1459  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.9662  Validation loss = 5.1457  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.9660  Validation loss = 5.1454  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.9658  Validation loss = 5.1451  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.9656  Validation loss = 5.1448  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.9654  Validation loss = 5.1445  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.9653  Validation loss = 5.1442  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.9651  Validation loss = 5.1439  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.9649  Validation loss = 5.1437  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.9648  Validation loss = 5.1435  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.9646  Validation loss = 5.1432  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.9644  Validation loss = 5.1428  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.9642  Validation loss = 5.1425  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.9641  Validation loss = 5.1423  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.9640  Validation loss = 5.1421  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.9638  Validation loss = 5.1418  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.9637  Validation loss = 5.1416  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.9635  Validation loss = 5.1413  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.9633  Validation loss = 5.1410  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.9632  Validation loss = 5.1409  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.9630  Validation loss = 5.1406  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.9629  Validation loss = 5.1403  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.9628  Validation loss = 5.1401  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.9626  Validation loss = 5.1398  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.9624  Validation loss = 5.1395  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.9622  Validation loss = 5.1392  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.9621  Validation loss = 5.1390  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.9619  Validation loss = 5.1387  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.9618  Validation loss = 5.1385  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.9616  Validation loss = 5.1381  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.9614  Validation loss = 5.1377  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.9612  Validation loss = 5.1375  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.9610  Validation loss = 5.1371  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.9609  Validation loss = 5.1369  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.9607  Validation loss = 5.1366  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.9605  Validation loss = 5.1364  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.9604  Validation loss = 5.1361  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.9602  Validation loss = 5.1358  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.9601  Validation loss = 5.1355  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.9599  Validation loss = 5.1353  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.9597  Validation loss = 5.1349  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.9595  Validation loss = 5.1347  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.9593  Validation loss = 5.1344  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.9592  Validation loss = 5.1341  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.9590  Validation loss = 5.1337  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.9588  Validation loss = 5.1335  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.9587  Validation loss = 5.1332  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.9585  Validation loss = 5.1330  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.9583  Validation loss = 5.1327  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.9582  Validation loss = 5.1324  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.9580  Validation loss = 5.1321  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.9578  Validation loss = 5.1318  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.9576  Validation loss = 5.1316  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.9575  Validation loss = 5.1314  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.9573  Validation loss = 5.1310  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.9571  Validation loss = 5.1307  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.9569  Validation loss = 5.1304  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.9568  Validation loss = 5.1301  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.9566  Validation loss = 5.1299  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.9564  Validation loss = 5.1296  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.9563  Validation loss = 5.1294  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.9561  Validation loss = 5.1291  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.9559  Validation loss = 5.1287  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.9557  Validation loss = 5.1284  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.9556  Validation loss = 5.1282  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.9554  Validation loss = 5.1279  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.9552  Validation loss = 5.1276  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.9551  Validation loss = 5.1274  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.9549  Validation loss = 5.1271  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.9547  Validation loss = 5.1268  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.9545  Validation loss = 5.1265  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.9543  Validation loss = 5.1261  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.9541  Validation loss = 5.1258  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.9540  Validation loss = 5.1255  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.9538  Validation loss = 5.1252  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.9536  Validation loss = 5.1250  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.9535  Validation loss = 5.1248  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.9534  Validation loss = 5.1246  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.9533  Validation loss = 5.1244  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.9531  Validation loss = 5.1241  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.9529  Validation loss = 5.1238  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.9527  Validation loss = 5.1234  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.9526  Validation loss = 5.1232  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.9524  Validation loss = 5.1229  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.9522  Validation loss = 5.1226  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.9521  Validation loss = 5.1223  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.9519  Validation loss = 5.1220  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.9517  Validation loss = 5.1217  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.9515  Validation loss = 5.1214  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.9514  Validation loss = 5.1212  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.9512  Validation loss = 5.1210  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.9510  Validation loss = 5.1206  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.9508  Validation loss = 5.1203  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.9506  Validation loss = 5.1199  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.9504  Validation loss = 5.1196  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.9503  Validation loss = 5.1194  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.9501  Validation loss = 5.1191  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.9500  Validation loss = 5.1188  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.9498  Validation loss = 5.1186  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.9496  Validation loss = 5.1183  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.9495  Validation loss = 5.1181  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.9494  Validation loss = 5.1178  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.9492  Validation loss = 5.1176  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.9491  Validation loss = 5.1173  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.9489  Validation loss = 5.1171  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.9488  Validation loss = 5.1168  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.9486  Validation loss = 5.1166  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.9485  Validation loss = 5.1165  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.9483  Validation loss = 5.1162  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.9482  Validation loss = 5.1159  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.9481  Validation loss = 5.1157  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.9479  Validation loss = 5.1155  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.9477  Validation loss = 5.1152  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.9476  Validation loss = 5.1149  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.9474  Validation loss = 5.1146  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.9473  Validation loss = 5.1144  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.9472  Validation loss = 5.1142  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.9470  Validation loss = 5.1139  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.9468  Validation loss = 5.1137  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.9467  Validation loss = 5.1135  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.9466  Validation loss = 5.1133  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.9465  Validation loss = 5.1130  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.9463  Validation loss = 5.1128  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.9461  Validation loss = 5.1124  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.9459  Validation loss = 5.1122  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.9458  Validation loss = 5.1119  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.9457  Validation loss = 5.1117  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.9455  Validation loss = 5.1115  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.9453  Validation loss = 5.1112  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.9452  Validation loss = 5.1109  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.9450  Validation loss = 5.1106  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.9448  Validation loss = 5.1103  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.9447  Validation loss = 5.1100  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.9445  Validation loss = 5.1097  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.9443  Validation loss = 5.1094  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.9442  Validation loss = 5.1092  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.9440  Validation loss = 5.1089  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.9438  Validation loss = 5.1086  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.9437  Validation loss = 5.1084  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.9435  Validation loss = 5.1081  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.9433  Validation loss = 5.1078  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.9432  Validation loss = 5.1075  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.9430  Validation loss = 5.1072  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.9429  Validation loss = 5.1070  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.9427  Validation loss = 5.1066  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.9425  Validation loss = 5.1064  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.9424  Validation loss = 5.1062  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.9423  Validation loss = 5.1059  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.9421  Validation loss = 5.1057  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.9419  Validation loss = 5.1055  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.9418  Validation loss = 5.1052  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.9416  Validation loss = 5.1049  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.9415  Validation loss = 5.1047  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.9414  Validation loss = 5.1044  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.9412  Validation loss = 5.1042  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.9410  Validation loss = 5.1039  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.9409  Validation loss = 5.1037  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.9408  Validation loss = 5.1035  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.9406  Validation loss = 5.1033  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.9405  Validation loss = 5.1029  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.9403  Validation loss = 5.1027  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.9402  Validation loss = 5.1025  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.9401  Validation loss = 5.1023  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.9399  Validation loss = 5.1020  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.9397  Validation loss = 5.1017  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.9396  Validation loss = 5.1015  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.9394  Validation loss = 5.1012  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.9393  Validation loss = 5.1009  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.9391  Validation loss = 5.1007  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.9390  Validation loss = 5.1005  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.9389  Validation loss = 5.1003  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.9387  Validation loss = 5.1000  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.9386  Validation loss = 5.0997  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.9384  Validation loss = 5.0995  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.9383  Validation loss = 5.0993  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.9381  Validation loss = 5.0990  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.9380  Validation loss = 5.0988  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.9379  Validation loss = 5.0986  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.9377  Validation loss = 5.0983  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.9376  Validation loss = 5.0981  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.9374  Validation loss = 5.0978  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.9373  Validation loss = 5.0976  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.9371  Validation loss = 5.0973  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.9369  Validation loss = 5.0970  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.9368  Validation loss = 5.0968  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.9367  Validation loss = 5.0966  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.9365  Validation loss = 5.0963  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.9363  Validation loss = 5.0961  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.9362  Validation loss = 5.0959  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.9361  Validation loss = 5.0957  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.9360  Validation loss = 5.0954  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.9358  Validation loss = 5.0952  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.9357  Validation loss = 5.0949  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.9355  Validation loss = 5.0947  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.9353  Validation loss = 5.0943  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.9351  Validation loss = 5.0940  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.9350  Validation loss = 5.0937  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.9348  Validation loss = 5.0935  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.9347  Validation loss = 5.0932  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.9345  Validation loss = 5.0929  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.9343  Validation loss = 5.0927  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.9342  Validation loss = 5.0923  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.9340  Validation loss = 5.0921  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.9338  Validation loss = 5.0918  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.9337  Validation loss = 5.0915  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.9335  Validation loss = 5.0912  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.9333  Validation loss = 5.0909  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.9332  Validation loss = 5.0907  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.9330  Validation loss = 5.0904  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.9328  Validation loss = 5.0901  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.9327  Validation loss = 5.0899  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.9325  Validation loss = 5.0896  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.9324  Validation loss = 5.0894  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.9323  Validation loss = 5.0892  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.9321  Validation loss = 5.0889  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.9320  Validation loss = 5.0887  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.9319  Validation loss = 5.0885  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.9317  Validation loss = 5.0882  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.9316  Validation loss = 5.0880  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.9314  Validation loss = 5.0877  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.9312  Validation loss = 5.0874  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.9311  Validation loss = 5.0871  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.9309  Validation loss = 5.0868  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.9308  Validation loss = 5.0867  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.9307  Validation loss = 5.0865  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.9305  Validation loss = 5.0863  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.9304  Validation loss = 5.0861  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.9302  Validation loss = 5.0857  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.9301  Validation loss = 5.0855  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.9299  Validation loss = 5.0852  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.9298  Validation loss = 5.0850  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.9296  Validation loss = 5.0847  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.9295  Validation loss = 5.0845  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.9293  Validation loss = 5.0842  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.9292  Validation loss = 5.0840  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.9291  Validation loss = 5.0838  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.9290  Validation loss = 5.0836  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.9288  Validation loss = 5.0834  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.9287  Validation loss = 5.0831  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.9285  Validation loss = 5.0828  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.9283  Validation loss = 5.0825  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.9282  Validation loss = 5.0823  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.9280  Validation loss = 5.0820  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.9278  Validation loss = 5.0817  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.9277  Validation loss = 5.0815  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.9275  Validation loss = 5.0812  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.9274  Validation loss = 5.0809  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.9272  Validation loss = 5.0807  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.9271  Validation loss = 5.0804  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.9269  Validation loss = 5.0801  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.9268  Validation loss = 5.0799  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.9266  Validation loss = 5.0796  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.9265  Validation loss = 5.0794  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.9263  Validation loss = 5.0792  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.9262  Validation loss = 5.0789  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.9261  Validation loss = 5.0787  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.9259  Validation loss = 5.0784  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.9258  Validation loss = 5.0782  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.9257  Validation loss = 5.0780  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.9255  Validation loss = 5.0777  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.9254  Validation loss = 5.0776  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.9253  Validation loss = 5.0773  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.9251  Validation loss = 5.0771  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.9250  Validation loss = 5.0769  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.9248  Validation loss = 5.0766  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.9247  Validation loss = 5.0763  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.9245  Validation loss = 5.0760  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.9244  Validation loss = 5.0759  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.9243  Validation loss = 5.0757  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.9242  Validation loss = 5.0756  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.9241  Validation loss = 5.0753  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.9239  Validation loss = 5.0750  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.9237  Validation loss = 5.0747  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.9236  Validation loss = 5.0744  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.9234  Validation loss = 5.0741  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.9232  Validation loss = 5.0738  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.9230  Validation loss = 5.0734  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.9229  Validation loss = 5.0732  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.9228  Validation loss = 5.0730  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 1.9226  Validation loss = 5.0728  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 1.9225  Validation loss = 5.0726  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 1.9224  Validation loss = 5.0724  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 1.9222  Validation loss = 5.0721  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 1.9220  Validation loss = 5.0718  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 1.9219  Validation loss = 5.0715  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 1.9218  Validation loss = 5.0713  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 1.9216  Validation loss = 5.0711  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 1.9215  Validation loss = 5.0709  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 1.9214  Validation loss = 5.0706  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 1.9212  Validation loss = 5.0704  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 1.9210  Validation loss = 5.0701  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 1.9209  Validation loss = 5.0699  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 1.9208  Validation loss = 5.0697  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 1.9206  Validation loss = 5.0694  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 1.9205  Validation loss = 5.0691  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 1.9203  Validation loss = 5.0688  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 1.9201  Validation loss = 5.0685  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 1.9200  Validation loss = 5.0683  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 1.9198  Validation loss = 5.0680  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 1.9197  Validation loss = 5.0678  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 1.9195  Validation loss = 5.0675  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 1.9194  Validation loss = 5.0672  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 1.9193  Validation loss = 5.0671  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 1.9192  Validation loss = 5.0668  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 1.9190  Validation loss = 5.0665  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 1.9188  Validation loss = 5.0662  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 1.9186  Validation loss = 5.0659  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 1.9185  Validation loss = 5.0657  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 1.9184  Validation loss = 5.0655  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 1.9183  Validation loss = 5.0653  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 1.9181  Validation loss = 5.0651  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 1.9180  Validation loss = 5.0648  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 1.9178  Validation loss = 5.0645  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 1.9177  Validation loss = 5.0643  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 1.9175  Validation loss = 5.0640  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 1.9174  Validation loss = 5.0637  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 1.9172  Validation loss = 5.0634  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 1.9170  Validation loss = 5.0631  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 1.9169  Validation loss = 5.0628  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 1.9167  Validation loss = 5.0626  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 1.9166  Validation loss = 5.0623  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 1.9165  Validation loss = 5.0621  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 1.9163  Validation loss = 5.0619  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 1.9162  Validation loss = 5.0616  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 1.9160  Validation loss = 5.0613  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 1.9159  Validation loss = 5.0611  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 1.9157  Validation loss = 5.0608  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 1.9156  Validation loss = 5.0606  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 1.9154  Validation loss = 5.0604  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 1.9153  Validation loss = 5.0601  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 1.9152  Validation loss = 5.0599  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 1.9150  Validation loss = 5.0596  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 1.9149  Validation loss = 5.0594  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 1.9148  Validation loss = 5.0592  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 1.9146  Validation loss = 5.0589  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 1.9144  Validation loss = 5.0586  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 1.9143  Validation loss = 5.0583  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 1.9141  Validation loss = 5.0580  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 1.9140  Validation loss = 5.0578  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 1.9138  Validation loss = 5.0574  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 1.9136  Validation loss = 5.0572  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 1.9135  Validation loss = 5.0569  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 1.9134  Validation loss = 5.0567  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 1.9132  Validation loss = 5.0564  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 1.9131  Validation loss = 5.0562  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 1.9129  Validation loss = 5.0559  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 1.9128  Validation loss = 5.0557  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 1.9127  Validation loss = 5.0556  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 1.9126  Validation loss = 5.0553  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 1.9124  Validation loss = 5.0550  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 1.9123  Validation loss = 5.0548  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 1.9121  Validation loss = 5.0545  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 1.9120  Validation loss = 5.0543  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 1.9119  Validation loss = 5.0541  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 1.9117  Validation loss = 5.0538  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 1.9116  Validation loss = 5.0536  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 1.9114  Validation loss = 5.0533  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 1.9112  Validation loss = 5.0530  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 1.9111  Validation loss = 5.0527  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 1.9109  Validation loss = 5.0524  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 1.9108  Validation loss = 5.0522  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 1.9106  Validation loss = 5.0519  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 1.9105  Validation loss = 5.0516  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 1.9103  Validation loss = 5.0513  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 1.9101  Validation loss = 5.0510  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 1.9100  Validation loss = 5.0508  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 1.9098  Validation loss = 5.0505  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 1.9097  Validation loss = 5.0504  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 1.9096  Validation loss = 5.0501  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 1.9095  Validation loss = 5.0500  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 1.9094  Validation loss = 5.0498  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 1.9092  Validation loss = 5.0495  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 1.9091  Validation loss = 5.0492  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 500  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 2.2545  Validation loss = 4.7675  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 2.2543  Validation loss = 4.7671  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 2.2541  Validation loss = 4.7668  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 2.2538  Validation loss = 4.7664  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 2.2536  Validation loss = 4.7661  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 2.2535  Validation loss = 4.7658  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 2.2533  Validation loss = 4.7654  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 2.2531  Validation loss = 4.7651  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 2.2529  Validation loss = 4.7648  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 2.2527  Validation loss = 4.7644  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 2.2525  Validation loss = 4.7639  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 2.2523  Validation loss = 4.7636  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 2.2520  Validation loss = 4.7632  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 2.2518  Validation loss = 4.7628  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 2.2516  Validation loss = 4.7623  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 2.2513  Validation loss = 4.7619  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 2.2511  Validation loss = 4.7615  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 2.2509  Validation loss = 4.7612  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 2.2507  Validation loss = 4.7609  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 2.2505  Validation loss = 4.7605  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 2.2504  Validation loss = 4.7602  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 2.2501  Validation loss = 4.7598  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 2.2499  Validation loss = 4.7594  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 2.2497  Validation loss = 4.7589  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 2.2495  Validation loss = 4.7586  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 2.2493  Validation loss = 4.7583  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 2.2491  Validation loss = 4.7579  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 2.2489  Validation loss = 4.7576  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 2.2487  Validation loss = 4.7573  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 2.2486  Validation loss = 4.7570  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 2.2484  Validation loss = 4.7567  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 2.2481  Validation loss = 4.7562  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 2.2479  Validation loss = 4.7559  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 2.2477  Validation loss = 4.7555  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 2.2475  Validation loss = 4.7552  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 2.2474  Validation loss = 4.7549  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 2.2471  Validation loss = 4.7545  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 2.2469  Validation loss = 4.7541  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 2.2467  Validation loss = 4.7537  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 2.2465  Validation loss = 4.7533  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 2.2463  Validation loss = 4.7530  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 2.2460  Validation loss = 4.7525  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 2.2458  Validation loss = 4.7521  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 2.2456  Validation loss = 4.7518  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 2.2454  Validation loss = 4.7514  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 2.2453  Validation loss = 4.7512  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 2.2451  Validation loss = 4.7508  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 2.2449  Validation loss = 4.7505  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 2.2447  Validation loss = 4.7501  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 2.2444  Validation loss = 4.7497  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 2.2442  Validation loss = 4.7493  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 2.2441  Validation loss = 4.7490  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 2.2439  Validation loss = 4.7487  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 2.2437  Validation loss = 4.7484  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 2.2435  Validation loss = 4.7480  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 2.2433  Validation loss = 4.7477  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 2.2431  Validation loss = 4.7473  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 2.2429  Validation loss = 4.7470  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 2.2427  Validation loss = 4.7467  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 2.2425  Validation loss = 4.7464  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 2.2423  Validation loss = 4.7461  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 2.2421  Validation loss = 4.7457  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 2.2420  Validation loss = 4.7455  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 2.2418  Validation loss = 4.7452  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 2.2416  Validation loss = 4.7448  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 2.2413  Validation loss = 4.7444  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 2.2411  Validation loss = 4.7439  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 2.2408  Validation loss = 4.7435  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 2.2407  Validation loss = 4.7432  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 2.2404  Validation loss = 4.7427  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 2.2402  Validation loss = 4.7423  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 2.2400  Validation loss = 4.7419  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 2.2397  Validation loss = 4.7415  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 2.2396  Validation loss = 4.7412  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 2.2394  Validation loss = 4.7409  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 2.2391  Validation loss = 4.7405  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 2.2389  Validation loss = 4.7402  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 2.2387  Validation loss = 4.7398  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 2.2385  Validation loss = 4.7395  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 2.2384  Validation loss = 4.7392  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 2.2381  Validation loss = 4.7388  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 2.2380  Validation loss = 4.7384  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 2.2378  Validation loss = 4.7381  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 2.2375  Validation loss = 4.7377  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 2.2373  Validation loss = 4.7372  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 2.2370  Validation loss = 4.7368  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 2.2368  Validation loss = 4.7364  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 2.2366  Validation loss = 4.7360  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 2.2365  Validation loss = 4.7358  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 2.2363  Validation loss = 4.7355  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 2.2361  Validation loss = 4.7352  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 2.2359  Validation loss = 4.7348  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 2.2357  Validation loss = 4.7344  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 2.2355  Validation loss = 4.7340  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 2.2353  Validation loss = 4.7337  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 2.2352  Validation loss = 4.7334  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 2.2350  Validation loss = 4.7332  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 2.2348  Validation loss = 4.7328  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 2.2346  Validation loss = 4.7325  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 2.2345  Validation loss = 4.7322  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 2.2343  Validation loss = 4.7319  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 2.2340  Validation loss = 4.7314  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 2.2339  Validation loss = 4.7311  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 2.2337  Validation loss = 4.7309  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 2.2335  Validation loss = 4.7305  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 2.2333  Validation loss = 4.7302  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 2.2331  Validation loss = 4.7298  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 2.2330  Validation loss = 4.7296  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 2.2328  Validation loss = 4.7293  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 2.2326  Validation loss = 4.7289  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 2.2325  Validation loss = 4.7287  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 2.2323  Validation loss = 4.7284  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 2.2321  Validation loss = 4.7281  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 2.2319  Validation loss = 4.7277  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 2.2317  Validation loss = 4.7273  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 2.2316  Validation loss = 4.7271  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 2.2313  Validation loss = 4.7267  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 2.2312  Validation loss = 4.7265  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 2.2309  Validation loss = 4.7260  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 2.2307  Validation loss = 4.7257  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 2.2305  Validation loss = 4.7251  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 2.2303  Validation loss = 4.7248  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 2.2301  Validation loss = 4.7245  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 2.2299  Validation loss = 4.7241  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 2.2296  Validation loss = 4.7237  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 2.2294  Validation loss = 4.7232  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 2.2292  Validation loss = 4.7230  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 2.2290  Validation loss = 4.7226  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 2.2288  Validation loss = 4.7222  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 2.2286  Validation loss = 4.7219  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 2.2285  Validation loss = 4.7216  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 2.2283  Validation loss = 4.7213  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 2.2281  Validation loss = 4.7210  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 2.2279  Validation loss = 4.7206  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 2.2277  Validation loss = 4.7203  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 2.2275  Validation loss = 4.7199  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 2.2273  Validation loss = 4.7196  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 2.2272  Validation loss = 4.7194  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 2.2270  Validation loss = 4.7191  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 2.2268  Validation loss = 4.7187  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 2.2266  Validation loss = 4.7184  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 2.2264  Validation loss = 4.7180  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 2.2262  Validation loss = 4.7176  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 2.2260  Validation loss = 4.7173  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 2.2258  Validation loss = 4.7170  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 2.2257  Validation loss = 4.7167  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 2.2255  Validation loss = 4.7163  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 2.2253  Validation loss = 4.7160  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 2.2251  Validation loss = 4.7157  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 2.2249  Validation loss = 4.7153  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 2.2247  Validation loss = 4.7149  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 2.2245  Validation loss = 4.7146  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 2.2243  Validation loss = 4.7143  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 2.2241  Validation loss = 4.7139  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 2.2240  Validation loss = 4.7136  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 2.2238  Validation loss = 4.7133  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 2.2235  Validation loss = 4.7129  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 2.2234  Validation loss = 4.7126  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 2.2232  Validation loss = 4.7123  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 2.2230  Validation loss = 4.7119  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 2.2228  Validation loss = 4.7116  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 2.2226  Validation loss = 4.7112  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 2.2224  Validation loss = 4.7108  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 2.2221  Validation loss = 4.7104  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 2.2219  Validation loss = 4.7100  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 2.2217  Validation loss = 4.7097  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 2.2215  Validation loss = 4.7093  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 2.2213  Validation loss = 4.7089  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 2.2211  Validation loss = 4.7086  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 2.2209  Validation loss = 4.7082  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 2.2207  Validation loss = 4.7078  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 2.2205  Validation loss = 4.7074  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 2.2203  Validation loss = 4.7071  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 2.2201  Validation loss = 4.7068  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 2.2199  Validation loss = 4.7065  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 2.2197  Validation loss = 4.7062  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 2.2195  Validation loss = 4.7057  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 2.2193  Validation loss = 4.7053  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 2.2191  Validation loss = 4.7049  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 2.2189  Validation loss = 4.7046  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 2.2188  Validation loss = 4.7044  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 2.2185  Validation loss = 4.7040  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 2.2183  Validation loss = 4.7037  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 2.2182  Validation loss = 4.7033  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 2.2180  Validation loss = 4.7030  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 2.2177  Validation loss = 4.7026  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 2.2175  Validation loss = 4.7022  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 2.2174  Validation loss = 4.7019  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 2.2172  Validation loss = 4.7016  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 2.2170  Validation loss = 4.7012  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 2.2168  Validation loss = 4.7009  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 2.2166  Validation loss = 4.7006  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 2.2164  Validation loss = 4.7003  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 2.2163  Validation loss = 4.7001  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 2.2161  Validation loss = 4.6997  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 2.2159  Validation loss = 4.6993  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 2.2158  Validation loss = 4.6990  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 2.2155  Validation loss = 4.6986  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 2.2153  Validation loss = 4.6982  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 2.2151  Validation loss = 4.6979  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 2.2150  Validation loss = 4.6976  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 2.2148  Validation loss = 4.6974  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 2.2147  Validation loss = 4.6971  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 2.2145  Validation loss = 4.6968  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 2.2143  Validation loss = 4.6964  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 2.2141  Validation loss = 4.6960  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 2.2139  Validation loss = 4.6956  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 2.2137  Validation loss = 4.6952  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 2.2135  Validation loss = 4.6950  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 2.2134  Validation loss = 4.6947  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 2.2132  Validation loss = 4.6944  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 2.2130  Validation loss = 4.6940  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 2.2128  Validation loss = 4.6937  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 2.2127  Validation loss = 4.6934  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 2.2125  Validation loss = 4.6930  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 2.2122  Validation loss = 4.6926  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 2.2120  Validation loss = 4.6922  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 2.2118  Validation loss = 4.6919  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 2.2116  Validation loss = 4.6915  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 2.2115  Validation loss = 4.6912  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 2.2112  Validation loss = 4.6908  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 2.2110  Validation loss = 4.6904  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 2.2108  Validation loss = 4.6900  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 2.2107  Validation loss = 4.6898  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 2.2105  Validation loss = 4.6894  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 2.2103  Validation loss = 4.6891  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 2.2101  Validation loss = 4.6887  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 2.2099  Validation loss = 4.6884  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 2.2098  Validation loss = 4.6881  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 2.2096  Validation loss = 4.6878  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 2.2094  Validation loss = 4.6875  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 2.2092  Validation loss = 4.6871  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 2.2090  Validation loss = 4.6868  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 2.2088  Validation loss = 4.6864  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 2.2087  Validation loss = 4.6861  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 2.2085  Validation loss = 4.6858  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 2.2083  Validation loss = 4.6854  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 2.2081  Validation loss = 4.6850  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 2.2080  Validation loss = 4.6848  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 2.2078  Validation loss = 4.6845  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 2.2076  Validation loss = 4.6842  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 2.2074  Validation loss = 4.6838  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 2.2073  Validation loss = 4.6836  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 2.2071  Validation loss = 4.6833  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 2.2070  Validation loss = 4.6830  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 2.2068  Validation loss = 4.6828  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 2.2067  Validation loss = 4.6826  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 2.2065  Validation loss = 4.6822  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 2.2063  Validation loss = 4.6818  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 2.2061  Validation loss = 4.6814  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 2.2059  Validation loss = 4.6812  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 2.2058  Validation loss = 4.6809  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 2.2056  Validation loss = 4.6806  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 2.2054  Validation loss = 4.6802  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 2.2052  Validation loss = 4.6799  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 2.2051  Validation loss = 4.6796  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 2.2048  Validation loss = 4.6792  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 2.2047  Validation loss = 4.6789  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 2.2044  Validation loss = 4.6784  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 2.2042  Validation loss = 4.6780  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 2.2039  Validation loss = 4.6775  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 2.2037  Validation loss = 4.6772  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 2.2036  Validation loss = 4.6769  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 2.2034  Validation loss = 4.6766  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 2.2033  Validation loss = 4.6764  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 2.2032  Validation loss = 4.6761  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 2.2030  Validation loss = 4.6759  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 2.2028  Validation loss = 4.6755  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 2.2026  Validation loss = 4.6752  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 2.2024  Validation loss = 4.6748  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 2.2023  Validation loss = 4.6745  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 2.2020  Validation loss = 4.6740  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 2.2018  Validation loss = 4.6736  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 2.2016  Validation loss = 4.6732  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 2.2014  Validation loss = 4.6729  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 2.2012  Validation loss = 4.6726  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 2.2010  Validation loss = 4.6722  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 2.2008  Validation loss = 4.6718  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 2.2006  Validation loss = 4.6715  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 2.2004  Validation loss = 4.6711  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 2.2003  Validation loss = 4.6709  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 2.2001  Validation loss = 4.6705  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 2.1999  Validation loss = 4.6702  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 2.1997  Validation loss = 4.6697  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 2.1995  Validation loss = 4.6694  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 2.1993  Validation loss = 4.6691  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 2.1992  Validation loss = 4.6689  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 2.1990  Validation loss = 4.6686  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 2.1988  Validation loss = 4.6682  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 2.1986  Validation loss = 4.6678  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 2.1984  Validation loss = 4.6675  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 2.1982  Validation loss = 4.6671  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 2.1980  Validation loss = 4.6668  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 2.1979  Validation loss = 4.6665  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 2.1977  Validation loss = 4.6662  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 2.1975  Validation loss = 4.6658  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 2.1973  Validation loss = 4.6654  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 2.1971  Validation loss = 4.6650  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 2.1969  Validation loss = 4.6647  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 2.1967  Validation loss = 4.6644  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 2.1965  Validation loss = 4.6640  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 2.1964  Validation loss = 4.6638  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 2.1962  Validation loss = 4.6634  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 2.1960  Validation loss = 4.6630  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 2.1958  Validation loss = 4.6627  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 2.1957  Validation loss = 4.6625  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 2.1956  Validation loss = 4.6622  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 2.1954  Validation loss = 4.6619  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 2.1952  Validation loss = 4.6616  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 2.1950  Validation loss = 4.6613  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 2.1948  Validation loss = 4.6609  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 2.1946  Validation loss = 4.6606  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 2.1944  Validation loss = 4.6602  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 2.1943  Validation loss = 4.6599  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 2.1940  Validation loss = 4.6594  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 2.1938  Validation loss = 4.6591  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 2.1936  Validation loss = 4.6587  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 2.1934  Validation loss = 4.6584  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 2.1932  Validation loss = 4.6581  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 2.1931  Validation loss = 4.6577  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 2.1929  Validation loss = 4.6574  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 2.1927  Validation loss = 4.6572  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 2.1926  Validation loss = 4.6569  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 2.1924  Validation loss = 4.6565  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 2.1922  Validation loss = 4.6562  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 2.1920  Validation loss = 4.6558  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 2.1918  Validation loss = 4.6555  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 2.1916  Validation loss = 4.6551  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 2.1914  Validation loss = 4.6548  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 2.1912  Validation loss = 4.6544  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 2.1911  Validation loss = 4.6541  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 2.1908  Validation loss = 4.6537  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 2.1907  Validation loss = 4.6534  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 2.1905  Validation loss = 4.6532  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 2.1903  Validation loss = 4.6528  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 2.1901  Validation loss = 4.6523  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 2.1899  Validation loss = 4.6519  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 2.1897  Validation loss = 4.6516  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 2.1895  Validation loss = 4.6513  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 2.1893  Validation loss = 4.6509  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 2.1891  Validation loss = 4.6506  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 2.1890  Validation loss = 4.6503  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 2.1888  Validation loss = 4.6500  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 2.1886  Validation loss = 4.6497  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 2.1884  Validation loss = 4.6493  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 2.1882  Validation loss = 4.6490  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 2.1881  Validation loss = 4.6486  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 2.1879  Validation loss = 4.6484  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 2.1877  Validation loss = 4.6480  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 2.1875  Validation loss = 4.6477  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 2.1874  Validation loss = 4.6474  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 2.1872  Validation loss = 4.6471  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 2.1871  Validation loss = 4.6468  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 2.1868  Validation loss = 4.6464  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 2.1866  Validation loss = 4.6460  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 2.1865  Validation loss = 4.6458  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 2.1863  Validation loss = 4.6454  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 2.1862  Validation loss = 4.6451  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 2.1860  Validation loss = 4.6448  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 2.1857  Validation loss = 4.6444  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 2.1856  Validation loss = 4.6441  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 2.1854  Validation loss = 4.6437  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 2.1852  Validation loss = 4.6435  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 2.1850  Validation loss = 4.6431  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 2.1849  Validation loss = 4.6428  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 2.1847  Validation loss = 4.6424  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 2.1845  Validation loss = 4.6420  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 2.1843  Validation loss = 4.6416  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 2.1841  Validation loss = 4.6413  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 2.1840  Validation loss = 4.6412  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 2.1838  Validation loss = 4.6408  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 2.1836  Validation loss = 4.6404  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 2.1834  Validation loss = 4.6401  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 2.1833  Validation loss = 4.6398  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 2.1831  Validation loss = 4.6395  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 2.1829  Validation loss = 4.6393  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 2.1827  Validation loss = 4.6388  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 2.1825  Validation loss = 4.6384  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 2.1823  Validation loss = 4.6381  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 2.1822  Validation loss = 4.6378  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 2.1820  Validation loss = 4.6375  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 2.1818  Validation loss = 4.6372  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 2.1817  Validation loss = 4.6369  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 2.1815  Validation loss = 4.6366  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 2.1813  Validation loss = 4.6363  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 2.1812  Validation loss = 4.6359  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 2.1810  Validation loss = 4.6356  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 2.1808  Validation loss = 4.6353  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 2.1806  Validation loss = 4.6350  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 2.1805  Validation loss = 4.6348  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 2.1803  Validation loss = 4.6344  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 2.1801  Validation loss = 4.6341  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 2.1800  Validation loss = 4.6337  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 2.1798  Validation loss = 4.6335  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 2.1797  Validation loss = 4.6332  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 2.1794  Validation loss = 4.6327  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 2.1792  Validation loss = 4.6324  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 2.1791  Validation loss = 4.6321  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 2.1789  Validation loss = 4.6318  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 2.1787  Validation loss = 4.6315  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 2.1786  Validation loss = 4.6312  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 2.1784  Validation loss = 4.6309  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 2.1782  Validation loss = 4.6306  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 2.1781  Validation loss = 4.6303  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 2.1779  Validation loss = 4.6300  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 2.1777  Validation loss = 4.6296  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 2.1775  Validation loss = 4.6293  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 2.1774  Validation loss = 4.6290  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 2.1772  Validation loss = 4.6288  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 2.1770  Validation loss = 4.6284  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 2.1768  Validation loss = 4.6281  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 2.1767  Validation loss = 4.6277  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 2.1765  Validation loss = 4.6274  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 2.1763  Validation loss = 4.6272  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 2.1762  Validation loss = 4.6269  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 2.1760  Validation loss = 4.6265  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 2.1758  Validation loss = 4.6262  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 2.1757  Validation loss = 4.6259  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 2.1755  Validation loss = 4.6255  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 2.1753  Validation loss = 4.6252  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 2.1752  Validation loss = 4.6249  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 2.1750  Validation loss = 4.6247  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 2.1749  Validation loss = 4.6244  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 2.1748  Validation loss = 4.6242  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 2.1746  Validation loss = 4.6239  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 2.1744  Validation loss = 4.6236  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 2.1742  Validation loss = 4.6232  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 2.1740  Validation loss = 4.6229  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 2.1739  Validation loss = 4.6225  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 2.1737  Validation loss = 4.6221  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 2.1735  Validation loss = 4.6219  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 2.1733  Validation loss = 4.6214  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 2.1731  Validation loss = 4.6210  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 2.1728  Validation loss = 4.6206  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 2.1726  Validation loss = 4.6202  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 2.1725  Validation loss = 4.6200  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 2.1724  Validation loss = 4.6197  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 2.1722  Validation loss = 4.6194  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 2.1720  Validation loss = 4.6191  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 2.1718  Validation loss = 4.6187  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 2.1717  Validation loss = 4.6185  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 2.1715  Validation loss = 4.6182  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 2.1713  Validation loss = 4.6178  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 2.1712  Validation loss = 4.6176  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 2.1710  Validation loss = 4.6172  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 2.1708  Validation loss = 4.6169  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 2.1707  Validation loss = 4.6166  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 2.1705  Validation loss = 4.6162  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 2.1703  Validation loss = 4.6158  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 2.1701  Validation loss = 4.6156  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 2.1700  Validation loss = 4.6153  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 2.1698  Validation loss = 4.6150  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 2.1696  Validation loss = 4.6146  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 2.1695  Validation loss = 4.6144  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 2.1693  Validation loss = 4.6140  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 2.1691  Validation loss = 4.6138  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 2.1689  Validation loss = 4.6134  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 2.1688  Validation loss = 4.6131  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 2.1686  Validation loss = 4.6128  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 2.1684  Validation loss = 4.6124  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 2.1682  Validation loss = 4.6120  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 2.1680  Validation loss = 4.6117  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 2.1678  Validation loss = 4.6113  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 2.1676  Validation loss = 4.6110  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 2.1675  Validation loss = 4.6108  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 2.1673  Validation loss = 4.6104  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 2.1671  Validation loss = 4.6101  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 2.1670  Validation loss = 4.6098  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 2.1668  Validation loss = 4.6094  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 2.1666  Validation loss = 4.6091  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 2.1664  Validation loss = 4.6088  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 2.1663  Validation loss = 4.6085  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 2.1662  Validation loss = 4.6083  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 2.1660  Validation loss = 4.6080  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 2.1658  Validation loss = 4.6076  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 2.1656  Validation loss = 4.6073  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 2.1654  Validation loss = 4.6069  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 2.1652  Validation loss = 4.6065  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 2.1651  Validation loss = 4.6062  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 2.1649  Validation loss = 4.6058  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 2.1647  Validation loss = 4.6054  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 2.1645  Validation loss = 4.6052  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 2.1644  Validation loss = 4.6049  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 2.1642  Validation loss = 4.6045  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 2.1640  Validation loss = 4.6042  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 2.1638  Validation loss = 4.6039  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 2.1637  Validation loss = 4.6036  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 2.1635  Validation loss = 4.6033  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 2.1633  Validation loss = 4.6029  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 2.1631  Validation loss = 4.6025  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 2.1629  Validation loss = 4.6022  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 2.1628  Validation loss = 4.6019  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 2.1626  Validation loss = 4.6016  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 2.1624  Validation loss = 4.6012  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 2.1622  Validation loss = 4.6007  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 2.1620  Validation loss = 4.6004  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 2.1618  Validation loss = 4.5999  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 2.1616  Validation loss = 4.5996  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 2.1614  Validation loss = 4.5992  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 2.1612  Validation loss = 4.5989  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.4258  Validation loss = 2.4620  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.4256  Validation loss = 2.4616  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.4254  Validation loss = 2.4612  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.4252  Validation loss = 2.4609  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.4249  Validation loss = 2.4605  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.4247  Validation loss = 2.4601  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.4244  Validation loss = 2.4596  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.4241  Validation loss = 2.4592  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.4239  Validation loss = 2.4587  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.4236  Validation loss = 2.4583  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.4234  Validation loss = 2.4580  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.4232  Validation loss = 2.4576  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.4230  Validation loss = 2.4572  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.4228  Validation loss = 2.4569  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.4225  Validation loss = 2.4565  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.4222  Validation loss = 2.4560  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.4220  Validation loss = 2.4556  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.4217  Validation loss = 2.4552  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.4216  Validation loss = 2.4550  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.4214  Validation loss = 2.4546  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.4211  Validation loss = 2.4542  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.4208  Validation loss = 2.4537  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.4206  Validation loss = 2.4533  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.4204  Validation loss = 2.4530  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.4202  Validation loss = 2.4526  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.4199  Validation loss = 2.4522  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.4197  Validation loss = 2.4518  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.4194  Validation loss = 2.4514  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.4192  Validation loss = 2.4509  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.4189  Validation loss = 2.4505  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.4186  Validation loss = 2.4501  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.4184  Validation loss = 2.4496  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.4182  Validation loss = 2.4493  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.4179  Validation loss = 2.4489  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.4177  Validation loss = 2.4484  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.4174  Validation loss = 2.4480  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.4171  Validation loss = 2.4475  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.4169  Validation loss = 2.4471  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.4167  Validation loss = 2.4468  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.4165  Validation loss = 2.4465  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.4163  Validation loss = 2.4461  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.4161  Validation loss = 2.4458  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.4158  Validation loss = 2.4454  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.4156  Validation loss = 2.4450  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.4154  Validation loss = 2.4446  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.4152  Validation loss = 2.4443  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.4149  Validation loss = 2.4439  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.4147  Validation loss = 2.4436  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.4145  Validation loss = 2.4432  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.4142  Validation loss = 2.4427  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.4140  Validation loss = 2.4423  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.4137  Validation loss = 2.4418  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.4135  Validation loss = 2.4415  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.4132  Validation loss = 2.4411  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.4130  Validation loss = 2.4406  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.4128  Validation loss = 2.4403  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.4125  Validation loss = 2.4398  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.4123  Validation loss = 2.4394  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.4120  Validation loss = 2.4390  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.4118  Validation loss = 2.4386  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.4115  Validation loss = 2.4382  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.4113  Validation loss = 2.4378  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.4111  Validation loss = 2.4374  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.4108  Validation loss = 2.4370  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.4106  Validation loss = 2.4366  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.4103  Validation loss = 2.4362  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.4101  Validation loss = 2.4358  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.4098  Validation loss = 2.4354  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.4096  Validation loss = 2.4350  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.4094  Validation loss = 2.4346  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.4091  Validation loss = 2.4342  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.4089  Validation loss = 2.4338  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.4086  Validation loss = 2.4334  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.4084  Validation loss = 2.4330  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.4082  Validation loss = 2.4326  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.4079  Validation loss = 2.4322  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.4077  Validation loss = 2.4318  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.4074  Validation loss = 2.4314  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.4072  Validation loss = 2.4309  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.4069  Validation loss = 2.4305  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.4067  Validation loss = 2.4301  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.4064  Validation loss = 2.4296  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.4062  Validation loss = 2.4293  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.4060  Validation loss = 2.4289  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.4057  Validation loss = 2.4285  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.4054  Validation loss = 2.4279  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.4051  Validation loss = 2.4276  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.4049  Validation loss = 2.4271  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.4046  Validation loss = 2.4267  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.4044  Validation loss = 2.4263  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.4041  Validation loss = 2.4259  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.4039  Validation loss = 2.4255  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.4037  Validation loss = 2.4251  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.4034  Validation loss = 2.4247  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.4032  Validation loss = 2.4243  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.4029  Validation loss = 2.4238  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.4027  Validation loss = 2.4235  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.4025  Validation loss = 2.4231  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.4022  Validation loss = 2.4227  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.4020  Validation loss = 2.4223  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.4018  Validation loss = 2.4219  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.4015  Validation loss = 2.4214  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.4013  Validation loss = 2.4211  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.4010  Validation loss = 2.4207  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.4008  Validation loss = 2.4203  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.4005  Validation loss = 2.4198  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.4003  Validation loss = 2.4194  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.4001  Validation loss = 2.4191  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.3998  Validation loss = 2.4187  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.3996  Validation loss = 2.4183  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.3993  Validation loss = 2.4178  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.3991  Validation loss = 2.4175  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.3989  Validation loss = 2.4171  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.3986  Validation loss = 2.4167  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.3984  Validation loss = 2.4163  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.3982  Validation loss = 2.4159  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.3979  Validation loss = 2.4155  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.3977  Validation loss = 2.4151  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.3975  Validation loss = 2.4148  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.3973  Validation loss = 2.4143  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.3970  Validation loss = 2.4139  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.3967  Validation loss = 2.4135  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.3965  Validation loss = 2.4130  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.3962  Validation loss = 2.4126  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.3960  Validation loss = 2.4122  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.3958  Validation loss = 2.4118  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.3955  Validation loss = 2.4113  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.3953  Validation loss = 2.4110  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.3950  Validation loss = 2.4106  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.3948  Validation loss = 2.4101  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.3946  Validation loss = 2.4098  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.3944  Validation loss = 2.4095  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.3942  Validation loss = 2.4092  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.3939  Validation loss = 2.4088  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.3937  Validation loss = 2.4084  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.3935  Validation loss = 2.4080  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.3933  Validation loss = 2.4076  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.3930  Validation loss = 2.4072  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.3927  Validation loss = 2.4067  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.3924  Validation loss = 2.4062  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.3922  Validation loss = 2.4058  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.3920  Validation loss = 2.4055  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.3918  Validation loss = 2.4051  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.3915  Validation loss = 2.4047  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.3912  Validation loss = 2.4041  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.3910  Validation loss = 2.4037  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.3908  Validation loss = 2.4034  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.3905  Validation loss = 2.4030  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.3902  Validation loss = 2.4025  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.3901  Validation loss = 2.4022  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.3898  Validation loss = 2.4018  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.3896  Validation loss = 2.4014  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.3893  Validation loss = 2.4009  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.3891  Validation loss = 2.4005  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.3888  Validation loss = 2.4000  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.3886  Validation loss = 2.3997  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.3883  Validation loss = 2.3992  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.3880  Validation loss = 2.3988  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.3878  Validation loss = 2.3984  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.3875  Validation loss = 2.3980  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.3874  Validation loss = 2.3977  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.3871  Validation loss = 2.3972  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.3869  Validation loss = 2.3969  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.3867  Validation loss = 2.3965  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.3865  Validation loss = 2.3962  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.3863  Validation loss = 2.3959  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.3861  Validation loss = 2.3955  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.3858  Validation loss = 2.3951  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.3856  Validation loss = 2.3946  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.3853  Validation loss = 2.3942  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.3850  Validation loss = 2.3937  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.3848  Validation loss = 2.3933  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.3846  Validation loss = 2.3930  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.3844  Validation loss = 2.3927  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.3842  Validation loss = 2.3922  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.3840  Validation loss = 2.3919  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.3837  Validation loss = 2.3914  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.3834  Validation loss = 2.3910  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.3832  Validation loss = 2.3905  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.3829  Validation loss = 2.3901  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.3827  Validation loss = 2.3897  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.3824  Validation loss = 2.3893  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.3822  Validation loss = 2.3889  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.3819  Validation loss = 2.3884  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.3816  Validation loss = 2.3879  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.3814  Validation loss = 2.3876  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.3812  Validation loss = 2.3872  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.3810  Validation loss = 2.3868  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.3808  Validation loss = 2.3865  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.3805  Validation loss = 2.3861  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.3803  Validation loss = 2.3858  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.3801  Validation loss = 2.3854  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.3799  Validation loss = 2.3849  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.3796  Validation loss = 2.3845  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.3794  Validation loss = 2.3841  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.3791  Validation loss = 2.3836  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.3788  Validation loss = 2.3832  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.3786  Validation loss = 2.3829  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.3785  Validation loss = 2.3825  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.3783  Validation loss = 2.3822  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.3781  Validation loss = 2.3819  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.3778  Validation loss = 2.3815  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.3776  Validation loss = 2.3810  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.3773  Validation loss = 2.3806  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.3771  Validation loss = 2.3803  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.3769  Validation loss = 2.3798  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 2.3767  Validation loss = 2.3795  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 2.3764  Validation loss = 2.3791  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 2.3762  Validation loss = 2.3788  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 2.3760  Validation loss = 2.3784  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 2.3758  Validation loss = 2.3780  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 2.3755  Validation loss = 2.3775  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 2.3752  Validation loss = 2.3770  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 2.3750  Validation loss = 2.3767  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 2.3747  Validation loss = 2.3762  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 2.3745  Validation loss = 2.3758  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 2.3743  Validation loss = 2.3755  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 2.3741  Validation loss = 2.3752  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 2.3738  Validation loss = 2.3747  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 2.3736  Validation loss = 2.3743  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 2.3734  Validation loss = 2.3740  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 2.3732  Validation loss = 2.3736  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 2.3730  Validation loss = 2.3733  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 2.3727  Validation loss = 2.3728  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 2.3724  Validation loss = 2.3723  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 2.3722  Validation loss = 2.3719  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 2.3720  Validation loss = 2.3716  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 2.3717  Validation loss = 2.3711  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 2.3715  Validation loss = 2.3708  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 2.3713  Validation loss = 2.3705  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 2.3710  Validation loss = 2.3699  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 2.3708  Validation loss = 2.3696  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 2.3707  Validation loss = 2.3693  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 2.3704  Validation loss = 2.3689  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 2.3702  Validation loss = 2.3685  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 2.3700  Validation loss = 2.3682  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 2.3697  Validation loss = 2.3677  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 2.3695  Validation loss = 2.3674  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 2.3692  Validation loss = 2.3669  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 2.3690  Validation loss = 2.3665  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 2.3688  Validation loss = 2.3661  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 2.3685  Validation loss = 2.3657  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 2.3683  Validation loss = 2.3652  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 2.3681  Validation loss = 2.3649  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 2.3678  Validation loss = 2.3645  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 2.3676  Validation loss = 2.3641  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 2.3673  Validation loss = 2.3636  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 2.3671  Validation loss = 2.3632  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 2.3668  Validation loss = 2.3628  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 2.3666  Validation loss = 2.3624  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 2.3664  Validation loss = 2.3620  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 2.3661  Validation loss = 2.3615  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 2.3659  Validation loss = 2.3612  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 2.3656  Validation loss = 2.3607  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 2.3654  Validation loss = 2.3604  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 2.3652  Validation loss = 2.3600  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 2.3649  Validation loss = 2.3596  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 2.3647  Validation loss = 2.3592  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 2.3645  Validation loss = 2.3588  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 2.3642  Validation loss = 2.3583  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 2.3640  Validation loss = 2.3580  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 2.3638  Validation loss = 2.3576  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 2.3634  Validation loss = 2.3570  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 2.3632  Validation loss = 2.3566  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 2.3629  Validation loss = 2.3562  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 2.3627  Validation loss = 2.3558  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 2.3625  Validation loss = 2.3555  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 2.3623  Validation loss = 2.3551  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 2.3621  Validation loss = 2.3547  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 2.3618  Validation loss = 2.3543  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 2.3616  Validation loss = 2.3540  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 2.3614  Validation loss = 2.3536  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 2.3612  Validation loss = 2.3531  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 2.3609  Validation loss = 2.3527  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 2.3607  Validation loss = 2.3523  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 2.3604  Validation loss = 2.3519  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 2.3602  Validation loss = 2.3515  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 2.3599  Validation loss = 2.3510  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 2.3597  Validation loss = 2.3506  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 2.3595  Validation loss = 2.3503  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 2.3593  Validation loss = 2.3500  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 2.3591  Validation loss = 2.3496  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 2.3589  Validation loss = 2.3493  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 2.3587  Validation loss = 2.3489  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 2.3584  Validation loss = 2.3485  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 2.3581  Validation loss = 2.3479  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 2.3579  Validation loss = 2.3476  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 2.3577  Validation loss = 2.3472  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 2.3574  Validation loss = 2.3467  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 2.3572  Validation loss = 2.3464  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 2.3569  Validation loss = 2.3459  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 2.3567  Validation loss = 2.3455  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 2.3564  Validation loss = 2.3451  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 2.3562  Validation loss = 2.3447  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 2.3560  Validation loss = 2.3443  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 2.3558  Validation loss = 2.3440  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 2.3556  Validation loss = 2.3437  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 2.3554  Validation loss = 2.3433  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 2.3552  Validation loss = 2.3429  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 2.3550  Validation loss = 2.3426  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 2.3547  Validation loss = 2.3422  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 2.3546  Validation loss = 2.3419  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 2.3544  Validation loss = 2.3416  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 2.3542  Validation loss = 2.3413  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 2.3539  Validation loss = 2.3408  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 2.3537  Validation loss = 2.3404  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 2.3534  Validation loss = 2.3400  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 2.3532  Validation loss = 2.3396  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 2.3529  Validation loss = 2.3391  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 2.3527  Validation loss = 2.3388  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 2.3525  Validation loss = 2.3383  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 2.3523  Validation loss = 2.3380  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 2.3521  Validation loss = 2.3377  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 2.3519  Validation loss = 2.3373  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 2.3517  Validation loss = 2.3370  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 2.3515  Validation loss = 2.3366  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 2.3512  Validation loss = 2.3361  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 2.3510  Validation loss = 2.3358  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 2.3509  Validation loss = 2.3356  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 2.3507  Validation loss = 2.3352  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 2.3504  Validation loss = 2.3349  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 2.3501  Validation loss = 2.3343  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 2.3499  Validation loss = 2.3339  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 2.3496  Validation loss = 2.3334  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 2.3493  Validation loss = 2.3330  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 2.3491  Validation loss = 2.3326  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 2.3489  Validation loss = 2.3322  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 2.3487  Validation loss = 2.3318  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 2.3484  Validation loss = 2.3313  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 2.3482  Validation loss = 2.3310  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 2.3479  Validation loss = 2.3305  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 2.3477  Validation loss = 2.3301  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 2.3474  Validation loss = 2.3296  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 2.3472  Validation loss = 2.3293  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 2.3471  Validation loss = 2.3290  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 2.3469  Validation loss = 2.3287  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 2.3467  Validation loss = 2.3283  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 2.3464  Validation loss = 2.3279  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 2.3462  Validation loss = 2.3275  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 2.3460  Validation loss = 2.3272  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 2.3458  Validation loss = 2.3269  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 2.3455  Validation loss = 2.3264  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 2.3453  Validation loss = 2.3260  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 2.3451  Validation loss = 2.3257  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 2.3449  Validation loss = 2.3253  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 2.3446  Validation loss = 2.3248  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 2.3444  Validation loss = 2.3245  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 2.3443  Validation loss = 2.3242  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 2.3440  Validation loss = 2.3238  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 2.3437  Validation loss = 2.3233  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 2.3434  Validation loss = 2.3228  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 2.3432  Validation loss = 2.3224  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 2.3430  Validation loss = 2.3220  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 2.3428  Validation loss = 2.3217  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 2.3426  Validation loss = 2.3214  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 2.3424  Validation loss = 2.3210  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 2.3422  Validation loss = 2.3207  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 2.3420  Validation loss = 2.3204  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 2.3418  Validation loss = 2.3199  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 2.3416  Validation loss = 2.3196  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 2.3414  Validation loss = 2.3192  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 2.3412  Validation loss = 2.3188  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 2.3409  Validation loss = 2.3184  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 2.3407  Validation loss = 2.3181  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 2.3405  Validation loss = 2.3177  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 2.3403  Validation loss = 2.3173  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 2.3400  Validation loss = 2.3169  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 2.3398  Validation loss = 2.3165  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 2.3395  Validation loss = 2.3161  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 2.3393  Validation loss = 2.3157  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 2.3392  Validation loss = 2.3154  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 2.3389  Validation loss = 2.3150  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 2.3387  Validation loss = 2.3146  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 2.3385  Validation loss = 2.3142  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 2.3383  Validation loss = 2.3140  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 2.3382  Validation loss = 2.3137  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 2.3379  Validation loss = 2.3133  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 2.3377  Validation loss = 2.3129  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 2.3375  Validation loss = 2.3125  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 2.3373  Validation loss = 2.3121  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 2.3370  Validation loss = 2.3117  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 2.3369  Validation loss = 2.3114  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 2.3366  Validation loss = 2.3110  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 2.3363  Validation loss = 2.3106  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 2.3362  Validation loss = 2.3102  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 2.3359  Validation loss = 2.3098  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 2.3357  Validation loss = 2.3094  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 2.3354  Validation loss = 2.3090  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 2.3352  Validation loss = 2.3086  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 2.3350  Validation loss = 2.3081  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 2.3347  Validation loss = 2.3078  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 2.3346  Validation loss = 2.3075  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 2.3344  Validation loss = 2.3071  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 2.3341  Validation loss = 2.3067  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 2.3339  Validation loss = 2.3063  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 2.3337  Validation loss = 2.3060  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 2.3334  Validation loss = 2.3055  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 2.3332  Validation loss = 2.3051  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 2.3330  Validation loss = 2.3047  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 2.3328  Validation loss = 2.3044  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 2.3326  Validation loss = 2.3040  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 2.3323  Validation loss = 2.3036  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 2.3321  Validation loss = 2.3031  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 2.3318  Validation loss = 2.3027  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 2.3316  Validation loss = 2.3023  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 2.3314  Validation loss = 2.3019  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 2.3312  Validation loss = 2.3016  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 2.3309  Validation loss = 2.3012  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 2.3308  Validation loss = 2.3009  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 2.3305  Validation loss = 2.3005  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 2.3304  Validation loss = 2.3002  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 2.3301  Validation loss = 2.2998  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 2.3299  Validation loss = 2.2993  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 2.3296  Validation loss = 2.2989  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 2.3293  Validation loss = 2.2984  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 2.3291  Validation loss = 2.2981  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 2.3289  Validation loss = 2.2977  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 2.3287  Validation loss = 2.2972  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 2.3285  Validation loss = 2.2969  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 2.3283  Validation loss = 2.2966  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 2.3280  Validation loss = 2.2961  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 2.3278  Validation loss = 2.2958  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 2.3276  Validation loss = 2.2955  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 2.3275  Validation loss = 2.2951  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 2.3273  Validation loss = 2.2948  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 2.3270  Validation loss = 2.2944  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 2.3269  Validation loss = 2.2941  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 2.3267  Validation loss = 2.2938  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 2.3264  Validation loss = 2.2933  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 2.3262  Validation loss = 2.2930  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 2.3260  Validation loss = 2.2926  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 2.3258  Validation loss = 2.2922  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 2.3256  Validation loss = 2.2919  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 2.3253  Validation loss = 2.2914  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 2.3251  Validation loss = 2.2910  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 2.3248  Validation loss = 2.2905  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 2.3246  Validation loss = 2.2902  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 2.3244  Validation loss = 2.2899  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 2.3242  Validation loss = 2.2895  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 2.3239  Validation loss = 2.2890  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 2.3237  Validation loss = 2.2886  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 2.3235  Validation loss = 2.2883  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 2.3233  Validation loss = 2.2879  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 2.3230  Validation loss = 2.2874  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 2.3228  Validation loss = 2.2870  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 2.3225  Validation loss = 2.2866  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 2.3224  Validation loss = 2.2863  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 2.3221  Validation loss = 2.2858  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 2.3219  Validation loss = 2.2854  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 2.3216  Validation loss = 2.2851  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 2.3214  Validation loss = 2.2847  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 2.3213  Validation loss = 2.2844  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 2.3210  Validation loss = 2.2840  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 2.3208  Validation loss = 2.2836  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 2.3206  Validation loss = 2.2833  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 2.3204  Validation loss = 2.2829  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 2.3202  Validation loss = 2.2826  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 2.3200  Validation loss = 2.2822  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 2.3197  Validation loss = 2.2817  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 2.3195  Validation loss = 2.2813  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 2.3193  Validation loss = 2.2809  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 2.3191  Validation loss = 2.2806  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 2.3189  Validation loss = 2.2803  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 2.3187  Validation loss = 2.2799  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 2.3185  Validation loss = 2.2796  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 2.3183  Validation loss = 2.2792  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 2.3181  Validation loss = 2.2789  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 2.3179  Validation loss = 2.2785  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 2.3176  Validation loss = 2.2780  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 2.3174  Validation loss = 2.2777  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 2.3173  Validation loss = 2.2774  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 2.3170  Validation loss = 2.2770  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 2.3168  Validation loss = 2.2766  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 2.3166  Validation loss = 2.2763  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 2.3164  Validation loss = 2.2759  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 2.3162  Validation loss = 2.2756  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 2.3159  Validation loss = 2.2751  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 2.3157  Validation loss = 2.2747  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 2.3155  Validation loss = 2.2744  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 2.3154  Validation loss = 2.2741  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 2.3152  Validation loss = 2.2737  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 2.3150  Validation loss = 2.2734  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 2.3148  Validation loss = 2.2731  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 2.3145  Validation loss = 2.2727  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 2.3143  Validation loss = 2.2723  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 2.3141  Validation loss = 2.2720  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 2.3140  Validation loss = 2.2717  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 2.3137  Validation loss = 2.2712  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 2.3134  Validation loss = 2.2708  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 2.3133  Validation loss = 2.2705  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 2.3131  Validation loss = 2.2701  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 2.3130  Validation loss = 2.2699  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 2.3128  Validation loss = 2.2696  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 2.3126  Validation loss = 2.2693  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 2.3124  Validation loss = 2.2689  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 2.3122  Validation loss = 2.2686  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 2.3120  Validation loss = 2.2682  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 2.3118  Validation loss = 2.2679  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 2.3116  Validation loss = 2.2675  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 2.3114  Validation loss = 2.2672  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 2.3545  Validation loss = 2.1178  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 2.3543  Validation loss = 2.1174  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 2.3540  Validation loss = 2.1169  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 2.3537  Validation loss = 2.1166  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 2.3535  Validation loss = 2.1161  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 2.3532  Validation loss = 2.1157  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 2.3530  Validation loss = 2.1154  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 2.3527  Validation loss = 2.1149  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 2.3524  Validation loss = 2.1144  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 2.3521  Validation loss = 2.1140  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 2.3518  Validation loss = 2.1135  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 2.3516  Validation loss = 2.1132  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 2.3513  Validation loss = 2.1127  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 2.3510  Validation loss = 2.1123  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 2.3507  Validation loss = 2.1118  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 2.3504  Validation loss = 2.1114  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 2.3502  Validation loss = 2.1110  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 2.3499  Validation loss = 2.1106  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 2.3497  Validation loss = 2.1102  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 2.3494  Validation loss = 2.1098  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 2.3492  Validation loss = 2.1094  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 2.3489  Validation loss = 2.1090  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 2.3486  Validation loss = 2.1085  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 2.3484  Validation loss = 2.1081  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 2.3481  Validation loss = 2.1077  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 2.3478  Validation loss = 2.1073  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 2.3475  Validation loss = 2.1069  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 2.3473  Validation loss = 2.1066  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 2.3471  Validation loss = 2.1061  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 2.3468  Validation loss = 2.1057  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 2.3465  Validation loss = 2.1053  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 2.3463  Validation loss = 2.1050  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 2.3461  Validation loss = 2.1046  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 2.3458  Validation loss = 2.1042  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 2.3456  Validation loss = 2.1039  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 2.3453  Validation loss = 2.1035  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 2.3452  Validation loss = 2.1032  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 2.3449  Validation loss = 2.1028  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 2.3447  Validation loss = 2.1024  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 2.3443  Validation loss = 2.1019  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 2.3440  Validation loss = 2.1014  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 2.3438  Validation loss = 2.1011  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 2.3435  Validation loss = 2.1006  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 2.3432  Validation loss = 2.1001  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 2.3429  Validation loss = 2.0997  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 2.3427  Validation loss = 2.0993  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 2.3425  Validation loss = 2.0990  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 2.3422  Validation loss = 2.0985  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 2.3420  Validation loss = 2.0982  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 2.3417  Validation loss = 2.0978  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 2.3415  Validation loss = 2.0974  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 2.3413  Validation loss = 2.0970  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 2.3410  Validation loss = 2.0967  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 2.3407  Validation loss = 2.0962  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 2.3405  Validation loss = 2.0959  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 2.3402  Validation loss = 2.0954  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 2.3399  Validation loss = 2.0950  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 2.3396  Validation loss = 2.0944  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 2.3393  Validation loss = 2.0940  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 2.3391  Validation loss = 2.0936  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 2.3388  Validation loss = 2.0932  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 2.3385  Validation loss = 2.0928  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 2.3383  Validation loss = 2.0924  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 2.3380  Validation loss = 2.0919  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 2.3377  Validation loss = 2.0915  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 2.3374  Validation loss = 2.0911  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 2.3372  Validation loss = 2.0907  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 2.3369  Validation loss = 2.0902  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 2.3366  Validation loss = 2.0897  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 2.3363  Validation loss = 2.0893  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 2.3360  Validation loss = 2.0889  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 2.3357  Validation loss = 2.0884  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 2.3354  Validation loss = 2.0880  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 2.3352  Validation loss = 2.0876  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 2.3350  Validation loss = 2.0872  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 2.3347  Validation loss = 2.0868  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 2.3344  Validation loss = 2.0863  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 2.3341  Validation loss = 2.0859  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 2.3338  Validation loss = 2.0854  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 2.3336  Validation loss = 2.0850  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 2.3333  Validation loss = 2.0846  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 2.3330  Validation loss = 2.0842  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 2.3327  Validation loss = 2.0838  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 2.3324  Validation loss = 2.0833  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 2.3322  Validation loss = 2.0829  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 2.3320  Validation loss = 2.0826  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 2.3317  Validation loss = 2.0822  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 2.3314  Validation loss = 2.0817  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 2.3312  Validation loss = 2.0813  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 2.3310  Validation loss = 2.0810  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 2.3307  Validation loss = 2.0805  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 2.3303  Validation loss = 2.0800  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 2.3301  Validation loss = 2.0796  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 2.3298  Validation loss = 2.0791  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 2.3295  Validation loss = 2.0786  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 2.3292  Validation loss = 2.0782  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 2.3290  Validation loss = 2.0780  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 2.3288  Validation loss = 2.0775  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 2.3285  Validation loss = 2.0772  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 2.3283  Validation loss = 2.0768  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 2.3280  Validation loss = 2.0763  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 2.3277  Validation loss = 2.0759  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 2.3275  Validation loss = 2.0755  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 2.3273  Validation loss = 2.0752  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 2.3270  Validation loss = 2.0748  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 2.3267  Validation loss = 2.0743  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 2.3264  Validation loss = 2.0739  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 2.3261  Validation loss = 2.0734  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 2.3258  Validation loss = 2.0730  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 2.3255  Validation loss = 2.0724  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 2.3252  Validation loss = 2.0720  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 2.3250  Validation loss = 2.0716  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 2.3248  Validation loss = 2.0712  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 2.3245  Validation loss = 2.0709  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 2.3243  Validation loss = 2.0705  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 2.3241  Validation loss = 2.0702  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 2.3238  Validation loss = 2.0698  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 2.3235  Validation loss = 2.0693  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 2.3232  Validation loss = 2.0688  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 2.3229  Validation loss = 2.0683  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 2.3226  Validation loss = 2.0678  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 2.3223  Validation loss = 2.0674  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 2.3221  Validation loss = 2.0670  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 2.3218  Validation loss = 2.0665  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 2.3215  Validation loss = 2.0662  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 2.3213  Validation loss = 2.0658  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 2.3209  Validation loss = 2.0653  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 2.3207  Validation loss = 2.0649  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 2.3204  Validation loss = 2.0645  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 2.3203  Validation loss = 2.0642  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 2.3200  Validation loss = 2.0638  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 2.3198  Validation loss = 2.0634  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 2.3195  Validation loss = 2.0630  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 2.3192  Validation loss = 2.0626  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 2.3190  Validation loss = 2.0621  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 2.3187  Validation loss = 2.0617  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 2.3185  Validation loss = 2.0614  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 2.3182  Validation loss = 2.0610  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 2.3180  Validation loss = 2.0606  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 2.3177  Validation loss = 2.0601  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 2.3174  Validation loss = 2.0596  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 2.3171  Validation loss = 2.0592  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 2.3168  Validation loss = 2.0588  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 2.3166  Validation loss = 2.0584  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 2.3164  Validation loss = 2.0580  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 2.3161  Validation loss = 2.0577  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 2.3159  Validation loss = 2.0573  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 2.3156  Validation loss = 2.0569  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 2.3154  Validation loss = 2.0566  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 2.3152  Validation loss = 2.0562  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 2.3149  Validation loss = 2.0558  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 2.3146  Validation loss = 2.0554  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 2.3144  Validation loss = 2.0550  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 2.3142  Validation loss = 2.0546  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 2.3138  Validation loss = 2.0541  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 2.3135  Validation loss = 2.0536  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 2.3133  Validation loss = 2.0532  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 2.3130  Validation loss = 2.0528  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 2.3127  Validation loss = 2.0524  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 2.3124  Validation loss = 2.0519  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 2.3121  Validation loss = 2.0513  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 2.3118  Validation loss = 2.0509  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 2.3116  Validation loss = 2.0505  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 2.3113  Validation loss = 2.0501  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 2.3111  Validation loss = 2.0497  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 2.3108  Validation loss = 2.0493  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 2.3105  Validation loss = 2.0489  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 2.3102  Validation loss = 2.0484  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 2.3100  Validation loss = 2.0480  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 2.3097  Validation loss = 2.0476  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 2.3095  Validation loss = 2.0472  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 2.3093  Validation loss = 2.0469  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 2.3091  Validation loss = 2.0466  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 2.3088  Validation loss = 2.0462  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 2.3086  Validation loss = 2.0459  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 2.3083  Validation loss = 2.0454  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 2.3081  Validation loss = 2.0451  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 2.3078  Validation loss = 2.0447  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 2.3076  Validation loss = 2.0443  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 2.3073  Validation loss = 2.0438  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 2.3070  Validation loss = 2.0434  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 2.3068  Validation loss = 2.0430  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 2.3065  Validation loss = 2.0426  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 2.3063  Validation loss = 2.0423  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 2.3061  Validation loss = 2.0419  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 2.3058  Validation loss = 2.0415  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 2.3056  Validation loss = 2.0411  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 2.3053  Validation loss = 2.0407  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 2.3050  Validation loss = 2.0402  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 2.3048  Validation loss = 2.0398  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 2.3045  Validation loss = 2.0394  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 2.3042  Validation loss = 2.0390  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 2.3040  Validation loss = 2.0386  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 2.3037  Validation loss = 2.0382  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 2.3035  Validation loss = 2.0378  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 2.3033  Validation loss = 2.0375  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 2.3030  Validation loss = 2.0371  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 2.3028  Validation loss = 2.0367  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 2.3026  Validation loss = 2.0363  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 2.3023  Validation loss = 2.0359  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 2.3020  Validation loss = 2.0354  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 2.3017  Validation loss = 2.0350  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 2.3015  Validation loss = 2.0347  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 2.3012  Validation loss = 2.0342  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 2.3009  Validation loss = 2.0337  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 2.3007  Validation loss = 2.0334  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 2.3004  Validation loss = 2.0329  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 2.3002  Validation loss = 2.0325  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 2.2999  Validation loss = 2.0321  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 2.2996  Validation loss = 2.0316  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 2.2993  Validation loss = 2.0312  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 2.2991  Validation loss = 2.0308  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 2.2989  Validation loss = 2.0305  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 2.2986  Validation loss = 2.0300  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 2.2983  Validation loss = 2.0297  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 2.2981  Validation loss = 2.0292  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 2.2978  Validation loss = 2.0287  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 2.2975  Validation loss = 2.0283  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 2.2972  Validation loss = 2.0278  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 2.2970  Validation loss = 2.0275  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 2.2967  Validation loss = 2.0271  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 2.2965  Validation loss = 2.0267  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 2.2963  Validation loss = 2.0264  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 2.2960  Validation loss = 2.0260  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 2.2958  Validation loss = 2.0256  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 2.2955  Validation loss = 2.0252  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 2.2953  Validation loss = 2.0248  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 2.2951  Validation loss = 2.0244  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 2.2948  Validation loss = 2.0240  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 2.2946  Validation loss = 2.0237  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 2.2943  Validation loss = 2.0233  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 2.2941  Validation loss = 2.0228  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 2.2938  Validation loss = 2.0224  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 2.2936  Validation loss = 2.0222  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 2.2934  Validation loss = 2.0219  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 2.2931  Validation loss = 2.0214  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 2.2928  Validation loss = 2.0209  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 2.2926  Validation loss = 2.0205  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 2.2923  Validation loss = 2.0201  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 2.2921  Validation loss = 2.0197  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 2.2918  Validation loss = 2.0193  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 2.2915  Validation loss = 2.0188  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 2.2912  Validation loss = 2.0183  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 2.2910  Validation loss = 2.0180  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 2.2908  Validation loss = 2.0176  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 2.2906  Validation loss = 2.0173  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 2.2904  Validation loss = 2.0170  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 2.2902  Validation loss = 2.0167  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 2.2899  Validation loss = 2.0162  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 2.2896  Validation loss = 2.0157  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 2.2893  Validation loss = 2.0153  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 2.2891  Validation loss = 2.0149  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 2.2888  Validation loss = 2.0145  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 2.2886  Validation loss = 2.0141  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 2.2884  Validation loss = 2.0138  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 2.2881  Validation loss = 2.0134  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 2.2879  Validation loss = 2.0131  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 2.2877  Validation loss = 2.0127  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 2.2874  Validation loss = 2.0123  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 2.2873  Validation loss = 2.0121  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 2.2870  Validation loss = 2.0117  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 2.2868  Validation loss = 2.0112  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 2.2866  Validation loss = 2.0110  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 2.2864  Validation loss = 2.0106  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 2.2861  Validation loss = 2.0102  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 2.2858  Validation loss = 2.0097  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 2.2856  Validation loss = 2.0094  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 2.2854  Validation loss = 2.0091  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 2.2852  Validation loss = 2.0087  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 2.2849  Validation loss = 2.0083  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 2.2846  Validation loss = 2.0078  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 2.2844  Validation loss = 2.0074  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 2.2841  Validation loss = 2.0070  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 2.2838  Validation loss = 2.0066  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 2.2835  Validation loss = 2.0061  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 2.2834  Validation loss = 2.0059  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 2.2831  Validation loss = 2.0055  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 2.2828  Validation loss = 2.0050  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 2.2826  Validation loss = 2.0046  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 2.2823  Validation loss = 2.0043  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 2.2820  Validation loss = 2.0038  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 2.2818  Validation loss = 2.0033  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 2.2815  Validation loss = 2.0030  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 2.2813  Validation loss = 2.0026  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 2.2810  Validation loss = 2.0022  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 2.2808  Validation loss = 2.0018  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 2.2805  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 2.2803  Validation loss = 2.0011  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 2.2801  Validation loss = 2.0007  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 2.2798  Validation loss = 2.0003  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 2.2795  Validation loss = 1.9998  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 2.2793  Validation loss = 1.9995  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 2.2791  Validation loss = 1.9992  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 2.2789  Validation loss = 1.9989  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 2.2787  Validation loss = 1.9985  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 2.2784  Validation loss = 1.9981  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 2.2782  Validation loss = 1.9977  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 2.2780  Validation loss = 1.9974  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 2.2778  Validation loss = 1.9971  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 2.2775  Validation loss = 1.9967  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 2.2773  Validation loss = 1.9963  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 2.2771  Validation loss = 1.9960  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 2.2768  Validation loss = 1.9955  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 2.2766  Validation loss = 1.9952  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 2.2763  Validation loss = 1.9947  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 2.2760  Validation loss = 1.9942  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 2.2757  Validation loss = 1.9938  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 2.2754  Validation loss = 1.9933  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 2.2751  Validation loss = 1.9928  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 2.2748  Validation loss = 1.9924  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 2.2746  Validation loss = 1.9920  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 2.2743  Validation loss = 1.9916  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 2.2740  Validation loss = 1.9912  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 2.2738  Validation loss = 1.9908  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 2.2736  Validation loss = 1.9904  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 2.2734  Validation loss = 1.9902  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 2.2732  Validation loss = 1.9898  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 2.2728  Validation loss = 1.9893  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 2.2726  Validation loss = 1.9888  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 2.2723  Validation loss = 1.9884  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 2.2721  Validation loss = 1.9880  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 2.2718  Validation loss = 1.9876  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 2.2716  Validation loss = 1.9872  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 2.2713  Validation loss = 1.9869  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 2.2711  Validation loss = 1.9865  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 2.2708  Validation loss = 1.9860  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 2.2706  Validation loss = 1.9856  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 2.2703  Validation loss = 1.9852  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 2.2701  Validation loss = 1.9848  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 2.2699  Validation loss = 1.9846  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 2.2696  Validation loss = 1.9841  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 2.2694  Validation loss = 1.9837  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 2.2692  Validation loss = 1.9834  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 2.2690  Validation loss = 1.9831  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 2.2687  Validation loss = 1.9827  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 2.2685  Validation loss = 1.9824  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 2.2683  Validation loss = 1.9820  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 2.2681  Validation loss = 1.9817  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 2.2678  Validation loss = 1.9813  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 2.2677  Validation loss = 1.9810  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 2.2675  Validation loss = 1.9807  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 2.2672  Validation loss = 1.9803  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 2.2670  Validation loss = 1.9799  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 2.2667  Validation loss = 1.9795  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 2.2665  Validation loss = 1.9791  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 2.2662  Validation loss = 1.9787  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 2.2660  Validation loss = 1.9783  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 2.2658  Validation loss = 1.9780  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 2.2656  Validation loss = 1.9777  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 2.2654  Validation loss = 1.9773  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 2.2651  Validation loss = 1.9769  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 2.2648  Validation loss = 1.9765  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 2.2645  Validation loss = 1.9760  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 2.2643  Validation loss = 1.9757  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 2.2641  Validation loss = 1.9753  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 2.2640  Validation loss = 1.9751  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 2.2637  Validation loss = 1.9746  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 2.2634  Validation loss = 1.9743  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 2.2632  Validation loss = 1.9738  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 2.2629  Validation loss = 1.9734  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 2.2626  Validation loss = 1.9730  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 2.2624  Validation loss = 1.9726  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 2.2622  Validation loss = 1.9723  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 2.2620  Validation loss = 1.9719  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 2.2618  Validation loss = 1.9716  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 2.2615  Validation loss = 1.9712  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 2.2613  Validation loss = 1.9708  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 2.2610  Validation loss = 1.9704  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 2.2608  Validation loss = 1.9700  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 2.2605  Validation loss = 1.9696  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 2.2603  Validation loss = 1.9692  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 2.2601  Validation loss = 1.9689  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 2.2598  Validation loss = 1.9684  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 2.2596  Validation loss = 1.9681  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 2.2593  Validation loss = 1.9677  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 2.2591  Validation loss = 1.9673  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 2.2588  Validation loss = 1.9669  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 2.2586  Validation loss = 1.9665  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 2.2583  Validation loss = 1.9661  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 2.2581  Validation loss = 1.9657  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 2.2578  Validation loss = 1.9653  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 2.2577  Validation loss = 1.9650  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 2.2574  Validation loss = 1.9646  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 2.2572  Validation loss = 1.9643  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 2.2570  Validation loss = 1.9639  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 2.2567  Validation loss = 1.9636  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 2.2565  Validation loss = 1.9632  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 2.2563  Validation loss = 1.9628  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 2.2560  Validation loss = 1.9624  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 2.2558  Validation loss = 1.9621  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 2.2556  Validation loss = 1.9617  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 2.2553  Validation loss = 1.9612  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 2.2551  Validation loss = 1.9609  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 2.2547  Validation loss = 1.9603  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 2.2545  Validation loss = 1.9599  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 2.2542  Validation loss = 1.9595  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 2.2540  Validation loss = 1.9592  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 2.2537  Validation loss = 1.9587  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 2.2535  Validation loss = 1.9584  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 2.2533  Validation loss = 1.9581  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 2.2531  Validation loss = 1.9576  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 2.2528  Validation loss = 1.9573  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 2.2527  Validation loss = 1.9570  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 2.2525  Validation loss = 1.9567  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 2.2522  Validation loss = 1.9563  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 2.2520  Validation loss = 1.9560  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 2.2518  Validation loss = 1.9556  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 2.2516  Validation loss = 1.9553  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 2.2513  Validation loss = 1.9548  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 2.2511  Validation loss = 1.9545  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 2.2509  Validation loss = 1.9542  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 2.2507  Validation loss = 1.9538  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 2.2505  Validation loss = 1.9535  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 2.2502  Validation loss = 1.9531  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 2.2500  Validation loss = 1.9527  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 2.2497  Validation loss = 1.9523  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 2.2495  Validation loss = 1.9519  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 2.2493  Validation loss = 1.9516  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 2.2491  Validation loss = 1.9513  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 2.2489  Validation loss = 1.9509  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 2.2486  Validation loss = 1.9505  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 2.2483  Validation loss = 1.9501  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 2.2481  Validation loss = 1.9497  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 2.2478  Validation loss = 1.9492  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 2.2475  Validation loss = 1.9488  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 2.2473  Validation loss = 1.9484  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 2.2470  Validation loss = 1.9480  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 2.2468  Validation loss = 1.9477  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 2.2466  Validation loss = 1.9473  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 2.2464  Validation loss = 1.9470  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 2.2462  Validation loss = 1.9467  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 2.2460  Validation loss = 1.9463  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 2.2458  Validation loss = 1.9460  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 2.2455  Validation loss = 1.9456  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 2.2453  Validation loss = 1.9453  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 2.2451  Validation loss = 1.9450  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 2.2449  Validation loss = 1.9446  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 2.2447  Validation loss = 1.9443  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 2.2445  Validation loss = 1.9439  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 2.2443  Validation loss = 1.9436  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 2.2440  Validation loss = 1.9431  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 2.2438  Validation loss = 1.9428  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 2.2436  Validation loss = 1.9425  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 2.2434  Validation loss = 1.9422  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 2.2432  Validation loss = 1.9418  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 2.2430  Validation loss = 1.9415  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 2.2427  Validation loss = 1.9410  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 2.2424  Validation loss = 1.9406  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 2.2422  Validation loss = 1.9402  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 2.2420  Validation loss = 1.9399  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 2.2417  Validation loss = 1.9395  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 2.2415  Validation loss = 1.9391  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 2.2412  Validation loss = 1.9387  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 2.2411  Validation loss = 1.9385  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 2.2408  Validation loss = 1.9380  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 2.2406  Validation loss = 1.9376  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 2.2404  Validation loss = 1.9373  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 2.2401  Validation loss = 1.9369  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 2.2398  Validation loss = 1.9365  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 2.2397  Validation loss = 1.9362  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 2.2394  Validation loss = 1.9357  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 2.2391  Validation loss = 1.9354  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 2.2389  Validation loss = 1.9350  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 2.2388  Validation loss = 1.9348  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 2.2385  Validation loss = 1.9344  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 2.2383  Validation loss = 1.9340  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 2.2381  Validation loss = 1.9337  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 2.2379  Validation loss = 1.9334  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 2.2377  Validation loss = 1.9331  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 2.2375  Validation loss = 1.9327  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 2.2372  Validation loss = 1.9323  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 2.2370  Validation loss = 1.9320  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 2.2367  Validation loss = 1.9315  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 2.2364  Validation loss = 1.9310  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 2.2362  Validation loss = 1.9306  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 2.2360  Validation loss = 1.9303  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 2.2358  Validation loss = 1.9300  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 2.2355  Validation loss = 1.9296  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 2.2353  Validation loss = 1.9293  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 2.2351  Validation loss = 1.9289  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 2.2349  Validation loss = 1.9286  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 2.2347  Validation loss = 1.9282  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 2.2345  Validation loss = 1.9279  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 2.2343  Validation loss = 1.9276  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 2.2340  Validation loss = 1.9272  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 2.2338  Validation loss = 1.9268  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 2.2336  Validation loss = 1.9265  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 2.2333  Validation loss = 1.9261  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 2.2331  Validation loss = 1.9257  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 2.2329  Validation loss = 1.9254  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 2.2327  Validation loss = 1.9251  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 2.2325  Validation loss = 1.9247  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 2.2323  Validation loss = 1.9245  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 2.2321  Validation loss = 1.9241  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 2.2319  Validation loss = 1.9238  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 2.2316  Validation loss = 1.9233  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 2.2313  Validation loss = 1.9229  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 2.2311  Validation loss = 1.9225  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 2.2309  Validation loss = 1.9221  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 2.2307  Validation loss = 1.9218  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 500  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 2.2265  Validation loss = 7.1280  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 2.2262  Validation loss = 7.1276  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 2.2259  Validation loss = 7.1272  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 2.2257  Validation loss = 7.1268  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 2.2254  Validation loss = 7.1264  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 2.2251  Validation loss = 7.1259  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 2.2249  Validation loss = 7.1255  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 2.2247  Validation loss = 7.1252  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 2.2244  Validation loss = 7.1247  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 2.2242  Validation loss = 7.1243  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 2.2240  Validation loss = 7.1240  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 2.2238  Validation loss = 7.1237  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 2.2235  Validation loss = 7.1233  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 2.2233  Validation loss = 7.1229  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 2.2231  Validation loss = 7.1225  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 2.2228  Validation loss = 7.1221  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 2.2226  Validation loss = 7.1217  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 2.2223  Validation loss = 7.1213  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 2.2221  Validation loss = 7.1210  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 2.2219  Validation loss = 7.1206  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 2.2216  Validation loss = 7.1202  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 2.2214  Validation loss = 7.1199  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 2.2211  Validation loss = 7.1194  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 2.2208  Validation loss = 7.1189  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 2.2206  Validation loss = 7.1187  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 2.2204  Validation loss = 7.1183  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 2.2203  Validation loss = 7.1180  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 2.2200  Validation loss = 7.1176  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 2.2197  Validation loss = 7.1172  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 2.2194  Validation loss = 7.1167  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 2.2192  Validation loss = 7.1164  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 2.2189  Validation loss = 7.1160  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 2.2187  Validation loss = 7.1156  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 2.2185  Validation loss = 7.1152  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 2.2182  Validation loss = 7.1148  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 2.2180  Validation loss = 7.1145  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 2.2178  Validation loss = 7.1141  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 2.2175  Validation loss = 7.1137  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 2.2173  Validation loss = 7.1134  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 2.2170  Validation loss = 7.1129  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 2.2167  Validation loss = 7.1125  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 2.2165  Validation loss = 7.1121  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 2.2163  Validation loss = 7.1118  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 2.2161  Validation loss = 7.1114  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 2.2159  Validation loss = 7.1111  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 2.2156  Validation loss = 7.1107  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 2.2154  Validation loss = 7.1103  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 2.2152  Validation loss = 7.1099  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 2.2150  Validation loss = 7.1097  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 2.2148  Validation loss = 7.1093  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 2.2145  Validation loss = 7.1089  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 2.2142  Validation loss = 7.1084  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 2.2140  Validation loss = 7.1081  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 2.2138  Validation loss = 7.1076  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 2.2136  Validation loss = 7.1073  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 2.2133  Validation loss = 7.1068  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 2.2130  Validation loss = 7.1063  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 2.2127  Validation loss = 7.1059  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 2.2124  Validation loss = 7.1055  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 2.2122  Validation loss = 7.1051  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 2.2120  Validation loss = 7.1048  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 2.2117  Validation loss = 7.1044  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 2.2115  Validation loss = 7.1040  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 2.2113  Validation loss = 7.1036  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 2.2110  Validation loss = 7.1031  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 2.2107  Validation loss = 7.1027  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 2.2104  Validation loss = 7.1022  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 2.2101  Validation loss = 7.1017  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 2.2099  Validation loss = 7.1014  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 2.2097  Validation loss = 7.1011  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 2.2094  Validation loss = 7.1007  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 2.2092  Validation loss = 7.1003  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 2.2090  Validation loss = 7.0999  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 2.2088  Validation loss = 7.0996  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 2.2085  Validation loss = 7.0992  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 2.2083  Validation loss = 7.0989  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 2.2081  Validation loss = 7.0985  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 2.2079  Validation loss = 7.0981  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 2.2076  Validation loss = 7.0976  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 2.2073  Validation loss = 7.0972  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 2.2071  Validation loss = 7.0969  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 2.2068  Validation loss = 7.0965  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 2.2066  Validation loss = 7.0961  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 2.2064  Validation loss = 7.0957  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 2.2062  Validation loss = 7.0954  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 2.2060  Validation loss = 7.0951  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 2.2058  Validation loss = 7.0948  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 2.2055  Validation loss = 7.0943  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 2.2052  Validation loss = 7.0939  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 2.2050  Validation loss = 7.0935  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 2.2047  Validation loss = 7.0931  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 2.2045  Validation loss = 7.0927  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 2.2043  Validation loss = 7.0924  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 2.2041  Validation loss = 7.0920  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 2.2038  Validation loss = 7.0916  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 2.2036  Validation loss = 7.0912  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 2.2033  Validation loss = 7.0908  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 2.2031  Validation loss = 7.0904  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 2.2029  Validation loss = 7.0901  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 2.2026  Validation loss = 7.0897  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 2.2024  Validation loss = 7.0893  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 2.2021  Validation loss = 7.0889  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 2.2020  Validation loss = 7.0886  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 2.2018  Validation loss = 7.0884  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 2.2016  Validation loss = 7.0880  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 2.2014  Validation loss = 7.0878  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 2.2012  Validation loss = 7.0873  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 2.2010  Validation loss = 7.0870  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 2.2007  Validation loss = 7.0866  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 2.2004  Validation loss = 7.0861  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 2.2002  Validation loss = 7.0857  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 2.1999  Validation loss = 7.0853  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 2.1997  Validation loss = 7.0849  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 2.1995  Validation loss = 7.0846  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 2.1992  Validation loss = 7.0842  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 2.1990  Validation loss = 7.0838  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 2.1987  Validation loss = 7.0834  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 2.1985  Validation loss = 7.0830  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 2.1983  Validation loss = 7.0826  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 2.1980  Validation loss = 7.0822  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 2.1977  Validation loss = 7.0818  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 2.1975  Validation loss = 7.0813  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 2.1972  Validation loss = 7.0810  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 2.1971  Validation loss = 7.0807  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 2.1968  Validation loss = 7.0804  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 2.1966  Validation loss = 7.0800  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 2.1963  Validation loss = 7.0795  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 2.1960  Validation loss = 7.0791  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 2.1958  Validation loss = 7.0787  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 2.1956  Validation loss = 7.0783  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 2.1953  Validation loss = 7.0779  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 2.1951  Validation loss = 7.0776  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 2.1949  Validation loss = 7.0773  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 2.1947  Validation loss = 7.0769  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 2.1945  Validation loss = 7.0766  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 2.1942  Validation loss = 7.0762  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 2.1940  Validation loss = 7.0757  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 2.1938  Validation loss = 7.0754  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 2.1936  Validation loss = 7.0751  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 2.1934  Validation loss = 7.0748  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 2.1932  Validation loss = 7.0744  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 2.1929  Validation loss = 7.0739  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 2.1926  Validation loss = 7.0735  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 2.1924  Validation loss = 7.0731  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 2.1921  Validation loss = 7.0727  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 2.1919  Validation loss = 7.0724  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 2.1917  Validation loss = 7.0720  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 2.1914  Validation loss = 7.0716  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 2.1912  Validation loss = 7.0713  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 2.1910  Validation loss = 7.0709  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 2.1908  Validation loss = 7.0705  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 2.1906  Validation loss = 7.0702  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 2.1904  Validation loss = 7.0699  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 2.1902  Validation loss = 7.0696  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 2.1899  Validation loss = 7.0692  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 2.1897  Validation loss = 7.0689  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 2.1894  Validation loss = 7.0684  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 2.1892  Validation loss = 7.0679  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 2.1889  Validation loss = 7.0676  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 2.1886  Validation loss = 7.0671  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 2.1884  Validation loss = 7.0668  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 2.1882  Validation loss = 7.0664  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 2.1879  Validation loss = 7.0659  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 2.1877  Validation loss = 7.0656  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 2.1875  Validation loss = 7.0653  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 2.1873  Validation loss = 7.0649  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 2.1870  Validation loss = 7.0644  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 2.1867  Validation loss = 7.0640  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 2.1865  Validation loss = 7.0636  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 2.1863  Validation loss = 7.0633  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 2.1860  Validation loss = 7.0629  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 2.1858  Validation loss = 7.0624  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 2.1856  Validation loss = 7.0622  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 2.1854  Validation loss = 7.0618  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 2.1852  Validation loss = 7.0615  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 2.1849  Validation loss = 7.0611  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 2.1848  Validation loss = 7.0608  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 2.1845  Validation loss = 7.0604  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 2.1843  Validation loss = 7.0601  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 2.1841  Validation loss = 7.0597  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 2.1839  Validation loss = 7.0593  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 2.1837  Validation loss = 7.0591  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 2.1834  Validation loss = 7.0586  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 2.1832  Validation loss = 7.0583  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 2.1830  Validation loss = 7.0579  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 2.1827  Validation loss = 7.0575  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 2.1825  Validation loss = 7.0572  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 2.1822  Validation loss = 7.0567  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 2.1821  Validation loss = 7.0564  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 2.1819  Validation loss = 7.0562  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 2.1816  Validation loss = 7.0557  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 2.1814  Validation loss = 7.0554  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 2.1812  Validation loss = 7.0550  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 2.1809  Validation loss = 7.0546  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 2.1807  Validation loss = 7.0542  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 2.1806  Validation loss = 7.0540  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 2.1803  Validation loss = 7.0535  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 2.1801  Validation loss = 7.0532  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 2.1798  Validation loss = 7.0528  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 2.1796  Validation loss = 7.0525  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 2.1794  Validation loss = 7.0521  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 2.1792  Validation loss = 7.0517  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 2.1790  Validation loss = 7.0514  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 2.1787  Validation loss = 7.0510  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 2.1785  Validation loss = 7.0506  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 2.1782  Validation loss = 7.0502  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 2.1780  Validation loss = 7.0498  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 2.1778  Validation loss = 7.0495  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 2.1775  Validation loss = 7.0490  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 2.1773  Validation loss = 7.0488  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 2.1771  Validation loss = 7.0483  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 2.1768  Validation loss = 7.0479  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 2.1766  Validation loss = 7.0475  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 2.1764  Validation loss = 7.0471  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 2.1761  Validation loss = 7.0467  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 2.1759  Validation loss = 7.0463  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 2.1757  Validation loss = 7.0460  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 2.1755  Validation loss = 7.0456  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 2.1752  Validation loss = 7.0452  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 2.1750  Validation loss = 7.0447  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 2.1747  Validation loss = 7.0443  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 2.1745  Validation loss = 7.0439  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 2.1742  Validation loss = 7.0435  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 2.1740  Validation loss = 7.0432  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 2.1738  Validation loss = 7.0428  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 2.1736  Validation loss = 7.0424  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 2.1734  Validation loss = 7.0421  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 2.1731  Validation loss = 7.0416  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 2.1729  Validation loss = 7.0412  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 2.1727  Validation loss = 7.0409  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 2.1724  Validation loss = 7.0406  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 2.1722  Validation loss = 7.0402  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 2.1720  Validation loss = 7.0398  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 2.1718  Validation loss = 7.0394  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 2.1716  Validation loss = 7.0391  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 2.1714  Validation loss = 7.0388  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 2.1711  Validation loss = 7.0384  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 2.1709  Validation loss = 7.0380  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 2.1706  Validation loss = 7.0376  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 2.1704  Validation loss = 7.0373  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 2.1702  Validation loss = 7.0370  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 2.1701  Validation loss = 7.0366  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 2.1698  Validation loss = 7.0363  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 2.1696  Validation loss = 7.0359  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 2.1694  Validation loss = 7.0355  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 2.1692  Validation loss = 7.0352  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 2.1690  Validation loss = 7.0348  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 2.1687  Validation loss = 7.0344  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 2.1685  Validation loss = 7.0341  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 2.1683  Validation loss = 7.0338  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 2.1681  Validation loss = 7.0335  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 2.1680  Validation loss = 7.0332  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 2.1677  Validation loss = 7.0328  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 2.1675  Validation loss = 7.0324  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 2.1673  Validation loss = 7.0320  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 2.1670  Validation loss = 7.0317  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 2.1669  Validation loss = 7.0314  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 2.1666  Validation loss = 7.0310  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 2.1664  Validation loss = 7.0306  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 2.1661  Validation loss = 7.0302  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 2.1658  Validation loss = 7.0297  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 2.1656  Validation loss = 7.0293  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 2.1653  Validation loss = 7.0289  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 2.1651  Validation loss = 7.0286  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 2.1650  Validation loss = 7.0283  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 2.1647  Validation loss = 7.0279  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 2.1646  Validation loss = 7.0276  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 2.1643  Validation loss = 7.0272  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 2.1640  Validation loss = 7.0267  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 2.1638  Validation loss = 7.0263  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 2.1635  Validation loss = 7.0259  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 2.1633  Validation loss = 7.0256  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 2.1631  Validation loss = 7.0252  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 2.1629  Validation loss = 7.0250  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 2.1627  Validation loss = 7.0246  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 2.1625  Validation loss = 7.0242  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 2.1623  Validation loss = 7.0239  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 2.1620  Validation loss = 7.0235  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 2.1617  Validation loss = 7.0230  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 2.1615  Validation loss = 7.0226  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 2.1613  Validation loss = 7.0223  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 2.1610  Validation loss = 7.0218  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 2.1608  Validation loss = 7.0215  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 2.1605  Validation loss = 7.0210  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 2.1602  Validation loss = 7.0206  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 2.1601  Validation loss = 7.0203  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 2.1598  Validation loss = 7.0198  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 2.1596  Validation loss = 7.0195  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 2.1593  Validation loss = 7.0190  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 2.1591  Validation loss = 7.0187  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 2.1589  Validation loss = 7.0183  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 2.1587  Validation loss = 7.0179  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 2.1584  Validation loss = 7.0176  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 2.1583  Validation loss = 7.0173  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 2.1581  Validation loss = 7.0171  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 2.1579  Validation loss = 7.0166  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 2.1577  Validation loss = 7.0163  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 2.1575  Validation loss = 7.0159  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 2.1573  Validation loss = 7.0156  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 2.1570  Validation loss = 7.0152  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 2.1568  Validation loss = 7.0149  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 2.1566  Validation loss = 7.0145  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 2.1564  Validation loss = 7.0142  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 2.1562  Validation loss = 7.0138  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 2.1559  Validation loss = 7.0134  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 2.1558  Validation loss = 7.0131  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 2.1555  Validation loss = 7.0127  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 2.1553  Validation loss = 7.0123  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 2.1551  Validation loss = 7.0120  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 2.1548  Validation loss = 7.0116  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 2.1546  Validation loss = 7.0112  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 2.1544  Validation loss = 7.0109  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 2.1542  Validation loss = 7.0105  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 2.1539  Validation loss = 7.0100  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 2.1537  Validation loss = 7.0097  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 2.1534  Validation loss = 7.0093  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 2.1532  Validation loss = 7.0089  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 2.1530  Validation loss = 7.0085  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 2.1528  Validation loss = 7.0082  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 2.1526  Validation loss = 7.0078  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 2.1524  Validation loss = 7.0075  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 2.1522  Validation loss = 7.0071  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 2.1520  Validation loss = 7.0068  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 2.1518  Validation loss = 7.0065  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 2.1515  Validation loss = 7.0061  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 2.1513  Validation loss = 7.0058  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 2.1511  Validation loss = 7.0054  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 2.1509  Validation loss = 7.0050  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 2.1507  Validation loss = 7.0046  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 2.1504  Validation loss = 7.0042  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 2.1502  Validation loss = 7.0039  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 2.1500  Validation loss = 7.0036  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 2.1498  Validation loss = 7.0031  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 2.1495  Validation loss = 7.0028  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 2.1493  Validation loss = 7.0024  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 2.1491  Validation loss = 7.0020  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 2.1488  Validation loss = 7.0016  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 2.1486  Validation loss = 7.0012  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 2.1484  Validation loss = 7.0008  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 2.1481  Validation loss = 7.0005  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 2.1479  Validation loss = 7.0001  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 2.1477  Validation loss = 6.9998  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 2.1476  Validation loss = 6.9995  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 2.1473  Validation loss = 6.9991  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 2.1471  Validation loss = 6.9987  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 2.1469  Validation loss = 6.9984  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 2.1467  Validation loss = 6.9981  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 2.1465  Validation loss = 6.9977  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 2.1463  Validation loss = 6.9974  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 2.1461  Validation loss = 6.9971  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 2.1459  Validation loss = 6.9967  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 2.1456  Validation loss = 6.9963  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 2.1454  Validation loss = 6.9959  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 2.1452  Validation loss = 6.9955  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 2.1450  Validation loss = 6.9951  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 2.1448  Validation loss = 6.9948  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 2.1446  Validation loss = 6.9945  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 2.1443  Validation loss = 6.9941  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 2.1441  Validation loss = 6.9936  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 2.1438  Validation loss = 6.9932  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 2.1436  Validation loss = 6.9928  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 2.1434  Validation loss = 6.9925  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 2.1432  Validation loss = 6.9923  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 2.1430  Validation loss = 6.9919  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 2.1428  Validation loss = 6.9915  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 2.1426  Validation loss = 6.9911  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 2.1423  Validation loss = 6.9908  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 2.1421  Validation loss = 6.9903  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 2.1418  Validation loss = 6.9900  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 2.1416  Validation loss = 6.9896  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 2.1413  Validation loss = 6.9891  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 2.1411  Validation loss = 6.9888  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 2.1409  Validation loss = 6.9884  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 2.1407  Validation loss = 6.9880  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 2.1404  Validation loss = 6.9876  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 2.1402  Validation loss = 6.9872  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 2.1399  Validation loss = 6.9868  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 2.1397  Validation loss = 6.9865  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 2.1395  Validation loss = 6.9861  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 2.1393  Validation loss = 6.9858  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 2.1391  Validation loss = 6.9854  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 2.1389  Validation loss = 6.9850  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 2.1387  Validation loss = 6.9848  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 2.1385  Validation loss = 6.9844  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 2.1382  Validation loss = 6.9840  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 2.1380  Validation loss = 6.9837  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 2.1378  Validation loss = 6.9833  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 2.1377  Validation loss = 6.9830  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 2.1374  Validation loss = 6.9827  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 2.1372  Validation loss = 6.9823  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 2.1370  Validation loss = 6.9820  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 2.1368  Validation loss = 6.9816  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 2.1366  Validation loss = 6.9813  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 2.1364  Validation loss = 6.9810  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 2.1361  Validation loss = 6.9805  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 2.1359  Validation loss = 6.9802  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 2.1356  Validation loss = 6.9797  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 2.1354  Validation loss = 6.9794  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 2.1353  Validation loss = 6.9791  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 2.1351  Validation loss = 6.9787  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 2.1349  Validation loss = 6.9784  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 2.1346  Validation loss = 6.9780  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 2.1344  Validation loss = 6.9777  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 2.1342  Validation loss = 6.9773  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 2.1340  Validation loss = 6.9769  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 2.1338  Validation loss = 6.9766  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 2.1336  Validation loss = 6.9763  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 2.1333  Validation loss = 6.9759  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 2.1331  Validation loss = 6.9755  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 2.1329  Validation loss = 6.9752  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 2.1327  Validation loss = 6.9748  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 2.1325  Validation loss = 6.9745  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 2.1323  Validation loss = 6.9741  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 2.1321  Validation loss = 6.9738  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 2.1319  Validation loss = 6.9735  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 2.1317  Validation loss = 6.9731  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 2.1315  Validation loss = 6.9728  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 2.1312  Validation loss = 6.9724  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 2.1311  Validation loss = 6.9721  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 2.1309  Validation loss = 6.9717  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 2.1307  Validation loss = 6.9714  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 2.1305  Validation loss = 6.9711  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 2.1302  Validation loss = 6.9706  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 2.1300  Validation loss = 6.9703  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 2.1298  Validation loss = 6.9699  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 2.1296  Validation loss = 6.9695  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 2.1293  Validation loss = 6.9691  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 2.1291  Validation loss = 6.9687  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 2.1289  Validation loss = 6.9683  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 2.1287  Validation loss = 6.9680  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 2.1285  Validation loss = 6.9677  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 2.1282  Validation loss = 6.9673  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 2.1280  Validation loss = 6.9669  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 2.1278  Validation loss = 6.9665  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 2.1276  Validation loss = 6.9663  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 2.1274  Validation loss = 6.9659  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 2.1272  Validation loss = 6.9655  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 2.1270  Validation loss = 6.9653  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 2.1268  Validation loss = 6.9650  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 2.1266  Validation loss = 6.9646  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 2.1264  Validation loss = 6.9643  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 2.1262  Validation loss = 6.9639  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 2.1261  Validation loss = 6.9636  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 2.1259  Validation loss = 6.9633  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 2.1257  Validation loss = 6.9630  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 2.1254  Validation loss = 6.9625  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 2.1252  Validation loss = 6.9622  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 2.1250  Validation loss = 6.9619  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 2.1248  Validation loss = 6.9616  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 2.1246  Validation loss = 6.9612  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 2.1244  Validation loss = 6.9609  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 2.1242  Validation loss = 6.9605  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 2.1240  Validation loss = 6.9602  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 2.1237  Validation loss = 6.9597  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 2.1235  Validation loss = 6.9593  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 2.1232  Validation loss = 6.9589  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 2.1230  Validation loss = 6.9585  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 2.1227  Validation loss = 6.9581  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 2.1225  Validation loss = 6.9577  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 2.1223  Validation loss = 6.9574  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 2.1221  Validation loss = 6.9570  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 2.1218  Validation loss = 6.9566  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 2.1216  Validation loss = 6.9562  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 2.1213  Validation loss = 6.9557  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 2.1211  Validation loss = 6.9553  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 2.1209  Validation loss = 6.9549  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 2.1207  Validation loss = 6.9547  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 2.1205  Validation loss = 6.9543  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 2.1203  Validation loss = 6.9540  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 2.1201  Validation loss = 6.9537  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 2.1199  Validation loss = 6.9533  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 2.1197  Validation loss = 6.9530  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 2.1195  Validation loss = 6.9526  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 2.1193  Validation loss = 6.9523  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 2.1191  Validation loss = 6.9520  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 2.1189  Validation loss = 6.9516  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 2.1187  Validation loss = 6.9512  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 2.1185  Validation loss = 6.9509  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 2.1183  Validation loss = 6.9505  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 2.1181  Validation loss = 6.9502  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 2.1178  Validation loss = 6.9498  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 2.1176  Validation loss = 6.9494  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 2.1174  Validation loss = 6.9491  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 2.1173  Validation loss = 6.9488  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 2.1171  Validation loss = 6.9485  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 2.1168  Validation loss = 6.9481  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 2.1167  Validation loss = 6.9479  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 2.1165  Validation loss = 6.9475  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 2.1163  Validation loss = 6.9472  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 2.1160  Validation loss = 6.9467  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 2.1158  Validation loss = 6.9464  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 2.1156  Validation loss = 6.9460  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 2.1154  Validation loss = 6.9456  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 2.1153  Validation loss = 6.9454  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 2.1151  Validation loss = 6.9450  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 2.1148  Validation loss = 6.9446  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 2.1146  Validation loss = 6.9443  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 2.1144  Validation loss = 6.9439  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 2.1141  Validation loss = 6.9435  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 2.1140  Validation loss = 6.9432  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 500  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.6777  Validation loss = 10.1820  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.6775  Validation loss = 10.1814  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.6772  Validation loss = 10.1809  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.6769  Validation loss = 10.1804  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.6766  Validation loss = 10.1799  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.6764  Validation loss = 10.1795  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.6761  Validation loss = 10.1790  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.6759  Validation loss = 10.1786  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.6756  Validation loss = 10.1780  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.6754  Validation loss = 10.1778  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.6752  Validation loss = 10.1773  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.6750  Validation loss = 10.1768  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.6748  Validation loss = 10.1764  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.6745  Validation loss = 10.1759  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.6742  Validation loss = 10.1754  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.6740  Validation loss = 10.1750  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.6738  Validation loss = 10.1746  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.6735  Validation loss = 10.1742  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.6733  Validation loss = 10.1738  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.6730  Validation loss = 10.1733  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.6727  Validation loss = 10.1728  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.6724  Validation loss = 10.1723  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.6722  Validation loss = 10.1718  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.6720  Validation loss = 10.1714  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.6718  Validation loss = 10.1710  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.6715  Validation loss = 10.1706  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.6712  Validation loss = 10.1701  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.6710  Validation loss = 10.1695  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.6707  Validation loss = 10.1691  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.6705  Validation loss = 10.1687  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.6703  Validation loss = 10.1682  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.6700  Validation loss = 10.1678  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.6697  Validation loss = 10.1672  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.6694  Validation loss = 10.1667  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.6692  Validation loss = 10.1663  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.6688  Validation loss = 10.1656  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.6685  Validation loss = 10.1648  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.6682  Validation loss = 10.1643  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.6680  Validation loss = 10.1638  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.6677  Validation loss = 10.1633  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.6675  Validation loss = 10.1628  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.6673  Validation loss = 10.1624  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.6670  Validation loss = 10.1619  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.6668  Validation loss = 10.1615  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.6666  Validation loss = 10.1609  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.6663  Validation loss = 10.1605  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.6661  Validation loss = 10.1600  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.6659  Validation loss = 10.1595  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.6656  Validation loss = 10.1589  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.6654  Validation loss = 10.1584  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.6651  Validation loss = 10.1579  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.6649  Validation loss = 10.1575  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.6647  Validation loss = 10.1570  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.6645  Validation loss = 10.1566  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.6642  Validation loss = 10.1561  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.6639  Validation loss = 10.1556  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.6637  Validation loss = 10.1551  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.6635  Validation loss = 10.1547  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.6633  Validation loss = 10.1542  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.6630  Validation loss = 10.1538  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.6627  Validation loss = 10.1532  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.6625  Validation loss = 10.1525  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.6623  Validation loss = 10.1521  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.6621  Validation loss = 10.1517  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.6618  Validation loss = 10.1511  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.6615  Validation loss = 10.1507  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.6613  Validation loss = 10.1502  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.6610  Validation loss = 10.1498  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.6608  Validation loss = 10.1492  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.6606  Validation loss = 10.1488  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.6603  Validation loss = 10.1481  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.6600  Validation loss = 10.1477  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.6597  Validation loss = 10.1468  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.6595  Validation loss = 10.1464  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.6593  Validation loss = 10.1459  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.6591  Validation loss = 10.1454  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.6588  Validation loss = 10.1449  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.6586  Validation loss = 10.1443  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.6583  Validation loss = 10.1439  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.6580  Validation loss = 10.1433  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.6577  Validation loss = 10.1426  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.6575  Validation loss = 10.1421  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.6572  Validation loss = 10.1415  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.6569  Validation loss = 10.1408  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.6566  Validation loss = 10.1403  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.6564  Validation loss = 10.1398  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.6562  Validation loss = 10.1392  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.6559  Validation loss = 10.1386  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.6556  Validation loss = 10.1381  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.6553  Validation loss = 10.1374  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.6551  Validation loss = 10.1369  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.6547  Validation loss = 10.1362  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.6545  Validation loss = 10.1358  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.6542  Validation loss = 10.1351  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.6540  Validation loss = 10.1347  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.6537  Validation loss = 10.1340  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.6535  Validation loss = 10.1335  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.6533  Validation loss = 10.1329  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.6530  Validation loss = 10.1324  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.6528  Validation loss = 10.1319  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.6526  Validation loss = 10.1315  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.6523  Validation loss = 10.1308  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.6521  Validation loss = 10.1304  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.6519  Validation loss = 10.1300  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.6516  Validation loss = 10.1294  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.6514  Validation loss = 10.1288  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.6511  Validation loss = 10.1282  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.6509  Validation loss = 10.1277  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.6507  Validation loss = 10.1272  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.6504  Validation loss = 10.1267  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.6502  Validation loss = 10.1262  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.6499  Validation loss = 10.1256  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.6497  Validation loss = 10.1250  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.6495  Validation loss = 10.1246  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.6492  Validation loss = 10.1239  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.6489  Validation loss = 10.1234  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.6487  Validation loss = 10.1229  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 2.6485  Validation loss = 10.1224  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 2.6482  Validation loss = 10.1216  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 2.6479  Validation loss = 10.1208  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 2.6475  Validation loss = 10.1199  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 2.6473  Validation loss = 10.1193  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 2.6469  Validation loss = 10.1184  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 2.6466  Validation loss = 10.1177  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 2.6464  Validation loss = 10.1171  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 2.6462  Validation loss = 10.1167  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 2.6459  Validation loss = 10.1162  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 2.6456  Validation loss = 10.1157  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 2.6454  Validation loss = 10.1151  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 2.6452  Validation loss = 10.1145  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 2.6450  Validation loss = 10.1141  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 2.6448  Validation loss = 10.1136  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 2.6445  Validation loss = 10.1130  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 2.6443  Validation loss = 10.1126  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 2.6441  Validation loss = 10.1121  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 2.6438  Validation loss = 10.1115  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 2.6436  Validation loss = 10.1110  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 2.6433  Validation loss = 10.1105  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 2.6431  Validation loss = 10.1100  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 2.6428  Validation loss = 10.1095  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 2.6426  Validation loss = 10.1090  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 2.6424  Validation loss = 10.1085  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 2.6422  Validation loss = 10.1082  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 2.6420  Validation loss = 10.1076  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 2.6417  Validation loss = 10.1069  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 2.6415  Validation loss = 10.1065  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 2.6413  Validation loss = 10.1061  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 2.6410  Validation loss = 10.1055  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 2.6408  Validation loss = 10.1049  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 2.6405  Validation loss = 10.1043  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 2.6402  Validation loss = 10.1037  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 2.6399  Validation loss = 10.1029  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 2.6396  Validation loss = 10.1023  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 2.6395  Validation loss = 10.1018  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 2.6393  Validation loss = 10.1013  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 2.6390  Validation loss = 10.1004  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 2.6388  Validation loss = 10.0999  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 2.6386  Validation loss = 10.0993  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 2.6383  Validation loss = 10.0986  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 2.6380  Validation loss = 10.0980  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 2.6378  Validation loss = 10.0975  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 2.6376  Validation loss = 10.0968  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 2.6374  Validation loss = 10.0961  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 2.6372  Validation loss = 10.0957  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 2.6369  Validation loss = 10.0948  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 2.6366  Validation loss = 10.0941  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 2.6363  Validation loss = 10.0934  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 2.6360  Validation loss = 10.0926  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 2.6358  Validation loss = 10.0919  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 2.6355  Validation loss = 10.0914  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 2.6353  Validation loss = 10.0908  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 2.6351  Validation loss = 10.0902  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 2.6348  Validation loss = 10.0895  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 2.6346  Validation loss = 10.0889  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 2.6344  Validation loss = 10.0884  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 2.6341  Validation loss = 10.0880  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 2.6339  Validation loss = 10.0874  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 2.6337  Validation loss = 10.0869  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 2.6334  Validation loss = 10.0861  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 2.6331  Validation loss = 10.0855  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 2.6329  Validation loss = 10.0850  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 2.6326  Validation loss = 10.0841  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 2.6323  Validation loss = 10.0836  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 2.6320  Validation loss = 10.0829  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 2.6318  Validation loss = 10.0822  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 2.6315  Validation loss = 10.0815  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 2.6312  Validation loss = 10.0807  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 2.6310  Validation loss = 10.0799  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 2.6307  Validation loss = 10.0794  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 2.6304  Validation loss = 10.0789  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 2.6301  Validation loss = 10.0780  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 2.6299  Validation loss = 10.0774  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 2.6297  Validation loss = 10.0766  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 2.6295  Validation loss = 10.0761  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 2.6293  Validation loss = 10.0756  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 2.6290  Validation loss = 10.0750  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 2.6286  Validation loss = 10.0744  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 2.6284  Validation loss = 10.0739  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 2.6282  Validation loss = 10.0734  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 2.6279  Validation loss = 10.0729  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 2.6276  Validation loss = 10.0724  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 2.6274  Validation loss = 10.0717  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 2.6270  Validation loss = 10.0709  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 2.6267  Validation loss = 10.0700  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 2.6264  Validation loss = 10.0694  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 2.6262  Validation loss = 10.0685  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 2.6259  Validation loss = 10.0678  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 2.6257  Validation loss = 10.0673  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 2.6255  Validation loss = 10.0667  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 2.6252  Validation loss = 10.0658  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 2.6249  Validation loss = 10.0650  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 2.6247  Validation loss = 10.0645  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 2.6244  Validation loss = 10.0641  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 2.6242  Validation loss = 10.0635  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 2.6240  Validation loss = 10.0631  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 2.6238  Validation loss = 10.0626  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 2.6235  Validation loss = 10.0619  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 2.6233  Validation loss = 10.0614  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 2.6231  Validation loss = 10.0611  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 2.6228  Validation loss = 10.0604  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 2.6226  Validation loss = 10.0600  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 2.6224  Validation loss = 10.0594  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 2.6221  Validation loss = 10.0588  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 2.6219  Validation loss = 10.0583  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 2.6217  Validation loss = 10.0578  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 2.6214  Validation loss = 10.0572  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 2.6212  Validation loss = 10.0566  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 2.6210  Validation loss = 10.0560  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 2.6207  Validation loss = 10.0555  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 2.6205  Validation loss = 10.0547  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 2.6202  Validation loss = 10.0543  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 2.6200  Validation loss = 10.0538  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 2.6197  Validation loss = 10.0531  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 2.6193  Validation loss = 10.0524  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 2.6191  Validation loss = 10.0519  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 2.6188  Validation loss = 10.0512  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 2.6186  Validation loss = 10.0507  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 2.6184  Validation loss = 10.0503  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 2.6182  Validation loss = 10.0499  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 2.6179  Validation loss = 10.0493  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 2.6176  Validation loss = 10.0488  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 2.6174  Validation loss = 10.0481  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 2.6171  Validation loss = 10.0475  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 2.6169  Validation loss = 10.0470  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 2.6166  Validation loss = 10.0464  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 2.6163  Validation loss = 10.0457  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 2.6160  Validation loss = 10.0451  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 2.6158  Validation loss = 10.0445  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 2.6156  Validation loss = 10.0440  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 2.6153  Validation loss = 10.0433  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 2.6151  Validation loss = 10.0430  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 2.6148  Validation loss = 10.0422  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 2.6146  Validation loss = 10.0419  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 2.6143  Validation loss = 10.0410  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 2.6141  Validation loss = 10.0402  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 2.6138  Validation loss = 10.0396  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 2.6136  Validation loss = 10.0392  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 2.6133  Validation loss = 10.0386  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 2.6131  Validation loss = 10.0380  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 2.6129  Validation loss = 10.0376  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 2.6127  Validation loss = 10.0369  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 2.6124  Validation loss = 10.0362  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 2.6121  Validation loss = 10.0356  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 2.6119  Validation loss = 10.0351  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 2.6117  Validation loss = 10.0347  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 2.6115  Validation loss = 10.0341  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 2.6113  Validation loss = 10.0338  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 2.6110  Validation loss = 10.0331  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 2.6108  Validation loss = 10.0327  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 2.6105  Validation loss = 10.0322  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 2.6103  Validation loss = 10.0318  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 2.6101  Validation loss = 10.0312  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 2.6099  Validation loss = 10.0308  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 2.6097  Validation loss = 10.0303  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 2.6094  Validation loss = 10.0297  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 2.6092  Validation loss = 10.0291  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 2.6090  Validation loss = 10.0287  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 2.6088  Validation loss = 10.0282  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 2.6085  Validation loss = 10.0276  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 2.6083  Validation loss = 10.0271  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 2.6081  Validation loss = 10.0265  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 2.6079  Validation loss = 10.0259  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 2.6077  Validation loss = 10.0253  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 2.6074  Validation loss = 10.0248  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 2.6072  Validation loss = 10.0243  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 2.6070  Validation loss = 10.0239  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 2.6067  Validation loss = 10.0233  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 2.6066  Validation loss = 10.0228  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 2.6064  Validation loss = 10.0224  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 2.6062  Validation loss = 10.0220  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 2.6059  Validation loss = 10.0213  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 2.6058  Validation loss = 10.0208  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 2.6055  Validation loss = 10.0204  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 2.6053  Validation loss = 10.0199  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 2.6050  Validation loss = 10.0194  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 2.6049  Validation loss = 10.0189  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 2.6046  Validation loss = 10.0184  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 2.6043  Validation loss = 10.0177  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 2.6040  Validation loss = 10.0172  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 2.6038  Validation loss = 10.0168  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 2.6036  Validation loss = 10.0162  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 2.6033  Validation loss = 10.0155  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 2.6031  Validation loss = 10.0150  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 2.6028  Validation loss = 10.0144  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 2.6027  Validation loss = 10.0139  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 2.6023  Validation loss = 10.0130  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 2.6021  Validation loss = 10.0126  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 2.6019  Validation loss = 10.0120  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 2.6016  Validation loss = 10.0115  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 2.6013  Validation loss = 10.0110  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 2.6011  Validation loss = 10.0106  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 2.6008  Validation loss = 10.0102  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 2.6006  Validation loss = 10.0096  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 2.6003  Validation loss = 10.0091  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 2.6001  Validation loss = 10.0085  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 2.5999  Validation loss = 10.0081  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 2.5997  Validation loss = 10.0076  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 2.5994  Validation loss = 10.0070  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 2.5992  Validation loss = 10.0062  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 2.5989  Validation loss = 10.0057  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 2.5986  Validation loss = 10.0051  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 2.5984  Validation loss = 10.0047  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 2.5981  Validation loss = 10.0042  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 2.5979  Validation loss = 10.0036  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 2.5977  Validation loss = 10.0031  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 2.5974  Validation loss = 10.0027  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 2.5972  Validation loss = 10.0022  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 2.5969  Validation loss = 10.0017  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 2.5967  Validation loss = 10.0012  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 2.5965  Validation loss = 10.0009  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 2.5962  Validation loss = 10.0004  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 2.5960  Validation loss = 9.9999  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 2.5957  Validation loss = 9.9994  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 2.5956  Validation loss = 9.9990  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 2.5953  Validation loss = 9.9985  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 2.5951  Validation loss = 9.9980  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 2.5948  Validation loss = 9.9974  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 2.5946  Validation loss = 9.9970  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 2.5944  Validation loss = 9.9965  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 2.5940  Validation loss = 9.9958  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 2.5938  Validation loss = 9.9952  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 2.5936  Validation loss = 9.9948  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 2.5933  Validation loss = 9.9942  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 2.5931  Validation loss = 9.9935  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 2.5928  Validation loss = 9.9930  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 2.5925  Validation loss = 9.9924  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 2.5923  Validation loss = 9.9921  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 2.5921  Validation loss = 9.9916  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 2.5919  Validation loss = 9.9912  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 2.5916  Validation loss = 9.9906  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 2.5914  Validation loss = 9.9900  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 2.5911  Validation loss = 9.9895  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 2.5909  Validation loss = 9.9890  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 2.5906  Validation loss = 9.9884  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 2.5904  Validation loss = 9.9881  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 2.5902  Validation loss = 9.9876  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 2.5900  Validation loss = 9.9871  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 2.5897  Validation loss = 9.9866  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 2.5895  Validation loss = 9.9861  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 2.5893  Validation loss = 9.9857  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 2.5891  Validation loss = 9.9852  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 2.5889  Validation loss = 9.9847  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 2.5887  Validation loss = 9.9844  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 2.5885  Validation loss = 9.9840  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 2.5882  Validation loss = 9.9834  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 2.5880  Validation loss = 9.9830  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 2.5877  Validation loss = 9.9826  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 2.5875  Validation loss = 9.9823  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 2.5873  Validation loss = 9.9819  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 2.5871  Validation loss = 9.9815  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 2.5869  Validation loss = 9.9810  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 2.5866  Validation loss = 9.9805  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 2.5863  Validation loss = 9.9801  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 2.5861  Validation loss = 9.9797  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 2.5859  Validation loss = 9.9793  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 2.5857  Validation loss = 9.9789  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 2.5854  Validation loss = 9.9784  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 2.5852  Validation loss = 9.9780  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 2.5850  Validation loss = 9.9775  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 2.5847  Validation loss = 9.9770  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 2.5845  Validation loss = 9.9766  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 2.5843  Validation loss = 9.9762  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 2.5841  Validation loss = 9.9756  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 2.5838  Validation loss = 9.9751  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 2.5836  Validation loss = 9.9746  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 2.5834  Validation loss = 9.9742  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 2.5831  Validation loss = 9.9737  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 2.5829  Validation loss = 9.9734  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 2.5827  Validation loss = 9.9729  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 2.5825  Validation loss = 9.9725  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 2.5822  Validation loss = 9.9719  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 2.5819  Validation loss = 9.9715  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 2.5817  Validation loss = 9.9711  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 2.5815  Validation loss = 9.9707  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 2.5812  Validation loss = 9.9702  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 2.5810  Validation loss = 9.9697  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 2.5808  Validation loss = 9.9693  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 2.5806  Validation loss = 9.9688  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 2.5803  Validation loss = 9.9683  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 2.5801  Validation loss = 9.9678  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 2.5799  Validation loss = 9.9675  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 2.5796  Validation loss = 9.9670  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 2.5795  Validation loss = 9.9666  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 2.5792  Validation loss = 9.9662  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 2.5790  Validation loss = 9.9657  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 2.5788  Validation loss = 9.9652  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 2.5785  Validation loss = 9.9648  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 2.5784  Validation loss = 9.9644  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 2.5781  Validation loss = 9.9639  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 2.5778  Validation loss = 9.9634  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 2.5776  Validation loss = 9.9629  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 2.5774  Validation loss = 9.9626  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 2.5772  Validation loss = 9.9622  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 2.5770  Validation loss = 9.9618  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 2.5768  Validation loss = 9.9614  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 2.5765  Validation loss = 9.9609  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 2.5764  Validation loss = 9.9605  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 2.5761  Validation loss = 9.9600  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 2.5759  Validation loss = 9.9596  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 2.5756  Validation loss = 9.9592  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 2.5754  Validation loss = 9.9588  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 2.5752  Validation loss = 9.9584  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 2.5750  Validation loss = 9.9581  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 2.5747  Validation loss = 9.9576  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 2.5745  Validation loss = 9.9571  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 2.5743  Validation loss = 9.9568  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 2.5741  Validation loss = 9.9565  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 2.5739  Validation loss = 9.9561  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 2.5737  Validation loss = 9.9557  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 2.5735  Validation loss = 9.9554  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 2.5733  Validation loss = 9.9551  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 2.5731  Validation loss = 9.9546  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 2.5729  Validation loss = 9.9542  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 2.5727  Validation loss = 9.9537  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 2.5724  Validation loss = 9.9532  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 2.5722  Validation loss = 9.9529  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 2.5720  Validation loss = 9.9524  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 2.5718  Validation loss = 9.9521  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 2.5716  Validation loss = 9.9517  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 2.5714  Validation loss = 9.9514  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 2.5712  Validation loss = 9.9510  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 2.5710  Validation loss = 9.9505  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 2.5708  Validation loss = 9.9502  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 2.5705  Validation loss = 9.9498  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 2.5703  Validation loss = 9.9494  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 2.5701  Validation loss = 9.9491  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 2.5699  Validation loss = 9.9487  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 2.5696  Validation loss = 9.9482  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 2.5694  Validation loss = 9.9478  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 2.5692  Validation loss = 9.9475  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 2.5690  Validation loss = 9.9470  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 2.5687  Validation loss = 9.9465  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 2.5684  Validation loss = 9.9461  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 2.5682  Validation loss = 9.9455  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 2.5679  Validation loss = 9.9452  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 2.5677  Validation loss = 9.9448  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 2.5676  Validation loss = 9.9445  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 2.5673  Validation loss = 9.9441  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 2.5671  Validation loss = 9.9437  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 2.5668  Validation loss = 9.9433  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 2.5667  Validation loss = 9.9430  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 2.5665  Validation loss = 9.9426  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 2.5663  Validation loss = 9.9423  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 2.5660  Validation loss = 9.9417  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 2.5658  Validation loss = 9.9413  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 2.5655  Validation loss = 9.9408  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 2.5653  Validation loss = 9.9404  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 2.5650  Validation loss = 9.9398  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 2.5648  Validation loss = 9.9395  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 2.5646  Validation loss = 9.9390  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 2.5644  Validation loss = 9.9387  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 2.5642  Validation loss = 9.9382  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 2.5640  Validation loss = 9.9379  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 2.5638  Validation loss = 9.9375  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 2.5636  Validation loss = 9.9372  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 2.5633  Validation loss = 9.9366  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 2.5631  Validation loss = 9.9363  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 2.5629  Validation loss = 9.9360  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 2.5627  Validation loss = 9.9356  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 2.5625  Validation loss = 9.9353  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 2.5623  Validation loss = 9.9349  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 2.5621  Validation loss = 9.9344  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 2.5618  Validation loss = 9.9339  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 2.5615  Validation loss = 9.9334  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 2.5612  Validation loss = 9.9330  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 2.5610  Validation loss = 9.9325  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 2.5608  Validation loss = 9.9322  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 2.5605  Validation loss = 9.9316  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 2.5602  Validation loss = 9.9311  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 2.5600  Validation loss = 9.9308  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 2.5598  Validation loss = 9.9302  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 2.5596  Validation loss = 9.9298  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 2.5593  Validation loss = 9.9294  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 2.5591  Validation loss = 9.9290  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 2.5589  Validation loss = 9.9286  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 2.5587  Validation loss = 9.9282  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 2.5584  Validation loss = 9.9277  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 2.5582  Validation loss = 9.9274  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 2.5580  Validation loss = 9.9270  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 2.5578  Validation loss = 9.9265  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 3.5270  Validation loss = 5.3622  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 3.5266  Validation loss = 5.3610  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 3.5260  Validation loss = 5.3595  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 3.5257  Validation loss = 5.3591  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 3.5254  Validation loss = 5.3585  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 3.5250  Validation loss = 5.3578  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 3.5247  Validation loss = 5.3571  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 3.5244  Validation loss = 5.3567  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 3.5239  Validation loss = 5.3557  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 3.5236  Validation loss = 5.3551  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 3.5233  Validation loss = 5.3545  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 3.5230  Validation loss = 5.3539  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 3.5227  Validation loss = 5.3534  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 3.5224  Validation loss = 5.3529  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 3.5222  Validation loss = 5.3526  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 3.5219  Validation loss = 5.3520  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 3.5215  Validation loss = 5.3513  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 3.5212  Validation loss = 5.3508  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 3.5209  Validation loss = 5.3503  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 3.5205  Validation loss = 5.3496  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 3.5202  Validation loss = 5.3490  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 3.5198  Validation loss = 5.3484  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 3.5195  Validation loss = 5.3478  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 3.5192  Validation loss = 5.3473  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 3.5189  Validation loss = 5.3467  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 3.5185  Validation loss = 5.3459  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 3.5181  Validation loss = 5.3453  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 3.5178  Validation loss = 5.3447  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 3.5175  Validation loss = 5.3442  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 3.5173  Validation loss = 5.3437  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 3.5171  Validation loss = 5.3434  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 3.5166  Validation loss = 5.3425  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 3.5162  Validation loss = 5.3418  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 3.5159  Validation loss = 5.3412  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 3.5155  Validation loss = 5.3405  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 3.5152  Validation loss = 5.3399  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 3.5149  Validation loss = 5.3394  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 3.5146  Validation loss = 5.3390  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 3.5143  Validation loss = 5.3384  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 3.5138  Validation loss = 5.3375  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 3.5136  Validation loss = 5.3371  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 3.5132  Validation loss = 5.3364  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 3.5129  Validation loss = 5.3359  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 3.5126  Validation loss = 5.3353  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 3.5123  Validation loss = 5.3349  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 3.5120  Validation loss = 5.3343  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 3.5117  Validation loss = 5.3338  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 3.5115  Validation loss = 5.3333  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 3.5112  Validation loss = 5.3328  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 3.5108  Validation loss = 5.3322  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 3.5105  Validation loss = 5.3316  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 3.5102  Validation loss = 5.3310  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 3.5098  Validation loss = 5.3302  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 3.5095  Validation loss = 5.3298  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 3.5092  Validation loss = 5.3292  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 3.5089  Validation loss = 5.3288  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 3.5086  Validation loss = 5.3282  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 3.5082  Validation loss = 5.3275  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 3.5079  Validation loss = 5.3269  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 3.5076  Validation loss = 5.3264  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 3.5074  Validation loss = 5.3260  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 3.5071  Validation loss = 5.3255  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 3.5069  Validation loss = 5.3251  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 3.5066  Validation loss = 5.3246  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 3.5063  Validation loss = 5.3240  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 3.5059  Validation loss = 5.3234  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 3.5056  Validation loss = 5.3228  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 3.5052  Validation loss = 5.3221  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 3.5049  Validation loss = 5.3215  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 3.5046  Validation loss = 5.3210  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 3.5043  Validation loss = 5.3205  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 3.5041  Validation loss = 5.3201  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 3.5038  Validation loss = 5.3196  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 3.5035  Validation loss = 5.3190  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 3.5032  Validation loss = 5.3183  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 3.5028  Validation loss = 5.3177  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 3.5025  Validation loss = 5.3172  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 3.5022  Validation loss = 5.3167  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 3.5020  Validation loss = 5.3162  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 3.5017  Validation loss = 5.3157  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 3.5013  Validation loss = 5.3151  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 3.5009  Validation loss = 5.3144  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 3.5004  Validation loss = 5.3135  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 3.5002  Validation loss = 5.3131  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 3.4998  Validation loss = 5.3124  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 3.4996  Validation loss = 5.3120  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 3.4992  Validation loss = 5.3113  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 3.4989  Validation loss = 5.3108  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 3.4986  Validation loss = 5.3102  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 3.4981  Validation loss = 5.3092  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 3.4977  Validation loss = 5.3084  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 3.4974  Validation loss = 5.3079  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 3.4971  Validation loss = 5.3074  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 3.4968  Validation loss = 5.3069  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 3.4965  Validation loss = 5.3063  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 3.4961  Validation loss = 5.3057  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 3.4958  Validation loss = 5.3052  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 3.4956  Validation loss = 5.3046  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 3.4953  Validation loss = 5.3041  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 3.4949  Validation loss = 5.3034  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 3.4946  Validation loss = 5.3029  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 3.4943  Validation loss = 5.3023  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 3.4939  Validation loss = 5.3016  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 3.4936  Validation loss = 5.3010  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 3.4932  Validation loss = 5.3004  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 3.4929  Validation loss = 5.2999  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 3.4926  Validation loss = 5.2992  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 3.4922  Validation loss = 5.2986  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 3.4920  Validation loss = 5.2982  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 3.4917  Validation loss = 5.2977  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 3.4913  Validation loss = 5.2971  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 3.4911  Validation loss = 5.2967  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 3.4908  Validation loss = 5.2962  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 3.4906  Validation loss = 5.2957  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 3.4902  Validation loss = 5.2951  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 3.4899  Validation loss = 5.2945  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 3.4896  Validation loss = 5.2939  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 3.4893  Validation loss = 5.2933  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 3.4890  Validation loss = 5.2928  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 3.4887  Validation loss = 5.2923  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 3.4884  Validation loss = 5.2917  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 3.4880  Validation loss = 5.2911  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 3.4878  Validation loss = 5.2907  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 3.4876  Validation loss = 5.2902  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 3.4872  Validation loss = 5.2896  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 3.4869  Validation loss = 5.2890  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 3.4866  Validation loss = 5.2885  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 3.4864  Validation loss = 5.2881  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 3.4861  Validation loss = 5.2877  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 3.4858  Validation loss = 5.2871  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 3.4856  Validation loss = 5.2867  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 3.4852  Validation loss = 5.2860  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 3.4849  Validation loss = 5.2855  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 3.4846  Validation loss = 5.2848  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 3.4842  Validation loss = 5.2842  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 3.4839  Validation loss = 5.2836  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 3.4834  Validation loss = 5.2827  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 3.4831  Validation loss = 5.2821  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 3.4828  Validation loss = 5.2817  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 3.4826  Validation loss = 5.2812  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 3.4823  Validation loss = 5.2807  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 3.4821  Validation loss = 5.2803  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 3.4817  Validation loss = 5.2796  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 3.4813  Validation loss = 5.2789  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 3.4810  Validation loss = 5.2784  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 3.4808  Validation loss = 5.2781  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 3.4806  Validation loss = 5.2777  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 3.4803  Validation loss = 5.2771  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 3.4799  Validation loss = 5.2764  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 3.4795  Validation loss = 5.2757  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 3.4793  Validation loss = 5.2753  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 3.4789  Validation loss = 5.2747  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 3.4785  Validation loss = 5.2738  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 3.4782  Validation loss = 5.2733  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 3.4779  Validation loss = 5.2727  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 3.4776  Validation loss = 5.2722  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 3.4773  Validation loss = 5.2716  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 3.4771  Validation loss = 5.2712  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 3.4767  Validation loss = 5.2707  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 3.4764  Validation loss = 5.2701  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 3.4761  Validation loss = 5.2695  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 3.4758  Validation loss = 5.2689  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 3.4755  Validation loss = 5.2685  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 3.4753  Validation loss = 5.2681  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 3.4750  Validation loss = 5.2675  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 3.4747  Validation loss = 5.2670  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 3.4744  Validation loss = 5.2665  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 3.4741  Validation loss = 5.2659  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 3.4739  Validation loss = 5.2656  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 3.4736  Validation loss = 5.2650  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 3.4732  Validation loss = 5.2642  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 3.4728  Validation loss = 5.2635  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 3.4725  Validation loss = 5.2629  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 3.4721  Validation loss = 5.2622  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 3.4717  Validation loss = 5.2614  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 3.4714  Validation loss = 5.2609  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 3.4711  Validation loss = 5.2601  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 3.4707  Validation loss = 5.2591  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 3.4703  Validation loss = 5.2582  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 3.4700  Validation loss = 5.2569  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 3.4691  Validation loss = 5.2503  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 3.4667  Validation loss = 5.2275  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 3.4652  Validation loss = 5.2175  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 3.4649  Validation loss = 5.2169  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 3.4646  Validation loss = 5.2161  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 3.4642  Validation loss = 5.2155  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 3.4640  Validation loss = 5.2150  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 3.4637  Validation loss = 5.2144  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 3.4633  Validation loss = 5.2137  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 3.4631  Validation loss = 5.2133  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 3.4628  Validation loss = 5.2127  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 3.4626  Validation loss = 5.2123  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 3.4622  Validation loss = 5.2117  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 3.4618  Validation loss = 5.2109  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 3.4614  Validation loss = 5.2101  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 3.4612  Validation loss = 5.2097  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 3.4609  Validation loss = 5.2092  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 3.4606  Validation loss = 5.2086  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 3.4602  Validation loss = 5.2079  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 3.4598  Validation loss = 5.2071  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 3.4595  Validation loss = 5.2065  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 3.4592  Validation loss = 5.2060  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 3.4589  Validation loss = 5.2054  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 3.4586  Validation loss = 5.2049  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 3.4582  Validation loss = 5.2043  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 3.4579  Validation loss = 5.2037  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 3.4576  Validation loss = 5.2032  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 3.4574  Validation loss = 5.2028  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 3.4570  Validation loss = 5.2021  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 3.4568  Validation loss = 5.2017  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 3.4565  Validation loss = 5.2012  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 3.4561  Validation loss = 5.2005  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 3.4559  Validation loss = 5.2000  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 3.4556  Validation loss = 5.1994  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 3.4552  Validation loss = 5.1988  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 3.4548  Validation loss = 5.1980  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 3.4545  Validation loss = 5.1974  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 3.4541  Validation loss = 5.1969  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 3.4539  Validation loss = 5.1965  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 3.4536  Validation loss = 5.1959  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 3.4534  Validation loss = 5.1956  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 3.4532  Validation loss = 5.1952  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 3.4530  Validation loss = 5.1948  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 3.4527  Validation loss = 5.1942  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 3.4523  Validation loss = 5.1935  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 3.4519  Validation loss = 5.1928  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 3.4516  Validation loss = 5.1921  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 3.4513  Validation loss = 5.1916  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 3.4510  Validation loss = 5.1911  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 3.4507  Validation loss = 5.1905  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 3.4503  Validation loss = 5.1899  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 3.4500  Validation loss = 5.1894  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 3.4497  Validation loss = 5.1889  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 3.4494  Validation loss = 5.1883  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 3.4492  Validation loss = 5.1879  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 3.4489  Validation loss = 5.1873  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 3.4487  Validation loss = 5.1869  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 3.4483  Validation loss = 5.1862  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 3.4479  Validation loss = 5.1855  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 3.4476  Validation loss = 5.1848  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 3.4473  Validation loss = 5.1844  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 3.4469  Validation loss = 5.1837  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 3.4466  Validation loss = 5.1831  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 3.4463  Validation loss = 5.1826  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 3.4459  Validation loss = 5.1819  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 3.4456  Validation loss = 5.1814  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 3.4453  Validation loss = 5.1807  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 3.4449  Validation loss = 5.1800  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 3.4447  Validation loss = 5.1796  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 3.4444  Validation loss = 5.1791  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 3.4442  Validation loss = 5.1785  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 3.4438  Validation loss = 5.1780  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 3.4435  Validation loss = 5.1773  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 3.4432  Validation loss = 5.1767  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 3.4430  Validation loss = 5.1763  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 3.4426  Validation loss = 5.1757  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 3.4423  Validation loss = 5.1751  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 3.4419  Validation loss = 5.1745  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 3.4417  Validation loss = 5.1739  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 3.4414  Validation loss = 5.1735  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 3.4412  Validation loss = 5.1730  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 3.4409  Validation loss = 5.1725  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 3.4405  Validation loss = 5.1718  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 3.4402  Validation loss = 5.1713  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 3.4396  Validation loss = 5.1703  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 3.4394  Validation loss = 5.1698  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 3.4391  Validation loss = 5.1693  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 3.4387  Validation loss = 5.1686  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 3.4385  Validation loss = 5.1681  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 3.4382  Validation loss = 5.1676  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 3.4378  Validation loss = 5.1669  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 3.4376  Validation loss = 5.1665  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 3.4372  Validation loss = 5.1658  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 3.4368  Validation loss = 5.1652  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 3.4365  Validation loss = 5.1647  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 3.4363  Validation loss = 5.1643  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 3.4360  Validation loss = 5.1637  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 3.4357  Validation loss = 5.1631  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 3.4352  Validation loss = 5.1622  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 3.4349  Validation loss = 5.1616  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 3.4346  Validation loss = 5.1611  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 3.4342  Validation loss = 5.1604  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 3.4339  Validation loss = 5.1598  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 3.4335  Validation loss = 5.1590  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 3.4333  Validation loss = 5.1586  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 3.4330  Validation loss = 5.1582  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 3.4327  Validation loss = 5.1575  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 3.4324  Validation loss = 5.1571  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 3.4321  Validation loss = 5.1564  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 3.4319  Validation loss = 5.1561  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 3.4317  Validation loss = 5.1556  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 3.4314  Validation loss = 5.1550  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 3.4311  Validation loss = 5.1545  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 3.4307  Validation loss = 5.1538  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 3.4304  Validation loss = 5.1533  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 3.4301  Validation loss = 5.1527  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 3.4298  Validation loss = 5.1522  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 3.4296  Validation loss = 5.1518  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 3.4294  Validation loss = 5.1514  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 3.4292  Validation loss = 5.1511  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 3.4289  Validation loss = 5.1505  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 3.4287  Validation loss = 5.1501  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 3.4284  Validation loss = 5.1497  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 3.4281  Validation loss = 5.1492  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 3.4278  Validation loss = 5.1486  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 3.4274  Validation loss = 5.1479  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 3.4270  Validation loss = 5.1472  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 3.4268  Validation loss = 5.1468  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 3.4265  Validation loss = 5.1462  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 3.4262  Validation loss = 5.1457  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 3.4260  Validation loss = 5.1453  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 3.4257  Validation loss = 5.1448  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 3.4254  Validation loss = 5.1442  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 3.4251  Validation loss = 5.1436  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 3.4247  Validation loss = 5.1430  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 3.4245  Validation loss = 5.1425  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 3.4242  Validation loss = 5.1419  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 3.4239  Validation loss = 5.1414  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 3.4235  Validation loss = 5.1407  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 3.4232  Validation loss = 5.1402  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 3.4230  Validation loss = 5.1397  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 3.4226  Validation loss = 5.1391  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 3.4223  Validation loss = 5.1386  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 3.4221  Validation loss = 5.1382  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 3.4218  Validation loss = 5.1376  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 3.4214  Validation loss = 5.1370  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 3.4212  Validation loss = 5.1365  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 3.4209  Validation loss = 5.1360  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 3.4206  Validation loss = 5.1354  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 3.4202  Validation loss = 5.1346  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 3.4199  Validation loss = 5.1341  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 3.4194  Validation loss = 5.1333  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 3.4192  Validation loss = 5.1328  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 3.4189  Validation loss = 5.1323  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 3.4186  Validation loss = 5.1318  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 3.4184  Validation loss = 5.1314  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 3.4181  Validation loss = 5.1309  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 3.4178  Validation loss = 5.1304  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 3.4176  Validation loss = 5.1300  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 3.4173  Validation loss = 5.1295  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 3.4170  Validation loss = 5.1290  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 3.4166  Validation loss = 5.1281  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 3.4163  Validation loss = 5.1275  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 3.4161  Validation loss = 5.1271  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 3.4158  Validation loss = 5.1265  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 3.4155  Validation loss = 5.1261  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 3.4153  Validation loss = 5.1257  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 3.4150  Validation loss = 5.1252  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 3.4147  Validation loss = 5.1246  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 3.4143  Validation loss = 5.1239  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 3.4141  Validation loss = 5.1234  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 3.4138  Validation loss = 5.1230  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 3.4135  Validation loss = 5.1223  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 3.4131  Validation loss = 5.1216  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 3.4127  Validation loss = 5.1209  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 3.4124  Validation loss = 5.1204  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 3.4122  Validation loss = 5.1199  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 3.4119  Validation loss = 5.1194  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 3.4115  Validation loss = 5.1186  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 3.4112  Validation loss = 5.1180  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 3.4109  Validation loss = 5.1174  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 3.4106  Validation loss = 5.1170  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 3.4104  Validation loss = 5.1164  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 3.4101  Validation loss = 5.1159  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 3.4097  Validation loss = 5.1153  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 3.4095  Validation loss = 5.1148  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 3.4092  Validation loss = 5.1143  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 3.4090  Validation loss = 5.1139  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 3.4087  Validation loss = 5.1134  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 3.4084  Validation loss = 5.1129  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 3.4082  Validation loss = 5.1124  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 3.4080  Validation loss = 5.1120  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 3.4076  Validation loss = 5.1114  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 3.4073  Validation loss = 5.1108  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 3.4070  Validation loss = 5.1103  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 3.4068  Validation loss = 5.1098  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 3.4064  Validation loss = 5.1092  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 3.4061  Validation loss = 5.1086  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 3.4058  Validation loss = 5.1080  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 3.4055  Validation loss = 5.1075  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 3.4052  Validation loss = 5.1070  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 3.4050  Validation loss = 5.1065  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 3.4046  Validation loss = 5.1059  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 3.4043  Validation loss = 5.1053  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 3.4039  Validation loss = 5.1046  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 3.4036  Validation loss = 5.1039  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 3.4033  Validation loss = 5.1034  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 3.4029  Validation loss = 5.1027  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 3.4027  Validation loss = 5.1022  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 3.4024  Validation loss = 5.1017  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 3.4021  Validation loss = 5.1012  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 3.4018  Validation loss = 5.1006  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 3.4014  Validation loss = 5.0998  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 3.4010  Validation loss = 5.0992  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 3.4008  Validation loss = 5.0987  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 3.4005  Validation loss = 5.0982  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 3.4001  Validation loss = 5.0975  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 3.3999  Validation loss = 5.0971  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 3.3997  Validation loss = 5.0966  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 3.3993  Validation loss = 5.0959  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 3.3988  Validation loss = 5.0950  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 3.3985  Validation loss = 5.0944  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 3.3982  Validation loss = 5.0937  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 3.3979  Validation loss = 5.0933  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 3.3976  Validation loss = 5.0926  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 3.3973  Validation loss = 5.0920  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 3.3971  Validation loss = 5.0917  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 3.3967  Validation loss = 5.0910  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 3.3965  Validation loss = 5.0906  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 3.3963  Validation loss = 5.0902  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 3.3961  Validation loss = 5.0898  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 3.3958  Validation loss = 5.0893  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 3.3954  Validation loss = 5.0886  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 3.3951  Validation loss = 5.0880  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 3.3948  Validation loss = 5.0874  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 3.3946  Validation loss = 5.0870  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 3.3943  Validation loss = 5.0865  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 3.3940  Validation loss = 5.0859  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 3.3937  Validation loss = 5.0854  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 3.3934  Validation loss = 5.0847  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 3.3931  Validation loss = 5.0842  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 3.3928  Validation loss = 5.0837  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 3.3925  Validation loss = 5.0830  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 3.3921  Validation loss = 5.0824  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 3.3919  Validation loss = 5.0820  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 3.3916  Validation loss = 5.0815  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 3.3913  Validation loss = 5.0809  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 3.3911  Validation loss = 5.0806  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 3.3909  Validation loss = 5.0803  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 3.3907  Validation loss = 5.0798  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 3.3903  Validation loss = 5.0792  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 3.3901  Validation loss = 5.0787  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 3.3898  Validation loss = 5.0782  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 3.3896  Validation loss = 5.0777  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 3.3892  Validation loss = 5.0771  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 3.3889  Validation loss = 5.0765  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 3.3886  Validation loss = 5.0758  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 3.3883  Validation loss = 5.0753  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 3.3879  Validation loss = 5.0746  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 3.3877  Validation loss = 5.0741  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 3.3873  Validation loss = 5.0735  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 3.3871  Validation loss = 5.0730  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 3.3869  Validation loss = 5.0726  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 3.3867  Validation loss = 5.0722  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 3.3863  Validation loss = 5.0716  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 3.3861  Validation loss = 5.0711  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 3.3858  Validation loss = 5.0705  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 3.3855  Validation loss = 5.0701  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 3.3852  Validation loss = 5.0694  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 3.3849  Validation loss = 5.0688  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 3.3846  Validation loss = 5.0684  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 3.3843  Validation loss = 5.0678  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 3.3840  Validation loss = 5.0673  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 3.3838  Validation loss = 5.0669  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 3.3835  Validation loss = 5.0662  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 3.3832  Validation loss = 5.0656  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 3.3828  Validation loss = 5.0649  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 3.3825  Validation loss = 5.0643  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 3.3823  Validation loss = 5.0639  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 3.3820  Validation loss = 5.0634  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 3.3817  Validation loss = 5.0628  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 3.3814  Validation loss = 5.0623  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 3.3811  Validation loss = 5.0617  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 3.3809  Validation loss = 5.0612  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 3.3805  Validation loss = 5.0606  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 3.3803  Validation loss = 5.0602  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 3.3800  Validation loss = 5.0597  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 3.3798  Validation loss = 5.0593  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 3.3795  Validation loss = 5.0587  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 3.3792  Validation loss = 5.0582  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 3.3790  Validation loss = 5.0578  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 3.3787  Validation loss = 5.0572  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 3.3784  Validation loss = 5.0566  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 3.3782  Validation loss = 5.0563  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 3.3779  Validation loss = 5.0557  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 3.3777  Validation loss = 5.0552  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 3.3774  Validation loss = 5.0546  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 3.3770  Validation loss = 5.0541  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 3.3768  Validation loss = 5.0537  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 3.3766  Validation loss = 5.0532  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 3.3762  Validation loss = 5.0526  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 3.3759  Validation loss = 5.0519  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 3.3756  Validation loss = 5.0513  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 3.3752  Validation loss = 5.0505  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 3.3748  Validation loss = 5.0499  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 3.3747  Validation loss = 5.0496  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 3.3743  Validation loss = 5.0490  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 3.3741  Validation loss = 5.0485  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 3.3738  Validation loss = 5.0479  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 3.3734  Validation loss = 5.0474  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 3.3732  Validation loss = 5.0469  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 3.3730  Validation loss = 5.0464  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 3.3727  Validation loss = 5.0459  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 3.3724  Validation loss = 5.0455  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 3.3721  Validation loss = 5.0448  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 3.3719  Validation loss = 5.0444  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 3.3716  Validation loss = 5.0439  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 3.3714  Validation loss = 5.0435  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 3.3709  Validation loss = 5.0427  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 3.3706  Validation loss = 5.0421  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 3.5791  Validation loss = 2.9059  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 3.5788  Validation loss = 2.9054  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 3.5785  Validation loss = 2.9049  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 3.5783  Validation loss = 2.9043  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 3.5779  Validation loss = 2.9037  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 3.5776  Validation loss = 2.9031  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 3.5771  Validation loss = 2.9023  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 3.5769  Validation loss = 2.9019  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 3.5764  Validation loss = 2.9011  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 3.5761  Validation loss = 2.9005  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 3.5757  Validation loss = 2.8999  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 3.5753  Validation loss = 2.8992  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 3.5749  Validation loss = 2.8985  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 3.5746  Validation loss = 2.8980  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 3.5743  Validation loss = 2.8975  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 3.5740  Validation loss = 2.8970  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 3.5736  Validation loss = 2.8962  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 3.5732  Validation loss = 2.8957  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 3.5729  Validation loss = 2.8950  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 3.5724  Validation loss = 2.8942  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 3.5721  Validation loss = 2.8937  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 3.5718  Validation loss = 2.8932  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 3.5715  Validation loss = 2.8926  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 3.5710  Validation loss = 2.8918  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 3.5706  Validation loss = 2.8912  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 3.5702  Validation loss = 2.8905  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 3.5698  Validation loss = 2.8898  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 3.5693  Validation loss = 2.8889  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 3.5689  Validation loss = 2.8883  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 3.5685  Validation loss = 2.8875  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 3.5681  Validation loss = 2.8868  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 3.5678  Validation loss = 2.8862  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 3.5674  Validation loss = 2.8855  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 3.5670  Validation loss = 2.8849  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 3.5667  Validation loss = 2.8843  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 3.5664  Validation loss = 2.8838  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 3.5660  Validation loss = 2.8831  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 3.5656  Validation loss = 2.8824  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 3.5652  Validation loss = 2.8818  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 3.5649  Validation loss = 2.8813  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 3.5645  Validation loss = 2.8806  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 3.5642  Validation loss = 2.8801  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 3.5639  Validation loss = 2.8795  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 3.5635  Validation loss = 2.8789  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 3.5631  Validation loss = 2.8782  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 3.5628  Validation loss = 2.8776  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 3.5625  Validation loss = 2.8771  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 3.5621  Validation loss = 2.8765  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 3.5616  Validation loss = 2.8756  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 3.5612  Validation loss = 2.8749  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 3.5609  Validation loss = 2.8743  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 3.5605  Validation loss = 2.8736  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 3.5602  Validation loss = 2.8730  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 3.5598  Validation loss = 2.8724  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 3.5594  Validation loss = 2.8716  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 3.5590  Validation loss = 2.8709  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 3.5586  Validation loss = 2.8704  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 3.5583  Validation loss = 2.8697  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 3.5579  Validation loss = 2.8690  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 3.5575  Validation loss = 2.8683  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 3.5571  Validation loss = 2.8677  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 3.5568  Validation loss = 2.8672  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 3.5565  Validation loss = 2.8667  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 3.5561  Validation loss = 2.8660  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 3.5558  Validation loss = 2.8653  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 3.5553  Validation loss = 2.8646  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 3.5549  Validation loss = 2.8639  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 3.5545  Validation loss = 2.8632  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 3.5542  Validation loss = 2.8626  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 3.5538  Validation loss = 2.8620  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 3.5535  Validation loss = 2.8614  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 3.5532  Validation loss = 2.8608  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 3.5528  Validation loss = 2.8601  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 3.5523  Validation loss = 2.8593  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 3.5518  Validation loss = 2.8585  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 3.5516  Validation loss = 2.8581  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 3.5512  Validation loss = 2.8574  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 3.5509  Validation loss = 2.8568  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 3.5505  Validation loss = 2.8562  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 3.5501  Validation loss = 2.8555  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 3.5497  Validation loss = 2.8549  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 3.5494  Validation loss = 2.8543  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 3.5489  Validation loss = 2.8535  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 3.5485  Validation loss = 2.8528  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 3.5482  Validation loss = 2.8523  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 3.5480  Validation loss = 2.8519  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 3.5476  Validation loss = 2.8511  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 3.5473  Validation loss = 2.8506  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 3.5469  Validation loss = 2.8499  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 3.5465  Validation loss = 2.8492  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 3.5462  Validation loss = 2.8488  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 3.5459  Validation loss = 2.8481  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 3.5455  Validation loss = 2.8474  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 3.5452  Validation loss = 2.8469  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 3.5450  Validation loss = 2.8465  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 3.5446  Validation loss = 2.8459  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 3.5442  Validation loss = 2.8452  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 3.5438  Validation loss = 2.8444  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 3.5435  Validation loss = 2.8438  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 3.5431  Validation loss = 2.8431  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 3.5427  Validation loss = 2.8425  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 3.5424  Validation loss = 2.8420  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 3.5420  Validation loss = 2.8413  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 3.5416  Validation loss = 2.8405  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 3.5412  Validation loss = 2.8399  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 3.5409  Validation loss = 2.8394  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 3.5405  Validation loss = 2.8387  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 3.5402  Validation loss = 2.8382  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 3.5398  Validation loss = 2.8374  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 3.5395  Validation loss = 2.8369  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 3.5391  Validation loss = 2.8362  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 3.5388  Validation loss = 2.8357  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 3.5386  Validation loss = 2.8354  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 3.5383  Validation loss = 2.8348  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 3.5379  Validation loss = 2.8341  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 3.5375  Validation loss = 2.8333  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 3.5371  Validation loss = 2.8327  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 3.5368  Validation loss = 2.8321  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 3.5364  Validation loss = 2.8314  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 3.5361  Validation loss = 2.8309  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 3.5358  Validation loss = 2.8303  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 3.5354  Validation loss = 2.8297  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 3.5351  Validation loss = 2.8290  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 3.5348  Validation loss = 2.8285  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 3.5344  Validation loss = 2.8279  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 3.5341  Validation loss = 2.8272  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 3.5337  Validation loss = 2.8266  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 3.5333  Validation loss = 2.8259  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 3.5329  Validation loss = 2.8253  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 3.5325  Validation loss = 2.8246  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 3.5321  Validation loss = 2.8238  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 3.5317  Validation loss = 2.8232  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 3.5313  Validation loss = 2.8225  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 3.5309  Validation loss = 2.8217  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 3.5304  Validation loss = 2.8209  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 3.5301  Validation loss = 2.8204  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 3.5298  Validation loss = 2.8199  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 3.5294  Validation loss = 2.8191  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 3.5292  Validation loss = 2.8187  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 3.5288  Validation loss = 2.8181  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 3.5285  Validation loss = 2.8176  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 3.5281  Validation loss = 2.8170  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 3.5278  Validation loss = 2.8164  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 3.5274  Validation loss = 2.8158  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 3.5270  Validation loss = 2.8151  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 3.5265  Validation loss = 2.8145  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 3.5259  Validation loss = 2.8137  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 3.5252  Validation loss = 2.8130  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 3.5248  Validation loss = 2.8125  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 3.5240  Validation loss = 2.8119  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 3.5232  Validation loss = 2.8112  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 3.5223  Validation loss = 2.8106  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 3.5209  Validation loss = 2.8099  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 3.5205  Validation loss = 2.8095  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 3.5199  Validation loss = 2.8086  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 3.5193  Validation loss = 2.8079  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 3.5189  Validation loss = 2.8074  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 3.5184  Validation loss = 2.8068  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 3.5179  Validation loss = 2.8061  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 3.5177  Validation loss = 2.8056  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 3.5172  Validation loss = 2.8049  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 3.5168  Validation loss = 2.8042  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 3.5164  Validation loss = 2.8035  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 3.5159  Validation loss = 2.8027  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 3.5156  Validation loss = 2.8022  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 3.5152  Validation loss = 2.8015  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 3.5149  Validation loss = 2.8009  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 3.5146  Validation loss = 2.8003  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 3.5141  Validation loss = 2.7996  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 3.5137  Validation loss = 2.7988  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 3.5133  Validation loss = 2.7982  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 3.5130  Validation loss = 2.7976  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 3.5126  Validation loss = 2.7969  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 3.5122  Validation loss = 2.7962  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 3.5119  Validation loss = 2.7956  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 3.5115  Validation loss = 2.7949  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 3.5111  Validation loss = 2.7943  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 3.5107  Validation loss = 2.7936  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 3.5102  Validation loss = 2.7928  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 3.5099  Validation loss = 2.7921  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 3.5095  Validation loss = 2.7915  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 3.5092  Validation loss = 2.7909  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 3.5088  Validation loss = 2.7902  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 3.5085  Validation loss = 2.7897  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 3.5081  Validation loss = 2.7890  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 3.5077  Validation loss = 2.7883  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 3.5074  Validation loss = 2.7877  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 3.5070  Validation loss = 2.7872  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 3.5066  Validation loss = 2.7864  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 3.5063  Validation loss = 2.7859  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 3.5060  Validation loss = 2.7853  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 3.5056  Validation loss = 2.7847  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 3.5052  Validation loss = 2.7840  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 3.5049  Validation loss = 2.7834  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 3.5046  Validation loss = 2.7828  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 3.5042  Validation loss = 2.7823  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 3.5039  Validation loss = 2.7818  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 3.5035  Validation loss = 2.7811  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 3.5032  Validation loss = 2.7805  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 3.5028  Validation loss = 2.7798  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 3.5025  Validation loss = 2.7792  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 3.5021  Validation loss = 2.7785  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 3.5017  Validation loss = 2.7779  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 3.5014  Validation loss = 2.7773  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 3.5011  Validation loss = 2.7767  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 3.5007  Validation loss = 2.7762  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 3.5006  Validation loss = 2.7758  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 3.5002  Validation loss = 2.7752  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 3.4999  Validation loss = 2.7746  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 3.4996  Validation loss = 2.7741  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 3.4992  Validation loss = 2.7735  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 3.4989  Validation loss = 2.7729  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 3.4984  Validation loss = 2.7721  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 3.4981  Validation loss = 2.7714  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 3.4977  Validation loss = 2.7707  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 3.4974  Validation loss = 2.7702  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 3.4970  Validation loss = 2.7695  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 3.4966  Validation loss = 2.7689  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 3.4964  Validation loss = 2.7685  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 3.4960  Validation loss = 2.7679  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 3.4956  Validation loss = 2.7672  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 3.4953  Validation loss = 2.7666  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 3.4950  Validation loss = 2.7661  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 3.4945  Validation loss = 2.7653  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 3.4941  Validation loss = 2.7644  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 3.4937  Validation loss = 2.7638  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 3.4934  Validation loss = 2.7633  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 3.4930  Validation loss = 2.7626  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 3.4927  Validation loss = 2.7621  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 3.4924  Validation loss = 2.7616  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 3.4920  Validation loss = 2.7609  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 3.4916  Validation loss = 2.7602  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 3.4913  Validation loss = 2.7597  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 3.4910  Validation loss = 2.7592  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 3.4908  Validation loss = 2.7587  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 3.4905  Validation loss = 2.7582  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 3.4902  Validation loss = 2.7576  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 3.4899  Validation loss = 2.7571  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 3.4896  Validation loss = 2.7565  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 3.4892  Validation loss = 2.7558  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 3.4888  Validation loss = 2.7552  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 3.4885  Validation loss = 2.7546  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 3.4881  Validation loss = 2.7538  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 3.4877  Validation loss = 2.7532  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 3.4873  Validation loss = 2.7526  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 3.4870  Validation loss = 2.7519  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 3.4865  Validation loss = 2.7512  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 3.4862  Validation loss = 2.7506  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 3.4860  Validation loss = 2.7501  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 3.4857  Validation loss = 2.7496  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 3.4854  Validation loss = 2.7491  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 3.4850  Validation loss = 2.7483  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 3.4846  Validation loss = 2.7477  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 3.4843  Validation loss = 2.7470  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 3.4839  Validation loss = 2.7463  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 3.4835  Validation loss = 2.7457  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 3.4832  Validation loss = 2.7451  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 3.4828  Validation loss = 2.7444  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 3.4825  Validation loss = 2.7439  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 3.4821  Validation loss = 2.7432  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 3.4817  Validation loss = 2.7425  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 3.4815  Validation loss = 2.7420  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 3.4811  Validation loss = 2.7414  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 3.4808  Validation loss = 2.7408  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 3.4804  Validation loss = 2.7401  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 3.4800  Validation loss = 2.7394  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 3.4797  Validation loss = 2.7388  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 3.4792  Validation loss = 2.7381  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 3.4789  Validation loss = 2.7375  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 3.4785  Validation loss = 2.7369  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 3.4781  Validation loss = 2.7362  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 3.4778  Validation loss = 2.7356  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 3.4775  Validation loss = 2.7351  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 3.4772  Validation loss = 2.7344  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 3.4768  Validation loss = 2.7338  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 3.4766  Validation loss = 2.7335  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 3.4764  Validation loss = 2.7330  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 3.4761  Validation loss = 2.7324  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 3.4757  Validation loss = 2.7318  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 3.4754  Validation loss = 2.7312  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 3.4751  Validation loss = 2.7306  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 3.4747  Validation loss = 2.7299  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 3.4743  Validation loss = 2.7292  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 3.4738  Validation loss = 2.7284  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 3.4735  Validation loss = 2.7279  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 3.4731  Validation loss = 2.7270  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 3.4727  Validation loss = 2.7264  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 3.4724  Validation loss = 2.7257  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 3.4720  Validation loss = 2.7250  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 3.4716  Validation loss = 2.7244  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 3.4712  Validation loss = 2.7237  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 3.4709  Validation loss = 2.7231  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 3.4706  Validation loss = 2.7226  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 3.4703  Validation loss = 2.7219  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 3.4700  Validation loss = 2.7213  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 3.4697  Validation loss = 2.7208  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 3.4693  Validation loss = 2.7201  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 3.4689  Validation loss = 2.7194  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 3.4685  Validation loss = 2.7188  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 3.4681  Validation loss = 2.7182  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 3.4677  Validation loss = 2.7174  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 3.4674  Validation loss = 2.7169  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 3.4672  Validation loss = 2.7164  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 3.4668  Validation loss = 2.7158  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 3.4665  Validation loss = 2.7153  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 3.4662  Validation loss = 2.7147  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 3.4659  Validation loss = 2.7140  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 3.4655  Validation loss = 2.7134  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 3.4653  Validation loss = 2.7130  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 3.4649  Validation loss = 2.7124  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 3.4646  Validation loss = 2.7118  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 3.4643  Validation loss = 2.7112  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 3.4639  Validation loss = 2.7105  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 3.4635  Validation loss = 2.7099  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 3.4632  Validation loss = 2.7093  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 3.4630  Validation loss = 2.7089  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 3.4626  Validation loss = 2.7081  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 3.4623  Validation loss = 2.7076  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 3.4620  Validation loss = 2.7070  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 3.4616  Validation loss = 2.7063  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 3.4612  Validation loss = 2.7058  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 3.4609  Validation loss = 2.7051  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 3.4604  Validation loss = 2.7042  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 3.4601  Validation loss = 2.7036  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 3.4597  Validation loss = 2.7029  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 3.4594  Validation loss = 2.7025  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 3.4591  Validation loss = 2.7019  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 3.4588  Validation loss = 2.7013  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 3.4584  Validation loss = 2.7006  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 3.4580  Validation loss = 2.7000  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 3.4577  Validation loss = 2.6993  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 3.4575  Validation loss = 2.6989  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 3.4572  Validation loss = 2.6984  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 3.4569  Validation loss = 2.6979  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 3.4567  Validation loss = 2.6975  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 3.4564  Validation loss = 2.6969  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 3.4560  Validation loss = 2.6964  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 3.4555  Validation loss = 2.6954  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 3.4551  Validation loss = 2.6946  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 3.4547  Validation loss = 2.6939  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 3.4543  Validation loss = 2.6933  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 3.4541  Validation loss = 2.6928  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 3.4537  Validation loss = 2.6920  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 3.4533  Validation loss = 2.6914  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 3.4530  Validation loss = 2.6909  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 3.4527  Validation loss = 2.6903  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 3.4523  Validation loss = 2.6897  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 3.4521  Validation loss = 2.6892  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 3.4517  Validation loss = 2.6887  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 3.4514  Validation loss = 2.6881  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 3.4511  Validation loss = 2.6875  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 3.4507  Validation loss = 2.6869  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 3.4504  Validation loss = 2.6863  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 3.4501  Validation loss = 2.6856  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 3.4498  Validation loss = 2.6851  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 3.4494  Validation loss = 2.6845  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 3.4491  Validation loss = 2.6839  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 3.4488  Validation loss = 2.6833  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 3.4485  Validation loss = 2.6828  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 3.4481  Validation loss = 2.6822  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 3.4480  Validation loss = 2.6819  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 3.4476  Validation loss = 2.6813  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 3.4473  Validation loss = 2.6807  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 3.4469  Validation loss = 2.6800  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 3.4466  Validation loss = 2.6794  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 3.4463  Validation loss = 2.6788  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 3.4459  Validation loss = 2.6781  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 3.4456  Validation loss = 2.6775  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 3.4453  Validation loss = 2.6770  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 3.4449  Validation loss = 2.6762  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 3.4445  Validation loss = 2.6756  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 3.4442  Validation loss = 2.6750  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 3.4439  Validation loss = 2.6744  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 3.4435  Validation loss = 2.6737  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 3.4432  Validation loss = 2.6731  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 3.4428  Validation loss = 2.6726  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 3.4425  Validation loss = 2.6720  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 3.4421  Validation loss = 2.6712  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 3.4418  Validation loss = 2.6707  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 3.4414  Validation loss = 2.6699  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 3.4411  Validation loss = 2.6695  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 3.4409  Validation loss = 2.6689  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 3.4406  Validation loss = 2.6684  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 3.4403  Validation loss = 2.6679  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 3.4399  Validation loss = 2.6673  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 3.4395  Validation loss = 2.6664  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 3.4391  Validation loss = 2.6659  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 3.4388  Validation loss = 2.6652  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 3.4384  Validation loss = 2.6645  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 3.4380  Validation loss = 2.6638  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 3.4376  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 3.4373  Validation loss = 2.6625  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 3.4370  Validation loss = 2.6620  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 3.4367  Validation loss = 2.6614  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 3.4364  Validation loss = 2.6610  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 3.4361  Validation loss = 2.6605  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 3.4357  Validation loss = 2.6598  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 3.4355  Validation loss = 2.6593  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 3.4351  Validation loss = 2.6587  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 3.4348  Validation loss = 2.6581  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 3.4345  Validation loss = 2.6576  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 3.4342  Validation loss = 2.6570  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 3.4339  Validation loss = 2.6565  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 3.4335  Validation loss = 2.6557  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 3.4331  Validation loss = 2.6551  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 3.4328  Validation loss = 2.6546  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 3.4325  Validation loss = 2.6540  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 3.4322  Validation loss = 2.6535  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 3.4320  Validation loss = 2.6531  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 3.4316  Validation loss = 2.6524  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 3.4313  Validation loss = 2.6518  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 3.4309  Validation loss = 2.6511  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 3.4305  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 3.4302  Validation loss = 2.6499  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 3.4298  Validation loss = 2.6492  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 3.4295  Validation loss = 2.6486  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 3.4291  Validation loss = 2.6478  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 3.4288  Validation loss = 2.6472  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 3.4284  Validation loss = 2.6466  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 3.4281  Validation loss = 2.6460  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 3.4277  Validation loss = 2.6454  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 3.4275  Validation loss = 2.6449  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 3.4271  Validation loss = 2.6442  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 3.4268  Validation loss = 2.6436  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 3.4265  Validation loss = 2.6431  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 3.4262  Validation loss = 2.6426  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 3.4259  Validation loss = 2.6420  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 3.4255  Validation loss = 2.6414  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 3.4252  Validation loss = 2.6408  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 3.4250  Validation loss = 2.6404  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 3.4246  Validation loss = 2.6398  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 3.4242  Validation loss = 2.6390  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 3.4239  Validation loss = 2.6385  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 3.4237  Validation loss = 2.6381  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 3.4233  Validation loss = 2.6374  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 3.4229  Validation loss = 2.6367  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 3.4225  Validation loss = 2.6360  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 3.4221  Validation loss = 2.6353  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 3.4218  Validation loss = 2.6347  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 3.4215  Validation loss = 2.6342  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 3.4211  Validation loss = 2.6335  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 3.4208  Validation loss = 2.6328  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 3.4204  Validation loss = 2.6322  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 3.4200  Validation loss = 2.6315  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 3.4197  Validation loss = 2.6309  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 3.4194  Validation loss = 2.6302  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 3.4191  Validation loss = 2.6298  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 3.4188  Validation loss = 2.6292  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 3.4184  Validation loss = 2.6286  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 3.4181  Validation loss = 2.6281  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 3.4177  Validation loss = 2.6275  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 3.4173  Validation loss = 2.6267  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 3.4170  Validation loss = 2.6261  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 3.4167  Validation loss = 2.6256  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 3.4164  Validation loss = 2.6250  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 3.4161  Validation loss = 2.6245  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 3.4159  Validation loss = 2.6240  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 3.4155  Validation loss = 2.6233  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 3.4152  Validation loss = 2.6229  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 3.4148  Validation loss = 2.6222  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 3.4145  Validation loss = 2.6216  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 3.4142  Validation loss = 2.6211  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 3.4138  Validation loss = 2.6205  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 3.4136  Validation loss = 2.6200  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 3.4132  Validation loss = 2.6193  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 3.4128  Validation loss = 2.6186  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 3.4125  Validation loss = 2.6180  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 3.4121  Validation loss = 2.6174  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 3.4118  Validation loss = 2.6168  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 3.4115  Validation loss = 2.6163  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 3.4111  Validation loss = 2.6157  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 3.4108  Validation loss = 2.6150  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 3.4104  Validation loss = 2.6143  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 3.4100  Validation loss = 2.6136  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 3.4099  Validation loss = 2.6133  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 3.4095  Validation loss = 2.6127  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 3.4091  Validation loss = 2.6119  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 3.4088  Validation loss = 2.6114  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 3.4085  Validation loss = 2.6108  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 3.4081  Validation loss = 2.6100  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 3.4077  Validation loss = 2.6093  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 3.4075  Validation loss = 2.6088  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 3.4071  Validation loss = 2.6083  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 3.4069  Validation loss = 2.6078  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 3.4065  Validation loss = 2.6072  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 3.4062  Validation loss = 2.6066  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 3.4059  Validation loss = 2.6060  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 3.4056  Validation loss = 2.6055  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 3.4053  Validation loss = 2.6049  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 3.4050  Validation loss = 2.6044  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 3.4046  Validation loss = 2.6037  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 3.4042  Validation loss = 2.6030  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 3.4038  Validation loss = 2.6023  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 3.4036  Validation loss = 2.6018  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 3.4032  Validation loss = 2.6011  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 3.4029  Validation loss = 2.6007  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 3.4026  Validation loss = 2.6001  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 3.4023  Validation loss = 2.5996  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 3.4021  Validation loss = 2.5991  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 3.4017  Validation loss = 2.5985  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 500  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 3.4477  Validation loss = 3.8429  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 3.4473  Validation loss = 3.8421  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 3.4469  Validation loss = 3.8414  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 3.4465  Validation loss = 3.8407  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 3.4462  Validation loss = 3.8400  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 3.4459  Validation loss = 3.8395  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 3.4455  Validation loss = 3.8388  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 3.4452  Validation loss = 3.8382  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 3.4447  Validation loss = 3.8373  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 3.4443  Validation loss = 3.8366  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 3.4440  Validation loss = 3.8361  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 3.4436  Validation loss = 3.8353  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 3.4432  Validation loss = 3.8347  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 3.4427  Validation loss = 3.8338  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 3.4421  Validation loss = 3.8330  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 3.4409  Validation loss = 3.8318  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 3.4392  Validation loss = 3.8307  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 3.4379  Validation loss = 3.8299  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 3.4358  Validation loss = 3.8286  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 3.4351  Validation loss = 3.8276  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 3.4344  Validation loss = 3.8264  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 3.4339  Validation loss = 3.8256  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 3.4334  Validation loss = 3.8247  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 3.4330  Validation loss = 3.8237  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 3.4327  Validation loss = 3.8232  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 3.4323  Validation loss = 3.8227  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 3.4319  Validation loss = 3.8218  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 3.4316  Validation loss = 3.8212  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 3.4313  Validation loss = 3.8206  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 3.4308  Validation loss = 3.8197  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 3.4304  Validation loss = 3.8190  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 3.4299  Validation loss = 3.8181  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 3.4296  Validation loss = 3.8175  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 3.4292  Validation loss = 3.8167  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 3.4287  Validation loss = 3.8157  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 3.4283  Validation loss = 3.8150  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 3.4280  Validation loss = 3.8144  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 3.4276  Validation loss = 3.8137  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 3.4271  Validation loss = 3.8127  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 3.4267  Validation loss = 3.8119  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 3.4264  Validation loss = 3.8110  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 3.4260  Validation loss = 3.8103  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 3.4256  Validation loss = 3.8096  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 3.4251  Validation loss = 3.8085  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 3.4247  Validation loss = 3.8078  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 3.4243  Validation loss = 3.8070  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 3.4239  Validation loss = 3.8064  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 3.4236  Validation loss = 3.8057  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 3.4232  Validation loss = 3.8049  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 3.4228  Validation loss = 3.8042  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 3.4224  Validation loss = 3.8034  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 3.4220  Validation loss = 3.8027  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 3.4215  Validation loss = 3.8017  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 3.4212  Validation loss = 3.8010  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 3.4210  Validation loss = 3.8006  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 3.4205  Validation loss = 3.7995  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 3.4201  Validation loss = 3.7987  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 3.4197  Validation loss = 3.7979  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 3.4193  Validation loss = 3.7973  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 3.4190  Validation loss = 3.7967  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 3.4187  Validation loss = 3.7960  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 3.4183  Validation loss = 3.7954  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 3.4179  Validation loss = 3.7946  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 3.4176  Validation loss = 3.7939  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 3.4172  Validation loss = 3.7930  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 3.4168  Validation loss = 3.7924  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 3.4165  Validation loss = 3.7917  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 3.4162  Validation loss = 3.7910  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 3.4158  Validation loss = 3.7903  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 3.4154  Validation loss = 3.7895  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 3.4151  Validation loss = 3.7889  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 3.4147  Validation loss = 3.7880  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 3.4143  Validation loss = 3.7873  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 3.4138  Validation loss = 3.7863  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 3.4135  Validation loss = 3.7857  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 3.4131  Validation loss = 3.7849  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 3.4128  Validation loss = 3.7842  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 3.4123  Validation loss = 3.7833  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 3.4120  Validation loss = 3.7827  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 3.4117  Validation loss = 3.7822  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 3.4113  Validation loss = 3.7813  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 3.4109  Validation loss = 3.7805  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 3.4104  Validation loss = 3.7794  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 3.4100  Validation loss = 3.7787  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 3.4096  Validation loss = 3.7780  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 3.4093  Validation loss = 3.7774  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 3.4089  Validation loss = 3.7766  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 3.4086  Validation loss = 3.7760  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 3.4082  Validation loss = 3.7751  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 3.4078  Validation loss = 3.7742  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 3.4075  Validation loss = 3.7736  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 3.4071  Validation loss = 3.7728  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 3.4067  Validation loss = 3.7720  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 3.4064  Validation loss = 3.7715  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 3.4061  Validation loss = 3.7709  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 3.4057  Validation loss = 3.7701  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 3.4053  Validation loss = 3.7692  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 3.4048  Validation loss = 3.7683  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 3.4043  Validation loss = 3.7672  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 3.4039  Validation loss = 3.7665  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 3.4036  Validation loss = 3.7658  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 3.4032  Validation loss = 3.7651  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 3.4028  Validation loss = 3.7643  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 3.4024  Validation loss = 3.7635  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 3.4020  Validation loss = 3.7628  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 3.4016  Validation loss = 3.7620  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 3.4012  Validation loss = 3.7613  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 3.4009  Validation loss = 3.7607  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 3.4005  Validation loss = 3.7600  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 3.4003  Validation loss = 3.7595  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 3.3998  Validation loss = 3.7587  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 3.3995  Validation loss = 3.7579  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 3.3991  Validation loss = 3.7572  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 3.3987  Validation loss = 3.7563  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 3.3982  Validation loss = 3.7553  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 3.3978  Validation loss = 3.7544  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 3.3974  Validation loss = 3.7535  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 3.3970  Validation loss = 3.7528  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 3.3967  Validation loss = 3.7520  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 3.3963  Validation loss = 3.7513  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 3.3960  Validation loss = 3.7507  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 3.3957  Validation loss = 3.7502  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 3.3954  Validation loss = 3.7495  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 3.3951  Validation loss = 3.7490  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 3.3946  Validation loss = 3.7480  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 3.3942  Validation loss = 3.7471  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 3.3939  Validation loss = 3.7465  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 3.3935  Validation loss = 3.7459  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 3.3932  Validation loss = 3.7453  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 3.3928  Validation loss = 3.7445  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 3.3924  Validation loss = 3.7437  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 3.3920  Validation loss = 3.7430  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 3.3917  Validation loss = 3.7424  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 3.3914  Validation loss = 3.7418  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 3.3911  Validation loss = 3.7412  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 3.3908  Validation loss = 3.7406  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 3.3905  Validation loss = 3.7401  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 3.3901  Validation loss = 3.7393  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 3.3898  Validation loss = 3.7387  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 3.3893  Validation loss = 3.7376  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 3.3889  Validation loss = 3.7368  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 3.3885  Validation loss = 3.7359  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 3.3881  Validation loss = 3.7351  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 3.3878  Validation loss = 3.7343  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 3.3874  Validation loss = 3.7336  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 3.3871  Validation loss = 3.7331  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 3.3868  Validation loss = 3.7324  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 3.3864  Validation loss = 3.7316  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 3.3859  Validation loss = 3.7306  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 3.3854  Validation loss = 3.7297  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 3.3851  Validation loss = 3.7291  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 3.3848  Validation loss = 3.7283  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 3.3844  Validation loss = 3.7277  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 3.3841  Validation loss = 3.7270  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 3.3838  Validation loss = 3.7263  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 3.3833  Validation loss = 3.7252  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 3.3829  Validation loss = 3.7246  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 3.3825  Validation loss = 3.7236  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 3.3822  Validation loss = 3.7230  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 3.3818  Validation loss = 3.7222  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 3.3814  Validation loss = 3.7213  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 3.3810  Validation loss = 3.7208  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 3.3806  Validation loss = 3.7201  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 3.3803  Validation loss = 3.7194  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 3.3799  Validation loss = 3.7187  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 3.3796  Validation loss = 3.7180  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 3.3793  Validation loss = 3.7173  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 3.3789  Validation loss = 3.7167  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 3.3786  Validation loss = 3.7160  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 3.3782  Validation loss = 3.7151  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 3.3779  Validation loss = 3.7146  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 3.3775  Validation loss = 3.7138  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 3.3771  Validation loss = 3.7129  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 3.3767  Validation loss = 3.7122  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 3.3764  Validation loss = 3.7114  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 3.3759  Validation loss = 3.7106  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 3.3756  Validation loss = 3.7101  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 3.3753  Validation loss = 3.7096  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 3.3750  Validation loss = 3.7089  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 3.3746  Validation loss = 3.7081  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 3.3742  Validation loss = 3.7072  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 3.3738  Validation loss = 3.7065  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 3.3734  Validation loss = 3.7055  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 3.3731  Validation loss = 3.7049  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 3.3727  Validation loss = 3.7041  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 3.3723  Validation loss = 3.7034  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 3.3721  Validation loss = 3.7030  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 3.3718  Validation loss = 3.7023  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 3.3714  Validation loss = 3.7016  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 3.3711  Validation loss = 3.7009  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 3.3708  Validation loss = 3.7003  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 3.3705  Validation loss = 3.6998  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 3.3701  Validation loss = 3.6989  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 3.3697  Validation loss = 3.6981  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 3.3694  Validation loss = 3.6974  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 3.3690  Validation loss = 3.6966  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 3.3686  Validation loss = 3.6959  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 3.3682  Validation loss = 3.6949  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 3.3677  Validation loss = 3.6939  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 3.3673  Validation loss = 3.6931  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 3.3670  Validation loss = 3.6924  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 3.3666  Validation loss = 3.6917  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 3.3663  Validation loss = 3.6910  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 3.3660  Validation loss = 3.6903  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 3.3656  Validation loss = 3.6895  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 3.3652  Validation loss = 3.6887  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 3.3648  Validation loss = 3.6879  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 3.3643  Validation loss = 3.6869  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 3.3640  Validation loss = 3.6863  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 3.3637  Validation loss = 3.6856  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 3.3633  Validation loss = 3.6848  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 3.3630  Validation loss = 3.6843  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 3.3625  Validation loss = 3.6833  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 3.3621  Validation loss = 3.6824  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 3.3617  Validation loss = 3.6816  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 3.3613  Validation loss = 3.6807  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 3.3608  Validation loss = 3.6799  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 3.3605  Validation loss = 3.6791  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 3.3601  Validation loss = 3.6785  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 3.3597  Validation loss = 3.6777  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 3.3594  Validation loss = 3.6769  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 3.3591  Validation loss = 3.6763  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 3.3586  Validation loss = 3.6754  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 3.3582  Validation loss = 3.6746  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 3.3579  Validation loss = 3.6740  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 3.3576  Validation loss = 3.6733  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 3.3572  Validation loss = 3.6726  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 3.3569  Validation loss = 3.6719  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 3.3565  Validation loss = 3.6711  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 3.3562  Validation loss = 3.6704  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 3.3558  Validation loss = 3.6695  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 3.3555  Validation loss = 3.6690  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 3.3552  Validation loss = 3.6684  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 3.3549  Validation loss = 3.6677  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 3.3545  Validation loss = 3.6668  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 3.3542  Validation loss = 3.6662  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 3.3539  Validation loss = 3.6657  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 3.3534  Validation loss = 3.6647  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 3.3532  Validation loss = 3.6641  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 3.3528  Validation loss = 3.6633  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 3.3523  Validation loss = 3.6623  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 3.3519  Validation loss = 3.6614  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 3.3516  Validation loss = 3.6607  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 3.3513  Validation loss = 3.6601  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 3.3509  Validation loss = 3.6593  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 3.3506  Validation loss = 3.6586  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 3.3503  Validation loss = 3.6578  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 3.3498  Validation loss = 3.6569  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 3.3495  Validation loss = 3.6562  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 3.3492  Validation loss = 3.6555  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 3.3489  Validation loss = 3.6549  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 3.3485  Validation loss = 3.6542  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 3.3482  Validation loss = 3.6535  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 3.3479  Validation loss = 3.6528  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 3.3475  Validation loss = 3.6520  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 3.3472  Validation loss = 3.6514  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 3.3470  Validation loss = 3.6510  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 3.3466  Validation loss = 3.6503  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 3.3462  Validation loss = 3.6495  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 3.3459  Validation loss = 3.6489  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 3.3456  Validation loss = 3.6483  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 3.3451  Validation loss = 3.6472  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 3.3448  Validation loss = 3.6465  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 3.3444  Validation loss = 3.6456  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 3.3440  Validation loss = 3.6449  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 3.3437  Validation loss = 3.6444  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 3.3433  Validation loss = 3.6436  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 3.3430  Validation loss = 3.6430  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 3.3427  Validation loss = 3.6423  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 3.3424  Validation loss = 3.6417  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 3.3420  Validation loss = 3.6410  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 3.3417  Validation loss = 3.6403  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 3.3413  Validation loss = 3.6396  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 3.3410  Validation loss = 3.6390  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 3.3406  Validation loss = 3.6382  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 3.3402  Validation loss = 3.6376  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 3.3399  Validation loss = 3.6367  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 3.3395  Validation loss = 3.6361  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 3.3392  Validation loss = 3.6354  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 3.3388  Validation loss = 3.6346  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 3.3385  Validation loss = 3.6340  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 3.3382  Validation loss = 3.6335  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 3.3379  Validation loss = 3.6329  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 3.3377  Validation loss = 3.6325  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 3.3373  Validation loss = 3.6316  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 3.3370  Validation loss = 3.6309  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 3.3366  Validation loss = 3.6302  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 3.3363  Validation loss = 3.6295  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 3.3359  Validation loss = 3.6287  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 3.3356  Validation loss = 3.6279  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 3.3353  Validation loss = 3.6274  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 3.3350  Validation loss = 3.6267  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 3.3345  Validation loss = 3.6256  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 3.3342  Validation loss = 3.6249  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 3.3338  Validation loss = 3.6242  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 3.3333  Validation loss = 3.6232  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 3.3330  Validation loss = 3.6225  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 3.3326  Validation loss = 3.6217  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 3.3322  Validation loss = 3.6208  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 3.3319  Validation loss = 3.6202  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 3.3316  Validation loss = 3.6195  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 3.3312  Validation loss = 3.6187  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 3.3309  Validation loss = 3.6181  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 3.3306  Validation loss = 3.6175  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 3.3304  Validation loss = 3.6170  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 3.3300  Validation loss = 3.6162  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 3.3297  Validation loss = 3.6155  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 3.3293  Validation loss = 3.6148  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 3.3290  Validation loss = 3.6140  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 3.3285  Validation loss = 3.6131  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 3.3282  Validation loss = 3.6123  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 3.3279  Validation loss = 3.6118  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 3.3276  Validation loss = 3.6112  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 3.3272  Validation loss = 3.6103  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 3.3269  Validation loss = 3.6097  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 3.3265  Validation loss = 3.6089  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 3.3263  Validation loss = 3.6083  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 3.3259  Validation loss = 3.6076  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 3.3255  Validation loss = 3.6067  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 3.3251  Validation loss = 3.6059  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 3.3248  Validation loss = 3.6052  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 3.3244  Validation loss = 3.6043  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 3.3239  Validation loss = 3.6032  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 3.3235  Validation loss = 3.6023  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 3.3232  Validation loss = 3.6018  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 3.3228  Validation loss = 3.6010  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 3.3224  Validation loss = 3.6001  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 3.3221  Validation loss = 3.5995  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 3.3218  Validation loss = 3.5989  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 3.3214  Validation loss = 3.5981  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 3.3211  Validation loss = 3.5974  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 3.3207  Validation loss = 3.5967  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 3.3203  Validation loss = 3.5959  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 3.3200  Validation loss = 3.5953  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 3.3196  Validation loss = 3.5945  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 3.3193  Validation loss = 3.5938  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 3.3189  Validation loss = 3.5929  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 3.3184  Validation loss = 3.5920  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 3.3179  Validation loss = 3.5911  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 3.3176  Validation loss = 3.5906  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 3.3173  Validation loss = 3.5900  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 3.3169  Validation loss = 3.5893  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 3.3163  Validation loss = 3.5884  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 3.3146  Validation loss = 3.5872  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 3.3144  Validation loss = 3.5865  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 3.3137  Validation loss = 3.5857  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 3.3134  Validation loss = 3.5851  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 3.3128  Validation loss = 3.5839  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 3.3124  Validation loss = 3.5831  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 3.3117  Validation loss = 3.5819  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 3.3113  Validation loss = 3.5813  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 3.3110  Validation loss = 3.5807  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 3.3107  Validation loss = 3.5800  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 3.3104  Validation loss = 3.5793  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 3.3100  Validation loss = 3.5786  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 3.3096  Validation loss = 3.5778  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 3.3092  Validation loss = 3.5769  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 3.3088  Validation loss = 3.5762  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 3.3085  Validation loss = 3.5756  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 3.3080  Validation loss = 3.5746  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 3.3077  Validation loss = 3.5738  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 3.3072  Validation loss = 3.5729  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 3.3070  Validation loss = 3.5724  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 3.3066  Validation loss = 3.5717  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 3.3062  Validation loss = 3.5708  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 3.3058  Validation loss = 3.5701  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 3.3054  Validation loss = 3.5692  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 3.3051  Validation loss = 3.5686  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 3.3047  Validation loss = 3.5676  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 3.3042  Validation loss = 3.5666  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 3.3038  Validation loss = 3.5658  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 3.3035  Validation loss = 3.5651  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 3.3032  Validation loss = 3.5645  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 3.3029  Validation loss = 3.5640  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 3.3026  Validation loss = 3.5634  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 3.3023  Validation loss = 3.5627  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 3.3020  Validation loss = 3.5621  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 3.3016  Validation loss = 3.5612  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 3.3012  Validation loss = 3.5604  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 3.3009  Validation loss = 3.5597  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 3.3004  Validation loss = 3.5588  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 3.3001  Validation loss = 3.5580  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 3.2996  Validation loss = 3.5570  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 3.2991  Validation loss = 3.5560  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 3.2986  Validation loss = 3.5551  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 3.2984  Validation loss = 3.5546  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 3.2980  Validation loss = 3.5539  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 3.2976  Validation loss = 3.5532  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 3.2973  Validation loss = 3.5525  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 3.2969  Validation loss = 3.5518  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 3.2965  Validation loss = 3.5510  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 3.2962  Validation loss = 3.5504  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 3.2958  Validation loss = 3.5496  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 3.2955  Validation loss = 3.5489  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 3.2952  Validation loss = 3.5485  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 3.2949  Validation loss = 3.5478  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 3.2945  Validation loss = 3.5471  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 3.2942  Validation loss = 3.5465  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 3.2939  Validation loss = 3.5461  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 3.2936  Validation loss = 3.5452  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 3.2933  Validation loss = 3.5447  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 3.2930  Validation loss = 3.5440  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 3.2927  Validation loss = 3.5435  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 3.2924  Validation loss = 3.5429  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 3.2920  Validation loss = 3.5420  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 3.2917  Validation loss = 3.5413  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 3.2913  Validation loss = 3.5405  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 3.2910  Validation loss = 3.5397  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 3.2905  Validation loss = 3.5388  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 3.2901  Validation loss = 3.5379  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 3.2897  Validation loss = 3.5372  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 3.2894  Validation loss = 3.5366  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 3.2890  Validation loss = 3.5356  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 3.2887  Validation loss = 3.5350  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 3.2883  Validation loss = 3.5343  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 3.2879  Validation loss = 3.5333  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 3.2875  Validation loss = 3.5325  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 3.2872  Validation loss = 3.5318  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 3.2867  Validation loss = 3.5308  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 3.2864  Validation loss = 3.5302  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 3.2860  Validation loss = 3.5292  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 3.2855  Validation loss = 3.5283  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 3.2852  Validation loss = 3.5279  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 3.2849  Validation loss = 3.5271  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 3.2845  Validation loss = 3.5263  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 3.2841  Validation loss = 3.5255  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 3.2837  Validation loss = 3.5246  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 3.2833  Validation loss = 3.5236  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 3.2829  Validation loss = 3.5228  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 3.2826  Validation loss = 3.5222  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 3.2821  Validation loss = 3.5212  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 3.2817  Validation loss = 3.5203  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 3.2813  Validation loss = 3.5196  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 3.2810  Validation loss = 3.5190  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 3.2807  Validation loss = 3.5183  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 3.2804  Validation loss = 3.5176  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 3.2801  Validation loss = 3.5169  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 3.2797  Validation loss = 3.5161  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 3.2794  Validation loss = 3.5155  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 3.2790  Validation loss = 3.5145  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 3.2786  Validation loss = 3.5139  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 3.2784  Validation loss = 3.5134  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 3.2781  Validation loss = 3.5129  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 3.2778  Validation loss = 3.5123  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 3.2775  Validation loss = 3.5116  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 3.2772  Validation loss = 3.5108  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 3.2769  Validation loss = 3.5102  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 3.2765  Validation loss = 3.5094  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 3.2761  Validation loss = 3.5086  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 3.2759  Validation loss = 3.5081  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 3.2756  Validation loss = 3.5077  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 3.2753  Validation loss = 3.5069  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 3.2748  Validation loss = 3.5060  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 3.2745  Validation loss = 3.5051  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 3.2741  Validation loss = 3.5044  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 3.2737  Validation loss = 3.5036  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 3.2734  Validation loss = 3.5029  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 3.2731  Validation loss = 3.5022  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 3.2727  Validation loss = 3.5015  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 3.2724  Validation loss = 3.5010  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 3.2721  Validation loss = 3.5003  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 3.2719  Validation loss = 3.4998  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 3.2716  Validation loss = 3.4992  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 3.2713  Validation loss = 3.4986  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 3.2709  Validation loss = 3.4977  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 3.2706  Validation loss = 3.4973  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 3.2703  Validation loss = 3.4966  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 3.2700  Validation loss = 3.4959  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 3.2697  Validation loss = 3.4953  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 3.2694  Validation loss = 3.4945  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 3.2691  Validation loss = 3.4939  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 3.2687  Validation loss = 3.4932  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 3.2684  Validation loss = 3.4924  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 3.2681  Validation loss = 3.4918  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 3.2677  Validation loss = 3.4909  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 3.2674  Validation loss = 3.4903  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 3.2669  Validation loss = 3.4894  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 3.2667  Validation loss = 3.4889  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 3.2664  Validation loss = 3.4883  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 3.2661  Validation loss = 3.4877  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 3.2658  Validation loss = 3.4870  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 3.2655  Validation loss = 3.4862  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 3.2652  Validation loss = 3.4855  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 3.2647  Validation loss = 3.4845  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 3.2644  Validation loss = 3.4839  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 3.2640  Validation loss = 3.4830  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 3.2637  Validation loss = 3.4825  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 3.2634  Validation loss = 3.4818  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 3.2630  Validation loss = 3.4810  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 3.2627  Validation loss = 3.4803  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 3.2623  Validation loss = 3.4794  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 3.2620  Validation loss = 3.4788  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 3.2618  Validation loss = 3.4783  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 3.2615  Validation loss = 3.4776  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 3.2612  Validation loss = 3.4769  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 3.2607  Validation loss = 3.4760  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 3.2603  Validation loss = 3.4751  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 3.2600  Validation loss = 3.4744  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 3.2597  Validation loss = 3.4738  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 3.2594  Validation loss = 3.4732  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 500  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 3.3484  Validation loss = 5.7173  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 3.3480  Validation loss = 5.7165  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 3.3475  Validation loss = 5.7155  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 3.3470  Validation loss = 5.7147  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 3.3466  Validation loss = 5.7138  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 3.3462  Validation loss = 5.7130  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 3.3458  Validation loss = 5.7124  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 3.3454  Validation loss = 5.7115  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 3.3450  Validation loss = 5.7109  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 3.3445  Validation loss = 5.7099  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 3.3442  Validation loss = 5.7094  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 3.3439  Validation loss = 5.7087  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 3.3435  Validation loss = 5.7080  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 3.3430  Validation loss = 5.7071  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 3.3426  Validation loss = 5.7063  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 3.3421  Validation loss = 5.7054  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 3.3417  Validation loss = 5.7046  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 3.3412  Validation loss = 5.7036  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 3.3409  Validation loss = 5.7030  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 3.3405  Validation loss = 5.7023  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 3.3401  Validation loss = 5.7017  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 3.3397  Validation loss = 5.7009  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 3.3392  Validation loss = 5.6999  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 3.3388  Validation loss = 5.6992  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 3.3383  Validation loss = 5.6982  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 3.3379  Validation loss = 5.6975  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 3.3374  Validation loss = 5.6964  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 3.3368  Validation loss = 5.6953  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 3.3363  Validation loss = 5.6944  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 3.3358  Validation loss = 5.6935  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 3.3354  Validation loss = 5.6926  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 3.3348  Validation loss = 5.6915  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 3.3342  Validation loss = 5.6905  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 3.3339  Validation loss = 5.6898  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 3.3334  Validation loss = 5.6890  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 3.3328  Validation loss = 5.6879  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 3.3324  Validation loss = 5.6870  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 3.3319  Validation loss = 5.6861  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 3.3314  Validation loss = 5.6852  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 3.3311  Validation loss = 5.6846  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 3.3308  Validation loss = 5.6840  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 3.3303  Validation loss = 5.6832  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 3.3299  Validation loss = 5.6822  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 3.3294  Validation loss = 5.6814  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 3.3289  Validation loss = 5.6804  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 3.3283  Validation loss = 5.6794  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 3.3279  Validation loss = 5.6785  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 3.3274  Validation loss = 5.6776  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 3.3269  Validation loss = 5.6766  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 3.3265  Validation loss = 5.6760  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 3.3261  Validation loss = 5.6752  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 3.3258  Validation loss = 5.6745  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 3.3253  Validation loss = 5.6736  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 3.3249  Validation loss = 5.6728  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 3.3245  Validation loss = 5.6721  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 3.3240  Validation loss = 5.6712  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 3.3236  Validation loss = 5.6704  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 3.3231  Validation loss = 5.6695  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 3.3228  Validation loss = 5.6688  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 3.3223  Validation loss = 5.6679  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 3.3218  Validation loss = 5.6670  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 3.3214  Validation loss = 5.6662  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 3.3210  Validation loss = 5.6654  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 3.3205  Validation loss = 5.6645  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 3.3200  Validation loss = 5.6635  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 3.3195  Validation loss = 5.6626  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 3.3191  Validation loss = 5.6617  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 3.3186  Validation loss = 5.6608  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 3.3182  Validation loss = 5.6601  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 3.3178  Validation loss = 5.6594  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 3.3173  Validation loss = 5.6585  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 3.3168  Validation loss = 5.6575  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 3.3162  Validation loss = 5.6564  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 3.3157  Validation loss = 5.6554  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 3.3152  Validation loss = 5.6544  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 3.3146  Validation loss = 5.6534  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 3.3140  Validation loss = 5.6521  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 3.3134  Validation loss = 5.6511  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 3.3130  Validation loss = 5.6502  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 3.3126  Validation loss = 5.6496  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 3.3122  Validation loss = 5.6488  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 3.3117  Validation loss = 5.6478  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 3.3112  Validation loss = 5.6468  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 3.3108  Validation loss = 5.6460  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 3.3104  Validation loss = 5.6452  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 3.3099  Validation loss = 5.6442  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 3.3094  Validation loss = 5.6433  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 3.3088  Validation loss = 5.6423  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 3.3084  Validation loss = 5.6415  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 3.3080  Validation loss = 5.6407  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 3.3076  Validation loss = 5.6400  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 3.3072  Validation loss = 5.6391  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 3.3067  Validation loss = 5.6381  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 3.3062  Validation loss = 5.6373  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 3.3058  Validation loss = 5.6365  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 3.3054  Validation loss = 5.6357  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 3.3049  Validation loss = 5.6347  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 3.3044  Validation loss = 5.6337  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 3.3040  Validation loss = 5.6330  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 3.3036  Validation loss = 5.6323  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 3.3033  Validation loss = 5.6316  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 3.3028  Validation loss = 5.6307  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 3.3023  Validation loss = 5.6297  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 3.3018  Validation loss = 5.6288  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 3.3014  Validation loss = 5.6280  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 3.3011  Validation loss = 5.6274  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 3.3006  Validation loss = 5.6265  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 3.3003  Validation loss = 5.6258  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 3.2999  Validation loss = 5.6250  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 3.2994  Validation loss = 5.6242  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 3.2989  Validation loss = 5.6233  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 3.2985  Validation loss = 5.6224  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 3.2981  Validation loss = 5.6217  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 3.2977  Validation loss = 5.6208  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 3.2972  Validation loss = 5.6200  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 3.2969  Validation loss = 5.6193  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 3.2964  Validation loss = 5.6184  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 3.2960  Validation loss = 5.6177  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 3.2955  Validation loss = 5.6166  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 3.2950  Validation loss = 5.6157  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 3.2945  Validation loss = 5.6147  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 3.2940  Validation loss = 5.6139  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 3.2935  Validation loss = 5.6128  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 3.2931  Validation loss = 5.6122  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 3.2926  Validation loss = 5.6111  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 3.2923  Validation loss = 5.6106  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 3.2918  Validation loss = 5.6096  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 3.2914  Validation loss = 5.6088  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 3.2910  Validation loss = 5.6080  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 3.2905  Validation loss = 5.6072  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 3.2901  Validation loss = 5.6063  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 3.2897  Validation loss = 5.6056  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 3.2893  Validation loss = 5.6048  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 3.2888  Validation loss = 5.6040  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 3.2883  Validation loss = 5.6029  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 3.2878  Validation loss = 5.6020  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 3.2875  Validation loss = 5.6014  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 3.2870  Validation loss = 5.6005  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 3.2865  Validation loss = 5.5995  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 3.2860  Validation loss = 5.5986  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 3.2856  Validation loss = 5.5978  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 3.2852  Validation loss = 5.5971  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 3.2848  Validation loss = 5.5964  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 3.2844  Validation loss = 5.5956  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 3.2840  Validation loss = 5.5947  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 3.2835  Validation loss = 5.5939  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 3.2832  Validation loss = 5.5932  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 3.2828  Validation loss = 5.5925  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 3.2824  Validation loss = 5.5917  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 3.2819  Validation loss = 5.5909  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 3.2814  Validation loss = 5.5900  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 3.2809  Validation loss = 5.5892  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 3.2805  Validation loss = 5.5883  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 3.2801  Validation loss = 5.5876  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 3.2795  Validation loss = 5.5867  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 3.2789  Validation loss = 5.5857  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 3.2784  Validation loss = 5.5852  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 3.2779  Validation loss = 5.5844  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 3.2772  Validation loss = 5.5836  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 3.2766  Validation loss = 5.5829  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 3.2760  Validation loss = 5.5821  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 3.2755  Validation loss = 5.5812  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 3.2751  Validation loss = 5.5805  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 3.2744  Validation loss = 5.5795  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 3.2740  Validation loss = 5.5786  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 3.2736  Validation loss = 5.5778  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 3.2733  Validation loss = 5.5773  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 3.2728  Validation loss = 5.5764  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 3.2724  Validation loss = 5.5756  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 3.2719  Validation loss = 5.5748  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 3.2715  Validation loss = 5.5741  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 3.2711  Validation loss = 5.5733  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 3.2707  Validation loss = 5.5725  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 3.2702  Validation loss = 5.5716  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 3.2698  Validation loss = 5.5708  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 3.2694  Validation loss = 5.5700  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 3.2689  Validation loss = 5.5691  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 3.2686  Validation loss = 5.5684  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 3.2681  Validation loss = 5.5675  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 3.2678  Validation loss = 5.5668  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 3.2672  Validation loss = 5.5658  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 3.2666  Validation loss = 5.5647  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 3.2662  Validation loss = 5.5639  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 3.2658  Validation loss = 5.5631  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 3.2653  Validation loss = 5.5621  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 3.2649  Validation loss = 5.5613  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 3.2645  Validation loss = 5.5605  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 3.2641  Validation loss = 5.5598  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 3.2637  Validation loss = 5.5591  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 3.2634  Validation loss = 5.5585  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 3.2631  Validation loss = 5.5578  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 3.2625  Validation loss = 5.5568  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 3.2621  Validation loss = 5.5560  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 3.2618  Validation loss = 5.5554  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 3.2614  Validation loss = 5.5547  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 3.2609  Validation loss = 5.5537  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 3.2606  Validation loss = 5.5529  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 3.2601  Validation loss = 5.5520  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 3.2596  Validation loss = 5.5511  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 3.2591  Validation loss = 5.5502  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 3.2588  Validation loss = 5.5495  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 3.2583  Validation loss = 5.5486  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 3.2579  Validation loss = 5.5477  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 3.2575  Validation loss = 5.5470  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 3.2572  Validation loss = 5.5464  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 3.2567  Validation loss = 5.5456  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 3.2563  Validation loss = 5.5447  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 3.2559  Validation loss = 5.5440  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 3.2555  Validation loss = 5.5431  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 3.2549  Validation loss = 5.5421  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 3.2545  Validation loss = 5.5412  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 3.2542  Validation loss = 5.5406  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 3.2537  Validation loss = 5.5397  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 3.2534  Validation loss = 5.5390  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 3.2529  Validation loss = 5.5381  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 3.2526  Validation loss = 5.5374  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 3.2521  Validation loss = 5.5366  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 3.2517  Validation loss = 5.5356  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 3.2512  Validation loss = 5.5347  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 3.2508  Validation loss = 5.5340  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 3.2504  Validation loss = 5.5331  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 3.2500  Validation loss = 5.5323  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 3.2496  Validation loss = 5.5317  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 3.2493  Validation loss = 5.5310  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 3.2489  Validation loss = 5.5303  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 3.2486  Validation loss = 5.5296  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 3.2481  Validation loss = 5.5288  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 3.2478  Validation loss = 5.5281  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 3.2474  Validation loss = 5.5273  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 3.2469  Validation loss = 5.5265  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 3.2464  Validation loss = 5.5255  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 3.2461  Validation loss = 5.5248  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 3.2457  Validation loss = 5.5240  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 3.2453  Validation loss = 5.5232  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 3.2449  Validation loss = 5.5224  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 3.2444  Validation loss = 5.5215  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 3.2440  Validation loss = 5.5207  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 3.2437  Validation loss = 5.5200  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 3.2433  Validation loss = 5.5194  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 3.2431  Validation loss = 5.5188  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 3.2426  Validation loss = 5.5180  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 3.2422  Validation loss = 5.5172  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 3.2418  Validation loss = 5.5165  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 3.2414  Validation loss = 5.5157  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 3.2410  Validation loss = 5.5149  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 3.2406  Validation loss = 5.5140  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 3.2401  Validation loss = 5.5132  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 3.2397  Validation loss = 5.5124  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 3.2394  Validation loss = 5.5117  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 3.2390  Validation loss = 5.5109  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 3.2386  Validation loss = 5.5102  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 3.2382  Validation loss = 5.5093  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 3.2378  Validation loss = 5.5085  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 3.2374  Validation loss = 5.5079  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 3.2370  Validation loss = 5.5071  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 3.2367  Validation loss = 5.5065  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 3.2362  Validation loss = 5.5055  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 3.2358  Validation loss = 5.5047  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 3.2353  Validation loss = 5.5038  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 3.2350  Validation loss = 5.5030  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 3.2345  Validation loss = 5.5022  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 3.2341  Validation loss = 5.5013  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 3.2337  Validation loss = 5.5007  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 3.2333  Validation loss = 5.4999  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 3.2330  Validation loss = 5.4993  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 3.2326  Validation loss = 5.4985  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 3.2323  Validation loss = 5.4978  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 3.2319  Validation loss = 5.4971  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 3.2315  Validation loss = 5.4963  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 3.2313  Validation loss = 5.4958  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 3.2309  Validation loss = 5.4950  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 3.2304  Validation loss = 5.4942  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 3.2300  Validation loss = 5.4934  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 3.2295  Validation loss = 5.4925  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 3.2291  Validation loss = 5.4916  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 3.2286  Validation loss = 5.4906  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 3.2283  Validation loss = 5.4899  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 3.2279  Validation loss = 5.4892  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 3.2275  Validation loss = 5.4885  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 3.2272  Validation loss = 5.4878  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 3.2269  Validation loss = 5.4872  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 3.2263  Validation loss = 5.4861  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 3.2261  Validation loss = 5.4856  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 3.2257  Validation loss = 5.4848  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 3.2253  Validation loss = 5.4840  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 3.2250  Validation loss = 5.4834  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 3.2246  Validation loss = 5.4826  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 3.2242  Validation loss = 5.4819  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 3.2238  Validation loss = 5.4811  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 3.2234  Validation loss = 5.4803  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 3.2230  Validation loss = 5.4796  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 3.2226  Validation loss = 5.4788  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 3.2223  Validation loss = 5.4781  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 3.2219  Validation loss = 5.4774  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 3.2216  Validation loss = 5.4768  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 3.2212  Validation loss = 5.4761  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 3.2208  Validation loss = 5.4751  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 3.2203  Validation loss = 5.4743  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 3.2200  Validation loss = 5.4737  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 3.2196  Validation loss = 5.4728  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 3.2193  Validation loss = 5.4722  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 3.2189  Validation loss = 5.4714  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 3.2185  Validation loss = 5.4707  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 3.2181  Validation loss = 5.4698  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 3.2176  Validation loss = 5.4689  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 3.2170  Validation loss = 5.4678  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 3.2167  Validation loss = 5.4672  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 3.2164  Validation loss = 5.4666  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 3.2162  Validation loss = 5.4660  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 3.2157  Validation loss = 5.4652  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 3.2153  Validation loss = 5.4643  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 3.2148  Validation loss = 5.4633  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 3.2144  Validation loss = 5.4626  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 3.2139  Validation loss = 5.4616  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 3.2134  Validation loss = 5.4607  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 3.2130  Validation loss = 5.4599  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 3.2124  Validation loss = 5.4587  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 3.2119  Validation loss = 5.4578  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 3.2114  Validation loss = 5.4568  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 3.2110  Validation loss = 5.4559  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 3.2106  Validation loss = 5.4550  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 3.2101  Validation loss = 5.4541  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 3.2097  Validation loss = 5.4535  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 3.2093  Validation loss = 5.4526  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 3.2089  Validation loss = 5.4518  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 3.2085  Validation loss = 5.4510  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 3.2081  Validation loss = 5.4502  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 3.2078  Validation loss = 5.4497  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 3.2074  Validation loss = 5.4487  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 3.2070  Validation loss = 5.4480  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 3.2066  Validation loss = 5.4473  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 3.2062  Validation loss = 5.4465  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 3.2057  Validation loss = 5.4455  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 3.2053  Validation loss = 5.4447  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 3.2049  Validation loss = 5.4438  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 3.2045  Validation loss = 5.4430  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 3.2040  Validation loss = 5.4420  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 3.2036  Validation loss = 5.4412  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 3.2032  Validation loss = 5.4405  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 3.2028  Validation loss = 5.4397  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 3.2024  Validation loss = 5.4390  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 3.2020  Validation loss = 5.4381  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 3.2017  Validation loss = 5.4375  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 3.2014  Validation loss = 5.4369  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 3.2010  Validation loss = 5.4361  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 3.2006  Validation loss = 5.4354  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 3.2001  Validation loss = 5.4344  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 3.1997  Validation loss = 5.4335  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 3.1993  Validation loss = 5.4327  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 3.1990  Validation loss = 5.4321  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 3.1985  Validation loss = 5.4313  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 3.1982  Validation loss = 5.4306  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 3.1977  Validation loss = 5.4296  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 3.1973  Validation loss = 5.4287  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 3.1969  Validation loss = 5.4279  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 3.1964  Validation loss = 5.4271  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 3.1958  Validation loss = 5.4259  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 3.1954  Validation loss = 5.4250  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 3.1949  Validation loss = 5.4241  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 3.1945  Validation loss = 5.4233  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 3.1940  Validation loss = 5.4224  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 3.1936  Validation loss = 5.4215  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 3.1931  Validation loss = 5.4206  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 3.1926  Validation loss = 5.4196  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 3.1923  Validation loss = 5.4189  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 3.1919  Validation loss = 5.4182  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 3.1914  Validation loss = 5.4173  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 3.1911  Validation loss = 5.4166  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 3.1907  Validation loss = 5.4158  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 3.1902  Validation loss = 5.4148  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 3.1897  Validation loss = 5.4139  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 3.1893  Validation loss = 5.4131  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 3.1889  Validation loss = 5.4122  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 3.1885  Validation loss = 5.4115  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 3.1882  Validation loss = 5.4109  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 3.1877  Validation loss = 5.4099  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 3.1872  Validation loss = 5.4089  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 3.1868  Validation loss = 5.4081  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 3.1864  Validation loss = 5.4073  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 3.1859  Validation loss = 5.4064  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 3.1855  Validation loss = 5.4057  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 3.1853  Validation loss = 5.4052  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 3.1848  Validation loss = 5.4042  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 3.1845  Validation loss = 5.4035  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 3.1841  Validation loss = 5.4028  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 3.1837  Validation loss = 5.4019  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 3.1832  Validation loss = 5.4010  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 3.1828  Validation loss = 5.4001  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 3.1823  Validation loss = 5.3991  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 3.1819  Validation loss = 5.3983  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 3.1815  Validation loss = 5.3976  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 3.1811  Validation loss = 5.3968  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 3.1807  Validation loss = 5.3960  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 3.1803  Validation loss = 5.3953  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 3.1799  Validation loss = 5.3943  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 3.1795  Validation loss = 5.3935  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 3.1790  Validation loss = 5.3926  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 3.1785  Validation loss = 5.3915  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 3.1780  Validation loss = 5.3907  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 3.1776  Validation loss = 5.3899  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 3.1771  Validation loss = 5.3889  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 3.1768  Validation loss = 5.3882  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 3.1763  Validation loss = 5.3871  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 3.1758  Validation loss = 5.3862  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 3.1755  Validation loss = 5.3855  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 3.1751  Validation loss = 5.3849  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 3.1746  Validation loss = 5.3839  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 3.1743  Validation loss = 5.3832  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 3.1738  Validation loss = 5.3823  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 3.1734  Validation loss = 5.3815  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 3.1731  Validation loss = 5.3808  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 3.1727  Validation loss = 5.3801  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 3.1724  Validation loss = 5.3794  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 3.1720  Validation loss = 5.3786  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 3.1716  Validation loss = 5.3779  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 3.1712  Validation loss = 5.3770  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 3.1708  Validation loss = 5.3763  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 3.1703  Validation loss = 5.3754  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 3.1699  Validation loss = 5.3744  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 3.1696  Validation loss = 5.3740  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 3.1691  Validation loss = 5.3729  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 3.1687  Validation loss = 5.3721  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 3.1683  Validation loss = 5.3714  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 3.1680  Validation loss = 5.3706  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 3.1676  Validation loss = 5.3699  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 3.1673  Validation loss = 5.3693  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 3.1669  Validation loss = 5.3685  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 3.1665  Validation loss = 5.3677  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 3.1661  Validation loss = 5.3669  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 3.1657  Validation loss = 5.3662  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 3.1654  Validation loss = 5.3654  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 3.1650  Validation loss = 5.3648  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 3.1647  Validation loss = 5.3640  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 3.1643  Validation loss = 5.3633  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 3.1639  Validation loss = 5.3625  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 3.1634  Validation loss = 5.3616  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 3.1630  Validation loss = 5.3608  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 3.1627  Validation loss = 5.3602  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 3.1623  Validation loss = 5.3594  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 3.1620  Validation loss = 5.3587  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 3.1616  Validation loss = 5.3579  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 3.1612  Validation loss = 5.3572  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 3.1609  Validation loss = 5.3566  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 3.1605  Validation loss = 5.3557  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 3.1602  Validation loss = 5.3551  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 3.1599  Validation loss = 5.3544  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 3.1596  Validation loss = 5.3538  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 3.1592  Validation loss = 5.3531  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 3.1587  Validation loss = 5.3520  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 3.1583  Validation loss = 5.3513  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 3.1580  Validation loss = 5.3506  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 3.1576  Validation loss = 5.3499  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 3.1572  Validation loss = 5.3490  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 3.1567  Validation loss = 5.3481  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 3.1564  Validation loss = 5.3474  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 3.1560  Validation loss = 5.3467  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 3.1557  Validation loss = 5.3460  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 3.1553  Validation loss = 5.3452  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 3.1548  Validation loss = 5.3441  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 3.1545  Validation loss = 5.3435  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 3.1540  Validation loss = 5.3427  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 3.1537  Validation loss = 5.3420  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 3.1533  Validation loss = 5.3413  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 3.1528  Validation loss = 5.3403  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 3.1526  Validation loss = 5.3398  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 3.1522  Validation loss = 5.3390  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 3.1518  Validation loss = 5.3382  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 3.1514  Validation loss = 5.3375  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 3.1511  Validation loss = 5.3367  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 3.1509  Validation loss = 5.3363  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 3.1505  Validation loss = 5.3356  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 3.1500  Validation loss = 5.3346  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 3.1496  Validation loss = 5.3338  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 3.1491  Validation loss = 5.3328  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 3.1487  Validation loss = 5.3319  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 3.1482  Validation loss = 5.3309  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 3.1479  Validation loss = 5.3304  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 3.1476  Validation loss = 5.3298  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 3.1473  Validation loss = 5.3291  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 3.1469  Validation loss = 5.3284  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 3.1465  Validation loss = 5.3276  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 3.1463  Validation loss = 5.3270  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 3.1460  Validation loss = 5.3264  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 3.1457  Validation loss = 5.3258  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 3.1453  Validation loss = 5.3250  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 3.1449  Validation loss = 5.3243  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 3.1446  Validation loss = 5.3236  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 3.1442  Validation loss = 5.3227  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 3.1439  Validation loss = 5.3222  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 3.1436  Validation loss = 5.3217  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 3.1432  Validation loss = 5.3208  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 3.1428  Validation loss = 5.3200  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 3.1424  Validation loss = 5.3192  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 3.1422  Validation loss = 5.3188  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 3.1418  Validation loss = 5.3179  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 3.1414  Validation loss = 5.3171  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 3.1411  Validation loss = 5.3166  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 3.1408  Validation loss = 5.3159  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 3.1405  Validation loss = 5.3153  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 3.1401  Validation loss = 5.3145  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 500  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 3.3907  Validation loss = 9.1634  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 3.3899  Validation loss = 9.1619  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 3.3894  Validation loss = 9.1610  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 3.3888  Validation loss = 9.1600  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 3.3882  Validation loss = 9.1592  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 3.3877  Validation loss = 9.1581  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 3.3873  Validation loss = 9.1575  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 3.3867  Validation loss = 9.1565  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 3.3862  Validation loss = 9.1556  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 3.3855  Validation loss = 9.1545  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 3.3850  Validation loss = 9.1535  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 3.3843  Validation loss = 9.1525  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 3.3837  Validation loss = 9.1514  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 3.3831  Validation loss = 9.1505  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 3.3826  Validation loss = 9.1495  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 3.3820  Validation loss = 9.1486  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 3.3814  Validation loss = 9.1477  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 3.3809  Validation loss = 9.1467  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 3.3803  Validation loss = 9.1459  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 3.3799  Validation loss = 9.1451  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 3.3793  Validation loss = 9.1440  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 3.3787  Validation loss = 9.1431  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 3.3782  Validation loss = 9.1422  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 3.3775  Validation loss = 9.1410  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 3.3770  Validation loss = 9.1402  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 3.3766  Validation loss = 9.1394  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 3.3760  Validation loss = 9.1385  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 3.3754  Validation loss = 9.1375  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 3.3748  Validation loss = 9.1366  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 3.3743  Validation loss = 9.1358  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 3.3739  Validation loss = 9.1349  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 3.3733  Validation loss = 9.1339  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 3.3727  Validation loss = 9.1330  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 3.3721  Validation loss = 9.1320  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 3.3715  Validation loss = 9.1310  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 3.3711  Validation loss = 9.1302  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 3.3704  Validation loss = 9.1291  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 3.3699  Validation loss = 9.1283  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 3.3693  Validation loss = 9.1273  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 3.3689  Validation loss = 9.1265  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 3.3684  Validation loss = 9.1255  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 3.3678  Validation loss = 9.1245  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 3.3671  Validation loss = 9.1235  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 3.3665  Validation loss = 9.1226  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 3.3659  Validation loss = 9.1215  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 3.3654  Validation loss = 9.1206  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 3.3649  Validation loss = 9.1198  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 3.3645  Validation loss = 9.1190  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 3.3639  Validation loss = 9.1181  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 3.3634  Validation loss = 9.1172  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 3.3630  Validation loss = 9.1165  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 3.3625  Validation loss = 9.1156  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 3.3620  Validation loss = 9.1148  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 3.3615  Validation loss = 9.1139  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 3.3608  Validation loss = 9.1129  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 3.3603  Validation loss = 9.1121  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 3.3598  Validation loss = 9.1110  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 3.3593  Validation loss = 9.1102  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 3.3588  Validation loss = 9.1095  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 3.3583  Validation loss = 9.1086  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 3.3579  Validation loss = 9.1078  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 3.3575  Validation loss = 9.1071  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 3.3571  Validation loss = 9.1063  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 3.3567  Validation loss = 9.1057  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 3.3562  Validation loss = 9.1049  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 3.3557  Validation loss = 9.1041  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 3.3552  Validation loss = 9.1033  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 3.3546  Validation loss = 9.1024  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 3.3542  Validation loss = 9.1016  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 3.3537  Validation loss = 9.1007  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 3.3531  Validation loss = 9.0998  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 3.3526  Validation loss = 9.0990  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 3.3520  Validation loss = 9.0980  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 3.3515  Validation loss = 9.0970  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 3.3510  Validation loss = 9.0962  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 3.3503  Validation loss = 9.0951  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 3.3498  Validation loss = 9.0942  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 3.3492  Validation loss = 9.0932  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 3.3488  Validation loss = 9.0925  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 3.3482  Validation loss = 9.0916  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 3.3478  Validation loss = 9.0908  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 3.3471  Validation loss = 9.0896  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 3.3466  Validation loss = 9.0887  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 3.3462  Validation loss = 9.0880  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 3.3456  Validation loss = 9.0870  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 3.3451  Validation loss = 9.0860  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 3.3446  Validation loss = 9.0853  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 3.3441  Validation loss = 9.0844  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 3.3435  Validation loss = 9.0835  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 3.3431  Validation loss = 9.0827  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 3.3427  Validation loss = 9.0821  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 3.3421  Validation loss = 9.0810  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 3.3416  Validation loss = 9.0801  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 3.3410  Validation loss = 9.0791  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 3.3407  Validation loss = 9.0786  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 3.3401  Validation loss = 9.0776  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 3.3397  Validation loss = 9.0770  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 3.3392  Validation loss = 9.0761  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 3.3387  Validation loss = 9.0752  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 3.3382  Validation loss = 9.0743  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 3.3377  Validation loss = 9.0735  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 3.3372  Validation loss = 9.0727  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 3.3368  Validation loss = 9.0720  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 3.3363  Validation loss = 9.0711  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 3.3358  Validation loss = 9.0703  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 3.3354  Validation loss = 9.0696  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 3.3349  Validation loss = 9.0686  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 3.3343  Validation loss = 9.0676  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 3.3338  Validation loss = 9.0666  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 3.3333  Validation loss = 9.0658  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 3.3326  Validation loss = 9.0647  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 3.3320  Validation loss = 9.0637  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 3.3316  Validation loss = 9.0629  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 3.3310  Validation loss = 9.0619  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 3.3307  Validation loss = 9.0613  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 3.3301  Validation loss = 9.0604  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 3.3294  Validation loss = 9.0592  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 3.3287  Validation loss = 9.0581  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 3.3281  Validation loss = 9.0571  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 3.3276  Validation loss = 9.0563  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 3.3270  Validation loss = 9.0553  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 3.3265  Validation loss = 9.0545  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 3.3260  Validation loss = 9.0536  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 3.3255  Validation loss = 9.0527  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 3.3249  Validation loss = 9.0517  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 3.3245  Validation loss = 9.0509  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 3.3240  Validation loss = 9.0501  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 3.3236  Validation loss = 9.0494  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 3.3230  Validation loss = 9.0483  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 3.3223  Validation loss = 9.0472  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 3.3218  Validation loss = 9.0464  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 3.3213  Validation loss = 9.0454  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 3.3207  Validation loss = 9.0445  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 3.3202  Validation loss = 9.0435  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 3.3197  Validation loss = 9.0427  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 3.3192  Validation loss = 9.0418  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 3.3187  Validation loss = 9.0411  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 3.3181  Validation loss = 9.0401  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 3.3177  Validation loss = 9.0393  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 3.3172  Validation loss = 9.0385  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 3.3165  Validation loss = 9.0374  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 3.3160  Validation loss = 9.0364  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 3.3156  Validation loss = 9.0357  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 3.3151  Validation loss = 9.0349  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 3.3145  Validation loss = 9.0340  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 3.3139  Validation loss = 9.0330  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 3.3136  Validation loss = 9.0324  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 3.3128  Validation loss = 9.0312  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 3.3123  Validation loss = 9.0303  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 3.3118  Validation loss = 9.0295  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 3.3112  Validation loss = 9.0285  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 3.3107  Validation loss = 9.0276  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 3.3101  Validation loss = 9.0265  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 3.3096  Validation loss = 9.0255  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 3.3092  Validation loss = 9.0249  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 3.3087  Validation loss = 9.0240  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 3.3082  Validation loss = 9.0233  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 3.3076  Validation loss = 9.0222  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 3.3072  Validation loss = 9.0215  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 3.3065  Validation loss = 9.0204  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 3.3058  Validation loss = 9.0193  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 3.3052  Validation loss = 9.0181  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 3.3048  Validation loss = 9.0173  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 3.3043  Validation loss = 9.0165  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 3.3037  Validation loss = 9.0155  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 3.3030  Validation loss = 9.0144  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 3.3024  Validation loss = 9.0132  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 3.3020  Validation loss = 9.0125  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 3.3014  Validation loss = 9.0115  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 3.3007  Validation loss = 9.0104  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 3.3002  Validation loss = 9.0095  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 3.2998  Validation loss = 9.0088  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 3.2993  Validation loss = 9.0080  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 3.2988  Validation loss = 9.0071  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 3.2982  Validation loss = 9.0060  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 3.2976  Validation loss = 9.0050  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 3.2969  Validation loss = 9.0039  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 3.2965  Validation loss = 9.0031  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 3.2959  Validation loss = 9.0021  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 3.2954  Validation loss = 9.0012  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 3.2948  Validation loss = 9.0002  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 3.2944  Validation loss = 8.9996  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 3.2939  Validation loss = 8.9987  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 3.2934  Validation loss = 8.9978  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 3.2929  Validation loss = 8.9969  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 3.2924  Validation loss = 8.9960  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 3.2918  Validation loss = 8.9949  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 3.2912  Validation loss = 8.9940  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 3.2905  Validation loss = 8.9929  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 3.2899  Validation loss = 8.9919  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 3.2895  Validation loss = 8.9911  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 3.2891  Validation loss = 8.9905  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 3.2884  Validation loss = 8.9894  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 3.2879  Validation loss = 8.9885  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 3.2873  Validation loss = 8.9875  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 3.2866  Validation loss = 8.9864  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 3.2862  Validation loss = 8.9855  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 3.2855  Validation loss = 8.9845  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 3.2849  Validation loss = 8.9834  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 3.2843  Validation loss = 8.9823  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 3.2838  Validation loss = 8.9813  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 3.2832  Validation loss = 8.9804  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 3.2826  Validation loss = 8.9792  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 3.2821  Validation loss = 8.9785  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 3.2817  Validation loss = 8.9777  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 3.2813  Validation loss = 8.9770  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 3.2808  Validation loss = 8.9762  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 3.2803  Validation loss = 8.9752  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 3.2797  Validation loss = 8.9743  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 3.2791  Validation loss = 8.9733  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 3.2786  Validation loss = 8.9724  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 3.2782  Validation loss = 8.9716  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 3.2777  Validation loss = 8.9707  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 3.2771  Validation loss = 8.9697  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 3.2764  Validation loss = 8.9685  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 3.2759  Validation loss = 8.9675  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 3.2753  Validation loss = 8.9666  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 3.2748  Validation loss = 8.9658  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 3.2744  Validation loss = 8.9652  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 3.2739  Validation loss = 8.9642  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 3.2734  Validation loss = 8.9634  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 3.2729  Validation loss = 8.9625  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 3.2726  Validation loss = 8.9620  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 3.2720  Validation loss = 8.9610  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 3.2714  Validation loss = 8.9600  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 3.2710  Validation loss = 8.9593  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 3.2706  Validation loss = 8.9586  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 3.2702  Validation loss = 8.9579  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 3.2696  Validation loss = 8.9570  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 3.2691  Validation loss = 8.9560  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 3.2686  Validation loss = 8.9552  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 3.2680  Validation loss = 8.9541  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 3.2675  Validation loss = 8.9533  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 3.2671  Validation loss = 8.9524  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 3.2667  Validation loss = 8.9518  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 3.2663  Validation loss = 8.9511  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 3.2659  Validation loss = 8.9503  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 3.2654  Validation loss = 8.9496  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 3.2650  Validation loss = 8.9489  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 3.2645  Validation loss = 8.9481  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 3.2639  Validation loss = 8.9471  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 3.2634  Validation loss = 8.9462  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 3.2629  Validation loss = 8.9452  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 3.2624  Validation loss = 8.9444  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 3.2620  Validation loss = 8.9438  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 3.2613  Validation loss = 8.9426  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 3.2609  Validation loss = 8.9417  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 3.2604  Validation loss = 8.9409  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 3.2599  Validation loss = 8.9401  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 3.2595  Validation loss = 8.9393  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 3.2589  Validation loss = 8.9383  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 3.2585  Validation loss = 8.9376  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 3.2581  Validation loss = 8.9368  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 3.2574  Validation loss = 8.9357  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 3.2571  Validation loss = 8.9350  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 3.2564  Validation loss = 8.9340  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 3.2558  Validation loss = 8.9329  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 3.2554  Validation loss = 8.9322  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 3.2549  Validation loss = 8.9313  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 3.2543  Validation loss = 8.9303  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 3.2537  Validation loss = 8.9293  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 3.2534  Validation loss = 8.9287  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 3.2528  Validation loss = 8.9276  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 3.2524  Validation loss = 8.9269  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 3.2518  Validation loss = 8.9258  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 3.2512  Validation loss = 8.9248  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 3.2507  Validation loss = 8.9238  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 3.2503  Validation loss = 8.9231  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 3.2497  Validation loss = 8.9221  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 3.2493  Validation loss = 8.9214  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 3.2486  Validation loss = 8.9204  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 3.2482  Validation loss = 8.9197  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 3.2476  Validation loss = 8.9185  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 3.2471  Validation loss = 8.9177  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 3.2467  Validation loss = 8.9170  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 3.2462  Validation loss = 8.9161  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 3.2456  Validation loss = 8.9152  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 3.2451  Validation loss = 8.9143  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 3.2447  Validation loss = 8.9135  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 3.2441  Validation loss = 8.9125  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 3.2435  Validation loss = 8.9115  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 3.2430  Validation loss = 8.9106  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 3.2425  Validation loss = 8.9098  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 3.2420  Validation loss = 8.9089  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 3.2415  Validation loss = 8.9080  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 3.2410  Validation loss = 8.9072  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 3.2406  Validation loss = 8.9064  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 3.2401  Validation loss = 8.9056  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 3.2397  Validation loss = 8.9047  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 3.2391  Validation loss = 8.9037  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 3.2387  Validation loss = 8.9030  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 3.2382  Validation loss = 8.9021  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 3.2377  Validation loss = 8.9013  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 3.2371  Validation loss = 8.9002  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 3.2368  Validation loss = 8.8996  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 3.2364  Validation loss = 8.8989  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 3.2360  Validation loss = 8.8982  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 3.2355  Validation loss = 8.8974  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 3.2349  Validation loss = 8.8964  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 3.2345  Validation loss = 8.8956  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 3.2338  Validation loss = 8.8943  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 3.2333  Validation loss = 8.8934  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 3.2327  Validation loss = 8.8924  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 3.2322  Validation loss = 8.8914  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 3.2318  Validation loss = 8.8907  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 3.2312  Validation loss = 8.8897  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 3.2307  Validation loss = 8.8888  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 3.2303  Validation loss = 8.8880  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 3.2298  Validation loss = 8.8872  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 3.2293  Validation loss = 8.8862  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 3.2288  Validation loss = 8.8853  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 3.2284  Validation loss = 8.8847  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 3.2279  Validation loss = 8.8837  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 3.2276  Validation loss = 8.8831  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 3.2270  Validation loss = 8.8822  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 3.2265  Validation loss = 8.8812  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 3.2262  Validation loss = 8.8807  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 3.2256  Validation loss = 8.8798  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 3.2254  Validation loss = 8.8793  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 3.2250  Validation loss = 8.8786  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 3.2245  Validation loss = 8.8778  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 3.2240  Validation loss = 8.8769  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 3.2235  Validation loss = 8.8760  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 3.2229  Validation loss = 8.8750  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 3.2224  Validation loss = 8.8741  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 3.2219  Validation loss = 8.8732  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 3.2213  Validation loss = 8.8721  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 3.2209  Validation loss = 8.8713  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 3.2204  Validation loss = 8.8705  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 3.2199  Validation loss = 8.8696  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 3.2194  Validation loss = 8.8689  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 3.2189  Validation loss = 8.8679  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 3.2185  Validation loss = 8.8673  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 3.2180  Validation loss = 8.8663  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 3.2176  Validation loss = 8.8657  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 3.2171  Validation loss = 8.8648  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 3.2165  Validation loss = 8.8637  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 3.2160  Validation loss = 8.8629  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 3.2155  Validation loss = 8.8620  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 3.2150  Validation loss = 8.8611  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 3.2146  Validation loss = 8.8604  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 3.2141  Validation loss = 8.8594  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 3.2135  Validation loss = 8.8583  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 3.2130  Validation loss = 8.8575  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 3.2126  Validation loss = 8.8568  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 3.2121  Validation loss = 8.8559  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 3.2116  Validation loss = 8.8550  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 3.2111  Validation loss = 8.8543  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 3.2107  Validation loss = 8.8535  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 3.2101  Validation loss = 8.8524  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 3.2095  Validation loss = 8.8515  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 3.2092  Validation loss = 8.8508  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 3.2087  Validation loss = 8.8500  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 3.2082  Validation loss = 8.8491  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 3.2078  Validation loss = 8.8482  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 3.2074  Validation loss = 8.8475  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 3.2069  Validation loss = 8.8466  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 3.2064  Validation loss = 8.8458  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 3.2060  Validation loss = 8.8450  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 3.2055  Validation loss = 8.8442  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 3.2051  Validation loss = 8.8434  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 3.2046  Validation loss = 8.8426  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 3.2041  Validation loss = 8.8417  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 3.2036  Validation loss = 8.8407  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 3.2032  Validation loss = 8.8401  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 3.2027  Validation loss = 8.8393  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 3.2023  Validation loss = 8.8386  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 3.2017  Validation loss = 8.8376  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 3.2014  Validation loss = 8.8369  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 3.2008  Validation loss = 8.8360  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 3.2004  Validation loss = 8.8351  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 3.1998  Validation loss = 8.8342  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 3.1992  Validation loss = 8.8332  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 3.1987  Validation loss = 8.8321  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 3.1982  Validation loss = 8.8313  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 3.1978  Validation loss = 8.8304  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 3.1973  Validation loss = 8.8296  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 3.1969  Validation loss = 8.8288  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 3.1964  Validation loss = 8.8280  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 3.1960  Validation loss = 8.8272  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 3.1956  Validation loss = 8.8266  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 3.1952  Validation loss = 8.8258  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 3.1948  Validation loss = 8.8252  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 3.1943  Validation loss = 8.8244  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 3.1939  Validation loss = 8.8236  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 3.1934  Validation loss = 8.8227  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 3.1928  Validation loss = 8.8217  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 3.1924  Validation loss = 8.8211  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 3.1920  Validation loss = 8.8202  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 3.1916  Validation loss = 8.8196  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 3.1913  Validation loss = 8.8188  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 3.1907  Validation loss = 8.8179  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 3.1902  Validation loss = 8.8170  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 3.1898  Validation loss = 8.8163  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 3.1894  Validation loss = 8.8157  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 3.1890  Validation loss = 8.8149  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 3.1886  Validation loss = 8.8143  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 3.1882  Validation loss = 8.8135  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 3.1876  Validation loss = 8.8125  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 3.1871  Validation loss = 8.8115  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 3.1866  Validation loss = 8.8107  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 3.1862  Validation loss = 8.8099  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 3.1859  Validation loss = 8.8094  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 3.1854  Validation loss = 8.8086  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 3.1849  Validation loss = 8.8076  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 3.1844  Validation loss = 8.8067  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 3.1840  Validation loss = 8.8059  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 3.1835  Validation loss = 8.8050  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 3.1832  Validation loss = 8.8045  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 3.1827  Validation loss = 8.8036  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 3.1822  Validation loss = 8.8026  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 3.1816  Validation loss = 8.8016  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 3.1812  Validation loss = 8.8007  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 3.1807  Validation loss = 8.7999  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 3.1803  Validation loss = 8.7991  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 3.1799  Validation loss = 8.7984  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 3.1794  Validation loss = 8.7975  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 3.1789  Validation loss = 8.7967  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 3.1785  Validation loss = 8.7959  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 3.1781  Validation loss = 8.7952  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 3.1775  Validation loss = 8.7942  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 3.1772  Validation loss = 8.7935  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 3.1766  Validation loss = 8.7926  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 3.1762  Validation loss = 8.7919  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 3.1758  Validation loss = 8.7911  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 3.1753  Validation loss = 8.7903  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 3.1748  Validation loss = 8.7893  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 3.1743  Validation loss = 8.7885  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 3.1738  Validation loss = 8.7876  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 3.1734  Validation loss = 8.7869  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 3.1730  Validation loss = 8.7861  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 3.1725  Validation loss = 8.7853  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 3.1721  Validation loss = 8.7845  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 3.1716  Validation loss = 8.7836  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 3.1711  Validation loss = 8.7828  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 3.1706  Validation loss = 8.7819  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 3.1704  Validation loss = 8.7815  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 3.1698  Validation loss = 8.7804  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 3.1694  Validation loss = 8.7795  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 3.1689  Validation loss = 8.7787  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 3.1684  Validation loss = 8.7778  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 3.1680  Validation loss = 8.7771  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 3.1677  Validation loss = 8.7764  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 3.1672  Validation loss = 8.7756  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 3.1667  Validation loss = 8.7747  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 3.1663  Validation loss = 8.7739  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 3.1659  Validation loss = 8.7732  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 3.1654  Validation loss = 8.7724  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 3.1650  Validation loss = 8.7717  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 3.1645  Validation loss = 8.7708  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 3.1641  Validation loss = 8.7701  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 3.1635  Validation loss = 8.7690  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 3.1629  Validation loss = 8.7679  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 3.1624  Validation loss = 8.7670  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 3.1621  Validation loss = 8.7664  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 3.1616  Validation loss = 8.7655  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 3.1610  Validation loss = 8.7645  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 3.1605  Validation loss = 8.7636  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 3.1601  Validation loss = 8.7629  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 3.1596  Validation loss = 8.7620  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 3.1591  Validation loss = 8.7612  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 3.1584  Validation loss = 8.7601  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 3.1580  Validation loss = 8.7594  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 3.1574  Validation loss = 8.7587  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 3.1569  Validation loss = 8.7578  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 3.1560  Validation loss = 8.7569  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 3.1551  Validation loss = 8.7560  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 3.1546  Validation loss = 8.7553  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 3.1537  Validation loss = 8.7545  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 3.1530  Validation loss = 8.7535  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 3.1526  Validation loss = 8.7529  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 3.1521  Validation loss = 8.7521  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 3.1514  Validation loss = 8.7511  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 3.1507  Validation loss = 8.7502  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 3.1499  Validation loss = 8.7491  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 3.1493  Validation loss = 8.7481  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 3.1488  Validation loss = 8.7472  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 3.1483  Validation loss = 8.7464  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 3.1477  Validation loss = 8.7455  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 3.1473  Validation loss = 8.7449  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 3.1468  Validation loss = 8.7441  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 3.1465  Validation loss = 8.7435  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 3.1460  Validation loss = 8.7426  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 3.1456  Validation loss = 8.7419  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 3.1451  Validation loss = 8.7411  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 3.1447  Validation loss = 8.7404  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 3.1444  Validation loss = 8.7399  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 3.1441  Validation loss = 8.7393  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 3.1437  Validation loss = 8.7385  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 3.1432  Validation loss = 8.7378  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 3.1427  Validation loss = 8.7369  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 3.1421  Validation loss = 8.7359  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 3.1417  Validation loss = 8.7349  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 3.1411  Validation loss = 8.7339  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 3.1405  Validation loss = 8.7328  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 3.1401  Validation loss = 8.7321  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 3.1398  Validation loss = 8.7315  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 3.1393  Validation loss = 8.7307  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 3.1388  Validation loss = 8.7296  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 3.1384  Validation loss = 8.7290  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 500  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 3.7958  Validation loss = 9.4093  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 3.7951  Validation loss = 9.4084  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 3.7945  Validation loss = 9.4073  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 3.7939  Validation loss = 9.4064  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 3.7934  Validation loss = 9.4055  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 3.7928  Validation loss = 9.4047  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 3.7921  Validation loss = 9.4038  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 3.7912  Validation loss = 9.4026  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 3.7906  Validation loss = 9.4018  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 3.7899  Validation loss = 9.4006  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 3.7892  Validation loss = 9.3994  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 3.7884  Validation loss = 9.3983  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 3.7877  Validation loss = 9.3973  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 3.7871  Validation loss = 9.3964  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 3.7864  Validation loss = 9.3954  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 3.7858  Validation loss = 9.3947  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 3.7852  Validation loss = 9.3938  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 3.7848  Validation loss = 9.3931  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 3.7842  Validation loss = 9.3923  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 3.7836  Validation loss = 9.3915  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 3.7830  Validation loss = 9.3907  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 3.7824  Validation loss = 9.3899  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 3.7817  Validation loss = 9.3890  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 3.7810  Validation loss = 9.3879  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 3.7803  Validation loss = 9.3869  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 3.7797  Validation loss = 9.3861  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 3.7791  Validation loss = 9.3854  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 3.7786  Validation loss = 9.3845  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 3.7781  Validation loss = 9.3839  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 3.7774  Validation loss = 9.3827  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 3.7767  Validation loss = 9.3817  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 3.7761  Validation loss = 9.3805  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 3.7755  Validation loss = 9.3797  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 3.7747  Validation loss = 9.3786  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 3.7741  Validation loss = 9.3777  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 3.7735  Validation loss = 9.3768  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 3.7727  Validation loss = 9.3759  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 3.7722  Validation loss = 9.3752  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 3.7714  Validation loss = 9.3740  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 3.7705  Validation loss = 9.3727  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 3.7698  Validation loss = 9.3716  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 3.7691  Validation loss = 9.3706  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 3.7684  Validation loss = 9.3695  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 3.7677  Validation loss = 9.3684  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 3.7671  Validation loss = 9.3678  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 3.7665  Validation loss = 9.3669  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 3.7659  Validation loss = 9.3661  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 3.7652  Validation loss = 9.3651  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 3.7643  Validation loss = 9.3636  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 3.7637  Validation loss = 9.3627  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 3.7630  Validation loss = 9.3616  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 3.7624  Validation loss = 9.3608  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 3.7618  Validation loss = 9.3599  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 3.7612  Validation loss = 9.3589  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 3.7606  Validation loss = 9.3579  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 3.7602  Validation loss = 9.3573  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 3.7596  Validation loss = 9.3565  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 3.7590  Validation loss = 9.3558  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 3.7583  Validation loss = 9.3549  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 3.7576  Validation loss = 9.3538  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 3.7571  Validation loss = 9.3531  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 3.7564  Validation loss = 9.3521  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 3.7558  Validation loss = 9.3511  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 3.7550  Validation loss = 9.3500  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 3.7544  Validation loss = 9.3490  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 3.7538  Validation loss = 9.3482  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 3.7531  Validation loss = 9.3472  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 3.7524  Validation loss = 9.3464  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 3.7516  Validation loss = 9.3453  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 3.7510  Validation loss = 9.3444  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 3.7503  Validation loss = 9.3435  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 3.7495  Validation loss = 9.3423  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 3.7489  Validation loss = 9.3414  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 3.7483  Validation loss = 9.3405  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 3.7475  Validation loss = 9.3394  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 3.7469  Validation loss = 9.3385  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 3.7462  Validation loss = 9.3375  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 3.7457  Validation loss = 9.3367  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 3.7450  Validation loss = 9.3357  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 3.7444  Validation loss = 9.3349  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 3.7438  Validation loss = 9.3340  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 3.7432  Validation loss = 9.3332  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 3.7425  Validation loss = 9.3322  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 3.7419  Validation loss = 9.3312  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 3.7413  Validation loss = 9.3303  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 3.7408  Validation loss = 9.3294  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 3.7400  Validation loss = 9.3282  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 3.7393  Validation loss = 9.3271  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 3.7386  Validation loss = 9.3261  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 3.7380  Validation loss = 9.3252  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 3.7374  Validation loss = 9.3243  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 3.7369  Validation loss = 9.3235  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 3.7362  Validation loss = 9.3224  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 3.7355  Validation loss = 9.3215  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 3.7349  Validation loss = 9.3207  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 3.7344  Validation loss = 9.3199  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 3.7337  Validation loss = 9.3189  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 3.7332  Validation loss = 9.3182  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 3.7324  Validation loss = 9.3169  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 3.7317  Validation loss = 9.3156  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 3.7310  Validation loss = 9.3146  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 3.7305  Validation loss = 9.3139  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 3.7299  Validation loss = 9.3131  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 3.7292  Validation loss = 9.3119  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 3.7286  Validation loss = 9.3110  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 3.7278  Validation loss = 9.3097  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 3.7272  Validation loss = 9.3088  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 3.7266  Validation loss = 9.3079  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 3.7262  Validation loss = 9.3074  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 3.7255  Validation loss = 9.3064  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 3.7249  Validation loss = 9.3054  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 3.7243  Validation loss = 9.3044  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 3.7238  Validation loss = 9.3037  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 3.7233  Validation loss = 9.3030  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 3.7226  Validation loss = 9.3020  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 3.7219  Validation loss = 9.3010  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 3.7213  Validation loss = 9.2999  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 3.7205  Validation loss = 9.2989  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 3.7201  Validation loss = 9.2981  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 3.7195  Validation loss = 9.2973  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 3.7190  Validation loss = 9.2966  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 3.7184  Validation loss = 9.2957  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 3.7178  Validation loss = 9.2947  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 3.7172  Validation loss = 9.2937  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 3.7165  Validation loss = 9.2925  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 3.7157  Validation loss = 9.2913  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 3.7151  Validation loss = 9.2903  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 3.7144  Validation loss = 9.2893  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 3.7137  Validation loss = 9.2882  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 3.7130  Validation loss = 9.2873  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 3.7123  Validation loss = 9.2859  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 3.7116  Validation loss = 9.2848  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 3.7110  Validation loss = 9.2839  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 3.7103  Validation loss = 9.2829  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 3.7097  Validation loss = 9.2819  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 3.7090  Validation loss = 9.2810  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 3.7083  Validation loss = 9.2798  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 3.7076  Validation loss = 9.2786  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 3.7067  Validation loss = 9.2774  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 3.7061  Validation loss = 9.2766  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 3.7056  Validation loss = 9.2759  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 3.7048  Validation loss = 9.2746  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 3.7043  Validation loss = 9.2739  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 3.7037  Validation loss = 9.2730  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 3.7032  Validation loss = 9.2722  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 3.7026  Validation loss = 9.2712  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 3.7018  Validation loss = 9.2702  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 3.7012  Validation loss = 9.2693  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 3.7007  Validation loss = 9.2686  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 3.7000  Validation loss = 9.2674  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 3.6995  Validation loss = 9.2665  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 3.6987  Validation loss = 9.2653  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 3.6982  Validation loss = 9.2646  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 3.6979  Validation loss = 9.2640  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 3.6973  Validation loss = 9.2630  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 3.6965  Validation loss = 9.2619  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 3.6960  Validation loss = 9.2612  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 3.6955  Validation loss = 9.2604  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 3.6949  Validation loss = 9.2595  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 3.6944  Validation loss = 9.2586  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 3.6937  Validation loss = 9.2578  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 3.6932  Validation loss = 9.2569  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 3.6927  Validation loss = 9.2561  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 3.6921  Validation loss = 9.2552  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 3.6915  Validation loss = 9.2543  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 3.6911  Validation loss = 9.2537  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 3.6903  Validation loss = 9.2527  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 3.6895  Validation loss = 9.2513  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 3.6890  Validation loss = 9.2507  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 3.6885  Validation loss = 9.2499  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 3.6880  Validation loss = 9.2491  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 3.6873  Validation loss = 9.2480  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 3.6865  Validation loss = 9.2468  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 3.6858  Validation loss = 9.2456  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 3.6852  Validation loss = 9.2446  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 3.6846  Validation loss = 9.2435  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 3.6842  Validation loss = 9.2428  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 3.6834  Validation loss = 9.2417  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 3.6829  Validation loss = 9.2408  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 3.6823  Validation loss = 9.2399  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 3.6818  Validation loss = 9.2389  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 3.6812  Validation loss = 9.2380  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 3.6805  Validation loss = 9.2369  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 3.6800  Validation loss = 9.2362  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 3.6793  Validation loss = 9.2352  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 3.6787  Validation loss = 9.2345  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 3.6783  Validation loss = 9.2337  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 3.6778  Validation loss = 9.2330  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 3.6771  Validation loss = 9.2321  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 3.6764  Validation loss = 9.2311  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 3.6758  Validation loss = 9.2302  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 3.6750  Validation loss = 9.2290  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 3.6745  Validation loss = 9.2281  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 3.6738  Validation loss = 9.2270  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 3.6732  Validation loss = 9.2263  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 3.6725  Validation loss = 9.2252  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 3.6719  Validation loss = 9.2242  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 3.6713  Validation loss = 9.2234  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 3.6706  Validation loss = 9.2226  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 3.6700  Validation loss = 9.2216  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 3.6694  Validation loss = 9.2206  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 3.6687  Validation loss = 9.2196  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 3.6683  Validation loss = 9.2189  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 3.6677  Validation loss = 9.2179  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 3.6671  Validation loss = 9.2169  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 3.6665  Validation loss = 9.2159  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 3.6658  Validation loss = 9.2149  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 3.6653  Validation loss = 9.2141  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 3.6648  Validation loss = 9.2134  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 3.6642  Validation loss = 9.2124  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 3.6639  Validation loss = 9.2120  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 3.6633  Validation loss = 9.2111  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 3.6629  Validation loss = 9.2103  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 3.6623  Validation loss = 9.2094  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 3.6618  Validation loss = 9.2085  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 3.6612  Validation loss = 9.2077  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 3.6606  Validation loss = 9.2068  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 3.6601  Validation loss = 9.2058  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 3.6594  Validation loss = 9.2048  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 3.6588  Validation loss = 9.2039  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 3.6582  Validation loss = 9.2028  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 3.6578  Validation loss = 9.2021  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 3.6572  Validation loss = 9.2013  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 3.6567  Validation loss = 9.2004  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 3.6560  Validation loss = 9.1993  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 3.6554  Validation loss = 9.1984  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 3.6550  Validation loss = 9.1978  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 3.6546  Validation loss = 9.1972  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 3.6540  Validation loss = 9.1964  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 3.6533  Validation loss = 9.1954  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 3.6526  Validation loss = 9.1942  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 3.6520  Validation loss = 9.1933  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 3.6515  Validation loss = 9.1925  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 3.6509  Validation loss = 9.1916  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 3.6501  Validation loss = 9.1904  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 3.6494  Validation loss = 9.1892  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 3.6488  Validation loss = 9.1880  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 3.6482  Validation loss = 9.1871  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 3.6475  Validation loss = 9.1861  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 3.6469  Validation loss = 9.1852  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 3.6463  Validation loss = 9.1843  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 3.6457  Validation loss = 9.1835  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 3.6452  Validation loss = 9.1827  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 3.6446  Validation loss = 9.1818  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 3.6440  Validation loss = 9.1810  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 3.6434  Validation loss = 9.1800  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 3.6428  Validation loss = 9.1790  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 3.6421  Validation loss = 9.1780  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 3.6416  Validation loss = 9.1771  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 3.6408  Validation loss = 9.1758  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 3.6402  Validation loss = 9.1748  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 3.6397  Validation loss = 9.1741  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 3.6391  Validation loss = 9.1732  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 3.6384  Validation loss = 9.1720  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 3.6377  Validation loss = 9.1709  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 3.6370  Validation loss = 9.1696  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 3.6364  Validation loss = 9.1687  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 3.6357  Validation loss = 9.1677  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 3.6348  Validation loss = 9.1664  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 3.6341  Validation loss = 9.1653  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 3.6337  Validation loss = 9.1647  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 3.6331  Validation loss = 9.1637  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 3.6323  Validation loss = 9.1624  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 3.6317  Validation loss = 9.1613  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 3.6312  Validation loss = 9.1606  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 3.6305  Validation loss = 9.1595  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 3.6299  Validation loss = 9.1586  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 3.6294  Validation loss = 9.1579  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 3.6287  Validation loss = 9.1569  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 3.6280  Validation loss = 9.1558  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 3.6275  Validation loss = 9.1550  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 3.6270  Validation loss = 9.1543  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 3.6264  Validation loss = 9.1533  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 3.6257  Validation loss = 9.1523  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 3.6250  Validation loss = 9.1513  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 3.6243  Validation loss = 9.1503  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 3.6237  Validation loss = 9.1494  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 3.6233  Validation loss = 9.1487  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 3.6228  Validation loss = 9.1480  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 3.6222  Validation loss = 9.1470  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 3.6215  Validation loss = 9.1460  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 3.6210  Validation loss = 9.1451  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 3.6202  Validation loss = 9.1439  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 3.6196  Validation loss = 9.1429  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 3.6191  Validation loss = 9.1420  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 3.6184  Validation loss = 9.1410  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 3.6179  Validation loss = 9.1402  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 3.6173  Validation loss = 9.1394  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 3.6167  Validation loss = 9.1384  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 3.6161  Validation loss = 9.1376  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 3.6155  Validation loss = 9.1367  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 3.6147  Validation loss = 9.1353  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 3.6140  Validation loss = 9.1340  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 3.6133  Validation loss = 9.1330  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 3.6130  Validation loss = 9.1324  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 3.6124  Validation loss = 9.1314  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 3.6119  Validation loss = 9.1306  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 3.6113  Validation loss = 9.1297  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 3.6107  Validation loss = 9.1285  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 3.6100  Validation loss = 9.1274  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 3.6095  Validation loss = 9.1264  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 3.6088  Validation loss = 9.1253  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 3.6083  Validation loss = 9.1245  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 3.6078  Validation loss = 9.1237  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 3.6073  Validation loss = 9.1229  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 3.6068  Validation loss = 9.1221  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 3.6063  Validation loss = 9.1214  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 3.6057  Validation loss = 9.1204  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 3.6050  Validation loss = 9.1194  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 3.6042  Validation loss = 9.1182  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 3.6033  Validation loss = 9.1167  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 3.6027  Validation loss = 9.1157  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 3.6021  Validation loss = 9.1147  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 3.6016  Validation loss = 9.1140  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 3.6011  Validation loss = 9.1133  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 3.6005  Validation loss = 9.1122  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 3.6000  Validation loss = 9.1113  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 3.5993  Validation loss = 9.1104  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 3.5987  Validation loss = 9.1093  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 3.5981  Validation loss = 9.1083  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 3.5976  Validation loss = 9.1074  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 3.5970  Validation loss = 9.1063  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 3.5964  Validation loss = 9.1054  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 3.5958  Validation loss = 9.1045  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 3.5953  Validation loss = 9.1037  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 3.5947  Validation loss = 9.1029  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 3.5941  Validation loss = 9.1020  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 3.5935  Validation loss = 9.1010  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 3.5930  Validation loss = 9.1001  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 3.5924  Validation loss = 9.0992  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 3.5918  Validation loss = 9.0980  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 3.5912  Validation loss = 9.0972  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 3.5904  Validation loss = 9.0961  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 3.5900  Validation loss = 9.0954  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 3.5895  Validation loss = 9.0945  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 3.5889  Validation loss = 9.0936  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 3.5884  Validation loss = 9.0929  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 3.5880  Validation loss = 9.0922  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 3.5874  Validation loss = 9.0911  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 3.5869  Validation loss = 9.0902  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 3.5861  Validation loss = 9.0891  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 3.5857  Validation loss = 9.0884  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 3.5852  Validation loss = 9.0876  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 3.5845  Validation loss = 9.0864  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 3.5839  Validation loss = 9.0855  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 3.5833  Validation loss = 9.0846  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 3.5826  Validation loss = 9.0835  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 3.5820  Validation loss = 9.0824  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 3.5814  Validation loss = 9.0815  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 3.5810  Validation loss = 9.0807  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 3.5803  Validation loss = 9.0796  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 3.5799  Validation loss = 9.0787  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 3.5794  Validation loss = 9.0778  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 3.5786  Validation loss = 9.0766  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 3.5781  Validation loss = 9.0756  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 3.5776  Validation loss = 9.0748  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 3.5770  Validation loss = 9.0740  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 3.5766  Validation loss = 9.0732  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 3.5760  Validation loss = 9.0723  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 3.5756  Validation loss = 9.0716  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 3.5750  Validation loss = 9.0707  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 3.5744  Validation loss = 9.0698  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 3.5737  Validation loss = 9.0687  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 3.5732  Validation loss = 9.0677  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 3.5725  Validation loss = 9.0666  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 3.5718  Validation loss = 9.0654  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 3.5712  Validation loss = 9.0645  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 3.5708  Validation loss = 9.0636  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 3.5702  Validation loss = 9.0626  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 3.5697  Validation loss = 9.0618  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 3.5691  Validation loss = 9.0608  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 3.5684  Validation loss = 9.0596  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 3.5678  Validation loss = 9.0586  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 3.5672  Validation loss = 9.0576  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 3.5667  Validation loss = 9.0567  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 3.5661  Validation loss = 9.0557  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 3.5655  Validation loss = 9.0546  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 3.5647  Validation loss = 9.0535  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 3.5643  Validation loss = 9.0528  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 3.5637  Validation loss = 9.0518  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 3.5631  Validation loss = 9.0509  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 3.5626  Validation loss = 9.0500  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 3.5619  Validation loss = 9.0488  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 3.5614  Validation loss = 9.0479  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 3.5608  Validation loss = 9.0470  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 3.5603  Validation loss = 9.0461  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 3.5598  Validation loss = 9.0454  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 3.5593  Validation loss = 9.0446  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 3.5588  Validation loss = 9.0438  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 3.5583  Validation loss = 9.0428  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 3.5580  Validation loss = 9.0422  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 3.5572  Validation loss = 9.0409  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 3.5567  Validation loss = 9.0400  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 3.5563  Validation loss = 9.0394  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 3.5557  Validation loss = 9.0385  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 3.5552  Validation loss = 9.0377  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 3.5546  Validation loss = 9.0368  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 3.5541  Validation loss = 9.0360  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 3.5537  Validation loss = 9.0354  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 3.5533  Validation loss = 9.0348  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 3.5526  Validation loss = 9.0336  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 3.5518  Validation loss = 9.0324  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 3.5512  Validation loss = 9.0314  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 3.5507  Validation loss = 9.0305  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 3.5501  Validation loss = 9.0293  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 3.5494  Validation loss = 9.0282  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 3.5488  Validation loss = 9.0274  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 3.5483  Validation loss = 9.0263  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 3.5477  Validation loss = 9.0255  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 3.5474  Validation loss = 9.0249  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 3.5468  Validation loss = 9.0240  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 3.5464  Validation loss = 9.0232  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 3.5459  Validation loss = 9.0224  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 3.5453  Validation loss = 9.0215  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 3.5447  Validation loss = 9.0205  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 3.5441  Validation loss = 9.0195  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 3.5434  Validation loss = 9.0185  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 3.5430  Validation loss = 9.0177  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 3.5425  Validation loss = 9.0169  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 3.5418  Validation loss = 9.0157  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 3.5412  Validation loss = 9.0149  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 3.5406  Validation loss = 9.0140  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 3.5401  Validation loss = 9.0130  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 3.5394  Validation loss = 9.0117  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 3.5388  Validation loss = 9.0106  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 3.5382  Validation loss = 9.0096  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 3.5376  Validation loss = 9.0084  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 3.5370  Validation loss = 9.0073  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 3.5365  Validation loss = 9.0065  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 3.5360  Validation loss = 9.0056  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 3.5353  Validation loss = 9.0044  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 3.5348  Validation loss = 9.0035  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 3.5342  Validation loss = 9.0025  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 3.5336  Validation loss = 9.0013  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 3.5330  Validation loss = 9.0005  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 3.5323  Validation loss = 8.9993  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 3.5318  Validation loss = 8.9983  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 3.5313  Validation loss = 8.9975  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 3.5307  Validation loss = 8.9966  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 3.5301  Validation loss = 8.9955  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 3.5296  Validation loss = 8.9947  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 3.5289  Validation loss = 8.9936  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 3.5284  Validation loss = 8.9929  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 3.5277  Validation loss = 8.9916  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 3.5271  Validation loss = 8.9908  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 3.5267  Validation loss = 8.9901  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 3.5262  Validation loss = 8.9893  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 3.5256  Validation loss = 8.9882  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 3.5251  Validation loss = 8.9875  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 3.5247  Validation loss = 8.9866  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 3.5241  Validation loss = 8.9858  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 3.5234  Validation loss = 8.9846  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 3.5230  Validation loss = 8.9838  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 3.5223  Validation loss = 8.9825  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 3.5216  Validation loss = 8.9815  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 3.5210  Validation loss = 8.9803  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 3.5205  Validation loss = 8.9794  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 3.5197  Validation loss = 8.9781  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 3.5192  Validation loss = 8.9773  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 3.5187  Validation loss = 8.9765  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 3.5181  Validation loss = 8.9754  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 3.5176  Validation loss = 8.9747  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 3.5169  Validation loss = 8.9735  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 3.5164  Validation loss = 8.9725  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 3.5158  Validation loss = 8.9715  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 3.5154  Validation loss = 8.9708  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 3.5148  Validation loss = 8.9698  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 3.5143  Validation loss = 8.9689  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 3.5138  Validation loss = 8.9682  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 3.5131  Validation loss = 8.9671  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 3.5125  Validation loss = 8.9661  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 3.5120  Validation loss = 8.9653  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 3.5115  Validation loss = 8.9643  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 3.5111  Validation loss = 8.9635  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 3.5106  Validation loss = 8.9628  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 3.5100  Validation loss = 8.9618  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 3.5094  Validation loss = 8.9608  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 3.5091  Validation loss = 8.9602  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 3.5084  Validation loss = 8.9591  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 3.5078  Validation loss = 8.9581  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 3.5073  Validation loss = 8.9574  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 3.5069  Validation loss = 8.9568  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 3.5065  Validation loss = 8.9561  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 3.5060  Validation loss = 8.9553  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 3.5054  Validation loss = 8.9542  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 3.5048  Validation loss = 8.9532  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 3.5043  Validation loss = 8.9523  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 3.5038  Validation loss = 8.9513  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 3.5032  Validation loss = 8.9505  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 3.5026  Validation loss = 8.9495  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 3.5023  Validation loss = 8.9489  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 3.5017  Validation loss = 8.9478  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 3.5012  Validation loss = 8.9469  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 3.5008  Validation loss = 8.9462  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 3.5003  Validation loss = 8.9454  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 3.5000  Validation loss = 8.9447  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 3.4995  Validation loss = 8.9439  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 3.4991  Validation loss = 8.9431  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 3.4985  Validation loss = 8.9421  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 3.4981  Validation loss = 8.9413  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 4.1129  Validation loss = 6.4835  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 4.1120  Validation loss = 6.4823  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 4.1111  Validation loss = 6.4813  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 4.1100  Validation loss = 6.4799  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 4.1092  Validation loss = 6.4790  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 4.1084  Validation loss = 6.4780  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 4.1078  Validation loss = 6.4773  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 4.1073  Validation loss = 6.4767  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 4.1066  Validation loss = 6.4758  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 4.1057  Validation loss = 6.4748  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 4.1049  Validation loss = 6.4739  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 4.1041  Validation loss = 6.4728  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 4.1035  Validation loss = 6.4720  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 4.1027  Validation loss = 6.4711  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 4.1020  Validation loss = 6.4703  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 4.1011  Validation loss = 6.4693  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 4.1002  Validation loss = 6.4681  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 4.0993  Validation loss = 6.4671  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 4.0983  Validation loss = 6.4660  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 4.0973  Validation loss = 6.4647  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 4.0963  Validation loss = 6.4635  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 4.0956  Validation loss = 6.4627  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 4.0946  Validation loss = 6.4614  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 4.0938  Validation loss = 6.4605  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 4.0932  Validation loss = 6.4598  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 4.0925  Validation loss = 6.4589  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 4.0919  Validation loss = 6.4582  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 4.0913  Validation loss = 6.4574  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 4.0906  Validation loss = 6.4565  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 4.0898  Validation loss = 6.4556  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 4.0889  Validation loss = 6.4546  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 4.0884  Validation loss = 6.4541  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 4.0878  Validation loss = 6.4532  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 4.0870  Validation loss = 6.4523  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 4.0862  Validation loss = 6.4513  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 4.0855  Validation loss = 6.4505  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 4.0848  Validation loss = 6.4496  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 4.0838  Validation loss = 6.4485  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 4.0831  Validation loss = 6.4476  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 4.0821  Validation loss = 6.4465  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 4.0811  Validation loss = 6.4452  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 4.0801  Validation loss = 6.4441  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 4.0794  Validation loss = 6.4431  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 4.0789  Validation loss = 6.4426  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 4.0783  Validation loss = 6.4418  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 4.0774  Validation loss = 6.4407  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 4.0765  Validation loss = 6.4396  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 4.0756  Validation loss = 6.4384  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 4.0747  Validation loss = 6.4374  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 4.0739  Validation loss = 6.4364  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 4.0733  Validation loss = 6.4356  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 4.0726  Validation loss = 6.4348  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 4.0718  Validation loss = 6.4339  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 4.0710  Validation loss = 6.4329  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 4.0701  Validation loss = 6.4319  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 4.0694  Validation loss = 6.4310  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 4.0686  Validation loss = 6.4300  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 4.0680  Validation loss = 6.4292  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 4.0673  Validation loss = 6.4284  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 4.0665  Validation loss = 6.4274  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 4.0658  Validation loss = 6.4265  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 4.0648  Validation loss = 6.4253  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 4.0641  Validation loss = 6.4246  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 4.0632  Validation loss = 6.4234  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 4.0623  Validation loss = 6.4224  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 4.0614  Validation loss = 6.4213  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 4.0604  Validation loss = 6.4201  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 4.0597  Validation loss = 6.4192  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 4.0590  Validation loss = 6.4183  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 4.0584  Validation loss = 6.4175  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 4.0575  Validation loss = 6.4165  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 4.0566  Validation loss = 6.4154  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 4.0558  Validation loss = 6.4145  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 4.0548  Validation loss = 6.4133  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 4.0539  Validation loss = 6.4121  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 4.0530  Validation loss = 6.4110  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 4.0524  Validation loss = 6.4102  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 4.0517  Validation loss = 6.4095  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 4.0510  Validation loss = 6.4085  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 4.0500  Validation loss = 6.4074  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 4.0492  Validation loss = 6.4065  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 4.0485  Validation loss = 6.4056  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 4.0476  Validation loss = 6.4046  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 4.0470  Validation loss = 6.4038  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 4.0460  Validation loss = 6.4026  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 4.0452  Validation loss = 6.4016  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 4.0444  Validation loss = 6.4007  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 4.0438  Validation loss = 6.4001  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 4.0431  Validation loss = 6.3991  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 4.0421  Validation loss = 6.3980  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 4.0415  Validation loss = 6.3972  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 4.0408  Validation loss = 6.3963  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 4.0399  Validation loss = 6.3952  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 4.0391  Validation loss = 6.3942  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 4.0381  Validation loss = 6.3930  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 4.0371  Validation loss = 6.3918  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 4.0362  Validation loss = 6.3907  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 4.0355  Validation loss = 6.3899  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 4.0350  Validation loss = 6.3893  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 4.0343  Validation loss = 6.3885  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 4.0333  Validation loss = 6.3873  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 4.0325  Validation loss = 6.3862  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 4.0316  Validation loss = 6.3852  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 4.0307  Validation loss = 6.3841  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 4.0300  Validation loss = 6.3832  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 4.0291  Validation loss = 6.3822  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 4.0283  Validation loss = 6.3812  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 4.0275  Validation loss = 6.3802  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 4.0265  Validation loss = 6.3790  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 4.0255  Validation loss = 6.3778  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 4.0248  Validation loss = 6.3769  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 4.0239  Validation loss = 6.3758  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 4.0231  Validation loss = 6.3748  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 4.0221  Validation loss = 6.3736  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 4.0214  Validation loss = 6.3727  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 4.0207  Validation loss = 6.3719  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 4.0198  Validation loss = 6.3707  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 4.0190  Validation loss = 6.3698  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 4.0184  Validation loss = 6.3689  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 4.0176  Validation loss = 6.3679  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 4.0167  Validation loss = 6.3669  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 4.0160  Validation loss = 6.3660  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 4.0154  Validation loss = 6.3652  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 4.0148  Validation loss = 6.3644  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 4.0141  Validation loss = 6.3636  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 4.0133  Validation loss = 6.3627  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 4.0127  Validation loss = 6.3620  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 4.0121  Validation loss = 6.3612  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 4.0113  Validation loss = 6.3602  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 4.0105  Validation loss = 6.3593  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 4.0098  Validation loss = 6.3584  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 4.0090  Validation loss = 6.3574  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 4.0082  Validation loss = 6.3565  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 4.0077  Validation loss = 6.3559  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 4.0068  Validation loss = 6.3548  \n",
      "\n",
      "Fold: 16  Epoch: 136  Training loss = 4.0061  Validation loss = 6.3541  \n",
      "\n",
      "Fold: 16  Epoch: 137  Training loss = 4.0055  Validation loss = 6.3533  \n",
      "\n",
      "Fold: 16  Epoch: 138  Training loss = 4.0046  Validation loss = 6.3524  \n",
      "\n",
      "Fold: 16  Epoch: 139  Training loss = 4.0039  Validation loss = 6.3514  \n",
      "\n",
      "Fold: 16  Epoch: 140  Training loss = 4.0032  Validation loss = 6.3506  \n",
      "\n",
      "Fold: 16  Epoch: 141  Training loss = 4.0023  Validation loss = 6.3496  \n",
      "\n",
      "Fold: 16  Epoch: 142  Training loss = 4.0015  Validation loss = 6.3487  \n",
      "\n",
      "Fold: 16  Epoch: 143  Training loss = 4.0007  Validation loss = 6.3476  \n",
      "\n",
      "Fold: 16  Epoch: 144  Training loss = 3.9998  Validation loss = 6.3465  \n",
      "\n",
      "Fold: 16  Epoch: 145  Training loss = 3.9991  Validation loss = 6.3456  \n",
      "\n",
      "Fold: 16  Epoch: 146  Training loss = 3.9982  Validation loss = 6.3446  \n",
      "\n",
      "Fold: 16  Epoch: 147  Training loss = 3.9975  Validation loss = 6.3436  \n",
      "\n",
      "Fold: 16  Epoch: 148  Training loss = 3.9968  Validation loss = 6.3428  \n",
      "\n",
      "Fold: 16  Epoch: 149  Training loss = 3.9961  Validation loss = 6.3420  \n",
      "\n",
      "Fold: 16  Epoch: 150  Training loss = 3.9954  Validation loss = 6.3411  \n",
      "\n",
      "Fold: 16  Epoch: 151  Training loss = 3.9947  Validation loss = 6.3402  \n",
      "\n",
      "Fold: 16  Epoch: 152  Training loss = 3.9940  Validation loss = 6.3393  \n",
      "\n",
      "Fold: 16  Epoch: 153  Training loss = 3.9934  Validation loss = 6.3385  \n",
      "\n",
      "Fold: 16  Epoch: 154  Training loss = 3.9923  Validation loss = 6.3373  \n",
      "\n",
      "Fold: 16  Epoch: 155  Training loss = 3.9914  Validation loss = 6.3362  \n",
      "\n",
      "Fold: 16  Epoch: 156  Training loss = 3.9908  Validation loss = 6.3356  \n",
      "\n",
      "Fold: 16  Epoch: 157  Training loss = 3.9899  Validation loss = 6.3345  \n",
      "\n",
      "Fold: 16  Epoch: 158  Training loss = 3.9893  Validation loss = 6.3337  \n",
      "\n",
      "Fold: 16  Epoch: 159  Training loss = 3.9885  Validation loss = 6.3327  \n",
      "\n",
      "Fold: 16  Epoch: 160  Training loss = 3.9878  Validation loss = 6.3319  \n",
      "\n",
      "Fold: 16  Epoch: 161  Training loss = 3.9871  Validation loss = 6.3309  \n",
      "\n",
      "Fold: 16  Epoch: 162  Training loss = 3.9862  Validation loss = 6.3298  \n",
      "\n",
      "Fold: 16  Epoch: 163  Training loss = 3.9854  Validation loss = 6.3289  \n",
      "\n",
      "Fold: 16  Epoch: 164  Training loss = 3.9846  Validation loss = 6.3280  \n",
      "\n",
      "Fold: 16  Epoch: 165  Training loss = 3.9839  Validation loss = 6.3271  \n",
      "\n",
      "Fold: 16  Epoch: 166  Training loss = 3.9829  Validation loss = 6.3258  \n",
      "\n",
      "Fold: 16  Epoch: 167  Training loss = 3.9821  Validation loss = 6.3248  \n",
      "\n",
      "Fold: 16  Epoch: 168  Training loss = 3.9813  Validation loss = 6.3240  \n",
      "\n",
      "Fold: 16  Epoch: 169  Training loss = 3.9805  Validation loss = 6.3230  \n",
      "\n",
      "Fold: 16  Epoch: 170  Training loss = 3.9797  Validation loss = 6.3220  \n",
      "\n",
      "Fold: 16  Epoch: 171  Training loss = 3.9789  Validation loss = 6.3210  \n",
      "\n",
      "Fold: 16  Epoch: 172  Training loss = 3.9781  Validation loss = 6.3201  \n",
      "\n",
      "Fold: 16  Epoch: 173  Training loss = 3.9771  Validation loss = 6.3190  \n",
      "\n",
      "Fold: 16  Epoch: 174  Training loss = 3.9764  Validation loss = 6.3181  \n",
      "\n",
      "Fold: 16  Epoch: 175  Training loss = 3.9758  Validation loss = 6.3173  \n",
      "\n",
      "Fold: 16  Epoch: 176  Training loss = 3.9746  Validation loss = 6.3161  \n",
      "\n",
      "Fold: 16  Epoch: 177  Training loss = 3.9735  Validation loss = 6.3149  \n",
      "\n",
      "Fold: 16  Epoch: 178  Training loss = 3.9726  Validation loss = 6.3140  \n",
      "\n",
      "Fold: 16  Epoch: 179  Training loss = 3.9720  Validation loss = 6.3132  \n",
      "\n",
      "Fold: 16  Epoch: 180  Training loss = 3.9709  Validation loss = 6.3121  \n",
      "\n",
      "Fold: 16  Epoch: 181  Training loss = 3.9702  Validation loss = 6.3113  \n",
      "\n",
      "Fold: 16  Epoch: 182  Training loss = 3.9694  Validation loss = 6.3105  \n",
      "\n",
      "Fold: 16  Epoch: 183  Training loss = 3.9685  Validation loss = 6.3094  \n",
      "\n",
      "Fold: 16  Epoch: 184  Training loss = 3.9678  Validation loss = 6.3085  \n",
      "\n",
      "Fold: 16  Epoch: 185  Training loss = 3.9673  Validation loss = 6.3080  \n",
      "\n",
      "Fold: 16  Epoch: 186  Training loss = 3.9667  Validation loss = 6.3072  \n",
      "\n",
      "Fold: 16  Epoch: 187  Training loss = 3.9658  Validation loss = 6.3063  \n",
      "\n",
      "Fold: 16  Epoch: 188  Training loss = 3.9650  Validation loss = 6.3053  \n",
      "\n",
      "Fold: 16  Epoch: 189  Training loss = 3.9642  Validation loss = 6.3043  \n",
      "\n",
      "Fold: 16  Epoch: 190  Training loss = 3.9634  Validation loss = 6.3033  \n",
      "\n",
      "Fold: 16  Epoch: 191  Training loss = 3.9627  Validation loss = 6.3024  \n",
      "\n",
      "Fold: 16  Epoch: 192  Training loss = 3.9621  Validation loss = 6.3016  \n",
      "\n",
      "Fold: 16  Epoch: 193  Training loss = 3.9615  Validation loss = 6.3009  \n",
      "\n",
      "Fold: 16  Epoch: 194  Training loss = 3.9607  Validation loss = 6.2998  \n",
      "\n",
      "Fold: 16  Epoch: 195  Training loss = 3.9601  Validation loss = 6.2991  \n",
      "\n",
      "Fold: 16  Epoch: 196  Training loss = 3.9592  Validation loss = 6.2981  \n",
      "\n",
      "Fold: 16  Epoch: 197  Training loss = 3.9583  Validation loss = 6.2969  \n",
      "\n",
      "Fold: 16  Epoch: 198  Training loss = 3.9573  Validation loss = 6.2957  \n",
      "\n",
      "Fold: 16  Epoch: 199  Training loss = 3.9566  Validation loss = 6.2949  \n",
      "\n",
      "Fold: 16  Epoch: 200  Training loss = 3.9559  Validation loss = 6.2940  \n",
      "\n",
      "Fold: 16  Epoch: 201  Training loss = 3.9550  Validation loss = 6.2930  \n",
      "\n",
      "Fold: 16  Epoch: 202  Training loss = 3.9545  Validation loss = 6.2922  \n",
      "\n",
      "Fold: 16  Epoch: 203  Training loss = 3.9535  Validation loss = 6.2910  \n",
      "\n",
      "Fold: 16  Epoch: 204  Training loss = 3.9524  Validation loss = 6.2898  \n",
      "\n",
      "Fold: 16  Epoch: 205  Training loss = 3.9517  Validation loss = 6.2888  \n",
      "\n",
      "Fold: 16  Epoch: 206  Training loss = 3.9507  Validation loss = 6.2878  \n",
      "\n",
      "Fold: 16  Epoch: 207  Training loss = 3.9498  Validation loss = 6.2867  \n",
      "\n",
      "Fold: 16  Epoch: 208  Training loss = 3.9492  Validation loss = 6.2859  \n",
      "\n",
      "Fold: 16  Epoch: 209  Training loss = 3.9483  Validation loss = 6.2848  \n",
      "\n",
      "Fold: 16  Epoch: 210  Training loss = 3.9474  Validation loss = 6.2838  \n",
      "\n",
      "Fold: 16  Epoch: 211  Training loss = 3.9469  Validation loss = 6.2832  \n",
      "\n",
      "Fold: 16  Epoch: 212  Training loss = 3.9462  Validation loss = 6.2822  \n",
      "\n",
      "Fold: 16  Epoch: 213  Training loss = 3.9454  Validation loss = 6.2812  \n",
      "\n",
      "Fold: 16  Epoch: 214  Training loss = 3.9449  Validation loss = 6.2806  \n",
      "\n",
      "Fold: 16  Epoch: 215  Training loss = 3.9440  Validation loss = 6.2796  \n",
      "\n",
      "Fold: 16  Epoch: 216  Training loss = 3.9433  Validation loss = 6.2788  \n",
      "\n",
      "Fold: 16  Epoch: 217  Training loss = 3.9424  Validation loss = 6.2777  \n",
      "\n",
      "Fold: 16  Epoch: 218  Training loss = 3.9417  Validation loss = 6.2768  \n",
      "\n",
      "Fold: 16  Epoch: 219  Training loss = 3.9411  Validation loss = 6.2760  \n",
      "\n",
      "Fold: 16  Epoch: 220  Training loss = 3.9403  Validation loss = 6.2750  \n",
      "\n",
      "Fold: 16  Epoch: 221  Training loss = 3.9396  Validation loss = 6.2741  \n",
      "\n",
      "Fold: 16  Epoch: 222  Training loss = 3.9391  Validation loss = 6.2736  \n",
      "\n",
      "Fold: 16  Epoch: 223  Training loss = 3.9384  Validation loss = 6.2727  \n",
      "\n",
      "Fold: 16  Epoch: 224  Training loss = 3.9376  Validation loss = 6.2718  \n",
      "\n",
      "Fold: 16  Epoch: 225  Training loss = 3.9368  Validation loss = 6.2707  \n",
      "\n",
      "Fold: 16  Epoch: 226  Training loss = 3.9359  Validation loss = 6.2697  \n",
      "\n",
      "Fold: 16  Epoch: 227  Training loss = 3.9350  Validation loss = 6.2687  \n",
      "\n",
      "Fold: 16  Epoch: 228  Training loss = 3.9342  Validation loss = 6.2677  \n",
      "\n",
      "Fold: 16  Epoch: 229  Training loss = 3.9334  Validation loss = 6.2668  \n",
      "\n",
      "Fold: 16  Epoch: 230  Training loss = 3.9325  Validation loss = 6.2657  \n",
      "\n",
      "Fold: 16  Epoch: 231  Training loss = 3.9320  Validation loss = 6.2650  \n",
      "\n",
      "Fold: 16  Epoch: 232  Training loss = 3.9311  Validation loss = 6.2640  \n",
      "\n",
      "Fold: 16  Epoch: 233  Training loss = 3.9302  Validation loss = 6.2630  \n",
      "\n",
      "Fold: 16  Epoch: 234  Training loss = 3.9293  Validation loss = 6.2619  \n",
      "\n",
      "Fold: 16  Epoch: 235  Training loss = 3.9284  Validation loss = 6.2609  \n",
      "\n",
      "Fold: 16  Epoch: 236  Training loss = 3.9275  Validation loss = 6.2597  \n",
      "\n",
      "Fold: 16  Epoch: 237  Training loss = 3.9268  Validation loss = 6.2589  \n",
      "\n",
      "Fold: 16  Epoch: 238  Training loss = 3.9260  Validation loss = 6.2579  \n",
      "\n",
      "Fold: 16  Epoch: 239  Training loss = 3.9252  Validation loss = 6.2570  \n",
      "\n",
      "Fold: 16  Epoch: 240  Training loss = 3.9245  Validation loss = 6.2563  \n",
      "\n",
      "Fold: 16  Epoch: 241  Training loss = 3.9236  Validation loss = 6.2551  \n",
      "\n",
      "Fold: 16  Epoch: 242  Training loss = 3.9226  Validation loss = 6.2539  \n",
      "\n",
      "Fold: 16  Epoch: 243  Training loss = 3.9217  Validation loss = 6.2527  \n",
      "\n",
      "Fold: 16  Epoch: 244  Training loss = 3.9210  Validation loss = 6.2519  \n",
      "\n",
      "Fold: 16  Epoch: 245  Training loss = 3.9202  Validation loss = 6.2508  \n",
      "\n",
      "Fold: 16  Epoch: 246  Training loss = 3.9194  Validation loss = 6.2499  \n",
      "\n",
      "Fold: 16  Epoch: 247  Training loss = 3.9187  Validation loss = 6.2490  \n",
      "\n",
      "Fold: 16  Epoch: 248  Training loss = 3.9180  Validation loss = 6.2482  \n",
      "\n",
      "Fold: 16  Epoch: 249  Training loss = 3.9172  Validation loss = 6.2472  \n",
      "\n",
      "Fold: 16  Epoch: 250  Training loss = 3.9166  Validation loss = 6.2465  \n",
      "\n",
      "Fold: 16  Epoch: 251  Training loss = 3.9161  Validation loss = 6.2457  \n",
      "\n",
      "Fold: 16  Epoch: 252  Training loss = 3.9151  Validation loss = 6.2446  \n",
      "\n",
      "Fold: 16  Epoch: 253  Training loss = 3.9144  Validation loss = 6.2437  \n",
      "\n",
      "Fold: 16  Epoch: 254  Training loss = 3.9136  Validation loss = 6.2427  \n",
      "\n",
      "Fold: 16  Epoch: 255  Training loss = 3.9129  Validation loss = 6.2418  \n",
      "\n",
      "Fold: 16  Epoch: 256  Training loss = 3.9125  Validation loss = 6.2413  \n",
      "\n",
      "Fold: 16  Epoch: 257  Training loss = 3.9118  Validation loss = 6.2405  \n",
      "\n",
      "Fold: 16  Epoch: 258  Training loss = 3.9110  Validation loss = 6.2395  \n",
      "\n",
      "Fold: 16  Epoch: 259  Training loss = 3.9105  Validation loss = 6.2389  \n",
      "\n",
      "Fold: 16  Epoch: 260  Training loss = 3.9094  Validation loss = 6.2375  \n",
      "\n",
      "Fold: 16  Epoch: 261  Training loss = 3.9088  Validation loss = 6.2366  \n",
      "\n",
      "Fold: 16  Epoch: 262  Training loss = 3.9082  Validation loss = 6.2359  \n",
      "\n",
      "Fold: 16  Epoch: 263  Training loss = 3.9075  Validation loss = 6.2350  \n",
      "\n",
      "Fold: 16  Epoch: 264  Training loss = 3.9067  Validation loss = 6.2339  \n",
      "\n",
      "Fold: 16  Epoch: 265  Training loss = 3.9059  Validation loss = 6.2329  \n",
      "\n",
      "Fold: 16  Epoch: 266  Training loss = 3.9049  Validation loss = 6.2317  \n",
      "\n",
      "Fold: 16  Epoch: 267  Training loss = 3.9044  Validation loss = 6.2311  \n",
      "\n",
      "Fold: 16  Epoch: 268  Training loss = 3.9035  Validation loss = 6.2299  \n",
      "\n",
      "Fold: 16  Epoch: 269  Training loss = 3.9029  Validation loss = 6.2293  \n",
      "\n",
      "Fold: 16  Epoch: 270  Training loss = 3.9024  Validation loss = 6.2286  \n",
      "\n",
      "Fold: 16  Epoch: 271  Training loss = 3.9016  Validation loss = 6.2275  \n",
      "\n",
      "Fold: 16  Epoch: 272  Training loss = 3.9006  Validation loss = 6.2264  \n",
      "\n",
      "Fold: 16  Epoch: 273  Training loss = 3.9001  Validation loss = 6.2257  \n",
      "\n",
      "Fold: 16  Epoch: 274  Training loss = 3.8994  Validation loss = 6.2248  \n",
      "\n",
      "Fold: 16  Epoch: 275  Training loss = 3.8985  Validation loss = 6.2237  \n",
      "\n",
      "Fold: 16  Epoch: 276  Training loss = 3.8977  Validation loss = 6.2227  \n",
      "\n",
      "Fold: 16  Epoch: 277  Training loss = 3.8971  Validation loss = 6.2219  \n",
      "\n",
      "Fold: 16  Epoch: 278  Training loss = 3.8964  Validation loss = 6.2209  \n",
      "\n",
      "Fold: 16  Epoch: 279  Training loss = 3.8956  Validation loss = 6.2199  \n",
      "\n",
      "Fold: 16  Epoch: 280  Training loss = 3.8949  Validation loss = 6.2191  \n",
      "\n",
      "Fold: 16  Epoch: 281  Training loss = 3.8943  Validation loss = 6.2184  \n",
      "\n",
      "Fold: 16  Epoch: 282  Training loss = 3.8934  Validation loss = 6.2172  \n",
      "\n",
      "Fold: 16  Epoch: 283  Training loss = 3.8925  Validation loss = 6.2160  \n",
      "\n",
      "Fold: 16  Epoch: 284  Training loss = 3.8917  Validation loss = 6.2150  \n",
      "\n",
      "Fold: 16  Epoch: 285  Training loss = 3.8909  Validation loss = 6.2140  \n",
      "\n",
      "Fold: 16  Epoch: 286  Training loss = 3.8901  Validation loss = 6.2128  \n",
      "\n",
      "Fold: 16  Epoch: 287  Training loss = 3.8895  Validation loss = 6.2121  \n",
      "\n",
      "Fold: 16  Epoch: 288  Training loss = 3.8884  Validation loss = 6.2109  \n",
      "\n",
      "Fold: 16  Epoch: 289  Training loss = 3.8878  Validation loss = 6.2100  \n",
      "\n",
      "Fold: 16  Epoch: 290  Training loss = 3.8869  Validation loss = 6.2089  \n",
      "\n",
      "Fold: 16  Epoch: 291  Training loss = 3.8860  Validation loss = 6.2077  \n",
      "\n",
      "Fold: 16  Epoch: 292  Training loss = 3.8851  Validation loss = 6.2065  \n",
      "\n",
      "Fold: 16  Epoch: 293  Training loss = 3.8844  Validation loss = 6.2057  \n",
      "\n",
      "Fold: 16  Epoch: 294  Training loss = 3.8838  Validation loss = 6.2049  \n",
      "\n",
      "Fold: 16  Epoch: 295  Training loss = 3.8829  Validation loss = 6.2038  \n",
      "\n",
      "Fold: 16  Epoch: 296  Training loss = 3.8820  Validation loss = 6.2027  \n",
      "\n",
      "Fold: 16  Epoch: 297  Training loss = 3.8812  Validation loss = 6.2017  \n",
      "\n",
      "Fold: 16  Epoch: 298  Training loss = 3.8806  Validation loss = 6.2009  \n",
      "\n",
      "Fold: 16  Epoch: 299  Training loss = 3.8799  Validation loss = 6.2000  \n",
      "\n",
      "Fold: 16  Epoch: 300  Training loss = 3.8789  Validation loss = 6.1988  \n",
      "\n",
      "Fold: 16  Epoch: 301  Training loss = 3.8782  Validation loss = 6.1979  \n",
      "\n",
      "Fold: 16  Epoch: 302  Training loss = 3.8776  Validation loss = 6.1972  \n",
      "\n",
      "Fold: 16  Epoch: 303  Training loss = 3.8771  Validation loss = 6.1964  \n",
      "\n",
      "Fold: 16  Epoch: 304  Training loss = 3.8763  Validation loss = 6.1955  \n",
      "\n",
      "Fold: 16  Epoch: 305  Training loss = 3.8756  Validation loss = 6.1947  \n",
      "\n",
      "Fold: 16  Epoch: 306  Training loss = 3.8748  Validation loss = 6.1936  \n",
      "\n",
      "Fold: 16  Epoch: 307  Training loss = 3.8739  Validation loss = 6.1925  \n",
      "\n",
      "Fold: 16  Epoch: 308  Training loss = 3.8732  Validation loss = 6.1916  \n",
      "\n",
      "Fold: 16  Epoch: 309  Training loss = 3.8724  Validation loss = 6.1905  \n",
      "\n",
      "Fold: 16  Epoch: 310  Training loss = 3.8716  Validation loss = 6.1895  \n",
      "\n",
      "Fold: 16  Epoch: 311  Training loss = 3.8709  Validation loss = 6.1886  \n",
      "\n",
      "Fold: 16  Epoch: 312  Training loss = 3.8702  Validation loss = 6.1876  \n",
      "\n",
      "Fold: 16  Epoch: 313  Training loss = 3.8689  Validation loss = 6.1861  \n",
      "\n",
      "Fold: 16  Epoch: 314  Training loss = 3.8681  Validation loss = 6.1850  \n",
      "\n",
      "Fold: 16  Epoch: 315  Training loss = 3.8673  Validation loss = 6.1840  \n",
      "\n",
      "Fold: 16  Epoch: 316  Training loss = 3.8665  Validation loss = 6.1830  \n",
      "\n",
      "Fold: 16  Epoch: 317  Training loss = 3.8660  Validation loss = 6.1823  \n",
      "\n",
      "Fold: 16  Epoch: 318  Training loss = 3.8652  Validation loss = 6.1814  \n",
      "\n",
      "Fold: 16  Epoch: 319  Training loss = 3.8646  Validation loss = 6.1805  \n",
      "\n",
      "Fold: 16  Epoch: 320  Training loss = 3.8640  Validation loss = 6.1796  \n",
      "\n",
      "Fold: 16  Epoch: 321  Training loss = 3.8631  Validation loss = 6.1786  \n",
      "\n",
      "Fold: 16  Epoch: 322  Training loss = 3.8623  Validation loss = 6.1775  \n",
      "\n",
      "Fold: 16  Epoch: 323  Training loss = 3.8615  Validation loss = 6.1765  \n",
      "\n",
      "Fold: 16  Epoch: 324  Training loss = 3.8606  Validation loss = 6.1753  \n",
      "\n",
      "Fold: 16  Epoch: 325  Training loss = 3.8601  Validation loss = 6.1746  \n",
      "\n",
      "Fold: 16  Epoch: 326  Training loss = 3.8594  Validation loss = 6.1738  \n",
      "\n",
      "Fold: 16  Epoch: 327  Training loss = 3.8587  Validation loss = 6.1729  \n",
      "\n",
      "Fold: 16  Epoch: 328  Training loss = 3.8580  Validation loss = 6.1720  \n",
      "\n",
      "Fold: 16  Epoch: 329  Training loss = 3.8571  Validation loss = 6.1708  \n",
      "\n",
      "Fold: 16  Epoch: 330  Training loss = 3.8563  Validation loss = 6.1697  \n",
      "\n",
      "Fold: 16  Epoch: 331  Training loss = 3.8553  Validation loss = 6.1683  \n",
      "\n",
      "Fold: 16  Epoch: 332  Training loss = 3.8545  Validation loss = 6.1673  \n",
      "\n",
      "Fold: 16  Epoch: 333  Training loss = 3.8533  Validation loss = 6.1657  \n",
      "\n",
      "Fold: 16  Epoch: 334  Training loss = 3.8527  Validation loss = 6.1650  \n",
      "\n",
      "Fold: 16  Epoch: 335  Training loss = 3.8519  Validation loss = 6.1640  \n",
      "\n",
      "Fold: 16  Epoch: 336  Training loss = 3.8511  Validation loss = 6.1629  \n",
      "\n",
      "Fold: 16  Epoch: 337  Training loss = 3.8501  Validation loss = 6.1617  \n",
      "\n",
      "Fold: 16  Epoch: 338  Training loss = 3.8489  Validation loss = 6.1602  \n",
      "\n",
      "Fold: 16  Epoch: 339  Training loss = 3.8481  Validation loss = 6.1591  \n",
      "\n",
      "Fold: 16  Epoch: 340  Training loss = 3.8474  Validation loss = 6.1583  \n",
      "\n",
      "Fold: 16  Epoch: 341  Training loss = 3.8466  Validation loss = 6.1572  \n",
      "\n",
      "Fold: 16  Epoch: 342  Training loss = 3.8459  Validation loss = 6.1563  \n",
      "\n",
      "Fold: 16  Epoch: 343  Training loss = 3.8451  Validation loss = 6.1552  \n",
      "\n",
      "Fold: 16  Epoch: 344  Training loss = 3.8443  Validation loss = 6.1541  \n",
      "\n",
      "Fold: 16  Epoch: 345  Training loss = 3.8434  Validation loss = 6.1530  \n",
      "\n",
      "Fold: 16  Epoch: 346  Training loss = 3.8425  Validation loss = 6.1518  \n",
      "\n",
      "Fold: 16  Epoch: 347  Training loss = 3.8418  Validation loss = 6.1508  \n",
      "\n",
      "Fold: 16  Epoch: 348  Training loss = 3.8409  Validation loss = 6.1498  \n",
      "\n",
      "Fold: 16  Epoch: 349  Training loss = 3.8403  Validation loss = 6.1490  \n",
      "\n",
      "Fold: 16  Epoch: 350  Training loss = 3.8398  Validation loss = 6.1483  \n",
      "\n",
      "Fold: 16  Epoch: 351  Training loss = 3.8392  Validation loss = 6.1475  \n",
      "\n",
      "Fold: 16  Epoch: 352  Training loss = 3.8387  Validation loss = 6.1468  \n",
      "\n",
      "Fold: 16  Epoch: 353  Training loss = 3.8380  Validation loss = 6.1459  \n",
      "\n",
      "Fold: 16  Epoch: 354  Training loss = 3.8375  Validation loss = 6.1452  \n",
      "\n",
      "Fold: 16  Epoch: 355  Training loss = 3.8368  Validation loss = 6.1442  \n",
      "\n",
      "Fold: 16  Epoch: 356  Training loss = 3.8359  Validation loss = 6.1430  \n",
      "\n",
      "Fold: 16  Epoch: 357  Training loss = 3.8352  Validation loss = 6.1421  \n",
      "\n",
      "Fold: 16  Epoch: 358  Training loss = 3.8346  Validation loss = 6.1413  \n",
      "\n",
      "Fold: 16  Epoch: 359  Training loss = 3.8335  Validation loss = 6.1399  \n",
      "\n",
      "Fold: 16  Epoch: 360  Training loss = 3.8328  Validation loss = 6.1389  \n",
      "\n",
      "Fold: 16  Epoch: 361  Training loss = 3.8318  Validation loss = 6.1377  \n",
      "\n",
      "Fold: 16  Epoch: 362  Training loss = 3.8311  Validation loss = 6.1368  \n",
      "\n",
      "Fold: 16  Epoch: 363  Training loss = 3.8304  Validation loss = 6.1359  \n",
      "\n",
      "Fold: 16  Epoch: 364  Training loss = 3.8296  Validation loss = 6.1348  \n",
      "\n",
      "Fold: 16  Epoch: 365  Training loss = 3.8289  Validation loss = 6.1339  \n",
      "\n",
      "Fold: 16  Epoch: 366  Training loss = 3.8280  Validation loss = 6.1327  \n",
      "\n",
      "Fold: 16  Epoch: 367  Training loss = 3.8274  Validation loss = 6.1320  \n",
      "\n",
      "Fold: 16  Epoch: 368  Training loss = 3.8269  Validation loss = 6.1313  \n",
      "\n",
      "Fold: 16  Epoch: 369  Training loss = 3.8260  Validation loss = 6.1302  \n",
      "\n",
      "Fold: 16  Epoch: 370  Training loss = 3.8256  Validation loss = 6.1297  \n",
      "\n",
      "Fold: 16  Epoch: 371  Training loss = 3.8250  Validation loss = 6.1289  \n",
      "\n",
      "Fold: 16  Epoch: 372  Training loss = 3.8241  Validation loss = 6.1277  \n",
      "\n",
      "Fold: 16  Epoch: 373  Training loss = 3.8234  Validation loss = 6.1267  \n",
      "\n",
      "Fold: 16  Epoch: 374  Training loss = 3.8227  Validation loss = 6.1259  \n",
      "\n",
      "Fold: 16  Epoch: 375  Training loss = 3.8218  Validation loss = 6.1248  \n",
      "\n",
      "Fold: 16  Epoch: 376  Training loss = 3.8210  Validation loss = 6.1238  \n",
      "\n",
      "Fold: 16  Epoch: 377  Training loss = 3.8204  Validation loss = 6.1230  \n",
      "\n",
      "Fold: 16  Epoch: 378  Training loss = 3.8196  Validation loss = 6.1219  \n",
      "\n",
      "Fold: 16  Epoch: 379  Training loss = 3.8188  Validation loss = 6.1210  \n",
      "\n",
      "Fold: 16  Epoch: 380  Training loss = 3.8185  Validation loss = 6.1205  \n",
      "\n",
      "Fold: 16  Epoch: 381  Training loss = 3.8176  Validation loss = 6.1194  \n",
      "\n",
      "Fold: 16  Epoch: 382  Training loss = 3.8170  Validation loss = 6.1186  \n",
      "\n",
      "Fold: 16  Epoch: 383  Training loss = 3.8164  Validation loss = 6.1178  \n",
      "\n",
      "Fold: 16  Epoch: 384  Training loss = 3.8157  Validation loss = 6.1169  \n",
      "\n",
      "Fold: 16  Epoch: 385  Training loss = 3.8148  Validation loss = 6.1156  \n",
      "\n",
      "Fold: 16  Epoch: 386  Training loss = 3.8139  Validation loss = 6.1145  \n",
      "\n",
      "Fold: 16  Epoch: 387  Training loss = 3.8127  Validation loss = 6.1129  \n",
      "\n",
      "Fold: 16  Epoch: 388  Training loss = 3.8118  Validation loss = 6.1116  \n",
      "\n",
      "Fold: 16  Epoch: 389  Training loss = 3.8111  Validation loss = 6.1108  \n",
      "\n",
      "Fold: 16  Epoch: 390  Training loss = 3.8103  Validation loss = 6.1098  \n",
      "\n",
      "Fold: 16  Epoch: 391  Training loss = 3.8098  Validation loss = 6.1091  \n",
      "\n",
      "Fold: 16  Epoch: 392  Training loss = 3.8092  Validation loss = 6.1084  \n",
      "\n",
      "Fold: 16  Epoch: 393  Training loss = 3.8085  Validation loss = 6.1074  \n",
      "\n",
      "Fold: 16  Epoch: 394  Training loss = 3.8075  Validation loss = 6.1062  \n",
      "\n",
      "Fold: 16  Epoch: 395  Training loss = 3.8067  Validation loss = 6.1051  \n",
      "\n",
      "Fold: 16  Epoch: 396  Training loss = 3.8060  Validation loss = 6.1040  \n",
      "\n",
      "Fold: 16  Epoch: 397  Training loss = 3.8054  Validation loss = 6.1032  \n",
      "\n",
      "Fold: 16  Epoch: 398  Training loss = 3.8046  Validation loss = 6.1023  \n",
      "\n",
      "Fold: 16  Epoch: 399  Training loss = 3.8037  Validation loss = 6.1011  \n",
      "\n",
      "Fold: 16  Epoch: 400  Training loss = 3.8030  Validation loss = 6.1000  \n",
      "\n",
      "Fold: 16  Epoch: 401  Training loss = 3.8022  Validation loss = 6.0990  \n",
      "\n",
      "Fold: 16  Epoch: 402  Training loss = 3.8015  Validation loss = 6.0981  \n",
      "\n",
      "Fold: 16  Epoch: 403  Training loss = 3.8011  Validation loss = 6.0975  \n",
      "\n",
      "Fold: 16  Epoch: 404  Training loss = 3.8004  Validation loss = 6.0967  \n",
      "\n",
      "Fold: 16  Epoch: 405  Training loss = 3.7997  Validation loss = 6.0956  \n",
      "\n",
      "Fold: 16  Epoch: 406  Training loss = 3.7990  Validation loss = 6.0948  \n",
      "\n",
      "Fold: 16  Epoch: 407  Training loss = 3.7982  Validation loss = 6.0936  \n",
      "\n",
      "Fold: 16  Epoch: 408  Training loss = 3.7975  Validation loss = 6.0927  \n",
      "\n",
      "Fold: 16  Epoch: 409  Training loss = 3.7967  Validation loss = 6.0916  \n",
      "\n",
      "Fold: 16  Epoch: 410  Training loss = 3.7959  Validation loss = 6.0905  \n",
      "\n",
      "Fold: 16  Epoch: 411  Training loss = 3.7950  Validation loss = 6.0893  \n",
      "\n",
      "Fold: 16  Epoch: 412  Training loss = 3.7943  Validation loss = 6.0883  \n",
      "\n",
      "Fold: 16  Epoch: 413  Training loss = 3.7938  Validation loss = 6.0878  \n",
      "\n",
      "Fold: 16  Epoch: 414  Training loss = 3.7932  Validation loss = 6.0870  \n",
      "\n",
      "Fold: 16  Epoch: 415  Training loss = 3.7923  Validation loss = 6.0858  \n",
      "\n",
      "Fold: 16  Epoch: 416  Training loss = 3.7917  Validation loss = 6.0849  \n",
      "\n",
      "Fold: 16  Epoch: 417  Training loss = 3.7908  Validation loss = 6.0837  \n",
      "\n",
      "Fold: 16  Epoch: 418  Training loss = 3.7900  Validation loss = 6.0826  \n",
      "\n",
      "Fold: 16  Epoch: 419  Training loss = 3.7894  Validation loss = 6.0816  \n",
      "\n",
      "Fold: 16  Epoch: 420  Training loss = 3.7885  Validation loss = 6.0804  \n",
      "\n",
      "Fold: 16  Epoch: 421  Training loss = 3.7877  Validation loss = 6.0793  \n",
      "\n",
      "Fold: 16  Epoch: 422  Training loss = 3.7870  Validation loss = 6.0784  \n",
      "\n",
      "Fold: 16  Epoch: 423  Training loss = 3.7863  Validation loss = 6.0774  \n",
      "\n",
      "Fold: 16  Epoch: 424  Training loss = 3.7855  Validation loss = 6.0763  \n",
      "\n",
      "Fold: 16  Epoch: 425  Training loss = 3.7848  Validation loss = 6.0755  \n",
      "\n",
      "Fold: 16  Epoch: 426  Training loss = 3.7843  Validation loss = 6.0748  \n",
      "\n",
      "Fold: 16  Epoch: 427  Training loss = 3.7834  Validation loss = 6.0736  \n",
      "\n",
      "Fold: 16  Epoch: 428  Training loss = 3.7828  Validation loss = 6.0728  \n",
      "\n",
      "Fold: 16  Epoch: 429  Training loss = 3.7821  Validation loss = 6.0717  \n",
      "\n",
      "Fold: 16  Epoch: 430  Training loss = 3.7812  Validation loss = 6.0706  \n",
      "\n",
      "Fold: 16  Epoch: 431  Training loss = 3.7806  Validation loss = 6.0698  \n",
      "\n",
      "Fold: 16  Epoch: 432  Training loss = 3.7798  Validation loss = 6.0687  \n",
      "\n",
      "Fold: 16  Epoch: 433  Training loss = 3.7793  Validation loss = 6.0681  \n",
      "\n",
      "Fold: 16  Epoch: 434  Training loss = 3.7783  Validation loss = 6.0667  \n",
      "\n",
      "Fold: 16  Epoch: 435  Training loss = 3.7777  Validation loss = 6.0658  \n",
      "\n",
      "Fold: 16  Epoch: 436  Training loss = 3.7767  Validation loss = 6.0644  \n",
      "\n",
      "Fold: 16  Epoch: 437  Training loss = 3.7761  Validation loss = 6.0636  \n",
      "\n",
      "Fold: 16  Epoch: 438  Training loss = 3.7755  Validation loss = 6.0628  \n",
      "\n",
      "Fold: 16  Epoch: 439  Training loss = 3.7747  Validation loss = 6.0617  \n",
      "\n",
      "Fold: 16  Epoch: 440  Training loss = 3.7741  Validation loss = 6.0609  \n",
      "\n",
      "Fold: 16  Epoch: 441  Training loss = 3.7737  Validation loss = 6.0602  \n",
      "\n",
      "Fold: 16  Epoch: 442  Training loss = 3.7730  Validation loss = 6.0593  \n",
      "\n",
      "Fold: 16  Epoch: 443  Training loss = 3.7723  Validation loss = 6.0584  \n",
      "\n",
      "Fold: 16  Epoch: 444  Training loss = 3.7716  Validation loss = 6.0574  \n",
      "\n",
      "Fold: 16  Epoch: 445  Training loss = 3.7709  Validation loss = 6.0564  \n",
      "\n",
      "Fold: 16  Epoch: 446  Training loss = 3.7702  Validation loss = 6.0554  \n",
      "\n",
      "Fold: 16  Epoch: 447  Training loss = 3.7694  Validation loss = 6.0544  \n",
      "\n",
      "Fold: 16  Epoch: 448  Training loss = 3.7685  Validation loss = 6.0531  \n",
      "\n",
      "Fold: 16  Epoch: 449  Training loss = 3.7679  Validation loss = 6.0523  \n",
      "\n",
      "Fold: 16  Epoch: 450  Training loss = 3.7672  Validation loss = 6.0512  \n",
      "\n",
      "Fold: 16  Epoch: 451  Training loss = 3.7665  Validation loss = 6.0503  \n",
      "\n",
      "Fold: 16  Epoch: 452  Training loss = 3.7658  Validation loss = 6.0493  \n",
      "\n",
      "Fold: 16  Epoch: 453  Training loss = 3.7650  Validation loss = 6.0483  \n",
      "\n",
      "Fold: 16  Epoch: 454  Training loss = 3.7646  Validation loss = 6.0476  \n",
      "\n",
      "Fold: 16  Epoch: 455  Training loss = 3.7640  Validation loss = 6.0468  \n",
      "\n",
      "Fold: 16  Epoch: 456  Training loss = 3.7634  Validation loss = 6.0459  \n",
      "\n",
      "Fold: 16  Epoch: 457  Training loss = 3.7627  Validation loss = 6.0450  \n",
      "\n",
      "Fold: 16  Epoch: 458  Training loss = 3.7619  Validation loss = 6.0439  \n",
      "\n",
      "Fold: 16  Epoch: 459  Training loss = 3.7614  Validation loss = 6.0431  \n",
      "\n",
      "Fold: 16  Epoch: 460  Training loss = 3.7607  Validation loss = 6.0421  \n",
      "\n",
      "Fold: 16  Epoch: 461  Training loss = 3.7601  Validation loss = 6.0413  \n",
      "\n",
      "Fold: 16  Epoch: 462  Training loss = 3.7596  Validation loss = 6.0404  \n",
      "\n",
      "Fold: 16  Epoch: 463  Training loss = 3.7586  Validation loss = 6.0392  \n",
      "\n",
      "Fold: 16  Epoch: 464  Training loss = 3.7582  Validation loss = 6.0386  \n",
      "\n",
      "Fold: 16  Epoch: 465  Training loss = 3.7577  Validation loss = 6.0380  \n",
      "\n",
      "Fold: 16  Epoch: 466  Training loss = 3.7569  Validation loss = 6.0368  \n",
      "\n",
      "Fold: 16  Epoch: 467  Training loss = 3.7562  Validation loss = 6.0360  \n",
      "\n",
      "Fold: 16  Epoch: 468  Training loss = 3.7554  Validation loss = 6.0347  \n",
      "\n",
      "Fold: 16  Epoch: 469  Training loss = 3.7545  Validation loss = 6.0336  \n",
      "\n",
      "Fold: 16  Epoch: 470  Training loss = 3.7539  Validation loss = 6.0327  \n",
      "\n",
      "Fold: 16  Epoch: 471  Training loss = 3.7531  Validation loss = 6.0316  \n",
      "\n",
      "Fold: 16  Epoch: 472  Training loss = 3.7525  Validation loss = 6.0307  \n",
      "\n",
      "Fold: 16  Epoch: 473  Training loss = 3.7516  Validation loss = 6.0296  \n",
      "\n",
      "Fold: 16  Epoch: 474  Training loss = 3.7507  Validation loss = 6.0283  \n",
      "\n",
      "Fold: 16  Epoch: 475  Training loss = 3.7501  Validation loss = 6.0275  \n",
      "\n",
      "Fold: 16  Epoch: 476  Training loss = 3.7493  Validation loss = 6.0265  \n",
      "\n",
      "Fold: 16  Epoch: 477  Training loss = 3.7484  Validation loss = 6.0251  \n",
      "\n",
      "Fold: 16  Epoch: 478  Training loss = 3.7477  Validation loss = 6.0242  \n",
      "\n",
      "Fold: 16  Epoch: 479  Training loss = 3.7471  Validation loss = 6.0235  \n",
      "\n",
      "Fold: 16  Epoch: 480  Training loss = 3.7463  Validation loss = 6.0223  \n",
      "\n",
      "Fold: 16  Epoch: 481  Training loss = 3.7458  Validation loss = 6.0216  \n",
      "\n",
      "Fold: 16  Epoch: 482  Training loss = 3.7451  Validation loss = 6.0206  \n",
      "\n",
      "Fold: 16  Epoch: 483  Training loss = 3.7445  Validation loss = 6.0199  \n",
      "\n",
      "Fold: 16  Epoch: 484  Training loss = 3.7439  Validation loss = 6.0191  \n",
      "\n",
      "Fold: 16  Epoch: 485  Training loss = 3.7433  Validation loss = 6.0183  \n",
      "\n",
      "Fold: 16  Epoch: 486  Training loss = 3.7426  Validation loss = 6.0174  \n",
      "\n",
      "Fold: 16  Epoch: 487  Training loss = 3.7420  Validation loss = 6.0165  \n",
      "\n",
      "Fold: 16  Epoch: 488  Training loss = 3.7413  Validation loss = 6.0155  \n",
      "\n",
      "Fold: 16  Epoch: 489  Training loss = 3.7404  Validation loss = 6.0142  \n",
      "\n",
      "Fold: 16  Epoch: 490  Training loss = 3.7397  Validation loss = 6.0132  \n",
      "\n",
      "Fold: 16  Epoch: 491  Training loss = 3.7390  Validation loss = 6.0123  \n",
      "\n",
      "Fold: 16  Epoch: 492  Training loss = 3.7384  Validation loss = 6.0115  \n",
      "\n",
      "Fold: 16  Epoch: 493  Training loss = 3.7378  Validation loss = 6.0107  \n",
      "\n",
      "Fold: 16  Epoch: 494  Training loss = 3.7373  Validation loss = 6.0099  \n",
      "\n",
      "Fold: 16  Epoch: 495  Training loss = 3.7369  Validation loss = 6.0094  \n",
      "\n",
      "Fold: 16  Epoch: 496  Training loss = 3.7363  Validation loss = 6.0084  \n",
      "\n",
      "Fold: 16  Epoch: 497  Training loss = 3.7359  Validation loss = 6.0078  \n",
      "\n",
      "Fold: 16  Epoch: 498  Training loss = 3.7350  Validation loss = 6.0066  \n",
      "\n",
      "Fold: 16  Epoch: 499  Training loss = 3.7342  Validation loss = 6.0054  \n",
      "\n",
      "Fold: 16  Epoch: 500  Training loss = 3.7337  Validation loss = 6.0047  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 500  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 4.0097  Validation loss = 3.0508  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 4.0089  Validation loss = 3.0506  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 4.0083  Validation loss = 3.0504  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 4.0073  Validation loss = 3.0501  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 4.0066  Validation loss = 3.0500  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 4.0057  Validation loss = 3.0498  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 4.0049  Validation loss = 3.0494  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 4.0042  Validation loss = 3.0493  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 4.0033  Validation loss = 3.0491  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 4.0026  Validation loss = 3.0490  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 4.0018  Validation loss = 3.0487  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 4.0009  Validation loss = 3.0482  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 4.0001  Validation loss = 3.0480  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 3.9993  Validation loss = 3.0480  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 3.9984  Validation loss = 3.0476  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 3.9973  Validation loss = 3.0474  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 3.9966  Validation loss = 3.0473  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 3.9956  Validation loss = 3.0471  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 3.9949  Validation loss = 3.0470  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 3.9940  Validation loss = 3.0466  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 3.9928  Validation loss = 3.0462  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 3.9920  Validation loss = 3.0459  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 3.9910  Validation loss = 3.0456  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 3.9901  Validation loss = 3.0455  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 3.9894  Validation loss = 3.0454  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 3.9885  Validation loss = 3.0452  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 3.9878  Validation loss = 3.0451  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 3.9870  Validation loss = 3.0448  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 3.9859  Validation loss = 3.0445  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 3.9852  Validation loss = 3.0443  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 3.9844  Validation loss = 3.0441  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 3.9835  Validation loss = 3.0437  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 3.9828  Validation loss = 3.0437  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 3.9821  Validation loss = 3.0435  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 3.9813  Validation loss = 3.0433  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 3.9805  Validation loss = 3.0431  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 3.9795  Validation loss = 3.0430  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 3.9786  Validation loss = 3.0425  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 3.9777  Validation loss = 3.0422  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 3.9770  Validation loss = 3.0421  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 3.9765  Validation loss = 3.0420  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 3.9757  Validation loss = 3.0418  \n",
      "\n",
      "Fold: 17  Epoch: 43  Training loss = 3.9748  Validation loss = 3.0418  \n",
      "\n",
      "Fold: 17  Epoch: 44  Training loss = 3.9741  Validation loss = 3.0417  \n",
      "\n",
      "Fold: 17  Epoch: 45  Training loss = 3.9730  Validation loss = 3.0414  \n",
      "\n",
      "Fold: 17  Epoch: 46  Training loss = 3.9724  Validation loss = 3.0412  \n",
      "\n",
      "Fold: 17  Epoch: 47  Training loss = 3.9719  Validation loss = 3.0410  \n",
      "\n",
      "Fold: 17  Epoch: 48  Training loss = 3.9709  Validation loss = 3.0409  \n",
      "\n",
      "Fold: 17  Epoch: 49  Training loss = 3.9699  Validation loss = 3.0408  \n",
      "\n",
      "Fold: 17  Epoch: 50  Training loss = 3.9691  Validation loss = 3.0405  \n",
      "\n",
      "Fold: 17  Epoch: 51  Training loss = 3.9679  Validation loss = 3.0401  \n",
      "\n",
      "Fold: 17  Epoch: 52  Training loss = 3.9672  Validation loss = 3.0399  \n",
      "\n",
      "Fold: 17  Epoch: 53  Training loss = 3.9664  Validation loss = 3.0398  \n",
      "\n",
      "Fold: 17  Epoch: 54  Training loss = 3.9657  Validation loss = 3.0396  \n",
      "\n",
      "Fold: 17  Epoch: 55  Training loss = 3.9649  Validation loss = 3.0394  \n",
      "\n",
      "Fold: 17  Epoch: 56  Training loss = 3.9642  Validation loss = 3.0392  \n",
      "\n",
      "Fold: 17  Epoch: 57  Training loss = 3.9635  Validation loss = 3.0389  \n",
      "\n",
      "Fold: 17  Epoch: 58  Training loss = 3.9628  Validation loss = 3.0389  \n",
      "\n",
      "Fold: 17  Epoch: 59  Training loss = 3.9619  Validation loss = 3.0386  \n",
      "\n",
      "Fold: 17  Epoch: 60  Training loss = 3.9613  Validation loss = 3.0385  \n",
      "\n",
      "Fold: 17  Epoch: 61  Training loss = 3.9603  Validation loss = 3.0382  \n",
      "\n",
      "Fold: 17  Epoch: 62  Training loss = 3.9595  Validation loss = 3.0380  \n",
      "\n",
      "Fold: 17  Epoch: 63  Training loss = 3.9585  Validation loss = 3.0378  \n",
      "\n",
      "Fold: 17  Epoch: 64  Training loss = 3.9579  Validation loss = 3.0374  \n",
      "\n",
      "Fold: 17  Epoch: 65  Training loss = 3.9571  Validation loss = 3.0371  \n",
      "\n",
      "Fold: 17  Epoch: 66  Training loss = 3.9560  Validation loss = 3.0369  \n",
      "\n",
      "Fold: 17  Epoch: 67  Training loss = 3.9552  Validation loss = 3.0365  \n",
      "\n",
      "Fold: 17  Epoch: 68  Training loss = 3.9546  Validation loss = 3.0363  \n",
      "\n",
      "Fold: 17  Epoch: 69  Training loss = 3.9538  Validation loss = 3.0359  \n",
      "\n",
      "Fold: 17  Epoch: 70  Training loss = 3.9530  Validation loss = 3.0356  \n",
      "\n",
      "Fold: 17  Epoch: 71  Training loss = 3.9520  Validation loss = 3.0352  \n",
      "\n",
      "Fold: 17  Epoch: 72  Training loss = 3.9511  Validation loss = 3.0347  \n",
      "\n",
      "Fold: 17  Epoch: 73  Training loss = 3.9504  Validation loss = 3.0347  \n",
      "\n",
      "Fold: 17  Epoch: 74  Training loss = 3.9496  Validation loss = 3.0346  \n",
      "\n",
      "Fold: 17  Epoch: 75  Training loss = 3.9488  Validation loss = 3.0344  \n",
      "\n",
      "Fold: 17  Epoch: 76  Training loss = 3.9478  Validation loss = 3.0341  \n",
      "\n",
      "Fold: 17  Epoch: 77  Training loss = 3.9470  Validation loss = 3.0340  \n",
      "\n",
      "Fold: 17  Epoch: 78  Training loss = 3.9463  Validation loss = 3.0338  \n",
      "\n",
      "Fold: 17  Epoch: 79  Training loss = 3.9453  Validation loss = 3.0336  \n",
      "\n",
      "Fold: 17  Epoch: 80  Training loss = 3.9442  Validation loss = 3.0334  \n",
      "\n",
      "Fold: 17  Epoch: 81  Training loss = 3.9437  Validation loss = 3.0333  \n",
      "\n",
      "Fold: 17  Epoch: 82  Training loss = 3.9428  Validation loss = 3.0332  \n",
      "\n",
      "Fold: 17  Epoch: 83  Training loss = 3.9418  Validation loss = 3.0332  \n",
      "\n",
      "Fold: 17  Epoch: 84  Training loss = 3.9410  Validation loss = 3.0329  \n",
      "\n",
      "Fold: 17  Epoch: 85  Training loss = 3.9401  Validation loss = 3.0328  \n",
      "\n",
      "Fold: 17  Epoch: 86  Training loss = 3.9393  Validation loss = 3.0324  \n",
      "\n",
      "Fold: 17  Epoch: 87  Training loss = 3.9383  Validation loss = 3.0321  \n",
      "\n",
      "Fold: 17  Epoch: 88  Training loss = 3.9374  Validation loss = 3.0318  \n",
      "\n",
      "Fold: 17  Epoch: 89  Training loss = 3.9366  Validation loss = 3.0317  \n",
      "\n",
      "Fold: 17  Epoch: 90  Training loss = 3.9357  Validation loss = 3.0314  \n",
      "\n",
      "Fold: 17  Epoch: 91  Training loss = 3.9353  Validation loss = 3.0313  \n",
      "\n",
      "Fold: 17  Epoch: 92  Training loss = 3.9347  Validation loss = 3.0310  \n",
      "\n",
      "Fold: 17  Epoch: 93  Training loss = 3.9336  Validation loss = 3.0306  \n",
      "\n",
      "Fold: 17  Epoch: 94  Training loss = 3.9330  Validation loss = 3.0302  \n",
      "\n",
      "Fold: 17  Epoch: 95  Training loss = 3.9321  Validation loss = 3.0298  \n",
      "\n",
      "Fold: 17  Epoch: 96  Training loss = 3.9312  Validation loss = 3.0296  \n",
      "\n",
      "Fold: 17  Epoch: 97  Training loss = 3.9305  Validation loss = 3.0295  \n",
      "\n",
      "Fold: 17  Epoch: 98  Training loss = 3.9298  Validation loss = 3.0293  \n",
      "\n",
      "Fold: 17  Epoch: 99  Training loss = 3.9288  Validation loss = 3.0291  \n",
      "\n",
      "Fold: 17  Epoch: 100  Training loss = 3.9279  Validation loss = 3.0290  \n",
      "\n",
      "Fold: 17  Epoch: 101  Training loss = 3.9272  Validation loss = 3.0287  \n",
      "\n",
      "Fold: 17  Epoch: 102  Training loss = 3.9265  Validation loss = 3.0286  \n",
      "\n",
      "Fold: 17  Epoch: 103  Training loss = 3.9256  Validation loss = 3.0284  \n",
      "\n",
      "Fold: 17  Epoch: 104  Training loss = 3.9248  Validation loss = 3.0282  \n",
      "\n",
      "Fold: 17  Epoch: 105  Training loss = 3.9240  Validation loss = 3.0282  \n",
      "\n",
      "Fold: 17  Epoch: 106  Training loss = 3.9228  Validation loss = 3.0281  \n",
      "\n",
      "Fold: 17  Epoch: 107  Training loss = 3.9219  Validation loss = 3.0277  \n",
      "\n",
      "Fold: 17  Epoch: 108  Training loss = 3.9210  Validation loss = 3.0274  \n",
      "\n",
      "Fold: 17  Epoch: 109  Training loss = 3.9203  Validation loss = 3.0272  \n",
      "\n",
      "Fold: 17  Epoch: 110  Training loss = 3.9195  Validation loss = 3.0269  \n",
      "\n",
      "Fold: 17  Epoch: 111  Training loss = 3.9186  Validation loss = 3.0264  \n",
      "\n",
      "Fold: 17  Epoch: 112  Training loss = 3.9179  Validation loss = 3.0262  \n",
      "\n",
      "Fold: 17  Epoch: 113  Training loss = 3.9171  Validation loss = 3.0262  \n",
      "\n",
      "Fold: 17  Epoch: 114  Training loss = 3.9162  Validation loss = 3.0258  \n",
      "\n",
      "Fold: 17  Epoch: 115  Training loss = 3.9154  Validation loss = 3.0254  \n",
      "\n",
      "Fold: 17  Epoch: 116  Training loss = 3.9144  Validation loss = 3.0251  \n",
      "\n",
      "Fold: 17  Epoch: 117  Training loss = 3.9139  Validation loss = 3.0249  \n",
      "\n",
      "Fold: 17  Epoch: 118  Training loss = 3.9129  Validation loss = 3.0247  \n",
      "\n",
      "Fold: 17  Epoch: 119  Training loss = 3.9123  Validation loss = 3.0247  \n",
      "\n",
      "Fold: 17  Epoch: 120  Training loss = 3.9114  Validation loss = 3.0246  \n",
      "\n",
      "Fold: 17  Epoch: 121  Training loss = 3.9106  Validation loss = 3.0245  \n",
      "\n",
      "Fold: 17  Epoch: 122  Training loss = 3.9098  Validation loss = 3.0244  \n",
      "\n",
      "Fold: 17  Epoch: 123  Training loss = 3.9089  Validation loss = 3.0242  \n",
      "\n",
      "Fold: 17  Epoch: 124  Training loss = 3.9076  Validation loss = 3.0240  \n",
      "\n",
      "Fold: 17  Epoch: 125  Training loss = 3.9066  Validation loss = 3.0237  \n",
      "\n",
      "Fold: 17  Epoch: 126  Training loss = 3.9059  Validation loss = 3.0234  \n",
      "\n",
      "Fold: 17  Epoch: 127  Training loss = 3.9048  Validation loss = 3.0234  \n",
      "\n",
      "Fold: 17  Epoch: 128  Training loss = 3.9041  Validation loss = 3.0232  \n",
      "\n",
      "Fold: 17  Epoch: 129  Training loss = 3.9031  Validation loss = 3.0228  \n",
      "\n",
      "Fold: 17  Epoch: 130  Training loss = 3.9024  Validation loss = 3.0226  \n",
      "\n",
      "Fold: 17  Epoch: 131  Training loss = 3.9014  Validation loss = 3.0224  \n",
      "\n",
      "Fold: 17  Epoch: 132  Training loss = 3.9006  Validation loss = 3.0223  \n",
      "\n",
      "Fold: 17  Epoch: 133  Training loss = 3.8998  Validation loss = 3.0221  \n",
      "\n",
      "Fold: 17  Epoch: 134  Training loss = 3.8991  Validation loss = 3.0219  \n",
      "\n",
      "Fold: 17  Epoch: 135  Training loss = 3.8984  Validation loss = 3.0217  \n",
      "\n",
      "Fold: 17  Epoch: 136  Training loss = 3.8977  Validation loss = 3.0216  \n",
      "\n",
      "Fold: 17  Epoch: 137  Training loss = 3.8967  Validation loss = 3.0215  \n",
      "\n",
      "Fold: 17  Epoch: 138  Training loss = 3.8961  Validation loss = 3.0214  \n",
      "\n",
      "Fold: 17  Epoch: 139  Training loss = 3.8952  Validation loss = 3.0213  \n",
      "\n",
      "Fold: 17  Epoch: 140  Training loss = 3.8942  Validation loss = 3.0212  \n",
      "\n",
      "Fold: 17  Epoch: 141  Training loss = 3.8934  Validation loss = 3.0211  \n",
      "\n",
      "Fold: 17  Epoch: 142  Training loss = 3.8926  Validation loss = 3.0208  \n",
      "\n",
      "Fold: 17  Epoch: 143  Training loss = 3.8917  Validation loss = 3.0207  \n",
      "\n",
      "Fold: 17  Epoch: 144  Training loss = 3.8909  Validation loss = 3.0206  \n",
      "\n",
      "Fold: 17  Epoch: 145  Training loss = 3.8900  Validation loss = 3.0204  \n",
      "\n",
      "Fold: 17  Epoch: 146  Training loss = 3.8894  Validation loss = 3.0204  \n",
      "\n",
      "Fold: 17  Epoch: 147  Training loss = 3.8887  Validation loss = 3.0203  \n",
      "\n",
      "Fold: 17  Epoch: 148  Training loss = 3.8880  Validation loss = 3.0202  \n",
      "\n",
      "Fold: 17  Epoch: 149  Training loss = 3.8870  Validation loss = 3.0200  \n",
      "\n",
      "Fold: 17  Epoch: 150  Training loss = 3.8861  Validation loss = 3.0198  \n",
      "\n",
      "Fold: 17  Epoch: 151  Training loss = 3.8852  Validation loss = 3.0196  \n",
      "\n",
      "Fold: 17  Epoch: 152  Training loss = 3.8844  Validation loss = 3.0195  \n",
      "\n",
      "Fold: 17  Epoch: 153  Training loss = 3.8835  Validation loss = 3.0191  \n",
      "\n",
      "Fold: 17  Epoch: 154  Training loss = 3.8826  Validation loss = 3.0188  \n",
      "\n",
      "Fold: 17  Epoch: 155  Training loss = 3.8818  Validation loss = 3.0185  \n",
      "\n",
      "Fold: 17  Epoch: 156  Training loss = 3.8812  Validation loss = 3.0184  \n",
      "\n",
      "Fold: 17  Epoch: 157  Training loss = 3.8804  Validation loss = 3.0184  \n",
      "\n",
      "Fold: 17  Epoch: 158  Training loss = 3.8796  Validation loss = 3.0180  \n",
      "\n",
      "Fold: 17  Epoch: 159  Training loss = 3.8789  Validation loss = 3.0178  \n",
      "\n",
      "Fold: 17  Epoch: 160  Training loss = 3.8781  Validation loss = 3.0175  \n",
      "\n",
      "Fold: 17  Epoch: 161  Training loss = 3.8773  Validation loss = 3.0173  \n",
      "\n",
      "Fold: 17  Epoch: 162  Training loss = 3.8766  Validation loss = 3.0173  \n",
      "\n",
      "Fold: 17  Epoch: 163  Training loss = 3.8758  Validation loss = 3.0168  \n",
      "\n",
      "Fold: 17  Epoch: 164  Training loss = 3.8752  Validation loss = 3.0166  \n",
      "\n",
      "Fold: 17  Epoch: 165  Training loss = 3.8744  Validation loss = 3.0165  \n",
      "\n",
      "Fold: 17  Epoch: 166  Training loss = 3.8735  Validation loss = 3.0163  \n",
      "\n",
      "Fold: 17  Epoch: 167  Training loss = 3.8728  Validation loss = 3.0161  \n",
      "\n",
      "Fold: 17  Epoch: 168  Training loss = 3.8721  Validation loss = 3.0161  \n",
      "\n",
      "Fold: 17  Epoch: 169  Training loss = 3.8714  Validation loss = 3.0160  \n",
      "\n",
      "Fold: 17  Epoch: 170  Training loss = 3.8707  Validation loss = 3.0157  \n",
      "\n",
      "Fold: 17  Epoch: 171  Training loss = 3.8700  Validation loss = 3.0156  \n",
      "\n",
      "Fold: 17  Epoch: 172  Training loss = 3.8693  Validation loss = 3.0153  \n",
      "\n",
      "Fold: 17  Epoch: 173  Training loss = 3.8685  Validation loss = 3.0153  \n",
      "\n",
      "Fold: 17  Epoch: 174  Training loss = 3.8679  Validation loss = 3.0152  \n",
      "\n",
      "Fold: 17  Epoch: 175  Training loss = 3.8671  Validation loss = 3.0151  \n",
      "\n",
      "Fold: 17  Epoch: 176  Training loss = 3.8660  Validation loss = 3.0149  \n",
      "\n",
      "Fold: 17  Epoch: 177  Training loss = 3.8653  Validation loss = 3.0147  \n",
      "\n",
      "Fold: 17  Epoch: 178  Training loss = 3.8647  Validation loss = 3.0146  \n",
      "\n",
      "Fold: 17  Epoch: 179  Training loss = 3.8640  Validation loss = 3.0146  \n",
      "\n",
      "Fold: 17  Epoch: 180  Training loss = 3.8632  Validation loss = 3.0145  \n",
      "\n",
      "Fold: 17  Epoch: 181  Training loss = 3.8624  Validation loss = 3.0143  \n",
      "\n",
      "Fold: 17  Epoch: 182  Training loss = 3.8615  Validation loss = 3.0143  \n",
      "\n",
      "Fold: 17  Epoch: 183  Training loss = 3.8607  Validation loss = 3.0142  \n",
      "\n",
      "Fold: 17  Epoch: 184  Training loss = 3.8601  Validation loss = 3.0141  \n",
      "\n",
      "Fold: 17  Epoch: 185  Training loss = 3.8594  Validation loss = 3.0137  \n",
      "\n",
      "Fold: 17  Epoch: 186  Training loss = 3.8587  Validation loss = 3.0134  \n",
      "\n",
      "Fold: 17  Epoch: 187  Training loss = 3.8580  Validation loss = 3.0134  \n",
      "\n",
      "Fold: 17  Epoch: 188  Training loss = 3.8573  Validation loss = 3.0130  \n",
      "\n",
      "Fold: 17  Epoch: 189  Training loss = 3.8565  Validation loss = 3.0130  \n",
      "\n",
      "Fold: 17  Epoch: 190  Training loss = 3.8557  Validation loss = 3.0129  \n",
      "\n",
      "Fold: 17  Epoch: 191  Training loss = 3.8550  Validation loss = 3.0126  \n",
      "\n",
      "Fold: 17  Epoch: 192  Training loss = 3.8543  Validation loss = 3.0124  \n",
      "\n",
      "Fold: 17  Epoch: 193  Training loss = 3.8534  Validation loss = 3.0121  \n",
      "\n",
      "Fold: 17  Epoch: 194  Training loss = 3.8526  Validation loss = 3.0119  \n",
      "\n",
      "Fold: 17  Epoch: 195  Training loss = 3.8518  Validation loss = 3.0117  \n",
      "\n",
      "Fold: 17  Epoch: 196  Training loss = 3.8510  Validation loss = 3.0115  \n",
      "\n",
      "Fold: 17  Epoch: 197  Training loss = 3.8501  Validation loss = 3.0113  \n",
      "\n",
      "Fold: 17  Epoch: 198  Training loss = 3.8491  Validation loss = 3.0112  \n",
      "\n",
      "Fold: 17  Epoch: 199  Training loss = 3.8484  Validation loss = 3.0111  \n",
      "\n",
      "Fold: 17  Epoch: 200  Training loss = 3.8476  Validation loss = 3.0111  \n",
      "\n",
      "Fold: 17  Epoch: 201  Training loss = 3.8468  Validation loss = 3.0111  \n",
      "\n",
      "Fold: 17  Epoch: 202  Training loss = 3.8458  Validation loss = 3.0109  \n",
      "\n",
      "Fold: 17  Epoch: 203  Training loss = 3.8448  Validation loss = 3.0110  \n",
      "\n",
      "Fold: 17  Epoch: 204  Training loss = 3.8435  Validation loss = 3.0109  \n",
      "\n",
      "Fold: 17  Epoch: 205  Training loss = 3.8424  Validation loss = 3.0107  \n",
      "\n",
      "Fold: 17  Epoch: 206  Training loss = 3.8390  Validation loss = 3.0107  \n",
      "\n",
      "Fold: 17  Epoch: 207  Training loss = 3.8379  Validation loss = 3.0106  \n",
      "\n",
      "Fold: 17  Epoch: 208  Training loss = 3.8367  Validation loss = 3.0103  \n",
      "\n",
      "Fold: 17  Epoch: 209  Training loss = 3.8358  Validation loss = 3.0100  \n",
      "\n",
      "Fold: 17  Epoch: 210  Training loss = 3.8355  Validation loss = 3.0098  \n",
      "\n",
      "Fold: 17  Epoch: 211  Training loss = 3.8347  Validation loss = 3.0095  \n",
      "\n",
      "Fold: 17  Epoch: 212  Training loss = 3.8340  Validation loss = 3.0094  \n",
      "\n",
      "Fold: 17  Epoch: 213  Training loss = 3.8331  Validation loss = 3.0094  \n",
      "\n",
      "Fold: 17  Epoch: 214  Training loss = 3.8325  Validation loss = 3.0093  \n",
      "\n",
      "Fold: 17  Epoch: 215  Training loss = 3.8319  Validation loss = 3.0091  \n",
      "\n",
      "Fold: 17  Epoch: 216  Training loss = 3.8310  Validation loss = 3.0089  \n",
      "\n",
      "Fold: 17  Epoch: 217  Training loss = 3.8305  Validation loss = 3.0089  \n",
      "\n",
      "Fold: 17  Epoch: 218  Training loss = 3.8298  Validation loss = 3.0088  \n",
      "\n",
      "Fold: 17  Epoch: 219  Training loss = 3.8294  Validation loss = 3.0087  \n",
      "\n",
      "Fold: 17  Epoch: 220  Training loss = 3.8288  Validation loss = 3.0084  \n",
      "\n",
      "Fold: 17  Epoch: 221  Training loss = 3.8281  Validation loss = 3.0083  \n",
      "\n",
      "Fold: 17  Epoch: 222  Training loss = 3.8274  Validation loss = 3.0082  \n",
      "\n",
      "Fold: 17  Epoch: 223  Training loss = 3.8265  Validation loss = 3.0080  \n",
      "\n",
      "Fold: 17  Epoch: 224  Training loss = 3.8260  Validation loss = 3.0079  \n",
      "\n",
      "Fold: 17  Epoch: 225  Training loss = 3.8254  Validation loss = 3.0079  \n",
      "\n",
      "Fold: 17  Epoch: 226  Training loss = 3.8247  Validation loss = 3.0077  \n",
      "\n",
      "Fold: 17  Epoch: 227  Training loss = 3.8242  Validation loss = 3.0075  \n",
      "\n",
      "Fold: 17  Epoch: 228  Training loss = 3.8234  Validation loss = 3.0072  \n",
      "\n",
      "Fold: 17  Epoch: 229  Training loss = 3.8227  Validation loss = 3.0071  \n",
      "\n",
      "Fold: 17  Epoch: 230  Training loss = 3.8222  Validation loss = 3.0069  \n",
      "\n",
      "Fold: 17  Epoch: 231  Training loss = 3.8214  Validation loss = 3.0068  \n",
      "\n",
      "Fold: 17  Epoch: 232  Training loss = 3.8206  Validation loss = 3.0067  \n",
      "\n",
      "Fold: 17  Epoch: 233  Training loss = 3.8198  Validation loss = 3.0066  \n",
      "\n",
      "Fold: 17  Epoch: 234  Training loss = 3.8191  Validation loss = 3.0065  \n",
      "\n",
      "Fold: 17  Epoch: 235  Training loss = 3.8182  Validation loss = 3.0063  \n",
      "\n",
      "Fold: 17  Epoch: 236  Training loss = 3.8175  Validation loss = 3.0062  \n",
      "\n",
      "Fold: 17  Epoch: 237  Training loss = 3.8167  Validation loss = 3.0059  \n",
      "\n",
      "Fold: 17  Epoch: 238  Training loss = 3.8158  Validation loss = 3.0059  \n",
      "\n",
      "Fold: 17  Epoch: 239  Training loss = 3.8149  Validation loss = 3.0058  \n",
      "\n",
      "Fold: 17  Epoch: 240  Training loss = 3.8144  Validation loss = 3.0056  \n",
      "\n",
      "Fold: 17  Epoch: 241  Training loss = 3.8138  Validation loss = 3.0055  \n",
      "\n",
      "Fold: 17  Epoch: 242  Training loss = 3.8132  Validation loss = 3.0055  \n",
      "\n",
      "Fold: 17  Epoch: 243  Training loss = 3.8124  Validation loss = 3.0051  \n",
      "\n",
      "Fold: 17  Epoch: 244  Training loss = 3.8119  Validation loss = 3.0049  \n",
      "\n",
      "Fold: 17  Epoch: 245  Training loss = 3.8114  Validation loss = 3.0049  \n",
      "\n",
      "Fold: 17  Epoch: 246  Training loss = 3.8106  Validation loss = 3.0048  \n",
      "\n",
      "Fold: 17  Epoch: 247  Training loss = 3.8101  Validation loss = 3.0046  \n",
      "\n",
      "Fold: 17  Epoch: 248  Training loss = 3.8093  Validation loss = 3.0045  \n",
      "\n",
      "Fold: 17  Epoch: 249  Training loss = 3.8088  Validation loss = 3.0042  \n",
      "\n",
      "Fold: 17  Epoch: 250  Training loss = 3.8083  Validation loss = 3.0041  \n",
      "\n",
      "Fold: 17  Epoch: 251  Training loss = 3.8077  Validation loss = 3.0040  \n",
      "\n",
      "Fold: 17  Epoch: 252  Training loss = 3.8070  Validation loss = 3.0038  \n",
      "\n",
      "Fold: 17  Epoch: 253  Training loss = 3.8065  Validation loss = 3.0036  \n",
      "\n",
      "Fold: 17  Epoch: 254  Training loss = 3.8060  Validation loss = 3.0033  \n",
      "\n",
      "Fold: 17  Epoch: 255  Training loss = 3.8053  Validation loss = 3.0031  \n",
      "\n",
      "Fold: 17  Epoch: 256  Training loss = 3.8048  Validation loss = 3.0029  \n",
      "\n",
      "Fold: 17  Epoch: 257  Training loss = 3.8042  Validation loss = 3.0027  \n",
      "\n",
      "Fold: 17  Epoch: 258  Training loss = 3.8035  Validation loss = 3.0025  \n",
      "\n",
      "Fold: 17  Epoch: 259  Training loss = 3.8027  Validation loss = 3.0024  \n",
      "\n",
      "Fold: 17  Epoch: 260  Training loss = 3.8021  Validation loss = 3.0024  \n",
      "\n",
      "Fold: 17  Epoch: 261  Training loss = 3.8013  Validation loss = 3.0022  \n",
      "\n",
      "Fold: 17  Epoch: 262  Training loss = 3.8005  Validation loss = 3.0020  \n",
      "\n",
      "Fold: 17  Epoch: 263  Training loss = 3.7997  Validation loss = 3.0019  \n",
      "\n",
      "Fold: 17  Epoch: 264  Training loss = 3.7989  Validation loss = 3.0016  \n",
      "\n",
      "Fold: 17  Epoch: 265  Training loss = 3.7981  Validation loss = 3.0015  \n",
      "\n",
      "Fold: 17  Epoch: 266  Training loss = 3.7976  Validation loss = 3.0014  \n",
      "\n",
      "Fold: 17  Epoch: 267  Training loss = 3.7964  Validation loss = 3.0013  \n",
      "\n",
      "Fold: 17  Epoch: 268  Training loss = 3.7956  Validation loss = 3.0010  \n",
      "\n",
      "Fold: 17  Epoch: 269  Training loss = 3.7950  Validation loss = 3.0008  \n",
      "\n",
      "Fold: 17  Epoch: 270  Training loss = 3.7943  Validation loss = 3.0007  \n",
      "\n",
      "Fold: 17  Epoch: 271  Training loss = 3.7936  Validation loss = 3.0005  \n",
      "\n",
      "Fold: 17  Epoch: 272  Training loss = 3.7927  Validation loss = 3.0004  \n",
      "\n",
      "Fold: 17  Epoch: 273  Training loss = 3.7923  Validation loss = 3.0004  \n",
      "\n",
      "Fold: 17  Epoch: 274  Training loss = 3.7916  Validation loss = 3.0003  \n",
      "\n",
      "Fold: 17  Epoch: 275  Training loss = 3.7910  Validation loss = 3.0003  \n",
      "\n",
      "Fold: 17  Epoch: 276  Training loss = 3.7906  Validation loss = 3.0003  \n",
      "\n",
      "Fold: 17  Epoch: 277  Training loss = 3.7902  Validation loss = 3.0001  \n",
      "\n",
      "Fold: 17  Epoch: 278  Training loss = 3.7895  Validation loss = 2.9999  \n",
      "\n",
      "Fold: 17  Epoch: 279  Training loss = 3.7889  Validation loss = 2.9999  \n",
      "\n",
      "Fold: 17  Epoch: 280  Training loss = 3.7881  Validation loss = 2.9997  \n",
      "\n",
      "Fold: 17  Epoch: 281  Training loss = 3.7872  Validation loss = 2.9997  \n",
      "\n",
      "Fold: 17  Epoch: 282  Training loss = 3.7867  Validation loss = 2.9996  \n",
      "\n",
      "Fold: 17  Epoch: 283  Training loss = 3.7859  Validation loss = 2.9995  \n",
      "\n",
      "Fold: 17  Epoch: 284  Training loss = 3.7855  Validation loss = 2.9995  \n",
      "\n",
      "Fold: 17  Epoch: 285  Training loss = 3.7850  Validation loss = 2.9994  \n",
      "\n",
      "Fold: 17  Epoch: 286  Training loss = 3.7842  Validation loss = 2.9991  \n",
      "\n",
      "Fold: 17  Epoch: 287  Training loss = 3.7835  Validation loss = 2.9989  \n",
      "\n",
      "Fold: 17  Epoch: 288  Training loss = 3.7826  Validation loss = 2.9988  \n",
      "\n",
      "Fold: 17  Epoch: 289  Training loss = 3.7819  Validation loss = 2.9986  \n",
      "\n",
      "Fold: 17  Epoch: 290  Training loss = 3.7813  Validation loss = 2.9986  \n",
      "\n",
      "Fold: 17  Epoch: 291  Training loss = 3.7805  Validation loss = 2.9986  \n",
      "\n",
      "Fold: 17  Epoch: 292  Training loss = 3.7799  Validation loss = 2.9985  \n",
      "\n",
      "Fold: 17  Epoch: 293  Training loss = 3.7792  Validation loss = 2.9983  \n",
      "\n",
      "Fold: 17  Epoch: 294  Training loss = 3.7786  Validation loss = 2.9981  \n",
      "\n",
      "Fold: 17  Epoch: 295  Training loss = 3.7777  Validation loss = 2.9981  \n",
      "\n",
      "Fold: 17  Epoch: 296  Training loss = 3.7772  Validation loss = 2.9980  \n",
      "\n",
      "Fold: 17  Epoch: 297  Training loss = 3.7765  Validation loss = 2.9979  \n",
      "\n",
      "Fold: 17  Epoch: 298  Training loss = 3.7755  Validation loss = 2.9977  \n",
      "\n",
      "Fold: 17  Epoch: 299  Training loss = 3.7749  Validation loss = 2.9977  \n",
      "\n",
      "Fold: 17  Epoch: 300  Training loss = 3.7742  Validation loss = 2.9976  \n",
      "\n",
      "Fold: 17  Epoch: 301  Training loss = 3.7736  Validation loss = 2.9975  \n",
      "\n",
      "Fold: 17  Epoch: 302  Training loss = 3.7728  Validation loss = 2.9972  \n",
      "\n",
      "Fold: 17  Epoch: 303  Training loss = 3.7723  Validation loss = 2.9970  \n",
      "\n",
      "Fold: 17  Epoch: 304  Training loss = 3.7718  Validation loss = 2.9971  \n",
      "\n",
      "Fold: 17  Epoch: 305  Training loss = 3.7712  Validation loss = 2.9970  \n",
      "\n",
      "Fold: 17  Epoch: 306  Training loss = 3.7704  Validation loss = 2.9968  \n",
      "\n",
      "Fold: 17  Epoch: 307  Training loss = 3.7697  Validation loss = 2.9967  \n",
      "\n",
      "Fold: 17  Epoch: 308  Training loss = 3.7689  Validation loss = 2.9967  \n",
      "\n",
      "Fold: 17  Epoch: 309  Training loss = 3.7683  Validation loss = 2.9967  \n",
      "\n",
      "Fold: 17  Epoch: 310  Training loss = 3.7678  Validation loss = 2.9966  \n",
      "\n",
      "Fold: 17  Epoch: 311  Training loss = 3.7671  Validation loss = 2.9964  \n",
      "\n",
      "Fold: 17  Epoch: 312  Training loss = 3.7666  Validation loss = 2.9961  \n",
      "\n",
      "Fold: 17  Epoch: 313  Training loss = 3.7661  Validation loss = 2.9960  \n",
      "\n",
      "Fold: 17  Epoch: 314  Training loss = 3.7654  Validation loss = 2.9960  \n",
      "\n",
      "Fold: 17  Epoch: 315  Training loss = 3.7648  Validation loss = 2.9960  \n",
      "\n",
      "Fold: 17  Epoch: 316  Training loss = 3.7641  Validation loss = 2.9960  \n",
      "\n",
      "Fold: 17  Epoch: 317  Training loss = 3.7633  Validation loss = 2.9960  \n",
      "\n",
      "Fold: 17  Epoch: 318  Training loss = 3.7625  Validation loss = 2.9957  \n",
      "\n",
      "Fold: 17  Epoch: 319  Training loss = 3.7620  Validation loss = 2.9956  \n",
      "\n",
      "Fold: 17  Epoch: 320  Training loss = 3.7615  Validation loss = 2.9956  \n",
      "\n",
      "Fold: 17  Epoch: 321  Training loss = 3.7607  Validation loss = 2.9955  \n",
      "\n",
      "Fold: 17  Epoch: 322  Training loss = 3.7601  Validation loss = 2.9954  \n",
      "\n",
      "Fold: 17  Epoch: 323  Training loss = 3.7596  Validation loss = 2.9954  \n",
      "\n",
      "Fold: 17  Epoch: 324  Training loss = 3.7589  Validation loss = 2.9953  \n",
      "\n",
      "Fold: 17  Epoch: 325  Training loss = 3.7582  Validation loss = 2.9952  \n",
      "\n",
      "Fold: 17  Epoch: 326  Training loss = 3.7574  Validation loss = 2.9949  \n",
      "\n",
      "Fold: 17  Epoch: 327  Training loss = 3.7565  Validation loss = 2.9950  \n",
      "\n",
      "Fold: 17  Epoch: 328  Training loss = 3.7559  Validation loss = 2.9949  \n",
      "\n",
      "Fold: 17  Epoch: 329  Training loss = 3.7552  Validation loss = 2.9946  \n",
      "\n",
      "Fold: 17  Epoch: 330  Training loss = 3.7544  Validation loss = 2.9944  \n",
      "\n",
      "Fold: 17  Epoch: 331  Training loss = 3.7537  Validation loss = 2.9944  \n",
      "\n",
      "Fold: 17  Epoch: 332  Training loss = 3.7529  Validation loss = 2.9944  \n",
      "\n",
      "Fold: 17  Epoch: 333  Training loss = 3.7523  Validation loss = 2.9943  \n",
      "\n",
      "Fold: 17  Epoch: 334  Training loss = 3.7518  Validation loss = 2.9942  \n",
      "\n",
      "Fold: 17  Epoch: 335  Training loss = 3.7511  Validation loss = 2.9939  \n",
      "\n",
      "Fold: 17  Epoch: 336  Training loss = 3.7502  Validation loss = 2.9937  \n",
      "\n",
      "Fold: 17  Epoch: 337  Training loss = 3.7496  Validation loss = 2.9936  \n",
      "\n",
      "Fold: 17  Epoch: 338  Training loss = 3.7492  Validation loss = 2.9933  \n",
      "\n",
      "Fold: 17  Epoch: 339  Training loss = 3.7485  Validation loss = 2.9933  \n",
      "\n",
      "Fold: 17  Epoch: 340  Training loss = 3.7477  Validation loss = 2.9933  \n",
      "\n",
      "Fold: 17  Epoch: 341  Training loss = 3.7473  Validation loss = 2.9932  \n",
      "\n",
      "Fold: 17  Epoch: 342  Training loss = 3.7466  Validation loss = 2.9931  \n",
      "\n",
      "Fold: 17  Epoch: 343  Training loss = 3.7461  Validation loss = 2.9930  \n",
      "\n",
      "Fold: 17  Epoch: 344  Training loss = 3.7454  Validation loss = 2.9929  \n",
      "\n",
      "Fold: 17  Epoch: 345  Training loss = 3.7447  Validation loss = 2.9929  \n",
      "\n",
      "Fold: 17  Epoch: 346  Training loss = 3.7442  Validation loss = 2.9927  \n",
      "\n",
      "Fold: 17  Epoch: 347  Training loss = 3.7434  Validation loss = 2.9928  \n",
      "\n",
      "Fold: 17  Epoch: 348  Training loss = 3.7427  Validation loss = 2.9927  \n",
      "\n",
      "Fold: 17  Epoch: 349  Training loss = 3.7418  Validation loss = 2.9926  \n",
      "\n",
      "Fold: 17  Epoch: 350  Training loss = 3.7413  Validation loss = 2.9926  \n",
      "\n",
      "Fold: 17  Epoch: 351  Training loss = 3.7406  Validation loss = 2.9925  \n",
      "\n",
      "Fold: 17  Epoch: 352  Training loss = 3.7400  Validation loss = 2.9924  \n",
      "\n",
      "Fold: 17  Epoch: 353  Training loss = 3.7389  Validation loss = 2.9923  \n",
      "\n",
      "Fold: 17  Epoch: 354  Training loss = 3.7382  Validation loss = 2.9923  \n",
      "\n",
      "Fold: 17  Epoch: 355  Training loss = 3.7375  Validation loss = 2.9923  \n",
      "\n",
      "Fold: 17  Epoch: 356  Training loss = 3.7368  Validation loss = 2.9922  \n",
      "\n",
      "Fold: 17  Epoch: 357  Training loss = 3.7362  Validation loss = 2.9921  \n",
      "\n",
      "Fold: 17  Epoch: 358  Training loss = 3.7356  Validation loss = 2.9921  \n",
      "\n",
      "Fold: 17  Epoch: 359  Training loss = 3.7349  Validation loss = 2.9920  \n",
      "\n",
      "Fold: 17  Epoch: 360  Training loss = 3.7341  Validation loss = 2.9918  \n",
      "\n",
      "Fold: 17  Epoch: 361  Training loss = 3.7334  Validation loss = 2.9916  \n",
      "\n",
      "Fold: 17  Epoch: 362  Training loss = 3.7327  Validation loss = 2.9916  \n",
      "\n",
      "Fold: 17  Epoch: 363  Training loss = 3.7319  Validation loss = 2.9917  \n",
      "\n",
      "Fold: 17  Epoch: 364  Training loss = 3.7315  Validation loss = 2.9915  \n",
      "\n",
      "Fold: 17  Epoch: 365  Training loss = 3.7308  Validation loss = 2.9915  \n",
      "\n",
      "Fold: 17  Epoch: 366  Training loss = 3.7301  Validation loss = 2.9915  \n",
      "\n",
      "Fold: 17  Epoch: 367  Training loss = 3.7292  Validation loss = 2.9914  \n",
      "\n",
      "Fold: 17  Epoch: 368  Training loss = 3.7286  Validation loss = 2.9914  \n",
      "\n",
      "Fold: 17  Epoch: 369  Training loss = 3.7279  Validation loss = 2.9915  \n",
      "\n",
      "Fold: 17  Epoch: 370  Training loss = 3.7273  Validation loss = 2.9913  \n",
      "\n",
      "Fold: 17  Epoch: 371  Training loss = 3.7266  Validation loss = 2.9912  \n",
      "\n",
      "Fold: 17  Epoch: 372  Training loss = 3.7260  Validation loss = 2.9912  \n",
      "\n",
      "Fold: 17  Epoch: 373  Training loss = 3.7255  Validation loss = 2.9911  \n",
      "\n",
      "Fold: 17  Epoch: 374  Training loss = 3.7250  Validation loss = 2.9911  \n",
      "\n",
      "Fold: 17  Epoch: 375  Training loss = 3.7246  Validation loss = 2.9911  \n",
      "\n",
      "Fold: 17  Epoch: 376  Training loss = 3.7240  Validation loss = 2.9911  \n",
      "\n",
      "Fold: 17  Epoch: 377  Training loss = 3.7232  Validation loss = 2.9910  \n",
      "\n",
      "Fold: 17  Epoch: 378  Training loss = 3.7225  Validation loss = 2.9908  \n",
      "\n",
      "Fold: 17  Epoch: 379  Training loss = 3.7219  Validation loss = 2.9907  \n",
      "\n",
      "Fold: 17  Epoch: 380  Training loss = 3.7214  Validation loss = 2.9906  \n",
      "\n",
      "Fold: 17  Epoch: 381  Training loss = 3.7210  Validation loss = 2.9905  \n",
      "\n",
      "Fold: 17  Epoch: 382  Training loss = 3.7203  Validation loss = 2.9905  \n",
      "\n",
      "Fold: 17  Epoch: 383  Training loss = 3.7198  Validation loss = 2.9904  \n",
      "\n",
      "Fold: 17  Epoch: 384  Training loss = 3.7191  Validation loss = 2.9903  \n",
      "\n",
      "Fold: 17  Epoch: 385  Training loss = 3.7187  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 17  Epoch: 386  Training loss = 3.7181  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 17  Epoch: 387  Training loss = 3.7176  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 17  Epoch: 388  Training loss = 3.7168  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 17  Epoch: 389  Training loss = 3.7162  Validation loss = 2.9903  \n",
      "\n",
      "Fold: 17  Epoch: 390  Training loss = 3.7155  Validation loss = 2.9903  \n",
      "\n",
      "Fold: 17  Epoch: 391  Training loss = 3.7147  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 17  Epoch: 392  Training loss = 3.7143  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 17  Epoch: 393  Training loss = 3.7136  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 17  Epoch: 394  Training loss = 3.7129  Validation loss = 2.9901  \n",
      "\n",
      "Fold: 17  Epoch: 395  Training loss = 3.7121  Validation loss = 2.9901  \n",
      "\n",
      "Fold: 17  Epoch: 396  Training loss = 3.7113  Validation loss = 2.9899  \n",
      "\n",
      "Fold: 17  Epoch: 397  Training loss = 3.7106  Validation loss = 2.9898  \n",
      "\n",
      "Fold: 17  Epoch: 398  Training loss = 3.7101  Validation loss = 2.9897  \n",
      "\n",
      "Fold: 17  Epoch: 399  Training loss = 3.7094  Validation loss = 2.9893  \n",
      "\n",
      "Fold: 17  Epoch: 400  Training loss = 3.7089  Validation loss = 2.9892  \n",
      "\n",
      "Fold: 17  Epoch: 401  Training loss = 3.7083  Validation loss = 2.9891  \n",
      "\n",
      "Fold: 17  Epoch: 402  Training loss = 3.7078  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 17  Epoch: 403  Training loss = 3.7073  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 17  Epoch: 404  Training loss = 3.7070  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 17  Epoch: 405  Training loss = 3.7063  Validation loss = 2.9889  \n",
      "\n",
      "Fold: 17  Epoch: 406  Training loss = 3.7059  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 17  Epoch: 407  Training loss = 3.7053  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 17  Epoch: 408  Training loss = 3.7047  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 17  Epoch: 409  Training loss = 3.7040  Validation loss = 2.9887  \n",
      "\n",
      "Fold: 17  Epoch: 410  Training loss = 3.7030  Validation loss = 2.9889  \n",
      "\n",
      "Fold: 17  Epoch: 411  Training loss = 3.7024  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 17  Epoch: 412  Training loss = 3.7017  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 17  Epoch: 413  Training loss = 3.7012  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 17  Epoch: 414  Training loss = 3.7005  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 17  Epoch: 415  Training loss = 3.7000  Validation loss = 2.9888  \n",
      "\n",
      "Fold: 17  Epoch: 416  Training loss = 3.6991  Validation loss = 2.9889  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 409  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.7697  Validation loss = 0.9519  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 3.7692  Validation loss = 0.9522  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.7684  Validation loss = 0.9525  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.7678  Validation loss = 0.9529  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.7673  Validation loss = 0.9531  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.7665  Validation loss = 0.9535  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 3.7659  Validation loss = 0.9538  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 3.7654  Validation loss = 0.9541  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 3.7647  Validation loss = 0.9544  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 3.7640  Validation loss = 0.9547  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.7635  Validation loss = 0.9549  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 1  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 3.7366  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 3.7362  Validation loss = 2.6507  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 3.7356  Validation loss = 2.6509  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 3.7350  Validation loss = 2.6511  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 3.7343  Validation loss = 2.6513  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 3.7336  Validation loss = 2.6515  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 3.7330  Validation loss = 2.6517  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 3.7325  Validation loss = 2.6521  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 3.7320  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 3.7313  Validation loss = 2.6525  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 3.7307  Validation loss = 2.6528  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 1  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 3.7867  Validation loss = 1.2261  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 3.7861  Validation loss = 1.2259  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 3.7854  Validation loss = 1.2256  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 3.7847  Validation loss = 1.2254  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 3.7838  Validation loss = 1.2250  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 3.7830  Validation loss = 1.2247  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 3.7824  Validation loss = 1.2245  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 3.7817  Validation loss = 1.2242  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 3.7811  Validation loss = 1.2237  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 3.7804  Validation loss = 1.2234  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 3.7801  Validation loss = 1.2232  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 3.7795  Validation loss = 1.2229  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 3.7790  Validation loss = 1.2229  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 3.7784  Validation loss = 1.2226  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 3.7779  Validation loss = 1.2222  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 3.7774  Validation loss = 1.2221  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 3.7767  Validation loss = 1.2219  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 3.7761  Validation loss = 1.2217  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 3.7754  Validation loss = 1.2214  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 3.7750  Validation loss = 1.2209  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 3.7746  Validation loss = 1.2207  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 3.7741  Validation loss = 1.2203  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 3.7736  Validation loss = 1.2201  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 3.7730  Validation loss = 1.2198  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 3.7723  Validation loss = 1.2197  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 3.7715  Validation loss = 1.2193  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 3.7707  Validation loss = 1.2190  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 3.7702  Validation loss = 1.2189  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 3.7694  Validation loss = 1.2184  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 3.7688  Validation loss = 1.2181  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 3.7684  Validation loss = 1.2180  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 3.7677  Validation loss = 1.2175  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 3.7671  Validation loss = 1.2172  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 3.7664  Validation loss = 1.2170  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 3.7660  Validation loss = 1.2166  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 3.7655  Validation loss = 1.2163  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 3.7649  Validation loss = 1.2161  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 3.7645  Validation loss = 1.2160  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 3.7640  Validation loss = 1.2156  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 3.7633  Validation loss = 1.2151  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 3.7628  Validation loss = 1.2147  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 3.7622  Validation loss = 1.2146  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 3.7616  Validation loss = 1.2142  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 3.7611  Validation loss = 1.2141  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 3.7606  Validation loss = 1.2138  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 3.7599  Validation loss = 1.2137  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 3.7591  Validation loss = 1.2135  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 3.7585  Validation loss = 1.2133  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 3.7579  Validation loss = 1.2131  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 3.7573  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 3.7567  Validation loss = 1.2127  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 3.7560  Validation loss = 1.2124  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 3.7554  Validation loss = 1.2123  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 3.7548  Validation loss = 1.2121  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 3.7541  Validation loss = 1.2119  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 3.7535  Validation loss = 1.2117  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 3.7530  Validation loss = 1.2115  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 3.7525  Validation loss = 1.2114  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 3.7518  Validation loss = 1.2112  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 3.7514  Validation loss = 1.2109  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 3.7508  Validation loss = 1.2106  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 3.7501  Validation loss = 1.2105  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 3.7493  Validation loss = 1.2100  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 3.7489  Validation loss = 1.2099  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 3.7483  Validation loss = 1.2094  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 3.7476  Validation loss = 1.2091  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 3.7471  Validation loss = 1.2088  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 3.7466  Validation loss = 1.2083  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 3.7460  Validation loss = 1.2081  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 3.7455  Validation loss = 1.2081  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 3.7450  Validation loss = 1.2079  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 3.7445  Validation loss = 1.2076  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 3.7440  Validation loss = 1.2073  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 3.7435  Validation loss = 1.2071  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 3.7430  Validation loss = 1.2068  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 3.7425  Validation loss = 1.2064  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 3.7417  Validation loss = 1.2061  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 3.7412  Validation loss = 1.2058  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 3.7406  Validation loss = 1.2057  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 3.7399  Validation loss = 1.2053  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 3.7392  Validation loss = 1.2048  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 3.7385  Validation loss = 1.2047  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 3.7381  Validation loss = 1.2045  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 3.7375  Validation loss = 1.2041  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 3.7370  Validation loss = 1.2040  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 3.7365  Validation loss = 1.2037  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 3.7358  Validation loss = 1.2036  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 3.7353  Validation loss = 1.2036  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 3.7349  Validation loss = 1.2035  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 3.7345  Validation loss = 1.2034  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 3.7338  Validation loss = 1.2031  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 3.7335  Validation loss = 1.2030  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 3.7329  Validation loss = 1.2028  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 3.7324  Validation loss = 1.2027  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 3.7317  Validation loss = 1.2024  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 3.7310  Validation loss = 1.2023  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 3.7306  Validation loss = 1.2020  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 3.7299  Validation loss = 1.2018  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 3.7295  Validation loss = 1.2016  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 3.7288  Validation loss = 1.2014  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 3.7284  Validation loss = 1.2012  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 3.7278  Validation loss = 1.2010  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 3.7273  Validation loss = 1.2008  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 3.7267  Validation loss = 1.2007  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 3.7261  Validation loss = 1.2004  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 3.7254  Validation loss = 1.1997  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 3.7246  Validation loss = 1.1996  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 3.7239  Validation loss = 1.1993  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 3.7233  Validation loss = 1.1991  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 3.7228  Validation loss = 1.1988  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 3.7223  Validation loss = 1.1986  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 3.7216  Validation loss = 1.1984  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 3.7208  Validation loss = 1.1981  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 3.7204  Validation loss = 1.1980  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 3.7198  Validation loss = 1.1977  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 3.7193  Validation loss = 1.1976  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 3.7189  Validation loss = 1.1974  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 3.7182  Validation loss = 1.1971  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 3.7175  Validation loss = 1.1969  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 3.7170  Validation loss = 1.1967  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 3.7164  Validation loss = 1.1965  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 3.7157  Validation loss = 1.1962  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 3.7152  Validation loss = 1.1959  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 3.7145  Validation loss = 1.1960  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 3.7141  Validation loss = 1.1957  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 3.7137  Validation loss = 1.1955  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 3.7133  Validation loss = 1.1953  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 3.7127  Validation loss = 1.1950  \n",
      "\n",
      "Fold: 20  Epoch: 129  Training loss = 3.7120  Validation loss = 1.1947  \n",
      "\n",
      "Fold: 20  Epoch: 130  Training loss = 3.7113  Validation loss = 1.1944  \n",
      "\n",
      "Fold: 20  Epoch: 131  Training loss = 3.7107  Validation loss = 1.1941  \n",
      "\n",
      "Fold: 20  Epoch: 132  Training loss = 3.7101  Validation loss = 1.1938  \n",
      "\n",
      "Fold: 20  Epoch: 133  Training loss = 3.7095  Validation loss = 1.1936  \n",
      "\n",
      "Fold: 20  Epoch: 134  Training loss = 3.7090  Validation loss = 1.1934  \n",
      "\n",
      "Fold: 20  Epoch: 135  Training loss = 3.7084  Validation loss = 1.1932  \n",
      "\n",
      "Fold: 20  Epoch: 136  Training loss = 3.7079  Validation loss = 1.1929  \n",
      "\n",
      "Fold: 20  Epoch: 137  Training loss = 3.7074  Validation loss = 1.1928  \n",
      "\n",
      "Fold: 20  Epoch: 138  Training loss = 3.7067  Validation loss = 1.1925  \n",
      "\n",
      "Fold: 20  Epoch: 139  Training loss = 3.7063  Validation loss = 1.1926  \n",
      "\n",
      "Fold: 20  Epoch: 140  Training loss = 3.7057  Validation loss = 1.1925  \n",
      "\n",
      "Fold: 20  Epoch: 141  Training loss = 3.7051  Validation loss = 1.1921  \n",
      "\n",
      "Fold: 20  Epoch: 142  Training loss = 3.7045  Validation loss = 1.1920  \n",
      "\n",
      "Fold: 20  Epoch: 143  Training loss = 3.7041  Validation loss = 1.1918  \n",
      "\n",
      "Fold: 20  Epoch: 144  Training loss = 3.7035  Validation loss = 1.1916  \n",
      "\n",
      "Fold: 20  Epoch: 145  Training loss = 3.7031  Validation loss = 1.1913  \n",
      "\n",
      "Fold: 20  Epoch: 146  Training loss = 3.7028  Validation loss = 1.1911  \n",
      "\n",
      "Fold: 20  Epoch: 147  Training loss = 3.7023  Validation loss = 1.1910  \n",
      "\n",
      "Fold: 20  Epoch: 148  Training loss = 3.7015  Validation loss = 1.1908  \n",
      "\n",
      "Fold: 20  Epoch: 149  Training loss = 3.7009  Validation loss = 1.1906  \n",
      "\n",
      "Fold: 20  Epoch: 150  Training loss = 3.7002  Validation loss = 1.1904  \n",
      "\n",
      "Fold: 20  Epoch: 151  Training loss = 3.6997  Validation loss = 1.1902  \n",
      "\n",
      "Fold: 20  Epoch: 152  Training loss = 3.6990  Validation loss = 1.1899  \n",
      "\n",
      "Fold: 20  Epoch: 153  Training loss = 3.6984  Validation loss = 1.1897  \n",
      "\n",
      "Fold: 20  Epoch: 154  Training loss = 3.6977  Validation loss = 1.1895  \n",
      "\n",
      "Fold: 20  Epoch: 155  Training loss = 3.6970  Validation loss = 1.1893  \n",
      "\n",
      "Fold: 20  Epoch: 156  Training loss = 3.6966  Validation loss = 1.1891  \n",
      "\n",
      "Fold: 20  Epoch: 157  Training loss = 3.6960  Validation loss = 1.1889  \n",
      "\n",
      "Fold: 20  Epoch: 158  Training loss = 3.6956  Validation loss = 1.1888  \n",
      "\n",
      "Fold: 20  Epoch: 159  Training loss = 3.6952  Validation loss = 1.1886  \n",
      "\n",
      "Fold: 20  Epoch: 160  Training loss = 3.6945  Validation loss = 1.1885  \n",
      "\n",
      "Fold: 20  Epoch: 161  Training loss = 3.6939  Validation loss = 1.1884  \n",
      "\n",
      "Fold: 20  Epoch: 162  Training loss = 3.6934  Validation loss = 1.1883  \n",
      "\n",
      "Fold: 20  Epoch: 163  Training loss = 3.6929  Validation loss = 1.1881  \n",
      "\n",
      "Fold: 20  Epoch: 164  Training loss = 3.6925  Validation loss = 1.1880  \n",
      "\n",
      "Fold: 20  Epoch: 165  Training loss = 3.6917  Validation loss = 1.1879  \n",
      "\n",
      "Fold: 20  Epoch: 166  Training loss = 3.6912  Validation loss = 1.1874  \n",
      "\n",
      "Fold: 20  Epoch: 167  Training loss = 3.6908  Validation loss = 1.1870  \n",
      "\n",
      "Fold: 20  Epoch: 168  Training loss = 3.6903  Validation loss = 1.1869  \n",
      "\n",
      "Fold: 20  Epoch: 169  Training loss = 3.6899  Validation loss = 1.1867  \n",
      "\n",
      "Fold: 20  Epoch: 170  Training loss = 3.6893  Validation loss = 1.1864  \n",
      "\n",
      "Fold: 20  Epoch: 171  Training loss = 3.6887  Validation loss = 1.1863  \n",
      "\n",
      "Fold: 20  Epoch: 172  Training loss = 3.6883  Validation loss = 1.1862  \n",
      "\n",
      "Fold: 20  Epoch: 173  Training loss = 3.6877  Validation loss = 1.1860  \n",
      "\n",
      "Fold: 20  Epoch: 174  Training loss = 3.6872  Validation loss = 1.1859  \n",
      "\n",
      "Fold: 20  Epoch: 175  Training loss = 3.6866  Validation loss = 1.1856  \n",
      "\n",
      "Fold: 20  Epoch: 176  Training loss = 3.6861  Validation loss = 1.1854  \n",
      "\n",
      "Fold: 20  Epoch: 177  Training loss = 3.6855  Validation loss = 1.1851  \n",
      "\n",
      "Fold: 20  Epoch: 178  Training loss = 3.6851  Validation loss = 1.1849  \n",
      "\n",
      "Fold: 20  Epoch: 179  Training loss = 3.6846  Validation loss = 1.1849  \n",
      "\n",
      "Fold: 20  Epoch: 180  Training loss = 3.6841  Validation loss = 1.1849  \n",
      "\n",
      "Fold: 20  Epoch: 181  Training loss = 3.6835  Validation loss = 1.1845  \n",
      "\n",
      "Fold: 20  Epoch: 182  Training loss = 3.6829  Validation loss = 1.1844  \n",
      "\n",
      "Fold: 20  Epoch: 183  Training loss = 3.6822  Validation loss = 1.1841  \n",
      "\n",
      "Fold: 20  Epoch: 184  Training loss = 3.6817  Validation loss = 1.1841  \n",
      "\n",
      "Fold: 20  Epoch: 185  Training loss = 3.6814  Validation loss = 1.1840  \n",
      "\n",
      "Fold: 20  Epoch: 186  Training loss = 3.6807  Validation loss = 1.1839  \n",
      "\n",
      "Fold: 20  Epoch: 187  Training loss = 3.6803  Validation loss = 1.1836  \n",
      "\n",
      "Fold: 20  Epoch: 188  Training loss = 3.6797  Validation loss = 1.1835  \n",
      "\n",
      "Fold: 20  Epoch: 189  Training loss = 3.6792  Validation loss = 1.1832  \n",
      "\n",
      "Fold: 20  Epoch: 190  Training loss = 3.6787  Validation loss = 1.1832  \n",
      "\n",
      "Fold: 20  Epoch: 191  Training loss = 3.6782  Validation loss = 1.1829  \n",
      "\n",
      "Fold: 20  Epoch: 192  Training loss = 3.6776  Validation loss = 1.1828  \n",
      "\n",
      "Fold: 20  Epoch: 193  Training loss = 3.6769  Validation loss = 1.1827  \n",
      "\n",
      "Fold: 20  Epoch: 194  Training loss = 3.6764  Validation loss = 1.1826  \n",
      "\n",
      "Fold: 20  Epoch: 195  Training loss = 3.6756  Validation loss = 1.1825  \n",
      "\n",
      "Fold: 20  Epoch: 196  Training loss = 3.6751  Validation loss = 1.1823  \n",
      "\n",
      "Fold: 20  Epoch: 197  Training loss = 3.6746  Validation loss = 1.1822  \n",
      "\n",
      "Fold: 20  Epoch: 198  Training loss = 3.6739  Validation loss = 1.1820  \n",
      "\n",
      "Fold: 20  Epoch: 199  Training loss = 3.6733  Validation loss = 1.1816  \n",
      "\n",
      "Fold: 20  Epoch: 200  Training loss = 3.6726  Validation loss = 1.1814  \n",
      "\n",
      "Fold: 20  Epoch: 201  Training loss = 3.6720  Validation loss = 1.1811  \n",
      "\n",
      "Fold: 20  Epoch: 202  Training loss = 3.6716  Validation loss = 1.1810  \n",
      "\n",
      "Fold: 20  Epoch: 203  Training loss = 3.6709  Validation loss = 1.1809  \n",
      "\n",
      "Fold: 20  Epoch: 204  Training loss = 3.6703  Validation loss = 1.1809  \n",
      "\n",
      "Fold: 20  Epoch: 205  Training loss = 3.6700  Validation loss = 1.1806  \n",
      "\n",
      "Fold: 20  Epoch: 206  Training loss = 3.6695  Validation loss = 1.1806  \n",
      "\n",
      "Fold: 20  Epoch: 207  Training loss = 3.6690  Validation loss = 1.1804  \n",
      "\n",
      "Fold: 20  Epoch: 208  Training loss = 3.6685  Validation loss = 1.1802  \n",
      "\n",
      "Fold: 20  Epoch: 209  Training loss = 3.6680  Validation loss = 1.1799  \n",
      "\n",
      "Fold: 20  Epoch: 210  Training loss = 3.6676  Validation loss = 1.1797  \n",
      "\n",
      "Fold: 20  Epoch: 211  Training loss = 3.6671  Validation loss = 1.1796  \n",
      "\n",
      "Fold: 20  Epoch: 212  Training loss = 3.6668  Validation loss = 1.1794  \n",
      "\n",
      "Fold: 20  Epoch: 213  Training loss = 3.6663  Validation loss = 1.1794  \n",
      "\n",
      "Fold: 20  Epoch: 214  Training loss = 3.6657  Validation loss = 1.1792  \n",
      "\n",
      "Fold: 20  Epoch: 215  Training loss = 3.6652  Validation loss = 1.1791  \n",
      "\n",
      "Fold: 20  Epoch: 216  Training loss = 3.6647  Validation loss = 1.1788  \n",
      "\n",
      "Fold: 20  Epoch: 217  Training loss = 3.6642  Validation loss = 1.1787  \n",
      "\n",
      "Fold: 20  Epoch: 218  Training loss = 3.6636  Validation loss = 1.1785  \n",
      "\n",
      "Fold: 20  Epoch: 219  Training loss = 3.6630  Validation loss = 1.1784  \n",
      "\n",
      "Fold: 20  Epoch: 220  Training loss = 3.6623  Validation loss = 1.1782  \n",
      "\n",
      "Fold: 20  Epoch: 221  Training loss = 3.6618  Validation loss = 1.1779  \n",
      "\n",
      "Fold: 20  Epoch: 222  Training loss = 3.6613  Validation loss = 1.1779  \n",
      "\n",
      "Fold: 20  Epoch: 223  Training loss = 3.6608  Validation loss = 1.1777  \n",
      "\n",
      "Fold: 20  Epoch: 224  Training loss = 3.6603  Validation loss = 1.1777  \n",
      "\n",
      "Fold: 20  Epoch: 225  Training loss = 3.6601  Validation loss = 1.1777  \n",
      "\n",
      "Fold: 20  Epoch: 226  Training loss = 3.6596  Validation loss = 1.1773  \n",
      "\n",
      "Fold: 20  Epoch: 227  Training loss = 3.6591  Validation loss = 1.1771  \n",
      "\n",
      "Fold: 20  Epoch: 228  Training loss = 3.6584  Validation loss = 1.1769  \n",
      "\n",
      "Fold: 20  Epoch: 229  Training loss = 3.6579  Validation loss = 1.1768  \n",
      "\n",
      "Fold: 20  Epoch: 230  Training loss = 3.6575  Validation loss = 1.1767  \n",
      "\n",
      "Fold: 20  Epoch: 231  Training loss = 3.6571  Validation loss = 1.1764  \n",
      "\n",
      "Fold: 20  Epoch: 232  Training loss = 3.6566  Validation loss = 1.1761  \n",
      "\n",
      "Fold: 20  Epoch: 233  Training loss = 3.6559  Validation loss = 1.1759  \n",
      "\n",
      "Fold: 20  Epoch: 234  Training loss = 3.6553  Validation loss = 1.1756  \n",
      "\n",
      "Fold: 20  Epoch: 235  Training loss = 3.6549  Validation loss = 1.1752  \n",
      "\n",
      "Fold: 20  Epoch: 236  Training loss = 3.6544  Validation loss = 1.1752  \n",
      "\n",
      "Fold: 20  Epoch: 237  Training loss = 3.6539  Validation loss = 1.1749  \n",
      "\n",
      "Fold: 20  Epoch: 238  Training loss = 3.6533  Validation loss = 1.1747  \n",
      "\n",
      "Fold: 20  Epoch: 239  Training loss = 3.6528  Validation loss = 1.1745  \n",
      "\n",
      "Fold: 20  Epoch: 240  Training loss = 3.6521  Validation loss = 1.1742  \n",
      "\n",
      "Fold: 20  Epoch: 241  Training loss = 3.6517  Validation loss = 1.1741  \n",
      "\n",
      "Fold: 20  Epoch: 242  Training loss = 3.6512  Validation loss = 1.1739  \n",
      "\n",
      "Fold: 20  Epoch: 243  Training loss = 3.6507  Validation loss = 1.1739  \n",
      "\n",
      "Fold: 20  Epoch: 244  Training loss = 3.6502  Validation loss = 1.1739  \n",
      "\n",
      "Fold: 20  Epoch: 245  Training loss = 3.6498  Validation loss = 1.1739  \n",
      "\n",
      "Fold: 20  Epoch: 246  Training loss = 3.6493  Validation loss = 1.1738  \n",
      "\n",
      "Fold: 20  Epoch: 247  Training loss = 3.6487  Validation loss = 1.1735  \n",
      "\n",
      "Fold: 20  Epoch: 248  Training loss = 3.6482  Validation loss = 1.1733  \n",
      "\n",
      "Fold: 20  Epoch: 249  Training loss = 3.6479  Validation loss = 1.1733  \n",
      "\n",
      "Fold: 20  Epoch: 250  Training loss = 3.6474  Validation loss = 1.1731  \n",
      "\n",
      "Fold: 20  Epoch: 251  Training loss = 3.6469  Validation loss = 1.1731  \n",
      "\n",
      "Fold: 20  Epoch: 252  Training loss = 3.6464  Validation loss = 1.1731  \n",
      "\n",
      "Fold: 20  Epoch: 253  Training loss = 3.6459  Validation loss = 1.1730  \n",
      "\n",
      "Fold: 20  Epoch: 254  Training loss = 3.6456  Validation loss = 1.1727  \n",
      "\n",
      "Fold: 20  Epoch: 255  Training loss = 3.6451  Validation loss = 1.1723  \n",
      "\n",
      "Fold: 20  Epoch: 256  Training loss = 3.6447  Validation loss = 1.1724  \n",
      "\n",
      "Fold: 20  Epoch: 257  Training loss = 3.6442  Validation loss = 1.1723  \n",
      "\n",
      "Fold: 20  Epoch: 258  Training loss = 3.6435  Validation loss = 1.1722  \n",
      "\n",
      "Fold: 20  Epoch: 259  Training loss = 3.6432  Validation loss = 1.1721  \n",
      "\n",
      "Fold: 20  Epoch: 260  Training loss = 3.6426  Validation loss = 1.1720  \n",
      "\n",
      "Fold: 20  Epoch: 261  Training loss = 3.6422  Validation loss = 1.1718  \n",
      "\n",
      "Fold: 20  Epoch: 262  Training loss = 3.6419  Validation loss = 1.1718  \n",
      "\n",
      "Fold: 20  Epoch: 263  Training loss = 3.6414  Validation loss = 1.1716  \n",
      "\n",
      "Fold: 20  Epoch: 264  Training loss = 3.6408  Validation loss = 1.1713  \n",
      "\n",
      "Fold: 20  Epoch: 265  Training loss = 3.6403  Validation loss = 1.1710  \n",
      "\n",
      "Fold: 20  Epoch: 266  Training loss = 3.6398  Validation loss = 1.1709  \n",
      "\n",
      "Fold: 20  Epoch: 267  Training loss = 3.6393  Validation loss = 1.1707  \n",
      "\n",
      "Fold: 20  Epoch: 268  Training loss = 3.6387  Validation loss = 1.1705  \n",
      "\n",
      "Fold: 20  Epoch: 269  Training loss = 3.6383  Validation loss = 1.1705  \n",
      "\n",
      "Fold: 20  Epoch: 270  Training loss = 3.6379  Validation loss = 1.1703  \n",
      "\n",
      "Fold: 20  Epoch: 271  Training loss = 3.6375  Validation loss = 1.1702  \n",
      "\n",
      "Fold: 20  Epoch: 272  Training loss = 3.6371  Validation loss = 1.1700  \n",
      "\n",
      "Fold: 20  Epoch: 273  Training loss = 3.6366  Validation loss = 1.1699  \n",
      "\n",
      "Fold: 20  Epoch: 274  Training loss = 3.6362  Validation loss = 1.1700  \n",
      "\n",
      "Fold: 20  Epoch: 275  Training loss = 3.6358  Validation loss = 1.1697  \n",
      "\n",
      "Fold: 20  Epoch: 276  Training loss = 3.6354  Validation loss = 1.1695  \n",
      "\n",
      "Fold: 20  Epoch: 277  Training loss = 3.6348  Validation loss = 1.1694  \n",
      "\n",
      "Fold: 20  Epoch: 278  Training loss = 3.6346  Validation loss = 1.1694  \n",
      "\n",
      "Fold: 20  Epoch: 279  Training loss = 3.6339  Validation loss = 1.1692  \n",
      "\n",
      "Fold: 20  Epoch: 280  Training loss = 3.6335  Validation loss = 1.1690  \n",
      "\n",
      "Fold: 20  Epoch: 281  Training loss = 3.6330  Validation loss = 1.1688  \n",
      "\n",
      "Fold: 20  Epoch: 282  Training loss = 3.6325  Validation loss = 1.1687  \n",
      "\n",
      "Fold: 20  Epoch: 283  Training loss = 3.6319  Validation loss = 1.1685  \n",
      "\n",
      "Fold: 20  Epoch: 284  Training loss = 3.6316  Validation loss = 1.1683  \n",
      "\n",
      "Fold: 20  Epoch: 285  Training loss = 3.6311  Validation loss = 1.1683  \n",
      "\n",
      "Fold: 20  Epoch: 286  Training loss = 3.6309  Validation loss = 1.1680  \n",
      "\n",
      "Fold: 20  Epoch: 287  Training loss = 3.6304  Validation loss = 1.1676  \n",
      "\n",
      "Fold: 20  Epoch: 288  Training loss = 3.6300  Validation loss = 1.1674  \n",
      "\n",
      "Fold: 20  Epoch: 289  Training loss = 3.6295  Validation loss = 1.1673  \n",
      "\n",
      "Fold: 20  Epoch: 290  Training loss = 3.6291  Validation loss = 1.1670  \n",
      "\n",
      "Fold: 20  Epoch: 291  Training loss = 3.6286  Validation loss = 1.1667  \n",
      "\n",
      "Fold: 20  Epoch: 292  Training loss = 3.6281  Validation loss = 1.1665  \n",
      "\n",
      "Fold: 20  Epoch: 293  Training loss = 3.6276  Validation loss = 1.1664  \n",
      "\n",
      "Fold: 20  Epoch: 294  Training loss = 3.6271  Validation loss = 1.1662  \n",
      "\n",
      "Fold: 20  Epoch: 295  Training loss = 3.6266  Validation loss = 1.1661  \n",
      "\n",
      "Fold: 20  Epoch: 296  Training loss = 3.6260  Validation loss = 1.1657  \n",
      "\n",
      "Fold: 20  Epoch: 297  Training loss = 3.6253  Validation loss = 1.1657  \n",
      "\n",
      "Fold: 20  Epoch: 298  Training loss = 3.6248  Validation loss = 1.1656  \n",
      "\n",
      "Fold: 20  Epoch: 299  Training loss = 3.6245  Validation loss = 1.1654  \n",
      "\n",
      "Fold: 20  Epoch: 300  Training loss = 3.6241  Validation loss = 1.1653  \n",
      "\n",
      "Fold: 20  Epoch: 301  Training loss = 3.6236  Validation loss = 1.1652  \n",
      "\n",
      "Fold: 20  Epoch: 302  Training loss = 3.6230  Validation loss = 1.1650  \n",
      "\n",
      "Fold: 20  Epoch: 303  Training loss = 3.6225  Validation loss = 1.1648  \n",
      "\n",
      "Fold: 20  Epoch: 304  Training loss = 3.6222  Validation loss = 1.1648  \n",
      "\n",
      "Fold: 20  Epoch: 305  Training loss = 3.6217  Validation loss = 1.1646  \n",
      "\n",
      "Fold: 20  Epoch: 306  Training loss = 3.6213  Validation loss = 1.1644  \n",
      "\n",
      "Fold: 20  Epoch: 307  Training loss = 3.6208  Validation loss = 1.1643  \n",
      "\n",
      "Fold: 20  Epoch: 308  Training loss = 3.6204  Validation loss = 1.1641  \n",
      "\n",
      "Fold: 20  Epoch: 309  Training loss = 3.6199  Validation loss = 1.1639  \n",
      "\n",
      "Fold: 20  Epoch: 310  Training loss = 3.6195  Validation loss = 1.1639  \n",
      "\n",
      "Fold: 20  Epoch: 311  Training loss = 3.6191  Validation loss = 1.1637  \n",
      "\n",
      "Fold: 20  Epoch: 312  Training loss = 3.6186  Validation loss = 1.1637  \n",
      "\n",
      "Fold: 20  Epoch: 313  Training loss = 3.6182  Validation loss = 1.1636  \n",
      "\n",
      "Fold: 20  Epoch: 314  Training loss = 3.6176  Validation loss = 1.1635  \n",
      "\n",
      "Fold: 20  Epoch: 315  Training loss = 3.6171  Validation loss = 1.1634  \n",
      "\n",
      "Fold: 20  Epoch: 316  Training loss = 3.6166  Validation loss = 1.1634  \n",
      "\n",
      "Fold: 20  Epoch: 317  Training loss = 3.6160  Validation loss = 1.1632  \n",
      "\n",
      "Fold: 20  Epoch: 318  Training loss = 3.6155  Validation loss = 1.1631  \n",
      "\n",
      "Fold: 20  Epoch: 319  Training loss = 3.6151  Validation loss = 1.1629  \n",
      "\n",
      "Fold: 20  Epoch: 320  Training loss = 3.6149  Validation loss = 1.1629  \n",
      "\n",
      "Fold: 20  Epoch: 321  Training loss = 3.6144  Validation loss = 1.1628  \n",
      "\n",
      "Fold: 20  Epoch: 322  Training loss = 3.6138  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 20  Epoch: 323  Training loss = 3.6130  Validation loss = 1.1626  \n",
      "\n",
      "Fold: 20  Epoch: 324  Training loss = 3.6124  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 20  Epoch: 325  Training loss = 3.6120  Validation loss = 1.1625  \n",
      "\n",
      "Fold: 20  Epoch: 326  Training loss = 3.6115  Validation loss = 1.1623  \n",
      "\n",
      "Fold: 20  Epoch: 327  Training loss = 3.6112  Validation loss = 1.1622  \n",
      "\n",
      "Fold: 20  Epoch: 328  Training loss = 3.6106  Validation loss = 1.1623  \n",
      "\n",
      "Fold: 20  Epoch: 329  Training loss = 3.6101  Validation loss = 1.1621  \n",
      "\n",
      "Fold: 20  Epoch: 330  Training loss = 3.6096  Validation loss = 1.1619  \n",
      "\n",
      "Fold: 20  Epoch: 331  Training loss = 3.6090  Validation loss = 1.1618  \n",
      "\n",
      "Fold: 20  Epoch: 332  Training loss = 3.6086  Validation loss = 1.1616  \n",
      "\n",
      "Fold: 20  Epoch: 333  Training loss = 3.6082  Validation loss = 1.1616  \n",
      "\n",
      "Fold: 20  Epoch: 334  Training loss = 3.6078  Validation loss = 1.1615  \n",
      "\n",
      "Fold: 20  Epoch: 335  Training loss = 3.6076  Validation loss = 1.1614  \n",
      "\n",
      "Fold: 20  Epoch: 336  Training loss = 3.6071  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 20  Epoch: 337  Training loss = 3.6067  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 20  Epoch: 338  Training loss = 3.6064  Validation loss = 1.1610  \n",
      "\n",
      "Fold: 20  Epoch: 339  Training loss = 3.6059  Validation loss = 1.1610  \n",
      "\n",
      "Fold: 20  Epoch: 340  Training loss = 3.6053  Validation loss = 1.1608  \n",
      "\n",
      "Fold: 20  Epoch: 341  Training loss = 3.6049  Validation loss = 1.1607  \n",
      "\n",
      "Fold: 20  Epoch: 342  Training loss = 3.6044  Validation loss = 1.1605  \n",
      "\n",
      "Fold: 20  Epoch: 343  Training loss = 3.6039  Validation loss = 1.1604  \n",
      "\n",
      "Fold: 20  Epoch: 344  Training loss = 3.6035  Validation loss = 1.1603  \n",
      "\n",
      "Fold: 20  Epoch: 345  Training loss = 3.6030  Validation loss = 1.1601  \n",
      "\n",
      "Fold: 20  Epoch: 346  Training loss = 3.6026  Validation loss = 1.1601  \n",
      "\n",
      "Fold: 20  Epoch: 347  Training loss = 3.6023  Validation loss = 1.1600  \n",
      "\n",
      "Fold: 20  Epoch: 348  Training loss = 3.6019  Validation loss = 1.1600  \n",
      "\n",
      "Fold: 20  Epoch: 349  Training loss = 3.6014  Validation loss = 1.1600  \n",
      "\n",
      "Fold: 20  Epoch: 350  Training loss = 3.6010  Validation loss = 1.1597  \n",
      "\n",
      "Fold: 20  Epoch: 351  Training loss = 3.6003  Validation loss = 1.1598  \n",
      "\n",
      "Fold: 20  Epoch: 352  Training loss = 3.5999  Validation loss = 1.1597  \n",
      "\n",
      "Fold: 20  Epoch: 353  Training loss = 3.5995  Validation loss = 1.1596  \n",
      "\n",
      "Fold: 20  Epoch: 354  Training loss = 3.5989  Validation loss = 1.1593  \n",
      "\n",
      "Fold: 20  Epoch: 355  Training loss = 3.5986  Validation loss = 1.1592  \n",
      "\n",
      "Fold: 20  Epoch: 356  Training loss = 3.5980  Validation loss = 1.1591  \n",
      "\n",
      "Fold: 20  Epoch: 357  Training loss = 3.5976  Validation loss = 1.1589  \n",
      "\n",
      "Fold: 20  Epoch: 358  Training loss = 3.5972  Validation loss = 1.1587  \n",
      "\n",
      "Fold: 20  Epoch: 359  Training loss = 3.5966  Validation loss = 1.1586  \n",
      "\n",
      "Fold: 20  Epoch: 360  Training loss = 3.5963  Validation loss = 1.1586  \n",
      "\n",
      "Fold: 20  Epoch: 361  Training loss = 3.5958  Validation loss = 1.1585  \n",
      "\n",
      "Fold: 20  Epoch: 362  Training loss = 3.5953  Validation loss = 1.1583  \n",
      "\n",
      "Fold: 20  Epoch: 363  Training loss = 3.5950  Validation loss = 1.1581  \n",
      "\n",
      "Fold: 20  Epoch: 364  Training loss = 3.5946  Validation loss = 1.1579  \n",
      "\n",
      "Fold: 20  Epoch: 365  Training loss = 3.5942  Validation loss = 1.1578  \n",
      "\n",
      "Fold: 20  Epoch: 366  Training loss = 3.5940  Validation loss = 1.1576  \n",
      "\n",
      "Fold: 20  Epoch: 367  Training loss = 3.5937  Validation loss = 1.1575  \n",
      "\n",
      "Fold: 20  Epoch: 368  Training loss = 3.5932  Validation loss = 1.1575  \n",
      "\n",
      "Fold: 20  Epoch: 369  Training loss = 3.5927  Validation loss = 1.1574  \n",
      "\n",
      "Fold: 20  Epoch: 370  Training loss = 3.5924  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 20  Epoch: 371  Training loss = 3.5922  Validation loss = 1.1571  \n",
      "\n",
      "Fold: 20  Epoch: 372  Training loss = 3.5917  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 20  Epoch: 373  Training loss = 3.5912  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 20  Epoch: 374  Training loss = 3.5908  Validation loss = 1.1568  \n",
      "\n",
      "Fold: 20  Epoch: 375  Training loss = 3.5903  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 20  Epoch: 376  Training loss = 3.5895  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 20  Epoch: 377  Training loss = 3.5887  Validation loss = 1.1566  \n",
      "\n",
      "Fold: 20  Epoch: 378  Training loss = 3.5855  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 20  Epoch: 379  Training loss = 3.5850  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 20  Epoch: 380  Training loss = 3.5844  Validation loss = 1.1564  \n",
      "\n",
      "Fold: 20  Epoch: 381  Training loss = 3.5835  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 20  Epoch: 382  Training loss = 3.5831  Validation loss = 1.1561  \n",
      "\n",
      "Fold: 20  Epoch: 383  Training loss = 3.5826  Validation loss = 1.1559  \n",
      "\n",
      "Fold: 20  Epoch: 384  Training loss = 3.5820  Validation loss = 1.1560  \n",
      "\n",
      "Fold: 20  Epoch: 385  Training loss = 3.5815  Validation loss = 1.1559  \n",
      "\n",
      "Fold: 20  Epoch: 386  Training loss = 3.5811  Validation loss = 1.1559  \n",
      "\n",
      "Fold: 20  Epoch: 387  Training loss = 3.5804  Validation loss = 1.1558  \n",
      "\n",
      "Fold: 20  Epoch: 388  Training loss = 3.5800  Validation loss = 1.1555  \n",
      "\n",
      "Fold: 20  Epoch: 389  Training loss = 3.5796  Validation loss = 1.1554  \n",
      "\n",
      "Fold: 20  Epoch: 390  Training loss = 3.5793  Validation loss = 1.1554  \n",
      "\n",
      "Fold: 20  Epoch: 391  Training loss = 3.5788  Validation loss = 1.1553  \n",
      "\n",
      "Fold: 20  Epoch: 392  Training loss = 3.5784  Validation loss = 1.1552  \n",
      "\n",
      "Fold: 20  Epoch: 393  Training loss = 3.5780  Validation loss = 1.1551  \n",
      "\n",
      "Fold: 20  Epoch: 394  Training loss = 3.5774  Validation loss = 1.1550  \n",
      "\n",
      "Fold: 20  Epoch: 395  Training loss = 3.5770  Validation loss = 1.1549  \n",
      "\n",
      "Fold: 20  Epoch: 396  Training loss = 3.5766  Validation loss = 1.1547  \n",
      "\n",
      "Fold: 20  Epoch: 397  Training loss = 3.5763  Validation loss = 1.1545  \n",
      "\n",
      "Fold: 20  Epoch: 398  Training loss = 3.5759  Validation loss = 1.1544  \n",
      "\n",
      "Fold: 20  Epoch: 399  Training loss = 3.5758  Validation loss = 1.1544  \n",
      "\n",
      "Fold: 20  Epoch: 400  Training loss = 3.5754  Validation loss = 1.1541  \n",
      "\n",
      "Fold: 20  Epoch: 401  Training loss = 3.5750  Validation loss = 1.1541  \n",
      "\n",
      "Fold: 20  Epoch: 402  Training loss = 3.5745  Validation loss = 1.1539  \n",
      "\n",
      "Fold: 20  Epoch: 403  Training loss = 3.5741  Validation loss = 1.1538  \n",
      "\n",
      "Fold: 20  Epoch: 404  Training loss = 3.5737  Validation loss = 1.1536  \n",
      "\n",
      "Fold: 20  Epoch: 405  Training loss = 3.5733  Validation loss = 1.1536  \n",
      "\n",
      "Fold: 20  Epoch: 406  Training loss = 3.5729  Validation loss = 1.1535  \n",
      "\n",
      "Fold: 20  Epoch: 407  Training loss = 3.5726  Validation loss = 1.1534  \n",
      "\n",
      "Fold: 20  Epoch: 408  Training loss = 3.5721  Validation loss = 1.1533  \n",
      "\n",
      "Fold: 20  Epoch: 409  Training loss = 3.5717  Validation loss = 1.1533  \n",
      "\n",
      "Fold: 20  Epoch: 410  Training loss = 3.5711  Validation loss = 1.1532  \n",
      "\n",
      "Fold: 20  Epoch: 411  Training loss = 3.5708  Validation loss = 1.1531  \n",
      "\n",
      "Fold: 20  Epoch: 412  Training loss = 3.5703  Validation loss = 1.1531  \n",
      "\n",
      "Fold: 20  Epoch: 413  Training loss = 3.5698  Validation loss = 1.1529  \n",
      "\n",
      "Fold: 20  Epoch: 414  Training loss = 3.5696  Validation loss = 1.1528  \n",
      "\n",
      "Fold: 20  Epoch: 415  Training loss = 3.5694  Validation loss = 1.1525  \n",
      "\n",
      "Fold: 20  Epoch: 416  Training loss = 3.5689  Validation loss = 1.1524  \n",
      "\n",
      "Fold: 20  Epoch: 417  Training loss = 3.5684  Validation loss = 1.1522  \n",
      "\n",
      "Fold: 20  Epoch: 418  Training loss = 3.5680  Validation loss = 1.1519  \n",
      "\n",
      "Fold: 20  Epoch: 419  Training loss = 3.5677  Validation loss = 1.1518  \n",
      "\n",
      "Fold: 20  Epoch: 420  Training loss = 3.5672  Validation loss = 1.1515  \n",
      "\n",
      "Fold: 20  Epoch: 421  Training loss = 3.5669  Validation loss = 1.1516  \n",
      "\n",
      "Fold: 20  Epoch: 422  Training loss = 3.5665  Validation loss = 1.1514  \n",
      "\n",
      "Fold: 20  Epoch: 423  Training loss = 3.5661  Validation loss = 1.1514  \n",
      "\n",
      "Fold: 20  Epoch: 424  Training loss = 3.5656  Validation loss = 1.1511  \n",
      "\n",
      "Fold: 20  Epoch: 425  Training loss = 3.5650  Validation loss = 1.1509  \n",
      "\n",
      "Fold: 20  Epoch: 426  Training loss = 3.5646  Validation loss = 1.1507  \n",
      "\n",
      "Fold: 20  Epoch: 427  Training loss = 3.5641  Validation loss = 1.1506  \n",
      "\n",
      "Fold: 20  Epoch: 428  Training loss = 3.5637  Validation loss = 1.1506  \n",
      "\n",
      "Fold: 20  Epoch: 429  Training loss = 3.5631  Validation loss = 1.1504  \n",
      "\n",
      "Fold: 20  Epoch: 430  Training loss = 3.5626  Validation loss = 1.1502  \n",
      "\n",
      "Fold: 20  Epoch: 431  Training loss = 3.5622  Validation loss = 1.1501  \n",
      "\n",
      "Fold: 20  Epoch: 432  Training loss = 3.5618  Validation loss = 1.1498  \n",
      "\n",
      "Fold: 20  Epoch: 433  Training loss = 3.5613  Validation loss = 1.1497  \n",
      "\n",
      "Fold: 20  Epoch: 434  Training loss = 3.5609  Validation loss = 1.1494  \n",
      "\n",
      "Fold: 20  Epoch: 435  Training loss = 3.5604  Validation loss = 1.1495  \n",
      "\n",
      "Fold: 20  Epoch: 436  Training loss = 3.5599  Validation loss = 1.1494  \n",
      "\n",
      "Fold: 20  Epoch: 437  Training loss = 3.5593  Validation loss = 1.1492  \n",
      "\n",
      "Fold: 20  Epoch: 438  Training loss = 3.5590  Validation loss = 1.1490  \n",
      "\n",
      "Fold: 20  Epoch: 439  Training loss = 3.5588  Validation loss = 1.1489  \n",
      "\n",
      "Fold: 20  Epoch: 440  Training loss = 3.5585  Validation loss = 1.1488  \n",
      "\n",
      "Fold: 20  Epoch: 441  Training loss = 3.5580  Validation loss = 1.1487  \n",
      "\n",
      "Fold: 20  Epoch: 442  Training loss = 3.5576  Validation loss = 1.1486  \n",
      "\n",
      "Fold: 20  Epoch: 443  Training loss = 3.5570  Validation loss = 1.1487  \n",
      "\n",
      "Fold: 20  Epoch: 444  Training loss = 3.5567  Validation loss = 1.1486  \n",
      "\n",
      "Fold: 20  Epoch: 445  Training loss = 3.5564  Validation loss = 1.1485  \n",
      "\n",
      "Fold: 20  Epoch: 446  Training loss = 3.5561  Validation loss = 1.1483  \n",
      "\n",
      "Fold: 20  Epoch: 447  Training loss = 3.5556  Validation loss = 1.1481  \n",
      "\n",
      "Fold: 20  Epoch: 448  Training loss = 3.5552  Validation loss = 1.1479  \n",
      "\n",
      "Fold: 20  Epoch: 449  Training loss = 3.5550  Validation loss = 1.1478  \n",
      "\n",
      "Fold: 20  Epoch: 450  Training loss = 3.5547  Validation loss = 1.1478  \n",
      "\n",
      "Fold: 20  Epoch: 451  Training loss = 3.5543  Validation loss = 1.1478  \n",
      "\n",
      "Fold: 20  Epoch: 452  Training loss = 3.5538  Validation loss = 1.1476  \n",
      "\n",
      "Fold: 20  Epoch: 453  Training loss = 3.5534  Validation loss = 1.1475  \n",
      "\n",
      "Fold: 20  Epoch: 454  Training loss = 3.5530  Validation loss = 1.1474  \n",
      "\n",
      "Fold: 20  Epoch: 455  Training loss = 3.5527  Validation loss = 1.1473  \n",
      "\n",
      "Fold: 20  Epoch: 456  Training loss = 3.5523  Validation loss = 1.1473  \n",
      "\n",
      "Fold: 20  Epoch: 457  Training loss = 3.5518  Validation loss = 1.1471  \n",
      "\n",
      "Fold: 20  Epoch: 458  Training loss = 3.5516  Validation loss = 1.1472  \n",
      "\n",
      "Fold: 20  Epoch: 459  Training loss = 3.5511  Validation loss = 1.1471  \n",
      "\n",
      "Fold: 20  Epoch: 460  Training loss = 3.5508  Validation loss = 1.1469  \n",
      "\n",
      "Fold: 20  Epoch: 461  Training loss = 3.5505  Validation loss = 1.1469  \n",
      "\n",
      "Fold: 20  Epoch: 462  Training loss = 3.5501  Validation loss = 1.1469  \n",
      "\n",
      "Fold: 20  Epoch: 463  Training loss = 3.5496  Validation loss = 1.1468  \n",
      "\n",
      "Fold: 20  Epoch: 464  Training loss = 3.5491  Validation loss = 1.1468  \n",
      "\n",
      "Fold: 20  Epoch: 465  Training loss = 3.5488  Validation loss = 1.1467  \n",
      "\n",
      "Fold: 20  Epoch: 466  Training loss = 3.5486  Validation loss = 1.1467  \n",
      "\n",
      "Fold: 20  Epoch: 467  Training loss = 3.5482  Validation loss = 1.1466  \n",
      "\n",
      "Fold: 20  Epoch: 468  Training loss = 3.5479  Validation loss = 1.1466  \n",
      "\n",
      "Fold: 20  Epoch: 469  Training loss = 3.5475  Validation loss = 1.1464  \n",
      "\n",
      "Fold: 20  Epoch: 470  Training loss = 3.5471  Validation loss = 1.1464  \n",
      "\n",
      "Fold: 20  Epoch: 471  Training loss = 3.5467  Validation loss = 1.1464  \n",
      "\n",
      "Fold: 20  Epoch: 472  Training loss = 3.5465  Validation loss = 1.1463  \n",
      "\n",
      "Fold: 20  Epoch: 473  Training loss = 3.5458  Validation loss = 1.1463  \n",
      "\n",
      "Fold: 20  Epoch: 474  Training loss = 3.5456  Validation loss = 1.1463  \n",
      "\n",
      "Fold: 20  Epoch: 475  Training loss = 3.5451  Validation loss = 1.1462  \n",
      "\n",
      "Fold: 20  Epoch: 476  Training loss = 3.5446  Validation loss = 1.1461  \n",
      "\n",
      "Fold: 20  Epoch: 477  Training loss = 3.5442  Validation loss = 1.1460  \n",
      "\n",
      "Fold: 20  Epoch: 478  Training loss = 3.5438  Validation loss = 1.1459  \n",
      "\n",
      "Fold: 20  Epoch: 479  Training loss = 3.5433  Validation loss = 1.1459  \n",
      "\n",
      "Fold: 20  Epoch: 480  Training loss = 3.5429  Validation loss = 1.1457  \n",
      "\n",
      "Fold: 20  Epoch: 481  Training loss = 3.5424  Validation loss = 1.1457  \n",
      "\n",
      "Fold: 20  Epoch: 482  Training loss = 3.5419  Validation loss = 1.1456  \n",
      "\n",
      "Fold: 20  Epoch: 483  Training loss = 3.5415  Validation loss = 1.1455  \n",
      "\n",
      "Fold: 20  Epoch: 484  Training loss = 3.5410  Validation loss = 1.1454  \n",
      "\n",
      "Fold: 20  Epoch: 485  Training loss = 3.5406  Validation loss = 1.1453  \n",
      "\n",
      "Fold: 20  Epoch: 486  Training loss = 3.5401  Validation loss = 1.1452  \n",
      "\n",
      "Fold: 20  Epoch: 487  Training loss = 3.5396  Validation loss = 1.1451  \n",
      "\n",
      "Fold: 20  Epoch: 488  Training loss = 3.5392  Validation loss = 1.1452  \n",
      "\n",
      "Fold: 20  Epoch: 489  Training loss = 3.5387  Validation loss = 1.1447  \n",
      "\n",
      "Fold: 20  Epoch: 490  Training loss = 3.5383  Validation loss = 1.1445  \n",
      "\n",
      "Fold: 20  Epoch: 491  Training loss = 3.5379  Validation loss = 1.1444  \n",
      "\n",
      "Fold: 20  Epoch: 492  Training loss = 3.5375  Validation loss = 1.1443  \n",
      "\n",
      "Fold: 20  Epoch: 493  Training loss = 3.5372  Validation loss = 1.1443  \n",
      "\n",
      "Fold: 20  Epoch: 494  Training loss = 3.5368  Validation loss = 1.1442  \n",
      "\n",
      "Fold: 20  Epoch: 495  Training loss = 3.5363  Validation loss = 1.1442  \n",
      "\n",
      "Fold: 20  Epoch: 496  Training loss = 3.5358  Validation loss = 1.1441  \n",
      "\n",
      "Fold: 20  Epoch: 497  Training loss = 3.5353  Validation loss = 1.1442  \n",
      "\n",
      "Fold: 20  Epoch: 498  Training loss = 3.5348  Validation loss = 1.1442  \n",
      "\n",
      "Fold: 20  Epoch: 499  Training loss = 3.5344  Validation loss = 1.1441  \n",
      "\n",
      "Fold: 20  Epoch: 500  Training loss = 3.5340  Validation loss = 1.1440  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 500  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 3.5385  Validation loss = 4.3972  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 3.5382  Validation loss = 4.3977  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 3.5377  Validation loss = 4.3984  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 3.5371  Validation loss = 4.3993  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 3.5366  Validation loss = 4.4003  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 3.5361  Validation loss = 4.4010  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 3.5357  Validation loss = 4.4018  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 3.5352  Validation loss = 4.4026  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 3.5349  Validation loss = 4.4030  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 3.5343  Validation loss = 4.4040  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 3.5340  Validation loss = 4.4044  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 3.6926  Validation loss = 2.9160  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 3.6924  Validation loss = 2.9159  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 3.6922  Validation loss = 2.9160  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 3.6918  Validation loss = 2.9162  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 3.6916  Validation loss = 2.9164  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 3.6912  Validation loss = 2.9167  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 3.6911  Validation loss = 2.9169  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 3.6908  Validation loss = 2.9170  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 3.6906  Validation loss = 2.9172  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 3.6904  Validation loss = 2.9173  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 3.6900  Validation loss = 2.9176  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 2  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 3.7429  Validation loss = 2.5098  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 3.7428  Validation loss = 2.5099  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 3.7425  Validation loss = 2.5101  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 3.7423  Validation loss = 2.5102  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 3.7420  Validation loss = 2.5103  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 3.7416  Validation loss = 2.5107  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 3.7414  Validation loss = 2.5111  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 3.7411  Validation loss = 2.5111  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 3.7409  Validation loss = 2.5114  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 3.7407  Validation loss = 2.5116  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 3.7404  Validation loss = 2.5119  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 1  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 3.7298  Validation loss = 2.0776  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 3.7295  Validation loss = 2.0771  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 3.7291  Validation loss = 2.0766  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 3.7289  Validation loss = 2.0762  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 3.7285  Validation loss = 2.0755  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 3.7282  Validation loss = 2.0749  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 3.7279  Validation loss = 2.0744  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 3.7275  Validation loss = 2.0737  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 3.7272  Validation loss = 2.0732  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 3.7270  Validation loss = 2.0728  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 3.7266  Validation loss = 2.0723  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 3.7264  Validation loss = 2.0719  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 3.7260  Validation loss = 2.0712  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 3.7256  Validation loss = 2.0708  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 3.7252  Validation loss = 2.0702  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 3.7250  Validation loss = 2.0699  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 3.7244  Validation loss = 2.0691  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 3.7241  Validation loss = 2.0686  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 3.7238  Validation loss = 2.0684  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 3.7234  Validation loss = 2.0679  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 3.7230  Validation loss = 2.0672  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 3.7227  Validation loss = 2.0666  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 3.7224  Validation loss = 2.0659  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 3.7220  Validation loss = 2.0652  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 3.7217  Validation loss = 2.0646  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 3.7216  Validation loss = 2.0644  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 3.7214  Validation loss = 2.0640  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 3.7212  Validation loss = 2.0636  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 3.7209  Validation loss = 2.0633  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 3.7206  Validation loss = 2.0627  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 3.7202  Validation loss = 2.0622  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 3.7199  Validation loss = 2.0619  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 3.7195  Validation loss = 2.0616  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 3.7192  Validation loss = 2.0612  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 3.7189  Validation loss = 2.0606  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 3.7185  Validation loss = 2.0602  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 3.7182  Validation loss = 2.0597  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 3.7178  Validation loss = 2.0590  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 3.7175  Validation loss = 2.0588  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 3.7172  Validation loss = 2.0583  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 3.7168  Validation loss = 2.0578  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 3.7166  Validation loss = 2.0573  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 3.7164  Validation loss = 2.0571  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 3.7161  Validation loss = 2.0565  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 3.7159  Validation loss = 2.0560  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 3.7156  Validation loss = 2.0554  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 3.7154  Validation loss = 2.0552  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 3.7150  Validation loss = 2.0541  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 3.7148  Validation loss = 2.0535  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 3.7144  Validation loss = 2.0530  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 3.7142  Validation loss = 2.0526  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 3.7140  Validation loss = 2.0523  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 3.7138  Validation loss = 2.0519  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 3.7134  Validation loss = 2.0513  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 3.7131  Validation loss = 2.0510  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 3.7127  Validation loss = 2.0505  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 3.7124  Validation loss = 2.0501  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 3.7121  Validation loss = 2.0498  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 3.7117  Validation loss = 2.0489  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 3.7114  Validation loss = 2.0485  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 3.7112  Validation loss = 2.0483  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 3.7110  Validation loss = 2.0478  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 3.7107  Validation loss = 2.0476  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 3.7104  Validation loss = 2.0471  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 3.7101  Validation loss = 2.0467  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 3.7099  Validation loss = 2.0463  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 3.7095  Validation loss = 2.0459  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 3.7091  Validation loss = 2.0453  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 3.7090  Validation loss = 2.0452  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 3.7086  Validation loss = 2.0443  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 3.7084  Validation loss = 2.0437  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 3.7081  Validation loss = 2.0428  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 3.7078  Validation loss = 2.0424  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 3.7075  Validation loss = 2.0421  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 3.7072  Validation loss = 2.0417  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 3.7069  Validation loss = 2.0408  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 3.7064  Validation loss = 2.0402  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 3.7061  Validation loss = 2.0398  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 3.7058  Validation loss = 2.0392  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 3.7056  Validation loss = 2.0386  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 3.7052  Validation loss = 2.0380  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 3.7048  Validation loss = 2.0374  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 3.7045  Validation loss = 2.0368  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 3.7041  Validation loss = 2.0361  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 3.7038  Validation loss = 2.0357  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 3.7033  Validation loss = 2.0352  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 3.7029  Validation loss = 2.0345  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 3.7026  Validation loss = 2.0341  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 3.7022  Validation loss = 2.0336  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 3.7019  Validation loss = 2.0333  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 3.7015  Validation loss = 2.0328  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 3.7013  Validation loss = 2.0327  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 3.7009  Validation loss = 2.0324  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 3.7006  Validation loss = 2.0319  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 3.7001  Validation loss = 2.0311  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 3.6997  Validation loss = 2.0304  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 3.6993  Validation loss = 2.0299  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 3.6990  Validation loss = 2.0294  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 3.6987  Validation loss = 2.0292  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 3.6984  Validation loss = 2.0288  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 3.6980  Validation loss = 2.0282  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 3.6977  Validation loss = 2.0278  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 3.6971  Validation loss = 2.0267  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 3.6968  Validation loss = 2.0260  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 3.6966  Validation loss = 2.0258  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 3.6963  Validation loss = 2.0254  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 3.6961  Validation loss = 2.0248  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 3.6958  Validation loss = 2.0244  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 3.6955  Validation loss = 2.0240  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 3.6952  Validation loss = 2.0233  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 3.6948  Validation loss = 2.0229  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 3.6944  Validation loss = 2.0224  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 3.6940  Validation loss = 2.0217  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 3.6938  Validation loss = 2.0211  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 3.6935  Validation loss = 2.0207  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 3.6932  Validation loss = 2.0203  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 3.6928  Validation loss = 2.0197  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 3.6924  Validation loss = 2.0189  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 3.6921  Validation loss = 2.0184  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 3.6918  Validation loss = 2.0179  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 3.6915  Validation loss = 2.0172  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 3.6910  Validation loss = 2.0164  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 3.6908  Validation loss = 2.0161  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 3.6904  Validation loss = 2.0154  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 3.6902  Validation loss = 2.0150  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 3.6897  Validation loss = 2.0142  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 3.6894  Validation loss = 2.0135  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 3.6891  Validation loss = 2.0130  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 3.6887  Validation loss = 2.0123  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 3.6884  Validation loss = 2.0117  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 3.6882  Validation loss = 2.0111  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 3.6878  Validation loss = 2.0106  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 3.6874  Validation loss = 2.0101  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 3.6871  Validation loss = 2.0097  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 3.6868  Validation loss = 2.0090  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 3.6866  Validation loss = 2.0086  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 3.6861  Validation loss = 2.0080  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 3.6856  Validation loss = 2.0072  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 3.6854  Validation loss = 2.0068  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 3.6851  Validation loss = 2.0060  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 3.6848  Validation loss = 2.0055  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 3.6842  Validation loss = 2.0050  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 3.6840  Validation loss = 2.0045  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 3.6837  Validation loss = 2.0042  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 3.6833  Validation loss = 2.0035  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 3.6832  Validation loss = 2.0030  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 3.6829  Validation loss = 2.0023  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 3.6826  Validation loss = 2.0017  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 3.6823  Validation loss = 2.0012  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 3.6819  Validation loss = 2.0008  \n",
      "\n",
      "Fold: 24  Epoch: 151  Training loss = 3.6817  Validation loss = 2.0004  \n",
      "\n",
      "Fold: 24  Epoch: 152  Training loss = 3.6815  Validation loss = 1.9999  \n",
      "\n",
      "Fold: 24  Epoch: 153  Training loss = 3.6811  Validation loss = 1.9992  \n",
      "\n",
      "Fold: 24  Epoch: 154  Training loss = 3.6808  Validation loss = 1.9989  \n",
      "\n",
      "Fold: 24  Epoch: 155  Training loss = 3.6803  Validation loss = 1.9983  \n",
      "\n",
      "Fold: 24  Epoch: 156  Training loss = 3.6800  Validation loss = 1.9978  \n",
      "\n",
      "Fold: 24  Epoch: 157  Training loss = 3.6797  Validation loss = 1.9969  \n",
      "\n",
      "Fold: 24  Epoch: 158  Training loss = 3.6794  Validation loss = 1.9966  \n",
      "\n",
      "Fold: 24  Epoch: 159  Training loss = 3.6790  Validation loss = 1.9960  \n",
      "\n",
      "Fold: 24  Epoch: 160  Training loss = 3.6786  Validation loss = 1.9953  \n",
      "\n",
      "Fold: 24  Epoch: 161  Training loss = 3.6784  Validation loss = 1.9946  \n",
      "\n",
      "Fold: 24  Epoch: 162  Training loss = 3.6782  Validation loss = 1.9942  \n",
      "\n",
      "Fold: 24  Epoch: 163  Training loss = 3.6779  Validation loss = 1.9939  \n",
      "\n",
      "Fold: 24  Epoch: 164  Training loss = 3.6775  Validation loss = 1.9936  \n",
      "\n",
      "Fold: 24  Epoch: 165  Training loss = 3.6772  Validation loss = 1.9932  \n",
      "\n",
      "Fold: 24  Epoch: 166  Training loss = 3.6769  Validation loss = 1.9925  \n",
      "\n",
      "Fold: 24  Epoch: 167  Training loss = 3.6765  Validation loss = 1.9919  \n",
      "\n",
      "Fold: 24  Epoch: 168  Training loss = 3.6762  Validation loss = 1.9915  \n",
      "\n",
      "Fold: 24  Epoch: 169  Training loss = 3.6758  Validation loss = 1.9910  \n",
      "\n",
      "Fold: 24  Epoch: 170  Training loss = 3.6756  Validation loss = 1.9907  \n",
      "\n",
      "Fold: 24  Epoch: 171  Training loss = 3.6753  Validation loss = 1.9901  \n",
      "\n",
      "Fold: 24  Epoch: 172  Training loss = 3.6751  Validation loss = 1.9896  \n",
      "\n",
      "Fold: 24  Epoch: 173  Training loss = 3.6748  Validation loss = 1.9892  \n",
      "\n",
      "Fold: 24  Epoch: 174  Training loss = 3.6746  Validation loss = 1.9888  \n",
      "\n",
      "Fold: 24  Epoch: 175  Training loss = 3.6744  Validation loss = 1.9883  \n",
      "\n",
      "Fold: 24  Epoch: 176  Training loss = 3.6741  Validation loss = 1.9878  \n",
      "\n",
      "Fold: 24  Epoch: 177  Training loss = 3.6737  Validation loss = 1.9871  \n",
      "\n",
      "Fold: 24  Epoch: 178  Training loss = 3.6734  Validation loss = 1.9865  \n",
      "\n",
      "Fold: 24  Epoch: 179  Training loss = 3.6733  Validation loss = 1.9863  \n",
      "\n",
      "Fold: 24  Epoch: 180  Training loss = 3.6730  Validation loss = 1.9859  \n",
      "\n",
      "Fold: 24  Epoch: 181  Training loss = 3.6728  Validation loss = 1.9855  \n",
      "\n",
      "Fold: 24  Epoch: 182  Training loss = 3.6725  Validation loss = 1.9851  \n",
      "\n",
      "Fold: 24  Epoch: 183  Training loss = 3.6722  Validation loss = 1.9846  \n",
      "\n",
      "Fold: 24  Epoch: 184  Training loss = 3.6719  Validation loss = 1.9842  \n",
      "\n",
      "Fold: 24  Epoch: 185  Training loss = 3.6716  Validation loss = 1.9837  \n",
      "\n",
      "Fold: 24  Epoch: 186  Training loss = 3.6713  Validation loss = 1.9834  \n",
      "\n",
      "Fold: 24  Epoch: 187  Training loss = 3.6711  Validation loss = 1.9825  \n",
      "\n",
      "Fold: 24  Epoch: 188  Training loss = 3.6709  Validation loss = 1.9823  \n",
      "\n",
      "Fold: 24  Epoch: 189  Training loss = 3.6706  Validation loss = 1.9819  \n",
      "\n",
      "Fold: 24  Epoch: 190  Training loss = 3.6704  Validation loss = 1.9814  \n",
      "\n",
      "Fold: 24  Epoch: 191  Training loss = 3.6702  Validation loss = 1.9811  \n",
      "\n",
      "Fold: 24  Epoch: 192  Training loss = 3.6699  Validation loss = 1.9808  \n",
      "\n",
      "Fold: 24  Epoch: 193  Training loss = 3.6696  Validation loss = 1.9804  \n",
      "\n",
      "Fold: 24  Epoch: 194  Training loss = 3.6694  Validation loss = 1.9801  \n",
      "\n",
      "Fold: 24  Epoch: 195  Training loss = 3.6691  Validation loss = 1.9794  \n",
      "\n",
      "Fold: 24  Epoch: 196  Training loss = 3.6687  Validation loss = 1.9788  \n",
      "\n",
      "Fold: 24  Epoch: 197  Training loss = 3.6682  Validation loss = 1.9781  \n",
      "\n",
      "Fold: 24  Epoch: 198  Training loss = 3.6679  Validation loss = 1.9774  \n",
      "\n",
      "Fold: 24  Epoch: 199  Training loss = 3.6677  Validation loss = 1.9766  \n",
      "\n",
      "Fold: 24  Epoch: 200  Training loss = 3.6672  Validation loss = 1.9758  \n",
      "\n",
      "Fold: 24  Epoch: 201  Training loss = 3.6670  Validation loss = 1.9754  \n",
      "\n",
      "Fold: 24  Epoch: 202  Training loss = 3.6669  Validation loss = 1.9749  \n",
      "\n",
      "Fold: 24  Epoch: 203  Training loss = 3.6664  Validation loss = 1.9740  \n",
      "\n",
      "Fold: 24  Epoch: 204  Training loss = 3.6662  Validation loss = 1.9736  \n",
      "\n",
      "Fold: 24  Epoch: 205  Training loss = 3.6659  Validation loss = 1.9732  \n",
      "\n",
      "Fold: 24  Epoch: 206  Training loss = 3.6657  Validation loss = 1.9725  \n",
      "\n",
      "Fold: 24  Epoch: 207  Training loss = 3.6655  Validation loss = 1.9719  \n",
      "\n",
      "Fold: 24  Epoch: 208  Training loss = 3.6652  Validation loss = 1.9718  \n",
      "\n",
      "Fold: 24  Epoch: 209  Training loss = 3.6649  Validation loss = 1.9714  \n",
      "\n",
      "Fold: 24  Epoch: 210  Training loss = 3.6645  Validation loss = 1.9709  \n",
      "\n",
      "Fold: 24  Epoch: 211  Training loss = 3.6641  Validation loss = 1.9704  \n",
      "\n",
      "Fold: 24  Epoch: 212  Training loss = 3.6639  Validation loss = 1.9700  \n",
      "\n",
      "Fold: 24  Epoch: 213  Training loss = 3.6636  Validation loss = 1.9696  \n",
      "\n",
      "Fold: 24  Epoch: 214  Training loss = 3.6633  Validation loss = 1.9691  \n",
      "\n",
      "Fold: 24  Epoch: 215  Training loss = 3.6629  Validation loss = 1.9686  \n",
      "\n",
      "Fold: 24  Epoch: 216  Training loss = 3.6627  Validation loss = 1.9680  \n",
      "\n",
      "Fold: 24  Epoch: 217  Training loss = 3.6623  Validation loss = 1.9672  \n",
      "\n",
      "Fold: 24  Epoch: 218  Training loss = 3.6619  Validation loss = 1.9667  \n",
      "\n",
      "Fold: 24  Epoch: 219  Training loss = 3.6616  Validation loss = 1.9662  \n",
      "\n",
      "Fold: 24  Epoch: 220  Training loss = 3.6613  Validation loss = 1.9657  \n",
      "\n",
      "Fold: 24  Epoch: 221  Training loss = 3.6610  Validation loss = 1.9654  \n",
      "\n",
      "Fold: 24  Epoch: 222  Training loss = 3.6607  Validation loss = 1.9647  \n",
      "\n",
      "Fold: 24  Epoch: 223  Training loss = 3.6605  Validation loss = 1.9644  \n",
      "\n",
      "Fold: 24  Epoch: 224  Training loss = 3.6602  Validation loss = 1.9642  \n",
      "\n",
      "Fold: 24  Epoch: 225  Training loss = 3.6600  Validation loss = 1.9641  \n",
      "\n",
      "Fold: 24  Epoch: 226  Training loss = 3.6596  Validation loss = 1.9636  \n",
      "\n",
      "Fold: 24  Epoch: 227  Training loss = 3.6592  Validation loss = 1.9632  \n",
      "\n",
      "Fold: 24  Epoch: 228  Training loss = 3.6590  Validation loss = 1.9630  \n",
      "\n",
      "Fold: 24  Epoch: 229  Training loss = 3.6587  Validation loss = 1.9626  \n",
      "\n",
      "Fold: 24  Epoch: 230  Training loss = 3.6585  Validation loss = 1.9624  \n",
      "\n",
      "Fold: 24  Epoch: 231  Training loss = 3.6581  Validation loss = 1.9617  \n",
      "\n",
      "Fold: 24  Epoch: 232  Training loss = 3.6578  Validation loss = 1.9613  \n",
      "\n",
      "Fold: 24  Epoch: 233  Training loss = 3.6575  Validation loss = 1.9609  \n",
      "\n",
      "Fold: 24  Epoch: 234  Training loss = 3.6573  Validation loss = 1.9604  \n",
      "\n",
      "Fold: 24  Epoch: 235  Training loss = 3.6572  Validation loss = 1.9603  \n",
      "\n",
      "Fold: 24  Epoch: 236  Training loss = 3.6569  Validation loss = 1.9600  \n",
      "\n",
      "Fold: 24  Epoch: 237  Training loss = 3.6565  Validation loss = 1.9595  \n",
      "\n",
      "Fold: 24  Epoch: 238  Training loss = 3.6563  Validation loss = 1.9591  \n",
      "\n",
      "Fold: 24  Epoch: 239  Training loss = 3.6562  Validation loss = 1.9588  \n",
      "\n",
      "Fold: 24  Epoch: 240  Training loss = 3.6559  Validation loss = 1.9586  \n",
      "\n",
      "Fold: 24  Epoch: 241  Training loss = 3.6556  Validation loss = 1.9579  \n",
      "\n",
      "Fold: 24  Epoch: 242  Training loss = 3.6555  Validation loss = 1.9578  \n",
      "\n",
      "Fold: 24  Epoch: 243  Training loss = 3.6550  Validation loss = 1.9573  \n",
      "\n",
      "Fold: 24  Epoch: 244  Training loss = 3.6548  Validation loss = 1.9569  \n",
      "\n",
      "Fold: 24  Epoch: 245  Training loss = 3.6546  Validation loss = 1.9566  \n",
      "\n",
      "Fold: 24  Epoch: 246  Training loss = 3.6542  Validation loss = 1.9561  \n",
      "\n",
      "Fold: 24  Epoch: 247  Training loss = 3.6539  Validation loss = 1.9559  \n",
      "\n",
      "Fold: 24  Epoch: 248  Training loss = 3.6535  Validation loss = 1.9554  \n",
      "\n",
      "Fold: 24  Epoch: 249  Training loss = 3.6533  Validation loss = 1.9548  \n",
      "\n",
      "Fold: 24  Epoch: 250  Training loss = 3.6529  Validation loss = 1.9542  \n",
      "\n",
      "Fold: 24  Epoch: 251  Training loss = 3.6526  Validation loss = 1.9538  \n",
      "\n",
      "Fold: 24  Epoch: 252  Training loss = 3.6523  Validation loss = 1.9535  \n",
      "\n",
      "Fold: 24  Epoch: 253  Training loss = 3.6521  Validation loss = 1.9531  \n",
      "\n",
      "Fold: 24  Epoch: 254  Training loss = 3.6519  Validation loss = 1.9525  \n",
      "\n",
      "Fold: 24  Epoch: 255  Training loss = 3.6515  Validation loss = 1.9521  \n",
      "\n",
      "Fold: 24  Epoch: 256  Training loss = 3.6513  Validation loss = 1.9514  \n",
      "\n",
      "Fold: 24  Epoch: 257  Training loss = 3.6511  Validation loss = 1.9510  \n",
      "\n",
      "Fold: 24  Epoch: 258  Training loss = 3.6508  Validation loss = 1.9504  \n",
      "\n",
      "Fold: 24  Epoch: 259  Training loss = 3.6505  Validation loss = 1.9498  \n",
      "\n",
      "Fold: 24  Epoch: 260  Training loss = 3.6501  Validation loss = 1.9494  \n",
      "\n",
      "Fold: 24  Epoch: 261  Training loss = 3.6499  Validation loss = 1.9490  \n",
      "\n",
      "Fold: 24  Epoch: 262  Training loss = 3.6494  Validation loss = 1.9484  \n",
      "\n",
      "Fold: 24  Epoch: 263  Training loss = 3.6492  Validation loss = 1.9479  \n",
      "\n",
      "Fold: 24  Epoch: 264  Training loss = 3.6489  Validation loss = 1.9476  \n",
      "\n",
      "Fold: 24  Epoch: 265  Training loss = 3.6485  Validation loss = 1.9471  \n",
      "\n",
      "Fold: 24  Epoch: 266  Training loss = 3.6483  Validation loss = 1.9469  \n",
      "\n",
      "Fold: 24  Epoch: 267  Training loss = 3.6481  Validation loss = 1.9465  \n",
      "\n",
      "Fold: 24  Epoch: 268  Training loss = 3.6478  Validation loss = 1.9459  \n",
      "\n",
      "Fold: 24  Epoch: 269  Training loss = 3.6476  Validation loss = 1.9456  \n",
      "\n",
      "Fold: 24  Epoch: 270  Training loss = 3.6474  Validation loss = 1.9455  \n",
      "\n",
      "Fold: 24  Epoch: 271  Training loss = 3.6472  Validation loss = 1.9452  \n",
      "\n",
      "Fold: 24  Epoch: 272  Training loss = 3.6469  Validation loss = 1.9448  \n",
      "\n",
      "Fold: 24  Epoch: 273  Training loss = 3.6466  Validation loss = 1.9443  \n",
      "\n",
      "Fold: 24  Epoch: 274  Training loss = 3.6462  Validation loss = 1.9435  \n",
      "\n",
      "Fold: 24  Epoch: 275  Training loss = 3.6460  Validation loss = 1.9428  \n",
      "\n",
      "Fold: 24  Epoch: 276  Training loss = 3.6458  Validation loss = 1.9424  \n",
      "\n",
      "Fold: 24  Epoch: 277  Training loss = 3.6454  Validation loss = 1.9417  \n",
      "\n",
      "Fold: 24  Epoch: 278  Training loss = 3.6451  Validation loss = 1.9412  \n",
      "\n",
      "Fold: 24  Epoch: 279  Training loss = 3.6447  Validation loss = 1.9405  \n",
      "\n",
      "Fold: 24  Epoch: 280  Training loss = 3.6443  Validation loss = 1.9400  \n",
      "\n",
      "Fold: 24  Epoch: 281  Training loss = 3.6440  Validation loss = 1.9393  \n",
      "\n",
      "Fold: 24  Epoch: 282  Training loss = 3.6436  Validation loss = 1.9385  \n",
      "\n",
      "Fold: 24  Epoch: 283  Training loss = 3.6434  Validation loss = 1.9382  \n",
      "\n",
      "Fold: 24  Epoch: 284  Training loss = 3.6430  Validation loss = 1.9378  \n",
      "\n",
      "Fold: 24  Epoch: 285  Training loss = 3.6428  Validation loss = 1.9376  \n",
      "\n",
      "Fold: 24  Epoch: 286  Training loss = 3.6426  Validation loss = 1.9370  \n",
      "\n",
      "Fold: 24  Epoch: 287  Training loss = 3.6426  Validation loss = 1.9367  \n",
      "\n",
      "Fold: 24  Epoch: 288  Training loss = 3.6424  Validation loss = 1.9364  \n",
      "\n",
      "Fold: 24  Epoch: 289  Training loss = 3.6421  Validation loss = 1.9359  \n",
      "\n",
      "Fold: 24  Epoch: 290  Training loss = 3.6417  Validation loss = 1.9351  \n",
      "\n",
      "Fold: 24  Epoch: 291  Training loss = 3.6414  Validation loss = 1.9348  \n",
      "\n",
      "Fold: 24  Epoch: 292  Training loss = 3.6411  Validation loss = 1.9344  \n",
      "\n",
      "Fold: 24  Epoch: 293  Training loss = 3.6410  Validation loss = 1.9339  \n",
      "\n",
      "Fold: 24  Epoch: 294  Training loss = 3.6407  Validation loss = 1.9333  \n",
      "\n",
      "Fold: 24  Epoch: 295  Training loss = 3.6405  Validation loss = 1.9327  \n",
      "\n",
      "Fold: 24  Epoch: 296  Training loss = 3.6402  Validation loss = 1.9323  \n",
      "\n",
      "Fold: 24  Epoch: 297  Training loss = 3.6399  Validation loss = 1.9317  \n",
      "\n",
      "Fold: 24  Epoch: 298  Training loss = 3.6396  Validation loss = 1.9311  \n",
      "\n",
      "Fold: 24  Epoch: 299  Training loss = 3.6394  Validation loss = 1.9308  \n",
      "\n",
      "Fold: 24  Epoch: 300  Training loss = 3.6391  Validation loss = 1.9304  \n",
      "\n",
      "Fold: 24  Epoch: 301  Training loss = 3.6389  Validation loss = 1.9303  \n",
      "\n",
      "Fold: 24  Epoch: 302  Training loss = 3.6386  Validation loss = 1.9295  \n",
      "\n",
      "Fold: 24  Epoch: 303  Training loss = 3.6383  Validation loss = 1.9289  \n",
      "\n",
      "Fold: 24  Epoch: 304  Training loss = 3.6380  Validation loss = 1.9283  \n",
      "\n",
      "Fold: 24  Epoch: 305  Training loss = 3.6378  Validation loss = 1.9278  \n",
      "\n",
      "Fold: 24  Epoch: 306  Training loss = 3.6375  Validation loss = 1.9273  \n",
      "\n",
      "Fold: 24  Epoch: 307  Training loss = 3.6373  Validation loss = 1.9271  \n",
      "\n",
      "Fold: 24  Epoch: 308  Training loss = 3.6371  Validation loss = 1.9266  \n",
      "\n",
      "Fold: 24  Epoch: 309  Training loss = 3.6367  Validation loss = 1.9259  \n",
      "\n",
      "Fold: 24  Epoch: 310  Training loss = 3.6366  Validation loss = 1.9258  \n",
      "\n",
      "Fold: 24  Epoch: 311  Training loss = 3.6364  Validation loss = 1.9252  \n",
      "\n",
      "Fold: 24  Epoch: 312  Training loss = 3.6360  Validation loss = 1.9247  \n",
      "\n",
      "Fold: 24  Epoch: 313  Training loss = 3.6357  Validation loss = 1.9244  \n",
      "\n",
      "Fold: 24  Epoch: 314  Training loss = 3.6353  Validation loss = 1.9239  \n",
      "\n",
      "Fold: 24  Epoch: 315  Training loss = 3.6349  Validation loss = 1.9233  \n",
      "\n",
      "Fold: 24  Epoch: 316  Training loss = 3.6346  Validation loss = 1.9229  \n",
      "\n",
      "Fold: 24  Epoch: 317  Training loss = 3.6343  Validation loss = 1.9222  \n",
      "\n",
      "Fold: 24  Epoch: 318  Training loss = 3.6340  Validation loss = 1.9219  \n",
      "\n",
      "Fold: 24  Epoch: 319  Training loss = 3.6337  Validation loss = 1.9217  \n",
      "\n",
      "Fold: 24  Epoch: 320  Training loss = 3.6335  Validation loss = 1.9212  \n",
      "\n",
      "Fold: 24  Epoch: 321  Training loss = 3.6332  Validation loss = 1.9208  \n",
      "\n",
      "Fold: 24  Epoch: 322  Training loss = 3.6328  Validation loss = 1.9203  \n",
      "\n",
      "Fold: 24  Epoch: 323  Training loss = 3.6326  Validation loss = 1.9198  \n",
      "\n",
      "Fold: 24  Epoch: 324  Training loss = 3.6324  Validation loss = 1.9194  \n",
      "\n",
      "Fold: 24  Epoch: 325  Training loss = 3.6320  Validation loss = 1.9188  \n",
      "\n",
      "Fold: 24  Epoch: 326  Training loss = 3.6318  Validation loss = 1.9184  \n",
      "\n",
      "Fold: 24  Epoch: 327  Training loss = 3.6314  Validation loss = 1.9182  \n",
      "\n",
      "Fold: 24  Epoch: 328  Training loss = 3.6312  Validation loss = 1.9177  \n",
      "\n",
      "Fold: 24  Epoch: 329  Training loss = 3.6309  Validation loss = 1.9174  \n",
      "\n",
      "Fold: 24  Epoch: 330  Training loss = 3.6306  Validation loss = 1.9168  \n",
      "\n",
      "Fold: 24  Epoch: 331  Training loss = 3.6303  Validation loss = 1.9166  \n",
      "\n",
      "Fold: 24  Epoch: 332  Training loss = 3.6300  Validation loss = 1.9161  \n",
      "\n",
      "Fold: 24  Epoch: 333  Training loss = 3.6297  Validation loss = 1.9156  \n",
      "\n",
      "Fold: 24  Epoch: 334  Training loss = 3.6296  Validation loss = 1.9156  \n",
      "\n",
      "Fold: 24  Epoch: 335  Training loss = 3.6294  Validation loss = 1.9153  \n",
      "\n",
      "Fold: 24  Epoch: 336  Training loss = 3.6290  Validation loss = 1.9148  \n",
      "\n",
      "Fold: 24  Epoch: 337  Training loss = 3.6287  Validation loss = 1.9143  \n",
      "\n",
      "Fold: 24  Epoch: 338  Training loss = 3.6284  Validation loss = 1.9135  \n",
      "\n",
      "Fold: 24  Epoch: 339  Training loss = 3.6281  Validation loss = 1.9126  \n",
      "\n",
      "Fold: 24  Epoch: 340  Training loss = 3.6278  Validation loss = 1.9123  \n",
      "\n",
      "Fold: 24  Epoch: 341  Training loss = 3.6277  Validation loss = 1.9120  \n",
      "\n",
      "Fold: 24  Epoch: 342  Training loss = 3.6275  Validation loss = 1.9119  \n",
      "\n",
      "Fold: 24  Epoch: 343  Training loss = 3.6273  Validation loss = 1.9117  \n",
      "\n",
      "Fold: 24  Epoch: 344  Training loss = 3.6272  Validation loss = 1.9115  \n",
      "\n",
      "Fold: 24  Epoch: 345  Training loss = 3.6269  Validation loss = 1.9111  \n",
      "\n",
      "Fold: 24  Epoch: 346  Training loss = 3.6265  Validation loss = 1.9103  \n",
      "\n",
      "Fold: 24  Epoch: 347  Training loss = 3.6263  Validation loss = 1.9099  \n",
      "\n",
      "Fold: 24  Epoch: 348  Training loss = 3.6261  Validation loss = 1.9098  \n",
      "\n",
      "Fold: 24  Epoch: 349  Training loss = 3.6258  Validation loss = 1.9094  \n",
      "\n",
      "Fold: 24  Epoch: 350  Training loss = 3.6255  Validation loss = 1.9088  \n",
      "\n",
      "Fold: 24  Epoch: 351  Training loss = 3.6252  Validation loss = 1.9084  \n",
      "\n",
      "Fold: 24  Epoch: 352  Training loss = 3.6250  Validation loss = 1.9080  \n",
      "\n",
      "Fold: 24  Epoch: 353  Training loss = 3.6248  Validation loss = 1.9076  \n",
      "\n",
      "Fold: 24  Epoch: 354  Training loss = 3.6245  Validation loss = 1.9071  \n",
      "\n",
      "Fold: 24  Epoch: 355  Training loss = 3.6242  Validation loss = 1.9065  \n",
      "\n",
      "Fold: 24  Epoch: 356  Training loss = 3.6240  Validation loss = 1.9062  \n",
      "\n",
      "Fold: 24  Epoch: 357  Training loss = 3.6238  Validation loss = 1.9059  \n",
      "\n",
      "Fold: 24  Epoch: 358  Training loss = 3.6235  Validation loss = 1.9056  \n",
      "\n",
      "Fold: 24  Epoch: 359  Training loss = 3.6233  Validation loss = 1.9053  \n",
      "\n",
      "Fold: 24  Epoch: 360  Training loss = 3.6231  Validation loss = 1.9047  \n",
      "\n",
      "Fold: 24  Epoch: 361  Training loss = 3.6228  Validation loss = 1.9043  \n",
      "\n",
      "Fold: 24  Epoch: 362  Training loss = 3.6225  Validation loss = 1.9035  \n",
      "\n",
      "Fold: 24  Epoch: 363  Training loss = 3.6223  Validation loss = 1.9031  \n",
      "\n",
      "Fold: 24  Epoch: 364  Training loss = 3.6219  Validation loss = 1.9027  \n",
      "\n",
      "Fold: 24  Epoch: 365  Training loss = 3.6216  Validation loss = 1.9022  \n",
      "\n",
      "Fold: 24  Epoch: 366  Training loss = 3.6214  Validation loss = 1.9017  \n",
      "\n",
      "Fold: 24  Epoch: 367  Training loss = 3.6212  Validation loss = 1.9010  \n",
      "\n",
      "Fold: 24  Epoch: 368  Training loss = 3.6208  Validation loss = 1.9004  \n",
      "\n",
      "Fold: 24  Epoch: 369  Training loss = 3.6207  Validation loss = 1.9002  \n",
      "\n",
      "Fold: 24  Epoch: 370  Training loss = 3.6204  Validation loss = 1.8994  \n",
      "\n",
      "Fold: 24  Epoch: 371  Training loss = 3.6201  Validation loss = 1.8991  \n",
      "\n",
      "Fold: 24  Epoch: 372  Training loss = 3.6199  Validation loss = 1.8986  \n",
      "\n",
      "Fold: 24  Epoch: 373  Training loss = 3.6196  Validation loss = 1.8983  \n",
      "\n",
      "Fold: 24  Epoch: 374  Training loss = 3.6193  Validation loss = 1.8979  \n",
      "\n",
      "Fold: 24  Epoch: 375  Training loss = 3.6193  Validation loss = 1.8977  \n",
      "\n",
      "Fold: 24  Epoch: 376  Training loss = 3.6189  Validation loss = 1.8972  \n",
      "\n",
      "Fold: 24  Epoch: 377  Training loss = 3.6187  Validation loss = 1.8966  \n",
      "\n",
      "Fold: 24  Epoch: 378  Training loss = 3.6185  Validation loss = 1.8960  \n",
      "\n",
      "Fold: 24  Epoch: 379  Training loss = 3.6182  Validation loss = 1.8954  \n",
      "\n",
      "Fold: 24  Epoch: 380  Training loss = 3.6180  Validation loss = 1.8948  \n",
      "\n",
      "Fold: 24  Epoch: 381  Training loss = 3.6179  Validation loss = 1.8945  \n",
      "\n",
      "Fold: 24  Epoch: 382  Training loss = 3.6177  Validation loss = 1.8944  \n",
      "\n",
      "Fold: 24  Epoch: 383  Training loss = 3.6174  Validation loss = 1.8939  \n",
      "\n",
      "Fold: 24  Epoch: 384  Training loss = 3.6171  Validation loss = 1.8935  \n",
      "\n",
      "Fold: 24  Epoch: 385  Training loss = 3.6168  Validation loss = 1.8931  \n",
      "\n",
      "Fold: 24  Epoch: 386  Training loss = 3.6165  Validation loss = 1.8927  \n",
      "\n",
      "Fold: 24  Epoch: 387  Training loss = 3.6162  Validation loss = 1.8921  \n",
      "\n",
      "Fold: 24  Epoch: 388  Training loss = 3.6159  Validation loss = 1.8917  \n",
      "\n",
      "Fold: 24  Epoch: 389  Training loss = 3.6157  Validation loss = 1.8913  \n",
      "\n",
      "Fold: 24  Epoch: 390  Training loss = 3.6153  Validation loss = 1.8905  \n",
      "\n",
      "Fold: 24  Epoch: 391  Training loss = 3.6151  Validation loss = 1.8903  \n",
      "\n",
      "Fold: 24  Epoch: 392  Training loss = 3.6149  Validation loss = 1.8900  \n",
      "\n",
      "Fold: 24  Epoch: 393  Training loss = 3.6147  Validation loss = 1.8891  \n",
      "\n",
      "Fold: 24  Epoch: 394  Training loss = 3.6143  Validation loss = 1.8886  \n",
      "\n",
      "Fold: 24  Epoch: 395  Training loss = 3.6142  Validation loss = 1.8881  \n",
      "\n",
      "Fold: 24  Epoch: 396  Training loss = 3.6139  Validation loss = 1.8878  \n",
      "\n",
      "Fold: 24  Epoch: 397  Training loss = 3.6136  Validation loss = 1.8873  \n",
      "\n",
      "Fold: 24  Epoch: 398  Training loss = 3.6134  Validation loss = 1.8866  \n",
      "\n",
      "Fold: 24  Epoch: 399  Training loss = 3.6130  Validation loss = 1.8860  \n",
      "\n",
      "Fold: 24  Epoch: 400  Training loss = 3.6129  Validation loss = 1.8859  \n",
      "\n",
      "Fold: 24  Epoch: 401  Training loss = 3.6127  Validation loss = 1.8855  \n",
      "\n",
      "Fold: 24  Epoch: 402  Training loss = 3.6124  Validation loss = 1.8850  \n",
      "\n",
      "Fold: 24  Epoch: 403  Training loss = 3.6122  Validation loss = 1.8848  \n",
      "\n",
      "Fold: 24  Epoch: 404  Training loss = 3.6120  Validation loss = 1.8841  \n",
      "\n",
      "Fold: 24  Epoch: 405  Training loss = 3.6117  Validation loss = 1.8837  \n",
      "\n",
      "Fold: 24  Epoch: 406  Training loss = 3.6114  Validation loss = 1.8833  \n",
      "\n",
      "Fold: 24  Epoch: 407  Training loss = 3.6112  Validation loss = 1.8831  \n",
      "\n",
      "Fold: 24  Epoch: 408  Training loss = 3.6111  Validation loss = 1.8830  \n",
      "\n",
      "Fold: 24  Epoch: 409  Training loss = 3.6108  Validation loss = 1.8824  \n",
      "\n",
      "Fold: 24  Epoch: 410  Training loss = 3.6105  Validation loss = 1.8819  \n",
      "\n",
      "Fold: 24  Epoch: 411  Training loss = 3.6102  Validation loss = 1.8818  \n",
      "\n",
      "Fold: 24  Epoch: 412  Training loss = 3.6098  Validation loss = 1.8814  \n",
      "\n",
      "Fold: 24  Epoch: 413  Training loss = 3.6096  Validation loss = 1.8809  \n",
      "\n",
      "Fold: 24  Epoch: 414  Training loss = 3.6094  Validation loss = 1.8807  \n",
      "\n",
      "Fold: 24  Epoch: 415  Training loss = 3.6090  Validation loss = 1.8803  \n",
      "\n",
      "Fold: 24  Epoch: 416  Training loss = 3.6086  Validation loss = 1.8793  \n",
      "\n",
      "Fold: 24  Epoch: 417  Training loss = 3.6083  Validation loss = 1.8789  \n",
      "\n",
      "Fold: 24  Epoch: 418  Training loss = 3.6079  Validation loss = 1.8785  \n",
      "\n",
      "Fold: 24  Epoch: 419  Training loss = 3.6076  Validation loss = 1.8782  \n",
      "\n",
      "Fold: 24  Epoch: 420  Training loss = 3.6075  Validation loss = 1.8780  \n",
      "\n",
      "Fold: 24  Epoch: 421  Training loss = 3.6071  Validation loss = 1.8776  \n",
      "\n",
      "Fold: 24  Epoch: 422  Training loss = 3.6067  Validation loss = 1.8771  \n",
      "\n",
      "Fold: 24  Epoch: 423  Training loss = 3.6064  Validation loss = 1.8767  \n",
      "\n",
      "Fold: 24  Epoch: 424  Training loss = 3.6061  Validation loss = 1.8762  \n",
      "\n",
      "Fold: 24  Epoch: 425  Training loss = 3.6057  Validation loss = 1.8757  \n",
      "\n",
      "Fold: 24  Epoch: 426  Training loss = 3.6055  Validation loss = 1.8752  \n",
      "\n",
      "Fold: 24  Epoch: 427  Training loss = 3.6052  Validation loss = 1.8745  \n",
      "\n",
      "Fold: 24  Epoch: 428  Training loss = 3.6050  Validation loss = 1.8741  \n",
      "\n",
      "Fold: 24  Epoch: 429  Training loss = 3.6048  Validation loss = 1.8736  \n",
      "\n",
      "Fold: 24  Epoch: 430  Training loss = 3.6045  Validation loss = 1.8732  \n",
      "\n",
      "Fold: 24  Epoch: 431  Training loss = 3.6043  Validation loss = 1.8729  \n",
      "\n",
      "Fold: 24  Epoch: 432  Training loss = 3.6041  Validation loss = 1.8728  \n",
      "\n",
      "Fold: 24  Epoch: 433  Training loss = 3.6039  Validation loss = 1.8727  \n",
      "\n",
      "Fold: 24  Epoch: 434  Training loss = 3.6036  Validation loss = 1.8721  \n",
      "\n",
      "Fold: 24  Epoch: 435  Training loss = 3.6035  Validation loss = 1.8719  \n",
      "\n",
      "Fold: 24  Epoch: 436  Training loss = 3.6033  Validation loss = 1.8716  \n",
      "\n",
      "Fold: 24  Epoch: 437  Training loss = 3.6030  Validation loss = 1.8713  \n",
      "\n",
      "Fold: 24  Epoch: 438  Training loss = 3.6028  Validation loss = 1.8709  \n",
      "\n",
      "Fold: 24  Epoch: 439  Training loss = 3.6024  Validation loss = 1.8705  \n",
      "\n",
      "Fold: 24  Epoch: 440  Training loss = 3.6022  Validation loss = 1.8699  \n",
      "\n",
      "Fold: 24  Epoch: 441  Training loss = 3.6020  Validation loss = 1.8695  \n",
      "\n",
      "Fold: 24  Epoch: 442  Training loss = 3.6017  Validation loss = 1.8693  \n",
      "\n",
      "Fold: 24  Epoch: 443  Training loss = 3.6014  Validation loss = 1.8691  \n",
      "\n",
      "Fold: 24  Epoch: 444  Training loss = 3.6012  Validation loss = 1.8689  \n",
      "\n",
      "Fold: 24  Epoch: 445  Training loss = 3.6009  Validation loss = 1.8684  \n",
      "\n",
      "Fold: 24  Epoch: 446  Training loss = 3.6006  Validation loss = 1.8675  \n",
      "\n",
      "Fold: 24  Epoch: 447  Training loss = 3.6003  Validation loss = 1.8670  \n",
      "\n",
      "Fold: 24  Epoch: 448  Training loss = 3.6001  Validation loss = 1.8666  \n",
      "\n",
      "Fold: 24  Epoch: 449  Training loss = 3.5997  Validation loss = 1.8664  \n",
      "\n",
      "Fold: 24  Epoch: 450  Training loss = 3.5995  Validation loss = 1.8660  \n",
      "\n",
      "Fold: 24  Epoch: 451  Training loss = 3.5992  Validation loss = 1.8655  \n",
      "\n",
      "Fold: 24  Epoch: 452  Training loss = 3.5990  Validation loss = 1.8653  \n",
      "\n",
      "Fold: 24  Epoch: 453  Training loss = 3.5987  Validation loss = 1.8649  \n",
      "\n",
      "Fold: 24  Epoch: 454  Training loss = 3.5984  Validation loss = 1.8641  \n",
      "\n",
      "Fold: 24  Epoch: 455  Training loss = 3.5981  Validation loss = 1.8638  \n",
      "\n",
      "Fold: 24  Epoch: 456  Training loss = 3.5979  Validation loss = 1.8635  \n",
      "\n",
      "Fold: 24  Epoch: 457  Training loss = 3.5976  Validation loss = 1.8632  \n",
      "\n",
      "Fold: 24  Epoch: 458  Training loss = 3.5973  Validation loss = 1.8629  \n",
      "\n",
      "Fold: 24  Epoch: 459  Training loss = 3.5971  Validation loss = 1.8627  \n",
      "\n",
      "Fold: 24  Epoch: 460  Training loss = 3.5969  Validation loss = 1.8625  \n",
      "\n",
      "Fold: 24  Epoch: 461  Training loss = 3.5968  Validation loss = 1.8622  \n",
      "\n",
      "Fold: 24  Epoch: 462  Training loss = 3.5965  Validation loss = 1.8620  \n",
      "\n",
      "Fold: 24  Epoch: 463  Training loss = 3.5963  Validation loss = 1.8619  \n",
      "\n",
      "Fold: 24  Epoch: 464  Training loss = 3.5961  Validation loss = 1.8615  \n",
      "\n",
      "Fold: 24  Epoch: 465  Training loss = 3.5959  Validation loss = 1.8612  \n",
      "\n",
      "Fold: 24  Epoch: 466  Training loss = 3.5956  Validation loss = 1.8608  \n",
      "\n",
      "Fold: 24  Epoch: 467  Training loss = 3.5953  Validation loss = 1.8604  \n",
      "\n",
      "Fold: 24  Epoch: 468  Training loss = 3.5950  Validation loss = 1.8600  \n",
      "\n",
      "Fold: 24  Epoch: 469  Training loss = 3.5948  Validation loss = 1.8596  \n",
      "\n",
      "Fold: 24  Epoch: 470  Training loss = 3.5945  Validation loss = 1.8593  \n",
      "\n",
      "Fold: 24  Epoch: 471  Training loss = 3.5942  Validation loss = 1.8587  \n",
      "\n",
      "Fold: 24  Epoch: 472  Training loss = 3.5939  Validation loss = 1.8585  \n",
      "\n",
      "Fold: 24  Epoch: 473  Training loss = 3.5936  Validation loss = 1.8578  \n",
      "\n",
      "Fold: 24  Epoch: 474  Training loss = 3.5933  Validation loss = 1.8573  \n",
      "\n",
      "Fold: 24  Epoch: 475  Training loss = 3.5931  Validation loss = 1.8573  \n",
      "\n",
      "Fold: 24  Epoch: 476  Training loss = 3.5928  Validation loss = 1.8567  \n",
      "\n",
      "Fold: 24  Epoch: 477  Training loss = 3.5925  Validation loss = 1.8561  \n",
      "\n",
      "Fold: 24  Epoch: 478  Training loss = 3.5923  Validation loss = 1.8557  \n",
      "\n",
      "Fold: 24  Epoch: 479  Training loss = 3.5920  Validation loss = 1.8551  \n",
      "\n",
      "Fold: 24  Epoch: 480  Training loss = 3.5918  Validation loss = 1.8548  \n",
      "\n",
      "Fold: 24  Epoch: 481  Training loss = 3.5915  Validation loss = 1.8545  \n",
      "\n",
      "Fold: 24  Epoch: 482  Training loss = 3.5910  Validation loss = 1.8540  \n",
      "\n",
      "Fold: 24  Epoch: 483  Training loss = 3.5908  Validation loss = 1.8536  \n",
      "\n",
      "Fold: 24  Epoch: 484  Training loss = 3.5905  Validation loss = 1.8534  \n",
      "\n",
      "Fold: 24  Epoch: 485  Training loss = 3.5902  Validation loss = 1.8531  \n",
      "\n",
      "Fold: 24  Epoch: 486  Training loss = 3.5900  Validation loss = 1.8525  \n",
      "\n",
      "Fold: 24  Epoch: 487  Training loss = 3.5897  Validation loss = 1.8518  \n",
      "\n",
      "Fold: 24  Epoch: 488  Training loss = 3.5896  Validation loss = 1.8515  \n",
      "\n",
      "Fold: 24  Epoch: 489  Training loss = 3.5892  Validation loss = 1.8510  \n",
      "\n",
      "Fold: 24  Epoch: 490  Training loss = 3.5890  Validation loss = 1.8504  \n",
      "\n",
      "Fold: 24  Epoch: 491  Training loss = 3.5887  Validation loss = 1.8501  \n",
      "\n",
      "Fold: 24  Epoch: 492  Training loss = 3.5886  Validation loss = 1.8497  \n",
      "\n",
      "Fold: 24  Epoch: 493  Training loss = 3.5884  Validation loss = 1.8495  \n",
      "\n",
      "Fold: 24  Epoch: 494  Training loss = 3.5880  Validation loss = 1.8491  \n",
      "\n",
      "Fold: 24  Epoch: 495  Training loss = 3.5877  Validation loss = 1.8487  \n",
      "\n",
      "Fold: 24  Epoch: 496  Training loss = 3.5874  Validation loss = 1.8479  \n",
      "\n",
      "Fold: 24  Epoch: 497  Training loss = 3.5871  Validation loss = 1.8474  \n",
      "\n",
      "Fold: 24  Epoch: 498  Training loss = 3.5869  Validation loss = 1.8470  \n",
      "\n",
      "Fold: 24  Epoch: 499  Training loss = 3.5867  Validation loss = 1.8467  \n",
      "\n",
      "Fold: 24  Epoch: 500  Training loss = 3.5864  Validation loss = 1.8461  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 500  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 3.5636  Validation loss = 2.6001  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 3.5635  Validation loss = 2.6001  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 3.5632  Validation loss = 2.5998  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 3.5631  Validation loss = 2.5997  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 3.5628  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 3.5624  Validation loss = 2.5995  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 3.5622  Validation loss = 2.5994  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 3.5618  Validation loss = 2.5991  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 3.5616  Validation loss = 2.5990  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 3.5612  Validation loss = 2.5989  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 3.5610  Validation loss = 2.5989  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 3.5608  Validation loss = 2.5988  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 3.5605  Validation loss = 2.5987  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 3.5602  Validation loss = 2.5986  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 3.5599  Validation loss = 2.5987  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 3.5595  Validation loss = 2.5986  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 3.5592  Validation loss = 2.5982  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 3.5590  Validation loss = 2.5978  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 3.5586  Validation loss = 2.5975  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 3.5585  Validation loss = 2.5971  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 3.5583  Validation loss = 2.5970  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 3.5580  Validation loss = 2.5969  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 3.5578  Validation loss = 2.5969  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 3.5576  Validation loss = 2.5969  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 3.5573  Validation loss = 2.5967  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 3.5570  Validation loss = 2.5967  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 3.5568  Validation loss = 2.5964  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 3.5566  Validation loss = 2.5964  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 3.5564  Validation loss = 2.5963  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 3.5562  Validation loss = 2.5963  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 3.5559  Validation loss = 2.5959  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 3.5557  Validation loss = 2.5958  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 3.5555  Validation loss = 2.5956  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 3.5552  Validation loss = 2.5955  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 3.5548  Validation loss = 2.5957  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 3.5545  Validation loss = 2.5955  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 3.5542  Validation loss = 2.5953  \n",
      "\n",
      "Fold: 25  Epoch: 38  Training loss = 3.5540  Validation loss = 2.5950  \n",
      "\n",
      "Fold: 25  Epoch: 39  Training loss = 3.5538  Validation loss = 2.5949  \n",
      "\n",
      "Fold: 25  Epoch: 40  Training loss = 3.5534  Validation loss = 2.5947  \n",
      "\n",
      "Fold: 25  Epoch: 41  Training loss = 3.5533  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 25  Epoch: 42  Training loss = 3.5531  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 25  Epoch: 43  Training loss = 3.5528  Validation loss = 2.5941  \n",
      "\n",
      "Fold: 25  Epoch: 44  Training loss = 3.5526  Validation loss = 2.5939  \n",
      "\n",
      "Fold: 25  Epoch: 45  Training loss = 3.5523  Validation loss = 2.5937  \n",
      "\n",
      "Fold: 25  Epoch: 46  Training loss = 3.5520  Validation loss = 2.5939  \n",
      "\n",
      "Fold: 25  Epoch: 47  Training loss = 3.5518  Validation loss = 2.5936  \n",
      "\n",
      "Fold: 25  Epoch: 48  Training loss = 3.5515  Validation loss = 2.5935  \n",
      "\n",
      "Fold: 25  Epoch: 49  Training loss = 3.5513  Validation loss = 2.5935  \n",
      "\n",
      "Fold: 25  Epoch: 50  Training loss = 3.5510  Validation loss = 2.5934  \n",
      "\n",
      "Fold: 25  Epoch: 51  Training loss = 3.5508  Validation loss = 2.5933  \n",
      "\n",
      "Fold: 25  Epoch: 52  Training loss = 3.5505  Validation loss = 2.5933  \n",
      "\n",
      "Fold: 25  Epoch: 53  Training loss = 3.5504  Validation loss = 2.5932  \n",
      "\n",
      "Fold: 25  Epoch: 54  Training loss = 3.5501  Validation loss = 2.5930  \n",
      "\n",
      "Fold: 25  Epoch: 55  Training loss = 3.5499  Validation loss = 2.5929  \n",
      "\n",
      "Fold: 25  Epoch: 56  Training loss = 3.5495  Validation loss = 2.5928  \n",
      "\n",
      "Fold: 25  Epoch: 57  Training loss = 3.5492  Validation loss = 2.5926  \n",
      "\n",
      "Fold: 25  Epoch: 58  Training loss = 3.5491  Validation loss = 2.5924  \n",
      "\n",
      "Fold: 25  Epoch: 59  Training loss = 3.5488  Validation loss = 2.5925  \n",
      "\n",
      "Fold: 25  Epoch: 60  Training loss = 3.5485  Validation loss = 2.5923  \n",
      "\n",
      "Fold: 25  Epoch: 61  Training loss = 3.5483  Validation loss = 2.5922  \n",
      "\n",
      "Fold: 25  Epoch: 62  Training loss = 3.5480  Validation loss = 2.5923  \n",
      "\n",
      "Fold: 25  Epoch: 63  Training loss = 3.5478  Validation loss = 2.5923  \n",
      "\n",
      "Fold: 25  Epoch: 64  Training loss = 3.5476  Validation loss = 2.5921  \n",
      "\n",
      "Fold: 25  Epoch: 65  Training loss = 3.5472  Validation loss = 2.5919  \n",
      "\n",
      "Fold: 25  Epoch: 66  Training loss = 3.5469  Validation loss = 2.5918  \n",
      "\n",
      "Fold: 25  Epoch: 67  Training loss = 3.5466  Validation loss = 2.5916  \n",
      "\n",
      "Fold: 25  Epoch: 68  Training loss = 3.5464  Validation loss = 2.5915  \n",
      "\n",
      "Fold: 25  Epoch: 69  Training loss = 3.5461  Validation loss = 2.5913  \n",
      "\n",
      "Fold: 25  Epoch: 70  Training loss = 3.5459  Validation loss = 2.5911  \n",
      "\n",
      "Fold: 25  Epoch: 71  Training loss = 3.5457  Validation loss = 2.5910  \n",
      "\n",
      "Fold: 25  Epoch: 72  Training loss = 3.5454  Validation loss = 2.5907  \n",
      "\n",
      "Fold: 25  Epoch: 73  Training loss = 3.5451  Validation loss = 2.5906  \n",
      "\n",
      "Fold: 25  Epoch: 74  Training loss = 3.5450  Validation loss = 2.5903  \n",
      "\n",
      "Fold: 25  Epoch: 75  Training loss = 3.5447  Validation loss = 2.5902  \n",
      "\n",
      "Fold: 25  Epoch: 76  Training loss = 3.5444  Validation loss = 2.5901  \n",
      "\n",
      "Fold: 25  Epoch: 77  Training loss = 3.5443  Validation loss = 2.5899  \n",
      "\n",
      "Fold: 25  Epoch: 78  Training loss = 3.5440  Validation loss = 2.5896  \n",
      "\n",
      "Fold: 25  Epoch: 79  Training loss = 3.5437  Validation loss = 2.5897  \n",
      "\n",
      "Fold: 25  Epoch: 80  Training loss = 3.5434  Validation loss = 2.5895  \n",
      "\n",
      "Fold: 25  Epoch: 81  Training loss = 3.5431  Validation loss = 2.5894  \n",
      "\n",
      "Fold: 25  Epoch: 82  Training loss = 3.5430  Validation loss = 2.5892  \n",
      "\n",
      "Fold: 25  Epoch: 83  Training loss = 3.5427  Validation loss = 2.5892  \n",
      "\n",
      "Fold: 25  Epoch: 84  Training loss = 3.5424  Validation loss = 2.5890  \n",
      "\n",
      "Fold: 25  Epoch: 85  Training loss = 3.5423  Validation loss = 2.5888  \n",
      "\n",
      "Fold: 25  Epoch: 86  Training loss = 3.5421  Validation loss = 2.5886  \n",
      "\n",
      "Fold: 25  Epoch: 87  Training loss = 3.5418  Validation loss = 2.5887  \n",
      "\n",
      "Fold: 25  Epoch: 88  Training loss = 3.5416  Validation loss = 2.5887  \n",
      "\n",
      "Fold: 25  Epoch: 89  Training loss = 3.5413  Validation loss = 2.5884  \n",
      "\n",
      "Fold: 25  Epoch: 90  Training loss = 3.5409  Validation loss = 2.5879  \n",
      "\n",
      "Fold: 25  Epoch: 91  Training loss = 3.5407  Validation loss = 2.5877  \n",
      "\n",
      "Fold: 25  Epoch: 92  Training loss = 3.5404  Validation loss = 2.5877  \n",
      "\n",
      "Fold: 25  Epoch: 93  Training loss = 3.5402  Validation loss = 2.5873  \n",
      "\n",
      "Fold: 25  Epoch: 94  Training loss = 3.5399  Validation loss = 2.5873  \n",
      "\n",
      "Fold: 25  Epoch: 95  Training loss = 3.5396  Validation loss = 2.5871  \n",
      "\n",
      "Fold: 25  Epoch: 96  Training loss = 3.5393  Validation loss = 2.5868  \n",
      "\n",
      "Fold: 25  Epoch: 97  Training loss = 3.5391  Validation loss = 2.5866  \n",
      "\n",
      "Fold: 25  Epoch: 98  Training loss = 3.5388  Validation loss = 2.5863  \n",
      "\n",
      "Fold: 25  Epoch: 99  Training loss = 3.5386  Validation loss = 2.5860  \n",
      "\n",
      "Fold: 25  Epoch: 100  Training loss = 3.5383  Validation loss = 2.5857  \n",
      "\n",
      "Fold: 25  Epoch: 101  Training loss = 3.5381  Validation loss = 2.5857  \n",
      "\n",
      "Fold: 25  Epoch: 102  Training loss = 3.5378  Validation loss = 2.5855  \n",
      "\n",
      "Fold: 25  Epoch: 103  Training loss = 3.5375  Validation loss = 2.5854  \n",
      "\n",
      "Fold: 25  Epoch: 104  Training loss = 3.5374  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 25  Epoch: 105  Training loss = 3.5371  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 25  Epoch: 106  Training loss = 3.5367  Validation loss = 2.5850  \n",
      "\n",
      "Fold: 25  Epoch: 107  Training loss = 3.5365  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 25  Epoch: 108  Training loss = 3.5363  Validation loss = 2.5847  \n",
      "\n",
      "Fold: 25  Epoch: 109  Training loss = 3.5362  Validation loss = 2.5846  \n",
      "\n",
      "Fold: 25  Epoch: 110  Training loss = 3.5360  Validation loss = 2.5844  \n",
      "\n",
      "Fold: 25  Epoch: 111  Training loss = 3.5357  Validation loss = 2.5842  \n",
      "\n",
      "Fold: 25  Epoch: 112  Training loss = 3.5353  Validation loss = 2.5844  \n",
      "\n",
      "Fold: 25  Epoch: 113  Training loss = 3.5351  Validation loss = 2.5843  \n",
      "\n",
      "Fold: 25  Epoch: 114  Training loss = 3.5349  Validation loss = 2.5842  \n",
      "\n",
      "Fold: 25  Epoch: 115  Training loss = 3.5346  Validation loss = 2.5841  \n",
      "\n",
      "Fold: 25  Epoch: 116  Training loss = 3.5344  Validation loss = 2.5841  \n",
      "\n",
      "Fold: 25  Epoch: 117  Training loss = 3.5342  Validation loss = 2.5841  \n",
      "\n",
      "Fold: 25  Epoch: 118  Training loss = 3.5339  Validation loss = 2.5839  \n",
      "\n",
      "Fold: 25  Epoch: 119  Training loss = 3.5336  Validation loss = 2.5840  \n",
      "\n",
      "Fold: 25  Epoch: 120  Training loss = 3.5333  Validation loss = 2.5840  \n",
      "\n",
      "Fold: 25  Epoch: 121  Training loss = 3.5330  Validation loss = 2.5837  \n",
      "\n",
      "Fold: 25  Epoch: 122  Training loss = 3.5326  Validation loss = 2.5837  \n",
      "\n",
      "Fold: 25  Epoch: 123  Training loss = 3.5323  Validation loss = 2.5835  \n",
      "\n",
      "Fold: 25  Epoch: 124  Training loss = 3.5322  Validation loss = 2.5833  \n",
      "\n",
      "Fold: 25  Epoch: 125  Training loss = 3.5319  Validation loss = 2.5831  \n",
      "\n",
      "Fold: 25  Epoch: 126  Training loss = 3.5317  Validation loss = 2.5830  \n",
      "\n",
      "Fold: 25  Epoch: 127  Training loss = 3.5315  Validation loss = 2.5831  \n",
      "\n",
      "Fold: 25  Epoch: 128  Training loss = 3.5313  Validation loss = 2.5828  \n",
      "\n",
      "Fold: 25  Epoch: 129  Training loss = 3.5310  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 25  Epoch: 130  Training loss = 3.5307  Validation loss = 2.5823  \n",
      "\n",
      "Fold: 25  Epoch: 131  Training loss = 3.5304  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 25  Epoch: 132  Training loss = 3.5299  Validation loss = 2.5825  \n",
      "\n",
      "Fold: 25  Epoch: 133  Training loss = 3.5296  Validation loss = 2.5823  \n",
      "\n",
      "Fold: 25  Epoch: 134  Training loss = 3.5294  Validation loss = 2.5823  \n",
      "\n",
      "Fold: 25  Epoch: 135  Training loss = 3.5292  Validation loss = 2.5820  \n",
      "\n",
      "Fold: 25  Epoch: 136  Training loss = 3.5289  Validation loss = 2.5818  \n",
      "\n",
      "Fold: 25  Epoch: 137  Training loss = 3.5287  Validation loss = 2.5815  \n",
      "\n",
      "Fold: 25  Epoch: 138  Training loss = 3.5284  Validation loss = 2.5814  \n",
      "\n",
      "Fold: 25  Epoch: 139  Training loss = 3.5281  Validation loss = 2.5813  \n",
      "\n",
      "Fold: 25  Epoch: 140  Training loss = 3.5278  Validation loss = 2.5814  \n",
      "\n",
      "Fold: 25  Epoch: 141  Training loss = 3.5277  Validation loss = 2.5814  \n",
      "\n",
      "Fold: 25  Epoch: 142  Training loss = 3.5275  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 25  Epoch: 143  Training loss = 3.5273  Validation loss = 2.5811  \n",
      "\n",
      "Fold: 25  Epoch: 144  Training loss = 3.5271  Validation loss = 2.5808  \n",
      "\n",
      "Fold: 25  Epoch: 145  Training loss = 3.5269  Validation loss = 2.5806  \n",
      "\n",
      "Fold: 25  Epoch: 146  Training loss = 3.5265  Validation loss = 2.5804  \n",
      "\n",
      "Fold: 25  Epoch: 147  Training loss = 3.5263  Validation loss = 2.5803  \n",
      "\n",
      "Fold: 25  Epoch: 148  Training loss = 3.5262  Validation loss = 2.5803  \n",
      "\n",
      "Fold: 25  Epoch: 149  Training loss = 3.5260  Validation loss = 2.5801  \n",
      "\n",
      "Fold: 25  Epoch: 150  Training loss = 3.5258  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 25  Epoch: 151  Training loss = 3.5254  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 25  Epoch: 152  Training loss = 3.5251  Validation loss = 2.5799  \n",
      "\n",
      "Fold: 25  Epoch: 153  Training loss = 3.5249  Validation loss = 2.5797  \n",
      "\n",
      "Fold: 25  Epoch: 154  Training loss = 3.5246  Validation loss = 2.5796  \n",
      "\n",
      "Fold: 25  Epoch: 155  Training loss = 3.5244  Validation loss = 2.5796  \n",
      "\n",
      "Fold: 25  Epoch: 156  Training loss = 3.5242  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 25  Epoch: 157  Training loss = 3.5240  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 25  Epoch: 158  Training loss = 3.5238  Validation loss = 2.5795  \n",
      "\n",
      "Fold: 25  Epoch: 159  Training loss = 3.5236  Validation loss = 2.5793  \n",
      "\n",
      "Fold: 25  Epoch: 160  Training loss = 3.5234  Validation loss = 2.5791  \n",
      "\n",
      "Fold: 25  Epoch: 161  Training loss = 3.5233  Validation loss = 2.5792  \n",
      "\n",
      "Fold: 25  Epoch: 162  Training loss = 3.5230  Validation loss = 2.5790  \n",
      "\n",
      "Fold: 25  Epoch: 163  Training loss = 3.5227  Validation loss = 2.5790  \n",
      "\n",
      "Fold: 25  Epoch: 164  Training loss = 3.5226  Validation loss = 2.5787  \n",
      "\n",
      "Fold: 25  Epoch: 165  Training loss = 3.5223  Validation loss = 2.5786  \n",
      "\n",
      "Fold: 25  Epoch: 166  Training loss = 3.5220  Validation loss = 2.5786  \n",
      "\n",
      "Fold: 25  Epoch: 167  Training loss = 3.5217  Validation loss = 2.5783  \n",
      "\n",
      "Fold: 25  Epoch: 168  Training loss = 3.5215  Validation loss = 2.5782  \n",
      "\n",
      "Fold: 25  Epoch: 169  Training loss = 3.5212  Validation loss = 2.5782  \n",
      "\n",
      "Fold: 25  Epoch: 170  Training loss = 3.5210  Validation loss = 2.5781  \n",
      "\n",
      "Fold: 25  Epoch: 171  Training loss = 3.5207  Validation loss = 2.5781  \n",
      "\n",
      "Fold: 25  Epoch: 172  Training loss = 3.5206  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 25  Epoch: 173  Training loss = 3.5204  Validation loss = 2.5778  \n",
      "\n",
      "Fold: 25  Epoch: 174  Training loss = 3.5201  Validation loss = 2.5778  \n",
      "\n",
      "Fold: 25  Epoch: 175  Training loss = 3.5199  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 25  Epoch: 176  Training loss = 3.5197  Validation loss = 2.5778  \n",
      "\n",
      "Fold: 25  Epoch: 177  Training loss = 3.5195  Validation loss = 2.5777  \n",
      "\n",
      "Fold: 25  Epoch: 178  Training loss = 3.5193  Validation loss = 2.5776  \n",
      "\n",
      "Fold: 25  Epoch: 179  Training loss = 3.5190  Validation loss = 2.5775  \n",
      "\n",
      "Fold: 25  Epoch: 180  Training loss = 3.5187  Validation loss = 2.5774  \n",
      "\n",
      "Fold: 25  Epoch: 181  Training loss = 3.5185  Validation loss = 2.5771  \n",
      "\n",
      "Fold: 25  Epoch: 182  Training loss = 3.5183  Validation loss = 2.5770  \n",
      "\n",
      "Fold: 25  Epoch: 183  Training loss = 3.5182  Validation loss = 2.5768  \n",
      "\n",
      "Fold: 25  Epoch: 184  Training loss = 3.5179  Validation loss = 2.5767  \n",
      "\n",
      "Fold: 25  Epoch: 185  Training loss = 3.5176  Validation loss = 2.5767  \n",
      "\n",
      "Fold: 25  Epoch: 186  Training loss = 3.5173  Validation loss = 2.5765  \n",
      "\n",
      "Fold: 25  Epoch: 187  Training loss = 3.5171  Validation loss = 2.5765  \n",
      "\n",
      "Fold: 25  Epoch: 188  Training loss = 3.5168  Validation loss = 2.5763  \n",
      "\n",
      "Fold: 25  Epoch: 189  Training loss = 3.5166  Validation loss = 2.5762  \n",
      "\n",
      "Fold: 25  Epoch: 190  Training loss = 3.5162  Validation loss = 2.5760  \n",
      "\n",
      "Fold: 25  Epoch: 191  Training loss = 3.5160  Validation loss = 2.5760  \n",
      "\n",
      "Fold: 25  Epoch: 192  Training loss = 3.5158  Validation loss = 2.5757  \n",
      "\n",
      "Fold: 25  Epoch: 193  Training loss = 3.5157  Validation loss = 2.5754  \n",
      "\n",
      "Fold: 25  Epoch: 194  Training loss = 3.5155  Validation loss = 2.5751  \n",
      "\n",
      "Fold: 25  Epoch: 195  Training loss = 3.5153  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 25  Epoch: 196  Training loss = 3.5151  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 25  Epoch: 197  Training loss = 3.5148  Validation loss = 2.5747  \n",
      "\n",
      "Fold: 25  Epoch: 198  Training loss = 3.5146  Validation loss = 2.5748  \n",
      "\n",
      "Fold: 25  Epoch: 199  Training loss = 3.5141  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 25  Epoch: 200  Training loss = 3.5138  Validation loss = 2.5749  \n",
      "\n",
      "Fold: 25  Epoch: 201  Training loss = 3.5136  Validation loss = 2.5747  \n",
      "\n",
      "Fold: 25  Epoch: 202  Training loss = 3.5135  Validation loss = 2.5746  \n",
      "\n",
      "Fold: 25  Epoch: 203  Training loss = 3.5131  Validation loss = 2.5745  \n",
      "\n",
      "Fold: 25  Epoch: 204  Training loss = 3.5129  Validation loss = 2.5743  \n",
      "\n",
      "Fold: 25  Epoch: 205  Training loss = 3.5127  Validation loss = 2.5742  \n",
      "\n",
      "Fold: 25  Epoch: 206  Training loss = 3.5124  Validation loss = 2.5740  \n",
      "\n",
      "Fold: 25  Epoch: 207  Training loss = 3.5121  Validation loss = 2.5738  \n",
      "\n",
      "Fold: 25  Epoch: 208  Training loss = 3.5119  Validation loss = 2.5739  \n",
      "\n",
      "Fold: 25  Epoch: 209  Training loss = 3.5115  Validation loss = 2.5739  \n",
      "\n",
      "Fold: 25  Epoch: 210  Training loss = 3.5112  Validation loss = 2.5738  \n",
      "\n",
      "Fold: 25  Epoch: 211  Training loss = 3.5110  Validation loss = 2.5735  \n",
      "\n",
      "Fold: 25  Epoch: 212  Training loss = 3.5107  Validation loss = 2.5735  \n",
      "\n",
      "Fold: 25  Epoch: 213  Training loss = 3.5106  Validation loss = 2.5735  \n",
      "\n",
      "Fold: 25  Epoch: 214  Training loss = 3.5104  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 25  Epoch: 215  Training loss = 3.5103  Validation loss = 2.5729  \n",
      "\n",
      "Fold: 25  Epoch: 216  Training loss = 3.5101  Validation loss = 2.5729  \n",
      "\n",
      "Fold: 25  Epoch: 217  Training loss = 3.5098  Validation loss = 2.5730  \n",
      "\n",
      "Fold: 25  Epoch: 218  Training loss = 3.5096  Validation loss = 2.5730  \n",
      "\n",
      "Fold: 25  Epoch: 219  Training loss = 3.5094  Validation loss = 2.5728  \n",
      "\n",
      "Fold: 25  Epoch: 220  Training loss = 3.5091  Validation loss = 2.5730  \n",
      "\n",
      "Fold: 25  Epoch: 221  Training loss = 3.5089  Validation loss = 2.5730  \n",
      "\n",
      "Fold: 25  Epoch: 222  Training loss = 3.5086  Validation loss = 2.5727  \n",
      "\n",
      "Fold: 25  Epoch: 223  Training loss = 3.5085  Validation loss = 2.5726  \n",
      "\n",
      "Fold: 25  Epoch: 224  Training loss = 3.5085  Validation loss = 2.5723  \n",
      "\n",
      "Fold: 25  Epoch: 225  Training loss = 3.5082  Validation loss = 2.5723  \n",
      "\n",
      "Fold: 25  Epoch: 226  Training loss = 3.5082  Validation loss = 2.5721  \n",
      "\n",
      "Fold: 25  Epoch: 227  Training loss = 3.5080  Validation loss = 2.5723  \n",
      "\n",
      "Fold: 25  Epoch: 228  Training loss = 3.5078  Validation loss = 2.5721  \n",
      "\n",
      "Fold: 25  Epoch: 229  Training loss = 3.5076  Validation loss = 2.5719  \n",
      "\n",
      "Fold: 25  Epoch: 230  Training loss = 3.5074  Validation loss = 2.5719  \n",
      "\n",
      "Fold: 25  Epoch: 231  Training loss = 3.5072  Validation loss = 2.5718  \n",
      "\n",
      "Fold: 25  Epoch: 232  Training loss = 3.5070  Validation loss = 2.5716  \n",
      "\n",
      "Fold: 25  Epoch: 233  Training loss = 3.5067  Validation loss = 2.5718  \n",
      "\n",
      "Fold: 25  Epoch: 234  Training loss = 3.5063  Validation loss = 2.5718  \n",
      "\n",
      "Fold: 25  Epoch: 235  Training loss = 3.5062  Validation loss = 2.5720  \n",
      "\n",
      "Fold: 25  Epoch: 236  Training loss = 3.5059  Validation loss = 2.5718  \n",
      "\n",
      "Fold: 25  Epoch: 237  Training loss = 3.5057  Validation loss = 2.5717  \n",
      "\n",
      "Fold: 25  Epoch: 238  Training loss = 3.5055  Validation loss = 2.5714  \n",
      "\n",
      "Fold: 25  Epoch: 239  Training loss = 3.5052  Validation loss = 2.5713  \n",
      "\n",
      "Fold: 25  Epoch: 240  Training loss = 3.5050  Validation loss = 2.5713  \n",
      "\n",
      "Fold: 25  Epoch: 241  Training loss = 3.5048  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 25  Epoch: 242  Training loss = 3.5046  Validation loss = 2.5709  \n",
      "\n",
      "Fold: 25  Epoch: 243  Training loss = 3.5043  Validation loss = 2.5709  \n",
      "\n",
      "Fold: 25  Epoch: 244  Training loss = 3.5040  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 25  Epoch: 245  Training loss = 3.5038  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 25  Epoch: 246  Training loss = 3.5036  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 25  Epoch: 247  Training loss = 3.5034  Validation loss = 2.5710  \n",
      "\n",
      "Fold: 25  Epoch: 248  Training loss = 3.5031  Validation loss = 2.5708  \n",
      "\n",
      "Fold: 25  Epoch: 249  Training loss = 3.5030  Validation loss = 2.5708  \n",
      "\n",
      "Fold: 25  Epoch: 250  Training loss = 3.5026  Validation loss = 2.5707  \n",
      "\n",
      "Fold: 25  Epoch: 251  Training loss = 3.5024  Validation loss = 2.5706  \n",
      "\n",
      "Fold: 25  Epoch: 252  Training loss = 3.5022  Validation loss = 2.5704  \n",
      "\n",
      "Fold: 25  Epoch: 253  Training loss = 3.5019  Validation loss = 2.5704  \n",
      "\n",
      "Fold: 25  Epoch: 254  Training loss = 3.5017  Validation loss = 2.5703  \n",
      "\n",
      "Fold: 25  Epoch: 255  Training loss = 3.5014  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 25  Epoch: 256  Training loss = 3.5013  Validation loss = 2.5698  \n",
      "\n",
      "Fold: 25  Epoch: 257  Training loss = 3.5012  Validation loss = 2.5696  \n",
      "\n",
      "Fold: 25  Epoch: 258  Training loss = 3.5010  Validation loss = 2.5699  \n",
      "\n",
      "Fold: 25  Epoch: 259  Training loss = 3.5008  Validation loss = 2.5697  \n",
      "\n",
      "Fold: 25  Epoch: 260  Training loss = 3.5006  Validation loss = 2.5696  \n",
      "\n",
      "Fold: 25  Epoch: 261  Training loss = 3.5005  Validation loss = 2.5694  \n",
      "\n",
      "Fold: 25  Epoch: 262  Training loss = 3.5002  Validation loss = 2.5695  \n",
      "\n",
      "Fold: 25  Epoch: 263  Training loss = 3.4999  Validation loss = 2.5694  \n",
      "\n",
      "Fold: 25  Epoch: 264  Training loss = 3.4997  Validation loss = 2.5693  \n",
      "\n",
      "Fold: 25  Epoch: 265  Training loss = 3.4994  Validation loss = 2.5693  \n",
      "\n",
      "Fold: 25  Epoch: 266  Training loss = 3.4993  Validation loss = 2.5691  \n",
      "\n",
      "Fold: 25  Epoch: 267  Training loss = 3.4989  Validation loss = 2.5690  \n",
      "\n",
      "Fold: 25  Epoch: 268  Training loss = 3.4986  Validation loss = 2.5690  \n",
      "\n",
      "Fold: 25  Epoch: 269  Training loss = 3.4984  Validation loss = 2.5688  \n",
      "\n",
      "Fold: 25  Epoch: 270  Training loss = 3.4982  Validation loss = 2.5685  \n",
      "\n",
      "Fold: 25  Epoch: 271  Training loss = 3.4980  Validation loss = 2.5684  \n",
      "\n",
      "Fold: 25  Epoch: 272  Training loss = 3.4978  Validation loss = 2.5683  \n",
      "\n",
      "Fold: 25  Epoch: 273  Training loss = 3.4976  Validation loss = 2.5681  \n",
      "\n",
      "Fold: 25  Epoch: 274  Training loss = 3.4973  Validation loss = 2.5683  \n",
      "\n",
      "Fold: 25  Epoch: 275  Training loss = 3.4972  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 25  Epoch: 276  Training loss = 3.4970  Validation loss = 2.5678  \n",
      "\n",
      "Fold: 25  Epoch: 277  Training loss = 3.4967  Validation loss = 2.5677  \n",
      "\n",
      "Fold: 25  Epoch: 278  Training loss = 3.4965  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 25  Epoch: 279  Training loss = 3.4963  Validation loss = 2.5674  \n",
      "\n",
      "Fold: 25  Epoch: 280  Training loss = 3.4960  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 25  Epoch: 281  Training loss = 3.4957  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 25  Epoch: 282  Training loss = 3.4956  Validation loss = 2.5673  \n",
      "\n",
      "Fold: 25  Epoch: 283  Training loss = 3.4953  Validation loss = 2.5672  \n",
      "\n",
      "Fold: 25  Epoch: 284  Training loss = 3.4950  Validation loss = 2.5674  \n",
      "\n",
      "Fold: 25  Epoch: 285  Training loss = 3.4949  Validation loss = 2.5674  \n",
      "\n",
      "Fold: 25  Epoch: 286  Training loss = 3.4947  Validation loss = 2.5674  \n",
      "\n",
      "Fold: 25  Epoch: 287  Training loss = 3.4945  Validation loss = 2.5673  \n",
      "\n",
      "Fold: 25  Epoch: 288  Training loss = 3.4943  Validation loss = 2.5672  \n",
      "\n",
      "Fold: 25  Epoch: 289  Training loss = 3.4941  Validation loss = 2.5670  \n",
      "\n",
      "Fold: 25  Epoch: 290  Training loss = 3.4939  Validation loss = 2.5669  \n",
      "\n",
      "Fold: 25  Epoch: 291  Training loss = 3.4937  Validation loss = 2.5665  \n",
      "\n",
      "Fold: 25  Epoch: 292  Training loss = 3.4936  Validation loss = 2.5663  \n",
      "\n",
      "Fold: 25  Epoch: 293  Training loss = 3.4934  Validation loss = 2.5662  \n",
      "\n",
      "Fold: 25  Epoch: 294  Training loss = 3.4931  Validation loss = 2.5660  \n",
      "\n",
      "Fold: 25  Epoch: 295  Training loss = 3.4928  Validation loss = 2.5659  \n",
      "\n",
      "Fold: 25  Epoch: 296  Training loss = 3.4925  Validation loss = 2.5658  \n",
      "\n",
      "Fold: 25  Epoch: 297  Training loss = 3.4923  Validation loss = 2.5660  \n",
      "\n",
      "Fold: 25  Epoch: 298  Training loss = 3.4921  Validation loss = 2.5659  \n",
      "\n",
      "Fold: 25  Epoch: 299  Training loss = 3.4917  Validation loss = 2.5657  \n",
      "\n",
      "Fold: 25  Epoch: 300  Training loss = 3.4916  Validation loss = 2.5657  \n",
      "\n",
      "Fold: 25  Epoch: 301  Training loss = 3.4914  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 25  Epoch: 302  Training loss = 3.4913  Validation loss = 2.5656  \n",
      "\n",
      "Fold: 25  Epoch: 303  Training loss = 3.4910  Validation loss = 2.5655  \n",
      "\n",
      "Fold: 25  Epoch: 304  Training loss = 3.4908  Validation loss = 2.5652  \n",
      "\n",
      "Fold: 25  Epoch: 305  Training loss = 3.4906  Validation loss = 2.5650  \n",
      "\n",
      "Fold: 25  Epoch: 306  Training loss = 3.4905  Validation loss = 2.5649  \n",
      "\n",
      "Fold: 25  Epoch: 307  Training loss = 3.4904  Validation loss = 2.5648  \n",
      "\n",
      "Fold: 25  Epoch: 308  Training loss = 3.4903  Validation loss = 2.5645  \n",
      "\n",
      "Fold: 25  Epoch: 309  Training loss = 3.4901  Validation loss = 2.5648  \n",
      "\n",
      "Fold: 25  Epoch: 310  Training loss = 3.4898  Validation loss = 2.5646  \n",
      "\n",
      "Fold: 25  Epoch: 311  Training loss = 3.4895  Validation loss = 2.5648  \n",
      "\n",
      "Fold: 25  Epoch: 312  Training loss = 3.4894  Validation loss = 2.5648  \n",
      "\n",
      "Fold: 25  Epoch: 313  Training loss = 3.4893  Validation loss = 2.5647  \n",
      "\n",
      "Fold: 25  Epoch: 314  Training loss = 3.4891  Validation loss = 2.5646  \n",
      "\n",
      "Fold: 25  Epoch: 315  Training loss = 3.4890  Validation loss = 2.5644  \n",
      "\n",
      "Fold: 25  Epoch: 316  Training loss = 3.4888  Validation loss = 2.5642  \n",
      "\n",
      "Fold: 25  Epoch: 317  Training loss = 3.4887  Validation loss = 2.5639  \n",
      "\n",
      "Fold: 25  Epoch: 318  Training loss = 3.4884  Validation loss = 2.5640  \n",
      "\n",
      "Fold: 25  Epoch: 319  Training loss = 3.4882  Validation loss = 2.5638  \n",
      "\n",
      "Fold: 25  Epoch: 320  Training loss = 3.4880  Validation loss = 2.5637  \n",
      "\n",
      "Fold: 25  Epoch: 321  Training loss = 3.4878  Validation loss = 2.5637  \n",
      "\n",
      "Fold: 25  Epoch: 322  Training loss = 3.4876  Validation loss = 2.5634  \n",
      "\n",
      "Fold: 25  Epoch: 323  Training loss = 3.4874  Validation loss = 2.5635  \n",
      "\n",
      "Fold: 25  Epoch: 324  Training loss = 3.4872  Validation loss = 2.5634  \n",
      "\n",
      "Fold: 25  Epoch: 325  Training loss = 3.4869  Validation loss = 2.5633  \n",
      "\n",
      "Fold: 25  Epoch: 326  Training loss = 3.4867  Validation loss = 2.5633  \n",
      "\n",
      "Fold: 25  Epoch: 327  Training loss = 3.4864  Validation loss = 2.5633  \n",
      "\n",
      "Fold: 25  Epoch: 328  Training loss = 3.4861  Validation loss = 2.5633  \n",
      "\n",
      "Fold: 25  Epoch: 329  Training loss = 3.4858  Validation loss = 2.5630  \n",
      "\n",
      "Fold: 25  Epoch: 330  Training loss = 3.4855  Validation loss = 2.5629  \n",
      "\n",
      "Fold: 25  Epoch: 331  Training loss = 3.4854  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 25  Epoch: 332  Training loss = 3.4852  Validation loss = 2.5628  \n",
      "\n",
      "Fold: 25  Epoch: 333  Training loss = 3.4850  Validation loss = 2.5625  \n",
      "\n",
      "Fold: 25  Epoch: 334  Training loss = 3.4848  Validation loss = 2.5623  \n",
      "\n",
      "Fold: 25  Epoch: 335  Training loss = 3.4845  Validation loss = 2.5621  \n",
      "\n",
      "Fold: 25  Epoch: 336  Training loss = 3.4842  Validation loss = 2.5619  \n",
      "\n",
      "Fold: 25  Epoch: 337  Training loss = 3.4839  Validation loss = 2.5614  \n",
      "\n",
      "Fold: 25  Epoch: 338  Training loss = 3.4837  Validation loss = 2.5613  \n",
      "\n",
      "Fold: 25  Epoch: 339  Training loss = 3.4836  Validation loss = 2.5609  \n",
      "\n",
      "Fold: 25  Epoch: 340  Training loss = 3.4833  Validation loss = 2.5608  \n",
      "\n",
      "Fold: 25  Epoch: 341  Training loss = 3.4833  Validation loss = 2.5605  \n",
      "\n",
      "Fold: 25  Epoch: 342  Training loss = 3.4831  Validation loss = 2.5604  \n",
      "\n",
      "Fold: 25  Epoch: 343  Training loss = 3.4828  Validation loss = 2.5604  \n",
      "\n",
      "Fold: 25  Epoch: 344  Training loss = 3.4826  Validation loss = 2.5601  \n",
      "\n",
      "Fold: 25  Epoch: 345  Training loss = 3.4823  Validation loss = 2.5603  \n",
      "\n",
      "Fold: 25  Epoch: 346  Training loss = 3.4821  Validation loss = 2.5600  \n",
      "\n",
      "Fold: 25  Epoch: 347  Training loss = 3.4819  Validation loss = 2.5600  \n",
      "\n",
      "Fold: 25  Epoch: 348  Training loss = 3.4819  Validation loss = 2.5598  \n",
      "\n",
      "Fold: 25  Epoch: 349  Training loss = 3.4817  Validation loss = 2.5596  \n",
      "\n",
      "Fold: 25  Epoch: 350  Training loss = 3.4816  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 25  Epoch: 351  Training loss = 3.4815  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 25  Epoch: 352  Training loss = 3.4812  Validation loss = 2.5590  \n",
      "\n",
      "Fold: 25  Epoch: 353  Training loss = 3.4811  Validation loss = 2.5591  \n",
      "\n",
      "Fold: 25  Epoch: 354  Training loss = 3.4810  Validation loss = 2.5589  \n",
      "\n",
      "Fold: 25  Epoch: 355  Training loss = 3.4807  Validation loss = 2.5587  \n",
      "\n",
      "Fold: 25  Epoch: 356  Training loss = 3.4804  Validation loss = 2.5586  \n",
      "\n",
      "Fold: 25  Epoch: 357  Training loss = 3.4803  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 25  Epoch: 358  Training loss = 3.4801  Validation loss = 2.5584  \n",
      "\n",
      "Fold: 25  Epoch: 359  Training loss = 3.4799  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 25  Epoch: 360  Training loss = 3.4798  Validation loss = 2.5582  \n",
      "\n",
      "Fold: 25  Epoch: 361  Training loss = 3.4796  Validation loss = 2.5581  \n",
      "\n",
      "Fold: 25  Epoch: 362  Training loss = 3.4794  Validation loss = 2.5579  \n",
      "\n",
      "Fold: 25  Epoch: 363  Training loss = 3.4792  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 25  Epoch: 364  Training loss = 3.4790  Validation loss = 2.5578  \n",
      "\n",
      "Fold: 25  Epoch: 365  Training loss = 3.4788  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 25  Epoch: 366  Training loss = 3.4785  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 25  Epoch: 367  Training loss = 3.4782  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 25  Epoch: 368  Training loss = 3.4780  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 25  Epoch: 369  Training loss = 3.4777  Validation loss = 2.5578  \n",
      "\n",
      "Fold: 25  Epoch: 370  Training loss = 3.4775  Validation loss = 2.5579  \n",
      "\n",
      "Fold: 25  Epoch: 371  Training loss = 3.4774  Validation loss = 2.5577  \n",
      "\n",
      "Fold: 25  Epoch: 372  Training loss = 3.4771  Validation loss = 2.5577  \n",
      "\n",
      "Fold: 25  Epoch: 373  Training loss = 3.4769  Validation loss = 2.5579  \n",
      "\n",
      "Fold: 25  Epoch: 374  Training loss = 3.4768  Validation loss = 2.5577  \n",
      "\n",
      "Fold: 25  Epoch: 375  Training loss = 3.4765  Validation loss = 2.5577  \n",
      "\n",
      "Fold: 25  Epoch: 376  Training loss = 3.4763  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 25  Epoch: 377  Training loss = 3.4761  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 25  Epoch: 378  Training loss = 3.4758  Validation loss = 2.5572  \n",
      "\n",
      "Fold: 25  Epoch: 379  Training loss = 3.4757  Validation loss = 2.5571  \n",
      "\n",
      "Fold: 25  Epoch: 380  Training loss = 3.4754  Validation loss = 2.5571  \n",
      "\n",
      "Fold: 25  Epoch: 381  Training loss = 3.4752  Validation loss = 2.5570  \n",
      "\n",
      "Fold: 25  Epoch: 382  Training loss = 3.4750  Validation loss = 2.5571  \n",
      "\n",
      "Fold: 25  Epoch: 383  Training loss = 3.4748  Validation loss = 2.5570  \n",
      "\n",
      "Fold: 25  Epoch: 384  Training loss = 3.4747  Validation loss = 2.5569  \n",
      "\n",
      "Fold: 25  Epoch: 385  Training loss = 3.4745  Validation loss = 2.5568  \n",
      "\n",
      "Fold: 25  Epoch: 386  Training loss = 3.4742  Validation loss = 2.5567  \n",
      "\n",
      "Fold: 25  Epoch: 387  Training loss = 3.4740  Validation loss = 2.5567  \n",
      "\n",
      "Fold: 25  Epoch: 388  Training loss = 3.4737  Validation loss = 2.5567  \n",
      "\n",
      "Fold: 25  Epoch: 389  Training loss = 3.4735  Validation loss = 2.5568  \n",
      "\n",
      "Fold: 25  Epoch: 390  Training loss = 3.4731  Validation loss = 2.5567  \n",
      "\n",
      "Fold: 25  Epoch: 391  Training loss = 3.4731  Validation loss = 2.5566  \n",
      "\n",
      "Fold: 25  Epoch: 392  Training loss = 3.4729  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 25  Epoch: 393  Training loss = 3.4728  Validation loss = 2.5562  \n",
      "\n",
      "Fold: 25  Epoch: 394  Training loss = 3.4725  Validation loss = 2.5562  \n",
      "\n",
      "Fold: 25  Epoch: 395  Training loss = 3.4724  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 25  Epoch: 396  Training loss = 3.4723  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 25  Epoch: 397  Training loss = 3.4721  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 25  Epoch: 398  Training loss = 3.4719  Validation loss = 2.5556  \n",
      "\n",
      "Fold: 25  Epoch: 399  Training loss = 3.4716  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 25  Epoch: 400  Training loss = 3.4714  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 25  Epoch: 401  Training loss = 3.4711  Validation loss = 2.5556  \n",
      "\n",
      "Fold: 25  Epoch: 402  Training loss = 3.4708  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 25  Epoch: 403  Training loss = 3.4706  Validation loss = 2.5553  \n",
      "\n",
      "Fold: 25  Epoch: 404  Training loss = 3.4705  Validation loss = 2.5552  \n",
      "\n",
      "Fold: 25  Epoch: 405  Training loss = 3.4703  Validation loss = 2.5552  \n",
      "\n",
      "Fold: 25  Epoch: 406  Training loss = 3.4700  Validation loss = 2.5553  \n",
      "\n",
      "Fold: 25  Epoch: 407  Training loss = 3.4698  Validation loss = 2.5553  \n",
      "\n",
      "Fold: 25  Epoch: 408  Training loss = 3.4697  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 25  Epoch: 409  Training loss = 3.4694  Validation loss = 2.5548  \n",
      "\n",
      "Fold: 25  Epoch: 410  Training loss = 3.4692  Validation loss = 2.5548  \n",
      "\n",
      "Fold: 25  Epoch: 411  Training loss = 3.4689  Validation loss = 2.5549  \n",
      "\n",
      "Fold: 25  Epoch: 412  Training loss = 3.4688  Validation loss = 2.5549  \n",
      "\n",
      "Fold: 25  Epoch: 413  Training loss = 3.4687  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 25  Epoch: 414  Training loss = 3.4685  Validation loss = 2.5550  \n",
      "\n",
      "Fold: 25  Epoch: 415  Training loss = 3.4683  Validation loss = 2.5549  \n",
      "\n",
      "Fold: 25  Epoch: 416  Training loss = 3.4681  Validation loss = 2.5546  \n",
      "\n",
      "Fold: 25  Epoch: 417  Training loss = 3.4679  Validation loss = 2.5546  \n",
      "\n",
      "Fold: 25  Epoch: 418  Training loss = 3.4677  Validation loss = 2.5545  \n",
      "\n",
      "Fold: 25  Epoch: 419  Training loss = 3.4675  Validation loss = 2.5542  \n",
      "\n",
      "Fold: 25  Epoch: 420  Training loss = 3.4672  Validation loss = 2.5542  \n",
      "\n",
      "Fold: 25  Epoch: 421  Training loss = 3.4671  Validation loss = 2.5540  \n",
      "\n",
      "Fold: 25  Epoch: 422  Training loss = 3.4669  Validation loss = 2.5539  \n",
      "\n",
      "Fold: 25  Epoch: 423  Training loss = 3.4667  Validation loss = 2.5538  \n",
      "\n",
      "Fold: 25  Epoch: 424  Training loss = 3.4665  Validation loss = 2.5537  \n",
      "\n",
      "Fold: 25  Epoch: 425  Training loss = 3.4662  Validation loss = 2.5538  \n",
      "\n",
      "Fold: 25  Epoch: 426  Training loss = 3.4661  Validation loss = 2.5536  \n",
      "\n",
      "Fold: 25  Epoch: 427  Training loss = 3.4659  Validation loss = 2.5535  \n",
      "\n",
      "Fold: 25  Epoch: 428  Training loss = 3.4658  Validation loss = 2.5532  \n",
      "\n",
      "Fold: 25  Epoch: 429  Training loss = 3.4657  Validation loss = 2.5533  \n",
      "\n",
      "Fold: 25  Epoch: 430  Training loss = 3.4655  Validation loss = 2.5533  \n",
      "\n",
      "Fold: 25  Epoch: 431  Training loss = 3.4653  Validation loss = 2.5531  \n",
      "\n",
      "Fold: 25  Epoch: 432  Training loss = 3.4650  Validation loss = 2.5529  \n",
      "\n",
      "Fold: 25  Epoch: 433  Training loss = 3.4649  Validation loss = 2.5528  \n",
      "\n",
      "Fold: 25  Epoch: 434  Training loss = 3.4647  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 25  Epoch: 435  Training loss = 3.4644  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 25  Epoch: 436  Training loss = 3.4643  Validation loss = 2.5524  \n",
      "\n",
      "Fold: 25  Epoch: 437  Training loss = 3.4640  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 25  Epoch: 438  Training loss = 3.4638  Validation loss = 2.5524  \n",
      "\n",
      "Fold: 25  Epoch: 439  Training loss = 3.4637  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 25  Epoch: 440  Training loss = 3.4635  Validation loss = 2.5522  \n",
      "\n",
      "Fold: 25  Epoch: 441  Training loss = 3.4633  Validation loss = 2.5517  \n",
      "\n",
      "Fold: 25  Epoch: 442  Training loss = 3.4632  Validation loss = 2.5516  \n",
      "\n",
      "Fold: 25  Epoch: 443  Training loss = 3.4631  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 25  Epoch: 444  Training loss = 3.4628  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 25  Epoch: 445  Training loss = 3.4627  Validation loss = 2.5512  \n",
      "\n",
      "Fold: 25  Epoch: 446  Training loss = 3.4624  Validation loss = 2.5510  \n",
      "\n",
      "Fold: 25  Epoch: 447  Training loss = 3.4623  Validation loss = 2.5505  \n",
      "\n",
      "Fold: 25  Epoch: 448  Training loss = 3.4620  Validation loss = 2.5503  \n",
      "\n",
      "Fold: 25  Epoch: 449  Training loss = 3.4618  Validation loss = 2.5504  \n",
      "\n",
      "Fold: 25  Epoch: 450  Training loss = 3.4616  Validation loss = 2.5503  \n",
      "\n",
      "Fold: 25  Epoch: 451  Training loss = 3.4614  Validation loss = 2.5502  \n",
      "\n",
      "Fold: 25  Epoch: 452  Training loss = 3.4612  Validation loss = 2.5500  \n",
      "\n",
      "Fold: 25  Epoch: 453  Training loss = 3.4609  Validation loss = 2.5499  \n",
      "\n",
      "Fold: 25  Epoch: 454  Training loss = 3.4607  Validation loss = 2.5499  \n",
      "\n",
      "Fold: 25  Epoch: 455  Training loss = 3.4606  Validation loss = 2.5495  \n",
      "\n",
      "Fold: 25  Epoch: 456  Training loss = 3.4603  Validation loss = 2.5494  \n",
      "\n",
      "Fold: 25  Epoch: 457  Training loss = 3.4601  Validation loss = 2.5492  \n",
      "\n",
      "Fold: 25  Epoch: 458  Training loss = 3.4599  Validation loss = 2.5493  \n",
      "\n",
      "Fold: 25  Epoch: 459  Training loss = 3.4597  Validation loss = 2.5493  \n",
      "\n",
      "Fold: 25  Epoch: 460  Training loss = 3.4594  Validation loss = 2.5493  \n",
      "\n",
      "Fold: 25  Epoch: 461  Training loss = 3.4592  Validation loss = 2.5493  \n",
      "\n",
      "Fold: 25  Epoch: 462  Training loss = 3.4590  Validation loss = 2.5494  \n",
      "\n",
      "Fold: 25  Epoch: 463  Training loss = 3.4588  Validation loss = 2.5495  \n",
      "\n",
      "Fold: 25  Epoch: 464  Training loss = 3.4586  Validation loss = 2.5493  \n",
      "\n",
      "Fold: 25  Epoch: 465  Training loss = 3.4585  Validation loss = 2.5492  \n",
      "\n",
      "Fold: 25  Epoch: 466  Training loss = 3.4583  Validation loss = 2.5488  \n",
      "\n",
      "Fold: 25  Epoch: 467  Training loss = 3.4581  Validation loss = 2.5489  \n",
      "\n",
      "Fold: 25  Epoch: 468  Training loss = 3.4579  Validation loss = 2.5486  \n",
      "\n",
      "Fold: 25  Epoch: 469  Training loss = 3.4577  Validation loss = 2.5486  \n",
      "\n",
      "Fold: 25  Epoch: 470  Training loss = 3.4574  Validation loss = 2.5485  \n",
      "\n",
      "Fold: 25  Epoch: 471  Training loss = 3.4572  Validation loss = 2.5484  \n",
      "\n",
      "Fold: 25  Epoch: 472  Training loss = 3.4570  Validation loss = 2.5484  \n",
      "\n",
      "Fold: 25  Epoch: 473  Training loss = 3.4569  Validation loss = 2.5483  \n",
      "\n",
      "Fold: 25  Epoch: 474  Training loss = 3.4567  Validation loss = 2.5481  \n",
      "\n",
      "Fold: 25  Epoch: 475  Training loss = 3.4564  Validation loss = 2.5483  \n",
      "\n",
      "Fold: 25  Epoch: 476  Training loss = 3.4562  Validation loss = 2.5482  \n",
      "\n",
      "Fold: 25  Epoch: 477  Training loss = 3.4561  Validation loss = 2.5482  \n",
      "\n",
      "Fold: 25  Epoch: 478  Training loss = 3.4559  Validation loss = 2.5482  \n",
      "\n",
      "Fold: 25  Epoch: 479  Training loss = 3.4557  Validation loss = 2.5484  \n",
      "\n",
      "Fold: 25  Epoch: 480  Training loss = 3.4555  Validation loss = 2.5481  \n",
      "\n",
      "Fold: 25  Epoch: 481  Training loss = 3.4553  Validation loss = 2.5480  \n",
      "\n",
      "Fold: 25  Epoch: 482  Training loss = 3.4551  Validation loss = 2.5479  \n",
      "\n",
      "Fold: 25  Epoch: 483  Training loss = 3.4549  Validation loss = 2.5478  \n",
      "\n",
      "Fold: 25  Epoch: 484  Training loss = 3.4548  Validation loss = 2.5479  \n",
      "\n",
      "Fold: 25  Epoch: 485  Training loss = 3.4546  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 25  Epoch: 486  Training loss = 3.4544  Validation loss = 2.5476  \n",
      "\n",
      "Fold: 25  Epoch: 487  Training loss = 3.4543  Validation loss = 2.5474  \n",
      "\n",
      "Fold: 25  Epoch: 488  Training loss = 3.4541  Validation loss = 2.5474  \n",
      "\n",
      "Fold: 25  Epoch: 489  Training loss = 3.4538  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 25  Epoch: 490  Training loss = 3.4537  Validation loss = 2.5473  \n",
      "\n",
      "Fold: 25  Epoch: 491  Training loss = 3.4535  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 25  Epoch: 492  Training loss = 3.4533  Validation loss = 2.5469  \n",
      "\n",
      "Fold: 25  Epoch: 493  Training loss = 3.4532  Validation loss = 2.5467  \n",
      "\n",
      "Fold: 25  Epoch: 494  Training loss = 3.4529  Validation loss = 2.5468  \n",
      "\n",
      "Fold: 25  Epoch: 495  Training loss = 3.4526  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 25  Epoch: 496  Training loss = 3.4524  Validation loss = 2.5468  \n",
      "\n",
      "Fold: 25  Epoch: 497  Training loss = 3.4521  Validation loss = 2.5470  \n",
      "\n",
      "Fold: 25  Epoch: 498  Training loss = 3.4518  Validation loss = 2.5466  \n",
      "\n",
      "Fold: 25  Epoch: 499  Training loss = 3.4515  Validation loss = 2.5469  \n",
      "\n",
      "Fold: 25  Epoch: 500  Training loss = 3.4512  Validation loss = 2.5469  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 498  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.2965  Validation loss = 2.8483  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.2964  Validation loss = 2.8482  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.2962  Validation loss = 2.8481  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.2961  Validation loss = 2.8480  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.2959  Validation loss = 2.8477  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.2957  Validation loss = 2.8480  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.2955  Validation loss = 2.8483  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.2954  Validation loss = 2.8486  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.2952  Validation loss = 2.8487  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.2950  Validation loss = 2.8487  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 3.2949  Validation loss = 2.8490  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 5  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.2860  Validation loss = 1.8457  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.2858  Validation loss = 1.8455  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.2857  Validation loss = 1.8454  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.2854  Validation loss = 1.8450  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.2852  Validation loss = 1.8442  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.2849  Validation loss = 1.8437  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.2846  Validation loss = 1.8433  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.2843  Validation loss = 1.8427  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.2841  Validation loss = 1.8426  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.2838  Validation loss = 1.8421  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.2835  Validation loss = 1.8414  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 3.2832  Validation loss = 1.8410  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 3.2831  Validation loss = 1.8405  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 3.2828  Validation loss = 1.8398  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 3.2824  Validation loss = 1.8391  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 3.2820  Validation loss = 1.8386  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 3.2816  Validation loss = 1.8376  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 3.2812  Validation loss = 1.8367  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 3.2807  Validation loss = 1.8357  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 3.2796  Validation loss = 1.8342  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 3.2790  Validation loss = 1.8330  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 3.2782  Validation loss = 1.8315  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 3.2771  Validation loss = 1.8302  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 3.2766  Validation loss = 1.8293  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 3.2763  Validation loss = 1.8291  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 3.2754  Validation loss = 1.8281  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 3.2739  Validation loss = 1.8266  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 3.2730  Validation loss = 1.8256  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 3.2726  Validation loss = 1.8254  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 3.2712  Validation loss = 1.8234  \n",
      "\n",
      "Fold: 27  Epoch: 31  Training loss = 3.2704  Validation loss = 1.8225  \n",
      "\n",
      "Fold: 27  Epoch: 32  Training loss = 3.2701  Validation loss = 1.8221  \n",
      "\n",
      "Fold: 27  Epoch: 33  Training loss = 3.2697  Validation loss = 1.8217  \n",
      "\n",
      "Fold: 27  Epoch: 34  Training loss = 3.2690  Validation loss = 1.8206  \n",
      "\n",
      "Fold: 27  Epoch: 35  Training loss = 3.2687  Validation loss = 1.8200  \n",
      "\n",
      "Fold: 27  Epoch: 36  Training loss = 3.2682  Validation loss = 1.8192  \n",
      "\n",
      "Fold: 27  Epoch: 37  Training loss = 3.2675  Validation loss = 1.8178  \n",
      "\n",
      "Fold: 27  Epoch: 38  Training loss = 3.2673  Validation loss = 1.8175  \n",
      "\n",
      "Fold: 27  Epoch: 39  Training loss = 3.2665  Validation loss = 1.8158  \n",
      "\n",
      "Fold: 27  Epoch: 40  Training loss = 3.2661  Validation loss = 1.8154  \n",
      "\n",
      "Fold: 27  Epoch: 41  Training loss = 3.2657  Validation loss = 1.8146  \n",
      "\n",
      "Fold: 27  Epoch: 42  Training loss = 3.2654  Validation loss = 1.8137  \n",
      "\n",
      "Fold: 27  Epoch: 43  Training loss = 3.2650  Validation loss = 1.8129  \n",
      "\n",
      "Fold: 27  Epoch: 44  Training loss = 3.2647  Validation loss = 1.8120  \n",
      "\n",
      "Fold: 27  Epoch: 45  Training loss = 3.2643  Validation loss = 1.8113  \n",
      "\n",
      "Fold: 27  Epoch: 46  Training loss = 3.2639  Validation loss = 1.8104  \n",
      "\n",
      "Fold: 27  Epoch: 47  Training loss = 3.2636  Validation loss = 1.8095  \n",
      "\n",
      "Fold: 27  Epoch: 48  Training loss = 3.2632  Validation loss = 1.8086  \n",
      "\n",
      "Fold: 27  Epoch: 49  Training loss = 3.2628  Validation loss = 1.8078  \n",
      "\n",
      "Fold: 27  Epoch: 50  Training loss = 3.2625  Validation loss = 1.8071  \n",
      "\n",
      "Fold: 27  Epoch: 51  Training loss = 3.2623  Validation loss = 1.8065  \n",
      "\n",
      "Fold: 27  Epoch: 52  Training loss = 3.2620  Validation loss = 1.8061  \n",
      "\n",
      "Fold: 27  Epoch: 53  Training loss = 3.2616  Validation loss = 1.8048  \n",
      "\n",
      "Fold: 27  Epoch: 54  Training loss = 3.2613  Validation loss = 1.8038  \n",
      "\n",
      "Fold: 27  Epoch: 55  Training loss = 3.2609  Validation loss = 1.8033  \n",
      "\n",
      "Fold: 27  Epoch: 56  Training loss = 3.2606  Validation loss = 1.8026  \n",
      "\n",
      "Fold: 27  Epoch: 57  Training loss = 3.2605  Validation loss = 1.8023  \n",
      "\n",
      "Fold: 27  Epoch: 58  Training loss = 3.2602  Validation loss = 1.8015  \n",
      "\n",
      "Fold: 27  Epoch: 59  Training loss = 3.2598  Validation loss = 1.8006  \n",
      "\n",
      "Fold: 27  Epoch: 60  Training loss = 3.2597  Validation loss = 1.8006  \n",
      "\n",
      "Fold: 27  Epoch: 61  Training loss = 3.2594  Validation loss = 1.8003  \n",
      "\n",
      "Fold: 27  Epoch: 62  Training loss = 3.2592  Validation loss = 1.7998  \n",
      "\n",
      "Fold: 27  Epoch: 63  Training loss = 3.2588  Validation loss = 1.7991  \n",
      "\n",
      "Fold: 27  Epoch: 64  Training loss = 3.2586  Validation loss = 1.7984  \n",
      "\n",
      "Fold: 27  Epoch: 65  Training loss = 3.2581  Validation loss = 1.7970  \n",
      "\n",
      "Fold: 27  Epoch: 66  Training loss = 3.2579  Validation loss = 1.7964  \n",
      "\n",
      "Fold: 27  Epoch: 67  Training loss = 3.2578  Validation loss = 1.7964  \n",
      "\n",
      "Fold: 27  Epoch: 68  Training loss = 3.2576  Validation loss = 1.7960  \n",
      "\n",
      "Fold: 27  Epoch: 69  Training loss = 3.2573  Validation loss = 1.7952  \n",
      "\n",
      "Fold: 27  Epoch: 70  Training loss = 3.2571  Validation loss = 1.7948  \n",
      "\n",
      "Fold: 27  Epoch: 71  Training loss = 3.2568  Validation loss = 1.7939  \n",
      "\n",
      "Fold: 27  Epoch: 72  Training loss = 3.2564  Validation loss = 1.7925  \n",
      "\n",
      "Fold: 27  Epoch: 73  Training loss = 3.2562  Validation loss = 1.7921  \n",
      "\n",
      "Fold: 27  Epoch: 74  Training loss = 3.2559  Validation loss = 1.7916  \n",
      "\n",
      "Fold: 27  Epoch: 75  Training loss = 3.2557  Validation loss = 1.7910  \n",
      "\n",
      "Fold: 27  Epoch: 76  Training loss = 3.2553  Validation loss = 1.7901  \n",
      "\n",
      "Fold: 27  Epoch: 77  Training loss = 3.2552  Validation loss = 1.7897  \n",
      "\n",
      "Fold: 27  Epoch: 78  Training loss = 3.2549  Validation loss = 1.7886  \n",
      "\n",
      "Fold: 27  Epoch: 79  Training loss = 3.2546  Validation loss = 1.7881  \n",
      "\n",
      "Fold: 27  Epoch: 80  Training loss = 3.2543  Validation loss = 1.7872  \n",
      "\n",
      "Fold: 27  Epoch: 81  Training loss = 3.2539  Validation loss = 1.7864  \n",
      "\n",
      "Fold: 27  Epoch: 82  Training loss = 3.2538  Validation loss = 1.7865  \n",
      "\n",
      "Fold: 27  Epoch: 83  Training loss = 3.2536  Validation loss = 1.7859  \n",
      "\n",
      "Fold: 27  Epoch: 84  Training loss = 3.2533  Validation loss = 1.7854  \n",
      "\n",
      "Fold: 27  Epoch: 85  Training loss = 3.2529  Validation loss = 1.7843  \n",
      "\n",
      "Fold: 27  Epoch: 86  Training loss = 3.2527  Validation loss = 1.7837  \n",
      "\n",
      "Fold: 27  Epoch: 87  Training loss = 3.2524  Validation loss = 1.7827  \n",
      "\n",
      "Fold: 27  Epoch: 88  Training loss = 3.2521  Validation loss = 1.7821  \n",
      "\n",
      "Fold: 27  Epoch: 89  Training loss = 3.2518  Validation loss = 1.7815  \n",
      "\n",
      "Fold: 27  Epoch: 90  Training loss = 3.2515  Validation loss = 1.7808  \n",
      "\n",
      "Fold: 27  Epoch: 91  Training loss = 3.2512  Validation loss = 1.7802  \n",
      "\n",
      "Fold: 27  Epoch: 92  Training loss = 3.2510  Validation loss = 1.7799  \n",
      "\n",
      "Fold: 27  Epoch: 93  Training loss = 3.2507  Validation loss = 1.7793  \n",
      "\n",
      "Fold: 27  Epoch: 94  Training loss = 3.2505  Validation loss = 1.7790  \n",
      "\n",
      "Fold: 27  Epoch: 95  Training loss = 3.2501  Validation loss = 1.7782  \n",
      "\n",
      "Fold: 27  Epoch: 96  Training loss = 3.2497  Validation loss = 1.7765  \n",
      "\n",
      "Fold: 27  Epoch: 97  Training loss = 3.2494  Validation loss = 1.7759  \n",
      "\n",
      "Fold: 27  Epoch: 98  Training loss = 3.2490  Validation loss = 1.7747  \n",
      "\n",
      "Fold: 27  Epoch: 99  Training loss = 3.2485  Validation loss = 1.7736  \n",
      "\n",
      "Fold: 27  Epoch: 100  Training loss = 3.2480  Validation loss = 1.7721  \n",
      "\n",
      "Fold: 27  Epoch: 101  Training loss = 3.2477  Validation loss = 1.7706  \n",
      "\n",
      "Fold: 27  Epoch: 102  Training loss = 3.2475  Validation loss = 1.7701  \n",
      "\n",
      "Fold: 27  Epoch: 103  Training loss = 3.2470  Validation loss = 1.7689  \n",
      "\n",
      "Fold: 27  Epoch: 104  Training loss = 3.2467  Validation loss = 1.7683  \n",
      "\n",
      "Fold: 27  Epoch: 105  Training loss = 3.2465  Validation loss = 1.7681  \n",
      "\n",
      "Fold: 27  Epoch: 106  Training loss = 3.2464  Validation loss = 1.7681  \n",
      "\n",
      "Fold: 27  Epoch: 107  Training loss = 3.2460  Validation loss = 1.7668  \n",
      "\n",
      "Fold: 27  Epoch: 108  Training loss = 3.2457  Validation loss = 1.7660  \n",
      "\n",
      "Fold: 27  Epoch: 109  Training loss = 3.2455  Validation loss = 1.7655  \n",
      "\n",
      "Fold: 27  Epoch: 110  Training loss = 3.2452  Validation loss = 1.7651  \n",
      "\n",
      "Fold: 27  Epoch: 111  Training loss = 3.2449  Validation loss = 1.7640  \n",
      "\n",
      "Fold: 27  Epoch: 112  Training loss = 3.2445  Validation loss = 1.7627  \n",
      "\n",
      "Fold: 27  Epoch: 113  Training loss = 3.2443  Validation loss = 1.7631  \n",
      "\n",
      "Fold: 27  Epoch: 114  Training loss = 3.2439  Validation loss = 1.7617  \n",
      "\n",
      "Fold: 27  Epoch: 115  Training loss = 3.2435  Validation loss = 1.7607  \n",
      "\n",
      "Fold: 27  Epoch: 116  Training loss = 3.2432  Validation loss = 1.7600  \n",
      "\n",
      "Fold: 27  Epoch: 117  Training loss = 3.2430  Validation loss = 1.7593  \n",
      "\n",
      "Fold: 27  Epoch: 118  Training loss = 3.2427  Validation loss = 1.7592  \n",
      "\n",
      "Fold: 27  Epoch: 119  Training loss = 3.2422  Validation loss = 1.7579  \n",
      "\n",
      "Fold: 27  Epoch: 120  Training loss = 3.2419  Validation loss = 1.7569  \n",
      "\n",
      "Fold: 27  Epoch: 121  Training loss = 3.2413  Validation loss = 1.7552  \n",
      "\n",
      "Fold: 27  Epoch: 122  Training loss = 3.2411  Validation loss = 1.7547  \n",
      "\n",
      "Fold: 27  Epoch: 123  Training loss = 3.2407  Validation loss = 1.7540  \n",
      "\n",
      "Fold: 27  Epoch: 124  Training loss = 3.2403  Validation loss = 1.7529  \n",
      "\n",
      "Fold: 27  Epoch: 125  Training loss = 3.2399  Validation loss = 1.7525  \n",
      "\n",
      "Fold: 27  Epoch: 126  Training loss = 3.2392  Validation loss = 1.7515  \n",
      "\n",
      "Fold: 27  Epoch: 127  Training loss = 3.2390  Validation loss = 1.7513  \n",
      "\n",
      "Fold: 27  Epoch: 128  Training loss = 3.2382  Validation loss = 1.7499  \n",
      "\n",
      "Fold: 27  Epoch: 129  Training loss = 3.2372  Validation loss = 1.7481  \n",
      "\n",
      "Fold: 27  Epoch: 130  Training loss = 3.2368  Validation loss = 1.7477  \n",
      "\n",
      "Fold: 27  Epoch: 131  Training loss = 3.2352  Validation loss = 1.7455  \n",
      "\n",
      "Fold: 27  Epoch: 132  Training loss = 3.2343  Validation loss = 1.7443  \n",
      "\n",
      "Fold: 27  Epoch: 133  Training loss = 3.2335  Validation loss = 1.7434  \n",
      "\n",
      "Fold: 27  Epoch: 134  Training loss = 3.2327  Validation loss = 1.7423  \n",
      "\n",
      "Fold: 27  Epoch: 135  Training loss = 3.2320  Validation loss = 1.7412  \n",
      "\n",
      "Fold: 27  Epoch: 136  Training loss = 3.2305  Validation loss = 1.7390  \n",
      "\n",
      "Fold: 27  Epoch: 137  Training loss = 3.2299  Validation loss = 1.7376  \n",
      "\n",
      "Fold: 27  Epoch: 138  Training loss = 3.2295  Validation loss = 1.7364  \n",
      "\n",
      "Fold: 27  Epoch: 139  Training loss = 3.2288  Validation loss = 1.7351  \n",
      "\n",
      "Fold: 27  Epoch: 140  Training loss = 3.2278  Validation loss = 1.7337  \n",
      "\n",
      "Fold: 27  Epoch: 141  Training loss = 3.2277  Validation loss = 1.7332  \n",
      "\n",
      "Fold: 27  Epoch: 142  Training loss = 3.2268  Validation loss = 1.7310  \n",
      "\n",
      "Fold: 27  Epoch: 143  Training loss = 3.2265  Validation loss = 1.7305  \n",
      "\n",
      "Fold: 27  Epoch: 144  Training loss = 3.2260  Validation loss = 1.7290  \n",
      "\n",
      "Fold: 27  Epoch: 145  Training loss = 3.2258  Validation loss = 1.7296  \n",
      "\n",
      "Fold: 27  Epoch: 146  Training loss = 3.2252  Validation loss = 1.7279  \n",
      "\n",
      "Fold: 27  Epoch: 147  Training loss = 3.2249  Validation loss = 1.7273  \n",
      "\n",
      "Fold: 27  Epoch: 148  Training loss = 3.2247  Validation loss = 1.7270  \n",
      "\n",
      "Fold: 27  Epoch: 149  Training loss = 3.2244  Validation loss = 1.7259  \n",
      "\n",
      "Fold: 27  Epoch: 150  Training loss = 3.2242  Validation loss = 1.7255  \n",
      "\n",
      "Fold: 27  Epoch: 151  Training loss = 3.2238  Validation loss = 1.7250  \n",
      "\n",
      "Fold: 27  Epoch: 152  Training loss = 3.2234  Validation loss = 1.7235  \n",
      "\n",
      "Fold: 27  Epoch: 153  Training loss = 3.2233  Validation loss = 1.7238  \n",
      "\n",
      "Fold: 27  Epoch: 154  Training loss = 3.2229  Validation loss = 1.7228  \n",
      "\n",
      "Fold: 27  Epoch: 155  Training loss = 3.2226  Validation loss = 1.7219  \n",
      "\n",
      "Fold: 27  Epoch: 156  Training loss = 3.2223  Validation loss = 1.7212  \n",
      "\n",
      "Fold: 27  Epoch: 157  Training loss = 3.2220  Validation loss = 1.7197  \n",
      "\n",
      "Fold: 27  Epoch: 158  Training loss = 3.2217  Validation loss = 1.7189  \n",
      "\n",
      "Fold: 27  Epoch: 159  Training loss = 3.2216  Validation loss = 1.7193  \n",
      "\n",
      "Fold: 27  Epoch: 160  Training loss = 3.2215  Validation loss = 1.7188  \n",
      "\n",
      "Fold: 27  Epoch: 161  Training loss = 3.2213  Validation loss = 1.7183  \n",
      "\n",
      "Fold: 27  Epoch: 162  Training loss = 3.2211  Validation loss = 1.7180  \n",
      "\n",
      "Fold: 27  Epoch: 163  Training loss = 3.2207  Validation loss = 1.7171  \n",
      "\n",
      "Fold: 27  Epoch: 164  Training loss = 3.2205  Validation loss = 1.7159  \n",
      "\n",
      "Fold: 27  Epoch: 165  Training loss = 3.2200  Validation loss = 1.7145  \n",
      "\n",
      "Fold: 27  Epoch: 166  Training loss = 3.2196  Validation loss = 1.7126  \n",
      "\n",
      "Fold: 27  Epoch: 167  Training loss = 3.2195  Validation loss = 1.7130  \n",
      "\n",
      "Fold: 27  Epoch: 168  Training loss = 3.2192  Validation loss = 1.7117  \n",
      "\n",
      "Fold: 27  Epoch: 169  Training loss = 3.2189  Validation loss = 1.7104  \n",
      "\n",
      "Fold: 27  Epoch: 170  Training loss = 3.2188  Validation loss = 1.7102  \n",
      "\n",
      "Fold: 27  Epoch: 171  Training loss = 3.2187  Validation loss = 1.7108  \n",
      "\n",
      "Fold: 27  Epoch: 172  Training loss = 3.2184  Validation loss = 1.7091  \n",
      "\n",
      "Fold: 27  Epoch: 173  Training loss = 3.2179  Validation loss = 1.7068  \n",
      "\n",
      "Fold: 27  Epoch: 174  Training loss = 3.2178  Validation loss = 1.7074  \n",
      "\n",
      "Fold: 27  Epoch: 175  Training loss = 3.2176  Validation loss = 1.7061  \n",
      "\n",
      "Fold: 27  Epoch: 176  Training loss = 3.2174  Validation loss = 1.7058  \n",
      "\n",
      "Fold: 27  Epoch: 177  Training loss = 3.2172  Validation loss = 1.7055  \n",
      "\n",
      "Fold: 27  Epoch: 178  Training loss = 3.2170  Validation loss = 1.7047  \n",
      "\n",
      "Fold: 27  Epoch: 179  Training loss = 3.2169  Validation loss = 1.7054  \n",
      "\n",
      "Fold: 27  Epoch: 180  Training loss = 3.2167  Validation loss = 1.7048  \n",
      "\n",
      "Fold: 27  Epoch: 181  Training loss = 3.2166  Validation loss = 1.7044  \n",
      "\n",
      "Fold: 27  Epoch: 182  Training loss = 3.2161  Validation loss = 1.7015  \n",
      "\n",
      "Fold: 27  Epoch: 183  Training loss = 3.2158  Validation loss = 1.6998  \n",
      "\n",
      "Fold: 27  Epoch: 184  Training loss = 3.2155  Validation loss = 1.6987  \n",
      "\n",
      "Fold: 27  Epoch: 185  Training loss = 3.2151  Validation loss = 1.6972  \n",
      "\n",
      "Fold: 27  Epoch: 186  Training loss = 3.2147  Validation loss = 1.6952  \n",
      "\n",
      "Fold: 27  Epoch: 187  Training loss = 3.2145  Validation loss = 1.6952  \n",
      "\n",
      "Fold: 27  Epoch: 188  Training loss = 3.2142  Validation loss = 1.6941  \n",
      "\n",
      "Fold: 27  Epoch: 189  Training loss = 3.2139  Validation loss = 1.6918  \n",
      "\n",
      "Fold: 27  Epoch: 190  Training loss = 3.2137  Validation loss = 1.6917  \n",
      "\n",
      "Fold: 27  Epoch: 191  Training loss = 3.2132  Validation loss = 1.6888  \n",
      "\n",
      "Fold: 27  Epoch: 192  Training loss = 3.2130  Validation loss = 1.6889  \n",
      "\n",
      "Fold: 27  Epoch: 193  Training loss = 3.2127  Validation loss = 1.6866  \n",
      "\n",
      "Fold: 27  Epoch: 194  Training loss = 3.2124  Validation loss = 1.6842  \n",
      "\n",
      "Fold: 27  Epoch: 195  Training loss = 3.2122  Validation loss = 1.6835  \n",
      "\n",
      "Fold: 27  Epoch: 196  Training loss = 3.2121  Validation loss = 1.6848  \n",
      "\n",
      "Fold: 27  Epoch: 197  Training loss = 3.2120  Validation loss = 1.6853  \n",
      "\n",
      "Fold: 27  Epoch: 198  Training loss = 3.2119  Validation loss = 1.6853  \n",
      "\n",
      "Fold: 27  Epoch: 199  Training loss = 3.2116  Validation loss = 1.6839  \n",
      "\n",
      "Fold: 27  Epoch: 200  Training loss = 3.2113  Validation loss = 1.6822  \n",
      "\n",
      "Fold: 27  Epoch: 201  Training loss = 3.2111  Validation loss = 1.6821  \n",
      "\n",
      "Fold: 27  Epoch: 202  Training loss = 3.2110  Validation loss = 1.6819  \n",
      "\n",
      "Fold: 27  Epoch: 203  Training loss = 3.2109  Validation loss = 1.6828  \n",
      "\n",
      "Fold: 27  Epoch: 204  Training loss = 3.2107  Validation loss = 1.6821  \n",
      "\n",
      "Fold: 27  Epoch: 205  Training loss = 3.2104  Validation loss = 1.6806  \n",
      "\n",
      "Fold: 27  Epoch: 206  Training loss = 3.2103  Validation loss = 1.6809  \n",
      "\n",
      "Fold: 27  Epoch: 207  Training loss = 3.2101  Validation loss = 1.6801  \n",
      "\n",
      "Fold: 27  Epoch: 208  Training loss = 3.2098  Validation loss = 1.6790  \n",
      "\n",
      "Fold: 27  Epoch: 209  Training loss = 3.2096  Validation loss = 1.6784  \n",
      "\n",
      "Fold: 27  Epoch: 210  Training loss = 3.2095  Validation loss = 1.6788  \n",
      "\n",
      "Fold: 27  Epoch: 211  Training loss = 3.2093  Validation loss = 1.6770  \n",
      "\n",
      "Fold: 27  Epoch: 212  Training loss = 3.2092  Validation loss = 1.6777  \n",
      "\n",
      "Fold: 27  Epoch: 213  Training loss = 3.2089  Validation loss = 1.6761  \n",
      "\n",
      "Fold: 27  Epoch: 214  Training loss = 3.2086  Validation loss = 1.6751  \n",
      "\n",
      "Fold: 27  Epoch: 215  Training loss = 3.2082  Validation loss = 1.6733  \n",
      "\n",
      "Fold: 27  Epoch: 216  Training loss = 3.2080  Validation loss = 1.6735  \n",
      "\n",
      "Fold: 27  Epoch: 217  Training loss = 3.2078  Validation loss = 1.6724  \n",
      "\n",
      "Fold: 27  Epoch: 218  Training loss = 3.2073  Validation loss = 1.6700  \n",
      "\n",
      "Fold: 27  Epoch: 219  Training loss = 3.2070  Validation loss = 1.6681  \n",
      "\n",
      "Fold: 27  Epoch: 220  Training loss = 3.2070  Validation loss = 1.6681  \n",
      "\n",
      "Fold: 27  Epoch: 221  Training loss = 3.2066  Validation loss = 1.6665  \n",
      "\n",
      "Fold: 27  Epoch: 222  Training loss = 3.2063  Validation loss = 1.6655  \n",
      "\n",
      "Fold: 27  Epoch: 223  Training loss = 3.2059  Validation loss = 1.6626  \n",
      "\n",
      "Fold: 27  Epoch: 224  Training loss = 3.2058  Validation loss = 1.6622  \n",
      "\n",
      "Fold: 27  Epoch: 225  Training loss = 3.2055  Validation loss = 1.6605  \n",
      "\n",
      "Fold: 27  Epoch: 226  Training loss = 3.2052  Validation loss = 1.6598  \n",
      "\n",
      "Fold: 27  Epoch: 227  Training loss = 3.2050  Validation loss = 1.6600  \n",
      "\n",
      "Fold: 27  Epoch: 228  Training loss = 3.2048  Validation loss = 1.6591  \n",
      "\n",
      "Fold: 27  Epoch: 229  Training loss = 3.2046  Validation loss = 1.6589  \n",
      "\n",
      "Fold: 27  Epoch: 230  Training loss = 3.2043  Validation loss = 1.6577  \n",
      "\n",
      "Fold: 27  Epoch: 231  Training loss = 3.2040  Validation loss = 1.6569  \n",
      "\n",
      "Fold: 27  Epoch: 232  Training loss = 3.2038  Validation loss = 1.6572  \n",
      "\n",
      "Fold: 27  Epoch: 233  Training loss = 3.2034  Validation loss = 1.6546  \n",
      "\n",
      "Fold: 27  Epoch: 234  Training loss = 3.2033  Validation loss = 1.6545  \n",
      "\n",
      "Fold: 27  Epoch: 235  Training loss = 3.2029  Validation loss = 1.6523  \n",
      "\n",
      "Fold: 27  Epoch: 236  Training loss = 3.2027  Validation loss = 1.6521  \n",
      "\n",
      "Fold: 27  Epoch: 237  Training loss = 3.2026  Validation loss = 1.6526  \n",
      "\n",
      "Fold: 27  Epoch: 238  Training loss = 3.2025  Validation loss = 1.6528  \n",
      "\n",
      "Fold: 27  Epoch: 239  Training loss = 3.2023  Validation loss = 1.6534  \n",
      "\n",
      "Fold: 27  Epoch: 240  Training loss = 3.2022  Validation loss = 1.6536  \n",
      "\n",
      "Fold: 27  Epoch: 241  Training loss = 3.2021  Validation loss = 1.6539  \n",
      "\n",
      "Fold: 27  Epoch: 242  Training loss = 3.2017  Validation loss = 1.6524  \n",
      "\n",
      "Fold: 27  Epoch: 243  Training loss = 3.2014  Validation loss = 1.6515  \n",
      "\n",
      "Fold: 27  Epoch: 244  Training loss = 3.2012  Validation loss = 1.6503  \n",
      "\n",
      "Fold: 27  Epoch: 245  Training loss = 3.2009  Validation loss = 1.6484  \n",
      "\n",
      "Fold: 27  Epoch: 246  Training loss = 3.2008  Validation loss = 1.6485  \n",
      "\n",
      "Fold: 27  Epoch: 247  Training loss = 3.2005  Validation loss = 1.6473  \n",
      "\n",
      "Fold: 27  Epoch: 248  Training loss = 3.2003  Validation loss = 1.6466  \n",
      "\n",
      "Fold: 27  Epoch: 249  Training loss = 3.2000  Validation loss = 1.6434  \n",
      "\n",
      "Fold: 27  Epoch: 250  Training loss = 3.1997  Validation loss = 1.6415  \n",
      "\n",
      "Fold: 27  Epoch: 251  Training loss = 3.1995  Validation loss = 1.6411  \n",
      "\n",
      "Fold: 27  Epoch: 252  Training loss = 3.1993  Validation loss = 1.6401  \n",
      "\n",
      "Fold: 27  Epoch: 253  Training loss = 3.1990  Validation loss = 1.6375  \n",
      "\n",
      "Fold: 27  Epoch: 254  Training loss = 3.1989  Validation loss = 1.6370  \n",
      "\n",
      "Fold: 27  Epoch: 255  Training loss = 3.1987  Validation loss = 1.6366  \n",
      "\n",
      "Fold: 27  Epoch: 256  Training loss = 3.1986  Validation loss = 1.6370  \n",
      "\n",
      "Fold: 27  Epoch: 257  Training loss = 3.1983  Validation loss = 1.6363  \n",
      "\n",
      "Fold: 27  Epoch: 258  Training loss = 3.1982  Validation loss = 1.6359  \n",
      "\n",
      "Fold: 27  Epoch: 259  Training loss = 3.1981  Validation loss = 1.6370  \n",
      "\n",
      "Fold: 27  Epoch: 260  Training loss = 3.1979  Validation loss = 1.6365  \n",
      "\n",
      "Fold: 27  Epoch: 261  Training loss = 3.1977  Validation loss = 1.6343  \n",
      "\n",
      "Fold: 27  Epoch: 262  Training loss = 3.1975  Validation loss = 1.6326  \n",
      "\n",
      "Fold: 27  Epoch: 263  Training loss = 3.1973  Validation loss = 1.6318  \n",
      "\n",
      "Fold: 27  Epoch: 264  Training loss = 3.1973  Validation loss = 1.6341  \n",
      "\n",
      "Fold: 27  Epoch: 265  Training loss = 3.1972  Validation loss = 1.6363  \n",
      "\n",
      "Fold: 27  Epoch: 266  Training loss = 3.1970  Validation loss = 1.6362  \n",
      "\n",
      "Fold: 27  Epoch: 267  Training loss = 3.1968  Validation loss = 1.6331  \n",
      "\n",
      "Fold: 27  Epoch: 268  Training loss = 3.1966  Validation loss = 1.6310  \n",
      "\n",
      "Fold: 27  Epoch: 269  Training loss = 3.1964  Validation loss = 1.6306  \n",
      "\n",
      "Fold: 27  Epoch: 270  Training loss = 3.1963  Validation loss = 1.6302  \n",
      "\n",
      "Fold: 27  Epoch: 271  Training loss = 3.1961  Validation loss = 1.6302  \n",
      "\n",
      "Fold: 27  Epoch: 272  Training loss = 3.1960  Validation loss = 1.6299  \n",
      "\n",
      "Fold: 27  Epoch: 273  Training loss = 3.1959  Validation loss = 1.6312  \n",
      "\n",
      "Fold: 27  Epoch: 274  Training loss = 3.1957  Validation loss = 1.6290  \n",
      "\n",
      "Fold: 27  Epoch: 275  Training loss = 3.1956  Validation loss = 1.6272  \n",
      "\n",
      "Fold: 27  Epoch: 276  Training loss = 3.1953  Validation loss = 1.6267  \n",
      "\n",
      "Fold: 27  Epoch: 277  Training loss = 3.1952  Validation loss = 1.6241  \n",
      "\n",
      "Fold: 27  Epoch: 278  Training loss = 3.1951  Validation loss = 1.6229  \n",
      "\n",
      "Fold: 27  Epoch: 279  Training loss = 3.1950  Validation loss = 1.6214  \n",
      "\n",
      "Fold: 27  Epoch: 280  Training loss = 3.1948  Validation loss = 1.6217  \n",
      "\n",
      "Fold: 27  Epoch: 281  Training loss = 3.1946  Validation loss = 1.6218  \n",
      "\n",
      "Fold: 27  Epoch: 282  Training loss = 3.1945  Validation loss = 1.6210  \n",
      "\n",
      "Fold: 27  Epoch: 283  Training loss = 3.1944  Validation loss = 1.6224  \n",
      "\n",
      "Fold: 27  Epoch: 284  Training loss = 3.1943  Validation loss = 1.6188  \n",
      "\n",
      "Fold: 27  Epoch: 285  Training loss = 3.1944  Validation loss = 1.6146  \n",
      "\n",
      "Fold: 27  Epoch: 286  Training loss = 3.1940  Validation loss = 1.6168  \n",
      "\n",
      "Fold: 27  Epoch: 287  Training loss = 3.1939  Validation loss = 1.6160  \n",
      "\n",
      "Fold: 27  Epoch: 288  Training loss = 3.1938  Validation loss = 1.6166  \n",
      "\n",
      "Fold: 27  Epoch: 289  Training loss = 3.1936  Validation loss = 1.6178  \n",
      "\n",
      "Fold: 27  Epoch: 290  Training loss = 3.1935  Validation loss = 1.6175  \n",
      "\n",
      "Fold: 27  Epoch: 291  Training loss = 3.1932  Validation loss = 1.6180  \n",
      "\n",
      "Fold: 27  Epoch: 292  Training loss = 3.1930  Validation loss = 1.6195  \n",
      "\n",
      "Fold: 27  Epoch: 293  Training loss = 3.1929  Validation loss = 1.6164  \n",
      "\n",
      "Fold: 27  Epoch: 294  Training loss = 3.1927  Validation loss = 1.6168  \n",
      "\n",
      "Fold: 27  Epoch: 295  Training loss = 3.1925  Validation loss = 1.6180  \n",
      "\n",
      "Fold: 27  Epoch: 296  Training loss = 3.1923  Validation loss = 1.6194  \n",
      "\n",
      "Fold: 27  Epoch: 297  Training loss = 3.1921  Validation loss = 1.6179  \n",
      "\n",
      "Fold: 27  Epoch: 298  Training loss = 3.1920  Validation loss = 1.6179  \n",
      "\n",
      "Fold: 27  Epoch: 299  Training loss = 3.1918  Validation loss = 1.6159  \n",
      "\n",
      "Fold: 27  Epoch: 300  Training loss = 3.1918  Validation loss = 1.6132  \n",
      "\n",
      "Fold: 27  Epoch: 301  Training loss = 3.1916  Validation loss = 1.6143  \n",
      "\n",
      "Fold: 27  Epoch: 302  Training loss = 3.1914  Validation loss = 1.6142  \n",
      "\n",
      "Fold: 27  Epoch: 303  Training loss = 3.1912  Validation loss = 1.6159  \n",
      "\n",
      "Fold: 27  Epoch: 304  Training loss = 3.1911  Validation loss = 1.6143  \n",
      "\n",
      "Fold: 27  Epoch: 305  Training loss = 3.1910  Validation loss = 1.6137  \n",
      "\n",
      "Fold: 27  Epoch: 306  Training loss = 3.1909  Validation loss = 1.6120  \n",
      "\n",
      "Fold: 27  Epoch: 307  Training loss = 3.1908  Validation loss = 1.6117  \n",
      "\n",
      "Fold: 27  Epoch: 308  Training loss = 3.1906  Validation loss = 1.6127  \n",
      "\n",
      "Fold: 27  Epoch: 309  Training loss = 3.1904  Validation loss = 1.6127  \n",
      "\n",
      "Fold: 27  Epoch: 310  Training loss = 3.1903  Validation loss = 1.6113  \n",
      "\n",
      "Fold: 27  Epoch: 311  Training loss = 3.1902  Validation loss = 1.6107  \n",
      "\n",
      "Fold: 27  Epoch: 312  Training loss = 3.1901  Validation loss = 1.6095  \n",
      "\n",
      "Fold: 27  Epoch: 313  Training loss = 3.1898  Validation loss = 1.6122  \n",
      "\n",
      "Fold: 27  Epoch: 314  Training loss = 3.1897  Validation loss = 1.6126  \n",
      "\n",
      "Fold: 27  Epoch: 315  Training loss = 3.1896  Validation loss = 1.6112  \n",
      "\n",
      "Fold: 27  Epoch: 316  Training loss = 3.1895  Validation loss = 1.6105  \n",
      "\n",
      "Fold: 27  Epoch: 317  Training loss = 3.1894  Validation loss = 1.6096  \n",
      "\n",
      "Fold: 27  Epoch: 318  Training loss = 3.1892  Validation loss = 1.6090  \n",
      "\n",
      "Fold: 27  Epoch: 319  Training loss = 3.1891  Validation loss = 1.6089  \n",
      "\n",
      "Fold: 27  Epoch: 320  Training loss = 3.1890  Validation loss = 1.6087  \n",
      "\n",
      "Fold: 27  Epoch: 321  Training loss = 3.1888  Validation loss = 1.6099  \n",
      "\n",
      "Fold: 27  Epoch: 322  Training loss = 3.1886  Validation loss = 1.6108  \n",
      "\n",
      "Fold: 27  Epoch: 323  Training loss = 3.1884  Validation loss = 1.6112  \n",
      "\n",
      "Fold: 27  Epoch: 324  Training loss = 3.1883  Validation loss = 1.6101  \n",
      "\n",
      "Fold: 27  Epoch: 325  Training loss = 3.1882  Validation loss = 1.6095  \n",
      "\n",
      "Fold: 27  Epoch: 326  Training loss = 3.1879  Validation loss = 1.6125  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 320  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.1815  Validation loss = 2.2324  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.1812  Validation loss = 2.2322  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.1811  Validation loss = 2.2320  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.1809  Validation loss = 2.2314  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.1807  Validation loss = 2.2295  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.1805  Validation loss = 2.2289  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.1803  Validation loss = 2.2287  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.1801  Validation loss = 2.2264  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.1799  Validation loss = 2.2263  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.1797  Validation loss = 2.2267  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.1795  Validation loss = 2.2254  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 3.1793  Validation loss = 2.2243  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 3.1791  Validation loss = 2.2245  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 3.1790  Validation loss = 2.2222  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 3.1788  Validation loss = 2.2210  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 3.1786  Validation loss = 2.2204  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 3.1785  Validation loss = 2.2190  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 3.1782  Validation loss = 2.2198  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 3.1780  Validation loss = 2.2201  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 3.1779  Validation loss = 2.2198  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 3.1777  Validation loss = 2.2187  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 3.1774  Validation loss = 2.2192  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 3.1773  Validation loss = 2.2171  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 3.1772  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 3.1771  Validation loss = 2.2156  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 3.1768  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 3.1765  Validation loss = 2.2196  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 3.1763  Validation loss = 2.2196  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 3.1761  Validation loss = 2.2189  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 3.1759  Validation loss = 2.2181  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 3.1758  Validation loss = 2.2182  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 3.1756  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 3.1755  Validation loss = 2.2153  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 3.1754  Validation loss = 2.2144  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 3.1753  Validation loss = 2.2123  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 3.1752  Validation loss = 2.2122  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 3.1751  Validation loss = 2.2104  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 3.1748  Validation loss = 2.2112  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 3.1748  Validation loss = 2.2096  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 3.1748  Validation loss = 2.2076  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 3.1744  Validation loss = 2.2083  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 3.1742  Validation loss = 2.2081  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 3.1740  Validation loss = 2.2082  \n",
      "\n",
      "Fold: 28  Epoch: 44  Training loss = 3.1738  Validation loss = 2.2079  \n",
      "\n",
      "Fold: 28  Epoch: 45  Training loss = 3.1735  Validation loss = 2.2077  \n",
      "\n",
      "Fold: 28  Epoch: 46  Training loss = 3.1734  Validation loss = 2.2070  \n",
      "\n",
      "Fold: 28  Epoch: 47  Training loss = 3.1732  Validation loss = 2.2071  \n",
      "\n",
      "Fold: 28  Epoch: 48  Training loss = 3.1731  Validation loss = 2.2061  \n",
      "\n",
      "Fold: 28  Epoch: 49  Training loss = 3.1731  Validation loss = 2.2039  \n",
      "\n",
      "Fold: 28  Epoch: 50  Training loss = 3.1730  Validation loss = 2.2028  \n",
      "\n",
      "Fold: 28  Epoch: 51  Training loss = 3.1727  Validation loss = 2.2037  \n",
      "\n",
      "Fold: 28  Epoch: 52  Training loss = 3.1725  Validation loss = 2.2031  \n",
      "\n",
      "Fold: 28  Epoch: 53  Training loss = 3.1724  Validation loss = 2.2023  \n",
      "\n",
      "Fold: 28  Epoch: 54  Training loss = 3.1721  Validation loss = 2.2031  \n",
      "\n",
      "Fold: 28  Epoch: 55  Training loss = 3.1720  Validation loss = 2.2016  \n",
      "\n",
      "Fold: 28  Epoch: 56  Training loss = 3.1716  Validation loss = 2.2033  \n",
      "\n",
      "Fold: 28  Epoch: 57  Training loss = 3.1713  Validation loss = 2.2040  \n",
      "\n",
      "Fold: 28  Epoch: 58  Training loss = 3.1712  Validation loss = 2.2022  \n",
      "\n",
      "Fold: 28  Epoch: 59  Training loss = 3.1711  Validation loss = 2.2020  \n",
      "\n",
      "Fold: 28  Epoch: 60  Training loss = 3.1707  Validation loss = 2.2041  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 55  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.2064  Validation loss = 1.1415  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.2061  Validation loss = 1.1412  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.2060  Validation loss = 1.1412  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.2058  Validation loss = 1.1409  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.2055  Validation loss = 1.1405  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.2054  Validation loss = 1.1404  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.2053  Validation loss = 1.1402  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.2052  Validation loss = 1.1401  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.2050  Validation loss = 1.1398  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.2048  Validation loss = 1.1395  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.2048  Validation loss = 1.1394  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 3.2048  Validation loss = 1.1392  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.2042  Validation loss = 1.1390  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 3.2040  Validation loss = 1.1387  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 3.2038  Validation loss = 1.1386  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 3.2036  Validation loss = 1.1383  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 3.2033  Validation loss = 1.1381  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 3.2029  Validation loss = 1.1377  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 3.2027  Validation loss = 1.1376  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 3.2025  Validation loss = 1.1376  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 3.2024  Validation loss = 1.1374  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 3.2020  Validation loss = 1.1371  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 3.2017  Validation loss = 1.1368  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 3.2016  Validation loss = 1.1368  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 3.2014  Validation loss = 1.1365  \n",
      "\n",
      "Fold: 29  Epoch: 26  Training loss = 3.2013  Validation loss = 1.1364  \n",
      "\n",
      "Fold: 29  Epoch: 27  Training loss = 3.2010  Validation loss = 1.1363  \n",
      "\n",
      "Fold: 29  Epoch: 28  Training loss = 3.2007  Validation loss = 1.1359  \n",
      "\n",
      "Fold: 29  Epoch: 29  Training loss = 3.2006  Validation loss = 1.1359  \n",
      "\n",
      "Fold: 29  Epoch: 30  Training loss = 3.2004  Validation loss = 1.1355  \n",
      "\n",
      "Fold: 29  Epoch: 31  Training loss = 3.2002  Validation loss = 1.1355  \n",
      "\n",
      "Fold: 29  Epoch: 32  Training loss = 3.1999  Validation loss = 1.1352  \n",
      "\n",
      "Fold: 29  Epoch: 33  Training loss = 3.1997  Validation loss = 1.1351  \n",
      "\n",
      "Fold: 29  Epoch: 34  Training loss = 3.1995  Validation loss = 1.1350  \n",
      "\n",
      "Fold: 29  Epoch: 35  Training loss = 3.1994  Validation loss = 1.1348  \n",
      "\n",
      "Fold: 29  Epoch: 36  Training loss = 3.1992  Validation loss = 1.1348  \n",
      "\n",
      "Fold: 29  Epoch: 37  Training loss = 3.1989  Validation loss = 1.1346  \n",
      "\n",
      "Fold: 29  Epoch: 38  Training loss = 3.1988  Validation loss = 1.1346  \n",
      "\n",
      "Fold: 29  Epoch: 39  Training loss = 3.1985  Validation loss = 1.1343  \n",
      "\n",
      "Fold: 29  Epoch: 40  Training loss = 3.1984  Validation loss = 1.1339  \n",
      "\n",
      "Fold: 29  Epoch: 41  Training loss = 3.1983  Validation loss = 1.1335  \n",
      "\n",
      "Fold: 29  Epoch: 42  Training loss = 3.1980  Validation loss = 1.1333  \n",
      "\n",
      "Fold: 29  Epoch: 43  Training loss = 3.1978  Validation loss = 1.1335  \n",
      "\n",
      "Fold: 29  Epoch: 44  Training loss = 3.1976  Validation loss = 1.1333  \n",
      "\n",
      "Fold: 29  Epoch: 45  Training loss = 3.1975  Validation loss = 1.1331  \n",
      "\n",
      "Fold: 29  Epoch: 46  Training loss = 3.1972  Validation loss = 1.1329  \n",
      "\n",
      "Fold: 29  Epoch: 47  Training loss = 3.1970  Validation loss = 1.1327  \n",
      "\n",
      "Fold: 29  Epoch: 48  Training loss = 3.1967  Validation loss = 1.1322  \n",
      "\n",
      "Fold: 29  Epoch: 49  Training loss = 3.1965  Validation loss = 1.1322  \n",
      "\n",
      "Fold: 29  Epoch: 50  Training loss = 3.1964  Validation loss = 1.1319  \n",
      "\n",
      "Fold: 29  Epoch: 51  Training loss = 3.1962  Validation loss = 1.1318  \n",
      "\n",
      "Fold: 29  Epoch: 52  Training loss = 3.1960  Validation loss = 1.1313  \n",
      "\n",
      "Fold: 29  Epoch: 53  Training loss = 3.1956  Validation loss = 1.1311  \n",
      "\n",
      "Fold: 29  Epoch: 54  Training loss = 3.1955  Validation loss = 1.1308  \n",
      "\n",
      "Fold: 29  Epoch: 55  Training loss = 3.1953  Validation loss = 1.1306  \n",
      "\n",
      "Fold: 29  Epoch: 56  Training loss = 3.1952  Validation loss = 1.1305  \n",
      "\n",
      "Fold: 29  Epoch: 57  Training loss = 3.1949  Validation loss = 1.1305  \n",
      "\n",
      "Fold: 29  Epoch: 58  Training loss = 3.1947  Validation loss = 1.1306  \n",
      "\n",
      "Fold: 29  Epoch: 59  Training loss = 3.1946  Validation loss = 1.1305  \n",
      "\n",
      "Fold: 29  Epoch: 60  Training loss = 3.1945  Validation loss = 1.1304  \n",
      "\n",
      "Fold: 29  Epoch: 61  Training loss = 3.1942  Validation loss = 1.1303  \n",
      "\n",
      "Fold: 29  Epoch: 62  Training loss = 3.1940  Validation loss = 1.1303  \n",
      "\n",
      "Fold: 29  Epoch: 63  Training loss = 3.1938  Validation loss = 1.1302  \n",
      "\n",
      "Fold: 29  Epoch: 64  Training loss = 3.1935  Validation loss = 1.1299  \n",
      "\n",
      "Fold: 29  Epoch: 65  Training loss = 3.1932  Validation loss = 1.1297  \n",
      "\n",
      "Fold: 29  Epoch: 66  Training loss = 3.1930  Validation loss = 1.1294  \n",
      "\n",
      "Fold: 29  Epoch: 67  Training loss = 3.1929  Validation loss = 1.1292  \n",
      "\n",
      "Fold: 29  Epoch: 68  Training loss = 3.1927  Validation loss = 1.1290  \n",
      "\n",
      "Fold: 29  Epoch: 69  Training loss = 3.1926  Validation loss = 1.1283  \n",
      "\n",
      "Fold: 29  Epoch: 70  Training loss = 3.1923  Validation loss = 1.1282  \n",
      "\n",
      "Fold: 29  Epoch: 71  Training loss = 3.1920  Validation loss = 1.1281  \n",
      "\n",
      "Fold: 29  Epoch: 72  Training loss = 3.1918  Validation loss = 1.1281  \n",
      "\n",
      "Fold: 29  Epoch: 73  Training loss = 3.1915  Validation loss = 1.1279  \n",
      "\n",
      "Fold: 29  Epoch: 74  Training loss = 3.1913  Validation loss = 1.1278  \n",
      "\n",
      "Fold: 29  Epoch: 75  Training loss = 3.1911  Validation loss = 1.1278  \n",
      "\n",
      "Fold: 29  Epoch: 76  Training loss = 3.1910  Validation loss = 1.1277  \n",
      "\n",
      "Fold: 29  Epoch: 77  Training loss = 3.1908  Validation loss = 1.1272  \n",
      "\n",
      "Fold: 29  Epoch: 78  Training loss = 3.1906  Validation loss = 1.1272  \n",
      "\n",
      "Fold: 29  Epoch: 79  Training loss = 3.1904  Validation loss = 1.1271  \n",
      "\n",
      "Fold: 29  Epoch: 80  Training loss = 3.1901  Validation loss = 1.1271  \n",
      "\n",
      "Fold: 29  Epoch: 81  Training loss = 3.1900  Validation loss = 1.1268  \n",
      "\n",
      "Fold: 29  Epoch: 82  Training loss = 3.1897  Validation loss = 1.1266  \n",
      "\n",
      "Fold: 29  Epoch: 83  Training loss = 3.1895  Validation loss = 1.1266  \n",
      "\n",
      "Fold: 29  Epoch: 84  Training loss = 3.1892  Validation loss = 1.1266  \n",
      "\n",
      "Fold: 29  Epoch: 85  Training loss = 3.1890  Validation loss = 1.1263  \n",
      "\n",
      "Fold: 29  Epoch: 86  Training loss = 3.1890  Validation loss = 1.1259  \n",
      "\n",
      "Fold: 29  Epoch: 87  Training loss = 3.1887  Validation loss = 1.1259  \n",
      "\n",
      "Fold: 29  Epoch: 88  Training loss = 3.1885  Validation loss = 1.1256  \n",
      "\n",
      "Fold: 29  Epoch: 89  Training loss = 3.1883  Validation loss = 1.1252  \n",
      "\n",
      "Fold: 29  Epoch: 90  Training loss = 3.1882  Validation loss = 1.1253  \n",
      "\n",
      "Fold: 29  Epoch: 91  Training loss = 3.1882  Validation loss = 1.1250  \n",
      "\n",
      "Fold: 29  Epoch: 92  Training loss = 3.1880  Validation loss = 1.1248  \n",
      "\n",
      "Fold: 29  Epoch: 93  Training loss = 3.1877  Validation loss = 1.1248  \n",
      "\n",
      "Fold: 29  Epoch: 94  Training loss = 3.1873  Validation loss = 1.1246  \n",
      "\n",
      "Fold: 29  Epoch: 95  Training loss = 3.1872  Validation loss = 1.1243  \n",
      "\n",
      "Fold: 29  Epoch: 96  Training loss = 3.1869  Validation loss = 1.1241  \n",
      "\n",
      "Fold: 29  Epoch: 97  Training loss = 3.1867  Validation loss = 1.1238  \n",
      "\n",
      "Fold: 29  Epoch: 98  Training loss = 3.1863  Validation loss = 1.1239  \n",
      "\n",
      "Fold: 29  Epoch: 99  Training loss = 3.1861  Validation loss = 1.1236  \n",
      "\n",
      "Fold: 29  Epoch: 100  Training loss = 3.1859  Validation loss = 1.1235  \n",
      "\n",
      "Fold: 29  Epoch: 101  Training loss = 3.1856  Validation loss = 1.1234  \n",
      "\n",
      "Fold: 29  Epoch: 102  Training loss = 3.1855  Validation loss = 1.1231  \n",
      "\n",
      "Fold: 29  Epoch: 103  Training loss = 3.1852  Validation loss = 1.1228  \n",
      "\n",
      "Fold: 29  Epoch: 104  Training loss = 3.1850  Validation loss = 1.1228  \n",
      "\n",
      "Fold: 29  Epoch: 105  Training loss = 3.1849  Validation loss = 1.1226  \n",
      "\n",
      "Fold: 29  Epoch: 106  Training loss = 3.1847  Validation loss = 1.1225  \n",
      "\n",
      "Fold: 29  Epoch: 107  Training loss = 3.1844  Validation loss = 1.1224  \n",
      "\n",
      "Fold: 29  Epoch: 108  Training loss = 3.1842  Validation loss = 1.1223  \n",
      "\n",
      "Fold: 29  Epoch: 109  Training loss = 3.1840  Validation loss = 1.1220  \n",
      "\n",
      "Fold: 29  Epoch: 110  Training loss = 3.1838  Validation loss = 1.1218  \n",
      "\n",
      "Fold: 29  Epoch: 111  Training loss = 3.1836  Validation loss = 1.1219  \n",
      "\n",
      "Fold: 29  Epoch: 112  Training loss = 3.1833  Validation loss = 1.1217  \n",
      "\n",
      "Fold: 29  Epoch: 113  Training loss = 3.1831  Validation loss = 1.1214  \n",
      "\n",
      "Fold: 29  Epoch: 114  Training loss = 3.1830  Validation loss = 1.1211  \n",
      "\n",
      "Fold: 29  Epoch: 115  Training loss = 3.1829  Validation loss = 1.1208  \n",
      "\n",
      "Fold: 29  Epoch: 116  Training loss = 3.1827  Validation loss = 1.1205  \n",
      "\n",
      "Fold: 29  Epoch: 117  Training loss = 3.1825  Validation loss = 1.1204  \n",
      "\n",
      "Fold: 29  Epoch: 118  Training loss = 3.1822  Validation loss = 1.1204  \n",
      "\n",
      "Fold: 29  Epoch: 119  Training loss = 3.1821  Validation loss = 1.1200  \n",
      "\n",
      "Fold: 29  Epoch: 120  Training loss = 3.1819  Validation loss = 1.1198  \n",
      "\n",
      "Fold: 29  Epoch: 121  Training loss = 3.1819  Validation loss = 1.1196  \n",
      "\n",
      "Fold: 29  Epoch: 122  Training loss = 3.1816  Validation loss = 1.1194  \n",
      "\n",
      "Fold: 29  Epoch: 123  Training loss = 3.1813  Validation loss = 1.1192  \n",
      "\n",
      "Fold: 29  Epoch: 124  Training loss = 3.1813  Validation loss = 1.1190  \n",
      "\n",
      "Fold: 29  Epoch: 125  Training loss = 3.1812  Validation loss = 1.1186  \n",
      "\n",
      "Fold: 29  Epoch: 126  Training loss = 3.1807  Validation loss = 1.1186  \n",
      "\n",
      "Fold: 29  Epoch: 127  Training loss = 3.1804  Validation loss = 1.1185  \n",
      "\n",
      "Fold: 29  Epoch: 128  Training loss = 3.1801  Validation loss = 1.1182  \n",
      "\n",
      "Fold: 29  Epoch: 129  Training loss = 3.1800  Validation loss = 1.1180  \n",
      "\n",
      "Fold: 29  Epoch: 130  Training loss = 3.1798  Validation loss = 1.1180  \n",
      "\n",
      "Fold: 29  Epoch: 131  Training loss = 3.1796  Validation loss = 1.1178  \n",
      "\n",
      "Fold: 29  Epoch: 132  Training loss = 3.1794  Validation loss = 1.1178  \n",
      "\n",
      "Fold: 29  Epoch: 133  Training loss = 3.1792  Validation loss = 1.1176  \n",
      "\n",
      "Fold: 29  Epoch: 134  Training loss = 3.1790  Validation loss = 1.1175  \n",
      "\n",
      "Fold: 29  Epoch: 135  Training loss = 3.1788  Validation loss = 1.1174  \n",
      "\n",
      "Fold: 29  Epoch: 136  Training loss = 3.1786  Validation loss = 1.1173  \n",
      "\n",
      "Fold: 29  Epoch: 137  Training loss = 3.1784  Validation loss = 1.1172  \n",
      "\n",
      "Fold: 29  Epoch: 138  Training loss = 3.1782  Validation loss = 1.1171  \n",
      "\n",
      "Fold: 29  Epoch: 139  Training loss = 3.1781  Validation loss = 1.1172  \n",
      "\n",
      "Fold: 29  Epoch: 140  Training loss = 3.1779  Validation loss = 1.1171  \n",
      "\n",
      "Fold: 29  Epoch: 141  Training loss = 3.1777  Validation loss = 1.1169  \n",
      "\n",
      "Fold: 29  Epoch: 142  Training loss = 3.1775  Validation loss = 1.1169  \n",
      "\n",
      "Fold: 29  Epoch: 143  Training loss = 3.1774  Validation loss = 1.1166  \n",
      "\n",
      "Fold: 29  Epoch: 144  Training loss = 3.1772  Validation loss = 1.1164  \n",
      "\n",
      "Fold: 29  Epoch: 145  Training loss = 3.1771  Validation loss = 1.1162  \n",
      "\n",
      "Fold: 29  Epoch: 146  Training loss = 3.1770  Validation loss = 1.1159  \n",
      "\n",
      "Fold: 29  Epoch: 147  Training loss = 3.1765  Validation loss = 1.1157  \n",
      "\n",
      "Fold: 29  Epoch: 148  Training loss = 3.1763  Validation loss = 1.1154  \n",
      "\n",
      "Fold: 29  Epoch: 149  Training loss = 3.1762  Validation loss = 1.1153  \n",
      "\n",
      "Fold: 29  Epoch: 150  Training loss = 3.1761  Validation loss = 1.1152  \n",
      "\n",
      "Fold: 29  Epoch: 151  Training loss = 3.1754  Validation loss = 1.1148  \n",
      "\n",
      "Fold: 29  Epoch: 152  Training loss = 3.1751  Validation loss = 1.1146  \n",
      "\n",
      "Fold: 29  Epoch: 153  Training loss = 3.1749  Validation loss = 1.1145  \n",
      "\n",
      "Fold: 29  Epoch: 154  Training loss = 3.1749  Validation loss = 1.1144  \n",
      "\n",
      "Fold: 29  Epoch: 155  Training loss = 3.1746  Validation loss = 1.1142  \n",
      "\n",
      "Fold: 29  Epoch: 156  Training loss = 3.1742  Validation loss = 1.1140  \n",
      "\n",
      "Fold: 29  Epoch: 157  Training loss = 3.1740  Validation loss = 1.1140  \n",
      "\n",
      "Fold: 29  Epoch: 158  Training loss = 3.1737  Validation loss = 1.1138  \n",
      "\n",
      "Fold: 29  Epoch: 159  Training loss = 3.1735  Validation loss = 1.1139  \n",
      "\n",
      "Fold: 29  Epoch: 160  Training loss = 3.1733  Validation loss = 1.1137  \n",
      "\n",
      "Fold: 29  Epoch: 161  Training loss = 3.1730  Validation loss = 1.1134  \n",
      "\n",
      "Fold: 29  Epoch: 162  Training loss = 3.1728  Validation loss = 1.1131  \n",
      "\n",
      "Fold: 29  Epoch: 163  Training loss = 3.1726  Validation loss = 1.1131  \n",
      "\n",
      "Fold: 29  Epoch: 164  Training loss = 3.1724  Validation loss = 1.1131  \n",
      "\n",
      "Fold: 29  Epoch: 165  Training loss = 3.1721  Validation loss = 1.1129  \n",
      "\n",
      "Fold: 29  Epoch: 166  Training loss = 3.1719  Validation loss = 1.1125  \n",
      "\n",
      "Fold: 29  Epoch: 167  Training loss = 3.1717  Validation loss = 1.1124  \n",
      "\n",
      "Fold: 29  Epoch: 168  Training loss = 3.1715  Validation loss = 1.1122  \n",
      "\n",
      "Fold: 29  Epoch: 169  Training loss = 3.1714  Validation loss = 1.1120  \n",
      "\n",
      "Fold: 29  Epoch: 170  Training loss = 3.1712  Validation loss = 1.1121  \n",
      "\n",
      "Fold: 29  Epoch: 171  Training loss = 3.1710  Validation loss = 1.1119  \n",
      "\n",
      "Fold: 29  Epoch: 172  Training loss = 3.1708  Validation loss = 1.1118  \n",
      "\n",
      "Fold: 29  Epoch: 173  Training loss = 3.1706  Validation loss = 1.1115  \n",
      "\n",
      "Fold: 29  Epoch: 174  Training loss = 3.1704  Validation loss = 1.1113  \n",
      "\n",
      "Fold: 29  Epoch: 175  Training loss = 3.1702  Validation loss = 1.1112  \n",
      "\n",
      "Fold: 29  Epoch: 176  Training loss = 3.1699  Validation loss = 1.1110  \n",
      "\n",
      "Fold: 29  Epoch: 177  Training loss = 3.1698  Validation loss = 1.1108  \n",
      "\n",
      "Fold: 29  Epoch: 178  Training loss = 3.1696  Validation loss = 1.1106  \n",
      "\n",
      "Fold: 29  Epoch: 179  Training loss = 3.1694  Validation loss = 1.1103  \n",
      "\n",
      "Fold: 29  Epoch: 180  Training loss = 3.1692  Validation loss = 1.1102  \n",
      "\n",
      "Fold: 29  Epoch: 181  Training loss = 3.1690  Validation loss = 1.1102  \n",
      "\n",
      "Fold: 29  Epoch: 182  Training loss = 3.1688  Validation loss = 1.1097  \n",
      "\n",
      "Fold: 29  Epoch: 183  Training loss = 3.1686  Validation loss = 1.1097  \n",
      "\n",
      "Fold: 29  Epoch: 184  Training loss = 3.1684  Validation loss = 1.1096  \n",
      "\n",
      "Fold: 29  Epoch: 185  Training loss = 3.1682  Validation loss = 1.1094  \n",
      "\n",
      "Fold: 29  Epoch: 186  Training loss = 3.1680  Validation loss = 1.1091  \n",
      "\n",
      "Fold: 29  Epoch: 187  Training loss = 3.1677  Validation loss = 1.1089  \n",
      "\n",
      "Fold: 29  Epoch: 188  Training loss = 3.1676  Validation loss = 1.1087  \n",
      "\n",
      "Fold: 29  Epoch: 189  Training loss = 3.1673  Validation loss = 1.1084  \n",
      "\n",
      "Fold: 29  Epoch: 190  Training loss = 3.1671  Validation loss = 1.1082  \n",
      "\n",
      "Fold: 29  Epoch: 191  Training loss = 3.1668  Validation loss = 1.1078  \n",
      "\n",
      "Fold: 29  Epoch: 192  Training loss = 3.1667  Validation loss = 1.1077  \n",
      "\n",
      "Fold: 29  Epoch: 193  Training loss = 3.1664  Validation loss = 1.1074  \n",
      "\n",
      "Fold: 29  Epoch: 194  Training loss = 3.1663  Validation loss = 1.1074  \n",
      "\n",
      "Fold: 29  Epoch: 195  Training loss = 3.1660  Validation loss = 1.1073  \n",
      "\n",
      "Fold: 29  Epoch: 196  Training loss = 3.1658  Validation loss = 1.1069  \n",
      "\n",
      "Fold: 29  Epoch: 197  Training loss = 3.1655  Validation loss = 1.1067  \n",
      "\n",
      "Fold: 29  Epoch: 198  Training loss = 3.1653  Validation loss = 1.1065  \n",
      "\n",
      "Fold: 29  Epoch: 199  Training loss = 3.1651  Validation loss = 1.1063  \n",
      "\n",
      "Fold: 29  Epoch: 200  Training loss = 3.1648  Validation loss = 1.1060  \n",
      "\n",
      "Fold: 29  Epoch: 201  Training loss = 3.1647  Validation loss = 1.1062  \n",
      "\n",
      "Fold: 29  Epoch: 202  Training loss = 3.1645  Validation loss = 1.1061  \n",
      "\n",
      "Fold: 29  Epoch: 203  Training loss = 3.1643  Validation loss = 1.1060  \n",
      "\n",
      "Fold: 29  Epoch: 204  Training loss = 3.1641  Validation loss = 1.1062  \n",
      "\n",
      "Fold: 29  Epoch: 205  Training loss = 3.1640  Validation loss = 1.1061  \n",
      "\n",
      "Fold: 29  Epoch: 206  Training loss = 3.1638  Validation loss = 1.1059  \n",
      "\n",
      "Fold: 29  Epoch: 207  Training loss = 3.1636  Validation loss = 1.1056  \n",
      "\n",
      "Fold: 29  Epoch: 208  Training loss = 3.1634  Validation loss = 1.1055  \n",
      "\n",
      "Fold: 29  Epoch: 209  Training loss = 3.1632  Validation loss = 1.1054  \n",
      "\n",
      "Fold: 29  Epoch: 210  Training loss = 3.1630  Validation loss = 1.1051  \n",
      "\n",
      "Fold: 29  Epoch: 211  Training loss = 3.1628  Validation loss = 1.1048  \n",
      "\n",
      "Fold: 29  Epoch: 212  Training loss = 3.1626  Validation loss = 1.1045  \n",
      "\n",
      "Fold: 29  Epoch: 213  Training loss = 3.1625  Validation loss = 1.1043  \n",
      "\n",
      "Fold: 29  Epoch: 214  Training loss = 3.1623  Validation loss = 1.1041  \n",
      "\n",
      "Fold: 29  Epoch: 215  Training loss = 3.1621  Validation loss = 1.1039  \n",
      "\n",
      "Fold: 29  Epoch: 216  Training loss = 3.1618  Validation loss = 1.1037  \n",
      "\n",
      "Fold: 29  Epoch: 217  Training loss = 3.1617  Validation loss = 1.1037  \n",
      "\n",
      "Fold: 29  Epoch: 218  Training loss = 3.1616  Validation loss = 1.1034  \n",
      "\n",
      "Fold: 29  Epoch: 219  Training loss = 3.1612  Validation loss = 1.1033  \n",
      "\n",
      "Fold: 29  Epoch: 220  Training loss = 3.1610  Validation loss = 1.1032  \n",
      "\n",
      "Fold: 29  Epoch: 221  Training loss = 3.1608  Validation loss = 1.1028  \n",
      "\n",
      "Fold: 29  Epoch: 222  Training loss = 3.1607  Validation loss = 1.1028  \n",
      "\n",
      "Fold: 29  Epoch: 223  Training loss = 3.1605  Validation loss = 1.1027  \n",
      "\n",
      "Fold: 29  Epoch: 224  Training loss = 3.1601  Validation loss = 1.1025  \n",
      "\n",
      "Fold: 29  Epoch: 225  Training loss = 3.1600  Validation loss = 1.1025  \n",
      "\n",
      "Fold: 29  Epoch: 226  Training loss = 3.1598  Validation loss = 1.1023  \n",
      "\n",
      "Fold: 29  Epoch: 227  Training loss = 3.1596  Validation loss = 1.1020  \n",
      "\n",
      "Fold: 29  Epoch: 228  Training loss = 3.1596  Validation loss = 1.1020  \n",
      "\n",
      "Fold: 29  Epoch: 229  Training loss = 3.1595  Validation loss = 1.1017  \n",
      "\n",
      "Fold: 29  Epoch: 230  Training loss = 3.1592  Validation loss = 1.1015  \n",
      "\n",
      "Fold: 29  Epoch: 231  Training loss = 3.1589  Validation loss = 1.1013  \n",
      "\n",
      "Fold: 29  Epoch: 232  Training loss = 3.1587  Validation loss = 1.1013  \n",
      "\n",
      "Fold: 29  Epoch: 233  Training loss = 3.1585  Validation loss = 1.1009  \n",
      "\n",
      "Fold: 29  Epoch: 234  Training loss = 3.1583  Validation loss = 1.1006  \n",
      "\n",
      "Fold: 29  Epoch: 235  Training loss = 3.1579  Validation loss = 1.1004  \n",
      "\n",
      "Fold: 29  Epoch: 236  Training loss = 3.1578  Validation loss = 1.1003  \n",
      "\n",
      "Fold: 29  Epoch: 237  Training loss = 3.1576  Validation loss = 1.1003  \n",
      "\n",
      "Fold: 29  Epoch: 238  Training loss = 3.1574  Validation loss = 1.1002  \n",
      "\n",
      "Fold: 29  Epoch: 239  Training loss = 3.1571  Validation loss = 1.0998  \n",
      "\n",
      "Fold: 29  Epoch: 240  Training loss = 3.1570  Validation loss = 1.0998  \n",
      "\n",
      "Fold: 29  Epoch: 241  Training loss = 3.1568  Validation loss = 1.0998  \n",
      "\n",
      "Fold: 29  Epoch: 242  Training loss = 3.1566  Validation loss = 1.0997  \n",
      "\n",
      "Fold: 29  Epoch: 243  Training loss = 3.1564  Validation loss = 1.0994  \n",
      "\n",
      "Fold: 29  Epoch: 244  Training loss = 3.1561  Validation loss = 1.0991  \n",
      "\n",
      "Fold: 29  Epoch: 245  Training loss = 3.1560  Validation loss = 1.0990  \n",
      "\n",
      "Fold: 29  Epoch: 246  Training loss = 3.1558  Validation loss = 1.0988  \n",
      "\n",
      "Fold: 29  Epoch: 247  Training loss = 3.1556  Validation loss = 1.0985  \n",
      "\n",
      "Fold: 29  Epoch: 248  Training loss = 3.1554  Validation loss = 1.0985  \n",
      "\n",
      "Fold: 29  Epoch: 249  Training loss = 3.1552  Validation loss = 1.0984  \n",
      "\n",
      "Fold: 29  Epoch: 250  Training loss = 3.1552  Validation loss = 1.0983  \n",
      "\n",
      "Fold: 29  Epoch: 251  Training loss = 3.1550  Validation loss = 1.0982  \n",
      "\n",
      "Fold: 29  Epoch: 252  Training loss = 3.1546  Validation loss = 1.0980  \n",
      "\n",
      "Fold: 29  Epoch: 253  Training loss = 3.1545  Validation loss = 1.0978  \n",
      "\n",
      "Fold: 29  Epoch: 254  Training loss = 3.1543  Validation loss = 1.0978  \n",
      "\n",
      "Fold: 29  Epoch: 255  Training loss = 3.1542  Validation loss = 1.0976  \n",
      "\n",
      "Fold: 29  Epoch: 256  Training loss = 3.1540  Validation loss = 1.0973  \n",
      "\n",
      "Fold: 29  Epoch: 257  Training loss = 3.1539  Validation loss = 1.0972  \n",
      "\n",
      "Fold: 29  Epoch: 258  Training loss = 3.1534  Validation loss = 1.0972  \n",
      "\n",
      "Fold: 29  Epoch: 259  Training loss = 3.1533  Validation loss = 1.0969  \n",
      "\n",
      "Fold: 29  Epoch: 260  Training loss = 3.1531  Validation loss = 1.0968  \n",
      "\n",
      "Fold: 29  Epoch: 261  Training loss = 3.1528  Validation loss = 1.0963  \n",
      "\n",
      "Fold: 29  Epoch: 262  Training loss = 3.1526  Validation loss = 1.0961  \n",
      "\n",
      "Fold: 29  Epoch: 263  Training loss = 3.1525  Validation loss = 1.0962  \n",
      "\n",
      "Fold: 29  Epoch: 264  Training loss = 3.1522  Validation loss = 1.0960  \n",
      "\n",
      "Fold: 29  Epoch: 265  Training loss = 3.1520  Validation loss = 1.0957  \n",
      "\n",
      "Fold: 29  Epoch: 266  Training loss = 3.1518  Validation loss = 1.0954  \n",
      "\n",
      "Fold: 29  Epoch: 267  Training loss = 3.1516  Validation loss = 1.0952  \n",
      "\n",
      "Fold: 29  Epoch: 268  Training loss = 3.1513  Validation loss = 1.0948  \n",
      "\n",
      "Fold: 29  Epoch: 269  Training loss = 3.1511  Validation loss = 1.0947  \n",
      "\n",
      "Fold: 29  Epoch: 270  Training loss = 3.1509  Validation loss = 1.0946  \n",
      "\n",
      "Fold: 29  Epoch: 271  Training loss = 3.1507  Validation loss = 1.0945  \n",
      "\n",
      "Fold: 29  Epoch: 272  Training loss = 3.1505  Validation loss = 1.0942  \n",
      "\n",
      "Fold: 29  Epoch: 273  Training loss = 3.1503  Validation loss = 1.0941  \n",
      "\n",
      "Fold: 29  Epoch: 274  Training loss = 3.1501  Validation loss = 1.0937  \n",
      "\n",
      "Fold: 29  Epoch: 275  Training loss = 3.1499  Validation loss = 1.0934  \n",
      "\n",
      "Fold: 29  Epoch: 276  Training loss = 3.1498  Validation loss = 1.0932  \n",
      "\n",
      "Fold: 29  Epoch: 277  Training loss = 3.1496  Validation loss = 1.0932  \n",
      "\n",
      "Fold: 29  Epoch: 278  Training loss = 3.1494  Validation loss = 1.0933  \n",
      "\n",
      "Fold: 29  Epoch: 279  Training loss = 3.1492  Validation loss = 1.0931  \n",
      "\n",
      "Fold: 29  Epoch: 280  Training loss = 3.1490  Validation loss = 1.0929  \n",
      "\n",
      "Fold: 29  Epoch: 281  Training loss = 3.1488  Validation loss = 1.0929  \n",
      "\n",
      "Fold: 29  Epoch: 282  Training loss = 3.1485  Validation loss = 1.0930  \n",
      "\n",
      "Fold: 29  Epoch: 283  Training loss = 3.1482  Validation loss = 1.0929  \n",
      "\n",
      "Fold: 29  Epoch: 284  Training loss = 3.1480  Validation loss = 1.0928  \n",
      "\n",
      "Fold: 29  Epoch: 285  Training loss = 3.1479  Validation loss = 1.0927  \n",
      "\n",
      "Fold: 29  Epoch: 286  Training loss = 3.1478  Validation loss = 1.0926  \n",
      "\n",
      "Fold: 29  Epoch: 287  Training loss = 3.1477  Validation loss = 1.0926  \n",
      "\n",
      "Fold: 29  Epoch: 288  Training loss = 3.1474  Validation loss = 1.0925  \n",
      "\n",
      "Fold: 29  Epoch: 289  Training loss = 3.1474  Validation loss = 1.0922  \n",
      "\n",
      "Fold: 29  Epoch: 290  Training loss = 3.1471  Validation loss = 1.0922  \n",
      "\n",
      "Fold: 29  Epoch: 291  Training loss = 3.1468  Validation loss = 1.0919  \n",
      "\n",
      "Fold: 29  Epoch: 292  Training loss = 3.1464  Validation loss = 1.0914  \n",
      "\n",
      "Fold: 29  Epoch: 293  Training loss = 3.1462  Validation loss = 1.0912  \n",
      "\n",
      "Fold: 29  Epoch: 294  Training loss = 3.1460  Validation loss = 1.0910  \n",
      "\n",
      "Fold: 29  Epoch: 295  Training loss = 3.1457  Validation loss = 1.0907  \n",
      "\n",
      "Fold: 29  Epoch: 296  Training loss = 3.1455  Validation loss = 1.0908  \n",
      "\n",
      "Fold: 29  Epoch: 297  Training loss = 3.1453  Validation loss = 1.0907  \n",
      "\n",
      "Fold: 29  Epoch: 298  Training loss = 3.1450  Validation loss = 1.0905  \n",
      "\n",
      "Fold: 29  Epoch: 299  Training loss = 3.1449  Validation loss = 1.0902  \n",
      "\n",
      "Fold: 29  Epoch: 300  Training loss = 3.1446  Validation loss = 1.0901  \n",
      "\n",
      "Fold: 29  Epoch: 301  Training loss = 3.1444  Validation loss = 1.0899  \n",
      "\n",
      "Fold: 29  Epoch: 302  Training loss = 3.1442  Validation loss = 1.0895  \n",
      "\n",
      "Fold: 29  Epoch: 303  Training loss = 3.1440  Validation loss = 1.0894  \n",
      "\n",
      "Fold: 29  Epoch: 304  Training loss = 3.1438  Validation loss = 1.0891  \n",
      "\n",
      "Fold: 29  Epoch: 305  Training loss = 3.1437  Validation loss = 1.0889  \n",
      "\n",
      "Fold: 29  Epoch: 306  Training loss = 3.1434  Validation loss = 1.0886  \n",
      "\n",
      "Fold: 29  Epoch: 307  Training loss = 3.1432  Validation loss = 1.0884  \n",
      "\n",
      "Fold: 29  Epoch: 308  Training loss = 3.1431  Validation loss = 1.0885  \n",
      "\n",
      "Fold: 29  Epoch: 309  Training loss = 3.1428  Validation loss = 1.0885  \n",
      "\n",
      "Fold: 29  Epoch: 310  Training loss = 3.1425  Validation loss = 1.0885  \n",
      "\n",
      "Fold: 29  Epoch: 311  Training loss = 3.1423  Validation loss = 1.0884  \n",
      "\n",
      "Fold: 29  Epoch: 312  Training loss = 3.1421  Validation loss = 1.0882  \n",
      "\n",
      "Fold: 29  Epoch: 313  Training loss = 3.1419  Validation loss = 1.0881  \n",
      "\n",
      "Fold: 29  Epoch: 314  Training loss = 3.1418  Validation loss = 1.0880  \n",
      "\n",
      "Fold: 29  Epoch: 315  Training loss = 3.1416  Validation loss = 1.0877  \n",
      "\n",
      "Fold: 29  Epoch: 316  Training loss = 3.1414  Validation loss = 1.0876  \n",
      "\n",
      "Fold: 29  Epoch: 317  Training loss = 3.1412  Validation loss = 1.0873  \n",
      "\n",
      "Fold: 29  Epoch: 318  Training loss = 3.1410  Validation loss = 1.0871  \n",
      "\n",
      "Fold: 29  Epoch: 319  Training loss = 3.1407  Validation loss = 1.0871  \n",
      "\n",
      "Fold: 29  Epoch: 320  Training loss = 3.1405  Validation loss = 1.0868  \n",
      "\n",
      "Fold: 29  Epoch: 321  Training loss = 3.1403  Validation loss = 1.0869  \n",
      "\n",
      "Fold: 29  Epoch: 322  Training loss = 3.1400  Validation loss = 1.0869  \n",
      "\n",
      "Fold: 29  Epoch: 323  Training loss = 3.1398  Validation loss = 1.0868  \n",
      "\n",
      "Fold: 29  Epoch: 324  Training loss = 3.1397  Validation loss = 1.0867  \n",
      "\n",
      "Fold: 29  Epoch: 325  Training loss = 3.1394  Validation loss = 1.0866  \n",
      "\n",
      "Fold: 29  Epoch: 326  Training loss = 3.1392  Validation loss = 1.0867  \n",
      "\n",
      "Fold: 29  Epoch: 327  Training loss = 3.1391  Validation loss = 1.0864  \n",
      "\n",
      "Fold: 29  Epoch: 328  Training loss = 3.1389  Validation loss = 1.0864  \n",
      "\n",
      "Fold: 29  Epoch: 329  Training loss = 3.1387  Validation loss = 1.0861  \n",
      "\n",
      "Fold: 29  Epoch: 330  Training loss = 3.1384  Validation loss = 1.0859  \n",
      "\n",
      "Fold: 29  Epoch: 331  Training loss = 3.1382  Validation loss = 1.0858  \n",
      "\n",
      "Fold: 29  Epoch: 332  Training loss = 3.1380  Validation loss = 1.0856  \n",
      "\n",
      "Fold: 29  Epoch: 333  Training loss = 3.1379  Validation loss = 1.0855  \n",
      "\n",
      "Fold: 29  Epoch: 334  Training loss = 3.1377  Validation loss = 1.0852  \n",
      "\n",
      "Fold: 29  Epoch: 335  Training loss = 3.1376  Validation loss = 1.0850  \n",
      "\n",
      "Fold: 29  Epoch: 336  Training loss = 3.1372  Validation loss = 1.0849  \n",
      "\n",
      "Fold: 29  Epoch: 337  Training loss = 3.1370  Validation loss = 1.0848  \n",
      "\n",
      "Fold: 29  Epoch: 338  Training loss = 3.1368  Validation loss = 1.0848  \n",
      "\n",
      "Fold: 29  Epoch: 339  Training loss = 3.1366  Validation loss = 1.0846  \n",
      "\n",
      "Fold: 29  Epoch: 340  Training loss = 3.1364  Validation loss = 1.0847  \n",
      "\n",
      "Fold: 29  Epoch: 341  Training loss = 3.1362  Validation loss = 1.0845  \n",
      "\n",
      "Fold: 29  Epoch: 342  Training loss = 3.1360  Validation loss = 1.0845  \n",
      "\n",
      "Fold: 29  Epoch: 343  Training loss = 3.1357  Validation loss = 1.0843  \n",
      "\n",
      "Fold: 29  Epoch: 344  Training loss = 3.1355  Validation loss = 1.0844  \n",
      "\n",
      "Fold: 29  Epoch: 345  Training loss = 3.1353  Validation loss = 1.0840  \n",
      "\n",
      "Fold: 29  Epoch: 346  Training loss = 3.1352  Validation loss = 1.0837  \n",
      "\n",
      "Fold: 29  Epoch: 347  Training loss = 3.1350  Validation loss = 1.0837  \n",
      "\n",
      "Fold: 29  Epoch: 348  Training loss = 3.1348  Validation loss = 1.0836  \n",
      "\n",
      "Fold: 29  Epoch: 349  Training loss = 3.1347  Validation loss = 1.0833  \n",
      "\n",
      "Fold: 29  Epoch: 350  Training loss = 3.1346  Validation loss = 1.0830  \n",
      "\n",
      "Fold: 29  Epoch: 351  Training loss = 3.1347  Validation loss = 1.0827  \n",
      "\n",
      "Fold: 29  Epoch: 352  Training loss = 3.1345  Validation loss = 1.0827  \n",
      "\n",
      "Fold: 29  Epoch: 353  Training loss = 3.1343  Validation loss = 1.0826  \n",
      "\n",
      "Fold: 29  Epoch: 354  Training loss = 3.1338  Validation loss = 1.0823  \n",
      "\n",
      "Fold: 29  Epoch: 355  Training loss = 3.1335  Validation loss = 1.0820  \n",
      "\n",
      "Fold: 29  Epoch: 356  Training loss = 3.1337  Validation loss = 1.0819  \n",
      "\n",
      "Fold: 29  Epoch: 357  Training loss = 3.1334  Validation loss = 1.0817  \n",
      "\n",
      "Fold: 29  Epoch: 358  Training loss = 3.1333  Validation loss = 1.0818  \n",
      "\n",
      "Fold: 29  Epoch: 359  Training loss = 3.1329  Validation loss = 1.0815  \n",
      "\n",
      "Fold: 29  Epoch: 360  Training loss = 3.1325  Validation loss = 1.0813  \n",
      "\n",
      "Fold: 29  Epoch: 361  Training loss = 3.1321  Validation loss = 1.0813  \n",
      "\n",
      "Fold: 29  Epoch: 362  Training loss = 3.1318  Validation loss = 1.0813  \n",
      "\n",
      "Fold: 29  Epoch: 363  Training loss = 3.1316  Validation loss = 1.0811  \n",
      "\n",
      "Fold: 29  Epoch: 364  Training loss = 3.1314  Validation loss = 1.0811  \n",
      "\n",
      "Fold: 29  Epoch: 365  Training loss = 3.1312  Validation loss = 1.0811  \n",
      "\n",
      "Fold: 29  Epoch: 366  Training loss = 3.1310  Validation loss = 1.0810  \n",
      "\n",
      "Fold: 29  Epoch: 367  Training loss = 3.1308  Validation loss = 1.0810  \n",
      "\n",
      "Fold: 29  Epoch: 368  Training loss = 3.1307  Validation loss = 1.0809  \n",
      "\n",
      "Fold: 29  Epoch: 369  Training loss = 3.1305  Validation loss = 1.0806  \n",
      "\n",
      "Fold: 29  Epoch: 370  Training loss = 3.1302  Validation loss = 1.0804  \n",
      "\n",
      "Fold: 29  Epoch: 371  Training loss = 3.1300  Validation loss = 1.0802  \n",
      "\n",
      "Fold: 29  Epoch: 372  Training loss = 3.1298  Validation loss = 1.0801  \n",
      "\n",
      "Fold: 29  Epoch: 373  Training loss = 3.1296  Validation loss = 1.0800  \n",
      "\n",
      "Fold: 29  Epoch: 374  Training loss = 3.1295  Validation loss = 1.0799  \n",
      "\n",
      "Fold: 29  Epoch: 375  Training loss = 3.1293  Validation loss = 1.0797  \n",
      "\n",
      "Fold: 29  Epoch: 376  Training loss = 3.1291  Validation loss = 1.0796  \n",
      "\n",
      "Fold: 29  Epoch: 377  Training loss = 3.1290  Validation loss = 1.0793  \n",
      "\n",
      "Fold: 29  Epoch: 378  Training loss = 3.1290  Validation loss = 1.0792  \n",
      "\n",
      "Fold: 29  Epoch: 379  Training loss = 3.1286  Validation loss = 1.0788  \n",
      "\n",
      "Fold: 29  Epoch: 380  Training loss = 3.1285  Validation loss = 1.0786  \n",
      "\n",
      "Fold: 29  Epoch: 381  Training loss = 3.1286  Validation loss = 1.0786  \n",
      "\n",
      "Fold: 29  Epoch: 382  Training loss = 3.1283  Validation loss = 1.0784  \n",
      "\n",
      "Fold: 29  Epoch: 383  Training loss = 3.1278  Validation loss = 1.0784  \n",
      "\n",
      "Fold: 29  Epoch: 384  Training loss = 3.1276  Validation loss = 1.0785  \n",
      "\n",
      "Fold: 29  Epoch: 385  Training loss = 3.1272  Validation loss = 1.0786  \n",
      "\n",
      "Fold: 29  Epoch: 386  Training loss = 3.1270  Validation loss = 1.0784  \n",
      "\n",
      "Fold: 29  Epoch: 387  Training loss = 3.1267  Validation loss = 1.0782  \n",
      "\n",
      "Fold: 29  Epoch: 388  Training loss = 3.1266  Validation loss = 1.0782  \n",
      "\n",
      "Fold: 29  Epoch: 389  Training loss = 3.1264  Validation loss = 1.0781  \n",
      "\n",
      "Fold: 29  Epoch: 390  Training loss = 3.1262  Validation loss = 1.0779  \n",
      "\n",
      "Fold: 29  Epoch: 391  Training loss = 3.1259  Validation loss = 1.0776  \n",
      "\n",
      "Fold: 29  Epoch: 392  Training loss = 3.1257  Validation loss = 1.0776  \n",
      "\n",
      "Fold: 29  Epoch: 393  Training loss = 3.1255  Validation loss = 1.0774  \n",
      "\n",
      "Fold: 29  Epoch: 394  Training loss = 3.1253  Validation loss = 1.0770  \n",
      "\n",
      "Fold: 29  Epoch: 395  Training loss = 3.1251  Validation loss = 1.0770  \n",
      "\n",
      "Fold: 29  Epoch: 396  Training loss = 3.1250  Validation loss = 1.0768  \n",
      "\n",
      "Fold: 29  Epoch: 397  Training loss = 3.1248  Validation loss = 1.0768  \n",
      "\n",
      "Fold: 29  Epoch: 398  Training loss = 3.1247  Validation loss = 1.0765  \n",
      "\n",
      "Fold: 29  Epoch: 399  Training loss = 3.1244  Validation loss = 1.0760  \n",
      "\n",
      "Fold: 29  Epoch: 400  Training loss = 3.1241  Validation loss = 1.0758  \n",
      "\n",
      "Fold: 29  Epoch: 401  Training loss = 3.1238  Validation loss = 1.0754  \n",
      "\n",
      "Fold: 29  Epoch: 402  Training loss = 3.1236  Validation loss = 1.0750  \n",
      "\n",
      "Fold: 29  Epoch: 403  Training loss = 3.1234  Validation loss = 1.0749  \n",
      "\n",
      "Fold: 29  Epoch: 404  Training loss = 3.1233  Validation loss = 1.0746  \n",
      "\n",
      "Fold: 29  Epoch: 405  Training loss = 3.1230  Validation loss = 1.0744  \n",
      "\n",
      "Fold: 29  Epoch: 406  Training loss = 3.1228  Validation loss = 1.0745  \n",
      "\n",
      "Fold: 29  Epoch: 407  Training loss = 3.1226  Validation loss = 1.0742  \n",
      "\n",
      "Fold: 29  Epoch: 408  Training loss = 3.1224  Validation loss = 1.0741  \n",
      "\n",
      "Fold: 29  Epoch: 409  Training loss = 3.1222  Validation loss = 1.0737  \n",
      "\n",
      "Fold: 29  Epoch: 410  Training loss = 3.1220  Validation loss = 1.0737  \n",
      "\n",
      "Fold: 29  Epoch: 411  Training loss = 3.1219  Validation loss = 1.0734  \n",
      "\n",
      "Fold: 29  Epoch: 412  Training loss = 3.1217  Validation loss = 1.0732  \n",
      "\n",
      "Fold: 29  Epoch: 413  Training loss = 3.1216  Validation loss = 1.0732  \n",
      "\n",
      "Fold: 29  Epoch: 414  Training loss = 3.1214  Validation loss = 1.0729  \n",
      "\n",
      "Fold: 29  Epoch: 415  Training loss = 3.1211  Validation loss = 1.0729  \n",
      "\n",
      "Fold: 29  Epoch: 416  Training loss = 3.1209  Validation loss = 1.0727  \n",
      "\n",
      "Fold: 29  Epoch: 417  Training loss = 3.1205  Validation loss = 1.0726  \n",
      "\n",
      "Fold: 29  Epoch: 418  Training loss = 3.1204  Validation loss = 1.0724  \n",
      "\n",
      "Fold: 29  Epoch: 419  Training loss = 3.1202  Validation loss = 1.0722  \n",
      "\n",
      "Fold: 29  Epoch: 420  Training loss = 3.1201  Validation loss = 1.0721  \n",
      "\n",
      "Fold: 29  Epoch: 421  Training loss = 3.1198  Validation loss = 1.0718  \n",
      "\n",
      "Fold: 29  Epoch: 422  Training loss = 3.1197  Validation loss = 1.0718  \n",
      "\n",
      "Fold: 29  Epoch: 423  Training loss = 3.1195  Validation loss = 1.0717  \n",
      "\n",
      "Fold: 29  Epoch: 424  Training loss = 3.1193  Validation loss = 1.0714  \n",
      "\n",
      "Fold: 29  Epoch: 425  Training loss = 3.1192  Validation loss = 1.0712  \n",
      "\n",
      "Fold: 29  Epoch: 426  Training loss = 3.1190  Validation loss = 1.0709  \n",
      "\n",
      "Fold: 29  Epoch: 427  Training loss = 3.1188  Validation loss = 1.0707  \n",
      "\n",
      "Fold: 29  Epoch: 428  Training loss = 3.1184  Validation loss = 1.0707  \n",
      "\n",
      "Fold: 29  Epoch: 429  Training loss = 3.1180  Validation loss = 1.0708  \n",
      "\n",
      "Fold: 29  Epoch: 430  Training loss = 3.1178  Validation loss = 1.0708  \n",
      "\n",
      "Fold: 29  Epoch: 431  Training loss = 3.1176  Validation loss = 1.0709  \n",
      "\n",
      "Fold: 29  Epoch: 432  Training loss = 3.1174  Validation loss = 1.0707  \n",
      "\n",
      "Fold: 29  Epoch: 433  Training loss = 3.1173  Validation loss = 1.0706  \n",
      "\n",
      "Fold: 29  Epoch: 434  Training loss = 3.1172  Validation loss = 1.0704  \n",
      "\n",
      "Fold: 29  Epoch: 435  Training loss = 3.1170  Validation loss = 1.0703  \n",
      "\n",
      "Fold: 29  Epoch: 436  Training loss = 3.1168  Validation loss = 1.0702  \n",
      "\n",
      "Fold: 29  Epoch: 437  Training loss = 3.1167  Validation loss = 1.0701  \n",
      "\n",
      "Fold: 29  Epoch: 438  Training loss = 3.1165  Validation loss = 1.0701  \n",
      "\n",
      "Fold: 29  Epoch: 439  Training loss = 3.1164  Validation loss = 1.0702  \n",
      "\n",
      "Fold: 29  Epoch: 440  Training loss = 3.1162  Validation loss = 1.0701  \n",
      "\n",
      "Fold: 29  Epoch: 441  Training loss = 3.1161  Validation loss = 1.0699  \n",
      "\n",
      "Fold: 29  Epoch: 442  Training loss = 3.1158  Validation loss = 1.0695  \n",
      "\n",
      "Fold: 29  Epoch: 443  Training loss = 3.1156  Validation loss = 1.0695  \n",
      "\n",
      "Fold: 29  Epoch: 444  Training loss = 3.1156  Validation loss = 1.0696  \n",
      "\n",
      "Fold: 29  Epoch: 445  Training loss = 3.1153  Validation loss = 1.0695  \n",
      "\n",
      "Fold: 29  Epoch: 446  Training loss = 3.1151  Validation loss = 1.0695  \n",
      "\n",
      "Fold: 29  Epoch: 447  Training loss = 3.1149  Validation loss = 1.0694  \n",
      "\n",
      "Fold: 29  Epoch: 448  Training loss = 3.1148  Validation loss = 1.0694  \n",
      "\n",
      "Fold: 29  Epoch: 449  Training loss = 3.1145  Validation loss = 1.0694  \n",
      "\n",
      "Fold: 29  Epoch: 450  Training loss = 3.1144  Validation loss = 1.0693  \n",
      "\n",
      "Fold: 29  Epoch: 451  Training loss = 3.1146  Validation loss = 1.0693  \n",
      "\n",
      "Fold: 29  Epoch: 452  Training loss = 3.1141  Validation loss = 1.0691  \n",
      "\n",
      "Fold: 29  Epoch: 453  Training loss = 3.1141  Validation loss = 1.0688  \n",
      "\n",
      "Fold: 29  Epoch: 454  Training loss = 3.1137  Validation loss = 1.0687  \n",
      "\n",
      "Fold: 29  Epoch: 455  Training loss = 3.1132  Validation loss = 1.0683  \n",
      "\n",
      "Fold: 29  Epoch: 456  Training loss = 3.1130  Validation loss = 1.0682  \n",
      "\n",
      "Fold: 29  Epoch: 457  Training loss = 3.1130  Validation loss = 1.0682  \n",
      "\n",
      "Fold: 29  Epoch: 458  Training loss = 3.1127  Validation loss = 1.0680  \n",
      "\n",
      "Fold: 29  Epoch: 459  Training loss = 3.1126  Validation loss = 1.0680  \n",
      "\n",
      "Fold: 29  Epoch: 460  Training loss = 3.1125  Validation loss = 1.0677  \n",
      "\n",
      "Fold: 29  Epoch: 461  Training loss = 3.1124  Validation loss = 1.0675  \n",
      "\n",
      "Fold: 29  Epoch: 462  Training loss = 3.1122  Validation loss = 1.0675  \n",
      "\n",
      "Fold: 29  Epoch: 463  Training loss = 3.1120  Validation loss = 1.0673  \n",
      "\n",
      "Fold: 29  Epoch: 464  Training loss = 3.1117  Validation loss = 1.0671  \n",
      "\n",
      "Fold: 29  Epoch: 465  Training loss = 3.1114  Validation loss = 1.0668  \n",
      "\n",
      "Fold: 29  Epoch: 466  Training loss = 3.1113  Validation loss = 1.0668  \n",
      "\n",
      "Fold: 29  Epoch: 467  Training loss = 3.1112  Validation loss = 1.0668  \n",
      "\n",
      "Fold: 29  Epoch: 468  Training loss = 3.1112  Validation loss = 1.0667  \n",
      "\n",
      "Fold: 29  Epoch: 469  Training loss = 3.1109  Validation loss = 1.0666  \n",
      "\n",
      "Fold: 29  Epoch: 470  Training loss = 3.1108  Validation loss = 1.0666  \n",
      "\n",
      "Fold: 29  Epoch: 471  Training loss = 3.1106  Validation loss = 1.0666  \n",
      "\n",
      "Fold: 29  Epoch: 472  Training loss = 3.1103  Validation loss = 1.0663  \n",
      "\n",
      "Fold: 29  Epoch: 473  Training loss = 3.1102  Validation loss = 1.0660  \n",
      "\n",
      "Fold: 29  Epoch: 474  Training loss = 3.1098  Validation loss = 1.0657  \n",
      "\n",
      "Fold: 29  Epoch: 475  Training loss = 3.1095  Validation loss = 1.0653  \n",
      "\n",
      "Fold: 29  Epoch: 476  Training loss = 3.1094  Validation loss = 1.0653  \n",
      "\n",
      "Fold: 29  Epoch: 477  Training loss = 3.1092  Validation loss = 1.0653  \n",
      "\n",
      "Fold: 29  Epoch: 478  Training loss = 3.1092  Validation loss = 1.0651  \n",
      "\n",
      "Fold: 29  Epoch: 479  Training loss = 3.1091  Validation loss = 1.0651  \n",
      "\n",
      "Fold: 29  Epoch: 480  Training loss = 3.1090  Validation loss = 1.0648  \n",
      "\n",
      "Fold: 29  Epoch: 481  Training loss = 3.1086  Validation loss = 1.0645  \n",
      "\n",
      "Fold: 29  Epoch: 482  Training loss = 3.1084  Validation loss = 1.0646  \n",
      "\n",
      "Fold: 29  Epoch: 483  Training loss = 3.1082  Validation loss = 1.0644  \n",
      "\n",
      "Fold: 29  Epoch: 484  Training loss = 3.1079  Validation loss = 1.0643  \n",
      "\n",
      "Fold: 29  Epoch: 485  Training loss = 3.1075  Validation loss = 1.0641  \n",
      "\n",
      "Fold: 29  Epoch: 486  Training loss = 3.1070  Validation loss = 1.0636  \n",
      "\n",
      "Fold: 29  Epoch: 487  Training loss = 3.1069  Validation loss = 1.0636  \n",
      "\n",
      "Fold: 29  Epoch: 488  Training loss = 3.1068  Validation loss = 1.0634  \n",
      "\n",
      "Fold: 29  Epoch: 489  Training loss = 3.1065  Validation loss = 1.0633  \n",
      "\n",
      "Fold: 29  Epoch: 490  Training loss = 3.1063  Validation loss = 1.0632  \n",
      "\n",
      "Fold: 29  Epoch: 491  Training loss = 3.1060  Validation loss = 1.0630  \n",
      "\n",
      "Fold: 29  Epoch: 492  Training loss = 3.1059  Validation loss = 1.0629  \n",
      "\n",
      "Fold: 29  Epoch: 493  Training loss = 3.1055  Validation loss = 1.0626  \n",
      "\n",
      "Fold: 29  Epoch: 494  Training loss = 3.1053  Validation loss = 1.0626  \n",
      "\n",
      "Fold: 29  Epoch: 495  Training loss = 3.1051  Validation loss = 1.0622  \n",
      "\n",
      "Fold: 29  Epoch: 496  Training loss = 3.1049  Validation loss = 1.0621  \n",
      "\n",
      "Fold: 29  Epoch: 497  Training loss = 3.1047  Validation loss = 1.0619  \n",
      "\n",
      "Fold: 29  Epoch: 498  Training loss = 3.1045  Validation loss = 1.0618  \n",
      "\n",
      "Fold: 29  Epoch: 499  Training loss = 3.1043  Validation loss = 1.0617  \n",
      "\n",
      "Fold: 29  Epoch: 500  Training loss = 3.1042  Validation loss = 1.0614  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 500  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.0826  Validation loss = 2.3991  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.0822  Validation loss = 2.4013  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.0823  Validation loss = 2.3964  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.0822  Validation loss = 2.3939  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.0822  Validation loss = 2.3916  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.0823  Validation loss = 2.3888  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.0824  Validation loss = 2.3863  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.0824  Validation loss = 2.3842  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.0817  Validation loss = 2.3873  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.0811  Validation loss = 2.3900  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.0808  Validation loss = 2.3909  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 3.0805  Validation loss = 2.3907  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 3.0806  Validation loss = 2.3882  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 3.0808  Validation loss = 2.3844  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 3.0805  Validation loss = 2.3848  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 3.0801  Validation loss = 2.3866  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 3.0795  Validation loss = 2.3912  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 8  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.8888  Validation loss = 1.9448  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.8886  Validation loss = 1.9440  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.8883  Validation loss = 1.9452  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.8881  Validation loss = 1.9450  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.8882  Validation loss = 1.9337  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.8882  Validation loss = 1.9312  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.8877  Validation loss = 1.9346  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.8876  Validation loss = 1.9316  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.8873  Validation loss = 1.9325  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.8872  Validation loss = 1.9293  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.8869  Validation loss = 1.9293  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.8868  Validation loss = 1.9277  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.8864  Validation loss = 1.9288  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.8858  Validation loss = 1.9346  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 12  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.4255  Validation loss = 3.6717  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.4238  Validation loss = 3.6624  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.4224  Validation loss = 3.6545  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.4210  Validation loss = 3.6474  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.4194  Validation loss = 3.6384  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.4182  Validation loss = 3.6319  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.4155  Validation loss = 3.6168  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.4137  Validation loss = 3.6064  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.4127  Validation loss = 3.6009  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.4115  Validation loss = 3.5945  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.4101  Validation loss = 3.5861  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.4092  Validation loss = 3.5813  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.4086  Validation loss = 3.5779  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.4071  Validation loss = 3.5694  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.4059  Validation loss = 3.5624  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.4053  Validation loss = 3.5586  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.4041  Validation loss = 3.5518  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.4030  Validation loss = 3.5453  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.4020  Validation loss = 3.5394  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.4012  Validation loss = 3.5342  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 2.4007  Validation loss = 3.5314  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 2.3994  Validation loss = 3.5231  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.3979  Validation loss = 3.5142  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 2.3965  Validation loss = 3.5053  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 2.3954  Validation loss = 3.4981  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 2.3944  Validation loss = 3.4915  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 2.3933  Validation loss = 3.4850  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 2.3922  Validation loss = 3.4771  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 2.3911  Validation loss = 3.4694  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 2.3901  Validation loss = 3.4626  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 2.3893  Validation loss = 3.4567  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 2.3888  Validation loss = 3.4543  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 2.3882  Validation loss = 3.4508  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 2.3874  Validation loss = 3.4445  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 2.3868  Validation loss = 3.4407  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 2.3857  Validation loss = 3.4322  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 2.3853  Validation loss = 3.4294  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 2.3846  Validation loss = 3.4257  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 2.3840  Validation loss = 3.4214  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 2.3830  Validation loss = 3.4136  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 2.3824  Validation loss = 3.4103  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 2.3818  Validation loss = 3.4064  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 2.3812  Validation loss = 3.4015  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 2.3808  Validation loss = 3.3993  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 2.3802  Validation loss = 3.3963  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 2.3796  Validation loss = 3.3925  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 2.3790  Validation loss = 3.3882  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 2.3786  Validation loss = 3.3853  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 2.3780  Validation loss = 3.3806  \n",
      "\n",
      "Fold: 32  Epoch: 50  Training loss = 2.3775  Validation loss = 3.3770  \n",
      "\n",
      "Fold: 32  Epoch: 51  Training loss = 2.3772  Validation loss = 3.3763  \n",
      "\n",
      "Fold: 32  Epoch: 52  Training loss = 2.3767  Validation loss = 3.3730  \n",
      "\n",
      "Fold: 32  Epoch: 53  Training loss = 2.3762  Validation loss = 3.3694  \n",
      "\n",
      "Fold: 32  Epoch: 54  Training loss = 2.3757  Validation loss = 3.3677  \n",
      "\n",
      "Fold: 32  Epoch: 55  Training loss = 2.3756  Validation loss = 3.3703  \n",
      "\n",
      "Fold: 32  Epoch: 56  Training loss = 2.3753  Validation loss = 3.3713  \n",
      "\n",
      "Fold: 32  Epoch: 57  Training loss = 2.3749  Validation loss = 3.3679  \n",
      "\n",
      "Fold: 32  Epoch: 58  Training loss = 2.3746  Validation loss = 3.3686  \n",
      "\n",
      "Fold: 32  Epoch: 59  Training loss = 2.3740  Validation loss = 3.3634  \n",
      "\n",
      "Fold: 32  Epoch: 60  Training loss = 2.3735  Validation loss = 3.3594  \n",
      "\n",
      "Fold: 32  Epoch: 61  Training loss = 2.3729  Validation loss = 3.3529  \n",
      "\n",
      "Fold: 32  Epoch: 62  Training loss = 2.3727  Validation loss = 3.3538  \n",
      "\n",
      "Fold: 32  Epoch: 63  Training loss = 2.3722  Validation loss = 3.3514  \n",
      "\n",
      "Fold: 32  Epoch: 64  Training loss = 2.3714  Validation loss = 3.3443  \n",
      "\n",
      "Fold: 32  Epoch: 65  Training loss = 2.3713  Validation loss = 3.3477  \n",
      "\n",
      "Fold: 32  Epoch: 66  Training loss = 2.3711  Validation loss = 3.3481  \n",
      "\n",
      "Fold: 32  Epoch: 67  Training loss = 2.3707  Validation loss = 3.3447  \n",
      "\n",
      "Fold: 32  Epoch: 68  Training loss = 2.3702  Validation loss = 3.3401  \n",
      "\n",
      "Fold: 32  Epoch: 69  Training loss = 2.3694  Validation loss = 3.3331  \n",
      "\n",
      "Fold: 32  Epoch: 70  Training loss = 2.3691  Validation loss = 3.3300  \n",
      "\n",
      "Fold: 32  Epoch: 71  Training loss = 2.3686  Validation loss = 3.3252  \n",
      "\n",
      "Fold: 32  Epoch: 72  Training loss = 2.3682  Validation loss = 3.3237  \n",
      "\n",
      "Fold: 32  Epoch: 73  Training loss = 2.3676  Validation loss = 3.3183  \n",
      "\n",
      "Fold: 32  Epoch: 74  Training loss = 2.3672  Validation loss = 3.3158  \n",
      "\n",
      "Fold: 32  Epoch: 75  Training loss = 2.3668  Validation loss = 3.3135  \n",
      "\n",
      "Fold: 32  Epoch: 76  Training loss = 2.3663  Validation loss = 3.3079  \n",
      "\n",
      "Fold: 32  Epoch: 77  Training loss = 2.3658  Validation loss = 3.3019  \n",
      "\n",
      "Fold: 32  Epoch: 78  Training loss = 2.3652  Validation loss = 3.2973  \n",
      "\n",
      "Fold: 32  Epoch: 79  Training loss = 2.3650  Validation loss = 3.2984  \n",
      "\n",
      "Fold: 32  Epoch: 80  Training loss = 2.3646  Validation loss = 3.2945  \n",
      "\n",
      "Fold: 32  Epoch: 81  Training loss = 2.3642  Validation loss = 3.2928  \n",
      "\n",
      "Fold: 32  Epoch: 82  Training loss = 2.3637  Validation loss = 3.2891  \n",
      "\n",
      "Fold: 32  Epoch: 83  Training loss = 2.3634  Validation loss = 3.2918  \n",
      "\n",
      "Fold: 32  Epoch: 84  Training loss = 2.3630  Validation loss = 3.2921  \n",
      "\n",
      "Fold: 32  Epoch: 85  Training loss = 2.3627  Validation loss = 3.2908  \n",
      "\n",
      "Fold: 32  Epoch: 86  Training loss = 2.3622  Validation loss = 3.2872  \n",
      "\n",
      "Fold: 32  Epoch: 87  Training loss = 2.3619  Validation loss = 3.2858  \n",
      "\n",
      "Fold: 32  Epoch: 88  Training loss = 2.3616  Validation loss = 3.2847  \n",
      "\n",
      "Fold: 32  Epoch: 89  Training loss = 2.3612  Validation loss = 3.2824  \n",
      "\n",
      "Fold: 32  Epoch: 90  Training loss = 2.3608  Validation loss = 3.2784  \n",
      "\n",
      "Fold: 32  Epoch: 91  Training loss = 2.3604  Validation loss = 3.2737  \n",
      "\n",
      "Fold: 32  Epoch: 92  Training loss = 2.3600  Validation loss = 3.2698  \n",
      "\n",
      "Fold: 32  Epoch: 93  Training loss = 2.3594  Validation loss = 3.2712  \n",
      "\n",
      "Fold: 32  Epoch: 94  Training loss = 2.3592  Validation loss = 3.2752  \n",
      "\n",
      "Fold: 32  Epoch: 95  Training loss = 2.3590  Validation loss = 3.2771  \n",
      "\n",
      "Fold: 32  Epoch: 96  Training loss = 2.3585  Validation loss = 3.2742  \n",
      "\n",
      "Fold: 32  Epoch: 97  Training loss = 2.3581  Validation loss = 3.2714  \n",
      "\n",
      "Fold: 32  Epoch: 98  Training loss = 2.3576  Validation loss = 3.2666  \n",
      "\n",
      "Fold: 32  Epoch: 99  Training loss = 2.3571  Validation loss = 3.2626  \n",
      "\n",
      "Fold: 32  Epoch: 100  Training loss = 2.3569  Validation loss = 3.2660  \n",
      "\n",
      "Fold: 32  Epoch: 101  Training loss = 2.3566  Validation loss = 3.2661  \n",
      "\n",
      "Fold: 32  Epoch: 102  Training loss = 2.3562  Validation loss = 3.2639  \n",
      "\n",
      "Fold: 32  Epoch: 103  Training loss = 2.3558  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 32  Epoch: 104  Training loss = 2.3552  Validation loss = 3.2585  \n",
      "\n",
      "Fold: 32  Epoch: 105  Training loss = 2.3547  Validation loss = 3.2537  \n",
      "\n",
      "Fold: 32  Epoch: 106  Training loss = 2.3545  Validation loss = 3.2562  \n",
      "\n",
      "Fold: 32  Epoch: 107  Training loss = 2.3539  Validation loss = 3.2518  \n",
      "\n",
      "Fold: 32  Epoch: 108  Training loss = 2.3536  Validation loss = 3.2503  \n",
      "\n",
      "Fold: 32  Epoch: 109  Training loss = 2.3530  Validation loss = 3.2443  \n",
      "\n",
      "Fold: 32  Epoch: 110  Training loss = 2.3526  Validation loss = 3.2429  \n",
      "\n",
      "Fold: 32  Epoch: 111  Training loss = 2.3522  Validation loss = 3.2396  \n",
      "\n",
      "Fold: 32  Epoch: 112  Training loss = 2.3518  Validation loss = 3.2355  \n",
      "\n",
      "Fold: 32  Epoch: 113  Training loss = 2.3516  Validation loss = 3.2391  \n",
      "\n",
      "Fold: 32  Epoch: 114  Training loss = 2.3513  Validation loss = 3.2379  \n",
      "\n",
      "Fold: 32  Epoch: 115  Training loss = 2.3509  Validation loss = 3.2364  \n",
      "\n",
      "Fold: 32  Epoch: 116  Training loss = 2.3504  Validation loss = 3.2336  \n",
      "\n",
      "Fold: 32  Epoch: 117  Training loss = 2.3500  Validation loss = 3.2309  \n",
      "\n",
      "Fold: 32  Epoch: 118  Training loss = 2.3493  Validation loss = 3.2255  \n",
      "\n",
      "Fold: 32  Epoch: 119  Training loss = 2.3490  Validation loss = 3.2230  \n",
      "\n",
      "Fold: 32  Epoch: 120  Training loss = 2.3488  Validation loss = 3.2253  \n",
      "\n",
      "Fold: 32  Epoch: 121  Training loss = 2.3485  Validation loss = 3.2267  \n",
      "\n",
      "Fold: 32  Epoch: 122  Training loss = 2.3481  Validation loss = 3.2230  \n",
      "\n",
      "Fold: 32  Epoch: 123  Training loss = 2.3478  Validation loss = 3.2228  \n",
      "\n",
      "Fold: 32  Epoch: 124  Training loss = 2.3473  Validation loss = 3.2198  \n",
      "\n",
      "Fold: 32  Epoch: 125  Training loss = 2.3468  Validation loss = 3.2144  \n",
      "\n",
      "Fold: 32  Epoch: 126  Training loss = 2.3464  Validation loss = 3.2099  \n",
      "\n",
      "Fold: 32  Epoch: 127  Training loss = 2.3459  Validation loss = 3.2063  \n",
      "\n",
      "Fold: 32  Epoch: 128  Training loss = 2.3457  Validation loss = 3.2066  \n",
      "\n",
      "Fold: 32  Epoch: 129  Training loss = 2.3453  Validation loss = 3.2043  \n",
      "\n",
      "Fold: 32  Epoch: 130  Training loss = 2.3449  Validation loss = 3.2016  \n",
      "\n",
      "Fold: 32  Epoch: 131  Training loss = 2.3444  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 32  Epoch: 132  Training loss = 2.3440  Validation loss = 3.1945  \n",
      "\n",
      "Fold: 32  Epoch: 133  Training loss = 2.3437  Validation loss = 3.1934  \n",
      "\n",
      "Fold: 32  Epoch: 134  Training loss = 2.3431  Validation loss = 3.1912  \n",
      "\n",
      "Fold: 32  Epoch: 135  Training loss = 2.3427  Validation loss = 3.1876  \n",
      "\n",
      "Fold: 32  Epoch: 136  Training loss = 2.3422  Validation loss = 3.1869  \n",
      "\n",
      "Fold: 32  Epoch: 137  Training loss = 2.3420  Validation loss = 3.1878  \n",
      "\n",
      "Fold: 32  Epoch: 138  Training loss = 2.3417  Validation loss = 3.1916  \n",
      "\n",
      "Fold: 32  Epoch: 139  Training loss = 2.3412  Validation loss = 3.1900  \n",
      "\n",
      "Fold: 32  Epoch: 140  Training loss = 2.3409  Validation loss = 3.1890  \n",
      "\n",
      "Fold: 32  Epoch: 141  Training loss = 2.3405  Validation loss = 3.1856  \n",
      "\n",
      "Fold: 32  Epoch: 142  Training loss = 2.3402  Validation loss = 3.1852  \n",
      "\n",
      "Fold: 32  Epoch: 143  Training loss = 2.3397  Validation loss = 3.1818  \n",
      "\n",
      "Fold: 32  Epoch: 144  Training loss = 2.3394  Validation loss = 3.1819  \n",
      "\n",
      "Fold: 32  Epoch: 145  Training loss = 2.3389  Validation loss = 3.1789  \n",
      "\n",
      "Fold: 32  Epoch: 146  Training loss = 2.3386  Validation loss = 3.1775  \n",
      "\n",
      "Fold: 32  Epoch: 147  Training loss = 2.3382  Validation loss = 3.1779  \n",
      "\n",
      "Fold: 32  Epoch: 148  Training loss = 2.3378  Validation loss = 3.1757  \n",
      "\n",
      "Fold: 32  Epoch: 149  Training loss = 2.3373  Validation loss = 3.1723  \n",
      "\n",
      "Fold: 32  Epoch: 150  Training loss = 2.3371  Validation loss = 3.1737  \n",
      "\n",
      "Fold: 32  Epoch: 151  Training loss = 2.3365  Validation loss = 3.1695  \n",
      "\n",
      "Fold: 32  Epoch: 152  Training loss = 2.3360  Validation loss = 3.1639  \n",
      "\n",
      "Fold: 32  Epoch: 153  Training loss = 2.3357  Validation loss = 3.1612  \n",
      "\n",
      "Fold: 32  Epoch: 154  Training loss = 2.3355  Validation loss = 3.1639  \n",
      "\n",
      "Fold: 32  Epoch: 155  Training loss = 2.3352  Validation loss = 3.1602  \n",
      "\n",
      "Fold: 32  Epoch: 156  Training loss = 2.3346  Validation loss = 3.1563  \n",
      "\n",
      "Fold: 32  Epoch: 157  Training loss = 2.3347  Validation loss = 3.1614  \n",
      "\n",
      "Fold: 32  Epoch: 158  Training loss = 2.3343  Validation loss = 3.1605  \n",
      "\n",
      "Fold: 32  Epoch: 159  Training loss = 2.3340  Validation loss = 3.1583  \n",
      "\n",
      "Fold: 32  Epoch: 160  Training loss = 2.3337  Validation loss = 3.1575  \n",
      "\n",
      "Fold: 32  Epoch: 161  Training loss = 2.3332  Validation loss = 3.1522  \n",
      "\n",
      "Fold: 32  Epoch: 162  Training loss = 2.3329  Validation loss = 3.1528  \n",
      "\n",
      "Fold: 32  Epoch: 163  Training loss = 2.3326  Validation loss = 3.1518  \n",
      "\n",
      "Fold: 32  Epoch: 164  Training loss = 2.3321  Validation loss = 3.1479  \n",
      "\n",
      "Fold: 32  Epoch: 165  Training loss = 2.3316  Validation loss = 3.1430  \n",
      "\n",
      "Fold: 32  Epoch: 166  Training loss = 2.3312  Validation loss = 3.1397  \n",
      "\n",
      "Fold: 32  Epoch: 167  Training loss = 2.3308  Validation loss = 3.1357  \n",
      "\n",
      "Fold: 32  Epoch: 168  Training loss = 2.3302  Validation loss = 3.1312  \n",
      "\n",
      "Fold: 32  Epoch: 169  Training loss = 2.3299  Validation loss = 3.1314  \n",
      "\n",
      "Fold: 32  Epoch: 170  Training loss = 2.3295  Validation loss = 3.1270  \n",
      "\n",
      "Fold: 32  Epoch: 171  Training loss = 2.3291  Validation loss = 3.1241  \n",
      "\n",
      "Fold: 32  Epoch: 172  Training loss = 2.3285  Validation loss = 3.1185  \n",
      "\n",
      "Fold: 32  Epoch: 173  Training loss = 2.3282  Validation loss = 3.1179  \n",
      "\n",
      "Fold: 32  Epoch: 174  Training loss = 2.3278  Validation loss = 3.1164  \n",
      "\n",
      "Fold: 32  Epoch: 175  Training loss = 2.3274  Validation loss = 3.1162  \n",
      "\n",
      "Fold: 32  Epoch: 176  Training loss = 2.3272  Validation loss = 3.1184  \n",
      "\n",
      "Fold: 32  Epoch: 177  Training loss = 2.3268  Validation loss = 3.1183  \n",
      "\n",
      "Fold: 32  Epoch: 178  Training loss = 2.3264  Validation loss = 3.1143  \n",
      "\n",
      "Fold: 32  Epoch: 179  Training loss = 2.3260  Validation loss = 3.1118  \n",
      "\n",
      "Fold: 32  Epoch: 180  Training loss = 2.3254  Validation loss = 3.1073  \n",
      "\n",
      "Fold: 32  Epoch: 181  Training loss = 2.3248  Validation loss = 3.1025  \n",
      "\n",
      "Fold: 32  Epoch: 182  Training loss = 2.3246  Validation loss = 3.1059  \n",
      "\n",
      "Fold: 32  Epoch: 183  Training loss = 2.3244  Validation loss = 3.1043  \n",
      "\n",
      "Fold: 32  Epoch: 184  Training loss = 2.3240  Validation loss = 3.1037  \n",
      "\n",
      "Fold: 32  Epoch: 185  Training loss = 2.3238  Validation loss = 3.1023  \n",
      "\n",
      "Fold: 32  Epoch: 186  Training loss = 2.3234  Validation loss = 3.0994  \n",
      "\n",
      "Fold: 32  Epoch: 187  Training loss = 2.3230  Validation loss = 3.0970  \n",
      "\n",
      "Fold: 32  Epoch: 188  Training loss = 2.3224  Validation loss = 3.0929  \n",
      "\n",
      "Fold: 32  Epoch: 189  Training loss = 2.3216  Validation loss = 3.0851  \n",
      "\n",
      "Fold: 32  Epoch: 190  Training loss = 2.3212  Validation loss = 3.0836  \n",
      "\n",
      "Fold: 32  Epoch: 191  Training loss = 2.3207  Validation loss = 3.0831  \n",
      "\n",
      "Fold: 32  Epoch: 192  Training loss = 2.3203  Validation loss = 3.0819  \n",
      "\n",
      "Fold: 32  Epoch: 193  Training loss = 2.3198  Validation loss = 3.0769  \n",
      "\n",
      "Fold: 32  Epoch: 194  Training loss = 2.3191  Validation loss = 3.0703  \n",
      "\n",
      "Fold: 32  Epoch: 195  Training loss = 2.3187  Validation loss = 3.0689  \n",
      "\n",
      "Fold: 32  Epoch: 196  Training loss = 2.3182  Validation loss = 3.0653  \n",
      "\n",
      "Fold: 32  Epoch: 197  Training loss = 2.3174  Validation loss = 3.0567  \n",
      "\n",
      "Fold: 32  Epoch: 198  Training loss = 2.3169  Validation loss = 3.0538  \n",
      "\n",
      "Fold: 32  Epoch: 199  Training loss = 2.3164  Validation loss = 3.0528  \n",
      "\n",
      "Fold: 32  Epoch: 200  Training loss = 2.3156  Validation loss = 3.0441  \n",
      "\n",
      "Fold: 32  Epoch: 201  Training loss = 2.3155  Validation loss = 3.0489  \n",
      "\n",
      "Fold: 32  Epoch: 202  Training loss = 2.3149  Validation loss = 3.0450  \n",
      "\n",
      "Fold: 32  Epoch: 203  Training loss = 2.3141  Validation loss = 3.0404  \n",
      "\n",
      "Fold: 32  Epoch: 204  Training loss = 2.3137  Validation loss = 3.0368  \n",
      "\n",
      "Fold: 32  Epoch: 205  Training loss = 2.3127  Validation loss = 3.0255  \n",
      "\n",
      "Fold: 32  Epoch: 206  Training loss = 2.3120  Validation loss = 3.0199  \n",
      "\n",
      "Fold: 32  Epoch: 207  Training loss = 2.3116  Validation loss = 3.0221  \n",
      "\n",
      "Fold: 32  Epoch: 208  Training loss = 2.3112  Validation loss = 3.0201  \n",
      "\n",
      "Fold: 32  Epoch: 209  Training loss = 2.3107  Validation loss = 3.0194  \n",
      "\n",
      "Fold: 32  Epoch: 210  Training loss = 2.3098  Validation loss = 3.0100  \n",
      "\n",
      "Fold: 32  Epoch: 211  Training loss = 2.3093  Validation loss = 3.0120  \n",
      "\n",
      "Fold: 32  Epoch: 212  Training loss = 2.3089  Validation loss = 3.0091  \n",
      "\n",
      "Fold: 32  Epoch: 213  Training loss = 2.3084  Validation loss = 3.0061  \n",
      "\n",
      "Fold: 32  Epoch: 214  Training loss = 2.3076  Validation loss = 2.9957  \n",
      "\n",
      "Fold: 32  Epoch: 215  Training loss = 2.3074  Validation loss = 2.9962  \n",
      "\n",
      "Fold: 32  Epoch: 216  Training loss = 2.3067  Validation loss = 2.9902  \n",
      "\n",
      "Fold: 32  Epoch: 217  Training loss = 2.3063  Validation loss = 2.9891  \n",
      "\n",
      "Fold: 32  Epoch: 218  Training loss = 2.3059  Validation loss = 2.9846  \n",
      "\n",
      "Fold: 32  Epoch: 219  Training loss = 2.3054  Validation loss = 2.9808  \n",
      "\n",
      "Fold: 32  Epoch: 220  Training loss = 2.3050  Validation loss = 2.9792  \n",
      "\n",
      "Fold: 32  Epoch: 221  Training loss = 2.3047  Validation loss = 2.9789  \n",
      "\n",
      "Fold: 32  Epoch: 222  Training loss = 2.3045  Validation loss = 2.9763  \n",
      "\n",
      "Fold: 32  Epoch: 223  Training loss = 2.3041  Validation loss = 2.9724  \n",
      "\n",
      "Fold: 32  Epoch: 224  Training loss = 2.3036  Validation loss = 2.9689  \n",
      "\n",
      "Fold: 32  Epoch: 225  Training loss = 2.3032  Validation loss = 2.9673  \n",
      "\n",
      "Fold: 32  Epoch: 226  Training loss = 2.3026  Validation loss = 2.9601  \n",
      "\n",
      "Fold: 32  Epoch: 227  Training loss = 2.3024  Validation loss = 2.9593  \n",
      "\n",
      "Fold: 32  Epoch: 228  Training loss = 2.3021  Validation loss = 2.9564  \n",
      "\n",
      "Fold: 32  Epoch: 229  Training loss = 2.3017  Validation loss = 2.9587  \n",
      "\n",
      "Fold: 32  Epoch: 230  Training loss = 2.3014  Validation loss = 2.9582  \n",
      "\n",
      "Fold: 32  Epoch: 231  Training loss = 2.3009  Validation loss = 2.9575  \n",
      "\n",
      "Fold: 32  Epoch: 232  Training loss = 2.3005  Validation loss = 2.9529  \n",
      "\n",
      "Fold: 32  Epoch: 233  Training loss = 2.3000  Validation loss = 2.9468  \n",
      "\n",
      "Fold: 32  Epoch: 234  Training loss = 2.2995  Validation loss = 2.9407  \n",
      "\n",
      "Fold: 32  Epoch: 235  Training loss = 2.2990  Validation loss = 2.9362  \n",
      "\n",
      "Fold: 32  Epoch: 236  Training loss = 2.2985  Validation loss = 2.9304  \n",
      "\n",
      "Fold: 32  Epoch: 237  Training loss = 2.2980  Validation loss = 2.9240  \n",
      "\n",
      "Fold: 32  Epoch: 238  Training loss = 2.2977  Validation loss = 2.9199  \n",
      "\n",
      "Fold: 32  Epoch: 239  Training loss = 2.2972  Validation loss = 2.9161  \n",
      "\n",
      "Fold: 32  Epoch: 240  Training loss = 2.2967  Validation loss = 2.9163  \n",
      "\n",
      "Fold: 32  Epoch: 241  Training loss = 2.2963  Validation loss = 2.9157  \n",
      "\n",
      "Fold: 32  Epoch: 242  Training loss = 2.2958  Validation loss = 2.9116  \n",
      "\n",
      "Fold: 32  Epoch: 243  Training loss = 2.2955  Validation loss = 2.9094  \n",
      "\n",
      "Fold: 32  Epoch: 244  Training loss = 2.2950  Validation loss = 2.9081  \n",
      "\n",
      "Fold: 32  Epoch: 245  Training loss = 2.2945  Validation loss = 2.9053  \n",
      "\n",
      "Fold: 32  Epoch: 246  Training loss = 2.2939  Validation loss = 2.8972  \n",
      "\n",
      "Fold: 32  Epoch: 247  Training loss = 2.2936  Validation loss = 2.8930  \n",
      "\n",
      "Fold: 32  Epoch: 248  Training loss = 2.2932  Validation loss = 2.8927  \n",
      "\n",
      "Fold: 32  Epoch: 249  Training loss = 2.2926  Validation loss = 2.8887  \n",
      "\n",
      "Fold: 32  Epoch: 250  Training loss = 2.2922  Validation loss = 2.8833  \n",
      "\n",
      "Fold: 32  Epoch: 251  Training loss = 2.2918  Validation loss = 2.8791  \n",
      "\n",
      "Fold: 32  Epoch: 252  Training loss = 2.2913  Validation loss = 2.8725  \n",
      "\n",
      "Fold: 32  Epoch: 253  Training loss = 2.2911  Validation loss = 2.8792  \n",
      "\n",
      "Fold: 32  Epoch: 254  Training loss = 2.2909  Validation loss = 2.8775  \n",
      "\n",
      "Fold: 32  Epoch: 255  Training loss = 2.2907  Validation loss = 2.8746  \n",
      "\n",
      "Fold: 32  Epoch: 256  Training loss = 2.2904  Validation loss = 2.8701  \n",
      "\n",
      "Fold: 32  Epoch: 257  Training loss = 2.2901  Validation loss = 2.8695  \n",
      "\n",
      "Fold: 32  Epoch: 258  Training loss = 2.2897  Validation loss = 2.8635  \n",
      "\n",
      "Fold: 32  Epoch: 259  Training loss = 2.2893  Validation loss = 2.8610  \n",
      "\n",
      "Fold: 32  Epoch: 260  Training loss = 2.2889  Validation loss = 2.8587  \n",
      "\n",
      "Fold: 32  Epoch: 261  Training loss = 2.2884  Validation loss = 2.8547  \n",
      "\n",
      "Fold: 32  Epoch: 262  Training loss = 2.2878  Validation loss = 2.8511  \n",
      "\n",
      "Fold: 32  Epoch: 263  Training loss = 2.2875  Validation loss = 2.8511  \n",
      "\n",
      "Fold: 32  Epoch: 264  Training loss = 2.2870  Validation loss = 2.8438  \n",
      "\n",
      "Fold: 32  Epoch: 265  Training loss = 2.2867  Validation loss = 2.8401  \n",
      "\n",
      "Fold: 32  Epoch: 266  Training loss = 2.2863  Validation loss = 2.8364  \n",
      "\n",
      "Fold: 32  Epoch: 267  Training loss = 2.2859  Validation loss = 2.8318  \n",
      "\n",
      "Fold: 32  Epoch: 268  Training loss = 2.2855  Validation loss = 2.8309  \n",
      "\n",
      "Fold: 32  Epoch: 269  Training loss = 2.2852  Validation loss = 2.8280  \n",
      "\n",
      "Fold: 32  Epoch: 270  Training loss = 2.2849  Validation loss = 2.8241  \n",
      "\n",
      "Fold: 32  Epoch: 271  Training loss = 2.2846  Validation loss = 2.8205  \n",
      "\n",
      "Fold: 32  Epoch: 272  Training loss = 2.2842  Validation loss = 2.8137  \n",
      "\n",
      "Fold: 32  Epoch: 273  Training loss = 2.2839  Validation loss = 2.8133  \n",
      "\n",
      "Fold: 32  Epoch: 274  Training loss = 2.2837  Validation loss = 2.8140  \n",
      "\n",
      "Fold: 32  Epoch: 275  Training loss = 2.2834  Validation loss = 2.8156  \n",
      "\n",
      "Fold: 32  Epoch: 276  Training loss = 2.2832  Validation loss = 2.8157  \n",
      "\n",
      "Fold: 32  Epoch: 277  Training loss = 2.2828  Validation loss = 2.8133  \n",
      "\n",
      "Fold: 32  Epoch: 278  Training loss = 2.2825  Validation loss = 2.8141  \n",
      "\n",
      "Fold: 32  Epoch: 279  Training loss = 2.2820  Validation loss = 2.8114  \n",
      "\n",
      "Fold: 32  Epoch: 280  Training loss = 2.2816  Validation loss = 2.8085  \n",
      "\n",
      "Fold: 32  Epoch: 281  Training loss = 2.2813  Validation loss = 2.8075  \n",
      "\n",
      "Fold: 32  Epoch: 282  Training loss = 2.2810  Validation loss = 2.8032  \n",
      "\n",
      "Fold: 32  Epoch: 283  Training loss = 2.2807  Validation loss = 2.8056  \n",
      "\n",
      "Fold: 32  Epoch: 284  Training loss = 2.2804  Validation loss = 2.8041  \n",
      "\n",
      "Fold: 32  Epoch: 285  Training loss = 2.2801  Validation loss = 2.7981  \n",
      "\n",
      "Fold: 32  Epoch: 286  Training loss = 2.2799  Validation loss = 2.7987  \n",
      "\n",
      "Fold: 32  Epoch: 287  Training loss = 2.2795  Validation loss = 2.7945  \n",
      "\n",
      "Fold: 32  Epoch: 288  Training loss = 2.2794  Validation loss = 2.7961  \n",
      "\n",
      "Fold: 32  Epoch: 289  Training loss = 2.2792  Validation loss = 2.8006  \n",
      "\n",
      "Fold: 32  Epoch: 290  Training loss = 2.2789  Validation loss = 2.7989  \n",
      "\n",
      "Fold: 32  Epoch: 291  Training loss = 2.2787  Validation loss = 2.7954  \n",
      "\n",
      "Fold: 32  Epoch: 292  Training loss = 2.2783  Validation loss = 2.7883  \n",
      "\n",
      "Fold: 32  Epoch: 293  Training loss = 2.2778  Validation loss = 2.7829  \n",
      "\n",
      "Fold: 32  Epoch: 294  Training loss = 2.2775  Validation loss = 2.7767  \n",
      "\n",
      "Fold: 32  Epoch: 295  Training loss = 2.2773  Validation loss = 2.7741  \n",
      "\n",
      "Fold: 32  Epoch: 296  Training loss = 2.2770  Validation loss = 2.7718  \n",
      "\n",
      "Fold: 32  Epoch: 297  Training loss = 2.2766  Validation loss = 2.7672  \n",
      "\n",
      "Fold: 32  Epoch: 298  Training loss = 2.2765  Validation loss = 2.7623  \n",
      "\n",
      "Fold: 32  Epoch: 299  Training loss = 2.2762  Validation loss = 2.7646  \n",
      "\n",
      "Fold: 32  Epoch: 300  Training loss = 2.2759  Validation loss = 2.7605  \n",
      "\n",
      "Fold: 32  Epoch: 301  Training loss = 2.2756  Validation loss = 2.7623  \n",
      "\n",
      "Fold: 32  Epoch: 302  Training loss = 2.2753  Validation loss = 2.7580  \n",
      "\n",
      "Fold: 32  Epoch: 303  Training loss = 2.2752  Validation loss = 2.7556  \n",
      "\n",
      "Fold: 32  Epoch: 304  Training loss = 2.2749  Validation loss = 2.7551  \n",
      "\n",
      "Fold: 32  Epoch: 305  Training loss = 2.2746  Validation loss = 2.7589  \n",
      "\n",
      "Fold: 32  Epoch: 306  Training loss = 2.2745  Validation loss = 2.7633  \n",
      "\n",
      "Fold: 32  Epoch: 307  Training loss = 2.2742  Validation loss = 2.7658  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 304  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 347\n",
      "Average validation error: 3.67862\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 2.0562  Test loss = 2.6718  \n",
      "\n",
      "Epoch: 2  Training loss = 2.0561  Test loss = 2.6716  \n",
      "\n",
      "Epoch: 3  Training loss = 2.0559  Test loss = 2.6715  \n",
      "\n",
      "Epoch: 4  Training loss = 2.0558  Test loss = 2.6713  \n",
      "\n",
      "Epoch: 5  Training loss = 2.0556  Test loss = 2.6711  \n",
      "\n",
      "Epoch: 6  Training loss = 2.0555  Test loss = 2.6709  \n",
      "\n",
      "Epoch: 7  Training loss = 2.0553  Test loss = 2.6707  \n",
      "\n",
      "Epoch: 8  Training loss = 2.0552  Test loss = 2.6706  \n",
      "\n",
      "Epoch: 9  Training loss = 2.0550  Test loss = 2.6704  \n",
      "\n",
      "Epoch: 10  Training loss = 2.0549  Test loss = 2.6702  \n",
      "\n",
      "Epoch: 11  Training loss = 2.0547  Test loss = 2.6700  \n",
      "\n",
      "Epoch: 12  Training loss = 2.0546  Test loss = 2.6699  \n",
      "\n",
      "Epoch: 13  Training loss = 2.0545  Test loss = 2.6697  \n",
      "\n",
      "Epoch: 14  Training loss = 2.0543  Test loss = 2.6695  \n",
      "\n",
      "Epoch: 15  Training loss = 2.0542  Test loss = 2.6693  \n",
      "\n",
      "Epoch: 16  Training loss = 2.0540  Test loss = 2.6692  \n",
      "\n",
      "Epoch: 17  Training loss = 2.0539  Test loss = 2.6690  \n",
      "\n",
      "Epoch: 18  Training loss = 2.0538  Test loss = 2.6688  \n",
      "\n",
      "Epoch: 19  Training loss = 2.0536  Test loss = 2.6686  \n",
      "\n",
      "Epoch: 20  Training loss = 2.0535  Test loss = 2.6685  \n",
      "\n",
      "Epoch: 21  Training loss = 2.0533  Test loss = 2.6683  \n",
      "\n",
      "Epoch: 22  Training loss = 2.0532  Test loss = 2.6681  \n",
      "\n",
      "Epoch: 23  Training loss = 2.0530  Test loss = 2.6679  \n",
      "\n",
      "Epoch: 24  Training loss = 2.0529  Test loss = 2.6678  \n",
      "\n",
      "Epoch: 25  Training loss = 2.0528  Test loss = 2.6676  \n",
      "\n",
      "Epoch: 26  Training loss = 2.0526  Test loss = 2.6674  \n",
      "\n",
      "Epoch: 27  Training loss = 2.0525  Test loss = 2.6673  \n",
      "\n",
      "Epoch: 28  Training loss = 2.0523  Test loss = 2.6671  \n",
      "\n",
      "Epoch: 29  Training loss = 2.0522  Test loss = 2.6669  \n",
      "\n",
      "Epoch: 30  Training loss = 2.0521  Test loss = 2.6667  \n",
      "\n",
      "Epoch: 31  Training loss = 2.0519  Test loss = 2.6666  \n",
      "\n",
      "Epoch: 32  Training loss = 2.0518  Test loss = 2.6664  \n",
      "\n",
      "Epoch: 33  Training loss = 2.0517  Test loss = 2.6662  \n",
      "\n",
      "Epoch: 34  Training loss = 2.0515  Test loss = 2.6661  \n",
      "\n",
      "Epoch: 35  Training loss = 2.0514  Test loss = 2.6659  \n",
      "\n",
      "Epoch: 36  Training loss = 2.0512  Test loss = 2.6657  \n",
      "\n",
      "Epoch: 37  Training loss = 2.0511  Test loss = 2.6656  \n",
      "\n",
      "Epoch: 38  Training loss = 2.0510  Test loss = 2.6654  \n",
      "\n",
      "Epoch: 39  Training loss = 2.0508  Test loss = 2.6652  \n",
      "\n",
      "Epoch: 40  Training loss = 2.0507  Test loss = 2.6651  \n",
      "\n",
      "Epoch: 41  Training loss = 2.0506  Test loss = 2.6649  \n",
      "\n",
      "Epoch: 42  Training loss = 2.0504  Test loss = 2.6647  \n",
      "\n",
      "Epoch: 43  Training loss = 2.0503  Test loss = 2.6646  \n",
      "\n",
      "Epoch: 44  Training loss = 2.0502  Test loss = 2.6644  \n",
      "\n",
      "Epoch: 45  Training loss = 2.0500  Test loss = 2.6642  \n",
      "\n",
      "Epoch: 46  Training loss = 2.0499  Test loss = 2.6641  \n",
      "\n",
      "Epoch: 47  Training loss = 2.0497  Test loss = 2.6639  \n",
      "\n",
      "Epoch: 48  Training loss = 2.0496  Test loss = 2.6637  \n",
      "\n",
      "Epoch: 49  Training loss = 2.0495  Test loss = 2.6636  \n",
      "\n",
      "Epoch: 50  Training loss = 2.0493  Test loss = 2.6634  \n",
      "\n",
      "Epoch: 51  Training loss = 2.0492  Test loss = 2.6633  \n",
      "\n",
      "Epoch: 52  Training loss = 2.0491  Test loss = 2.6631  \n",
      "\n",
      "Epoch: 53  Training loss = 2.0489  Test loss = 2.6629  \n",
      "\n",
      "Epoch: 54  Training loss = 2.0488  Test loss = 2.6628  \n",
      "\n",
      "Epoch: 55  Training loss = 2.0487  Test loss = 2.6626  \n",
      "\n",
      "Epoch: 56  Training loss = 2.0485  Test loss = 2.6624  \n",
      "\n",
      "Epoch: 57  Training loss = 2.0484  Test loss = 2.6623  \n",
      "\n",
      "Epoch: 58  Training loss = 2.0483  Test loss = 2.6621  \n",
      "\n",
      "Epoch: 59  Training loss = 2.0481  Test loss = 2.6620  \n",
      "\n",
      "Epoch: 60  Training loss = 2.0480  Test loss = 2.6618  \n",
      "\n",
      "Epoch: 61  Training loss = 2.0479  Test loss = 2.6616  \n",
      "\n",
      "Epoch: 62  Training loss = 2.0478  Test loss = 2.6615  \n",
      "\n",
      "Epoch: 63  Training loss = 2.0476  Test loss = 2.6613  \n",
      "\n",
      "Epoch: 64  Training loss = 2.0475  Test loss = 2.6612  \n",
      "\n",
      "Epoch: 65  Training loss = 2.0474  Test loss = 2.6610  \n",
      "\n",
      "Epoch: 66  Training loss = 2.0472  Test loss = 2.6608  \n",
      "\n",
      "Epoch: 67  Training loss = 2.0471  Test loss = 2.6607  \n",
      "\n",
      "Epoch: 68  Training loss = 2.0470  Test loss = 2.6605  \n",
      "\n",
      "Epoch: 69  Training loss = 2.0468  Test loss = 2.6604  \n",
      "\n",
      "Epoch: 70  Training loss = 2.0467  Test loss = 2.6602  \n",
      "\n",
      "Epoch: 71  Training loss = 2.0466  Test loss = 2.6600  \n",
      "\n",
      "Epoch: 72  Training loss = 2.0465  Test loss = 2.6599  \n",
      "\n",
      "Epoch: 73  Training loss = 2.0463  Test loss = 2.6597  \n",
      "\n",
      "Epoch: 74  Training loss = 2.0462  Test loss = 2.6596  \n",
      "\n",
      "Epoch: 75  Training loss = 2.0461  Test loss = 2.6594  \n",
      "\n",
      "Epoch: 76  Training loss = 2.0459  Test loss = 2.6593  \n",
      "\n",
      "Epoch: 77  Training loss = 2.0458  Test loss = 2.6591  \n",
      "\n",
      "Epoch: 78  Training loss = 2.0457  Test loss = 2.6589  \n",
      "\n",
      "Epoch: 79  Training loss = 2.0456  Test loss = 2.6588  \n",
      "\n",
      "Epoch: 80  Training loss = 2.0454  Test loss = 2.6586  \n",
      "\n",
      "Epoch: 81  Training loss = 2.0453  Test loss = 2.6585  \n",
      "\n",
      "Epoch: 82  Training loss = 2.0452  Test loss = 2.6583  \n",
      "\n",
      "Epoch: 83  Training loss = 2.0450  Test loss = 2.6582  \n",
      "\n",
      "Epoch: 84  Training loss = 2.0449  Test loss = 2.6580  \n",
      "\n",
      "Epoch: 85  Training loss = 2.0448  Test loss = 2.6579  \n",
      "\n",
      "Epoch: 86  Training loss = 2.0447  Test loss = 2.6577  \n",
      "\n",
      "Epoch: 87  Training loss = 2.0445  Test loss = 2.6576  \n",
      "\n",
      "Epoch: 88  Training loss = 2.0444  Test loss = 2.6574  \n",
      "\n",
      "Epoch: 89  Training loss = 2.0443  Test loss = 2.6573  \n",
      "\n",
      "Epoch: 90  Training loss = 2.0442  Test loss = 2.6571  \n",
      "\n",
      "Epoch: 91  Training loss = 2.0440  Test loss = 2.6569  \n",
      "\n",
      "Epoch: 92  Training loss = 2.0439  Test loss = 2.6568  \n",
      "\n",
      "Epoch: 93  Training loss = 2.0438  Test loss = 2.6566  \n",
      "\n",
      "Epoch: 94  Training loss = 2.0437  Test loss = 2.6565  \n",
      "\n",
      "Epoch: 95  Training loss = 2.0435  Test loss = 2.6563  \n",
      "\n",
      "Epoch: 96  Training loss = 2.0434  Test loss = 2.6562  \n",
      "\n",
      "Epoch: 97  Training loss = 2.0433  Test loss = 2.6560  \n",
      "\n",
      "Epoch: 98  Training loss = 2.0432  Test loss = 2.6559  \n",
      "\n",
      "Epoch: 99  Training loss = 2.0430  Test loss = 2.6557  \n",
      "\n",
      "Epoch: 100  Training loss = 2.0429  Test loss = 2.6556  \n",
      "\n",
      "Epoch: 101  Training loss = 2.0428  Test loss = 2.6554  \n",
      "\n",
      "Epoch: 102  Training loss = 2.0427  Test loss = 2.6553  \n",
      "\n",
      "Epoch: 103  Training loss = 2.0425  Test loss = 2.6551  \n",
      "\n",
      "Epoch: 104  Training loss = 2.0424  Test loss = 2.6550  \n",
      "\n",
      "Epoch: 105  Training loss = 2.0423  Test loss = 2.6548  \n",
      "\n",
      "Epoch: 106  Training loss = 2.0422  Test loss = 2.6547  \n",
      "\n",
      "Epoch: 107  Training loss = 2.0421  Test loss = 2.6545  \n",
      "\n",
      "Epoch: 108  Training loss = 2.0419  Test loss = 2.6544  \n",
      "\n",
      "Epoch: 109  Training loss = 2.0418  Test loss = 2.6542  \n",
      "\n",
      "Epoch: 110  Training loss = 2.0417  Test loss = 2.6541  \n",
      "\n",
      "Epoch: 111  Training loss = 2.0416  Test loss = 2.6540  \n",
      "\n",
      "Epoch: 112  Training loss = 2.0414  Test loss = 2.6538  \n",
      "\n",
      "Epoch: 113  Training loss = 2.0413  Test loss = 2.6537  \n",
      "\n",
      "Epoch: 114  Training loss = 2.0412  Test loss = 2.6535  \n",
      "\n",
      "Epoch: 115  Training loss = 2.0411  Test loss = 2.6534  \n",
      "\n",
      "Epoch: 116  Training loss = 2.0410  Test loss = 2.6532  \n",
      "\n",
      "Epoch: 117  Training loss = 2.0408  Test loss = 2.6531  \n",
      "\n",
      "Epoch: 118  Training loss = 2.0407  Test loss = 2.6529  \n",
      "\n",
      "Epoch: 119  Training loss = 2.0406  Test loss = 2.6528  \n",
      "\n",
      "Epoch: 120  Training loss = 2.0405  Test loss = 2.6526  \n",
      "\n",
      "Epoch: 121  Training loss = 2.0404  Test loss = 2.6525  \n",
      "\n",
      "Epoch: 122  Training loss = 2.0402  Test loss = 2.6523  \n",
      "\n",
      "Epoch: 123  Training loss = 2.0401  Test loss = 2.6522  \n",
      "\n",
      "Epoch: 124  Training loss = 2.0400  Test loss = 2.6521  \n",
      "\n",
      "Epoch: 125  Training loss = 2.0399  Test loss = 2.6519  \n",
      "\n",
      "Epoch: 126  Training loss = 2.0398  Test loss = 2.6518  \n",
      "\n",
      "Epoch: 127  Training loss = 2.0397  Test loss = 2.6516  \n",
      "\n",
      "Epoch: 128  Training loss = 2.0395  Test loss = 2.6515  \n",
      "\n",
      "Epoch: 129  Training loss = 2.0394  Test loss = 2.6513  \n",
      "\n",
      "Epoch: 130  Training loss = 2.0393  Test loss = 2.6512  \n",
      "\n",
      "Epoch: 131  Training loss = 2.0392  Test loss = 2.6511  \n",
      "\n",
      "Epoch: 132  Training loss = 2.0391  Test loss = 2.6509  \n",
      "\n",
      "Epoch: 133  Training loss = 2.0389  Test loss = 2.6508  \n",
      "\n",
      "Epoch: 134  Training loss = 2.0388  Test loss = 2.6506  \n",
      "\n",
      "Epoch: 135  Training loss = 2.0387  Test loss = 2.6505  \n",
      "\n",
      "Epoch: 136  Training loss = 2.0386  Test loss = 2.6503  \n",
      "\n",
      "Epoch: 137  Training loss = 2.0385  Test loss = 2.6502  \n",
      "\n",
      "Epoch: 138  Training loss = 2.0384  Test loss = 2.6501  \n",
      "\n",
      "Epoch: 139  Training loss = 2.0382  Test loss = 2.6499  \n",
      "\n",
      "Epoch: 140  Training loss = 2.0381  Test loss = 2.6498  \n",
      "\n",
      "Epoch: 141  Training loss = 2.0380  Test loss = 2.6496  \n",
      "\n",
      "Epoch: 142  Training loss = 2.0379  Test loss = 2.6495  \n",
      "\n",
      "Epoch: 143  Training loss = 2.0378  Test loss = 2.6494  \n",
      "\n",
      "Epoch: 144  Training loss = 2.0377  Test loss = 2.6492  \n",
      "\n",
      "Epoch: 145  Training loss = 2.0376  Test loss = 2.6491  \n",
      "\n",
      "Epoch: 146  Training loss = 2.0374  Test loss = 2.6489  \n",
      "\n",
      "Epoch: 147  Training loss = 2.0373  Test loss = 2.6488  \n",
      "\n",
      "Epoch: 148  Training loss = 2.0372  Test loss = 2.6487  \n",
      "\n",
      "Epoch: 149  Training loss = 2.0371  Test loss = 2.6485  \n",
      "\n",
      "Epoch: 150  Training loss = 2.0370  Test loss = 2.6484  \n",
      "\n",
      "Epoch: 151  Training loss = 2.0369  Test loss = 2.6482  \n",
      "\n",
      "Epoch: 152  Training loss = 2.0368  Test loss = 2.6481  \n",
      "\n",
      "Epoch: 153  Training loss = 2.0366  Test loss = 2.6480  \n",
      "\n",
      "Epoch: 154  Training loss = 2.0365  Test loss = 2.6478  \n",
      "\n",
      "Epoch: 155  Training loss = 2.0364  Test loss = 2.6477  \n",
      "\n",
      "Epoch: 156  Training loss = 2.0363  Test loss = 2.6475  \n",
      "\n",
      "Epoch: 157  Training loss = 2.0362  Test loss = 2.6474  \n",
      "\n",
      "Epoch: 158  Training loss = 2.0361  Test loss = 2.6473  \n",
      "\n",
      "Epoch: 159  Training loss = 2.0360  Test loss = 2.6471  \n",
      "\n",
      "Epoch: 160  Training loss = 2.0358  Test loss = 2.6470  \n",
      "\n",
      "Epoch: 161  Training loss = 2.0357  Test loss = 2.6469  \n",
      "\n",
      "Epoch: 162  Training loss = 2.0356  Test loss = 2.6467  \n",
      "\n",
      "Epoch: 163  Training loss = 2.0355  Test loss = 2.6466  \n",
      "\n",
      "Epoch: 164  Training loss = 2.0354  Test loss = 2.6465  \n",
      "\n",
      "Epoch: 165  Training loss = 2.0353  Test loss = 2.6463  \n",
      "\n",
      "Epoch: 166  Training loss = 2.0352  Test loss = 2.6462  \n",
      "\n",
      "Epoch: 167  Training loss = 2.0351  Test loss = 2.6460  \n",
      "\n",
      "Epoch: 168  Training loss = 2.0349  Test loss = 2.6459  \n",
      "\n",
      "Epoch: 169  Training loss = 2.0348  Test loss = 2.6458  \n",
      "\n",
      "Epoch: 170  Training loss = 2.0347  Test loss = 2.6456  \n",
      "\n",
      "Epoch: 171  Training loss = 2.0346  Test loss = 2.6455  \n",
      "\n",
      "Epoch: 172  Training loss = 2.0345  Test loss = 2.6454  \n",
      "\n",
      "Epoch: 173  Training loss = 2.0344  Test loss = 2.6452  \n",
      "\n",
      "Epoch: 174  Training loss = 2.0343  Test loss = 2.6451  \n",
      "\n",
      "Epoch: 175  Training loss = 2.0342  Test loss = 2.6450  \n",
      "\n",
      "Epoch: 176  Training loss = 2.0341  Test loss = 2.6448  \n",
      "\n",
      "Epoch: 177  Training loss = 2.0340  Test loss = 2.6447  \n",
      "\n",
      "Epoch: 178  Training loss = 2.0338  Test loss = 2.6446  \n",
      "\n",
      "Epoch: 179  Training loss = 2.0337  Test loss = 2.6444  \n",
      "\n",
      "Epoch: 180  Training loss = 2.0336  Test loss = 2.6443  \n",
      "\n",
      "Epoch: 181  Training loss = 2.0335  Test loss = 2.6442  \n",
      "\n",
      "Epoch: 182  Training loss = 2.0334  Test loss = 2.6440  \n",
      "\n",
      "Epoch: 183  Training loss = 2.0333  Test loss = 2.6439  \n",
      "\n",
      "Epoch: 184  Training loss = 2.0332  Test loss = 2.6438  \n",
      "\n",
      "Epoch: 185  Training loss = 2.0331  Test loss = 2.6436  \n",
      "\n",
      "Epoch: 186  Training loss = 2.0330  Test loss = 2.6435  \n",
      "\n",
      "Epoch: 187  Training loss = 2.0329  Test loss = 2.6434  \n",
      "\n",
      "Epoch: 188  Training loss = 2.0328  Test loss = 2.6432  \n",
      "\n",
      "Epoch: 189  Training loss = 2.0326  Test loss = 2.6431  \n",
      "\n",
      "Epoch: 190  Training loss = 2.0325  Test loss = 2.6430  \n",
      "\n",
      "Epoch: 191  Training loss = 2.0324  Test loss = 2.6429  \n",
      "\n",
      "Epoch: 192  Training loss = 2.0323  Test loss = 2.6427  \n",
      "\n",
      "Epoch: 193  Training loss = 2.0322  Test loss = 2.6426  \n",
      "\n",
      "Epoch: 194  Training loss = 2.0321  Test loss = 2.6425  \n",
      "\n",
      "Epoch: 195  Training loss = 2.0320  Test loss = 2.6423  \n",
      "\n",
      "Epoch: 196  Training loss = 2.0319  Test loss = 2.6422  \n",
      "\n",
      "Epoch: 197  Training loss = 2.0318  Test loss = 2.6421  \n",
      "\n",
      "Epoch: 198  Training loss = 2.0317  Test loss = 2.6419  \n",
      "\n",
      "Epoch: 199  Training loss = 2.0316  Test loss = 2.6418  \n",
      "\n",
      "Epoch: 200  Training loss = 2.0315  Test loss = 2.6417  \n",
      "\n",
      "Epoch: 201  Training loss = 2.0314  Test loss = 2.6416  \n",
      "\n",
      "Epoch: 202  Training loss = 2.0313  Test loss = 2.6414  \n",
      "\n",
      "Epoch: 203  Training loss = 2.0311  Test loss = 2.6413  \n",
      "\n",
      "Epoch: 204  Training loss = 2.0310  Test loss = 2.6412  \n",
      "\n",
      "Epoch: 205  Training loss = 2.0309  Test loss = 2.6410  \n",
      "\n",
      "Epoch: 206  Training loss = 2.0308  Test loss = 2.6409  \n",
      "\n",
      "Epoch: 207  Training loss = 2.0307  Test loss = 2.6408  \n",
      "\n",
      "Epoch: 208  Training loss = 2.0306  Test loss = 2.6407  \n",
      "\n",
      "Epoch: 209  Training loss = 2.0305  Test loss = 2.6405  \n",
      "\n",
      "Epoch: 210  Training loss = 2.0304  Test loss = 2.6404  \n",
      "\n",
      "Epoch: 211  Training loss = 2.0303  Test loss = 2.6403  \n",
      "\n",
      "Epoch: 212  Training loss = 2.0302  Test loss = 2.6401  \n",
      "\n",
      "Epoch: 213  Training loss = 2.0301  Test loss = 2.6400  \n",
      "\n",
      "Epoch: 214  Training loss = 2.0300  Test loss = 2.6399  \n",
      "\n",
      "Epoch: 215  Training loss = 2.0299  Test loss = 2.6398  \n",
      "\n",
      "Epoch: 216  Training loss = 2.0298  Test loss = 2.6396  \n",
      "\n",
      "Epoch: 217  Training loss = 2.0297  Test loss = 2.6395  \n",
      "\n",
      "Epoch: 218  Training loss = 2.0296  Test loss = 2.6394  \n",
      "\n",
      "Epoch: 219  Training loss = 2.0295  Test loss = 2.6393  \n",
      "\n",
      "Epoch: 220  Training loss = 2.0294  Test loss = 2.6391  \n",
      "\n",
      "Epoch: 221  Training loss = 2.0293  Test loss = 2.6390  \n",
      "\n",
      "Epoch: 222  Training loss = 2.0292  Test loss = 2.6389  \n",
      "\n",
      "Epoch: 223  Training loss = 2.0291  Test loss = 2.6388  \n",
      "\n",
      "Epoch: 224  Training loss = 2.0290  Test loss = 2.6386  \n",
      "\n",
      "Epoch: 225  Training loss = 2.0289  Test loss = 2.6385  \n",
      "\n",
      "Epoch: 226  Training loss = 2.0287  Test loss = 2.6384  \n",
      "\n",
      "Epoch: 227  Training loss = 2.0286  Test loss = 2.6383  \n",
      "\n",
      "Epoch: 228  Training loss = 2.0285  Test loss = 2.6381  \n",
      "\n",
      "Epoch: 229  Training loss = 2.0284  Test loss = 2.6380  \n",
      "\n",
      "Epoch: 230  Training loss = 2.0283  Test loss = 2.6379  \n",
      "\n",
      "Epoch: 231  Training loss = 2.0282  Test loss = 2.6378  \n",
      "\n",
      "Epoch: 232  Training loss = 2.0281  Test loss = 2.6376  \n",
      "\n",
      "Epoch: 233  Training loss = 2.0280  Test loss = 2.6375  \n",
      "\n",
      "Epoch: 234  Training loss = 2.0279  Test loss = 2.6374  \n",
      "\n",
      "Epoch: 235  Training loss = 2.0278  Test loss = 2.6373  \n",
      "\n",
      "Epoch: 236  Training loss = 2.0277  Test loss = 2.6371  \n",
      "\n",
      "Epoch: 237  Training loss = 2.0276  Test loss = 2.6370  \n",
      "\n",
      "Epoch: 238  Training loss = 2.0275  Test loss = 2.6369  \n",
      "\n",
      "Epoch: 239  Training loss = 2.0274  Test loss = 2.6368  \n",
      "\n",
      "Epoch: 240  Training loss = 2.0273  Test loss = 2.6367  \n",
      "\n",
      "Epoch: 241  Training loss = 2.0272  Test loss = 2.6365  \n",
      "\n",
      "Epoch: 242  Training loss = 2.0271  Test loss = 2.6364  \n",
      "\n",
      "Epoch: 243  Training loss = 2.0270  Test loss = 2.6363  \n",
      "\n",
      "Epoch: 244  Training loss = 2.0269  Test loss = 2.6362  \n",
      "\n",
      "Epoch: 245  Training loss = 2.0268  Test loss = 2.6360  \n",
      "\n",
      "Epoch: 246  Training loss = 2.0267  Test loss = 2.6359  \n",
      "\n",
      "Epoch: 247  Training loss = 2.0266  Test loss = 2.6358  \n",
      "\n",
      "Epoch: 248  Training loss = 2.0265  Test loss = 2.6357  \n",
      "\n",
      "Epoch: 249  Training loss = 2.0264  Test loss = 2.6356  \n",
      "\n",
      "Epoch: 250  Training loss = 2.0263  Test loss = 2.6354  \n",
      "\n",
      "Epoch: 251  Training loss = 2.0262  Test loss = 2.6353  \n",
      "\n",
      "Epoch: 252  Training loss = 2.0261  Test loss = 2.6352  \n",
      "\n",
      "Epoch: 253  Training loss = 2.0260  Test loss = 2.6351  \n",
      "\n",
      "Epoch: 254  Training loss = 2.0259  Test loss = 2.6350  \n",
      "\n",
      "Epoch: 255  Training loss = 2.0258  Test loss = 2.6348  \n",
      "\n",
      "Epoch: 256  Training loss = 2.0257  Test loss = 2.6347  \n",
      "\n",
      "Epoch: 257  Training loss = 2.0256  Test loss = 2.6346  \n",
      "\n",
      "Epoch: 258  Training loss = 2.0255  Test loss = 2.6345  \n",
      "\n",
      "Epoch: 259  Training loss = 2.0254  Test loss = 2.6344  \n",
      "\n",
      "Epoch: 260  Training loss = 2.0253  Test loss = 2.6342  \n",
      "\n",
      "Epoch: 261  Training loss = 2.0252  Test loss = 2.6341  \n",
      "\n",
      "Epoch: 262  Training loss = 2.0251  Test loss = 2.6340  \n",
      "\n",
      "Epoch: 263  Training loss = 2.0250  Test loss = 2.6339  \n",
      "\n",
      "Epoch: 264  Training loss = 2.0249  Test loss = 2.6338  \n",
      "\n",
      "Epoch: 265  Training loss = 2.0248  Test loss = 2.6336  \n",
      "\n",
      "Epoch: 266  Training loss = 2.0247  Test loss = 2.6335  \n",
      "\n",
      "Epoch: 267  Training loss = 2.0246  Test loss = 2.6334  \n",
      "\n",
      "Epoch: 268  Training loss = 2.0245  Test loss = 2.6333  \n",
      "\n",
      "Epoch: 269  Training loss = 2.0245  Test loss = 2.6332  \n",
      "\n",
      "Epoch: 270  Training loss = 2.0244  Test loss = 2.6330  \n",
      "\n",
      "Epoch: 271  Training loss = 2.0243  Test loss = 2.6329  \n",
      "\n",
      "Epoch: 272  Training loss = 2.0242  Test loss = 2.6328  \n",
      "\n",
      "Epoch: 273  Training loss = 2.0241  Test loss = 2.6327  \n",
      "\n",
      "Epoch: 274  Training loss = 2.0240  Test loss = 2.6326  \n",
      "\n",
      "Epoch: 275  Training loss = 2.0239  Test loss = 2.6325  \n",
      "\n",
      "Epoch: 276  Training loss = 2.0238  Test loss = 2.6323  \n",
      "\n",
      "Epoch: 277  Training loss = 2.0237  Test loss = 2.6322  \n",
      "\n",
      "Epoch: 278  Training loss = 2.0236  Test loss = 2.6321  \n",
      "\n",
      "Epoch: 279  Training loss = 2.0235  Test loss = 2.6320  \n",
      "\n",
      "Epoch: 280  Training loss = 2.0234  Test loss = 2.6319  \n",
      "\n",
      "Epoch: 281  Training loss = 2.0233  Test loss = 2.6318  \n",
      "\n",
      "Epoch: 282  Training loss = 2.0232  Test loss = 2.6316  \n",
      "\n",
      "Epoch: 283  Training loss = 2.0231  Test loss = 2.6315  \n",
      "\n",
      "Epoch: 284  Training loss = 2.0230  Test loss = 2.6314  \n",
      "\n",
      "Epoch: 285  Training loss = 2.0229  Test loss = 2.6313  \n",
      "\n",
      "Epoch: 286  Training loss = 2.0228  Test loss = 2.6312  \n",
      "\n",
      "Epoch: 287  Training loss = 2.0227  Test loss = 2.6311  \n",
      "\n",
      "Epoch: 288  Training loss = 2.0226  Test loss = 2.6309  \n",
      "\n",
      "Epoch: 289  Training loss = 2.0225  Test loss = 2.6308  \n",
      "\n",
      "Epoch: 290  Training loss = 2.0224  Test loss = 2.6307  \n",
      "\n",
      "Epoch: 291  Training loss = 2.0223  Test loss = 2.6306  \n",
      "\n",
      "Epoch: 292  Training loss = 2.0222  Test loss = 2.6305  \n",
      "\n",
      "Epoch: 293  Training loss = 2.0222  Test loss = 2.6304  \n",
      "\n",
      "Epoch: 294  Training loss = 2.0221  Test loss = 2.6303  \n",
      "\n",
      "Epoch: 295  Training loss = 2.0220  Test loss = 2.6301  \n",
      "\n",
      "Epoch: 296  Training loss = 2.0219  Test loss = 2.6300  \n",
      "\n",
      "Epoch: 297  Training loss = 2.0218  Test loss = 2.6299  \n",
      "\n",
      "Epoch: 298  Training loss = 2.0217  Test loss = 2.6298  \n",
      "\n",
      "Epoch: 299  Training loss = 2.0216  Test loss = 2.6297  \n",
      "\n",
      "Epoch: 300  Training loss = 2.0215  Test loss = 2.6296  \n",
      "\n",
      "Epoch: 301  Training loss = 2.0214  Test loss = 2.6295  \n",
      "\n",
      "Epoch: 302  Training loss = 2.0213  Test loss = 2.6293  \n",
      "\n",
      "Epoch: 303  Training loss = 2.0212  Test loss = 2.6292  \n",
      "\n",
      "Epoch: 304  Training loss = 2.0211  Test loss = 2.6291  \n",
      "\n",
      "Epoch: 305  Training loss = 2.0210  Test loss = 2.6290  \n",
      "\n",
      "Epoch: 306  Training loss = 2.0209  Test loss = 2.6289  \n",
      "\n",
      "Epoch: 307  Training loss = 2.0208  Test loss = 2.6288  \n",
      "\n",
      "Epoch: 308  Training loss = 2.0208  Test loss = 2.6287  \n",
      "\n",
      "Epoch: 309  Training loss = 2.0207  Test loss = 2.6285  \n",
      "\n",
      "Epoch: 310  Training loss = 2.0206  Test loss = 2.6284  \n",
      "\n",
      "Epoch: 311  Training loss = 2.0205  Test loss = 2.6283  \n",
      "\n",
      "Epoch: 312  Training loss = 2.0204  Test loss = 2.6282  \n",
      "\n",
      "Epoch: 313  Training loss = 2.0203  Test loss = 2.6281  \n",
      "\n",
      "Epoch: 314  Training loss = 2.0202  Test loss = 2.6280  \n",
      "\n",
      "Epoch: 315  Training loss = 2.0201  Test loss = 2.6279  \n",
      "\n",
      "Epoch: 316  Training loss = 2.0200  Test loss = 2.6278  \n",
      "\n",
      "Epoch: 317  Training loss = 2.0199  Test loss = 2.6277  \n",
      "\n",
      "Epoch: 318  Training loss = 2.0198  Test loss = 2.6275  \n",
      "\n",
      "Epoch: 319  Training loss = 2.0197  Test loss = 2.6274  \n",
      "\n",
      "Epoch: 320  Training loss = 2.0197  Test loss = 2.6273  \n",
      "\n",
      "Epoch: 321  Training loss = 2.0196  Test loss = 2.6272  \n",
      "\n",
      "Epoch: 322  Training loss = 2.0195  Test loss = 2.6271  \n",
      "\n",
      "Epoch: 323  Training loss = 2.0194  Test loss = 2.6270  \n",
      "\n",
      "Epoch: 324  Training loss = 2.0193  Test loss = 2.6269  \n",
      "\n",
      "Epoch: 325  Training loss = 2.0192  Test loss = 2.6268  \n",
      "\n",
      "Epoch: 326  Training loss = 2.0191  Test loss = 2.6267  \n",
      "\n",
      "Epoch: 327  Training loss = 2.0190  Test loss = 2.6265  \n",
      "\n",
      "Epoch: 328  Training loss = 2.0189  Test loss = 2.6264  \n",
      "\n",
      "Epoch: 329  Training loss = 2.0188  Test loss = 2.6263  \n",
      "\n",
      "Epoch: 330  Training loss = 2.0187  Test loss = 2.6262  \n",
      "\n",
      "Epoch: 331  Training loss = 2.0187  Test loss = 2.6261  \n",
      "\n",
      "Epoch: 332  Training loss = 2.0186  Test loss = 2.6260  \n",
      "\n",
      "Epoch: 333  Training loss = 2.0185  Test loss = 2.6259  \n",
      "\n",
      "Epoch: 334  Training loss = 2.0184  Test loss = 2.6258  \n",
      "\n",
      "Epoch: 335  Training loss = 2.0183  Test loss = 2.6257  \n",
      "\n",
      "Epoch: 336  Training loss = 2.0182  Test loss = 2.6256  \n",
      "\n",
      "Epoch: 337  Training loss = 2.0181  Test loss = 2.6254  \n",
      "\n",
      "Epoch: 338  Training loss = 2.0180  Test loss = 2.6253  \n",
      "\n",
      "Epoch: 339  Training loss = 2.0179  Test loss = 2.6252  \n",
      "\n",
      "Epoch: 340  Training loss = 2.0178  Test loss = 2.6251  \n",
      "\n",
      "Epoch: 341  Training loss = 2.0178  Test loss = 2.6250  \n",
      "\n",
      "Epoch: 342  Training loss = 2.0177  Test loss = 2.6249  \n",
      "\n",
      "Epoch: 343  Training loss = 2.0176  Test loss = 2.6248  \n",
      "\n",
      "Epoch: 344  Training loss = 2.0175  Test loss = 2.6247  \n",
      "\n",
      "Epoch: 345  Training loss = 2.0174  Test loss = 2.6246  \n",
      "\n",
      "Epoch: 346  Training loss = 2.0173  Test loss = 2.6245  \n",
      "\n",
      "Epoch: 347  Training loss = 2.0172  Test loss = 2.6244  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzH8BFzCsJ9NKTQsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc5e9898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ni/Ef0SWxL/ny/fAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcac9668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.62435467978 \n",
      "Fixed scheme MAE:  1.77575261916\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 2.0172  Test loss = 0.8166  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 2.0153  Test loss = 0.4015  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.9638  Test loss = 0.3704  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.9566  Test loss = 0.2401  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.7852  Test loss = 0.5399  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.7484  Test loss = 1.6673  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.7324  Test loss = 0.5907  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.7338  Test loss = 0.4470  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.6585  Test loss = 0.2291  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.6573  Test loss = 0.2722  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.6193  Test loss = 0.0535  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.6065  Test loss = 1.0056  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.5562  Test loss = 0.0300  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.5559  Test loss = 1.3066  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.5579  Test loss = 2.3116  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.5840  Test loss = 2.3748  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.5763  Test loss = 0.0580  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.5743  Test loss = 1.2069  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.5457  Test loss = 0.2807  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.3204  Test loss = 0.1513  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.2919  Test loss = 0.3728  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.2926  Test loss = 4.2717  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.3714  Test loss = 0.6449  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.3573  Test loss = 2.3447  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.3723  Test loss = 0.7862  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.3756  Test loss = 0.3134  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.3757  Test loss = 1.5585  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.3835  Test loss = 0.5515  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.3577  Test loss = 1.4301  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.3474  Test loss = 0.9103  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.3329  Test loss = 2.7449  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.3330  Test loss = 0.0245  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.3217  Test loss = 1.7533  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.3392  Test loss = 0.1922  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.2494  Test loss = 0.7683  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.2514  Test loss = 5.2728  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.3259  Test loss = 0.5843  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2659  Test loss = 1.8185  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.2853  Test loss = 0.6210  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2864  Test loss = 2.2819  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.2954  Test loss = 0.8419  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.2937  Test loss = 2.0146  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.3176  Test loss = 3.2503  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.3777  Test loss = 11.8783  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0129  Test loss = 5.8273  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1387  Test loss = 0.0448  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1387  Test loss = 0.7458  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1407  Test loss = 0.5874  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.0710  Test loss = 1.6332  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.0765  Test loss = 2.9156  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.1076  Test loss = 1.5369  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.1152  Test loss = 0.5204  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.0937  Test loss = 1.0730  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.0976  Test loss = 1.3207  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.1036  Test loss = 0.9072  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.1027  Test loss = 0.4507  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.0886  Test loss = 0.0517  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.0862  Test loss = 1.2557  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.0911  Test loss = 0.9247  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.0917  Test loss = 0.0535  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.0823  Test loss = 0.1916  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.0825  Test loss = 3.1694  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.1186  Test loss = 1.0378  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.1144  Test loss = 1.6680  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.1142  Test loss = 0.1828  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.1124  Test loss = 0.9446  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.1100  Test loss = 0.8505  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.1100  Test loss = 3.5090  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.1447  Test loss = 5.3846  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.2455  Test loss = 0.9824  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.2488  Test loss = 0.6953  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.2448  Test loss = 2.2137  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.2450  Test loss = 2.1651  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.2598  Test loss = 1.5127  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.2638  Test loss = 0.6657  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.2604  Test loss = 0.6955  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.2380  Test loss = 1.1201  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc9fcf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.22964646926 \n",
      "Updating scheme MAE:  1.40807985736\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
