{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/64_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-2\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 64 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 64 \n",
      "Learning rate = 0.01 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.01\n",
      "Fold: 1  Epoch: 1  Training loss = 2.7181  Validation loss = 2.0810  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.6457  Validation loss = 1.7567  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.6068  Validation loss = 1.1967  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.6059  Validation loss = 0.8064  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.5113  Validation loss = 1.3402  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.4042  Validation loss = 1.3450  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.3112  Validation loss = 1.0360  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.2903  Validation loss = 0.8462  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.2349  Validation loss = 1.3936  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.1395  Validation loss = 1.3538  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.0741  Validation loss = 1.2610  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.0835  Validation loss = 1.5988  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 4  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 1.8681  Validation loss = 1.8845  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 1.8892  Validation loss = 1.9715  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 1.8491  Validation loss = 1.9646  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 1.8533  Validation loss = 1.9717  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 1.7940  Validation loss = 1.9526  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 1.7304  Validation loss = 1.7748  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 1.7140  Validation loss = 1.9731  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 1.8302  Validation loss = 2.3523  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 1.6067  Validation loss = 1.8629  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 1.5860  Validation loss = 2.1257  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 1.5805  Validation loss = 1.8315  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 1.5886  Validation loss = 1.9095  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 1.5730  Validation loss = 2.0788  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 1.5674  Validation loss = 2.2427  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 1.6190  Validation loss = 2.5197  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 6  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.1723  Validation loss = 0.7371  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.1607  Validation loss = 0.7813  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.1785  Validation loss = 1.4971  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.1519  Validation loss = 1.2164  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.1153  Validation loss = 1.0351  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.1235  Validation loss = 1.6436  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.0973  Validation loss = 1.2096  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.1258  Validation loss = 1.7662  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.1117  Validation loss = 1.2784  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.1088  Validation loss = 1.4121  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.1569  Validation loss = 1.1044  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.0890  Validation loss = 0.9499  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.0723  Validation loss = 0.9897  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.0386  Validation loss = 1.4671  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.1098  Validation loss = 1.2351  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.0956  Validation loss = 1.4349  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.0441  Validation loss = 0.9061  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.0669  Validation loss = 1.5976  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 1  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.2261  Validation loss = 2.3944  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.0861  Validation loss = 1.3601  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.0280  Validation loss = 1.6752  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 0.9821  Validation loss = 1.5820  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 0.9770  Validation loss = 1.4466  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.0071  Validation loss = 1.7769  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 0.9900  Validation loss = 1.6789  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.0022  Validation loss = 1.8226  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 0.9612  Validation loss = 1.4449  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 0.9730  Validation loss = 1.2835  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.1118  Validation loss = 1.2541  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 0.9591  Validation loss = 1.4770  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 0.9551  Validation loss = 1.7402  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 0.9984  Validation loss = 1.6998  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 0.9436  Validation loss = 1.5794  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.2669  Validation loss = 1.4189  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 0.9365  Validation loss = 1.5317  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 0.9387  Validation loss = 1.5539  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 0.9543  Validation loss = 1.8161  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 11  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 0.9089  Validation loss = 1.9235  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.0290  Validation loss = 2.0295  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 0.8863  Validation loss = 1.8437  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 0.8936  Validation loss = 1.5419  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 0.8977  Validation loss = 1.7844  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 0.9663  Validation loss = 1.8494  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 0.8831  Validation loss = 1.8939  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 0.8758  Validation loss = 1.7974  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 0.8742  Validation loss = 1.7105  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 0.8706  Validation loss = 1.7535  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.9120  Validation loss = 1.9481  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 0.8502  Validation loss = 1.8439  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 0.8850  Validation loss = 1.6565  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.0041  Validation loss = 1.7039  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.8418  Validation loss = 1.5086  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 0.8230  Validation loss = 1.8667  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 0.9639  Validation loss = 1.7587  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 0.8462  Validation loss = 1.6346  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 0.8186  Validation loss = 1.7200  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 0.8064  Validation loss = 1.6697  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 0.8592  Validation loss = 1.3711  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 0.8518  Validation loss = 1.5705  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 0.8253  Validation loss = 1.7751  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 0.8249  Validation loss = 1.6732  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 0.8279  Validation loss = 1.5027  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 0.8133  Validation loss = 1.5468  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 0.7848  Validation loss = 1.7468  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 0.8227  Validation loss = 2.0393  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 21  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 0.8431  Validation loss = 0.8249  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 0.8240  Validation loss = 1.0200  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.8678  Validation loss = 1.0103  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.8339  Validation loss = 0.9009  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.8103  Validation loss = 0.8270  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.8691  Validation loss = 0.9729  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.0216  Validation loss = 0.9274  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.9916  Validation loss = 1.0714  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.8359  Validation loss = 0.8996  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.8304  Validation loss = 0.8190  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.7991  Validation loss = 0.9712  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.8147  Validation loss = 0.9703  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.7965  Validation loss = 1.0135  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.8342  Validation loss = 1.0262  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 0.7911  Validation loss = 0.9469  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 0.8408  Validation loss = 1.1394  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 10  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.8279  Validation loss = 1.7082  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.7791  Validation loss = 1.5873  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.7876  Validation loss = 1.3902  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.8300  Validation loss = 1.1935  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.8219  Validation loss = 1.8938  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.8106  Validation loss = 1.7072  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.8638  Validation loss = 2.2328  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.7596  Validation loss = 1.5894  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.7830  Validation loss = 2.0011  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.7754  Validation loss = 1.4416  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.7675  Validation loss = 1.6067  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.8231  Validation loss = 2.0833  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.8242  Validation loss = 2.1773  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.7900  Validation loss = 1.5000  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 0.7433  Validation loss = 1.6085  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 0.7913  Validation loss = 1.3831  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 0.7639  Validation loss = 1.5552  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 0.7504  Validation loss = 1.3678  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 0.7554  Validation loss = 1.8407  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 0.7435  Validation loss = 1.8651  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 0.7453  Validation loss = 1.7280  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 0.7490  Validation loss = 1.7803  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 0.7993  Validation loss = 1.6143  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 0.8943  Validation loss = 2.4959  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 4  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.7398  Validation loss = 3.8890  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.7137  Validation loss = 4.1096  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.7162  Validation loss = 4.0059  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.7346  Validation loss = 4.0880  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.7161  Validation loss = 3.8385  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.7328  Validation loss = 3.6705  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.6943  Validation loss = 3.7949  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.7322  Validation loss = 4.2066  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.6804  Validation loss = 3.9388  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.7212  Validation loss = 3.8331  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.7124  Validation loss = 4.0873  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.6858  Validation loss = 3.5993  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 0.7199  Validation loss = 3.6017  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 0.7440  Validation loss = 3.9073  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 0.6690  Validation loss = 3.9448  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 0.6515  Validation loss = 3.8630  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 0.7280  Validation loss = 3.6669  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 0.6609  Validation loss = 3.6798  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 0.6649  Validation loss = 3.9034  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 0.6799  Validation loss = 3.9148  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 0.7028  Validation loss = 3.4949  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 0.6488  Validation loss = 3.9944  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 21  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.0933  Validation loss = 5.9156  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 0.9871  Validation loss = 6.3373  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 0.9985  Validation loss = 6.4414  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.1251  Validation loss = 6.4328  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 0.9687  Validation loss = 6.5294  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.0369  Validation loss = 6.6932  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.0066  Validation loss = 6.5584  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 0.9011  Validation loss = 6.5166  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 0.9694  Validation loss = 6.4919  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 0.9172  Validation loss = 6.2493  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 0.9193  Validation loss = 6.1979  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 0.9090  Validation loss = 6.1629  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 0.8821  Validation loss = 6.2528  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 0.8190  Validation loss = 6.2282  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 0.8227  Validation loss = 6.2477  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 0.8830  Validation loss = 6.2292  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 0.8238  Validation loss = 6.2035  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 0.8540  Validation loss = 5.9848  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 0.8374  Validation loss = 6.1661  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 0.9419  Validation loss = 6.1620  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 0.9957  Validation loss = 6.2339  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 0.9819  Validation loss = 5.9146  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 0.8458  Validation loss = 6.2523  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 22  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 1.4005  Validation loss = 3.3421  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.4533  Validation loss = 3.6222  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.1437  Validation loss = 3.0995  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.1588  Validation loss = 3.1239  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.1670  Validation loss = 3.2845  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.2387  Validation loss = 3.3093  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.2002  Validation loss = 3.4520  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.3312  Validation loss = 3.3621  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 0.9856  Validation loss = 3.5224  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 0.9263  Validation loss = 3.5222  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 0.9108  Validation loss = 3.6123  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 0.9710  Validation loss = 2.4506  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 0.8964  Validation loss = 3.7533  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 12  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.2533  Validation loss = 1.7200  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.1188  Validation loss = 3.4260  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.0717  Validation loss = 2.1870  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.3242  Validation loss = 3.0878  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.1201  Validation loss = 1.8325  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.0710  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.1161  Validation loss = 2.4374  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.1031  Validation loss = 3.4667  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.3598  Validation loss = 3.2977  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.1266  Validation loss = 1.8654  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 0.9732  Validation loss = 2.7202  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.2690  Validation loss = 1.5659  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.2495  Validation loss = 2.1136  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.0112  Validation loss = 3.1371  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 1.0609  Validation loss = 2.1723  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 0.9302  Validation loss = 2.4436  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 1.1038  Validation loss = 1.5641  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 0.9402  Validation loss = 2.0674  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 0.9237  Validation loss = 3.0633  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 0.9060  Validation loss = 2.8058  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 0.8771  Validation loss = 2.1735  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 0.9281  Validation loss = 2.6246  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 1.0315  Validation loss = 3.7965  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 17  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.0832  Validation loss = 1.1194  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 0.9583  Validation loss = 1.1716  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.0880  Validation loss = 1.1139  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.1092  Validation loss = 1.4461  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 0.9929  Validation loss = 1.2928  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 0.9601  Validation loss = 1.2909  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 0.9617  Validation loss = 1.3762  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.2341  Validation loss = 1.3706  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 0.8920  Validation loss = 1.6010  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 0.9188  Validation loss = 1.2763  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 0.9723  Validation loss = 1.1102  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 0.8537  Validation loss = 1.0554  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 0.9958  Validation loss = 1.0761  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 0.9726  Validation loss = 1.1822  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 1.0902  Validation loss = 1.1944  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 0.9657  Validation loss = 1.1638  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 0.9646  Validation loss = 1.2327  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 0.8933  Validation loss = 1.3502  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 1.0567  Validation loss = 1.3671  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 12  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 0.8504  Validation loss = 2.3734  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 0.9177  Validation loss = 2.6753  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 0.8589  Validation loss = 2.6405  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 0.8013  Validation loss = 3.0318  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.3169  Validation loss = 3.9683  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 0.8661  Validation loss = 2.5547  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 0.8244  Validation loss = 3.2379  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 0.9309  Validation loss = 3.4727  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 0.7924  Validation loss = 2.7497  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 0.8755  Validation loss = 2.7604  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 0.8992  Validation loss = 2.7501  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.0672  Validation loss = 1.9906  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 0.7867  Validation loss = 2.5901  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 0.7234  Validation loss = 2.8692  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 0.7437  Validation loss = 3.0629  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 0.7580  Validation loss = 2.8081  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 0.7612  Validation loss = 3.0623  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 0.7022  Validation loss = 3.0105  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 0.6524  Validation loss = 2.9173  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 0.8236  Validation loss = 2.6550  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 0.7496  Validation loss = 3.2771  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 12  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 0.9667  Validation loss = 4.5929  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 0.9068  Validation loss = 4.4014  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 0.8772  Validation loss = 3.4957  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.0627  Validation loss = 4.8716  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 0.8739  Validation loss = 4.5185  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 0.7986  Validation loss = 4.3303  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.3030  Validation loss = 3.6206  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 0.7168  Validation loss = 4.3768  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 0.8460  Validation loss = 4.0164  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 0.7682  Validation loss = 3.7947  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 0.7315  Validation loss = 3.9111  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 0.7458  Validation loss = 4.5920  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 0.6451  Validation loss = 3.7042  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 0.6974  Validation loss = 4.0775  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 0.7855  Validation loss = 4.5249  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 0.7040  Validation loss = 4.5990  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 3  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 1.1088  Validation loss = 4.0265  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 1.0926  Validation loss = 3.7097  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 1.2007  Validation loss = 3.3207  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.0965  Validation loss = 3.3990  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.2642  Validation loss = 3.6382  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.0794  Validation loss = 4.0757  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 1.2470  Validation loss = 3.8486  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 0.9122  Validation loss = 3.8077  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 0.9800  Validation loss = 3.6218  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 1.0413  Validation loss = 3.6880  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 0.8397  Validation loss = 4.0918  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 3  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 1.3204  Validation loss = 4.5197  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 1.1890  Validation loss = 4.6027  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 1.2840  Validation loss = 4.7721  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 1.6744  Validation loss = 5.1808  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 1.6250  Validation loss = 4.8998  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 1.4135  Validation loss = 4.7278  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 1.2728  Validation loss = 4.8455  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 1.2612  Validation loss = 5.6205  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 1.2485  Validation loss = 4.7798  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 1.1855  Validation loss = 5.0082  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 1.1774  Validation loss = 4.6575  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 1.1950  Validation loss = 4.3163  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 1.0846  Validation loss = 4.5250  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 1.0808  Validation loss = 4.5351  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 1.0546  Validation loss = 4.7725  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 1.2806  Validation loss = 4.8270  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 1.1563  Validation loss = 4.7748  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 1.1407  Validation loss = 4.9999  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 1.1031  Validation loss = 4.8287  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 1.6089  Validation loss = 4.7127  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 1.1240  Validation loss = 4.5582  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 1.1737  Validation loss = 4.7023  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 1.0625  Validation loss = 4.6917  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 1.0809  Validation loss = 4.7407  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 1.0458  Validation loss = 4.8130  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 1.1146  Validation loss = 4.6698  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 1.0027  Validation loss = 4.7444  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 1.0225  Validation loss = 4.8972  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 12  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 1.4997  Validation loss = 2.7822  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 1.2482  Validation loss = 3.2226  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 1.2162  Validation loss = 3.0446  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 1.2227  Validation loss = 3.3640  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 1.1429  Validation loss = 2.9533  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 1.0923  Validation loss = 3.1795  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 1.0797  Validation loss = 2.8726  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 1.0698  Validation loss = 3.4005  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 1.1645  Validation loss = 3.2000  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 1.2238  Validation loss = 2.8054  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 1.2394  Validation loss = 3.4055  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 1  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 1.3184  Validation loss = 1.2024  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 1.4165  Validation loss = 1.7483  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 1.1614  Validation loss = 0.8773  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 1.1662  Validation loss = 0.8574  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 1.1590  Validation loss = 0.9758  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 1.1443  Validation loss = 0.8298  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 1.1927  Validation loss = 1.0690  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 1.3090  Validation loss = 0.9470  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 1.1309  Validation loss = 0.5795  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 1.0989  Validation loss = 0.7455  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 1.0748  Validation loss = 0.6990  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 1.0244  Validation loss = 0.8742  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 1.0949  Validation loss = 0.8622  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 1.1679  Validation loss = 1.0689  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 0.9525  Validation loss = 0.4596  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 0.9822  Validation loss = 0.5120  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 1.0228  Validation loss = 0.5812  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 1.0483  Validation loss = 0.8713  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 1.0029  Validation loss = 0.7150  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 1.1385  Validation loss = 0.5643  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 1.0380  Validation loss = 0.7258  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 0.9797  Validation loss = 0.8221  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 1.0748  Validation loss = 0.9063  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 0.9852  Validation loss = 0.5769  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 0.8956  Validation loss = 0.6460  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 0.8996  Validation loss = 0.6457  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 0.8809  Validation loss = 0.7305  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 0.8835  Validation loss = 0.7950  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 0.8181  Validation loss = 0.7751  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 1.0189  Validation loss = 0.7810  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 0.9216  Validation loss = 1.0044  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 15  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 0.9551  Validation loss = 3.0681  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 0.8876  Validation loss = 2.7971  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 0.8411  Validation loss = 2.6423  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 0.9417  Validation loss = 2.4862  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 0.8679  Validation loss = 2.4881  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 0.9117  Validation loss = 3.0055  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 0.7800  Validation loss = 2.9751  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 0.7769  Validation loss = 2.5105  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 0.7552  Validation loss = 2.8239  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 0.7334  Validation loss = 2.5991  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 0.7902  Validation loss = 3.1432  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 4  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 1.2265  Validation loss = 2.8019  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 1.2084  Validation loss = 2.7636  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 0.9263  Validation loss = 2.4248  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 0.8870  Validation loss = 2.6338  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 0.9228  Validation loss = 2.6240  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 1.0661  Validation loss = 2.4383  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 0.9446  Validation loss = 2.6708  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 1.0181  Validation loss = 2.1421  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 0.9566  Validation loss = 2.4719  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 1.0790  Validation loss = 2.1584  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 0.9354  Validation loss = 2.2936  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 0.9850  Validation loss = 2.3484  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 0.8937  Validation loss = 2.5676  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 0.8850  Validation loss = 2.6719  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 8  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 0.9555  Validation loss = 4.4340  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.1366  Validation loss = 3.6158  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 1.1296  Validation loss = 4.0633  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 1.2566  Validation loss = 4.2043  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 1.2536  Validation loss = 4.5147  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 0.9872  Validation loss = 4.8653  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 1.0981  Validation loss = 4.8934  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 0.8690  Validation loss = 4.4253  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 1.0240  Validation loss = 4.4044  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 0.8949  Validation loss = 4.3889  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 0.9443  Validation loss = 3.8774  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 1.2540  Validation loss = 3.8995  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 1.0288  Validation loss = 4.2179  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 1.0534  Validation loss = 3.4868  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 0.9667  Validation loss = 3.9494  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 0.8584  Validation loss = 3.9455  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 0.8568  Validation loss = 3.6178  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 0.9295  Validation loss = 3.9009  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 0.9292  Validation loss = 4.4834  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 14  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 1.5543  Validation loss = 4.3706  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 1.4938  Validation loss = 3.9813  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 1.4035  Validation loss = 4.3459  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 1.1446  Validation loss = 3.6068  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 1.1273  Validation loss = 4.0470  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 0.9966  Validation loss = 4.6342  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 1.2651  Validation loss = 4.4995  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 1.0920  Validation loss = 4.4954  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 1.0632  Validation loss = 4.6194  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 1.0892  Validation loss = 3.8384  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 0.9978  Validation loss = 4.2473  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 0.9060  Validation loss = 4.5750  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 0.9841  Validation loss = 5.0854  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 4  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 1.4446  Validation loss = 3.1486  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 1.5587  Validation loss = 3.7847  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 1.4129  Validation loss = 3.8192  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 1.4305  Validation loss = 4.0900  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 1.2774  Validation loss = 3.4860  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 1.4594  Validation loss = 2.9944  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 1.3826  Validation loss = 2.5634  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 1.4851  Validation loss = 2.8519  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 1.5075  Validation loss = 3.9895  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 1.6952  Validation loss = 4.7711  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 1.3993  Validation loss = 3.3149  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 1.4113  Validation loss = 3.9346  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 1.3181  Validation loss = 4.3132  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 1.3699  Validation loss = 3.5922  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 1.5272  Validation loss = 4.7003  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 1.3959  Validation loss = 4.2900  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 1.2825  Validation loss = 4.0159  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 1.3545  Validation loss = 4.3077  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 1.4295  Validation loss = 2.0587  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 1.2407  Validation loss = 3.8265  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 1.2977  Validation loss = 3.1230  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 1.5536  Validation loss = 3.0106  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 1.2498  Validation loss = 2.9473  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 1.2090  Validation loss = 3.9565  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 1.1455  Validation loss = 4.1031  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 1.1402  Validation loss = 4.2371  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 1.1859  Validation loss = 3.7913  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 1.1467  Validation loss = 3.2402  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 1.0819  Validation loss = 3.6077  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 1.1009  Validation loss = 4.2833  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 19  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.9407  Validation loss = 2.2145  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.3852  Validation loss = 1.5253  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 1.3715  Validation loss = 1.5621  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 1.1337  Validation loss = 1.3907  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.0546  Validation loss = 1.5134  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.4598  Validation loss = 1.7675  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 1.2623  Validation loss = 1.4682  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 1.2940  Validation loss = 1.6477  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 1.3355  Validation loss = 2.0341  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 1.2738  Validation loss = 1.7367  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 1.3904  Validation loss = 2.1825  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 4  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 1.2593  Validation loss = 2.1854  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 1.2974  Validation loss = 2.1057  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 1.4563  Validation loss = 3.2547  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 1.2192  Validation loss = 2.6431  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 1.2136  Validation loss = 2.1472  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 1.2919  Validation loss = 2.0158  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 1.3797  Validation loss = 2.6216  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 1.2519  Validation loss = 2.3546  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 1.1838  Validation loss = 2.5385  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 1.1100  Validation loss = 2.6030  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 1.0538  Validation loss = 2.4884  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 0.9926  Validation loss = 2.3219  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 1.1115  Validation loss = 2.7363  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 6  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 1.2686  Validation loss = 2.3683  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 1.1740  Validation loss = 1.7218  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 1.2790  Validation loss = 2.6097  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 1.3423  Validation loss = 2.3906  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 1.4105  Validation loss = 3.6549  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 1.1597  Validation loss = 3.2819  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 1.1582  Validation loss = 3.3828  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 1.1640  Validation loss = 2.9467  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 1.2913  Validation loss = 3.5622  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 1.6611  Validation loss = 4.2959  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 1.3662  Validation loss = 1.8909  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 1.5633  Validation loss = 2.8102  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 1.3919  Validation loss = 3.3965  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 1.4492  Validation loss = 2.3645  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 1.5320  Validation loss = 1.9070  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 1.8557  Validation loss = 2.5807  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 1.5382  Validation loss = 2.9907  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 1.4458  Validation loss = 2.2166  \n",
      "\n",
      "Fold: 26  Epoch: 19  Training loss = 1.4115  Validation loss = 1.6861  \n",
      "\n",
      "Fold: 26  Epoch: 20  Training loss = 1.3171  Validation loss = 2.7360  \n",
      "\n",
      "Fold: 26  Epoch: 21  Training loss = 1.9884  Validation loss = 0.9479  \n",
      "\n",
      "Fold: 26  Epoch: 22  Training loss = 1.9879  Validation loss = 5.0696  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 21  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 1.7372  Validation loss = 0.9584  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 1.4859  Validation loss = 0.9487  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 1.4970  Validation loss = 0.9782  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 1.4328  Validation loss = 0.8564  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 1.4551  Validation loss = 0.9600  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 1.4307  Validation loss = 1.3024  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 1.3751  Validation loss = 1.5939  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 1.3511  Validation loss = 1.2633  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 1.4135  Validation loss = 1.3944  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.4632  Validation loss = 1.0979  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 1.4698  Validation loss = 0.9801  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 1.4511  Validation loss = 1.0075  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 1.3656  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 1.4121  Validation loss = 1.2327  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 1.3354  Validation loss = 0.6258  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 1.3462  Validation loss = 0.9371  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 1.2974  Validation loss = 0.7017  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 1.2839  Validation loss = 1.0186  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 1.3445  Validation loss = 1.4966  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 15  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 1.2348  Validation loss = 2.8295  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 1.2617  Validation loss = 3.0959  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 1.2419  Validation loss = 2.4223  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 1.2322  Validation loss = 2.8932  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 1.1797  Validation loss = 2.6451  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 1.1719  Validation loss = 2.1756  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 1.1299  Validation loss = 2.9531  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 1.1101  Validation loss = 2.3473  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 1.2654  Validation loss = 2.2397  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 1.2537  Validation loss = 1.9496  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 1.2460  Validation loss = 2.3398  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 1.2027  Validation loss = 2.3483  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 1.3210  Validation loss = 2.2571  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 1.2247  Validation loss = 2.7062  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 1.1560  Validation loss = 2.7431  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 1.1899  Validation loss = 2.0054  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 1.1827  Validation loss = 2.3606  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 1.1749  Validation loss = 2.1859  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 1.2228  Validation loss = 2.1558  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 1.1482  Validation loss = 2.6910  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 1.1228  Validation loss = 2.3387  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 1.0839  Validation loss = 2.6059  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 1.1426  Validation loss = 1.8916  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 1.1733  Validation loss = 2.1481  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 1.1499  Validation loss = 1.6892  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 1.1978  Validation loss = 2.3913  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 1.1558  Validation loss = 2.8327  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 25  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 1.2978  Validation loss = 1.5143  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 1.3999  Validation loss = 1.4502  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 1.4883  Validation loss = 1.4302  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 1.5328  Validation loss = 1.3941  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 1.3393  Validation loss = 1.4061  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 1.4422  Validation loss = 1.8130  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 1.2686  Validation loss = 1.5672  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 1.5387  Validation loss = 1.7397  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 1.3778  Validation loss = 1.7560  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.4688  Validation loss = 1.6985  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 1.4361  Validation loss = 1.5880  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 1.3999  Validation loss = 1.5788  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 1.3878  Validation loss = 1.6210  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 1.3188  Validation loss = 1.6458  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 1.5322  Validation loss = 2.0109  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 4  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.3626  Validation loss = 2.4649  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 1.2898  Validation loss = 2.4778  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 1.4214  Validation loss = 1.9403  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 1.3241  Validation loss = 3.0501  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 1.2887  Validation loss = 2.3083  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.3936  Validation loss = 2.4614  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 1.4823  Validation loss = 3.3928  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 1.2837  Validation loss = 3.0305  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.2760  Validation loss = 3.0905  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 1.3675  Validation loss = 2.7610  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 1.3455  Validation loss = 2.4883  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 1.2934  Validation loss = 1.7620  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 1.3211  Validation loss = 3.5871  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 12  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 1.5512  Validation loss = 4.1470  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.4802  Validation loss = 3.9785  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 1.4692  Validation loss = 3.6345  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.6674  Validation loss = 4.5629  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 1.5009  Validation loss = 3.7370  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 1.5380  Validation loss = 3.9845  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 1.4316  Validation loss = 3.9181  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.4379  Validation loss = 3.7866  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 1.4059  Validation loss = 3.6466  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 1.4572  Validation loss = 3.4898  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.3659  Validation loss = 3.6925  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 1.4710  Validation loss = 4.1463  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 1.4951  Validation loss = 3.5215  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 1.3507  Validation loss = 3.4135  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 1.3815  Validation loss = 3.6414  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 1.3282  Validation loss = 3.6088  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 1.4240  Validation loss = 4.0418  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 1.4268  Validation loss = 3.7216  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 1.3102  Validation loss = 3.6424  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 1.3094  Validation loss = 4.0366  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 1.3271  Validation loss = 3.4902  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 1.3150  Validation loss = 3.4161  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 1.2775  Validation loss = 3.9378  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 1.3619  Validation loss = 3.2585  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 1.2963  Validation loss = 3.2656  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 1.3553  Validation loss = 3.5828  \n",
      "\n",
      "Fold: 31  Epoch: 27  Training loss = 1.3223  Validation loss = 3.7308  \n",
      "\n",
      "Fold: 31  Epoch: 28  Training loss = 1.2932  Validation loss = 3.5743  \n",
      "\n",
      "Fold: 31  Epoch: 29  Training loss = 1.2350  Validation loss = 3.8036  \n",
      "\n",
      "Fold: 31  Epoch: 30  Training loss = 1.2453  Validation loss = 3.7296  \n",
      "\n",
      "Fold: 31  Epoch: 31  Training loss = 1.2296  Validation loss = 3.5650  \n",
      "\n",
      "Fold: 31  Epoch: 32  Training loss = 1.2426  Validation loss = 4.1329  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 24  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.3991  Validation loss = 4.2851  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.3322  Validation loss = 4.2388  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.1261  Validation loss = 2.8166  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.1755  Validation loss = 3.8610  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.2634  Validation loss = 3.9291  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.0808  Validation loss = 3.2353  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 0.9721  Validation loss = 2.8447  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.1470  Validation loss = 3.5834  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 0.9652  Validation loss = 3.3601  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 0.9359  Validation loss = 2.9239  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 0.9433  Validation loss = 2.8528  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 0.8681  Validation loss = 3.1837  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 0.8642  Validation loss = 3.0821  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 0.8911  Validation loss = 2.9343  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.1116  Validation loss = 3.7603  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 3  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 10\n",
      "Average validation error: 3.16004\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.1079  Test loss = 3.6352  \n",
      "\n",
      "Epoch: 2  Training loss = 1.0393  Test loss = 3.5196  \n",
      "\n",
      "Epoch: 3  Training loss = 1.0112  Test loss = 3.4691  \n",
      "\n",
      "Epoch: 4  Training loss = 0.9904  Test loss = 3.4366  \n",
      "\n",
      "Epoch: 5  Training loss = 0.9729  Test loss = 3.4118  \n",
      "\n",
      "Epoch: 6  Training loss = 0.9578  Test loss = 3.3913  \n",
      "\n",
      "Epoch: 7  Training loss = 0.9443  Test loss = 3.3737  \n",
      "\n",
      "Epoch: 8  Training loss = 0.9323  Test loss = 3.3582  \n",
      "\n",
      "Epoch: 9  Training loss = 0.9214  Test loss = 3.3443  \n",
      "\n",
      "Epoch: 10  Training loss = 0.9114  Test loss = 3.3318  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc5b8908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPInmzitWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcbf0e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.33176814722 \n",
      "Fixed scheme MAE:  2.28629128695\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 0.9114  Test loss = 2.0371  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 0.9457  Test loss = 1.8173  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 0.9719  Test loss = 0.3186  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 0.9727  Test loss = 0.8912  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 0.6359  Test loss = 0.6316  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 0.6405  Test loss = 0.8185  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 0.6416  Test loss = 0.3553  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 0.6430  Test loss = 0.3284  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.5182  Test loss = 0.4574  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.5213  Test loss = 1.3539  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 0.5459  Test loss = 2.6602  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 0.6378  Test loss = 2.5697  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.5140  Test loss = 0.4705  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.5173  Test loss = 3.3507  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 0.6636  Test loss = 0.9555  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 0.6741  Test loss = 3.0768  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.5838  Test loss = 0.3820  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 0.5857  Test loss = 1.1055  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 0.6015  Test loss = 1.0069  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 0.6143  Test loss = 1.7669  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.4690  Test loss = 0.1568  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.4691  Test loss = 4.1153  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 0.6917  Test loss = 2.2494  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 0.7457  Test loss = 1.4370  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.5414  Test loss = 0.4623  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.5367  Test loss = 0.2516  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 0.5373  Test loss = 0.4484  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 0.5362  Test loss = 1.5914  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.4576  Test loss = 1.1819  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.4803  Test loss = 0.5250  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.4845  Test loss = 4.3777  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.7275  Test loss = 1.7103  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.6617  Test loss = 3.2512  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.7748  Test loss = 3.7483  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.8919  Test loss = 0.5190  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.8937  Test loss = 8.0051  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.1589  Test loss = 1.5651  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.1611  Test loss = 0.7876  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.1652  Test loss = 1.1282  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.1734  Test loss = 1.8609  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.5978  Test loss = 3.6752  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.7518  Test loss = 2.1478  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.7976  Test loss = 2.8542  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 0.8702  Test loss = 13.7166  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.8643  Test loss = 7.9596  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1095  Test loss = 4.1489  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1714  Test loss = 1.1631  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1755  Test loss = 0.1210  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.4089  Test loss = 2.2094  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.4341  Test loss = 2.6116  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.4702  Test loss = 0.8891  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.4740  Test loss = 0.0090  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.2609  Test loss = 6.2491  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.4778  Test loss = 4.5768  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.5804  Test loss = 5.7407  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.7263  Test loss = 1.3255  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.1164  Test loss = 0.6655  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.1193  Test loss = 1.2740  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.1298  Test loss = 1.1931  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.1357  Test loss = 1.4514  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.3724  Test loss = 1.4671  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.3834  Test loss = 1.2857  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.3914  Test loss = 1.1057  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.3804  Test loss = 3.1237  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 0.9904  Test loss = 1.1958  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.0002  Test loss = 0.2670  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.0007  Test loss = 3.4421  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.0877  Test loss = 3.4547  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 0.9448  Test loss = 5.1884  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.1431  Test loss = 2.7141  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.1911  Test loss = 0.3115  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.1916  Test loss = 3.1758  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 0.8771  Test loss = 3.0515  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 0.9553  Test loss = 0.3575  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 0.9555  Test loss = 2.0856  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 0.9880  Test loss = 0.0252  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 0.6861  Test loss = 2.2875  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYjcz65gvAQhcEBa7FdGqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcc33240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 3.04307434158 \n",
      "Updating scheme MAE:  2.13307128981\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
