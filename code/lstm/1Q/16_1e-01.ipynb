{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/16_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-1\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 16 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 16 \n",
      "Learning rate = 0.1 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.1\n",
      "Fold: 1  Epoch: 1  Training loss = 2.6984  Validation loss = 1.8226  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.6147  Validation loss = 1.4360  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.6094  Validation loss = 2.3361  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.4256  Validation loss = 2.1051  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.3202  Validation loss = 1.5394  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.2160  Validation loss = 1.6009  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.5904  Validation loss = 2.4013  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.1634  Validation loss = 2.1398  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 1.9154  Validation loss = 1.1022  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 1.8148  Validation loss = 2.0201  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 1.8032  Validation loss = 1.6953  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 1.7976  Validation loss = 1.1323  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 1.7417  Validation loss = 1.0986  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 1.7026  Validation loss = 1.7635  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 2.0790  Validation loss = 1.0493  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 1.6775  Validation loss = 1.2848  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 1.5605  Validation loss = 1.9169  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 1.5680  Validation loss = 2.2236  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 15  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 1.5120  Validation loss = 1.7945  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 1.9039  Validation loss = 1.9146  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.2437  Validation loss = 1.7864  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.0511  Validation loss = 1.5558  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 1.8794  Validation loss = 1.6502  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 1.5640  Validation loss = 1.8934  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 1.5670  Validation loss = 1.9706  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 1.4735  Validation loss = 2.0201  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 1.4449  Validation loss = 2.2751  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 1.5241  Validation loss = 2.5332  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 1.3544  Validation loss = 2.3576  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 1.3886  Validation loss = 2.4600  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 1.5199  Validation loss = 1.4811  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 1.3476  Validation loss = 1.4196  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 1.4730  Validation loss = 2.0804  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 1.4635  Validation loss = 2.3667  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 1.5115  Validation loss = 2.0747  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 1.4320  Validation loss = 2.2115  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 1.3182  Validation loss = 1.4479  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 1.4794  Validation loss = 1.4646  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 1.3140  Validation loss = 1.5026  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 1.3411  Validation loss = 1.4154  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 1.3286  Validation loss = 1.5004  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 1.3753  Validation loss = 1.5871  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 1.3389  Validation loss = 1.3265  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 1.4469  Validation loss = 1.4020  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 1.2788  Validation loss = 1.4726  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 1.2863  Validation loss = 1.2579  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 1.2417  Validation loss = 1.3406  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 1.2815  Validation loss = 1.2253  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 1.1988  Validation loss = 1.3380  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 1.2427  Validation loss = 1.5345  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 1.2864  Validation loss = 1.3298  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 1.2863  Validation loss = 1.3916  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 1.2467  Validation loss = 1.3171  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 1.5609  Validation loss = 2.2204  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 30  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.2197  Validation loss = 1.1513  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.1806  Validation loss = 1.2909  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.3979  Validation loss = 1.1733  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.1823  Validation loss = 1.0127  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.1777  Validation loss = 1.5223  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.1614  Validation loss = 1.3622  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.1778  Validation loss = 0.9184  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.2529  Validation loss = 0.9214  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.3097  Validation loss = 0.9573  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.1966  Validation loss = 0.6978  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.1482  Validation loss = 1.2319  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.1589  Validation loss = 1.2285  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.1494  Validation loss = 1.2339  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.1321  Validation loss = 1.0106  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.1509  Validation loss = 1.2952  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.1343  Validation loss = 1.0600  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.1605  Validation loss = 1.4351  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 10  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.1060  Validation loss = 3.9616  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.1153  Validation loss = 3.9914  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.0901  Validation loss = 3.7205  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.0558  Validation loss = 4.1594  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.1001  Validation loss = 4.3153  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.0265  Validation loss = 3.7159  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.0149  Validation loss = 4.0529  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.1100  Validation loss = 3.3228  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.0165  Validation loss = 3.5748  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.0220  Validation loss = 3.7362  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.0154  Validation loss = 4.0603  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.0089  Validation loss = 3.7142  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 0.9799  Validation loss = 3.8769  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 0.9950  Validation loss = 3.7591  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.0545  Validation loss = 4.1320  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 8  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.2181  Validation loss = 1.9752  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.0949  Validation loss = 1.3773  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.1636  Validation loss = 1.0322  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.0534  Validation loss = 1.1400  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.0035  Validation loss = 1.1911  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 0.9714  Validation loss = 1.2291  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 0.9523  Validation loss = 1.2116  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 0.9270  Validation loss = 0.9446  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.0437  Validation loss = 1.6217  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 0.9404  Validation loss = 0.9818  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.9764  Validation loss = 1.2076  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 0.9240  Validation loss = 1.1483  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.0082  Validation loss = 1.0579  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 0.8917  Validation loss = 0.9703  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.9355  Validation loss = 0.9987  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 0.9071  Validation loss = 1.1188  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.0505  Validation loss = 1.1398  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 0.8890  Validation loss = 1.5304  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 0.9727  Validation loss = 1.3983  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 0.8882  Validation loss = 1.4438  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 0.9380  Validation loss = 1.4854  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 0.8562  Validation loss = 1.2475  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 0.9388  Validation loss = 1.3429  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 0.9525  Validation loss = 1.3115  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 0.9458  Validation loss = 1.2037  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 0.9637  Validation loss = 1.1911  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 0.8996  Validation loss = 1.1305  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 0.9319  Validation loss = 1.1903  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 0.9445  Validation loss = 1.1107  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 0.9653  Validation loss = 1.2566  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 0.9868  Validation loss = 1.4219  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 8  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 0.9290  Validation loss = 2.0522  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 0.9274  Validation loss = 2.1944  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.9226  Validation loss = 1.9753  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.9827  Validation loss = 1.9309  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.9690  Validation loss = 2.0060  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.9284  Validation loss = 1.8758  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.9082  Validation loss = 1.9678  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.9471  Validation loss = 2.2171  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.8752  Validation loss = 2.1413  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.8811  Validation loss = 2.0565  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.8843  Validation loss = 2.0482  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.9463  Validation loss = 1.9628  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.9479  Validation loss = 2.2322  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 6  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.9668  Validation loss = 0.3968  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.9190  Validation loss = 0.4387  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.0576  Validation loss = 0.7061  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.0160  Validation loss = 0.6736  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.9199  Validation loss = 0.4116  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.9115  Validation loss = 0.3627  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.9666  Validation loss = 0.3521  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.9933  Validation loss = 0.8106  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.8822  Validation loss = 0.3664  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.9031  Validation loss = 0.4000  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.8942  Validation loss = 0.6131  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.9072  Validation loss = 0.6933  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.8768  Validation loss = 0.3050  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.9586  Validation loss = 0.2926  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 0.9852  Validation loss = 0.5968  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 0.8521  Validation loss = 0.3825  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 0.8655  Validation loss = 0.4481  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 0.8452  Validation loss = 0.6138  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 0.8967  Validation loss = 0.5583  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 0.8598  Validation loss = 0.3359  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 0.8366  Validation loss = 0.5573  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.0933  Validation loss = 1.1038  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 14  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.7913  Validation loss = 5.1613  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.7394  Validation loss = 4.9004  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.8238  Validation loss = 5.7550  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.7422  Validation loss = 4.8236  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.7317  Validation loss = 4.9975  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.7620  Validation loss = 5.1336  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.7961  Validation loss = 5.5807  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.7298  Validation loss = 5.3132  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.7520  Validation loss = 5.3220  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.7176  Validation loss = 5.2138  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.7566  Validation loss = 5.2691  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.7697  Validation loss = 5.8384  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 4  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.3724  Validation loss = 7.0991  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.4659  Validation loss = 6.4323  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.4785  Validation loss = 6.3191  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.5852  Validation loss = 6.9525  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.5239  Validation loss = 5.0736  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.4447  Validation loss = 5.8905  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.3422  Validation loss = 6.9105  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.6989  Validation loss = 5.7985  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.5225  Validation loss = 6.8712  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.4422  Validation loss = 7.4229  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.4054  Validation loss = 7.0457  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.7688  Validation loss = 7.3530  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.4814  Validation loss = 7.0264  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.4496  Validation loss = 5.9802  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.4822  Validation loss = 6.3382  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.3569  Validation loss = 6.1768  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.3508  Validation loss = 5.3105  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.3218  Validation loss = 5.8913  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.7611  Validation loss = 7.0369  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.4893  Validation loss = 7.1507  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.3560  Validation loss = 7.2276  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 1.2453  Validation loss = 6.1555  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.2810  Validation loss = 6.3722  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 1.6727  Validation loss = 5.3958  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 1.1346  Validation loss = 6.1246  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 1.1901  Validation loss = 6.0452  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 1.1591  Validation loss = 6.1318  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 1.1493  Validation loss = 5.3456  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 1.0975  Validation loss = 5.5900  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 1.1640  Validation loss = 5.5552  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 1.0130  Validation loss = 5.8335  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 1.1239  Validation loss = 6.4962  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 5  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 1.6249  Validation loss = 2.3520  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.4808  Validation loss = 1.6419  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.5582  Validation loss = 3.6095  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.4357  Validation loss = 3.3925  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.9220  Validation loss = 2.2171  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.6575  Validation loss = 2.7779  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.1413  Validation loss = 2.7008  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.0554  Validation loss = 2.8218  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.1171  Validation loss = 3.3526  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.4447  Validation loss = 2.2981  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.5525  Validation loss = 2.3032  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 1.6556  Validation loss = 1.7713  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 1.6031  Validation loss = 2.9106  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.7750  Validation loss = 2.2029  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 1.6293  Validation loss = 1.3241  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 1.3436  Validation loss = 2.1167  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 3.0465  Validation loss = 5.2493  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 15  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 2.7422  Validation loss = 4.2937  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 2.0378  Validation loss = 1.6162  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.9839  Validation loss = 1.8190  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 2.0259  Validation loss = 2.8232  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.6412  Validation loss = 1.7585  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.9049  Validation loss = 1.0232  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.7538  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.5441  Validation loss = 1.7375  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.5619  Validation loss = 3.0510  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.3701  Validation loss = 3.4066  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.3013  Validation loss = 2.7174  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.2775  Validation loss = 3.3104  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.5259  Validation loss = 5.0375  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 6  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.3682  Validation loss = 1.6258  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.4161  Validation loss = 2.1893  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.2868  Validation loss = 2.1547  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.2221  Validation loss = 2.1520  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.2459  Validation loss = 1.9666  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.2535  Validation loss = 1.6272  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.1827  Validation loss = 1.8895  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.3027  Validation loss = 2.4669  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.1422  Validation loss = 2.2391  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.3835  Validation loss = 1.7954  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.1536  Validation loss = 2.4949  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 1  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.2975  Validation loss = 2.9495  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.1905  Validation loss = 3.2673  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.1888  Validation loss = 3.0924  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.4319  Validation loss = 2.7413  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.8958  Validation loss = 2.9230  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.7249  Validation loss = 2.8191  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.8527  Validation loss = 1.8825  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.7533  Validation loss = 2.8564  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.6995  Validation loss = 2.6732  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.7229  Validation loss = 2.7663  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.7816  Validation loss = 3.7606  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 7  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.0941  Validation loss = 8.0142  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.2184  Validation loss = 4.5438  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.4677  Validation loss = 6.5495  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.0453  Validation loss = 5.6454  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.0024  Validation loss = 6.1410  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.8604  Validation loss = 5.9389  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.5751  Validation loss = 3.7618  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.8950  Validation loss = 6.5820  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.0081  Validation loss = 6.9307  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.9807  Validation loss = 6.7887  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.8984  Validation loss = 5.8287  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.9055  Validation loss = 6.6632  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.9773  Validation loss = 6.7461  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.8608  Validation loss = 6.3193  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.1429  Validation loss = 6.2023  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.0542  Validation loss = 6.1138  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.8741  Validation loss = 5.5454  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.9997  Validation loss = 6.0834  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 2.4840  Validation loss = 3.9261  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.3142  Validation loss = 4.1502  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 2.5066  Validation loss = 7.0295  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 7  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.7340  Validation loss = 8.1684  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.9194  Validation loss = 8.1687  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.6426  Validation loss = 7.2653  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.5080  Validation loss = 7.7005  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.6984  Validation loss = 6.7650  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.5343  Validation loss = 7.9110  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.8980  Validation loss = 6.5767  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.5009  Validation loss = 7.7382  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.6573  Validation loss = 9.0865  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.7685  Validation loss = 9.0010  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.5152  Validation loss = 7.3313  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.5332  Validation loss = 7.8570  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.5548  Validation loss = 6.5560  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.4891  Validation loss = 7.4673  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.4867  Validation loss = 7.3348  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.4128  Validation loss = 7.3942  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.7780  Validation loss = 8.1399  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 2.8797  Validation loss = 8.2876  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.5068  Validation loss = 7.6779  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.5967  Validation loss = 7.6028  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.4376  Validation loss = 7.2442  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 2.4153  Validation loss = 8.0768  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 2.4792  Validation loss = 7.3938  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.6442  Validation loss = 8.7185  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 13  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.9482  Validation loss = 2.5165  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.8876  Validation loss = 2.9868  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 3.1402  Validation loss = 3.1868  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 3.0358  Validation loss = 2.8808  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.8012  Validation loss = 2.4722  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.8412  Validation loss = 2.5946  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.9557  Validation loss = 2.1187  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.8173  Validation loss = 2.8996  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.9193  Validation loss = 2.1155  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.8111  Validation loss = 2.3989  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.8441  Validation loss = 2.4179  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 3.1983  Validation loss = 2.0319  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.9107  Validation loss = 2.8090  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 3.0452  Validation loss = 3.2751  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 12  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 3.1882  Validation loss = 4.4679  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.9465  Validation loss = 3.5087  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.7833  Validation loss = 4.4398  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 3.4143  Validation loss = 2.3024  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 3.1734  Validation loss = 2.9434  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 3.6229  Validation loss = 4.6930  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 3.2306  Validation loss = 4.8019  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 3.1755  Validation loss = 4.1430  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 3.3080  Validation loss = 2.3880  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 3.2213  Validation loss = 2.5400  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 3.3245  Validation loss = 3.7474  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 3.2660  Validation loss = 3.5953  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 3.0774  Validation loss = 3.5749  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 3.2744  Validation loss = 3.9045  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 4.0060  Validation loss = 2.2489  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 3.1095  Validation loss = 4.6185  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 3.0977  Validation loss = 5.3630  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 15  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 3.2221  Validation loss = 3.6844  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 3.1670  Validation loss = 4.9000  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 3.5998  Validation loss = 5.5653  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.8729  Validation loss = 2.0424  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 3.1012  Validation loss = 5.1062  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 3.3665  Validation loss = 3.6660  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 3.2446  Validation loss = 5.2383  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.9870  Validation loss = 4.1203  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 3.2127  Validation loss = 5.2377  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 3.0045  Validation loss = 4.1379  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.0349  Validation loss = 4.0657  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 3.2979  Validation loss = 5.4865  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 3.1746  Validation loss = 5.4170  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 3.3825  Validation loss = 4.3885  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 4.3853  Validation loss = 2.1015  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 3.3361  Validation loss = 5.5266  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 4  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 3.2187  Validation loss = 3.0586  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 3.2519  Validation loss = 2.2210  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 3.0665  Validation loss = 2.9573  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 3.0543  Validation loss = 2.7330  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.9616  Validation loss = 2.9369  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.9329  Validation loss = 2.5234  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.8535  Validation loss = 2.7288  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.8813  Validation loss = 3.5557  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.9219  Validation loss = 3.2410  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 3.3792  Validation loss = 2.0491  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 3.3812  Validation loss = 3.6853  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 10  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 3.3667  Validation loss = 5.7278  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 3.3595  Validation loss = 4.6841  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 3.1260  Validation loss = 3.7662  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 3.4096  Validation loss = 2.8800  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 3.2218  Validation loss = 5.6224  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 3.0191  Validation loss = 4.4230  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.9830  Validation loss = 5.6054  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.8571  Validation loss = 4.6676  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.9203  Validation loss = 3.6354  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.8218  Validation loss = 1.1408  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.8970  Validation loss = 0.8042  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.9767  Validation loss = 2.1791  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 2.9518  Validation loss = 2.2206  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.9275  Validation loss = 1.5350  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.8077  Validation loss = 0.7628  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.8979  Validation loss = 1.2985  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.9048  Validation loss = 0.7620  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.9548  Validation loss = 1.4977  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 3.3025  Validation loss = 2.7426  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 17  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.7115  Validation loss = 3.8036  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.7202  Validation loss = 4.0806  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.8149  Validation loss = 3.9656  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.8909  Validation loss = 4.3466  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 3.4816  Validation loss = 3.9021  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 3.0709  Validation loss = 3.7741  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.7814  Validation loss = 3.4597  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.8423  Validation loss = 3.0815  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.7736  Validation loss = 3.4084  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.9783  Validation loss = 4.9835  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.6841  Validation loss = 4.6300  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.7269  Validation loss = 4.7024  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 2.6186  Validation loss = 5.1870  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 8  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 3.1550  Validation loss = 3.8214  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.9520  Validation loss = 4.1723  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 3.1480  Validation loss = 3.5780  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.9337  Validation loss = 4.2043  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 3.0129  Validation loss = 3.6007  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.9370  Validation loss = 4.3983  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 2.7123  Validation loss = 3.8111  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.6790  Validation loss = 4.2975  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.7089  Validation loss = 3.5546  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.4557  Validation loss = 3.8934  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.4943  Validation loss = 3.3850  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.7843  Validation loss = 2.5805  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.6190  Validation loss = 2.9598  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 3.0679  Validation loss = 2.9832  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 3.6067  Validation loss = 3.4831  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 3.0667  Validation loss = 7.0296  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 12  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 3.9573  Validation loss = 5.7001  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 3.1066  Validation loss = 3.8818  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 3.0384  Validation loss = 3.2702  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.9276  Validation loss = 3.4349  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.8702  Validation loss = 3.3735  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 3.1893  Validation loss = 4.1694  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 3.0654  Validation loss = 3.4761  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 3.1789  Validation loss = 3.3370  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.9046  Validation loss = 3.5643  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.8632  Validation loss = 3.0841  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.8832  Validation loss = 3.0700  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.9129  Validation loss = 3.2527  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 2.8856  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 3.1504  Validation loss = 3.4695  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 3.7180  Validation loss = 3.4999  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 3.0858  Validation loss = 3.2553  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 3.6477  Validation loss = 3.6514  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 11  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.8735  Validation loss = 1.9030  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.8836  Validation loss = 2.2150  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.9984  Validation loss = 3.6260  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.9803  Validation loss = 3.1704  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.8449  Validation loss = 2.9314  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 3.1202  Validation loss = 1.6495  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.9413  Validation loss = 2.0729  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.7991  Validation loss = 2.1574  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.7872  Validation loss = 2.6712  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.8491  Validation loss = 4.1465  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.5558  Validation loss = 3.4392  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.5709  Validation loss = 2.5316  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.4030  Validation loss = 2.9189  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.4103  Validation loss = 2.4662  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.5236  Validation loss = 2.0974  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.7332  Validation loss = 3.8280  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.5540  Validation loss = 2.2259  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.4652  Validation loss = 2.9975  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.5725  Validation loss = 2.2908  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 2.7747  Validation loss = 3.4820  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 2.6819  Validation loss = 2.0281  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 2.4854  Validation loss = 3.0865  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 2.4555  Validation loss = 2.8722  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 2.4053  Validation loss = 3.0191  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 2.5259  Validation loss = 1.9717  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 2.5528  Validation loss = 2.4449  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 2.5850  Validation loss = 1.7741  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 2.4941  Validation loss = 2.2887  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 2.6886  Validation loss = 1.9270  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 2.4380  Validation loss = 2.3179  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 2.4378  Validation loss = 2.2679  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 2.4393  Validation loss = 2.0785  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 2.5307  Validation loss = 2.8801  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 2.4675  Validation loss = 1.7583  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 2.5263  Validation loss = 1.8848  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 2.4572  Validation loss = 1.9671  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 2.4692  Validation loss = 2.5265  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 2.5101  Validation loss = 1.8558  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 2.4453  Validation loss = 2.5455  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 2.4561  Validation loss = 1.9451  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 2.5556  Validation loss = 1.7370  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 2.9010  Validation loss = 3.5743  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 6  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.6715  Validation loss = 3.0261  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.6348  Validation loss = 2.2911  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.6386  Validation loss = 2.2990  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.6330  Validation loss = 2.8072  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.7772  Validation loss = 2.2332  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.8643  Validation loss = 1.7260  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.6435  Validation loss = 1.4296  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.4937  Validation loss = 2.1430  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.5025  Validation loss = 2.0543  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.4886  Validation loss = 2.2458  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.5569  Validation loss = 2.0183  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.4994  Validation loss = 2.5307  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.5031  Validation loss = 2.5878  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.4806  Validation loss = 2.3177  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.7949  Validation loss = 2.2134  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.5018  Validation loss = 2.8570  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 7  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.5348  Validation loss = 7.2170  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.1543  Validation loss = 5.8381  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.0632  Validation loss = 4.4763  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.0521  Validation loss = 5.3399  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.2015  Validation loss = 5.1550  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.0040  Validation loss = 5.1664  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.1345  Validation loss = 5.0705  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.4887  Validation loss = 6.3884  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.0520  Validation loss = 5.4057  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.0389  Validation loss = 4.6590  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.9721  Validation loss = 4.5747  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.9798  Validation loss = 4.3875  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 3.0535  Validation loss = 4.6859  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 3.0094  Validation loss = 3.8649  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 2.9774  Validation loss = 4.7177  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 3.0086  Validation loss = 4.3691  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 3.0389  Validation loss = 4.2715  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 3.0449  Validation loss = 4.9305  \n",
      "\n",
      "Fold: 26  Epoch: 19  Training loss = 3.3291  Validation loss = 5.0129  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 14  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.3194  Validation loss = 1.7665  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.1657  Validation loss = 2.0731  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.1125  Validation loss = 2.2372  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.1172  Validation loss = 2.1204  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.1019  Validation loss = 2.4775  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.1441  Validation loss = 2.2820  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.1028  Validation loss = 2.4761  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.1413  Validation loss = 2.8369  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.1112  Validation loss = 2.3959  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.0910  Validation loss = 2.4247  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.2605  Validation loss = 3.2632  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 1  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.2643  Validation loss = 2.3771  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.0250  Validation loss = 3.0055  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.0588  Validation loss = 3.9190  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.0060  Validation loss = 3.5978  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.3163  Validation loss = 3.3633  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.2914  Validation loss = 3.1482  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.2074  Validation loss = 2.7799  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.2184  Validation loss = 2.6169  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.1362  Validation loss = 3.3928  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.1661  Validation loss = 2.7168  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.1350  Validation loss = 3.9030  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 3.1256  Validation loss = 3.7842  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 3.3275  Validation loss = 4.4364  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 1  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.1941  Validation loss = 3.3815  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.3638  Validation loss = 3.9183  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.1575  Validation loss = 3.3232  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.2807  Validation loss = 4.1256  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.2206  Validation loss = 3.8164  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.1275  Validation loss = 3.5488  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.2743  Validation loss = 3.4237  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.2053  Validation loss = 3.0948  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.1532  Validation loss = 3.3663  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.3757  Validation loss = 4.2504  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.1234  Validation loss = 3.0767  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 3.1447  Validation loss = 3.5030  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.1310  Validation loss = 3.3533  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 3.0942  Validation loss = 2.1869  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 3.1178  Validation loss = 2.0395  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 3.1290  Validation loss = 2.7504  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 3.2643  Validation loss = 2.2650  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 3.1190  Validation loss = 2.7232  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 3.1628  Validation loss = 1.6333  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 3.2400  Validation loss = 1.9876  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 3.6980  Validation loss = 1.6042  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 3.2470  Validation loss = 1.7841  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 3.3321  Validation loss = 1.8218  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 3.2523  Validation loss = 3.0690  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 21  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.1890  Validation loss = 3.7575  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.0542  Validation loss = 2.3540  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.0055  Validation loss = 3.0707  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.1071  Validation loss = 2.0289  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.0505  Validation loss = 2.3803  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.0156  Validation loss = 2.9264  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.0343  Validation loss = 3.4547  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.1411  Validation loss = 2.3538  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.5144  Validation loss = 4.5209  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.2961  Validation loss = 1.8734  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.0318  Validation loss = 3.1977  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 3.0877  Validation loss = 3.4276  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 3.0003  Validation loss = 2.7624  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 3.1274  Validation loss = 3.6705  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 2.9568  Validation loss = 3.0494  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 2.9683  Validation loss = 2.5458  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 3.0047  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 3.0533  Validation loss = 3.2767  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 3.1541  Validation loss = 1.6631  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 3.1544  Validation loss = 3.1345  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 3.2239  Validation loss = 3.4558  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 3.0142  Validation loss = 2.3965  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 2.9658  Validation loss = 3.0882  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 3.0664  Validation loss = 3.0435  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 2.9371  Validation loss = 2.2872  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 2.9553  Validation loss = 2.8152  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 3.0821  Validation loss = 2.8590  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 3.0940  Validation loss = 2.0302  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 2.9232  Validation loss = 2.7834  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 2.9216  Validation loss = 2.3615  \n",
      "\n",
      "Fold: 30  Epoch: 31  Training loss = 2.8990  Validation loss = 2.9368  \n",
      "\n",
      "Fold: 30  Epoch: 32  Training loss = 2.9650  Validation loss = 2.5224  \n",
      "\n",
      "Fold: 30  Epoch: 33  Training loss = 2.9235  Validation loss = 3.1950  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 19  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.8807  Validation loss = 2.1591  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 3.1557  Validation loss = 3.7342  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.9446  Validation loss = 1.6409  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.9025  Validation loss = 1.4844  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.8140  Validation loss = 1.9798  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.8897  Validation loss = 3.1103  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.8447  Validation loss = 2.6234  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.7839  Validation loss = 2.3400  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.8557  Validation loss = 1.6967  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.8169  Validation loss = 2.0079  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.8422  Validation loss = 1.7862  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.7706  Validation loss = 2.3198  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.8511  Validation loss = 2.8000  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 3.0152  Validation loss = 1.2756  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.8125  Validation loss = 1.6717  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.9835  Validation loss = 3.0890  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 14  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.2442  Validation loss = 2.3608  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.2135  Validation loss = 2.6928  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.3730  Validation loss = 1.6717  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.2482  Validation loss = 3.0061  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.1927  Validation loss = 2.5536  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.2148  Validation loss = 2.4675  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.2017  Validation loss = 2.6394  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.1552  Validation loss = 2.2597  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.1396  Validation loss = 2.3550  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.1702  Validation loss = 3.0472  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.1352  Validation loss = 2.2439  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.2398  Validation loss = 1.5695  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.2617  Validation loss = 1.6609  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.2380  Validation loss = 1.5134  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.3019  Validation loss = 3.7010  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 14  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 10\n",
      "Average validation error: 4.00163\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.8234  Test loss = 3.6112  \n",
      "\n",
      "Epoch: 2  Training loss = 1.7144  Test loss = 3.4056  \n",
      "\n",
      "Epoch: 3  Training loss = 1.6706  Test loss = 3.3103  \n",
      "\n",
      "Epoch: 4  Training loss = 1.6453  Test loss = 3.2602  \n",
      "\n",
      "Epoch: 5  Training loss = 1.6282  Test loss = 3.2305  \n",
      "\n",
      "Epoch: 6  Training loss = 1.6159  Test loss = 3.2109  \n",
      "\n",
      "Epoch: 7  Training loss = 1.6068  Test loss = 3.1967  \n",
      "\n",
      "Epoch: 8  Training loss = 1.5999  Test loss = 3.1858  \n",
      "\n",
      "Epoch: 9  Training loss = 1.5947  Test loss = 3.1770  \n",
      "\n",
      "Epoch: 10  Training loss = 1.5905  Test loss = 3.1696  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmUUfO38AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc5bcf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXlc1NX+/18HhkX2TURQFBQUV1Dct0KtTMtccrmmZrm3\nfltu91b2U+t2q9vNVq9XW8y6mfuSuWWmWSaCG4gCEoqIiCi77MP5/XHmDLN8PrMzA3KejwcPYOYz\nn89hmM95nfd6CKUUAoFAIGh9ODl6AAKBQCBwDEIABAKBoJUiBEAgEAhaKUIABAKBoJUiBEAgEAha\nKUIABAKBoJUiBEAgEAhaKUIABAKBoJUiBEAgEAhaKQpHD8AQQUFBtHPnzo4ehkAgELQYTp06dYtS\n2taUY5u1AHTu3BnJycmOHoZAIBC0GAghOaYeK1xAAoFA0EoRAiAQCAStFCEAAoFA0EoRAiAQCASt\nFCEAAoFA0EoRAiAQCAStFCEAAoFA0EoRAiAQCAxz8iSwb5+jRyFoAoQACAQCw7z6KvDgg8AHHzh6\nJAIbY7UAEEK6EULOanyVEUKe1znmHkJIqcYxb1h7XYFAYCeuXgVcXIAXXwT+9jeAUkePSGAjrG4F\nQSnNABALAIQQZwB5AHZIHHqMUjrB2usJBAI7QimQmwssXQpUVwPvvgsUFgL//S+gaNadZAQmYOv/\n4GgAf1JKTe5FIRAImjG3b7OJv3Nn4LnngHbtgJUrATc3YPVqR49OYCW2jgHMALBR5rkhhJBzhJB9\nhJCeNr6uQCBoCq5dY987dgQIAVasAB5+GPj5Z8eOS2ATbCYAhBBXAA8D2CLx9GkAnSilfQF8AmCn\ngfMsJIQkE0KSCwsLbTU8gUBgCbm57HuHDo2PdewI3LrlmPEIbIotLYBxAE5TSgt0n6CUllFKK1Q/\n7wXgQggJkjoJpXQtpTSeUhrftq1JLa0FAkFTwQWgY8fGx4KCgOJioL7eMWMS2AxbCsBMyLh/CCEh\nhBCi+nmg6rq3bXhtgUDQFFy7xoK97do1PhYUxILDxcWOG5fAJtgkCEwI8QQwFsAijccWAwCldA2A\nqQCWEELqAVQBmEGpyCUTCJo9ublAWBjg7Nz4WJDKeL91CxBWeovGJgJAKb0DIFDnsTUaP38K4FNb\nXEsgENiR3Fxt/z+gLQCCFo1I5HUEmzcDp08zH2p9PVBXx9Lt8vKA69eBGzeAN98EXnjB0SNl/PQT\n0L490KuXo0cisDfXrgEDBmg/Fqha6wkBaPEIAZCioADw8QHatGmac8+axX52c2P+VYUCCAhgpvbg\nwcD+/cAff1h+jVu3AA8P9mUtlAJ/+QswejTw/ffWn0/QcqCUCcDkydqPCwvgrkEIgC6UAv37A088\nwQpebM2337JV/4ULQEyM9DGjRgE3b1p+jZEjgbFjgY8+svwcnPx8dqOLlNzWR2EhUFOj7wISFsBd\ng2gGp0tJCXPFXLpk+3NTCnz5JVvly03+ABAcbLkA1NQA6em2G/+5c+z7bZG01erQLALThFuX4jPR\n4hECoEuOqouFNStwOZKS2Mp/3jzDx1kjADk5TGhsNX4hAK0XqRoATlCQsADuAoQA6MIFoECvns16\nvvqKxRWmTzd8XLt2QFERCw6by+XL7Lutxp+Swr4LAWh9SFUBc4QA3BUIAdDlyhX23dYCUFUFbNwI\nTJkC+PoaPjY4mH23xO/OBeDmTdu07eUWQFUVUFlp/fkELYfcXNYGmn8eNRECcFcgBEAXbgHcvm3b\nUvcdO4DSUuPuH6DxhrPEjcMFoLaWXc8aqquBjIzGKlBhBbQurl1jq38niWlCCMBdgRAAXbgAUGrb\nD/hXX7GWuvfcY/xYWwgAYL0Vc+ECoFQCCQnsdyEANuHdd9/Fxx9/7OhhGEeqCIwjBOCuQAiALjk5\nrO0tYDs3UE4Oa5/7+OPSqyldrBUANzf2s7Xj5+6fe+9l35uJANy6dQtlZWWOHoZFVFZW4s0338S2\nbdscPRTj5OZKB4ABlgpaWmpZnErQbBACoEtOTmOKpq0yab7+mlkUc+eadjx3uVgqAP37W/56TVJS\nWNB60CD2ezMRgEceeQSLFy929DAs4sCBA7hz5w5qa2sdPRTDNDSwdGg5AeDFYM3kMyGwDCEAmty5\nw8zagQPZ77ayAL79lrlROnc27XgfH8DV1fzrl5ezG5JP2LawAHr3bmz41Uxu9tFnziD86FFHD8Mi\ntmzZgjUAXs7Kst9Fn3sOmDnTvNfcvMlW94ZcQIBwA7VwhABocvUq+857n9hCAMrLWVHW6NGmv4YQ\ny2oBuP9/wAB2DmvGTymzAPr0aaz8bAYCUFtTg+crKzE9Px8NDQ2OHo5ZVFdX44fduzEVwIO3b9sv\nq2rnTtbGIzPT9NcYqgEAhAVwlyAEQBMeAO7Tx7IVuBT8puve3bzXWSIA2dnse9eu7Aa1xgV0/Tq7\nufv2Ze+Fl1ezuNlvnTwJfwA9KUUe/3vN5bHH2KrYzhw4cABBd+4gEIA7paZvq7h0KbBwoWUXLS5u\nXNj897+mv06uCpjTkiyA//4XePZZR4+iWSIEQBMuAJ06MT+8LWIA6ensu7kCYMn1uQUQEcFeb42A\n8QKwPn3Y98DAZiEAlceOAQBcARQcOmTZSQ4dAnbtst2gTGTr1q0Y5eXV+MAPP5j2wkOHgCNHLLso\n/z+GhgLr17N6DlMwVAQGtCwB2LaNiUBzj7s4ACEAmuTksM6coaHWT6Cc9HS2mUaXLua9zlIXkJcX\nm6yDg60bP88AamYCQJOT1T9X/fab+Se4c4e9Lzk5dp28ampqsHv3bkyLiEC9kxMOursDe/YYL9ZT\nKllx4tWrLDBrLvz/+K9/seryLVJbdkuQm8uyyeQ2fGlJDeFyc9nkn5bm6JE0O4QAaJKTw1Y8zs7W\nT6Cc9HQgMrIxNdNU+PXNqea9fJmt/gmx3oI5d45ZQn5+7PdmIgBtLlzAKQBFAFxTU80/gWadxKlT\nthqWUX766SeUlZVhoLMzrgcEYLeLC+u0evq04Rfm5bFgbE2NZZXhZ8+ySXzmTKBbN2DNGuOvARqL\nwHhKtC5uboC3d/MXAEobrRk7/r9bCkIANMnJYZMeYFsXkLnuH4AJQE0NCyKbyuXLTGwA27iA+Oof\naB4CQCkCcnJwGsDFNm0QxH3b5qAZN9CwJpqaLVu2wM/XF4FXriC3XTvsI4RNrsbcQJrjteTvPXeO\nxXEIARYvZvtMcKvAEIaKwDgtoRisuJhZfYBxsW2FCAHQREoArOmno1SyILClAgCYLkKUNloAABt/\nRYVlmSa8BUTfvo2PBQU5XgAuX4ZHdTUyvL2RHxqK8NJSJpLmwCfUoCC7rQhra2uxa9cuLBg9GqSk\nBNdDQ3Gjvh4YMqRpBaC+nrk9+P9xzhzA3V3fCpDq82SoCIwTGNj8BYCv/p2chAUggRAATl0dy3zh\nufrBweyx4mLLz3nlCvM9WiIA5haDFRaym5gLgDXVxLwFhK4FUFLCHncUqhs4v317VHTrBhdKQc11\nA2VnM9fFmDF2swAOHTqE0tJSzOjaFQBwo0MH1NXVAQ89xFaleXmGx8sxVwAyMphAxsay3wMCgBkz\nWF1KeTn7f775JlvpDxrUKKZKJbsXjAlAS7AAuAAMG8YsH1G5rIUQAM61ayzIpmkBANa5gSzNAALM\nn8A1M4CAxvFb4gbiLgJNCyAwkFkZ1giitZw+jTpCUN65M5xVxXplv/xi3jmys5mbLD6eTQ5Nse+D\nDlu3boWvry/61NcDrq4oCQtDXV0d6IQJ7IAffzQ83s6dWXDfXAGQ+j8uXswsw2nT2HnfeAPo2RM4\nf54FigH2mamvN80F5Gir0Bj8PXvkESZwFy44djzNDJsJACHkCiEklRBylhCit7QijI8JIVmEkBRC\nSD9bXdsmaKaAAtZNoBwuAN26mf9aLgCmXt/WAuDhoZ251ByKwU6dQrpCgbYdOiB40CAUAag0NxMo\nO5u9R7xdRhO7BSoqKrBlyxZMnjwZijNngL594eTuDgCoi4piYzHkBsrOZv+H8HDzBeDsWVbDobkA\nGTiQ/e3797PixNOngV9/ZYLw1lvMZWmsCIzTUiwAFxfgwQfZ7yIOoIWtLYB7KaWxlNJ4iefGAYhS\nfS0E8B8bX9s6dAXA3AlYivR0loHBJ09z4Ol35loAmi4sc16vSUoK0KsXy4biOFoAKAU9dQqJ9fVo\n3749ukZF4TQAF57nbuI51IHyfqr1RxMLwKZNm1BRUYH5TzzBrhUfD1dXVwBALXcDHTokH6vhFosl\nAnDuHNCjB5sAOTzwnJnJ8uPj4tjjH37I4gNLlpgnAOXl5sdh7EluLhAWBkRHM9efiANoYU8X0EQA\nGyjjBAA/Qkh7O17fMHwjGP6ht5ULyBL3D8BWbv7+5glA27bMVQBYLmB37gCJiY3tMDiOzvvOyQEp\nKkIypWjfvj06deqEM4TAj+d4m8KNGyzAHRnJ+i1FRzd5HGDdunXo0aMHhgQHA2VlQP/+agGoq6sD\nJkxgY5KqCi4vZ7EdLgB8kWIqPANIl/btgago/cfeeQc4fBh4/332mCkuIKB5u4GuXmX3tJMTEzsh\nAFrYUgAogIOEkFOEEKm69TAAuRq/X1M91jzIyWE3Ac/XDwxkHxprLQBLBQAwrxhMMwMIYKs5X1/z\nx797N1uNPvqo9uOOtgBUN+4pAO3bt4dCoUBucDAUSiXzX5sCD6jyVNn4eJtMCN999x2+/fZbvcdT\nU1ORmJiIBQsWgPDraFoAtbXAqFFsZSrlBuJWHReAwkLTK3kLCtgXDwCbwsKFLDMpMZF9foxZri2h\nGjg3l713AHN9nTtn242eWji2FIDhlNJ+YK6epwghIy05CSFkISEkmRCSXGhJ4YulaKaAAsz9ERRk\nuQDcusW+rBUAU6/Pfdu6rzfXgtm4kZnMI0ZoP94MBKDB2RmpYAIAABXR0ernTEJXAPr3Z8F/Kwv+\n3nrrLcybNw+pOhlJ69atg6urK2bPns0sDXd3oEcPuKhcMrW1tczSS0gApLqb6goA0OieMYZUANgY\nTk6sZYJCwVbNckVgnOYuALotrfv3ZwJ68aJjx9WMsJkAUErzVN9vAtgBYKDOIXkANJ2KHVSP6Z5n\nLaU0nlIa31auDL0p0BUAwLpisIwM9t0eFoBSyUxdXQEwtxisqIgFB6dP19+4xtubTQwOFIDi0FDU\noFEAPPv0QSm020MYJDubTWr8/xwfrz63pSiVSvz555+or6/HE088gXrV6rKqqgrffPMNpkyZgsDA\nQHaNvn0BFxdtFxDAUjAzM/UzrDQFiwuAqXGAs2fZd3MEAGDtv1evNq1ZXnMXgIIClvapKQCACARr\nYBMBIIR4EkK8+c8A7gOga5fvBjBHlQ00GEAppTTfFte3moYGtrKSEgBLV4fWpIBqXt8UAbh2jZm1\n1grA9u3shpHqHU+I46qBKQVOncJVVVwjJCQEANA1KgqnANSfPGnaebKzmXWjysJBXBz7u6yIA+Tl\n5aG2thZjx45FcnIyVq1aBQDYtm0bSkpKsGDBAvb5UgWAAWi7gIDG/SeSkvTH6+vLYkH8s2mqAJw7\nx3z4AQHm/1ELFgBPPWX8OEfHhYzB3ysunlFRgKeniANoYCsLoB2A3wgh5wCcBPAjpXQ/IWQxIYRv\n3bQXQDaALADrACy10bWt58YNFkjUFQBr+gGlp7N4gu45zSE42LTN6XVTQDVfb44Fs3EjayXNV0q6\nOEoArl4Fbt9Ghqcn/P394a6awLt27YpTAJzT0kwLBPOMGo63N0vRNTIhPPHEE3jttdckn8tSbezy\nyiuvYOLEiXjjjTeQmZmJdevWoUuXLhg1ahRb3VdUyAtAfDwTosRE6fESwoSLEPMEwNzVvwT19fVY\nvHgxXnjhBf0nm7sA6GYzOTuLQLAONhEASmk2pbSv6qsnpfQfqsfXUErXqH6mlNKnKKVdKKW9KaX2\na8RiDN0UUI61FkB0tHYqpbnwTB5jN5icALRrxyZsU6of8/OBX35hq38536+jBEB1w54mRO3+ARoF\nwKmuzrROj7oCADCxM2ABJCUl4auvvsL27dsln+cCEBUVhdWrV8PNzQ1TpkzBr7/+ivnz58NJswWB\nSgC0YgAAW+V37w7oWjKa43VxYV1qTRGA6mr2+TMnACxBbW0tpk2bhv/+97+SQW64uLCxN9csIKl0\n1v79mXvMkRXtzQhRCQwYFoDKysZmUuZgbQYQYHoq5+XLzGfPTV0OT2U1JZi+eTNztRjaOtCRAqBQ\nILGqSksAOnfujDNcrIyt6qqqWHsDXQGIj2eP50t7I99++20AwKVLlyT38c3KyoKbmxs6dOiA0NBQ\nfPDBBzh//jwUCgUef/xxdlByMttbWfV50IsBACwOcPJkY++phgbt5n6AfC1AcbH2Z4S38rDCAqiq\nqsKkSZOwY8cODB48GIWFhbgpZU0252Kwq1eZy8ffv/Gx/v3ZPc1jdK0cIQCAYQEAzLcCamrY6s1W\nAmDMjXP5MvP3qiYWs18PMPdP375ATIz8MU0kANu2bcMx1UYvAIB33wXGjWM58o88AmzYAPTsiZyC\nAi0BcHNzQ114OCpdXIwLAK/zkLIAAMnXp6amYufOnYiJiYFSqVSv9jXJyspCZGQkW+kDmDdvHqZN\nm4YFCxYgxNkZePVV4PPPWV2FQgFAwgUEsDjAzZuNn8X8fPY50hUAqVqA6dPZKnfBAva5szQArKKi\nogITJkzAvn37sHbtWqxYsQIAkCZlZTVnAeAN7TQtWntUgNfWMpdfC0AIAMBuKn9/5hPWxNJiqqws\ntoKzVgBMLUbTrQHQfb2x8WdnM/+zsY3DuQBY0yFVB0oplixZgpUrV7IHNmwA/vY3tnq7cYNN3L6+\noE88gfz8fC0BAIAuUVFIa9NGP4Cqi24KKIcHgiUmhLfffhteXl746KOPAAAXJdIH//zzT3RVNXkD\nAEIINn38MVa7u7MFxTvvsDYEX36pPkbPBQQwCwBodANJjTc8nE1qmhvDVFWxFNIuXYBvvmFuxxUr\n9Ft5mMHixYtx5MgRbNiwAQsWLECvXr0AtGAB0KRbN/beNKUAvPACK8p89VWgtNT81584wfpD2cFN\nJQQAkE4BBSyvBrZFBhBg2gq+pob5vzUmITWmCsD337PvM2YAAFJSUnCN7wmrSWAgW91Y4hKTIT8/\nH4WFhbh06RIzy5cuBUaOZEHM5GS2mj1/HsWPPYba2lp9AejSBb/X1rLjq6vlLyQnAF5e7P+kEwfI\nzMzE5s2bsXTpUgwdOhSAvgBQSpGVlYUumhMtpWzC//hjVkx34QKwaZPWZCxpAfTuzZIGeCBYTgB0\nN4ZJTGT/k3/9i73m2WfZ84MHWxR/qqiowLZt27BkyRI89thjAFjarZ+fn+UCsGOHefsR//ADs5qs\n5epVfbeoszOLjZiT+bV/P2uVYQoNDWzXNV9f4J//ZP/3jz82bzvK998H5s83XodhA4QAAEwAeA8d\nTSx1AXEB4IVKluLrywJthgRg2zbW1lc1eWthqgvo+++BoUPVIvjggw9KZ72YWgw2fTqrKjXBUjhz\n5gwbYk4OGh59lKVofved2l3CyVf56HUFoGvXrjhSXc0ypVTnkiQ7m638+HuiSd++jXvnqnjnnXfg\n6uqKF154AZ6enujUqZOeANy4cQOVlZVaFgD++IPlmX/6KfD115KLAMkYgIsL60+kaQHoxnWkUkGP\nHmUTxfDhLEj8wQes+EkmaG2MvXv3orq6GtOmTVM/RghBz549cV6q4tqYANTVMVF/5hlm0ZnCsmVs\n9WwNtbXsvpXqZ5SQwP5P3C1ojJUrgZdfNm01n5zM7rd//7ux9uO551j7cVOorAT27QMmTdKvxWkC\nhAAA8ptf8EI0MwXg2qFDqGvfvrEvj6UQYjwVdc0atvpPSNB/ztubTaiGXp+ZCaSmskkbbFLLy8tD\ngdRrTBWAI0eAdevYTWCEsyp/9fsAnFJTmQsoTL9DiCEBUOfO6KZRaqKZUqlLnz5sUlXd4Dk5Ofjm\nm2+wYMECtFMtAmJiYnBBp5UwjwloCcDq1azPkGr1LIWkBQAwN9CpU2zSzM5mn0nNuI5UMdiRI2xF\ny7fuBJg709dX9vqG2Lp1K9q1a4dhw4ZpPd6rVy+kpaWB6op6UBCbtOSa2e3ezSb+ujrTrIDCQmbN\nFRZatgUmJy+PLUCk7uuFC9nnYPVq4+cpLWWiXF8P/PST8eP37GET9wMPMEE/dIjtuXDsmGmB5wMH\n2Hs5ebLxY22AEIDqataki6/2NXFzYzeWGS6g4sJC3D5yBOcMuSPMwVAxWFoa+2AtXCi9WuB7AxsS\ngG3b2HfVB46vyIuKivSPNUUAlEq2ImzTBnjlFeDgQfljAVxMSsJiQrAUwKVHHmls26uDIQHIB1AZ\nEKCfRqmJVAooh298o2rl8P7774MQgpdffll9SExMDDIyMtCg4X/XE4DCQmb+z5ljUPwlYwAACwRX\nVbH/q9R4dQWgpob5i0eNkr2WOVRWVuLHH3/E5MmT4azjPurZsyeKi4txQ3cVb+wzsWYNG/f99wP/\n+Y9xV4jm/g7WbOLOU0B1XUAAE4XJk9kixZg78+jRRl+8oX0bOHv2MGuavy+EsM8DAOzaZfz127ez\n4j0b/U+NIQSAm69ybSdMrQX480/gtdfgFh2NvgB2FxcjMzPToiFNnz4da/i2fYaKudauZStEnm4o\nhbFisG3b2MpT1fmRr8gtFoCiIuYHXbaMbTQyYwZ7bzhVVeyaTz0F9OuH9bt24T+U4jiAXbwiVgI5\nAYhUTZI5ISHyFgClWhPqlStXcEvTbcEFQOUGOnbsGMaMGYOOGqvHmJgYVFVVIUcjCycrKwsKhQKd\nuGvmq6/YBLdkiezfAci4gIDGQHBiorQA+Plpbwxz8iRbwNhosti/fz8qKysxdepUved69uwJAPpu\nIEPtIC5dYivghQuB//s/dh9t2WJ4ED//3Gj1WCMA/D2Sa2n97LPMdfq//xk+z6FDbDEzaRKwd692\nAF6XvDzmhhw/Xvvx8HCWbGBMAGprWfzj4Ye1W3g3IUIAuJkpJwCmVAPPm8fcMO+8gzRXV8z19cV7\nzs5Yt26d2cNJS0vD5s2bsWrVKmZuy03glZXMxzx1qvzYAcMCduUKczlMmaJ+yGoLgI81MhLYuZP9\n/MgjzLR98kkgJISNecMG1Pv44J8Avp8zBzOCgpChuf2hDvn5+fD09IS3TqaWh4cHwsLCkNKmDZs0\npdwGN28ClZW44eGBmTNnIjIyEkuXahSid+jAJleVAJSWlkK3D1WPHj0AaAeCs7Ky0LlzZygUCjYx\nrFnDJmPVsXLIuoAiIth7fOQIc5voCgAh2rUAvIGcbuM+C9m6dSsCAwMxcqR+H0fZTCBDLaHXrmWx\nnCeeAMaOZRk4H31kODb088/MfeLjY7oAUKp/TmN7Ggwbxibljz82Pp6RI5nFcPOm4eyhvXvZd77T\nmyYTJ7K4g6G55PBh5nLSuB+bGiEAxgTAWD+ezExg/Xrg8cdRlpqK4SUlCHrySYyfOBHr169Hjc5m\nGUqlEnPnzsU333wjebpNmzapTpvJbjYuALof0k2b2Idl0SLDf58hAeCBQo0PHLcASkpKoNRNQ+N9\nZUwRgOBgNoFt2sQyYR54gK3+Jk1ivtTiYhxfuRJvAPCZPh0do6NZJpAMUimgnB49euBQWRn7RSId\n9PrvvwMA5r/9Nn744QcEBgYiT3MfXkJYFo7KBVRSUgI/TZ86mAUA6AuAOgPowAGWjqspLDLICgAh\nzA3EW0NLuaw0awGOHmXjtmTDIR2qq6vxww8/YNKkSUzQdAgODkZQUJC8AOhaANXVzCJ65BHWZt3J\nia26k5LkLbUrV5i1OHo0sx7lBKCqir3fK1awepHAQDaha94jubnscQ8P6XMQwsaTlqbtdtLk+nX2\n2R0zhn1+CTHsBtqzhwXqVdaSFhMnsvHt2SP/+u3bmYVnasDYBggBMEUATPGhr1yJH86cQW1tLaZO\nnYpFixbh1q1bei0E1qxZgw0bNuD111/Xm2Appdi0aRP69OkDQgi2bdvGJtKqKv3CkjVrWNGWsdVf\ncDD7G6VM161bWQBRNdGUl5fj0qVLCAoKAqUUpbpZDy4ubGVmKOuDv1c822bsWBYI3LSJrWrXr2cf\ncIVCLTaxsbGIiooy6DIzJAD9+/fH1suXQZ2cJCeX1S+9BAC498kncfnyZYwaNQolJSXaB/XpA6Sm\noqG+HmVlZfDVCaIGBAQgODhYHQimlGrXAKxezT4rjzwi/96okI0BAMwNxP3ScgJw9SoLqh4/bjP3\nz8GDB1FRUSHp/uFIZgLJCcC2bWyhoLlAmTOHBac//lj6AnxTHE0BkFqdL1rEJuQVK5jbJT6era41\nJ3K+EYwhZsxg4zc2njFj2HGDB8sLQHU1cxeNHy+daNC3LxMHbhXrolSy58aPb2xWaAeEAJjiAiou\nlg9ebdvGVm0dO2Lr1q0ICwvDoEGDMGbMGERGRuK/GpkP165dw9///neEhYXh6tWr2MtNRhUpKSnI\nzMzE0qVLMWzYMCYAUrUIZ84w/+/ixcZzhdu1YxkMuq2G8/LYTaOx+k9RuUASVBlFkm4gYxuB83Fq\nBtXHj2d7zuqsxs6cOYPg4GC0b98e0dHRyM/PR4VMBaUhAYiPj0dJfT2qIiP1BKC8vBxE1SvpxU8+\nQdu2beHn5yctAOXluHPhAhoaGvQsAIBZAdwCuH37NkpLS5kAXLnCJob58/WrsSWQjQEAjZ1BAWkB\n6NQJKCyE8sgR5ga85x6j1zOFrVu3wt/fX/2/l6JXr164cOGCdiaQvz/7DOoKgFR2mpcXcwNu2cJW\n17r8/DNzEfbowQTg9m1965tSdtxDDzELOCWFLTDatgVUnVgByGf2aeLuzsRk9+7GflqaHDrEPu88\nRjR+PEvzlEpn5f8PKfcPwN6jhx9m55QKPP/2G5uL7Oj+AYQAsDfd2Vk7jU4TQ/10uA996lSUl5dj\n3759mDJlCpycnODk5IQFCxbg6NGjSE9PB6UUTz31FOrr63H48GGEhoZitU4a2qZNm+Ds7IwpU6Zg\nypQpSE0wjOHgAAAgAElEQVRNRR6fJDRvhDVr2Id39mzjf59cLcOOHey7hP/foAAYawdx8yaokxN+\nNpSTr+Ls2bOIjY0FIQRRqi0KpdotAMYtAADIaddOu58OWDO3CADVAQEsmAfICwCAalUmka4FADQK\nAC8AA1QZQGvXsht8odRGePoYtAC4AHh5Sbt2VFktO/n/TcJfby41NTXYvXs3Jk6cqB6bFD179kRZ\nWZl2kaBCwURAUwDOn2cT2qJF+tlpTz3FVrv/0dkSnFLmAx89mr2X3I2ik3qLnBwmHvff31i5z/cy\n3rOHBZ4B7Z3ADLF4MRvjZ5/pj+fQISZg/G/gwd39+/XPs2cPW+Dce6/8tR55hFkKUplx27ezv2Pc\nOONjtiFCAAoLmcrLFV0YKgbj7p8pU7B3717U1NRomdDz5s2DQqHA2rVrsW3bNuzevRsrV65EdHQ0\nFixYgAMHDiBbFfjk7p/Ro0cjKCgIk1VpmQd5XxcuAJ9+ytLXHntMu8mVHHLFYNu2MReSRu+fs2fP\nIigoCL179wZguQAUAhhz3314/vnn9WIgnNraWqSlpSFOtSk5FwCpOEBFRQUqKioQGhoqea5OnToh\nMDCQ1QMUF7NWHCpOnDiB7gAUGnvg+vn5obKyUnsFrppwlKqdtKQsgB49eqCkpAQFBQXaArBzJ3N1\nmTLhAHB2doaTk5O0AAQGsupRmZqFGtVeCGPLy3HJ1RX5Ntje8Oeff0ZpaalB9w/QGAiWdAPdusUm\n9v372WQsl50WGcn84R99pF3PkJbG7rHRo9nvXAB04wCqeA506hTU1/z4Y+YuLS42bgEALAHg0UeZ\nIGm6INPTmdBo+uP79mXFdrpuIErZY6NHG3bfjBjBFpq62UCUMgG4/37ra4fMRAhAYaHhLBpD/YC2\nbVP70Ldu3YqQkBB12wAAaNeuHR555BF8/fXXeOaZZxAXF4fnn38eALBgwQI4OTmpXUSnTp1CdnY2\npqsKssLDwzFgwABs/fVXdrIbN1g14jPPMPNX1Z/GKFICVlgI/PqrnrnJV+SBqpWnJQJQnZuLGw0N\n6NWrFz766CMMGTJE0rd/4cIF1NXVIVbVspj70qWOlUsB5RBC0L9/f/zIV6EabqCKPXswFIDioYfU\nj/HJXSvG4e0NREayvQUgbwEALBCclZUFQggigoLYZKE7IRnB1dVVWgAA4B//kK2EPaP6G30AHGlo\nwOjRo6W7dJrB9u3b4ePjgzFGgo88FVQvEBwYyALS4eFsBXvhAisC5PEBXVatYpPek082Wmua/n+A\nBY79/KQFwNubBb81CQlhvay++kodzDdJAADWesHNjVnUXFAPHWLfNd8TQlidysGD2i3WL1xg3gA5\n9w/HxYVZEXv2aO/xkZTENnVSLfrKysrw22+/mTZ2KxECYEwA5PoBafjQ79y5g71790oW0CxatAhF\nRUW4efMm1q1bp86wCAsLw8SJE/HFF1+guroamzZtgouLCyZNmqR+7ZQpU/ATb1Hw+uvsg7p0KVst\nyGU3yIz/kuYHaudOFhTWEIC6ujqkpqYiLi4OAapsH4sE4OpV3ATw0UcfYdeuXcjJyUG/fv2we/du\nreO4u4lbAF5eXggNDZW0AK6r/MVyAgCwOMCurCxQT091QRitq8OspCTc8vRkDbpUcAGQcgO1UQmQ\nXAwAYOKVlZWF8PBwuF24wCYxvr2kibi6ukrHAABWla1aCOiyPzUVPJw//LXXcOXKFYwZM0a7rsFM\nTp48ieHDh8PNzc3gcQEBAQgJCdEXgKgodh/FxbHEguvXgaeflj9R587ss3zoUGN18KFDLGbArShC\nWCxASgDk+hw99xzzry9fzn430SJDWBhzq548yfr38PFERuo3WRw/nhWO8vuppKRxMaab/y/FxIns\n/uGWzB9/sM+mQgE6YQK+/fZbdOvWDRMnTkSlXHW1LaGUNtuv/v370yYnOprSadPkny8vZ1nG776r\n/fgnn7DHL16kW7dupQDo4cOH9V6uVCrpyJEj6fLly/WeO3ToEAVAN2zYQMPDw+n48eO1nr906RIF\nQKvatGkcQ0ODWX+esq6O1gF0a1AQpXv3Uvrvf1MaE0Nply5a50pJSaEA6P/+9z9aV1dHAdAVK1bo\nn3DFCjaW2lrJ6xUHBtL/AfTmzZuUUkpzc3NpXFwcDQoKoiUlJerjnn32Werh4UHr6+vVj40aNYoO\nHTpU75wbN26kAOj58+dl/87t27dTALQ0Lo7SgQMppZQWvvkmpQDdP3++1rE//PADBUCTkpK0T/LG\nG1RJCG0D0EuXLuldo6GhgXp7e9OnnnqKDho0iCYkJLD3E6C0oEB2bFIEBQXRpUuXmvUaSikdPnw4\nveHiwq6Zn08PHTpE3d3d6aRJk8w+F6WU1tfXUzc3N/rSSy+ZdPyYMWNofHy89oOVlZTeumXehRsa\nKB0zhlJPT0ozMyn19qZ00SLtYxYsoDQgoPFzWlJCKSGUStxLakaN4lUBlF65Yt6YZs2i1NmZ0j/+\nYONZuFD/mPJySl1dKZ06ldJ58yjl96ahOUSTsjL2+vHjKb3nHvbawEB69fXX6fDhwykAOmDAAHry\n5Enzxq4BgGRq4hzr8Ene0JddBMDfn9KnnpJ/vqGBVikUNNHHh44fPZpOnz6dLl68mP4ZHk4L27Wj\n69atowkJCbRt27a0rq7OrEs3NDTQ6OhoGhISohYCXfr06UM/jIigdPt2c/8ySimlWVlZ9FpjqQz7\natuW0jVrtI77+uuvKQB64cIFSimlPj4+9LnnntM/4aefUgrQfevXS16v0sWFrvXw0Hrs9OnTlBBC\n//rXv6ofGzFiBB0yZIjWcfPnz6dBQUF65/zggw8oAHr79m3ZvzMnJ4cCoKfHjGE3WH4+rfbyor8A\n9PSpU1rH/vrrrxQA/emnn7RPsnUrpQDtryFgugwcOJAmJCTQwMBAunDhQkpnzqQ0PFx2XHK0b9+e\nztcRJmNUVFRQFxcXmh0WxhYuKubMmUPDwsLMHgOljYuML774wqTjn3vuOerh4UGVSqVF19MiJ4dN\ntJ07s8/l5s3az3/4oVroKKWU7t/Pftf9v2mycyc7hhDZRYosxcWUdujAREdqPJyxY9nzXl5MJJKT\nzbvOuHHs9WFhlK5aRf+3di11cnKigYGBdN26dVa/t0IATKW2lr0FBlYUN2/epM+oJs7T3t40PjKS\ndg8IoPUAXQFQqL4sWc1RSumqVasoAOrm5kZLS0v1nl+xYgUlhNDr169bdP7t27fTsQBdCNBvFi6k\ntLBQ8rj/+7//o23atFGvyDt37kxnz56tf+DGjZQCdGbfvvrPVVZSCtAvu3bVe+rxxx+nrq6uNDs7\nmyqVSurt7U2XLFmidcx7771HAdDi4mKtx19++WXq5uZGGwxYPw0NDbRt27b0s4QE9j8dPpwqCaED\n3dz0hJlbO1u2bNE+SUYGpQB9HKA1NTWS13n88cepj48PBUDfe+89SqOiKJ08WXZccnTq1InOnTvX\nrNccOHCAAqDHP/mE0sRE9eMrV66kAOidO3fMHsfu3bvZOY8fN+n4tWvXUgA0Ozvb7GtJ8vnnjRO2\n7mfzp5/Yc4cOsd+XLaPUyYmtouWor6c0MpLS0FDLxvPzz/Lj4Vy4QOnXXxsehyEyM9l9VF1NKWWL\nit69extc4JiDOQLQumMA3JdtIAaQmJiITwBcfOMNxNXUIMnVFRcXL4YzgBePH0dOTg5SUlLwbxM6\nX0oxd+5ctGnTBuPGjYOPj4/e81OmTAGlFDt42qaZpKSk4BAhSOzbFx8kJckG5s6cOYPevXurYxgB\nAQGSMQClyjd+Iy0N1ToN7+pVvnpPiY1I3nrrLSgUCvztb3/D5cuXUV5ervb/c+QygfLz8xESEgJi\noOaBB4J38vzy337DzrZt4T5okF5lq2wMoEsX1CoU6OfsrM7V1yUmJgZlqqrjmPbtWdqhmf5/wEgQ\nWIbDhw9DoVCg9+OPa9UL8Pct20ArDTl4XUOMoZ3gNJDNBLKUJ55gfvGRI/U/m7qZQL//zjJxdDdu\n0sTZmRUbmtq/X5eEBNb++bHH5IPYMTGsqM3QOAwRFcWK0NzccPv2bSQlJWHKlCnq2Js9sVoACCEd\nCSG/EEIuEELSCCHPSRxzDyGklBByVvX1hrXXtQnGisDABMDZ2Rnhf/0ri/7fuAG8/TbQtSs8Bw9G\neHg4evfuDXcLq/f8/f1x9OhRfKabh6yiR48eiIyMxM88S8JMUlJS0LVrV8ydOxdnzpyRDLJSSnH2\n7FmtCVlOAEpVk6lPfT1O6fRFyVX93laiF05YWBhefvllbN68WV3/EKuzaTmfyHQzgQzVAGgSHx+P\nw5mZoCEhoH5+eLq4GIN4gzUNZAXA2Rl5/v6INbCRiuZE2aOqil/Y6Nh0sUQAfvnlFwwcOBBeOqmC\nPINKrobCEBcvXkRISIhk0FsK3hNJcnMYSyCEJTUcPqz/XEgIS3VOS2NZM4mJpmVbjRjBUjstZdky\n1pbcDvz888+glOK+++6zy/V0sYUFUA/gRUppDwCDATxFCJHqhnWMUhqr+lppg+tajwkCcOLECfTp\n0weenp6s7P7334FevVhBi4127BkwYIBsjjshBAMGDNCbbE0lNTUVffr0Ued4b5HoxpiTk4OSkhKt\nCVlOAApU6WuBAI4fP6713LXTpwEAYTore87LL7+M9u3b44MPPoCzs7N6Ncnp0qULCCFaIlVVVYWU\nlBR0ltqwR4f+/ftD2dCAzOefR/qKFcivq8PgwYP1jvPy8oKTk5O+AADI9vJCT6VStkGYpgB04BWh\nfJ9ZM3BxcTFLAEpLS5GcnCxZqcv7ERnqpSTHxYsXTV79Ayw9tkOHDrYTAAB3qqpQwns5acILwtLS\n2B4Bd+6YJAC3bt3CFVM3e3EwBw4cgJ+fHwYMGOCQ61stAJTSfErpadXP5QAuAtDf0cORnD/P0rV0\nMSIASqUSiYmJ2pNIjx4sz1iVz28P+vfvj5ycHNw2c0P2O3fuICsrC3369EHHjh0xdOhQbN68We84\n3pPHFAsgXzVpSQlAoWpS6CTzYfb09MQ//vEPAED37t3RRlWZy3F3d0d4eLjWRPb555+jsLAQixcv\nNvbnIl61Ev/J0xMHVRO4lAAQQqSrgQFkuroiQKmU7f8UEREBNzc3tG/fHq4pKSxV0ALT3WAaqATH\njh1DQ0MD7pWoNPX390dgYKDZFgCl1GwBAIA+ffrg+PHjWnsjWMOMGTMwfPhwFpTUhQuAXAGYBE8+\n+SSGDBlitoVlbyilOHjwIEaPHi3ZgM8e2DQGQAjpDCAOgFS7vyGEkHOEkH2EEIl2eU3E3r2sWOvt\nt/Wf4wIg4+tLT09HeXm5pBvBnvBWB+ZaAXwHpz6qNgfTpk3DuXPn9FwsZ86cgZOTk7oCGGgUAN2b\nMq+kBDUA+oSG4vjx41rPl6n6/rsZKMCZM2cORo4ciQkyRTNRUVFqAaipqcG7776LESNGYJQJTc/C\nwsLQrl07nDp1CidOnECHDh1kLSs5AUjlVp3mFpHnz7O6D7Aq3h49eqBbt26sL4wF7h/AfBfQL7/8\nAldXVwwZMkTy+aioKLMF4Pr16ygrKzNbAGbNmoXs7GwcNLLZjylkZWVhz549SEtLQ7LUPr09e7LF\n29atrLDLSHFXeXk5Dhw4gBs3bug1YmxupKen49q1a7j//vsdNgabCQAhxAvANgDPU0p17bnTADpR\nSvsC+ASATEs8gBCykBCSTAhJLrRmSziAVdg9+igrUZfajo2fX6adbqKqolRqFWlP+vXrB8B8AeDN\n3fjEPkVV+KXrBjp79iy6desGD43isoCAACiVSpSXl2sdW3DzJm4D6NOhA27evKkVeKzPy0O1szPg\n6Sk7JmdnZxw9ehTvvPOO5PO8KyilFOvXr0deXh6WLVtm0t/LA8HJyck4ceKEwf+bnACc5qvy48fZ\nxuQDBrCq0wceUHdU3bBhA9a+/Tar/rSTABw+fBhDhw7Vs5o4Xbt2NdsFxAPAPYzsX6DL1KlTERIS\ngk8++cSs10mxZs0aKBQKuLq64n9Sm7PwQPCxYyat/g8cOICamhp4eHjo9dpqbhw4cAAAMHbsWIeN\nwSYCQAhxAZv8/0cp1ZNdSmkZpbRC9fNeAC6EEMllN6V0LaU0nlIar7sph1n8+SerzAsOBoYMYZuF\n6FJYyMx3GfPrxIkT8Pf3VwcnHYWfnx+6dOkivUIyQGpqKjw9PRGhqmbs0KEDhg0bpnYDVVdXY9my\nZdi7d6+elSNXDXzjxg3kE4IIVaD0d5VpXlZWBreyMlRLZDKZQ3R0NEpLS5Gfn4933nkHAwcONNqi\nQJP4+HikpaXhypUrRgVAr901gCsVFSjx8GCthhcsYK24H3+cWQGqHjC9evVCFPdZWygA5sQAioqK\ncO7cOUn3D6dr167Izc1FFQ9Mm4C5GUAcV1dXLFq0CPv27bMo8MyprKzEl19+icmTJ2PChAn4/vvv\nUa/b20izt74JArBr1y4EBARg2bJlOHbsmE2ylfbu3Yt/8gphC8jJyZFs7XDw4EFER0ebFN9qKmyR\nBUQAfAHgIqX0A5ljQlTHgRAyUHVd8xza5lBY2Lhi27+freIuX9YP7N26ZTQAPHDgQDjJNYqzI/Hx\n8RZZAL1799Ya/7Rp05CSkoK1a9eiT58+eOuttzBz5ky8//77Wq81JAC5Hh7wunYNPj4+6jjA+fPn\nEQyAWiPaaMwEWr58Oa5cuYJly5YZTP/UpX///mq3lCHXnZwFUFJSgt8GDWK7vP3+O4v3rFvH2hf8\n85+NnyEuxirrzFzMiQEcPXoUlFKDrZr5+3ZZqq2xDBcvXoSvry9CVA3mzGHRokVwdnaWzV4zhU2b\nNqG4uBhLly7FrFmzUFBQgMO62UDBwY0xFiMCUFdXhz179uChhx7C/Pnz4ebmhv/odh21gPXr1+PV\nV1+1KMgOAK+//joSEhKQynsUgbk3jxw54lD3D2AbC2AYgNkAEjTSPB8khCwmhPDI3VQA5wkh5wB8\nDGAGlYz42IA7d1hTpmvX2M5K3bqxfh537uj3LDfQB6i8vBznz593uPuHY24gmFKqFgBNpkyZAkII\nFi1ahIaGBvz000/YsGGDugEcR04ACgoKcDMgACQ3F/cMGKAWgJSUFLQD4GZq/xUZ+ES2bt06xMXF\nYbwp/VU04IFghUKhdp1J4evrqycA1dXVqKmpQerYscCXX7LNvQlhFuJLL7G+LceOsYOTk4HoaLbB\niQWY4wI6fPgwPDw8MNDAnsmWpILyALA5Astp3749Hn30UXz55ZdaezjU19dj4cKF2ltuyrB69Wr0\n7NkTI0eOxIMPPghfX199NxDPBPLyUjeAy83N1ZpMOceOHUNJSQkmTpyIoKAgTJs2Dd98842eG9Nc\n+D2g3qfbTHjjwyeffFJt4fz222+oqqpyWPonxxZZQL9RSgmltI9GmudeSukaSuka1TGfUkp7Ukr7\nUkoHU0qPGzuvxTg7s9Xa998z1w/Q2NBJtTrau3cvkpKSDApAcnIyKKXNSgAA0+MA169fR1FRkToA\nzAkLC8Nrr72GN954A6mpqbLuFUMWQKlqxfhgVBTOnz+P0tJSJgCEoI2VAhAREaEuRnv99dfNnpxC\nQ0MREhKCvn37asU0dJGyALhLSKoTKJ54gn1WeOzCigAwYJ4L6Ny5c+jXr59scRrQKADmrFItyQDS\n5JlnnkFZWZl6e1O+3em6devw+eefG2xmlpSUhOTkZCxduhSEELi7u2Pq1KnYvn27/utefhl47z21\nq/aFF17AsGHDUKCTqbVz5064u7urJ9WlS5eivLxcOrZgBvwe+PLLL81u0EYpRUZGBqKjo5GUlISP\nVI3jDh48CBcXF9xjow19LMXxvg1b4+7Oth+cOLHxMQ0ByMrKwoQJEzBw4ECUXLqE2zLunRMnTgCA\nwVWXPTE3EMxXSLoCAABvvvkmVqxYIRtQBAwLQI3KZzk0IACUUiQmJuJ8SgraAiCaO4FZgIuLC6Ki\notCzZ088YsL2ilJ8+OGHeOuttwwe4+fnh4qKCi2fMxcAyaKoNm1Y6u++fWw/2mvXrBIAcyyAoqIi\nBPO25DIEBAQgICDAZAugqKgIBQUFVgnA4MGD0b9/f3z66adQKpWYP38+vvvuOzz00EOoq6sz2NL4\ns88+g5eXFx577DH1Y7NmzUJFRQV+4Hsicx56iPX7V5GZmYny8nKt5ABKKXbt2oWxY8eymh0wF2Bc\nXBxWr14tnWJqIkVFRejSpQtKSkqwceNGs16bl5eHO3fu4LnnnsPEiROxbNkyZGVl4cCBAxg2bJhe\nUZ+9ufsEQAoNAVi1ahVcXFzw+quvwqu2Fmu2bcPMmTORm5ur9ZITJ04gOjraIeXZUvBAsKkCoJsB\nZC7+qs1mNAWgrq4Ot2/fBomOBghBFKVwcnLCb7/9hqspKVBQ2rh/ghVs3rwZe/bssTj2Mn36dDzw\nwAMGj5HaE4BbBJIWAMBacXt7sz72gNUCYGoMoKioSP3/METXrl1NFgBLA8CaEELwzDPP4MKFCxgz\nZgzWr1+P5cuX47vvvoNCodD356u4ffs2vv/+e8yePVur/cmoUaMQFhZmcMVOKcXly5fh7u6Ozz//\nXF3DcvbsWVy9ehUTNRZ+hBAsWbIEqampejUr5lBUVITx48ejV69e+Oyzz8wSkwxV9mH37t2xevVq\nuLq6YubMmTh37pzD3T9AaxEAb28gKAhVFy/iq6++wuzZs/HmCy9AAaDvmDHYvXs37r//fnWPF76q\nbS7uH07//v3NEoAOHTqYNHFI4e7uDg8PDy0BKCwsBKUUgR06AJ06wf3KFfTu3RubNm2CO/ez2kAA\nevfu3eSZEVLtIPjPsm0R/PzYSjQvj+0gJ1PxbArmWgCmLETMSQW1hQAATGyDgoJw5MgR/P3vf8cb\nb7wBLy8vDB48WFYAvvrqK9TU1GCJxqoeAJycnDBz5kzs27dPNtZ1+/ZtlJeX45VXXkFgYCCef/55\n9eqfEIKHNDb+AYC//OUv8PHxsThYXVdXh/LycgQGBmLp0qU4c+aMOj3cFLgAdOvWDaGhoXj//ffV\n2XyODgADrUUAACAiAtdVgZcXX3xRXQMwYd48/Pjjj8jMzMTs2bPR0NCAnJwcFBQUNEsBuHLlikmB\n4JSUFEn3jzn4+/trCcANVeuDkJAQFlxPT8ewYcOQmZkJ9bRvAwGwB1ICYNAFxHn+ebZ7VEyMVdv3\nmRoDqKqqQk1NjUkCEBUVhatXr8puw6nJxYsX4e7ubrXQuru7Y+3atfjoo4/wj3/8Qx2zSUhIwKlT\np/TiLJRSfPHFFxg2bJikdTpr1izU19dLtiwBGrOc4uLi8Oabb+Lo0aPYvn07du7ciaFDh+q5yjw9\nPTFv3jxs2bJFey9jE+HjDwgIwGOPPQZvb2+zxCQ9PV292RHAqpRHjx6N0NBQvV5YjqDVCEB9eDjI\nlSuYMGECW/VotIG45557sGrVKuzevRsrVqxQ+/8dXQGsCw8En1b13JGjtrYW6enpVguAbjsIHnRT\nC0BmJoaqAu13gwAYdQEBbKvCzz5jDcOswFQXEH//TXUBcReJMS5evIhu3brp7WBnCZMmTcKzzz6r\nFbBPSEhAQ0MDfuVbmqo4ffo00tPTMWfOHMlz9e3bFz169MD3338v+Tz/2yIjIzF//nz07t0bTz/9\nNM6dOycbM3ruuefQ0NBgUeEaf/8DAgLg7e2NuXPnYvPmzSZvw5mRkYFu3bqp3xtCCHbt2oWkpKRm\nkV7u+BHYiZTycnRoaMDLfGtAnT5ATz/9NObNm4eVK1fi3XffRZs2bSz2nzcVpgaCMzIyUFdXZ3MB\n4BZAu3btgO7dgTt3MCIyEgDQg6eRtmABMMkCAFgMQGbLRlMx1QVUXFwMACa7gADTUkGtzQAyxuDB\ng9GmTRs9N9C3334LV1dXPCrTrZMQgoSEBJw+fVrS184rzyMiIqBQKLBq1Sr151LT/69JREQEpk6d\nijVr1qjdvKaiKQAAsGTJEtTW1uKLL74w6fXp6emsbYgGnp6esi1K7E2rEAClUontp0/DFcAI3qte\nRwAIIVi9ejUGDhyIs2fPIj4+Hi4uLo4ZsAz+/v6IjIw0KgDWBoA5BgVA9aHueOcOwsLC0LNtW5az\nLddDvZkhZwE4Ozurs0iaEldXVyiVSiiVSoPH6U5AhpDbT0GXyspK5OTkNKkAuLm5Yfjw4VptzOvr\n67Fx40ZMmDDBoEUTExOD8vJy9V7Qmly+fBlBQUHq7JnRo0dj2rRpGDBggMGK/ZdeegllZWUmT9wc\n3fe/R48euPfee/H5558bDQZXVlbi6tWr6N69u1nXtCetQgB27tyJk6oiMMLbxEo0gnN3d8eOHTsQ\nHh6OcePG2XmUpsF73RgiJSUFLi4ueisPc5FyAfn4+LD8etW5SWYm9u7diwfj41lPJQd1NTQXuSwg\nX19fiwqjzIUvLoy5gcxxAQUEBMDPz8+oBZCRkQFKaZMKAMDcQOfPn1e7Dg8dOoSCggLMnj3b4Ov4\nhJmenq73XHZ2NiJVVifnu+++M5rlM2DAAIwcORIffvihWV1YpQR42rRpyM7OVgd45eBCbO192JTc\n9QLQ0NCAd999F0reRZD7RwsLAR8fFtDTIDQ0FNnZ2fj73/9u55GaRnx8vNFAcGpqKnr06GG1BaPb\nEfTGjRts9Q8AoaEsCJqRgT59+sC7srLFuH8AticAIUTPBWTQ/29DeFGXscnIHBcQIcSkVFBbZQAZ\ng7euOHLkCADm/vH39ze6uOLj4uPU5PLly+reVhxnZ2eT2im/9NJLuHr1KrZu3WrK8AFICzBPMd6/\nf7/B13IBExaAA/nss8+QlJSEOa+/zlwUmgIgUwVsi8BYU2EsEMx397LW/w+wSaempkbdYOzGjRuN\nfWMIYVYAXwXdvNmiBMDJyUmvHURJSYnJO2NZCxcAY3EAcywAwLRagAsXLsDJyanJmxz269cPPj4+\nOCbO5MkAABmaSURBVHz4MCoqKrBjxw5MmzYNbjqLLl1CQkLg6+urJwBKpRI5OTl6FoCpjB8/Ht26\ndcP7779vci4/f/81PxedO3dG9+7dsW/fPoOvzcjIACHE4c0kDXFXC0BmZiZeeeUVjBs3DnMWLADC\nwkwSgOaMsUBwXl4e8vPzbbLDEF918lVoQUFBowUAqFNBAbQ4AQD020E4wgIwRQCcnZ0l94uWIioq\nCleuXDF43gsXLqBLly5GJ2JrUSgUGDVqFA4fPowdO3agsrLSqPsHYJZM9+7d9VxA165dQ319vZ4F\nYCpOTk548cUXcfr0afzyyy8mvaaoqAh+fn56i8Jx48bh6NGjBltDpKenIzw83GDFvaO5awWgvr4e\nc+bMUVcMEkJYRXALFwB/f3907dpVthiFP26LFFbddhBaFgDABODqVaCy8q4QAHtaANw9Z0wAiouL\n4e/vb3JcomvXrmhoaJDdEpFSiuPHj9ttC8LRo0cjKysL7733HiIiIjB06FCTXhcTE6NnAfAUUEsF\nAABmz56N4OBgfPCBZONiPeSK8MaNG4eamhqDQpKRkdGs3T/AXSwA7733HhITE/HZZ581plxFRDTu\nC9BCBQAAhg0bht9//13SjE1MTISrqyv69u1r9XU0BaCmpgYlJSXaAsA/3GlpbNemFi4ApaWldncB\nmRIENqea21gqaEZGBgoKCgzuLWBLeBzg/PnzeOyxx0wWsu7duyM/P18rSM9TQC11AQEs0WP69Ok4\nfPiw0QwsQF4ARo4cCQ8PD1k3EG8C15wDwMBdKgDnzp3D8uXL8eijj2LGjBmNT0REANevA9XVLVoA\nRowYgcLCQr2tHQEmALGxsTYx7zUFgGdy6LmAgMYWyS1cAHgWkD0wxwVkTj8qY6mgPCBrry6UPXv2\nBN/YSbPxmzF4IFjTDXT58mU4OTmho5FtIY3Rr18/VFVVmdQ2o7i4WPL9d3NzQ0JCAvbt2ye5EONN\n4IQFYGdqamowe/ZsBAQEYPXq1dorjogItqHH+fNAXV2LyVnXZfjw4QBY/3NN6uvrkZycbLMKZk0B\n0GoDweHBLT4OKzuB2htNAVAqlSgrK2uWLiBzBCAoKAg+Pj6yFsCRI0cQFhaGLrwepolxcnLCtGnT\ncN999yE6Otrk10mlgl6+fBnh4eFWZ7fxFgy8kZwhDAnwuHHjkJ2dLSkkmj2AmjN3nQDU1dVhwIAB\n+PzzzxGkO8Fz3+HJk+x7C7UAoqOj0bZtW712u2lpaaisrGwSAdBqA8Hx8AA6dborLAC+aUhzSwM1\n1wXEU0GlrENKKY4cOYJ77rnHLrUOnE8//VS9/62pREZGwsXFRSsOkJ2dbZX/n8NTpK0VAJ4OKuUG\n4sIlBMDOeHl54YsvvsCECRP0n7xLBIAQguHDh+tZACdVf5etBMDT0xMuLi5aFkA73VV+t24Ar0lo\ngQJQXl6O+vp6451AbYypLiBzLQCAxYiOHj2q14iN+/8dvQmJKSgUCkRFRelZALYQAFdXV/Ts2RNn\nzpwxeFxDQ4PB9z8yMhLR0dGSApCRkaHVBK65ctcJgEFCQwEXFyApif3eQgUAYHGA7OxsrXL5xMRE\nBAYG2sy8J4Soi8G4AOhtTKK5wmmBAgCwDe0N7gbWBJgiAEqlEiUlJWa39J49ezZqamr0Cp54xkpL\nEABAOxOosrISN27csCoArElsbCzOnDljsB6grKwMDQ0NBgWYp4PyWhmObhO45krrEgBnZ+ay4GZl\nCxYAHgfQdAMlJiZi4MCBNv3QcQEoKChAQECAfnCZB7nc3Ni+Cy0IPtmXlpba3QIwJQZQWloKSqnZ\nFkB8fDy6d++ODRs2aD1ub/+/tcTExODPP/9EbW2tOq3VFhYAwASgsLBQvbCRwpQ+TOPGjUN1dbU6\nuM5JT09v9gFgoLUJANAYCAZatADExcXB09NT7QYqLy9HWlqazbew1LQA9Nw/QKMFEBzMqoNbEJoN\n4RzlAjIUAzCnDYQmhBDMnTsXx44dU6dOcv//vffe2+xXpZzu3btDqVQiKyvLJjUAmpgSCDalCnvU\nqFFo06aNlhuIN4Fr7v5/oLUKAMD2eLVD18emQqFQYMiQIWoLgG9ib+s9DDQFQCsAzNEUgBaGpgA0\nRxeQuW0gNJk1axYIIfj2228BsBXpzZs3W4z7B9DuCWSLGgBNeJ2MKQJgSIDd3d2RkJCAb7/9Vr2X\nMQ/AtxoBIIQ8QAjJIIRkEUL+JvG8GyFkk+r5REJIZ1tc1yL4B6gFr/45w4cPx7lz51BaWqquAG4q\nC0CvDQQnLIwJaQsXgOYYBDanFbQuHTt2REJCAjZs2KBe/QMtx/8PNE6g6enpuHz5Mjw8PPRjUBbi\n5+eHiIgIqwUAAN5//3107NgRDz/8MObMmaPeUKpVuIAIIc4APgMwDkAPADMJIT10DnsSQDGltCuA\nVQDetfa6FsMtgLtAAEaMGAFKKf744w8kJiaia9euCOQbs9gIoxYAIcCiRcCkSTa9rj2QsgBM7blj\nLabEACx1AXHmzJmDP//8E3/88QeOHDmCDh062GwFbQ88PT0RHh6utgAiIiJs6r7igWA5TBWA7t27\nIykpCf/v//0/bNy4EUuWLGn2TeA4trAABgLIopRmU0prAXwPQHdrnokAvlb9vBXAaOIoR+RdJACD\nBg2CQqHAsWPHcPLkySbZwjIgIAAVFRWoqKiQFgAA+Pe/gQULbH7tpkbXAuBpr/bAlBiANS4gAJg8\neTI8PDzw9ddfOyT/3xbwpnC2SgHVJDY2FllZWeoaEF3Mef9dXV2xfPlyJCUlITY2FgMGDGjWTeA4\nthCAMAC5Gr9fUz0meQyltB5AKQDbLlVN5S4SAE9PT/Tr1w+bN2/G9evXm0wAOJIuoBaMj4+Pek8A\ne3YCBUxzAXELwFIB8PLywpQpU7B+/foW5//nxMTENKkAUEqRmpoq+XxxcTE8PT3NaqvCrQpjG9Q0\nF5pdEJgQspAQkkwISS7ku3bZksBAoEMHwIyy9ObM8OHD1WX/TS0AshZAC8XJyQk+Pj5qC8Be/n/A\nNBdQUVERPDw8rOrrNGfOHPU1WqIAdO/eHXfu3EF5ebnN3VfGMoHM7cOkSXPeU0QTWwhAHgDN7kwd\nVI9JHkMIUQDwBSC5pRWldC2lNJ5SGt+2KVbphACpqcArr9j+3A5gxIgRAGCzDqC63M0CADS2g7Bn\nIzjAdBeQpRMQ595770VYWBg6duzYovz/HM1dy2xtAXTs2BH+/v5NIgAtBVts4JoEIIoQEgE20c8A\n8BedY3YDmAvgDwBTARympm7J0xTYcaXX1AwbNgwAbNYBVJe72QUENApAaWkpmmTBIYOpLiBrJyBn\nZ2d8+eWXqK2tbXH+f0BbAGwtYIQQxMXFtWoBsNoCUPn0nwZwAMBFAJsppWmEkJWEkIdVh30BIJAQ\nkgXgBQB6qaICy2jbti0mTpyI6dOnN8n5+Q1ACLHrBGkv+LaQzdUFZKn/X5P77rtPujdWC6Bt27bq\n98DWFgDAFk6pqamor6/Xe641CIAtLABQSvcC2Kvz2BsaP1cDeNQW1xLos3PnziY7N78B2rZta9LG\n2y0NPz8/5OTk2D0ITAiBQqEwKgDmtFC+GyGEICYmBpmZmfDy8rL5+WNjY1FdXY2MjAz07NlT67nW\nIADNLggsaF74+PjAycnprnT/AEwAiouL7W4BAMwNZKwVxN0+AZnCvHnzsHjx4iY5t1wgmFLaKgTg\n7lvSCWyKk5MT/P3978oAMMAE4MaNG6irq7OrBQAwAbCHC6ilM3/+/CY7d/fu3eHm5oazZ89i1qxZ\n6scrKytRW1t717//wgIQGCUmJga9e/d29DCaBD8/P/Uk7AgLQE4AqqqqUF1dfdevQB2Ni4sLevXq\npWcBWNOGoyUhLACBUQ4fPgwnp7tzraA56dvbAnBxcZEVAGuLwASmExsbi507d4JSqs6Uai0CcHfe\n1QKb4uLi0mIKW8xFUwCaUwygtUxAzYHY2Fjcvn0b165dUz9mbR+mloIQAEGrxpEWgCEXUGuZgJoD\ncXFxAKDVGK61CLAQAEGrxtEWgJwAWNsITmA6ffv2BSFEKw4gBEAgaAU4UgAMxQBaywTUHPDy8kJU\nVJSwAASC1oam28cRLiC5GIBwAdmXuLg4PQFwdXWFh4eHA0fV9AgBELRq+KpfoVDY/WY35gJycnKC\nt7e3XcfUWomNjUVOTo565c+LwFpi/yRzEAIgaNXwHcB8fX3tfrMbcwH5+/vftem3zQ0eCD537hyA\n1tEGAhACIGjlKBQKeHt7293/Dxh3AYkAsP3QzQQSAiAQtBL8/Pzs7v8HjLuAWsME1FwIDg5GaGio\nlgC0BgEWAiBo9QgBEADageDW8v6LVhCCVs+rr77aJK2GjWGsFURUVJSdR9S6iYuLw/79+1FVVdVq\nOrEKARC0embMmOGQ6xprBdEaJqDmRGxsLJRKJc6cOYOKiopW8f4LF5BA4CDkXEANDQ0oKSlpFRNQ\nc4IHgn/++WcAraMGQwiAQOAg5ASgtLQUlNJWEYRsTkRERMDX11cIgEAgaHrkYgCtpQ1Bc4MQgtjY\nWPzxxx8AWsf7LwRAIHAQcjEAsReA44iLi1OLshAAgUDQZHAXEKVU63FhATgOvkcw0Dref6uygAgh\n/wLwEIBaAH8CmEcpLZE47gqAcgBKAPWU0nhrrisQ3A24urqCUgqlUgmFovFWFALgOHggGGgd77+1\nFsBPAHpRSvsAyATwdwPH3kspjRWTv0DAcHFxAQA9N5BwATmOmJgYuLm5wcnJSd0n6m7GKgGglB6k\nlNarfj0BoIP1QxIIWgeurq4AoBcIFpvBOA6+Sbyfn1+raMRny7/wCQD7ZJ6jAA4SQk4RQhYaOgkh\nZCEhJJkQklxYWGjD4QkEzQtDAuDh4QF3d3dHDKvVM2HCBAwaNMjRw7ALRmMAhJBDAEIknnqNUrpL\ndcxrAOoB/E/mNMMppXmEkGAAPxFC0imlv0odSCldC2AtAMTHx1OpYwSCuwHuAtIVANEJ1LEsX77c\n0UOwG0YFgFI6xtDzhJDHAUwAMJrqpjM0niNP9f0mIWQHgIEAJAVAIGgtcAtANwYg2kAI7IVVLiBC\nyAMA/grgYUpppcwxnoQQb/4zgPsAnLfmugLB3YCcC0hYAAJ7YW0M4FMA3mBunbOEkDUAQAgJJYTs\nVR3TDsBvhJBzAE4C+JFSut/K6woELR45ASgrK3NIe2pB68OqOgBKaVeZx68DeFD1czaAvtZcRyC4\nG5GLAZSWlqJnz56OGJKglXH35zkJBM0UuRhAWVlZq8hBFzgeIQACgYOQcgFRSoULSGA3hAAIBA5C\nSgCqq6tRV1cnLACBXRACIBA4CKkYQFlZGQAIC0BgF4QACAQOQioGwAVAWAACeyAEQCBwEFIuoNLS\nUgBCAAT2QQiAQOAgpARAuIAE9kQIgEDgIKTaQQsXkMCeCAEQCByEcAEJHI0QAIHAQQgXkMDRCAEQ\nCByEVBootwC8vb0dMiZB60IIgEDgIOTSQN3c3ODm5uaoYQlaEUIABAIHIecCEu4fgb0QAiAQOAhn\nZ2cQQvRcQCIALLAXQgAEAgdBCIGLi4ueBSAEQGAvhAAIBA7E1dVVLwYgXEACeyEEQCBwIK6ursIF\nJHAYQgAEAgeiKwDCAhDYEyEAAoEDcXFx0XMBCQtAYC+EAAgEDkTTAuC7gQkBENgLqwSAELKcEJJH\nCDmr+npQ5rgHCCEZhJAsQsjfrLmmQHA3oSkAlZWVUCqVwgUksBsKG5xjFaX0fbknCSHOAD4DMBbA\nNQBJhJDdlNILNri2QNCi0UwDFZ1ABfbGHi6ggQCyKKXZlNJaAN8DmGiH6woEzR7NNFDRCVRgb2wh\nAE8TQlIIIV8SQvwlng8D/n979xdjxVmHcfz7dNmjsltKaytSIYJKaLiQbbvBNqKxiA0lpqIxCjGm\nJk3woiZtQmJKmph4qUnVXpgmWKs3BhurtQRJW8AmRi+gSwu6FJCqGKAUFgJCNCEL/rw479HJZv8A\ns847nHk+ycnOn8OZJzsLD+87c/ZwtLB+LG0za7ziFJB/E6hVbcoCkLRD0vA4j88BTwMfBgaAE8CT\nZQNJWi9pSNLQyMhI2Zczq7XxCsAjAKvKlNcAImLllbyQpB8BW8fZdRyYX1ifl7ZNdLxNwCaAwcHB\nuJJjm12vent7uXDhAuApIKte2buA5hZWPw8Mj/O014BFkhZKagFrgS1ljmvWLYrXADwFZFUrexfQ\ndyUNAAEcAb4OIOl24JmIWB0RlyR9A3gZ6AGejYj9JY9r1hU8BWQ5lSqAiPjqBNvfBlYX1rcB28oc\ny6wbFQvAnwZmVfM7gc0yKv4qiPPnzzNz5sz/flSk2f+bC8Aso7FTQJ7+sSq5AMwyGjsF5AvAViUX\ngFlGHgFYTi4As4zGXgNwAViVXABmGXkKyHJyAZhl1HkjmD8LwHJwAZhl1Lnlc3R01AVglXMBmGXU\narUAuHjxoj8P2CrnAjDLqFMAZ8+eJSI8ArBKuQDMMuoUwOnTpwH/HiCrlgvALKPONYBOAXgKyKrk\nAjDLyCMAy8kFYJaRC8BycgGYZTS2ADwFZFVyAZhlNPYagEcAViUXgFlGHgFYTi4As4w6BTAyMgJA\nf39/zjjWMC4As4yKI4D+/n56enoyJ7ImcQGYZdS5BnDmzBlP/1jlXABmGRVHAL4AbFWbUeYPS3oO\nWJxWZwPnImJgnOcdAS4Al4FLETFY5rhm3aJTAKOjoy4Aq1ypAoiIL3eWJT0J/GOSp98XEafLHM+s\n23SmgMB3AFn1ShVAhyQBXwJWTMfrmTVFZwQAfg+AVW+6rgF8AjgZEYcn2B/AK5L2SFo/2QtJWi9p\nSNJQ59Y4s27lArCcphwBSNoBvH+cXU9ExItpeR2weZKXWR4RxyW9D9gu6WBE/G68J0bEJmATwODg\nYEyVz+x6ViwATwFZ1aYsgIhYOdl+STOALwB3T/Iax9PXU5JeAJYB4xaAWZMUrwF4BGBVm44poJXA\nwYg4Nt5OSX2SbuwsA/cDw9NwXLPrnqeALKfpKIC1jJn+kXS7pG1pdQ7we0n7gN3AbyLipWk4rtl1\nz3cBWU6l7wKKiK+Ns+1tYHVa/iuwtOxxzLpRT08PPT09XL582SMAq5zfCWyWWWcU4BGAVc0FYJZZ\n5zqARwBWNReAWWYuAMvFBWCWmaeALBcXgFlmHgFYLi4As8xarRaS6Ovryx3FGsYFYJZZq9Vi1qxZ\n3HCD/zpatfwTZ5ZZb2+vp38sCxeAWWadEYBZ1abl8wDM7Nq1Wi1/GLxl4QIwy2zDhg25I1hDuQDM\nMluzZk3uCNZQvgZgZtZQLgAzs4ZyAZiZNZQLwMysoVwAZmYN5QIwM2soF4CZWUO5AMzMGkoRkTvD\nhCSNAH+/xj9+K3B6GuNMN+crx/nKcb5y6pzvgxFx25U8sdYFUIakoYgYzJ1jIs5XjvOV43zl1D3f\nlfIUkJlZQ7kAzMwaqpsLYFPuAFNwvnKcrxznK6fu+a5I114DMDOzyXXzCMDMzCbRdQUgaZWkQ5Le\nkvR47jwAkp6VdErScGHbLZK2Szqcvt6cKdt8Sa9KelPSfkmP1izfuyXtlrQv5ft22r5Q0q50np+T\n1MqRr5CzR9IbkrbWNN8RSX+StFfSUNpWi3OcssyW9Lykg5IOSLq3LvkkLU7ft87jvKTH6pKvjK4q\nAEk9wA+BB4AlwDpJS/KmAuCnwKox2x4HdkbEImBnWs/hErAhIpYA9wCPpO9ZXfJdBFZExFJgAFgl\n6R7gO8D3I+IjwFng4Uz5Oh4FDhTW65YP4L6IGCjcvliXcwzwFPBSRNwBLKX9vaxFvog4lL5vA8Dd\nwL+AF+qSr5SI6JoHcC/wcmF9I7Axd66UZQEwXFg/BMxNy3OBQ7kzpiwvAp+pYz5gJvA68DHab8KZ\nMd55z5BrHu1/AFYAWwHVKV/KcAS4dcy2Wpxj4Cbgb6RrknXLNybT/cAf6prvah9dNQIAPgAcLawf\nS9vqaE5EnEjL7wBzcoYBkLQAuBPYRY3ypemVvcApYDvwF+BcRFxKT8l9nn8AfBP4d1p/L/XKBxDA\nK5L2SFqfttXlHC8ERoCfpGm0ZyT11Shf0Vpgc1quY76r0m0FcF2K9n8hst6OJakf+CXwWEScL+7L\nnS8iLkd7+D0PWAbckSvLWJI+C5yKiD25s0xheUTcRXt69BFJnyzuzHyOZwB3AU9HxJ3APxkznZL7\nZxAgXcd5EPjF2H11yHctuq0AjgPzC+vz0rY6OilpLkD6eipXEEm9tP/x/1lE/Kpu+Toi4hzwKu0p\nldmSZqRdOc/zx4EHJR0Bfk57Gugp6pMPgIg4nr6eoj1/vYz6nONjwLGI2JXWn6ddCHXJ1/EA8HpE\nnEzrdct31bqtAF4DFqU7MFq0h2tbMmeayBbgobT8EO2598pJEvBj4EBEfK+wqy75bpM0Oy2/h/b1\niQO0i+CLufNFxMaImBcRC2j/vP02Ir5Sl3wAkvok3dhZpj2PPUxNznFEvAMclbQ4bfo08CY1yVew\njv9N/0D98l293BchpvsBrAb+THue+InceVKmzcAJYJT2/3Yepj1PvBM4DOwAbsmUbTntoesfgb3p\nsbpG+T4KvJHyDQPfSts/BOwG3qI9JH9XDc7zp4CtdcuXsuxLj/2dvxd1OccpywAwlM7zr4Gba5av\nDzgD3FTYVpt81/rwO4HNzBqq26aAzMzsCrkAzMwaygVgZtZQLgAzs4ZyAZiZNZQLwMysoVwAZmYN\n5QIwM2uo/wAnIyAwDV2rcgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd0c9dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.16963498502 \n",
      "Fixed scheme MAE:  2.28088483638\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.5905  Test loss = 1.3527  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.5787  Test loss = 1.2383  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.5862  Test loss = 2.1317  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.6067  Test loss = 2.1899  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.5541  Test loss = 4.3550  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.6411  Test loss = 0.5066  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.5814  Test loss = 0.6542  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.5723  Test loss = 1.5110  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.4501  Test loss = 0.6211  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.4403  Test loss = 1.7698  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.4520  Test loss = 1.5928  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.4571  Test loss = 2.4221  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.3822  Test loss = 0.6926  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.3842  Test loss = 0.3035  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.3801  Test loss = 1.7449  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.3969  Test loss = 4.0096  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.4257  Test loss = 2.9532  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.4699  Test loss = 0.3815  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.4620  Test loss = 0.7779  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.3692  Test loss = 1.6200  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.3411  Test loss = 0.6133  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.3427  Test loss = 5.1233  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.4570  Test loss = 0.3806  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.4564  Test loss = 0.8986  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.4105  Test loss = 0.0195  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.4085  Test loss = 1.5107  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.4208  Test loss = 0.3087  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.4077  Test loss = 1.3626  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.3903  Test loss = 1.0298  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.3816  Test loss = 0.3347  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.3746  Test loss = 3.1308  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.3814  Test loss = 0.7172  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.3646  Test loss = 0.3330  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.3652  Test loss = 0.8449  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.2636  Test loss = 0.3421  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.2626  Test loss = 5.3367  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.3353  Test loss = 1.3980  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2402  Test loss = 2.0041  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.2641  Test loss = 0.0200  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2627  Test loss = 2.2083  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.2611  Test loss = 1.3262  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.2711  Test loss = 2.0084  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.2948  Test loss = 3.0310  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.3468  Test loss = 11.4260  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.9286  Test loss = 5.4465  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.0421  Test loss = 0.9967  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.0458  Test loss = 1.2450  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.0514  Test loss = 1.9636  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.9256  Test loss = 1.6221  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.9320  Test loss = 4.0025  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.9943  Test loss = 1.7709  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.0039  Test loss = 0.5366  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.9766  Test loss = 2.3133  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.9974  Test loss = 1.4373  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.0053  Test loss = 3.3658  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.0332  Test loss = 0.5992  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.9808  Test loss = 0.6603  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.9823  Test loss = 1.0404  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.9694  Test loss = 0.5234  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.9609  Test loss = 1.2255  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.9564  Test loss = 0.0121  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.9563  Test loss = 2.2003  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.9692  Test loss = 0.5640  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.9699  Test loss = 0.7798  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.9310  Test loss = 1.5970  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.9402  Test loss = 0.5070  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.9412  Test loss = 0.6230  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.9403  Test loss = 2.4897  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.9903  Test loss = 3.7665  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.0430  Test loss = 0.7388  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.0408  Test loss = 0.4387  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.0412  Test loss = 1.1549  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.9656  Test loss = 2.2419  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.9831  Test loss = 2.0833  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.9999  Test loss = 0.1075  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.9981  Test loss = 0.2172  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.9678  Test loss = 1.3744  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd079198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.36512233451 \n",
      "Updating scheme MAE:  1.6647037388\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
