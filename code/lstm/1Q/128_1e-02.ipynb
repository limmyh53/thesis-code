{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/128_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-2\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 128 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 128 \n",
      "Learning rate = 0.01 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.01\n",
      "Fold: 1  Epoch: 1  Training loss = 2.6347  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.5953  Validation loss = 1.3509  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.5971  Validation loss = 1.7544  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.5389  Validation loss = 1.0734  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.6114  Validation loss = 1.9306  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.6325  Validation loss = 2.0021  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.4456  Validation loss = 1.1622  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.4598  Validation loss = 1.5626  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.3642  Validation loss = 1.1389  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.2479  Validation loss = 0.8805  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.0891  Validation loss = 1.1478  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.0368  Validation loss = 1.1483  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.0889  Validation loss = 1.5298  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 1.8683  Validation loss = 1.3052  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 1.7990  Validation loss = 1.3682  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 1.8272  Validation loss = 1.1855  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 1.7774  Validation loss = 1.1480  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 1.7790  Validation loss = 1.2967  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 1.7203  Validation loss = 1.6328  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 10  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 1.5629  Validation loss = 2.4466  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 1.7540  Validation loss = 2.7018  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 1.5033  Validation loss = 2.2280  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 1.5934  Validation loss = 2.0786  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 1.4346  Validation loss = 2.2593  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 1.4861  Validation loss = 2.2593  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 1.4340  Validation loss = 1.9158  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 1.4215  Validation loss = 1.9484  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 1.4323  Validation loss = 2.1096  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 1.3893  Validation loss = 2.0301  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 1.4236  Validation loss = 1.7818  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 1.4038  Validation loss = 2.0905  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 1.4432  Validation loss = 2.0283  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 1.5588  Validation loss = 2.1533  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 1.4757  Validation loss = 2.6439  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 11  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.2097  Validation loss = 1.2722  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.1378  Validation loss = 1.1079  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.2118  Validation loss = 1.1401  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.1709  Validation loss = 1.2617  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.0918  Validation loss = 1.1496  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.1185  Validation loss = 1.1242  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.3569  Validation loss = 1.1979  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.0737  Validation loss = 1.2894  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.1704  Validation loss = 1.2059  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.0883  Validation loss = 1.1427  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.3013  Validation loss = 1.6906  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 2  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.0387  Validation loss = 1.2901  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.0650  Validation loss = 1.1470  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.1467  Validation loss = 1.4827  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.0337  Validation loss = 1.1225  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.0211  Validation loss = 1.3729  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.0118  Validation loss = 1.3114  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.0809  Validation loss = 1.1089  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.0084  Validation loss = 1.3618  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.0236  Validation loss = 1.1916  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.0185  Validation loss = 1.2160  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 0.9825  Validation loss = 1.4573  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.3380  Validation loss = 1.2200  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 0.9797  Validation loss = 1.2943  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.0464  Validation loss = 1.0848  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.1030  Validation loss = 1.2818  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 0.9834  Validation loss = 1.3918  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.0076  Validation loss = 2.0210  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 14  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 0.9189  Validation loss = 2.3123  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 0.9960  Validation loss = 2.1329  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 0.9826  Validation loss = 2.3137  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 0.9048  Validation loss = 2.3789  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 0.9511  Validation loss = 2.3243  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 0.9259  Validation loss = 2.3878  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 0.9245  Validation loss = 2.4387  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 0.9599  Validation loss = 2.2794  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.0048  Validation loss = 2.2009  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 0.8893  Validation loss = 2.2980  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.9416  Validation loss = 2.4380  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 0.9459  Validation loss = 2.3631  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 0.9788  Validation loss = 2.3120  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 0.8631  Validation loss = 2.2702  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.8624  Validation loss = 2.4650  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 2  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.0453  Validation loss = 1.5386  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 0.9885  Validation loss = 1.2299  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.9726  Validation loss = 1.2224  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.9324  Validation loss = 1.0874  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.9472  Validation loss = 1.1597  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.9192  Validation loss = 1.0424  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.9117  Validation loss = 0.9397  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.8988  Validation loss = 1.1767  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.8843  Validation loss = 1.1926  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.9138  Validation loss = 1.2717  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.9529  Validation loss = 1.2258  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.8710  Validation loss = 0.9342  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.8716  Validation loss = 1.0845  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.8694  Validation loss = 1.0577  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 0.8751  Validation loss = 0.9725  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 0.9613  Validation loss = 1.1547  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 0.8815  Validation loss = 1.0244  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 0.9422  Validation loss = 1.0369  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 0.9773  Validation loss = 1.2202  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 0.9222  Validation loss = 1.0255  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 0.8562  Validation loss = 0.9737  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 0.9057  Validation loss = 1.2035  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 0.8888  Validation loss = 0.9905  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 0.8990  Validation loss = 1.0781  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 0.9896  Validation loss = 1.2616  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 12  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.9145  Validation loss = 2.0967  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.8654  Validation loss = 1.6028  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.8412  Validation loss = 1.5759  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.8346  Validation loss = 1.7051  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.8136  Validation loss = 1.5733  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.8186  Validation loss = 1.5637  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.8278  Validation loss = 1.7231  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.8685  Validation loss = 2.0410  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.8243  Validation loss = 1.9775  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.7945  Validation loss = 1.7283  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.8078  Validation loss = 1.8443  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.8443  Validation loss = 1.4562  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.8973  Validation loss = 1.2312  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.8088  Validation loss = 1.5004  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 0.8045  Validation loss = 2.0315  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 0.8081  Validation loss = 2.0658  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 13  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.8882  Validation loss = 4.1147  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.8216  Validation loss = 3.2319  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.7583  Validation loss = 3.8814  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.7383  Validation loss = 3.6276  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.7952  Validation loss = 3.4063  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.7642  Validation loss = 3.7226  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.8179  Validation loss = 3.8098  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.7432  Validation loss = 3.7616  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.8317  Validation loss = 4.0335  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.7414  Validation loss = 3.7184  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.7575  Validation loss = 3.3142  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.7314  Validation loss = 3.5141  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 0.7274  Validation loss = 3.8028  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 0.8134  Validation loss = 4.0661  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 2  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.0075  Validation loss = 6.1630  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 0.9788  Validation loss = 6.1743  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 0.9694  Validation loss = 6.1101  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 0.9221  Validation loss = 5.8921  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.0766  Validation loss = 6.1752  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.5502  Validation loss = 5.6891  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 0.8777  Validation loss = 6.1040  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 0.8405  Validation loss = 5.8944  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 0.9017  Validation loss = 6.0380  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 0.8354  Validation loss = 6.0088  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 0.8236  Validation loss = 5.8134  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 0.9021  Validation loss = 5.7414  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 0.8762  Validation loss = 5.5621  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 0.9401  Validation loss = 5.3624  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 0.8605  Validation loss = 5.7646  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 0.8294  Validation loss = 5.5871  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 0.8824  Validation loss = 5.3694  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 0.9059  Validation loss = 5.0867  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 0.7430  Validation loss = 5.6800  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 0.8584  Validation loss = 5.4383  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 0.7700  Validation loss = 5.4771  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 0.8412  Validation loss = 5.5902  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 0.7896  Validation loss = 5.1646  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 0.8929  Validation loss = 5.8162  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 18  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 1.3728  Validation loss = 2.5802  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.3187  Validation loss = 2.2247  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.1152  Validation loss = 2.5201  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.1378  Validation loss = 2.8645  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.3059  Validation loss = 2.4607  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.2248  Validation loss = 2.7743  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 0.9332  Validation loss = 2.3935  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 0.9003  Validation loss = 2.5402  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 0.9288  Validation loss = 1.9785  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 0.8399  Validation loss = 2.6517  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 0.9606  Validation loss = 2.7668  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 0.8161  Validation loss = 2.7137  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 0.7765  Validation loss = 2.8001  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 0.8816  Validation loss = 2.8094  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 9  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.0353  Validation loss = 1.9545  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.3292  Validation loss = 3.0778  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 0.9904  Validation loss = 2.6069  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 0.9260  Validation loss = 2.0249  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 0.8952  Validation loss = 1.8409  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 0.9505  Validation loss = 1.7856  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 0.9086  Validation loss = 1.9970  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.0056  Validation loss = 2.3591  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 0.9514  Validation loss = 1.2915  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 0.8757  Validation loss = 1.9597  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.1673  Validation loss = 2.1665  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.0816  Validation loss = 1.5632  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.1639  Validation loss = 1.3948  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 0.9076  Validation loss = 1.4702  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 0.9346  Validation loss = 1.3692  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 0.8262  Validation loss = 1.4459  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 0.9142  Validation loss = 2.2824  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 1.0243  Validation loss = 1.5946  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 0.8635  Validation loss = 1.9371  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 0.7940  Validation loss = 2.0793  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 0.8157  Validation loss = 1.9954  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 0.8404  Validation loss = 1.6196  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 0.7955  Validation loss = 2.6602  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 9  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 0.9792  Validation loss = 2.1535  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.3822  Validation loss = 2.9702  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 0.8570  Validation loss = 1.6863  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 0.9079  Validation loss = 1.6988  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 0.8480  Validation loss = 1.1312  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 0.9783  Validation loss = 1.4134  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 0.8086  Validation loss = 1.3100  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 0.8182  Validation loss = 1.4521  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 0.8492  Validation loss = 1.3009  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.2160  Validation loss = 2.1706  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 0.7914  Validation loss = 1.6384  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 0.7556  Validation loss = 1.9928  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 0.8722  Validation loss = 2.1510  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 0.9507  Validation loss = 1.6444  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 0.8928  Validation loss = 2.7152  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 5  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 0.9086  Validation loss = 2.6776  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.1306  Validation loss = 2.4492  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 0.8331  Validation loss = 2.9971  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 0.7912  Validation loss = 2.7839  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 0.7949  Validation loss = 2.4427  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 0.9115  Validation loss = 4.0806  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 0.7164  Validation loss = 3.5942  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 0.7537  Validation loss = 2.8545  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 0.6967  Validation loss = 3.4498  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 0.6769  Validation loss = 3.1026  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 0.7456  Validation loss = 3.7719  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 0.6759  Validation loss = 3.2013  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 0.7081  Validation loss = 3.7227  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 0.5899  Validation loss = 3.4668  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 0.6769  Validation loss = 2.8121  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 0.7161  Validation loss = 3.9485  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 5  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.0618  Validation loss = 5.3342  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.3297  Validation loss = 3.2372  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.0073  Validation loss = 4.0249  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.2907  Validation loss = 5.1527  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 0.9183  Validation loss = 4.6311  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.0545  Validation loss = 5.0694  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 0.8819  Validation loss = 4.7233  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 0.8342  Validation loss = 4.7974  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 0.7295  Validation loss = 5.0389  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 0.8232  Validation loss = 4.4449  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 0.7550  Validation loss = 4.5930  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 0.6887  Validation loss = 4.6040  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 0.6671  Validation loss = 4.9484  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 0.8788  Validation loss = 5.3329  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 2  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 1.4737  Validation loss = 5.0211  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 1.3144  Validation loss = 4.5080  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 1.1668  Validation loss = 4.0441  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.0928  Validation loss = 4.3661  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.3712  Validation loss = 5.2726  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.0584  Validation loss = 4.6501  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 1.1394  Validation loss = 4.3374  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 0.9996  Validation loss = 5.1052  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 0.9504  Validation loss = 4.8842  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 0.9119  Validation loss = 4.5603  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 0.8789  Validation loss = 4.2447  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 0.8503  Validation loss = 4.5374  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 0.8320  Validation loss = 5.0542  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 1.5118  Validation loss = 4.2936  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 0.9756  Validation loss = 4.8647  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 1.0205  Validation loss = 4.8180  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 0.9344  Validation loss = 5.0627  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 1.2371  Validation loss = 5.0715  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 3  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 1.5947  Validation loss = 3.4738  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 1.5297  Validation loss = 2.3215  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 1.4006  Validation loss = 2.5489  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 1.3802  Validation loss = 2.7452  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 1.4990  Validation loss = 3.0348  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 1.1644  Validation loss = 2.8269  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 1.2373  Validation loss = 3.4316  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 1.3574  Validation loss = 2.5901  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 1.0477  Validation loss = 2.9549  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 1.0559  Validation loss = 2.7576  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 1.1983  Validation loss = 2.8702  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 1.2448  Validation loss = 2.4809  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 1.1462  Validation loss = 2.8120  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 1.2327  Validation loss = 3.1644  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 1.1894  Validation loss = 3.2925  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 1.2118  Validation loss = 3.3241  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 1.2063  Validation loss = 3.0584  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 1.2462  Validation loss = 3.5895  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 2  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 1.3382  Validation loss = 3.4396  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 1.3949  Validation loss = 2.8274  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 1.3458  Validation loss = 3.0391  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 1.5334  Validation loss = 2.6700  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 1.5591  Validation loss = 2.4630  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 1.1887  Validation loss = 2.7543  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 1.4897  Validation loss = 3.5460  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 1.4675  Validation loss = 2.6016  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 1.4263  Validation loss = 2.4843  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 1.1815  Validation loss = 3.1792  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 1.2667  Validation loss = 2.7702  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 1.3892  Validation loss = 2.2771  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 1.3892  Validation loss = 2.3754  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 1.3164  Validation loss = 3.0194  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 1.3372  Validation loss = 2.8702  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 1.4800  Validation loss = 3.2615  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 1.4637  Validation loss = 2.6817  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 1.1507  Validation loss = 2.7964  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 1.0811  Validation loss = 2.5080  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 1.2369  Validation loss = 2.9824  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 1.3199  Validation loss = 2.3796  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 1.4531  Validation loss = 2.6963  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 1.2340  Validation loss = 2.7622  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 1.0771  Validation loss = 2.5874  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 1.0878  Validation loss = 2.3297  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 1.1398  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 1.1044  Validation loss = 2.7821  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 1.0415  Validation loss = 2.7915  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 1.3451  Validation loss = 3.2957  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 26  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 1.2103  Validation loss = 1.8254  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 1.1920  Validation loss = 1.7474  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 1.1595  Validation loss = 1.5304  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 1.0263  Validation loss = 1.6581  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 0.9510  Validation loss = 1.8228  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 0.9336  Validation loss = 1.3533  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 1.0395  Validation loss = 1.9371  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 0.9949  Validation loss = 1.5046  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 0.9197  Validation loss = 1.4661  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 0.9275  Validation loss = 1.5221  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 0.9807  Validation loss = 1.3036  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 1.0434  Validation loss = 1.6897  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 0.8878  Validation loss = 1.2860  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 1.0906  Validation loss = 0.8527  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 0.8620  Validation loss = 1.3014  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 0.8600  Validation loss = 1.5997  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 0.8156  Validation loss = 1.5174  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 0.9865  Validation loss = 0.8628  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 0.7692  Validation loss = 1.2052  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 1.0088  Validation loss = 1.7167  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 14  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 0.9479  Validation loss = 2.8110  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 0.9289  Validation loss = 2.6689  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 0.9920  Validation loss = 2.5521  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 0.8343  Validation loss = 2.6692  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 0.8047  Validation loss = 2.4800  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 0.7793  Validation loss = 2.0770  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 1.0195  Validation loss = 1.9559  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 0.9183  Validation loss = 1.9845  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 0.7873  Validation loss = 2.1664  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 0.8048  Validation loss = 2.3685  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 0.7646  Validation loss = 2.4507  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 0.8028  Validation loss = 2.0994  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 0.7996  Validation loss = 2.5011  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 0.8234  Validation loss = 2.5955  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 7  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 1.0991  Validation loss = 1.8883  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 0.9867  Validation loss = 1.7763  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 0.8075  Validation loss = 1.3484  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 1.0763  Validation loss = 1.1787  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 0.8319  Validation loss = 1.9296  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 0.8854  Validation loss = 1.4070  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 0.8658  Validation loss = 1.4648  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 1.0570  Validation loss = 0.7368  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 0.8109  Validation loss = 1.1209  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 0.6995  Validation loss = 1.2563  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 0.7365  Validation loss = 1.0369  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 0.6847  Validation loss = 1.0298  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 0.9119  Validation loss = 1.0047  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 0.6626  Validation loss = 1.0957  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 0.7622  Validation loss = 1.3226  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 0.7270  Validation loss = 1.0184  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 0.6832  Validation loss = 1.0202  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 0.6770  Validation loss = 1.5134  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 8  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 0.7515  Validation loss = 3.7035  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 0.6785  Validation loss = 3.7597  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 0.6505  Validation loss = 3.8381  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 0.6499  Validation loss = 3.9400  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 0.6644  Validation loss = 3.7471  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 0.6254  Validation loss = 3.8528  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 0.6563  Validation loss = 4.0205  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 0.5807  Validation loss = 3.8921  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 0.6237  Validation loss = 3.8498  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 0.5557  Validation loss = 3.8677  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 0.5864  Validation loss = 3.7460  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 0.7258  Validation loss = 4.2528  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 1.0662  Validation loss = 3.4007  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 0.9004  Validation loss = 3.4633  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 0.8024  Validation loss = 3.5710  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 0.7583  Validation loss = 3.4631  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 0.7316  Validation loss = 3.4587  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 0.8508  Validation loss = 3.5460  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 0.7735  Validation loss = 3.5018  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 0.7971  Validation loss = 3.6471  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 0.8796  Validation loss = 3.2235  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 0.7693  Validation loss = 3.2296  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 0.6898  Validation loss = 3.3819  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 0.6595  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 0.8032  Validation loss = 3.4685  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 0.6555  Validation loss = 3.4404  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 1.0563  Validation loss = 2.7912  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 0.7356  Validation loss = 3.1294  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 0.6942  Validation loss = 2.9677  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 0.6778  Validation loss = 3.2411  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 0.7364  Validation loss = 2.9589  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 0.9958  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 0.7391  Validation loss = 3.5931  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 15  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 1.1702  Validation loss = 2.1918  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 1.0540  Validation loss = 2.4644  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 1.8587  Validation loss = 3.7992  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 1.1710  Validation loss = 2.8052  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 1.3634  Validation loss = 3.5028  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 1.1163  Validation loss = 3.3684  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 1.1862  Validation loss = 2.8285  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 1.4202  Validation loss = 1.8855  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 1.1348  Validation loss = 2.7792  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 1.4566  Validation loss = 2.0690  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 1.3556  Validation loss = 4.4847  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 8  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.2215  Validation loss = 2.1612  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.4215  Validation loss = 2.0099  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 1.4211  Validation loss = 2.5369  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 1.7059  Validation loss = 1.5658  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.2446  Validation loss = 1.8963  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.4073  Validation loss = 2.5230  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 1.4624  Validation loss = 1.8989  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 1.0407  Validation loss = 1.8115  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 1.0965  Validation loss = 2.4141  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 1.4987  Validation loss = 1.8343  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 1.4940  Validation loss = 2.0859  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 1.0901  Validation loss = 2.1453  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 1.4291  Validation loss = 1.9514  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 1.0110  Validation loss = 2.2761  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.6643  Validation loss = 2.1612  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 1.1583  Validation loss = 1.8366  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.4541  Validation loss = 1.9784  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 1.3191  Validation loss = 1.9031  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 1.1562  Validation loss = 2.2195  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 1.0832  Validation loss = 2.0071  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 1.1160  Validation loss = 1.6876  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 1.2361  Validation loss = 2.0080  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 1.3554  Validation loss = 1.4679  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 1.2637  Validation loss = 1.4063  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 1.0815  Validation loss = 1.7038  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 1.2516  Validation loss = 2.3783  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 24  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 1.4022  Validation loss = 2.7472  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 1.2191  Validation loss = 2.8170  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 1.2148  Validation loss = 2.3164  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 1.3337  Validation loss = 2.7802  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 1.0886  Validation loss = 2.5665  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 1.1824  Validation loss = 2.7082  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 1.4545  Validation loss = 3.8784  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 1.2700  Validation loss = 3.0018  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 1.0404  Validation loss = 2.4730  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 1.1085  Validation loss = 2.8486  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 0.9587  Validation loss = 2.4938  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 0.9754  Validation loss = 2.4914  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 0.9146  Validation loss = 2.7215  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 0.8591  Validation loss = 2.4798  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 0.8468  Validation loss = 2.8295  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 0.8488  Validation loss = 2.6224  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 1.3145  Validation loss = 2.5336  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 1.2991  Validation loss = 2.7922  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 1.0878  Validation loss = 2.5420  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 1.2988  Validation loss = 3.4053  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 3  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 1.2316  Validation loss = 1.5293  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 1.1631  Validation loss = 2.1973  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 1.0748  Validation loss = 1.8821  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 1.0775  Validation loss = 2.1582  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 1.1220  Validation loss = 2.9196  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 1.2653  Validation loss = 2.1503  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 1.2543  Validation loss = 2.2780  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 1.4143  Validation loss = 2.3349  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 1.1357  Validation loss = 1.6561  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 1.2377  Validation loss = 2.3939  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 1.2080  Validation loss = 2.2121  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 1.0941  Validation loss = 2.2378  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 1.0768  Validation loss = 2.6133  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 1.0792  Validation loss = 2.9744  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 1  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 1.1177  Validation loss = 1.0665  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 1.3753  Validation loss = 1.4627  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 1.3425  Validation loss = 0.8686  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 1.2408  Validation loss = 1.4117  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 1.3036  Validation loss = 0.8218  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 1.2493  Validation loss = 1.1106  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 1.2453  Validation loss = 1.2547  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 1.2808  Validation loss = 1.0713  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 1.1582  Validation loss = 1.2409  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.3352  Validation loss = 1.4513  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 1.2417  Validation loss = 1.4592  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 1.3989  Validation loss = 1.3594  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 1.4620  Validation loss = 1.5724  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 5  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 1.4075  Validation loss = 2.3040  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 1.6193  Validation loss = 2.8351  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 1.3144  Validation loss = 2.0521  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 1.3686  Validation loss = 2.4116  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 1.2935  Validation loss = 1.5966  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 1.2243  Validation loss = 2.0212  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 1.1943  Validation loss = 2.4403  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 1.1587  Validation loss = 2.1812  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 1.0829  Validation loss = 1.8065  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 1.0439  Validation loss = 1.2169  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 0.9367  Validation loss = 1.6868  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 0.9668  Validation loss = 1.3806  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 1.0839  Validation loss = 2.0404  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 0.9957  Validation loss = 1.6795  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 1.0068  Validation loss = 1.5161  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 0.9578  Validation loss = 1.9821  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 1.0530  Validation loss = 1.7139  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 1.1085  Validation loss = 2.4167  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 10  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 1.2457  Validation loss = 1.5920  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 1.3810  Validation loss = 1.3103  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 1.1930  Validation loss = 1.4702  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 1.0883  Validation loss = 1.3666  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 1.0560  Validation loss = 1.3036  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 1.0937  Validation loss = 1.5080  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 1.0073  Validation loss = 1.4507  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 0.9513  Validation loss = 1.2563  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 0.9258  Validation loss = 1.4231  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.0363  Validation loss = 1.3155  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 1.0236  Validation loss = 1.7475  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 8  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.0360  Validation loss = 2.6178  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 1.2683  Validation loss = 3.2680  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 0.9521  Validation loss = 2.6661  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 0.9738  Validation loss = 2.5709  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 0.9492  Validation loss = 2.3886  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 0.9529  Validation loss = 2.2845  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 0.9728  Validation loss = 3.0056  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 0.9242  Validation loss = 2.3798  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.0557  Validation loss = 3.2057  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 1.0243  Validation loss = 2.3858  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 1.3226  Validation loss = 3.2157  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 0.9600  Validation loss = 2.2995  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 0.9320  Validation loss = 2.7476  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 1.1127  Validation loss = 2.5329  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 1.0806  Validation loss = 2.7727  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 0.9844  Validation loss = 2.4837  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 0.9386  Validation loss = 2.6409  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 1.0055  Validation loss = 2.7056  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 0.9608  Validation loss = 2.4314  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 1.0498  Validation loss = 2.9811  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 0.9519  Validation loss = 2.7140  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 0.9677  Validation loss = 2.9114  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 1.2446  Validation loss = 3.3722  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 6  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 1.2577  Validation loss = 3.3472  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.1050  Validation loss = 3.6990  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 1.4878  Validation loss = 3.1594  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.5329  Validation loss = 2.9170  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 1.3882  Validation loss = 2.6144  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 1.1523  Validation loss = 3.0087  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 1.1105  Validation loss = 3.6821  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.1558  Validation loss = 3.6209  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 1.2199  Validation loss = 3.5660  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 1.1758  Validation loss = 3.2207  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.1810  Validation loss = 2.8289  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 1.0545  Validation loss = 3.1162  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 1.0995  Validation loss = 2.9042  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 1.0596  Validation loss = 3.1923  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 1.0743  Validation loss = 3.3112  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 1.1013  Validation loss = 2.9895  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 1.1204  Validation loss = 2.9511  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 1.1128  Validation loss = 3.3178  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 1.0481  Validation loss = 3.0189  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 1.2006  Validation loss = 3.8267  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 5  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 0.9104  Validation loss = 3.7426  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 0.8544  Validation loss = 3.2171  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 0.9159  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 0.8148  Validation loss = 3.0244  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 0.7859  Validation loss = 3.0537  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 0.7209  Validation loss = 3.0712  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 0.7837  Validation loss = 3.1184  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 0.7511  Validation loss = 2.7489  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.0337  Validation loss = 2.2714  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 0.9154  Validation loss = 2.1097  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 0.7621  Validation loss = 3.1159  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 0.7196  Validation loss = 2.8910  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 0.7406  Validation loss = 2.3452  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 0.7652  Validation loss = 2.5999  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 0.6990  Validation loss = 2.9314  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 0.7567  Validation loss = 2.7701  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 0.6605  Validation loss = 2.2928  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 0.6813  Validation loss = 2.3288  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 0.7565  Validation loss = 3.0604  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 0.7860  Validation loss = 3.2692  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 10  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 8\n",
      "Average validation error: 3.0064\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 0.8490  Test loss = 3.5311  \n",
      "\n",
      "Epoch: 2  Training loss = 0.8128  Test loss = 3.5010  \n",
      "\n",
      "Epoch: 3  Training loss = 0.7893  Test loss = 3.4967  \n",
      "\n",
      "Epoch: 4  Training loss = 0.7702  Test loss = 3.4923  \n",
      "\n",
      "Epoch: 5  Training loss = 0.7542  Test loss = 3.4879  \n",
      "\n",
      "Epoch: 6  Training loss = 0.7407  Test loss = 3.4838  \n",
      "\n",
      "Epoch: 7  Training loss = 0.7289  Test loss = 3.4803  \n",
      "\n",
      "Epoch: 8  Training loss = 0.7183  Test loss = 3.4774  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc1cd630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwMysof4DW/+Lc64WY2oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xce6bef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.47741883342 \n",
      "Fixed scheme MAE:  2.34051342066\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 0.7183  Test loss = 4.5088  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 0.9094  Test loss = 4.0239  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.0374  Test loss = 0.8575  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.0428  Test loss = 2.2676  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 0.6456  Test loss = 2.9555  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 0.7418  Test loss = 0.7541  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 0.7469  Test loss = 0.5952  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 0.7495  Test loss = 1.1043  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.5372  Test loss = 0.7305  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.5447  Test loss = 1.7029  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 0.5759  Test loss = 1.7097  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 0.6107  Test loss = 0.4912  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.4281  Test loss = 0.5886  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.4335  Test loss = 0.6523  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 0.4391  Test loss = 2.1066  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 0.5100  Test loss = 3.6535  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.5038  Test loss = 0.6115  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 0.5082  Test loss = 1.3145  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 0.5337  Test loss = 0.8660  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 0.5443  Test loss = 0.4765  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.3329  Test loss = 0.2380  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.3342  Test loss = 2.8622  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 0.4862  Test loss = 3.4433  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 0.6470  Test loss = 1.7017  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.5101  Test loss = 0.8564  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.5165  Test loss = 0.3069  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 0.5147  Test loss = 0.3080  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 0.5158  Test loss = 1.8062  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.4106  Test loss = 1.0858  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.4292  Test loss = 0.1687  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.4297  Test loss = 4.8072  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.7336  Test loss = 1.8399  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.5963  Test loss = 2.8155  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.6910  Test loss = 4.3347  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.8636  Test loss = 0.9903  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.8720  Test loss = 8.0689  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.1419  Test loss = 0.7662  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.1425  Test loss = 1.1703  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.1509  Test loss = 0.3602  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.1518  Test loss = 1.1277  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.5630  Test loss = 3.7085  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.7262  Test loss = 1.8859  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.7623  Test loss = 2.7549  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 0.8315  Test loss = 16.5007  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0384  Test loss = 9.5746  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.3591  Test loss = 5.0594  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.4410  Test loss = 0.4800  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.4417  Test loss = 0.0299  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.3139  Test loss = 2.4341  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.3476  Test loss = 4.8465  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.4756  Test loss = 2.8800  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.5181  Test loss = 1.7226  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.2665  Test loss = 6.0751  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.4734  Test loss = 3.3117  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.5295  Test loss = 0.8622  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.5073  Test loss = 3.1184  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.1729  Test loss = 1.8961  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.1961  Test loss = 2.1093  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.2210  Test loss = 1.8522  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.2415  Test loss = 4.1723  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.1753  Test loss = 2.3964  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.2120  Test loss = 2.8225  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.2523  Test loss = 1.2787  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.2605  Test loss = 2.1817  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.0560  Test loss = 1.7262  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.0747  Test loss = 1.8698  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.0984  Test loss = 1.9178  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.1237  Test loss = 3.4242  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 0.9428  Test loss = 3.3282  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.0290  Test loss = 2.6322  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.0795  Test loss = 1.6740  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.0989  Test loss = 3.3918  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 0.8843  Test loss = 2.6346  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 0.9424  Test loss = 0.2498  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 0.9420  Test loss = 1.5534  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 0.9520  Test loss = 1.3690  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 0.7803  Test loss = 1.6617  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nADAzq6n/AkxfIgK1gpQDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc817b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 3.34873473859 \n",
      "Updating scheme MAE:  2.36902873806\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
