{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/128_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-5\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 128 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 128 \n",
      "Learning rate = 1e-05 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-05\n",
      "Fold: 1  Epoch: 1  Training loss = 3.3132  Validation loss = 3.4794  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.3088  Validation loss = 3.4721  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.3061  Validation loss = 3.4677  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.3037  Validation loss = 3.4639  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.3006  Validation loss = 3.4588  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.2971  Validation loss = 3.4531  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.2938  Validation loss = 3.4478  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.2902  Validation loss = 3.4418  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.2866  Validation loss = 3.4358  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.2828  Validation loss = 3.4295  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.2794  Validation loss = 3.4240  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.2767  Validation loss = 3.4197  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.2743  Validation loss = 3.4156  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.2712  Validation loss = 3.4105  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.2683  Validation loss = 3.4057  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.2653  Validation loss = 3.4008  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.2613  Validation loss = 3.3942  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.2572  Validation loss = 3.3871  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.2541  Validation loss = 3.3820  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.2507  Validation loss = 3.3764  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.2475  Validation loss = 3.3711  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.2442  Validation loss = 3.3653  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.2403  Validation loss = 3.3586  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.2368  Validation loss = 3.3526  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.2345  Validation loss = 3.3488  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.2313  Validation loss = 3.3435  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.2291  Validation loss = 3.3397  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.2256  Validation loss = 3.3336  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.2224  Validation loss = 3.3283  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.2197  Validation loss = 3.3238  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.2160  Validation loss = 3.3173  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.2130  Validation loss = 3.3123  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.2099  Validation loss = 3.3070  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.2067  Validation loss = 3.3014  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.2029  Validation loss = 3.2947  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.1995  Validation loss = 3.2889  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.1975  Validation loss = 3.2854  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.1949  Validation loss = 3.2809  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.1916  Validation loss = 3.2753  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.1890  Validation loss = 3.2707  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.1863  Validation loss = 3.2661  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.1840  Validation loss = 3.2620  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.1805  Validation loss = 3.2557  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.1788  Validation loss = 3.2529  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.1759  Validation loss = 3.2479  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.1727  Validation loss = 3.2424  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.1698  Validation loss = 3.2372  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.1680  Validation loss = 3.2340  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.1647  Validation loss = 3.2282  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.1622  Validation loss = 3.2239  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.1587  Validation loss = 3.2175  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.1562  Validation loss = 3.2131  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.1543  Validation loss = 3.2099  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.1514  Validation loss = 3.2047  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.1486  Validation loss = 3.1997  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.1464  Validation loss = 3.1956  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.1442  Validation loss = 3.1918  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.1415  Validation loss = 3.1870  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.1395  Validation loss = 3.1833  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.1368  Validation loss = 3.1785  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.1341  Validation loss = 3.1735  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.1310  Validation loss = 3.1681  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.1278  Validation loss = 3.1623  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.1252  Validation loss = 3.1575  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.1226  Validation loss = 3.1530  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.1198  Validation loss = 3.1478  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.1174  Validation loss = 3.1433  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.1143  Validation loss = 3.1376  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.1120  Validation loss = 3.1335  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.1089  Validation loss = 3.1278  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.1066  Validation loss = 3.1235  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.1041  Validation loss = 3.1190  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.1015  Validation loss = 3.1142  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.0991  Validation loss = 3.1099  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.0967  Validation loss = 3.1053  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.0945  Validation loss = 3.1015  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.0920  Validation loss = 3.0966  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.0899  Validation loss = 3.0926  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.0867  Validation loss = 3.0867  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.0845  Validation loss = 3.0824  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.0816  Validation loss = 3.0770  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.0796  Validation loss = 3.0734  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.0773  Validation loss = 3.0690  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.0742  Validation loss = 3.0630  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.0727  Validation loss = 3.0602  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.0687  Validation loss = 3.0526  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.0662  Validation loss = 3.0478  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.0637  Validation loss = 3.0429  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.0616  Validation loss = 3.0391  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.0600  Validation loss = 3.0360  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.0576  Validation loss = 3.0315  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.0550  Validation loss = 3.0264  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.0528  Validation loss = 3.0222  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.0501  Validation loss = 3.0169  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.0473  Validation loss = 3.0114  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.0450  Validation loss = 3.0068  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.0421  Validation loss = 3.0011  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.0396  Validation loss = 2.9962  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.0380  Validation loss = 2.9933  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.0358  Validation loss = 2.9889  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.0336  Validation loss = 2.9847  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.0319  Validation loss = 2.9814  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.0296  Validation loss = 2.9768  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.0275  Validation loss = 2.9727  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.0255  Validation loss = 2.9687  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.0229  Validation loss = 2.9635  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.0205  Validation loss = 2.9585  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.0180  Validation loss = 2.9535  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.0156  Validation loss = 2.9488  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.0133  Validation loss = 2.9442  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.0113  Validation loss = 2.9403  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.0099  Validation loss = 2.9374  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.0076  Validation loss = 2.9327  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.0061  Validation loss = 2.9298  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.0038  Validation loss = 2.9254  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.0025  Validation loss = 2.9227  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.0004  Validation loss = 2.9184  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 2.9991  Validation loss = 2.9157  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 2.9975  Validation loss = 2.9126  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 2.9946  Validation loss = 2.9064  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 2.9926  Validation loss = 2.9025  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 2.9900  Validation loss = 2.8971  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 2.9871  Validation loss = 2.8911  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 2.9849  Validation loss = 2.8867  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 2.9824  Validation loss = 2.8816  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 2.9796  Validation loss = 2.8759  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 2.9788  Validation loss = 2.8741  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 2.9759  Validation loss = 2.8680  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 2.9738  Validation loss = 2.8636  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 2.9717  Validation loss = 2.8593  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 2.9700  Validation loss = 2.8556  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 2.9677  Validation loss = 2.8506  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 2.9658  Validation loss = 2.8468  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 2.9640  Validation loss = 2.8431  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 2.9618  Validation loss = 2.8382  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 2.9592  Validation loss = 2.8327  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 2.9568  Validation loss = 2.8276  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 2.9550  Validation loss = 2.8238  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 2.9534  Validation loss = 2.8205  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 2.9511  Validation loss = 2.8156  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 2.9491  Validation loss = 2.8113  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 2.9469  Validation loss = 2.8068  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 2.9454  Validation loss = 2.8034  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 2.9437  Validation loss = 2.7999  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 2.9422  Validation loss = 2.7968  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 2.9409  Validation loss = 2.7938  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 2.9389  Validation loss = 2.7894  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 2.9376  Validation loss = 2.7866  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 2.9352  Validation loss = 2.7812  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 2.9334  Validation loss = 2.7773  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 2.9320  Validation loss = 2.7742  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 2.9300  Validation loss = 2.7699  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 2.9283  Validation loss = 2.7661  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 2.9267  Validation loss = 2.7625  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 2.9248  Validation loss = 2.7583  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 2.9235  Validation loss = 2.7554  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 2.9214  Validation loss = 2.7510  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 2.9198  Validation loss = 2.7473  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 2.9182  Validation loss = 2.7437  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 2.9166  Validation loss = 2.7400  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 2.9148  Validation loss = 2.7360  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 2.9136  Validation loss = 2.7333  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 2.9127  Validation loss = 2.7311  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 2.9109  Validation loss = 2.7272  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 2.9097  Validation loss = 2.7245  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 2.9083  Validation loss = 2.7213  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 2.9064  Validation loss = 2.7170  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 2.9048  Validation loss = 2.7135  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 2.9033  Validation loss = 2.7101  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 2.9016  Validation loss = 2.7063  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 2.8996  Validation loss = 2.7019  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 2.8982  Validation loss = 2.6985  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 2.8967  Validation loss = 2.6951  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 2.8943  Validation loss = 2.6894  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 2.8927  Validation loss = 2.6859  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 2.8911  Validation loss = 2.6823  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 2.8893  Validation loss = 2.6781  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 2.8875  Validation loss = 2.6741  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 2.8858  Validation loss = 2.6701  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 2.8844  Validation loss = 2.6668  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 2.8832  Validation loss = 2.6640  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 2.8814  Validation loss = 2.6599  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 2.8798  Validation loss = 2.6559  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 2.8781  Validation loss = 2.6520  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 2.8769  Validation loss = 2.6491  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 2.8755  Validation loss = 2.6458  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 2.8744  Validation loss = 2.6432  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 2.8729  Validation loss = 2.6397  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 2.8717  Validation loss = 2.6371  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 2.8704  Validation loss = 2.6340  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 2.8683  Validation loss = 2.6288  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 2.8663  Validation loss = 2.6242  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 2.8651  Validation loss = 2.6213  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 2.8634  Validation loss = 2.6170  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 2.8624  Validation loss = 2.6146  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 2.8608  Validation loss = 2.6106  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 2.8591  Validation loss = 2.6064  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 2.8584  Validation loss = 2.6047  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 2.8569  Validation loss = 2.6012  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 2.8558  Validation loss = 2.5982  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 2.8550  Validation loss = 2.5963  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 2.8539  Validation loss = 2.5936  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 2.8525  Validation loss = 2.5901  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 2.8513  Validation loss = 2.5873  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 2.8503  Validation loss = 2.5849  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 2.8486  Validation loss = 2.5805  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 2.8476  Validation loss = 2.5779  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 2.8459  Validation loss = 2.5737  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 2.8450  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 2.8440  Validation loss = 2.5688  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 2.8429  Validation loss = 2.5661  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 2.8419  Validation loss = 2.5637  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 2.8402  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 2.8386  Validation loss = 2.5551  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 2.8367  Validation loss = 2.5503  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 2.8354  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 2.8343  Validation loss = 2.5441  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 2.8332  Validation loss = 2.5412  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 2.8318  Validation loss = 2.5376  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 2.8307  Validation loss = 2.5346  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 2.8296  Validation loss = 2.5318  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 2.8284  Validation loss = 2.5288  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 2.8274  Validation loss = 2.5262  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 2.8258  Validation loss = 2.5219  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 2.8240  Validation loss = 2.5172  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 2.8224  Validation loss = 2.5131  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 2.8215  Validation loss = 2.5105  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 2.8204  Validation loss = 2.5078  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 2.8189  Validation loss = 2.5037  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 2.8165  Validation loss = 2.4975  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 2.8155  Validation loss = 2.4946  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 2.8152  Validation loss = 2.4938  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 2.8142  Validation loss = 2.4912  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 2.8131  Validation loss = 2.4882  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 2.8123  Validation loss = 2.4860  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 2.8113  Validation loss = 2.4835  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 2.8108  Validation loss = 2.4820  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 2.8097  Validation loss = 2.4791  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 2.8087  Validation loss = 2.4766  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 2.8082  Validation loss = 2.4751  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 2.8078  Validation loss = 2.4739  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 2.8070  Validation loss = 2.4717  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 2.8050  Validation loss = 2.4666  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 2.8036  Validation loss = 2.4626  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 2.8021  Validation loss = 2.4583  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 2.8008  Validation loss = 2.4548  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 2.7989  Validation loss = 2.4497  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 2.7976  Validation loss = 2.4460  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 2.7967  Validation loss = 2.4437  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 2.7961  Validation loss = 2.4422  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 2.7950  Validation loss = 2.4389  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 2.7940  Validation loss = 2.4359  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 2.7931  Validation loss = 2.4334  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 2.7914  Validation loss = 2.4287  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 2.7907  Validation loss = 2.4267  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 2.7894  Validation loss = 2.4232  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 2.7892  Validation loss = 2.4225  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 2.7887  Validation loss = 2.4211  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 2.7882  Validation loss = 2.4199  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 2.7878  Validation loss = 2.4187  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 2.7864  Validation loss = 2.4146  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 2.7856  Validation loss = 2.4125  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 2.7848  Validation loss = 2.4102  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 2.7830  Validation loss = 2.4049  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 2.7822  Validation loss = 2.4028  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 2.7812  Validation loss = 2.3999  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 2.7805  Validation loss = 2.3979  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 2.7789  Validation loss = 2.3932  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 2.7780  Validation loss = 2.3909  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 2.7776  Validation loss = 2.3897  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 2.7768  Validation loss = 2.3875  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 2.7766  Validation loss = 2.3867  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 2.7758  Validation loss = 2.3845  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 2.7750  Validation loss = 2.3823  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 2.7744  Validation loss = 2.3805  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 2.7735  Validation loss = 2.3779  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 2.7721  Validation loss = 2.3735  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 2.7715  Validation loss = 2.3717  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 2.7702  Validation loss = 2.3678  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 2.7693  Validation loss = 2.3650  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 2.7679  Validation loss = 2.3612  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 2.7672  Validation loss = 2.3590  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 2.7663  Validation loss = 2.3564  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 2.7656  Validation loss = 2.3542  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 2.7650  Validation loss = 2.3524  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 2.7635  Validation loss = 2.3480  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 2.7631  Validation loss = 2.3469  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 2.7617  Validation loss = 2.3425  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 2.7608  Validation loss = 2.3398  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 2.7598  Validation loss = 2.3364  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 2.7593  Validation loss = 2.3351  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 2.7582  Validation loss = 2.3314  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 2.7572  Validation loss = 2.3284  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 2.7568  Validation loss = 2.3272  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 2.7557  Validation loss = 2.3238  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 2.7546  Validation loss = 2.3203  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 2.7533  Validation loss = 2.3162  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 2.7528  Validation loss = 2.3147  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 2.7526  Validation loss = 2.3139  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 2.7519  Validation loss = 2.3118  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 2.7512  Validation loss = 2.3098  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 2.7506  Validation loss = 2.3077  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 2.7497  Validation loss = 2.3048  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 2.7489  Validation loss = 2.3022  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 2.7485  Validation loss = 2.3012  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 2.7481  Validation loss = 2.3000  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 2.7477  Validation loss = 2.2989  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 2.7469  Validation loss = 2.2962  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 2.7462  Validation loss = 2.2942  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 2.7452  Validation loss = 2.2910  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 2.7442  Validation loss = 2.2877  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 2.7432  Validation loss = 2.2846  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 2.7420  Validation loss = 2.2807  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 2.7415  Validation loss = 2.2789  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 2.7410  Validation loss = 2.2773  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 2.7401  Validation loss = 2.2743  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 2.7396  Validation loss = 2.2724  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 2.7393  Validation loss = 2.2717  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 2.7392  Validation loss = 2.2714  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 2.7388  Validation loss = 2.2702  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 2.7382  Validation loss = 2.2683  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 2.7379  Validation loss = 2.2674  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 2.7374  Validation loss = 2.2655  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 2.7364  Validation loss = 2.2624  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 2.7350  Validation loss = 2.2574  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 2.7349  Validation loss = 2.2572  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 2.7345  Validation loss = 2.2556  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 2.7339  Validation loss = 2.2540  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 2.7335  Validation loss = 2.2528  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 2.7328  Validation loss = 2.2503  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 2.7321  Validation loss = 2.2478  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 2.7314  Validation loss = 2.2455  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 2.7309  Validation loss = 2.2436  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 2.7301  Validation loss = 2.2411  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 2.7299  Validation loss = 2.2402  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 2.7295  Validation loss = 2.2389  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 2.7287  Validation loss = 2.2360  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 2.7281  Validation loss = 2.2339  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 2.7273  Validation loss = 2.2310  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 2.7258  Validation loss = 2.2259  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 2.7249  Validation loss = 2.2228  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 2.7235  Validation loss = 2.2181  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 2.7227  Validation loss = 2.2153  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 2.7223  Validation loss = 2.2139  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 2.7218  Validation loss = 2.2122  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 2.7213  Validation loss = 2.2102  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 2.7206  Validation loss = 2.2081  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 2.7201  Validation loss = 2.2064  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 2.7193  Validation loss = 2.2034  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 2.7189  Validation loss = 2.2018  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 2.7182  Validation loss = 2.1994  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 2.7178  Validation loss = 2.1978  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 2.7176  Validation loss = 2.1975  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 2.7169  Validation loss = 2.1947  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 2.7163  Validation loss = 2.1928  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 2.7162  Validation loss = 2.1923  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 2.7160  Validation loss = 2.1916  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 2.7158  Validation loss = 2.1909  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 2.7152  Validation loss = 2.1890  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 2.7148  Validation loss = 2.1876  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 2.7142  Validation loss = 2.1854  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 2.7138  Validation loss = 2.1837  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 2.7134  Validation loss = 2.1823  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 2.7123  Validation loss = 2.1781  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 2.7119  Validation loss = 2.1769  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 2.7109  Validation loss = 2.1730  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 2.7106  Validation loss = 2.1719  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 2.7105  Validation loss = 2.1713  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 2.7097  Validation loss = 2.1686  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 2.7090  Validation loss = 2.1660  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 2.7086  Validation loss = 2.1643  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 2.7081  Validation loss = 2.1625  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 2.7074  Validation loss = 2.1601  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 2.7069  Validation loss = 2.1582  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 2.7062  Validation loss = 2.1553  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 2.7057  Validation loss = 2.1534  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 2.7053  Validation loss = 2.1520  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 2.7046  Validation loss = 2.1493  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 2.7037  Validation loss = 2.1457  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 2.7035  Validation loss = 2.1452  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 2.7032  Validation loss = 2.1441  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 2.7031  Validation loss = 2.1437  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 2.7024  Validation loss = 2.1411  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 2.7019  Validation loss = 2.1389  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 2.7014  Validation loss = 2.1369  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 2.7008  Validation loss = 2.1345  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 2.7001  Validation loss = 2.1319  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 2.6996  Validation loss = 2.1300  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 2.6990  Validation loss = 2.1275  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 2.6986  Validation loss = 2.1260  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 2.6981  Validation loss = 2.1244  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 2.6973  Validation loss = 2.1214  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 2.6969  Validation loss = 2.1195  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 2.6967  Validation loss = 2.1190  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 2.6964  Validation loss = 2.1180  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 2.6962  Validation loss = 2.1171  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 2.6959  Validation loss = 2.1159  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 2.6955  Validation loss = 2.1143  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 2.6948  Validation loss = 2.1117  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 2.6943  Validation loss = 2.1097  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 2.6938  Validation loss = 2.1077  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 2.6937  Validation loss = 2.1072  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 2.6934  Validation loss = 2.1061  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 2.6928  Validation loss = 2.1036  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 2.6926  Validation loss = 2.1030  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 2.6922  Validation loss = 2.1014  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 2.6920  Validation loss = 2.1007  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 2.6916  Validation loss = 2.0992  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 2.6916  Validation loss = 2.0988  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 2.6904  Validation loss = 2.0942  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 2.6900  Validation loss = 2.0925  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 2.6899  Validation loss = 2.0923  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 2.6898  Validation loss = 2.0917  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 2.6892  Validation loss = 2.0892  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 2.6882  Validation loss = 2.0851  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 2.6880  Validation loss = 2.0845  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 2.6875  Validation loss = 2.0825  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 2.6873  Validation loss = 2.0817  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 2.6873  Validation loss = 2.0817  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 2.6871  Validation loss = 2.0806  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 2.6866  Validation loss = 2.0788  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 2.6862  Validation loss = 2.0770  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 2.6861  Validation loss = 2.0769  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 2.6858  Validation loss = 2.0753  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 2.6847  Validation loss = 2.0708  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 2.6840  Validation loss = 2.0676  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 2.6832  Validation loss = 2.0641  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 2.6828  Validation loss = 2.0627  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 2.6826  Validation loss = 2.0617  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 2.6824  Validation loss = 2.0607  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 2.6823  Validation loss = 2.0602  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 2.6818  Validation loss = 2.0582  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 2.6809  Validation loss = 2.0542  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 2.6804  Validation loss = 2.0519  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 2.6801  Validation loss = 2.0505  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 2.6796  Validation loss = 2.0485  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 2.6795  Validation loss = 2.0478  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 2.6795  Validation loss = 2.0479  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 2.6788  Validation loss = 2.0449  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 2.6785  Validation loss = 2.0437  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 2.6780  Validation loss = 2.0413  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 2.6778  Validation loss = 2.0406  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 2.6772  Validation loss = 2.0381  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 2.6765  Validation loss = 2.0349  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 2.6759  Validation loss = 2.0322  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 2.6752  Validation loss = 2.0290  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 2.6747  Validation loss = 2.0268  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 2.6745  Validation loss = 2.0257  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 2.6740  Validation loss = 2.0234  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 2.6738  Validation loss = 2.0223  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 2.6732  Validation loss = 2.0198  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 2.6728  Validation loss = 2.0181  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 2.6726  Validation loss = 2.0173  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 2.6720  Validation loss = 2.0146  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 2.6717  Validation loss = 2.0131  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 2.6713  Validation loss = 2.0110  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 2.6710  Validation loss = 2.0096  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 2.6709  Validation loss = 2.0094  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 2.6708  Validation loss = 2.0086  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 2.6704  Validation loss = 2.0070  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 2.6701  Validation loss = 2.0057  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 2.6699  Validation loss = 2.0046  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 2.6696  Validation loss = 2.0033  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 2.6693  Validation loss = 2.0017  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 2.6691  Validation loss = 2.0008  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 2.6689  Validation loss = 1.9998  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 2.6688  Validation loss = 1.9995  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 2.6683  Validation loss = 1.9971  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 2.6678  Validation loss = 1.9948  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 2.6674  Validation loss = 1.9927  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 2.6672  Validation loss = 1.9919  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 2.6669  Validation loss = 1.9905  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 2.6667  Validation loss = 1.9895  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 2.6662  Validation loss = 1.9869  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 2.6660  Validation loss = 1.9859  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 2.6657  Validation loss = 1.9846  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 2.6654  Validation loss = 1.9831  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 2.6652  Validation loss = 1.9818  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 2.6648  Validation loss = 1.9799  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 2.6644  Validation loss = 1.9778  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 2.6640  Validation loss = 1.9761  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 2.6642  Validation loss = 1.9769  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 2.6641  Validation loss = 1.9769  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 2.6639  Validation loss = 1.9756  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 2.6633  Validation loss = 1.9727  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 2.6631  Validation loss = 1.9717  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 2.6625  Validation loss = 1.9687  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 2.6622  Validation loss = 1.9672  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 2.6620  Validation loss = 1.9664  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 2.6615  Validation loss = 1.9640  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 2.6608  Validation loss = 1.9602  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 2.6603  Validation loss = 1.9578  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 2.6601  Validation loss = 1.9566  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 2.6596  Validation loss = 1.9543  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 2.6596  Validation loss = 1.9538  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 2.6593  Validation loss = 1.9528  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 2.6590  Validation loss = 1.9510  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 2.6586  Validation loss = 1.9490  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 2.6584  Validation loss = 1.9479  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 2.6581  Validation loss = 1.9462  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.5576  Validation loss = 2.0958  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.5570  Validation loss = 2.0937  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.5563  Validation loss = 2.0913  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.5560  Validation loss = 2.0904  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.5557  Validation loss = 2.0896  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.5556  Validation loss = 2.0892  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.5555  Validation loss = 2.0888  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.5550  Validation loss = 2.0873  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.5545  Validation loss = 2.0857  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.5540  Validation loss = 2.0839  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.5538  Validation loss = 2.0834  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.5535  Validation loss = 2.0823  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.5534  Validation loss = 2.0821  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.5529  Validation loss = 2.0806  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.5524  Validation loss = 2.0790  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.5519  Validation loss = 2.0772  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.5513  Validation loss = 2.0751  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.5508  Validation loss = 2.0737  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.5507  Validation loss = 2.0730  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.5505  Validation loss = 2.0725  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.5503  Validation loss = 2.0717  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.5502  Validation loss = 2.0715  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.5496  Validation loss = 2.0696  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.5492  Validation loss = 2.0681  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.5492  Validation loss = 2.0681  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.5487  Validation loss = 2.0666  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.5482  Validation loss = 2.0649  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.5482  Validation loss = 2.0648  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.5482  Validation loss = 2.0647  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.5480  Validation loss = 2.0643  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.5476  Validation loss = 2.0628  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.5476  Validation loss = 2.0627  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.5473  Validation loss = 2.0619  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.5473  Validation loss = 2.0618  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.5473  Validation loss = 2.0617  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.5472  Validation loss = 2.0616  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.5468  Validation loss = 2.0602  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.5468  Validation loss = 2.0601  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.5465  Validation loss = 2.0594  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.5464  Validation loss = 2.0590  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.5459  Validation loss = 2.0572  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.5455  Validation loss = 2.0557  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.5454  Validation loss = 2.0555  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.5450  Validation loss = 2.0539  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.5445  Validation loss = 2.0519  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.5441  Validation loss = 2.0506  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.5439  Validation loss = 2.0498  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.5438  Validation loss = 2.0496  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.5435  Validation loss = 2.0484  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.5431  Validation loss = 2.0470  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.5428  Validation loss = 2.0461  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.5428  Validation loss = 2.0461  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.5424  Validation loss = 2.0443  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.5416  Validation loss = 2.0412  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.5413  Validation loss = 2.0402  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.5411  Validation loss = 2.0392  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.5409  Validation loss = 2.0385  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.5405  Validation loss = 2.0372  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.5402  Validation loss = 2.0362  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.5403  Validation loss = 2.0363  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.5397  Validation loss = 2.0343  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.5396  Validation loss = 2.0342  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.5392  Validation loss = 2.0330  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.5389  Validation loss = 2.0319  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.5389  Validation loss = 2.0318  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.5383  Validation loss = 2.0296  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.5379  Validation loss = 2.0285  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.5377  Validation loss = 2.0274  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.5375  Validation loss = 2.0267  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.5372  Validation loss = 2.0255  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.5370  Validation loss = 2.0250  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.5366  Validation loss = 2.0234  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.5361  Validation loss = 2.0218  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.5357  Validation loss = 2.0204  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.5355  Validation loss = 2.0197  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.5352  Validation loss = 2.0183  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.5348  Validation loss = 2.0167  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.5345  Validation loss = 2.0157  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.5345  Validation loss = 2.0159  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.5346  Validation loss = 2.0163  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.5348  Validation loss = 2.0172  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.5348  Validation loss = 2.0172  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.5345  Validation loss = 2.0158  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.5344  Validation loss = 2.0154  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.5340  Validation loss = 2.0137  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.5334  Validation loss = 2.0116  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.5332  Validation loss = 2.0107  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.5326  Validation loss = 2.0087  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.5323  Validation loss = 2.0073  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.5319  Validation loss = 2.0052  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.5316  Validation loss = 2.0042  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.5313  Validation loss = 2.0030  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.5313  Validation loss = 2.0033  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.5308  Validation loss = 2.0013  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.5305  Validation loss = 2.0000  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.5301  Validation loss = 1.9985  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.5296  Validation loss = 1.9965  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.5295  Validation loss = 1.9959  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.5293  Validation loss = 1.9953  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.5293  Validation loss = 1.9954  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.5293  Validation loss = 1.9951  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.5290  Validation loss = 1.9942  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.5290  Validation loss = 1.9940  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.5289  Validation loss = 1.9940  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.5288  Validation loss = 1.9932  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.5284  Validation loss = 1.9919  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.5282  Validation loss = 1.9913  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.5281  Validation loss = 1.9908  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.5280  Validation loss = 1.9903  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.5277  Validation loss = 1.9894  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.5276  Validation loss = 1.9892  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.5276  Validation loss = 1.9888  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.5275  Validation loss = 1.9887  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.5273  Validation loss = 1.9879  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.5271  Validation loss = 1.9868  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.5266  Validation loss = 1.9850  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.5265  Validation loss = 1.9844  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.5262  Validation loss = 1.9833  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.5257  Validation loss = 1.9810  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.5257  Validation loss = 1.9812  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.5255  Validation loss = 1.9804  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.5254  Validation loss = 1.9800  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.5255  Validation loss = 1.9803  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.5253  Validation loss = 1.9797  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.5252  Validation loss = 1.9789  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.5249  Validation loss = 1.9776  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.5248  Validation loss = 1.9774  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.5248  Validation loss = 1.9778  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.5247  Validation loss = 1.9771  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.5245  Validation loss = 1.9766  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.5245  Validation loss = 1.9765  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.5244  Validation loss = 1.9759  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.5242  Validation loss = 1.9750  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.5240  Validation loss = 1.9742  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.5238  Validation loss = 1.9733  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.5236  Validation loss = 1.9728  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.5233  Validation loss = 1.9714  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.5233  Validation loss = 1.9715  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.5232  Validation loss = 1.9708  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.5229  Validation loss = 1.9698  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.5228  Validation loss = 1.9692  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.5226  Validation loss = 1.9684  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.5222  Validation loss = 1.9666  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.5220  Validation loss = 1.9657  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.5218  Validation loss = 1.9650  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.5217  Validation loss = 1.9645  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.5214  Validation loss = 1.9629  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.5212  Validation loss = 1.9623  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.5211  Validation loss = 1.9621  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.5210  Validation loss = 1.9617  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.5209  Validation loss = 1.9611  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.5209  Validation loss = 1.9612  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.5208  Validation loss = 1.9605  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.5207  Validation loss = 1.9602  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.5207  Validation loss = 1.9606  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.5208  Validation loss = 1.9610  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.5206  Validation loss = 1.9601  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.5206  Validation loss = 1.9601  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.5205  Validation loss = 1.9602  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.5202  Validation loss = 1.9590  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.5201  Validation loss = 1.9584  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.5200  Validation loss = 1.9583  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.5198  Validation loss = 1.9573  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.5198  Validation loss = 1.9572  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.5196  Validation loss = 1.9566  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.5195  Validation loss = 1.9561  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.5195  Validation loss = 1.9561  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.5193  Validation loss = 1.9554  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.5193  Validation loss = 1.9553  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.5193  Validation loss = 1.9554  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.5192  Validation loss = 1.9552  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.5192  Validation loss = 1.9550  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.5191  Validation loss = 1.9550  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.5188  Validation loss = 1.9538  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.5184  Validation loss = 1.9524  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.5183  Validation loss = 1.9521  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.5180  Validation loss = 1.9507  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.5179  Validation loss = 1.9501  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.5176  Validation loss = 1.9491  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.5173  Validation loss = 1.9476  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.5173  Validation loss = 1.9479  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.5171  Validation loss = 1.9468  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.5170  Validation loss = 1.9467  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.5167  Validation loss = 1.9450  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.5166  Validation loss = 1.9443  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.5165  Validation loss = 1.9438  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.5164  Validation loss = 1.9433  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.5162  Validation loss = 1.9426  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.5162  Validation loss = 1.9426  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.5161  Validation loss = 1.9424  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.5159  Validation loss = 1.9415  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.5158  Validation loss = 1.9409  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.5155  Validation loss = 1.9394  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.5152  Validation loss = 1.9385  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.5151  Validation loss = 1.9379  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.5148  Validation loss = 1.9366  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.5145  Validation loss = 1.9351  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.5144  Validation loss = 1.9346  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.5142  Validation loss = 1.9337  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.5141  Validation loss = 1.9335  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.5137  Validation loss = 1.9316  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.5136  Validation loss = 1.9316  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.5137  Validation loss = 1.9317  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.5137  Validation loss = 1.9319  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.5137  Validation loss = 1.9318  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.5135  Validation loss = 1.9312  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.5135  Validation loss = 1.9310  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.5133  Validation loss = 1.9301  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.5133  Validation loss = 1.9302  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.5132  Validation loss = 1.9296  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.5129  Validation loss = 1.9281  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.5128  Validation loss = 1.9278  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.5126  Validation loss = 1.9268  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.5124  Validation loss = 1.9260  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.5122  Validation loss = 1.9244  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.5120  Validation loss = 1.9238  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.5116  Validation loss = 1.9220  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.5114  Validation loss = 1.9209  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.5114  Validation loss = 1.9214  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.5112  Validation loss = 1.9201  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.5111  Validation loss = 1.9197  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.5109  Validation loss = 1.9190  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.5106  Validation loss = 1.9174  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.5103  Validation loss = 1.9162  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.5103  Validation loss = 1.9164  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.5100  Validation loss = 1.9148  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.5099  Validation loss = 1.9144  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.5097  Validation loss = 1.9137  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.5097  Validation loss = 1.9139  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.5098  Validation loss = 1.9145  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.5096  Validation loss = 1.9137  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.5095  Validation loss = 1.9132  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.5094  Validation loss = 1.9130  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.5094  Validation loss = 1.9126  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.5092  Validation loss = 1.9119  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.5091  Validation loss = 1.9116  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.5090  Validation loss = 1.9113  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.5088  Validation loss = 1.9103  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.5087  Validation loss = 1.9096  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.5084  Validation loss = 1.9081  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.5083  Validation loss = 1.9072  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.5082  Validation loss = 1.9066  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.5080  Validation loss = 1.9060  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.5079  Validation loss = 1.9050  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.5075  Validation loss = 1.9033  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.5074  Validation loss = 1.9026  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.5073  Validation loss = 1.9024  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.5073  Validation loss = 1.9023  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.5073  Validation loss = 1.9028  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.5071  Validation loss = 1.9017  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.5070  Validation loss = 1.9011  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.5070  Validation loss = 1.9015  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.5071  Validation loss = 1.9020  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.5068  Validation loss = 1.9003  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.5066  Validation loss = 1.8993  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.5065  Validation loss = 1.8991  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.5064  Validation loss = 1.8985  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.5064  Validation loss = 1.8985  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.5063  Validation loss = 1.8978  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.5062  Validation loss = 1.8976  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.5063  Validation loss = 1.8980  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.5062  Validation loss = 1.8977  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.5061  Validation loss = 1.8973  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.5059  Validation loss = 1.8961  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.5058  Validation loss = 1.8960  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.5055  Validation loss = 1.8941  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.5054  Validation loss = 1.8936  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.5052  Validation loss = 1.8927  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.5052  Validation loss = 1.8931  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.5052  Validation loss = 1.8927  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.5051  Validation loss = 1.8918  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.5051  Validation loss = 1.8924  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.5051  Validation loss = 1.8922  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.5050  Validation loss = 1.8917  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.5050  Validation loss = 1.8916  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.5049  Validation loss = 1.8913  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.5049  Validation loss = 1.8916  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.5050  Validation loss = 1.8923  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.5050  Validation loss = 1.8926  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.5049  Validation loss = 1.8924  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.5048  Validation loss = 1.8923  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.5049  Validation loss = 1.8931  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 276  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.4970  Validation loss = 2.7335  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.4969  Validation loss = 2.7336  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.4968  Validation loss = 2.7338  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.4967  Validation loss = 2.7345  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.4966  Validation loss = 2.7347  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.4965  Validation loss = 2.7341  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.4964  Validation loss = 2.7329  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.4964  Validation loss = 2.7337  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.4963  Validation loss = 2.7330  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.4962  Validation loss = 2.7334  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.4961  Validation loss = 2.7335  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.4960  Validation loss = 2.7335  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.4959  Validation loss = 2.7328  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.4958  Validation loss = 2.7322  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.4957  Validation loss = 2.7332  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.4956  Validation loss = 2.7335  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.4954  Validation loss = 2.7344  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 14  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.5521  Validation loss = 3.8941  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.5520  Validation loss = 3.8939  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.5518  Validation loss = 3.8921  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.5517  Validation loss = 3.8918  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.5516  Validation loss = 3.8917  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.5514  Validation loss = 3.8902  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.5514  Validation loss = 3.8912  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.5513  Validation loss = 3.8906  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.5512  Validation loss = 3.8900  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.5510  Validation loss = 3.8892  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.5508  Validation loss = 3.8888  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.5507  Validation loss = 3.8887  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.5506  Validation loss = 3.8881  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.5506  Validation loss = 3.8884  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.5505  Validation loss = 3.8896  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.5505  Validation loss = 3.8896  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.5504  Validation loss = 3.8897  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.5503  Validation loss = 3.8899  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.5501  Validation loss = 3.8887  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.5500  Validation loss = 3.8883  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.5498  Validation loss = 3.8870  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.5496  Validation loss = 3.8858  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.5495  Validation loss = 3.8860  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.5494  Validation loss = 3.8856  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.5494  Validation loss = 3.8856  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.5493  Validation loss = 3.8853  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.5490  Validation loss = 3.8841  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.5489  Validation loss = 3.8844  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.5488  Validation loss = 3.8837  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.5487  Validation loss = 3.8831  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.5486  Validation loss = 3.8818  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.5485  Validation loss = 3.8816  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.5483  Validation loss = 3.8808  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.5481  Validation loss = 3.8795  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.5480  Validation loss = 3.8791  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.5478  Validation loss = 3.8775  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.5477  Validation loss = 3.8772  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.5476  Validation loss = 3.8775  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.5475  Validation loss = 3.8773  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.5475  Validation loss = 3.8772  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.5474  Validation loss = 3.8765  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.5473  Validation loss = 3.8764  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.5471  Validation loss = 3.8746  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.5470  Validation loss = 3.8742  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.5468  Validation loss = 3.8734  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.5467  Validation loss = 3.8724  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.5465  Validation loss = 3.8724  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.5464  Validation loss = 3.8721  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.5462  Validation loss = 3.8712  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.5461  Validation loss = 3.8703  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.5459  Validation loss = 3.8684  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.5458  Validation loss = 3.8678  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.5456  Validation loss = 3.8666  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.5455  Validation loss = 3.8655  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.5453  Validation loss = 3.8651  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.5452  Validation loss = 3.8650  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.5451  Validation loss = 3.8647  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.5450  Validation loss = 3.8639  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.5449  Validation loss = 3.8642  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.5448  Validation loss = 3.8639  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.5447  Validation loss = 3.8627  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.5446  Validation loss = 3.8626  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.5446  Validation loss = 3.8632  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.5444  Validation loss = 3.8624  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.5443  Validation loss = 3.8622  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.5442  Validation loss = 3.8612  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.5441  Validation loss = 3.8610  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.5440  Validation loss = 3.8604  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.5438  Validation loss = 3.8590  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.5437  Validation loss = 3.8591  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.5436  Validation loss = 3.8584  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.5435  Validation loss = 3.8584  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.5434  Validation loss = 3.8580  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.5432  Validation loss = 3.8584  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.5431  Validation loss = 3.8577  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.5430  Validation loss = 3.8578  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.5429  Validation loss = 3.8565  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.5428  Validation loss = 3.8560  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.5427  Validation loss = 3.8553  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.5427  Validation loss = 3.8549  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.5427  Validation loss = 3.8556  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.5426  Validation loss = 3.8550  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.5425  Validation loss = 3.8554  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.5424  Validation loss = 3.8558  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.5424  Validation loss = 3.8561  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.5423  Validation loss = 3.8560  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.5422  Validation loss = 3.8556  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.5421  Validation loss = 3.8553  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.5420  Validation loss = 3.8555  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.5419  Validation loss = 3.8551  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.5417  Validation loss = 3.8539  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.5416  Validation loss = 3.8543  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.5415  Validation loss = 3.8539  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.5415  Validation loss = 3.8541  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.5414  Validation loss = 3.8534  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.5413  Validation loss = 3.8531  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.5411  Validation loss = 3.8525  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.5411  Validation loss = 3.8530  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.5410  Validation loss = 3.8525  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.5408  Validation loss = 3.8513  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.5406  Validation loss = 3.8500  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.5405  Validation loss = 3.8493  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.5404  Validation loss = 3.8489  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.5403  Validation loss = 3.8487  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.5402  Validation loss = 3.8484  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.5401  Validation loss = 3.8483  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.5400  Validation loss = 3.8482  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.5399  Validation loss = 3.8477  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.5397  Validation loss = 3.8469  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.5396  Validation loss = 3.8470  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.5394  Validation loss = 3.8451  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.5393  Validation loss = 3.8439  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.5392  Validation loss = 3.8432  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.5391  Validation loss = 3.8422  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.5390  Validation loss = 3.8422  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.5390  Validation loss = 3.8430  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.5389  Validation loss = 3.8443  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.5388  Validation loss = 3.8430  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.5387  Validation loss = 3.8417  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.5386  Validation loss = 3.8411  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.5385  Validation loss = 3.8413  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.5384  Validation loss = 3.8413  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.5383  Validation loss = 3.8409  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.5381  Validation loss = 3.8401  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.5381  Validation loss = 3.8401  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.5380  Validation loss = 3.8393  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.5378  Validation loss = 3.8385  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.5377  Validation loss = 3.8379  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.5376  Validation loss = 3.8373  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.5375  Validation loss = 3.8360  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.5374  Validation loss = 3.8357  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.5373  Validation loss = 3.8349  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.5372  Validation loss = 3.8348  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.5371  Validation loss = 3.8343  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.5369  Validation loss = 3.8329  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.5368  Validation loss = 3.8335  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.5367  Validation loss = 3.8339  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.5366  Validation loss = 3.8321  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.5364  Validation loss = 3.8316  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.5363  Validation loss = 3.8315  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.5362  Validation loss = 3.8301  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.5361  Validation loss = 3.8298  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.5360  Validation loss = 3.8303  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.5359  Validation loss = 3.8299  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.5358  Validation loss = 3.8302  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.5357  Validation loss = 3.8294  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.5356  Validation loss = 3.8291  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.5355  Validation loss = 3.8284  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.5354  Validation loss = 3.8285  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.5354  Validation loss = 3.8281  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.5352  Validation loss = 3.8269  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.5351  Validation loss = 3.8274  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.5350  Validation loss = 3.8268  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.5349  Validation loss = 3.8263  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.5349  Validation loss = 3.8271  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.5348  Validation loss = 3.8271  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.5346  Validation loss = 3.8271  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.5345  Validation loss = 3.8250  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.5345  Validation loss = 3.8260  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.5344  Validation loss = 3.8261  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.5343  Validation loss = 3.8263  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.5342  Validation loss = 3.8267  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.5340  Validation loss = 3.8259  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.5338  Validation loss = 3.8240  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.5337  Validation loss = 3.8232  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.5336  Validation loss = 3.8224  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.5335  Validation loss = 3.8225  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.5334  Validation loss = 3.8228  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.5333  Validation loss = 3.8231  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.5332  Validation loss = 3.8225  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.5332  Validation loss = 3.8223  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.5331  Validation loss = 3.8213  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.5329  Validation loss = 3.8204  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.5329  Validation loss = 3.8205  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.5328  Validation loss = 3.8198  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.5327  Validation loss = 3.8196  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.5325  Validation loss = 3.8179  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.5324  Validation loss = 3.8173  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.5323  Validation loss = 3.8161  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.5322  Validation loss = 3.8155  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.5321  Validation loss = 3.8152  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.5320  Validation loss = 3.8142  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.5319  Validation loss = 3.8147  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.5318  Validation loss = 3.8138  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.5317  Validation loss = 3.8143  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.5315  Validation loss = 3.8128  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.5314  Validation loss = 3.8127  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.5313  Validation loss = 3.8124  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.5312  Validation loss = 3.8125  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.5311  Validation loss = 3.8120  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.5309  Validation loss = 3.8107  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.5308  Validation loss = 3.8106  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.5307  Validation loss = 3.8096  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.5306  Validation loss = 3.8102  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.5305  Validation loss = 3.8097  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.5304  Validation loss = 3.8103  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.5303  Validation loss = 3.8090  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.5302  Validation loss = 3.8086  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.5300  Validation loss = 3.8083  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.5300  Validation loss = 3.8085  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.5299  Validation loss = 3.8084  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.5298  Validation loss = 3.8076  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.5297  Validation loss = 3.8073  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.5296  Validation loss = 3.8074  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.5295  Validation loss = 3.8070  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.5294  Validation loss = 3.8060  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.5293  Validation loss = 3.8058  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.5292  Validation loss = 3.8059  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.5290  Validation loss = 3.8052  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.5289  Validation loss = 3.8043  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.5288  Validation loss = 3.8044  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.5288  Validation loss = 3.8051  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.5286  Validation loss = 3.8043  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.5285  Validation loss = 3.8043  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.5284  Validation loss = 3.8034  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.5283  Validation loss = 3.8028  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.5282  Validation loss = 3.8026  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.5280  Validation loss = 3.8014  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.5279  Validation loss = 3.8014  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.5277  Validation loss = 3.8007  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.5276  Validation loss = 3.8002  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.5275  Validation loss = 3.7999  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.5275  Validation loss = 3.8008  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.5274  Validation loss = 3.8009  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.5273  Validation loss = 3.8014  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.5273  Validation loss = 3.8016  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.5271  Validation loss = 3.8008  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.5269  Validation loss = 3.7996  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.5268  Validation loss = 3.7986  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.5267  Validation loss = 3.7976  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.5266  Validation loss = 3.7973  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.5266  Validation loss = 3.7978  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.5265  Validation loss = 3.7966  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.5264  Validation loss = 3.7953  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.5262  Validation loss = 3.7941  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.5261  Validation loss = 3.7949  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.5261  Validation loss = 3.7956  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.5260  Validation loss = 3.7952  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.5259  Validation loss = 3.7942  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.5258  Validation loss = 3.7946  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.5257  Validation loss = 3.7935  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.5255  Validation loss = 3.7913  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.5254  Validation loss = 3.7911  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.5253  Validation loss = 3.7903  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.5252  Validation loss = 3.7903  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.5251  Validation loss = 3.7898  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.5249  Validation loss = 3.7892  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.5248  Validation loss = 3.7887  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.5248  Validation loss = 3.7895  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.5247  Validation loss = 3.7889  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.5246  Validation loss = 3.7879  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.5245  Validation loss = 3.7876  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.5244  Validation loss = 3.7873  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.5243  Validation loss = 3.7869  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.5242  Validation loss = 3.7868  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.5241  Validation loss = 3.7856  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.5240  Validation loss = 3.7858  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.5239  Validation loss = 3.7858  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.5238  Validation loss = 3.7859  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.5237  Validation loss = 3.7842  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.5236  Validation loss = 3.7838  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.5235  Validation loss = 3.7836  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.5234  Validation loss = 3.7837  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.5234  Validation loss = 3.7833  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.5233  Validation loss = 3.7830  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.5232  Validation loss = 3.7828  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.5231  Validation loss = 3.7831  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.5230  Validation loss = 3.7834  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.5229  Validation loss = 3.7829  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.5228  Validation loss = 3.7831  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.5227  Validation loss = 3.7824  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.5226  Validation loss = 3.7813  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.5224  Validation loss = 3.7811  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.5223  Validation loss = 3.7802  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.5223  Validation loss = 3.7802  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.5221  Validation loss = 3.7797  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.5221  Validation loss = 3.7790  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.5220  Validation loss = 3.7777  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.5220  Validation loss = 3.7782  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.5219  Validation loss = 3.7770  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.5218  Validation loss = 3.7765  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.5216  Validation loss = 3.7758  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.5216  Validation loss = 3.7755  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.5215  Validation loss = 3.7758  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.5214  Validation loss = 3.7755  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.5212  Validation loss = 3.7747  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.5212  Validation loss = 3.7750  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.5210  Validation loss = 3.7732  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.5209  Validation loss = 3.7725  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.5208  Validation loss = 3.7719  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.5206  Validation loss = 3.7702  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.5206  Validation loss = 3.7705  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.5205  Validation loss = 3.7708  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.5203  Validation loss = 3.7693  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.5201  Validation loss = 3.7676  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.5201  Validation loss = 3.7672  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.5199  Validation loss = 3.7651  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.5198  Validation loss = 3.7653  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.5198  Validation loss = 3.7653  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.5196  Validation loss = 3.7638  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.5195  Validation loss = 3.7630  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.5194  Validation loss = 3.7630  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.5193  Validation loss = 3.7622  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.5192  Validation loss = 3.7619  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.5191  Validation loss = 3.7609  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.5190  Validation loss = 3.7605  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.5189  Validation loss = 3.7611  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.5188  Validation loss = 3.7600  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.5187  Validation loss = 3.7593  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.5186  Validation loss = 3.7586  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.5185  Validation loss = 3.7585  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.5184  Validation loss = 3.7581  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.5183  Validation loss = 3.7571  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.5182  Validation loss = 3.7564  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.5181  Validation loss = 3.7566  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.5180  Validation loss = 3.7557  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.5179  Validation loss = 3.7543  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.5178  Validation loss = 3.7537  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.5178  Validation loss = 3.7541  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.5177  Validation loss = 3.7540  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.5176  Validation loss = 3.7540  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.5176  Validation loss = 3.7551  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.5174  Validation loss = 3.7540  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.5174  Validation loss = 3.7536  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.5172  Validation loss = 3.7531  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.5171  Validation loss = 3.7519  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.5170  Validation loss = 3.7518  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.5168  Validation loss = 3.7512  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.5167  Validation loss = 3.7509  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.5166  Validation loss = 3.7501  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.5165  Validation loss = 3.7497  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.5164  Validation loss = 3.7489  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.5163  Validation loss = 3.7488  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.5162  Validation loss = 3.7478  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.5161  Validation loss = 3.7469  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.5160  Validation loss = 3.7466  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.5159  Validation loss = 3.7460  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.5159  Validation loss = 3.7458  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.5158  Validation loss = 3.7464  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.5157  Validation loss = 3.7466  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.5157  Validation loss = 3.7473  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.5157  Validation loss = 3.7473  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.5155  Validation loss = 3.7461  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.5154  Validation loss = 3.7452  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.5154  Validation loss = 3.7452  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.5152  Validation loss = 3.7440  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.5151  Validation loss = 3.7431  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.5150  Validation loss = 3.7421  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.5149  Validation loss = 3.7410  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.5147  Validation loss = 3.7396  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.5145  Validation loss = 3.7389  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.5144  Validation loss = 3.7378  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.5143  Validation loss = 3.7371  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.5142  Validation loss = 3.7372  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.5141  Validation loss = 3.7365  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.5140  Validation loss = 3.7354  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.5138  Validation loss = 3.7344  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.5137  Validation loss = 3.7339  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.5137  Validation loss = 3.7337  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.5136  Validation loss = 3.7341  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.5135  Validation loss = 3.7328  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.5133  Validation loss = 3.7309  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.5132  Validation loss = 3.7308  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.5131  Validation loss = 3.7303  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.5130  Validation loss = 3.7293  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.5129  Validation loss = 3.7286  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.5128  Validation loss = 3.7278  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.5127  Validation loss = 3.7267  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.5126  Validation loss = 3.7262  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.5125  Validation loss = 3.7263  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.5124  Validation loss = 3.7257  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.5124  Validation loss = 3.7252  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.5122  Validation loss = 3.7237  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.5121  Validation loss = 3.7237  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.5120  Validation loss = 3.7236  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.5119  Validation loss = 3.7225  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.5117  Validation loss = 3.7222  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.5115  Validation loss = 3.7202  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.5114  Validation loss = 3.7199  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.5113  Validation loss = 3.7196  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.5112  Validation loss = 3.7193  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.5111  Validation loss = 3.7182  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.5110  Validation loss = 3.7178  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.5110  Validation loss = 3.7181  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.5109  Validation loss = 3.7171  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.5107  Validation loss = 3.7161  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.5106  Validation loss = 3.7151  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.5105  Validation loss = 3.7148  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.5104  Validation loss = 3.7143  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.5103  Validation loss = 3.7140  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.5102  Validation loss = 3.7140  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.5101  Validation loss = 3.7136  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.5100  Validation loss = 3.7133  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.5100  Validation loss = 3.7145  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.5099  Validation loss = 3.7145  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.5098  Validation loss = 3.7137  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.5096  Validation loss = 3.7124  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.5095  Validation loss = 3.7117  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.5094  Validation loss = 3.7116  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.5094  Validation loss = 3.7121  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.5093  Validation loss = 3.7117  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.5092  Validation loss = 3.7120  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.5091  Validation loss = 3.7120  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.5090  Validation loss = 3.7123  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.5090  Validation loss = 3.7124  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.5089  Validation loss = 3.7127  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 399  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.7179  Validation loss = 3.5112  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.7175  Validation loss = 3.5089  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.7170  Validation loss = 3.5064  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.7164  Validation loss = 3.5033  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.7160  Validation loss = 3.5017  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.7157  Validation loss = 3.5005  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.7154  Validation loss = 3.4992  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.7150  Validation loss = 3.4971  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.7146  Validation loss = 3.4952  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.7143  Validation loss = 3.4939  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.7138  Validation loss = 3.4921  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.7137  Validation loss = 3.4913  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.7134  Validation loss = 3.4901  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.7129  Validation loss = 3.4874  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.7125  Validation loss = 3.4858  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.7122  Validation loss = 3.4843  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.7119  Validation loss = 3.4831  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.7116  Validation loss = 3.4815  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.7112  Validation loss = 3.4799  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.7109  Validation loss = 3.4782  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.7105  Validation loss = 3.4765  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.7103  Validation loss = 3.4760  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.7100  Validation loss = 3.4745  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.7099  Validation loss = 3.4739  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.7096  Validation loss = 3.4727  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.7094  Validation loss = 3.4718  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.7092  Validation loss = 3.4710  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.7090  Validation loss = 3.4704  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.7087  Validation loss = 3.4691  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.7085  Validation loss = 3.4686  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.7081  Validation loss = 3.4666  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.7078  Validation loss = 3.4650  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.7075  Validation loss = 3.4640  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.7071  Validation loss = 3.4621  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.7069  Validation loss = 3.4616  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.7064  Validation loss = 3.4591  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.7059  Validation loss = 3.4567  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.7054  Validation loss = 3.4542  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.7049  Validation loss = 3.4520  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.7047  Validation loss = 3.4511  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.7041  Validation loss = 3.4480  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.7036  Validation loss = 3.4451  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.7031  Validation loss = 3.4425  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.7027  Validation loss = 3.4408  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.7023  Validation loss = 3.4387  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.7019  Validation loss = 3.4366  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.7016  Validation loss = 3.4353  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.7013  Validation loss = 3.4338  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.7010  Validation loss = 3.4323  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.7007  Validation loss = 3.4308  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.7003  Validation loss = 3.4288  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.7000  Validation loss = 3.4275  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.6996  Validation loss = 3.4251  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.6994  Validation loss = 3.4249  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.6992  Validation loss = 3.4245  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.6990  Validation loss = 3.4236  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.6989  Validation loss = 3.4233  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.6984  Validation loss = 3.4205  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.6981  Validation loss = 3.4193  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.6974  Validation loss = 3.4150  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.6970  Validation loss = 3.4127  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.6965  Validation loss = 3.4106  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 1.6961  Validation loss = 3.4079  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 1.6958  Validation loss = 3.4068  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 1.6955  Validation loss = 3.4048  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 1.6952  Validation loss = 3.4034  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 1.6948  Validation loss = 3.4019  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 1.6941  Validation loss = 3.3979  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 1.6941  Validation loss = 3.3981  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 1.6938  Validation loss = 3.3967  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 1.6932  Validation loss = 3.3936  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 1.6930  Validation loss = 3.3927  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 1.6926  Validation loss = 3.3905  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 1.6923  Validation loss = 3.3897  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 1.6921  Validation loss = 3.3889  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 1.6919  Validation loss = 3.3887  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 1.6914  Validation loss = 3.3858  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 1.6911  Validation loss = 3.3844  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 1.6906  Validation loss = 3.3818  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 1.6904  Validation loss = 3.3806  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 1.6900  Validation loss = 3.3789  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 1.6897  Validation loss = 3.3776  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 1.6894  Validation loss = 3.3754  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 1.6891  Validation loss = 3.3738  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 1.6889  Validation loss = 3.3731  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 1.6887  Validation loss = 3.3728  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 1.6883  Validation loss = 3.3704  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 1.6879  Validation loss = 3.3681  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 1.6876  Validation loss = 3.3666  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 1.6871  Validation loss = 3.3638  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 1.6869  Validation loss = 3.3628  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 1.6864  Validation loss = 3.3604  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 1.6859  Validation loss = 3.3572  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 1.6855  Validation loss = 3.3555  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 1.6850  Validation loss = 3.3530  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 1.6848  Validation loss = 3.3518  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 1.6845  Validation loss = 3.3509  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 1.6842  Validation loss = 3.3494  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 1.6838  Validation loss = 3.3471  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 1.6835  Validation loss = 3.3459  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 1.6832  Validation loss = 3.3443  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 1.6830  Validation loss = 3.3433  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 1.6825  Validation loss = 3.3408  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 1.6822  Validation loss = 3.3389  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 1.6817  Validation loss = 3.3359  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 1.6815  Validation loss = 3.3351  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 1.6813  Validation loss = 3.3343  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 1.6811  Validation loss = 3.3337  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 1.6810  Validation loss = 3.3334  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 1.6806  Validation loss = 3.3317  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 1.6803  Validation loss = 3.3305  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 1.6800  Validation loss = 3.3282  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 1.6797  Validation loss = 3.3270  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 1.6791  Validation loss = 3.3233  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 1.6787  Validation loss = 3.3211  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 1.6785  Validation loss = 3.3200  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 1.6782  Validation loss = 3.3184  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 1.6781  Validation loss = 3.3179  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 1.6777  Validation loss = 3.3158  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 1.6775  Validation loss = 3.3150  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 1.6771  Validation loss = 3.3127  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 1.6770  Validation loss = 3.3122  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 1.6767  Validation loss = 3.3114  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 1.6764  Validation loss = 3.3098  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 1.6762  Validation loss = 3.3090  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 1.6758  Validation loss = 3.3073  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 1.6753  Validation loss = 3.3037  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 1.6751  Validation loss = 3.3036  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 1.6747  Validation loss = 3.3011  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 1.6744  Validation loss = 3.2988  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 1.6742  Validation loss = 3.2984  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 1.6739  Validation loss = 3.2970  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 1.6736  Validation loss = 3.2955  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 1.6734  Validation loss = 3.2953  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 1.6730  Validation loss = 3.2924  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 1.6727  Validation loss = 3.2907  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 1.6724  Validation loss = 3.2888  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 1.6720  Validation loss = 3.2873  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 1.6717  Validation loss = 3.2853  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 1.6714  Validation loss = 3.2841  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 1.6712  Validation loss = 3.2825  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 1.6708  Validation loss = 3.2805  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 1.6705  Validation loss = 3.2788  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 1.6702  Validation loss = 3.2775  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 1.6701  Validation loss = 3.2776  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 1.6698  Validation loss = 3.2761  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 1.6696  Validation loss = 3.2753  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 1.6695  Validation loss = 3.2744  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 1.6693  Validation loss = 3.2737  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 1.6687  Validation loss = 3.2696  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 1.6682  Validation loss = 3.2662  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 1.6680  Validation loss = 3.2655  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 1.6679  Validation loss = 3.2654  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 1.6674  Validation loss = 3.2621  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 1.6671  Validation loss = 3.2608  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 1.6670  Validation loss = 3.2610  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 1.6668  Validation loss = 3.2605  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 1.6666  Validation loss = 3.2595  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 1.6664  Validation loss = 3.2590  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 1.6661  Validation loss = 3.2583  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 1.6658  Validation loss = 3.2569  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 1.6656  Validation loss = 3.2569  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 1.6656  Validation loss = 3.2566  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 1.6653  Validation loss = 3.2551  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 1.6650  Validation loss = 3.2540  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 1.6648  Validation loss = 3.2536  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 1.6646  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 1.6643  Validation loss = 3.2506  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 1.6641  Validation loss = 3.2499  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 1.6639  Validation loss = 3.2498  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 1.6637  Validation loss = 3.2487  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 1.6633  Validation loss = 3.2461  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 1.6630  Validation loss = 3.2446  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 1.6628  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 1.6624  Validation loss = 3.2407  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 1.6622  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 1.6620  Validation loss = 3.2393  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 1.6618  Validation loss = 3.2385  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 1.6616  Validation loss = 3.2385  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 1.6615  Validation loss = 3.2385  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 1.6611  Validation loss = 3.2364  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 1.6608  Validation loss = 3.2348  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 1.6605  Validation loss = 3.2330  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 1.6603  Validation loss = 3.2320  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 1.6600  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 1.6596  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 1.6594  Validation loss = 3.2270  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 1.6591  Validation loss = 3.2252  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 1.6587  Validation loss = 3.2224  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 1.6584  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 1.6582  Validation loss = 3.2198  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 1.6579  Validation loss = 3.2185  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 1.6577  Validation loss = 3.2178  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 1.6574  Validation loss = 3.2160  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 1.6571  Validation loss = 3.2149  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 1.6569  Validation loss = 3.2144  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 1.6568  Validation loss = 3.2138  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 1.6565  Validation loss = 3.2127  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 1.6562  Validation loss = 3.2112  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 1.6560  Validation loss = 3.2110  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 1.6558  Validation loss = 3.2097  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 1.6557  Validation loss = 3.2098  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 1.6556  Validation loss = 3.2098  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 1.6553  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 1.6551  Validation loss = 3.2075  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 1.6547  Validation loss = 3.2049  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 1.6543  Validation loss = 3.2027  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 1.6540  Validation loss = 3.2010  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 1.6538  Validation loss = 3.1999  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 1.6535  Validation loss = 3.1980  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 1.6531  Validation loss = 3.1963  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 1.6529  Validation loss = 3.1952  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 1.6528  Validation loss = 3.1955  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 1.6526  Validation loss = 3.1948  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 1.6524  Validation loss = 3.1936  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 1.6521  Validation loss = 3.1917  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 1.6519  Validation loss = 3.1904  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 1.6516  Validation loss = 3.1886  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 1.6515  Validation loss = 3.1881  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 1.6513  Validation loss = 3.1877  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 1.6511  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 1.6509  Validation loss = 3.1874  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 1.6507  Validation loss = 3.1864  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 1.6504  Validation loss = 3.1841  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 1.6500  Validation loss = 3.1823  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 1.6497  Validation loss = 3.1801  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 1.6493  Validation loss = 3.1779  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 1.6490  Validation loss = 3.1762  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 1.6488  Validation loss = 3.1754  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 1.6485  Validation loss = 3.1734  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 1.6483  Validation loss = 3.1727  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 1.6481  Validation loss = 3.1721  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 1.6478  Validation loss = 3.1705  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 1.6476  Validation loss = 3.1704  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 1.6475  Validation loss = 3.1712  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 1.6474  Validation loss = 3.1720  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 1.6471  Validation loss = 3.1702  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 1.6469  Validation loss = 3.1695  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 1.6467  Validation loss = 3.1678  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 1.6464  Validation loss = 3.1662  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 1.6462  Validation loss = 3.1654  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 1.6459  Validation loss = 3.1644  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 1.6457  Validation loss = 3.1632  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 1.6456  Validation loss = 3.1630  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 1.6454  Validation loss = 3.1617  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 1.6450  Validation loss = 3.1594  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 1.6447  Validation loss = 3.1580  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 1.6445  Validation loss = 3.1571  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 1.6442  Validation loss = 3.1544  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 1.6439  Validation loss = 3.1525  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 1.6435  Validation loss = 3.1507  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 1.6434  Validation loss = 3.1516  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 1.6431  Validation loss = 3.1492  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 1.6430  Validation loss = 3.1498  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 1.6427  Validation loss = 3.1483  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 1.6425  Validation loss = 3.1479  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 1.6423  Validation loss = 3.1477  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 1.6422  Validation loss = 3.1481  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 1.6420  Validation loss = 3.1473  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 1.6417  Validation loss = 3.1453  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 1.6413  Validation loss = 3.1422  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 1.6411  Validation loss = 3.1411  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 1.6408  Validation loss = 3.1396  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 1.6406  Validation loss = 3.1389  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 1.6405  Validation loss = 3.1386  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 1.6401  Validation loss = 3.1362  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 1.6399  Validation loss = 3.1360  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 1.6396  Validation loss = 3.1347  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 1.6394  Validation loss = 3.1341  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 1.6393  Validation loss = 3.1342  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 1.6390  Validation loss = 3.1332  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 1.6387  Validation loss = 3.1311  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 1.6384  Validation loss = 3.1291  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 1.6380  Validation loss = 3.1269  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 1.6379  Validation loss = 3.1264  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 1.6376  Validation loss = 3.1243  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 1.6375  Validation loss = 3.1240  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 1.6373  Validation loss = 3.1231  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 1.6369  Validation loss = 3.1210  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 1.6368  Validation loss = 3.1202  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 1.6364  Validation loss = 3.1176  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 1.6363  Validation loss = 3.1167  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 1.6360  Validation loss = 3.1155  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 1.6358  Validation loss = 3.1150  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 1.6356  Validation loss = 3.1144  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 1.6355  Validation loss = 3.1141  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 1.6352  Validation loss = 3.1127  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 1.6350  Validation loss = 3.1115  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 1.6349  Validation loss = 3.1121  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 1.6347  Validation loss = 3.1113  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 1.6345  Validation loss = 3.1114  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 1.6343  Validation loss = 3.1100  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 1.6342  Validation loss = 3.1106  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 1.6340  Validation loss = 3.1098  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 1.6338  Validation loss = 3.1090  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 1.6336  Validation loss = 3.1088  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 1.6335  Validation loss = 3.1092  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 1.6332  Validation loss = 3.1076  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 1.6331  Validation loss = 3.1075  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 1.6330  Validation loss = 3.1070  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 1.6328  Validation loss = 3.1060  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 1.6327  Validation loss = 3.1058  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 1.6323  Validation loss = 3.1037  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 1.6320  Validation loss = 3.1020  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 1.6317  Validation loss = 3.1007  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 1.6316  Validation loss = 3.1011  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 1.6313  Validation loss = 3.0994  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 1.6309  Validation loss = 3.0975  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 1.6307  Validation loss = 3.0962  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 1.6306  Validation loss = 3.0964  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 1.6303  Validation loss = 3.0953  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 1.6301  Validation loss = 3.0944  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 1.6299  Validation loss = 3.0927  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 1.6296  Validation loss = 3.0908  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 1.6293  Validation loss = 3.0891  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 1.6291  Validation loss = 3.0881  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 1.6289  Validation loss = 3.0866  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 1.6286  Validation loss = 3.0851  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 1.6285  Validation loss = 3.0840  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 1.6283  Validation loss = 3.0835  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 1.6280  Validation loss = 3.0812  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 1.6279  Validation loss = 3.0807  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 1.6278  Validation loss = 3.0809  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 1.6275  Validation loss = 3.0803  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 1.6273  Validation loss = 3.0794  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 1.6270  Validation loss = 3.0787  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 1.6267  Validation loss = 3.0768  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 1.6266  Validation loss = 3.0756  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 1.6265  Validation loss = 3.0759  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 1.6263  Validation loss = 3.0742  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 1.6260  Validation loss = 3.0732  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 1.6258  Validation loss = 3.0718  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 1.6256  Validation loss = 3.0706  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 1.6253  Validation loss = 3.0690  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 1.6251  Validation loss = 3.0685  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 1.6250  Validation loss = 3.0686  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 1.6249  Validation loss = 3.0703  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 1.6245  Validation loss = 3.0673  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 1.6242  Validation loss = 3.0652  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 1.6239  Validation loss = 3.0630  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 1.6237  Validation loss = 3.0625  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 1.6236  Validation loss = 3.0631  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 1.6234  Validation loss = 3.0616  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 1.6232  Validation loss = 3.0614  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 1.6230  Validation loss = 3.0602  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 1.6226  Validation loss = 3.0567  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 1.6225  Validation loss = 3.0569  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 1.6224  Validation loss = 3.0570  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 1.6221  Validation loss = 3.0553  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 1.6219  Validation loss = 3.0549  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 1.6216  Validation loss = 3.0534  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 1.6213  Validation loss = 3.0514  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 1.6211  Validation loss = 3.0506  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 1.6209  Validation loss = 3.0498  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 1.6205  Validation loss = 3.0460  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 1.6204  Validation loss = 3.0456  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 1.6202  Validation loss = 3.0454  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 1.6200  Validation loss = 3.0448  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 1.6197  Validation loss = 3.0435  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 1.6195  Validation loss = 3.0424  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 1.6193  Validation loss = 3.0414  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 1.6189  Validation loss = 3.0376  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 1.6189  Validation loss = 3.0391  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 1.6186  Validation loss = 3.0388  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 1.6186  Validation loss = 3.0393  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 1.6184  Validation loss = 3.0383  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 1.6182  Validation loss = 3.0370  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 1.6180  Validation loss = 3.0364  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 1.6177  Validation loss = 3.0349  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 1.6174  Validation loss = 3.0331  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 1.6172  Validation loss = 3.0325  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 1.6170  Validation loss = 3.0312  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 1.6168  Validation loss = 3.0317  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 1.6165  Validation loss = 3.0296  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 1.6162  Validation loss = 3.0280  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 1.6159  Validation loss = 3.0274  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 1.6157  Validation loss = 3.0263  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 1.6155  Validation loss = 3.0264  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 1.6153  Validation loss = 3.0253  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 1.6150  Validation loss = 3.0239  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 1.6148  Validation loss = 3.0218  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 1.6145  Validation loss = 3.0199  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 1.6142  Validation loss = 3.0194  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 1.6139  Validation loss = 3.0184  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 1.6136  Validation loss = 3.0168  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 1.6134  Validation loss = 3.0154  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 1.6132  Validation loss = 3.0141  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 1.6131  Validation loss = 3.0138  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 1.6128  Validation loss = 3.0135  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 1.6127  Validation loss = 3.0131  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 1.6124  Validation loss = 3.0120  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 1.6122  Validation loss = 3.0119  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 1.6120  Validation loss = 3.0120  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 1.6119  Validation loss = 3.0121  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 1.6116  Validation loss = 3.0108  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 1.6113  Validation loss = 3.0078  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 1.6112  Validation loss = 3.0083  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 1.6110  Validation loss = 3.0083  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 1.6108  Validation loss = 3.0074  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 1.6106  Validation loss = 3.0076  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 1.6105  Validation loss = 3.0069  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 1.6102  Validation loss = 3.0057  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 1.6100  Validation loss = 3.0051  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 1.6098  Validation loss = 3.0033  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 1.6095  Validation loss = 3.0018  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 1.6093  Validation loss = 3.0025  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 1.6090  Validation loss = 3.0012  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 1.6089  Validation loss = 3.0014  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 1.6088  Validation loss = 3.0003  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 1.6085  Validation loss = 2.9987  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 1.6083  Validation loss = 2.9978  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 1.6080  Validation loss = 2.9971  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 1.6079  Validation loss = 2.9967  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 1.6078  Validation loss = 2.9971  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 1.6075  Validation loss = 2.9962  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 1.6072  Validation loss = 2.9948  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 1.6071  Validation loss = 2.9944  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 1.6069  Validation loss = 2.9939  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 1.6067  Validation loss = 2.9932  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 1.6064  Validation loss = 2.9906  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 1.6061  Validation loss = 2.9891  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 1.6059  Validation loss = 2.9886  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 1.6057  Validation loss = 2.9881  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 1.6055  Validation loss = 2.9864  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 1.6054  Validation loss = 2.9854  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 1.6052  Validation loss = 2.9851  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 1.6050  Validation loss = 2.9841  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 1.6047  Validation loss = 2.9834  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 1.6045  Validation loss = 2.9833  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 1.6043  Validation loss = 2.9824  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 1.6041  Validation loss = 2.9818  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 1.6038  Validation loss = 2.9803  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 1.6037  Validation loss = 2.9796  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 1.6035  Validation loss = 2.9775  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 1.6032  Validation loss = 2.9767  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 1.6030  Validation loss = 2.9750  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 1.6027  Validation loss = 2.9731  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 1.6026  Validation loss = 2.9720  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 1.6022  Validation loss = 2.9697  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 1.6019  Validation loss = 2.9673  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 1.6017  Validation loss = 2.9650  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 1.6015  Validation loss = 2.9648  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 1.6013  Validation loss = 2.9631  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 1.6011  Validation loss = 2.9623  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 1.6008  Validation loss = 2.9608  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 1.6006  Validation loss = 2.9595  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 1.6002  Validation loss = 2.9566  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 1.6000  Validation loss = 2.9565  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 1.5998  Validation loss = 2.9551  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 1.5996  Validation loss = 2.9549  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 1.5994  Validation loss = 2.9540  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 1.5992  Validation loss = 2.9523  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 1.5990  Validation loss = 2.9531  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 1.5988  Validation loss = 2.9529  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 1.5985  Validation loss = 2.9503  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 1.5983  Validation loss = 2.9500  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 1.5982  Validation loss = 2.9496  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 1.5981  Validation loss = 2.9496  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 1.5978  Validation loss = 2.9488  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 1.5976  Validation loss = 2.9470  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 1.5974  Validation loss = 2.9462  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 1.5972  Validation loss = 2.9460  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 1.5971  Validation loss = 2.9463  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 1.5969  Validation loss = 2.9454  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 1.5966  Validation loss = 2.9445  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 1.5964  Validation loss = 2.9431  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 1.5961  Validation loss = 2.9413  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 1.5959  Validation loss = 2.9415  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 1.5957  Validation loss = 2.9408  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 1.5955  Validation loss = 2.9399  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 1.5953  Validation loss = 2.9395  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 1.5950  Validation loss = 2.9370  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 1.5948  Validation loss = 2.9363  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 1.5946  Validation loss = 2.9350  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 1.5943  Validation loss = 2.9335  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 1.5942  Validation loss = 2.9346  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 1.5940  Validation loss = 2.9336  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 1.5938  Validation loss = 2.9332  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 1.5935  Validation loss = 2.9321  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 1.5933  Validation loss = 2.9318  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 1.5931  Validation loss = 2.9308  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 1.5929  Validation loss = 2.9291  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 1.5927  Validation loss = 2.9286  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 1.5925  Validation loss = 2.9264  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 1.5922  Validation loss = 2.9257  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 1.5921  Validation loss = 2.9257  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 1.5918  Validation loss = 2.9240  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 1.5916  Validation loss = 2.9226  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 1.5913  Validation loss = 2.9205  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 1.5911  Validation loss = 2.9191  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 1.5908  Validation loss = 2.9170  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 1.5906  Validation loss = 2.9157  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 1.5904  Validation loss = 2.9145  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 1.5901  Validation loss = 2.9138  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 1.5899  Validation loss = 2.9125  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 1.5896  Validation loss = 2.9115  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 1.5895  Validation loss = 2.9112  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 1.5892  Validation loss = 2.9101  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 1.5890  Validation loss = 2.9087  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 1.5888  Validation loss = 2.9078  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.6946  Validation loss = 0.8138  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.6940  Validation loss = 0.8120  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.6935  Validation loss = 0.8115  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.6924  Validation loss = 0.8084  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.6917  Validation loss = 0.8069  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.6913  Validation loss = 0.8060  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.6902  Validation loss = 0.8037  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.6897  Validation loss = 0.8025  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.6893  Validation loss = 0.8017  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.6885  Validation loss = 0.8003  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.6880  Validation loss = 0.7990  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.6872  Validation loss = 0.7978  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.6866  Validation loss = 0.7970  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 1.6859  Validation loss = 0.7958  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 1.6853  Validation loss = 0.7950  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 1.6845  Validation loss = 0.7926  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 1.6836  Validation loss = 0.7905  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 1.6830  Validation loss = 0.7885  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 1.6822  Validation loss = 0.7868  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 1.6812  Validation loss = 0.7834  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 1.6804  Validation loss = 0.7814  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 1.6798  Validation loss = 0.7803  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 1.6790  Validation loss = 0.7784  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 1.6783  Validation loss = 0.7774  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 1.6773  Validation loss = 0.7751  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 1.6766  Validation loss = 0.7734  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 1.6757  Validation loss = 0.7711  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 1.6745  Validation loss = 0.7678  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 1.6736  Validation loss = 0.7659  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 1.6732  Validation loss = 0.7652  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 1.6731  Validation loss = 0.7658  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 1.6725  Validation loss = 0.7642  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 1.6720  Validation loss = 0.7631  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 1.6713  Validation loss = 0.7616  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 1.6710  Validation loss = 0.7611  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 1.6705  Validation loss = 0.7608  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 1.6699  Validation loss = 0.7588  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 1.6690  Validation loss = 0.7560  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 1.6681  Validation loss = 0.7539  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 1.6674  Validation loss = 0.7521  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 1.6668  Validation loss = 0.7509  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 1.6662  Validation loss = 0.7499  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 1.6654  Validation loss = 0.7481  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 1.6650  Validation loss = 0.7477  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 1.6641  Validation loss = 0.7453  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 1.6636  Validation loss = 0.7443  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 1.6631  Validation loss = 0.7437  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 1.6621  Validation loss = 0.7408  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 1.6615  Validation loss = 0.7392  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 1.6608  Validation loss = 0.7378  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 1.6602  Validation loss = 0.7369  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 1.6595  Validation loss = 0.7359  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 1.6588  Validation loss = 0.7341  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 1.6581  Validation loss = 0.7326  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 1.6575  Validation loss = 0.7313  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 1.6569  Validation loss = 0.7302  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 1.6561  Validation loss = 0.7280  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 1.6556  Validation loss = 0.7269  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 1.6549  Validation loss = 0.7258  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 1.6538  Validation loss = 0.7232  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 1.6534  Validation loss = 0.7233  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 1.6527  Validation loss = 0.7216  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 1.6520  Validation loss = 0.7201  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 1.6514  Validation loss = 0.7189  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 1.6509  Validation loss = 0.7178  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 1.6504  Validation loss = 0.7172  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 1.6496  Validation loss = 0.7154  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 1.6489  Validation loss = 0.7143  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 1.6484  Validation loss = 0.7139  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 1.6476  Validation loss = 0.7125  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 1.6469  Validation loss = 0.7107  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 1.6465  Validation loss = 0.7101  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 1.6459  Validation loss = 0.7092  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 1.6452  Validation loss = 0.7077  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 1.6448  Validation loss = 0.7068  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 1.6440  Validation loss = 0.7047  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 1.6432  Validation loss = 0.7027  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 1.6426  Validation loss = 0.7023  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 1.6419  Validation loss = 0.7008  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 1.6414  Validation loss = 0.7002  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 1.6410  Validation loss = 0.7000  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 1.6405  Validation loss = 0.6992  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 1.6398  Validation loss = 0.6974  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 1.6391  Validation loss = 0.6960  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 1.6383  Validation loss = 0.6943  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 1.6377  Validation loss = 0.6937  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 1.6373  Validation loss = 0.6930  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 1.6364  Validation loss = 0.6911  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 1.6361  Validation loss = 0.6913  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 1.6355  Validation loss = 0.6902  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 1.6350  Validation loss = 0.6895  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 1.6344  Validation loss = 0.6884  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 1.6338  Validation loss = 0.6875  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 1.6334  Validation loss = 0.6870  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 1.6330  Validation loss = 0.6861  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 1.6325  Validation loss = 0.6856  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 1.6319  Validation loss = 0.6839  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 1.6312  Validation loss = 0.6824  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 1.6305  Validation loss = 0.6809  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 1.6302  Validation loss = 0.6806  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 1.6293  Validation loss = 0.6785  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 1.6283  Validation loss = 0.6757  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 1.6274  Validation loss = 0.6741  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 1.6269  Validation loss = 0.6724  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 1.6265  Validation loss = 0.6718  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 1.6260  Validation loss = 0.6706  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 1.6252  Validation loss = 0.6688  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 1.6248  Validation loss = 0.6682  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 1.6245  Validation loss = 0.6677  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 1.6237  Validation loss = 0.6656  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 1.6231  Validation loss = 0.6650  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 1.6226  Validation loss = 0.6639  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 1.6222  Validation loss = 0.6634  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 1.6217  Validation loss = 0.6629  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 1.6214  Validation loss = 0.6618  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 1.6209  Validation loss = 0.6606  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 1.6203  Validation loss = 0.6595  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 1.6199  Validation loss = 0.6586  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 1.6191  Validation loss = 0.6571  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 1.6186  Validation loss = 0.6565  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 1.6180  Validation loss = 0.6549  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 1.6174  Validation loss = 0.6541  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 1.6170  Validation loss = 0.6540  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 1.6166  Validation loss = 0.6539  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 1.6163  Validation loss = 0.6533  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 1.6156  Validation loss = 0.6525  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 1.6151  Validation loss = 0.6516  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 1.6146  Validation loss = 0.6511  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 1.6140  Validation loss = 0.6496  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 1.6136  Validation loss = 0.6490  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 1.6130  Validation loss = 0.6482  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 1.6124  Validation loss = 0.6476  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 1.6121  Validation loss = 0.6475  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 1.6113  Validation loss = 0.6464  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 1.6106  Validation loss = 0.6447  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 1.6103  Validation loss = 0.6448  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 1.6096  Validation loss = 0.6436  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 1.6093  Validation loss = 0.6428  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 1.6086  Validation loss = 0.6411  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 1.6080  Validation loss = 0.6398  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 1.6075  Validation loss = 0.6388  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 1.6071  Validation loss = 0.6382  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 1.6063  Validation loss = 0.6365  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 1.6056  Validation loss = 0.6351  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 1.6050  Validation loss = 0.6339  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 1.6045  Validation loss = 0.6334  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 1.6036  Validation loss = 0.6311  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 1.6032  Validation loss = 0.6309  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 1.6027  Validation loss = 0.6297  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 1.6021  Validation loss = 0.6286  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 1.6017  Validation loss = 0.6284  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 1.6014  Validation loss = 0.6286  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 1.6011  Validation loss = 0.6284  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 1.6006  Validation loss = 0.6278  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 1.6001  Validation loss = 0.6271  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 1.5997  Validation loss = 0.6263  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 1.5991  Validation loss = 0.6249  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 1.5989  Validation loss = 0.6253  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 1.5984  Validation loss = 0.6244  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 1.5977  Validation loss = 0.6239  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 1.5974  Validation loss = 0.6236  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 1.5968  Validation loss = 0.6229  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 1.5963  Validation loss = 0.6217  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 1.5960  Validation loss = 0.6221  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 1.5957  Validation loss = 0.6223  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 1.5951  Validation loss = 0.6219  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 1.5946  Validation loss = 0.6212  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 1.5942  Validation loss = 0.6207  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 1.5936  Validation loss = 0.6197  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 1.5930  Validation loss = 0.6188  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 1.5927  Validation loss = 0.6187  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 1.5922  Validation loss = 0.6181  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 1.5918  Validation loss = 0.6179  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 1.5913  Validation loss = 0.6175  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 1.5909  Validation loss = 0.6168  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 1.5903  Validation loss = 0.6160  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 1.5898  Validation loss = 0.6156  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 1.5893  Validation loss = 0.6147  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 1.5888  Validation loss = 0.6137  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 1.5884  Validation loss = 0.6132  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 1.5878  Validation loss = 0.6115  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 1.5873  Validation loss = 0.6105  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 1.5867  Validation loss = 0.6095  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 1.5865  Validation loss = 0.6096  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 1.5860  Validation loss = 0.6086  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 1.5856  Validation loss = 0.6084  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 1.5850  Validation loss = 0.6071  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 1.5846  Validation loss = 0.6065  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 1.5841  Validation loss = 0.6059  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 1.5836  Validation loss = 0.6053  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 1.5831  Validation loss = 0.6047  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 1.5825  Validation loss = 0.6036  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 1.5821  Validation loss = 0.6039  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 1.5818  Validation loss = 0.6040  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 1.5811  Validation loss = 0.6021  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 1.5805  Validation loss = 0.6018  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 1.5803  Validation loss = 0.6020  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 1.5799  Validation loss = 0.6018  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 1.5795  Validation loss = 0.6016  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 1.5789  Validation loss = 0.6003  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 1.5785  Validation loss = 0.5999  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 1.5779  Validation loss = 0.5991  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 1.5774  Validation loss = 0.5985  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 1.5770  Validation loss = 0.5985  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 1.5766  Validation loss = 0.5983  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 1.5762  Validation loss = 0.5984  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 1.5759  Validation loss = 0.5982  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 1.5756  Validation loss = 0.5980  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 1.5751  Validation loss = 0.5978  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 1.5747  Validation loss = 0.5978  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 1.5742  Validation loss = 0.5970  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 1.5738  Validation loss = 0.5970  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 1.5731  Validation loss = 0.5953  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 1.5726  Validation loss = 0.5950  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 1.5720  Validation loss = 0.5938  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 1.5714  Validation loss = 0.5928  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 1.5710  Validation loss = 0.5925  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 1.5706  Validation loss = 0.5924  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 1.5705  Validation loss = 0.5930  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 1.5701  Validation loss = 0.5929  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 1.5695  Validation loss = 0.5921  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 1.5692  Validation loss = 0.5920  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 1.5688  Validation loss = 0.5913  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 1.5685  Validation loss = 0.5911  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 1.5678  Validation loss = 0.5903  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 1.5674  Validation loss = 0.5898  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 1.5669  Validation loss = 0.5894  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 1.5664  Validation loss = 0.5890  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 1.5659  Validation loss = 0.5882  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 1.5653  Validation loss = 0.5872  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 1.5647  Validation loss = 0.5865  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 1.5643  Validation loss = 0.5861  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 1.5639  Validation loss = 0.5856  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 1.5638  Validation loss = 0.5856  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 1.5634  Validation loss = 0.5852  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 1.5629  Validation loss = 0.5848  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 1.5625  Validation loss = 0.5846  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 1.5621  Validation loss = 0.5847  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 1.5617  Validation loss = 0.5846  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 1.5614  Validation loss = 0.5844  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 1.5608  Validation loss = 0.5834  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 1.5604  Validation loss = 0.5834  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 1.5600  Validation loss = 0.5834  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 1.5597  Validation loss = 0.5832  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 1.5593  Validation loss = 0.5825  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 1.5589  Validation loss = 0.5824  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 1.5584  Validation loss = 0.5821  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 1.5578  Validation loss = 0.5811  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 1.5574  Validation loss = 0.5809  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 1.5570  Validation loss = 0.5807  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 1.5566  Validation loss = 0.5804  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 1.5562  Validation loss = 0.5799  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 1.5558  Validation loss = 0.5796  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 1.5555  Validation loss = 0.5796  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 1.5550  Validation loss = 0.5789  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 1.5545  Validation loss = 0.5788  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 1.5541  Validation loss = 0.5781  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 1.5536  Validation loss = 0.5780  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 1.5531  Validation loss = 0.5771  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 1.5526  Validation loss = 0.5762  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 1.5523  Validation loss = 0.5759  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 1.5519  Validation loss = 0.5754  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 1.5513  Validation loss = 0.5751  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 1.5510  Validation loss = 0.5753  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 1.5506  Validation loss = 0.5748  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 1.5501  Validation loss = 0.5742  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 1.5496  Validation loss = 0.5735  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 1.5491  Validation loss = 0.5731  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 1.5487  Validation loss = 0.5729  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 1.5483  Validation loss = 0.5724  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 1.5480  Validation loss = 0.5721  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 1.5477  Validation loss = 0.5719  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 1.5472  Validation loss = 0.5715  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 1.5468  Validation loss = 0.5710  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 1.5465  Validation loss = 0.5710  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 1.5461  Validation loss = 0.5705  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 1.5459  Validation loss = 0.5704  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 1.5454  Validation loss = 0.5697  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 1.5450  Validation loss = 0.5695  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 1.5446  Validation loss = 0.5692  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 1.5443  Validation loss = 0.5690  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 1.5439  Validation loss = 0.5692  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 1.5433  Validation loss = 0.5689  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 1.5429  Validation loss = 0.5685  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 1.5425  Validation loss = 0.5685  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 1.5421  Validation loss = 0.5683  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 1.5413  Validation loss = 0.5673  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 1.5409  Validation loss = 0.5668  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 1.5404  Validation loss = 0.5669  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 1.5401  Validation loss = 0.5666  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 1.5399  Validation loss = 0.5668  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 1.5395  Validation loss = 0.5665  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 1.5391  Validation loss = 0.5665  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 1.5386  Validation loss = 0.5661  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 1.5382  Validation loss = 0.5659  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 1.5379  Validation loss = 0.5658  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 1.5375  Validation loss = 0.5652  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 1.5372  Validation loss = 0.5650  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 1.5369  Validation loss = 0.5649  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 1.5363  Validation loss = 0.5645  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 1.5358  Validation loss = 0.5642  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 1.5352  Validation loss = 0.5637  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 1.5348  Validation loss = 0.5633  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 1.5343  Validation loss = 0.5631  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 1.5339  Validation loss = 0.5630  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 1.5335  Validation loss = 0.5632  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 1.5333  Validation loss = 0.5632  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 1.5327  Validation loss = 0.5628  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 1.5323  Validation loss = 0.5624  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 1.5320  Validation loss = 0.5622  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 1.5315  Validation loss = 0.5620  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 1.5312  Validation loss = 0.5619  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 1.5307  Validation loss = 0.5613  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 1.5304  Validation loss = 0.5609  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 1.5300  Validation loss = 0.5606  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 1.5296  Validation loss = 0.5606  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 1.5291  Validation loss = 0.5600  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 1.5286  Validation loss = 0.5596  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 1.5282  Validation loss = 0.5592  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 1.5278  Validation loss = 0.5591  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 1.5274  Validation loss = 0.5591  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 1.5270  Validation loss = 0.5587  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 1.5265  Validation loss = 0.5584  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 1.5261  Validation loss = 0.5582  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 1.5257  Validation loss = 0.5577  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 1.5253  Validation loss = 0.5573  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 1.5248  Validation loss = 0.5575  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 1.5244  Validation loss = 0.5572  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 1.5240  Validation loss = 0.5569  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 1.5237  Validation loss = 0.5569  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 1.5234  Validation loss = 0.5569  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 1.5231  Validation loss = 0.5569  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 1.5226  Validation loss = 0.5569  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 1.5221  Validation loss = 0.5565  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 1.5218  Validation loss = 0.5564  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 1.5213  Validation loss = 0.5560  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 1.5208  Validation loss = 0.5558  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 1.5204  Validation loss = 0.5558  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 1.5200  Validation loss = 0.5557  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 1.5195  Validation loss = 0.5554  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 1.5191  Validation loss = 0.5557  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 1.5187  Validation loss = 0.5552  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 1.5184  Validation loss = 0.5552  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 1.5179  Validation loss = 0.5555  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 1.5176  Validation loss = 0.5554  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 1.5174  Validation loss = 0.5555  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 1.5171  Validation loss = 0.5555  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 1.5166  Validation loss = 0.5552  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 1.5162  Validation loss = 0.5552  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 1.5158  Validation loss = 0.5550  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 1.5154  Validation loss = 0.5550  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 1.5151  Validation loss = 0.5551  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 1.5147  Validation loss = 0.5550  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 1.5143  Validation loss = 0.5550  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 1.5140  Validation loss = 0.5551  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 1.5137  Validation loss = 0.5550  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 1.5132  Validation loss = 0.5550  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 1.5130  Validation loss = 0.5548  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 1.5126  Validation loss = 0.5548  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 1.5122  Validation loss = 0.5544  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 1.5117  Validation loss = 0.5544  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 1.5113  Validation loss = 0.5544  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 1.5109  Validation loss = 0.5545  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 1.5106  Validation loss = 0.5545  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 1.5104  Validation loss = 0.5547  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 1.5100  Validation loss = 0.5546  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 1.5096  Validation loss = 0.5545  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 1.5093  Validation loss = 0.5546  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 1.5089  Validation loss = 0.5546  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 1.5085  Validation loss = 0.5546  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 1.5080  Validation loss = 0.5544  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 1.5076  Validation loss = 0.5542  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 1.5071  Validation loss = 0.5545  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 1.5065  Validation loss = 0.5544  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 1.5063  Validation loss = 0.5544  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 1.5059  Validation loss = 0.5546  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 1.5056  Validation loss = 0.5545  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 1.5053  Validation loss = 0.5545  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 1.5049  Validation loss = 0.5546  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 372  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.4496  Validation loss = 0.7967  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.4493  Validation loss = 0.7967  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.4489  Validation loss = 0.7968  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.4486  Validation loss = 0.7967  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.4484  Validation loss = 0.7968  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.4481  Validation loss = 0.7971  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.4477  Validation loss = 0.7966  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.4473  Validation loss = 0.7966  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.4470  Validation loss = 0.7965  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.4468  Validation loss = 0.7971  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.4463  Validation loss = 0.7965  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.4462  Validation loss = 0.7971  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.4459  Validation loss = 0.7969  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.4455  Validation loss = 0.7967  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.4451  Validation loss = 0.7958  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.4449  Validation loss = 0.7957  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.4446  Validation loss = 0.7959  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.4443  Validation loss = 0.7961  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.4441  Validation loss = 0.7960  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.4436  Validation loss = 0.7950  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 1.4431  Validation loss = 0.7942  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.4428  Validation loss = 0.7942  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 1.4426  Validation loss = 0.7945  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 1.4422  Validation loss = 0.7936  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 1.4418  Validation loss = 0.7934  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 1.4415  Validation loss = 0.7936  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 1.4413  Validation loss = 0.7936  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 1.4408  Validation loss = 0.7924  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 1.4405  Validation loss = 0.7925  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 1.4403  Validation loss = 0.7924  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 1.4399  Validation loss = 0.7924  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 1.4398  Validation loss = 0.7934  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 1.4395  Validation loss = 0.7940  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 28  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.3897  Validation loss = 5.3830  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.3895  Validation loss = 5.3824  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.3890  Validation loss = 5.3802  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.3887  Validation loss = 5.3795  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.3885  Validation loss = 5.3801  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.3881  Validation loss = 5.3786  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.3877  Validation loss = 5.3776  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.3874  Validation loss = 5.3764  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.3869  Validation loss = 5.3750  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.3866  Validation loss = 5.3744  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.3864  Validation loss = 5.3729  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.3861  Validation loss = 5.3715  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.3858  Validation loss = 5.3713  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 1.3854  Validation loss = 5.3704  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 1.3850  Validation loss = 5.3704  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.3846  Validation loss = 5.3680  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 1.3843  Validation loss = 5.3685  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 1.3841  Validation loss = 5.3683  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 1.3838  Validation loss = 5.3671  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 1.3836  Validation loss = 5.3676  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 1.3833  Validation loss = 5.3675  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 1.3829  Validation loss = 5.3661  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 1.3824  Validation loss = 5.3641  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 1.3820  Validation loss = 5.3629  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 1.3817  Validation loss = 5.3618  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 1.3814  Validation loss = 5.3613  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 1.3808  Validation loss = 5.3590  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 1.3806  Validation loss = 5.3586  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 1.3801  Validation loss = 5.3562  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 1.3798  Validation loss = 5.3552  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 1.3793  Validation loss = 5.3534  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 1.3791  Validation loss = 5.3534  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 1.3787  Validation loss = 5.3516  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 1.3785  Validation loss = 5.3520  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 1.3780  Validation loss = 5.3499  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 1.3778  Validation loss = 5.3489  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 1.3776  Validation loss = 5.3490  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 1.3772  Validation loss = 5.3473  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 1.3769  Validation loss = 5.3468  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 1.3765  Validation loss = 5.3450  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 1.3762  Validation loss = 5.3438  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 1.3759  Validation loss = 5.3429  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 1.3755  Validation loss = 5.3424  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 1.3753  Validation loss = 5.3414  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 1.3752  Validation loss = 5.3428  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 1.3748  Validation loss = 5.3424  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 1.3744  Validation loss = 5.3415  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 1.3742  Validation loss = 5.3412  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 1.3738  Validation loss = 5.3397  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 1.3735  Validation loss = 5.3385  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 1.3734  Validation loss = 5.3386  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 1.3730  Validation loss = 5.3378  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 1.3727  Validation loss = 5.3372  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 1.3724  Validation loss = 5.3363  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 1.3721  Validation loss = 5.3363  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 1.3718  Validation loss = 5.3361  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 1.3717  Validation loss = 5.3363  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 1.3713  Validation loss = 5.3353  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 1.3712  Validation loss = 5.3347  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 1.3709  Validation loss = 5.3338  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 1.3706  Validation loss = 5.3328  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 1.3703  Validation loss = 5.3318  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 1.3700  Validation loss = 5.3307  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 1.3697  Validation loss = 5.3294  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 1.3695  Validation loss = 5.3289  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 1.3693  Validation loss = 5.3294  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 1.3689  Validation loss = 5.3285  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 1.3685  Validation loss = 5.3259  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 1.3681  Validation loss = 5.3242  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 1.3679  Validation loss = 5.3241  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 1.3676  Validation loss = 5.3228  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 1.3673  Validation loss = 5.3226  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 1.3670  Validation loss = 5.3227  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 1.3668  Validation loss = 5.3215  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 1.3665  Validation loss = 5.3206  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 1.3663  Validation loss = 5.3206  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 1.3660  Validation loss = 5.3198  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 1.3657  Validation loss = 5.3192  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 1.3655  Validation loss = 5.3201  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 1.3652  Validation loss = 5.3187  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 1.3651  Validation loss = 5.3190  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 1.3649  Validation loss = 5.3194  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 1.3646  Validation loss = 5.3185  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 1.3642  Validation loss = 5.3177  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 1.3640  Validation loss = 5.3176  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 1.3636  Validation loss = 5.3168  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 1.3634  Validation loss = 5.3155  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 1.3630  Validation loss = 5.3136  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 1.3626  Validation loss = 5.3121  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 1.3625  Validation loss = 5.3119  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 1.3622  Validation loss = 5.3116  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 1.3621  Validation loss = 5.3118  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 1.3616  Validation loss = 5.3100  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 1.3614  Validation loss = 5.3097  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 1.3610  Validation loss = 5.3081  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 1.3608  Validation loss = 5.3083  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 1.3606  Validation loss = 5.3084  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 1.3603  Validation loss = 5.3076  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 1.3600  Validation loss = 5.3075  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 1.3597  Validation loss = 5.3064  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 1.3595  Validation loss = 5.3065  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 1.3592  Validation loss = 5.3063  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 1.3589  Validation loss = 5.3053  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 1.3586  Validation loss = 5.3057  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 1.3583  Validation loss = 5.3042  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 1.3578  Validation loss = 5.3017  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 1.3575  Validation loss = 5.3005  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 1.3571  Validation loss = 5.3004  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 1.3570  Validation loss = 5.3001  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 1.3568  Validation loss = 5.3001  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 1.3566  Validation loss = 5.3000  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 1.3563  Validation loss = 5.2987  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 1.3561  Validation loss = 5.2993  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 1.3559  Validation loss = 5.2985  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 1.3558  Validation loss = 5.2991  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 1.3557  Validation loss = 5.2991  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 1.3555  Validation loss = 5.2976  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 1.3553  Validation loss = 5.2984  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 1.3551  Validation loss = 5.2983  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 1.3548  Validation loss = 5.2986  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 1.3545  Validation loss = 5.2971  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 1.3541  Validation loss = 5.2954  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 1.3537  Validation loss = 5.2938  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 1.3534  Validation loss = 5.2937  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 1.3531  Validation loss = 5.2925  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 1.3528  Validation loss = 5.2909  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 1.3526  Validation loss = 5.2909  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 1.3523  Validation loss = 5.2905  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 1.3520  Validation loss = 5.2894  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 1.3517  Validation loss = 5.2889  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 1.3514  Validation loss = 5.2870  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 1.3513  Validation loss = 5.2888  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 1.3510  Validation loss = 5.2876  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 1.3508  Validation loss = 5.2879  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 1.3505  Validation loss = 5.2884  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 1.3503  Validation loss = 5.2885  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 1.3500  Validation loss = 5.2877  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 1.3496  Validation loss = 5.2865  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 1.3494  Validation loss = 5.2857  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 1.3492  Validation loss = 5.2859  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 1.3491  Validation loss = 5.2872  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 1.3488  Validation loss = 5.2853  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 1.3485  Validation loss = 5.2848  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 1.3482  Validation loss = 5.2830  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 1.3480  Validation loss = 5.2829  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 1.3477  Validation loss = 5.2830  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 1.3474  Validation loss = 5.2813  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 1.3471  Validation loss = 5.2810  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 1.3468  Validation loss = 5.2793  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 1.3465  Validation loss = 5.2790  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 1.3464  Validation loss = 5.2798  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 1.3463  Validation loss = 5.2801  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 1.3460  Validation loss = 5.2796  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 1.3458  Validation loss = 5.2803  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 1.3455  Validation loss = 5.2804  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 1.3453  Validation loss = 5.2798  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 1.3451  Validation loss = 5.2806  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 1.3448  Validation loss = 5.2787  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 1.3446  Validation loss = 5.2791  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 1.3443  Validation loss = 5.2779  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 1.3440  Validation loss = 5.2763  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 1.3437  Validation loss = 5.2743  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 1.3433  Validation loss = 5.2733  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 1.3430  Validation loss = 5.2713  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 1.3428  Validation loss = 5.2714  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 1.3427  Validation loss = 5.2712  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 1.3423  Validation loss = 5.2712  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 1.3422  Validation loss = 5.2716  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 1.3420  Validation loss = 5.2721  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 1.3418  Validation loss = 5.2717  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 1.3415  Validation loss = 5.2703  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 1.3412  Validation loss = 5.2684  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 1.3409  Validation loss = 5.2658  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 1.3408  Validation loss = 5.2664  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 1.3405  Validation loss = 5.2662  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 1.3402  Validation loss = 5.2648  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 1.3399  Validation loss = 5.2633  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 1.3396  Validation loss = 5.2627  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 1.3393  Validation loss = 5.2610  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 1.3392  Validation loss = 5.2622  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 1.3390  Validation loss = 5.2621  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 1.3388  Validation loss = 5.2605  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 1.3385  Validation loss = 5.2603  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 1.3384  Validation loss = 5.2610  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 1.3382  Validation loss = 5.2614  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 1.3379  Validation loss = 5.2598  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 1.3378  Validation loss = 5.2592  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 1.3376  Validation loss = 5.2602  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 1.3373  Validation loss = 5.2601  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 1.3371  Validation loss = 5.2595  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 1.3367  Validation loss = 5.2571  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 1.3364  Validation loss = 5.2564  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 1.3361  Validation loss = 5.2560  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 1.3358  Validation loss = 5.2564  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 1.3356  Validation loss = 5.2559  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 1.3354  Validation loss = 5.2564  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 1.3352  Validation loss = 5.2550  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 1.3349  Validation loss = 5.2545  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 1.3347  Validation loss = 5.2539  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 1.3344  Validation loss = 5.2534  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 1.3340  Validation loss = 5.2515  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 1.3336  Validation loss = 5.2494  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 1.3334  Validation loss = 5.2486  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 1.3330  Validation loss = 5.2477  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 1.3328  Validation loss = 5.2472  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 1.3326  Validation loss = 5.2460  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 1.3322  Validation loss = 5.2443  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 1.3319  Validation loss = 5.2430  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 1.3318  Validation loss = 5.2432  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 1.3314  Validation loss = 5.2411  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 1.3311  Validation loss = 5.2397  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 1.3308  Validation loss = 5.2390  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 1.3305  Validation loss = 5.2377  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 1.3303  Validation loss = 5.2382  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 1.3301  Validation loss = 5.2379  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 1.3300  Validation loss = 5.2387  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 1.3297  Validation loss = 5.2383  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 1.3295  Validation loss = 5.2383  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 1.3293  Validation loss = 5.2377  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 1.3291  Validation loss = 5.2377  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 1.3289  Validation loss = 5.2379  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 1.3287  Validation loss = 5.2366  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 1.3284  Validation loss = 5.2344  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 1.3282  Validation loss = 5.2332  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 1.3282  Validation loss = 5.2336  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 1.3280  Validation loss = 5.2317  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 1.3278  Validation loss = 5.2326  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 1.3277  Validation loss = 5.2321  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 1.3276  Validation loss = 5.2315  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 1.3275  Validation loss = 5.2315  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 1.3273  Validation loss = 5.2309  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 1.3271  Validation loss = 5.2321  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 1.3270  Validation loss = 5.2309  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 1.3267  Validation loss = 5.2296  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 1.3264  Validation loss = 5.2278  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 1.3261  Validation loss = 5.2271  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 1.3260  Validation loss = 5.2273  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 1.3258  Validation loss = 5.2263  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 1.3256  Validation loss = 5.2245  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 1.3253  Validation loss = 5.2232  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 1.3251  Validation loss = 5.2228  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 1.3249  Validation loss = 5.2230  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 1.3247  Validation loss = 5.2241  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 1.3246  Validation loss = 5.2247  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 1.3244  Validation loss = 5.2250  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 1.3241  Validation loss = 5.2248  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 1.3238  Validation loss = 5.2242  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 1.3238  Validation loss = 5.2262  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 241  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.8366  Validation loss = 8.1110  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.8358  Validation loss = 8.1078  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.8353  Validation loss = 8.1027  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.8348  Validation loss = 8.0994  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.8340  Validation loss = 8.0933  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.8330  Validation loss = 8.0862  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.8320  Validation loss = 8.0791  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.8319  Validation loss = 8.0780  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.8313  Validation loss = 8.0744  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.8307  Validation loss = 8.0726  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.8300  Validation loss = 8.0668  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.8299  Validation loss = 8.0659  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.8298  Validation loss = 8.0646  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.8292  Validation loss = 8.0599  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.8287  Validation loss = 8.0563  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.8280  Validation loss = 8.0496  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.8276  Validation loss = 8.0466  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.8270  Validation loss = 8.0422  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 1.8264  Validation loss = 8.0370  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 1.8259  Validation loss = 8.0327  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 1.8257  Validation loss = 8.0306  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 1.8250  Validation loss = 8.0248  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 1.8243  Validation loss = 8.0198  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 1.8235  Validation loss = 8.0147  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 1.8228  Validation loss = 8.0097  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 1.8225  Validation loss = 8.0077  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 1.8221  Validation loss = 8.0055  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 1.8218  Validation loss = 8.0036  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 1.8209  Validation loss = 7.9980  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 1.8203  Validation loss = 7.9936  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 1.8198  Validation loss = 7.9905  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 1.8191  Validation loss = 7.9858  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 1.8188  Validation loss = 7.9845  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 1.8182  Validation loss = 7.9807  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 1.8177  Validation loss = 7.9778  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 1.8173  Validation loss = 7.9752  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 1.8167  Validation loss = 7.9719  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 1.8163  Validation loss = 7.9701  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 1.8160  Validation loss = 7.9677  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 1.8154  Validation loss = 7.9637  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 1.8145  Validation loss = 7.9593  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 1.8139  Validation loss = 7.9555  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 1.8132  Validation loss = 7.9516  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 1.8126  Validation loss = 7.9491  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 1.8121  Validation loss = 7.9461  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 1.8115  Validation loss = 7.9429  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 1.8113  Validation loss = 7.9412  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 1.8111  Validation loss = 7.9405  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 1.8108  Validation loss = 7.9391  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 1.8099  Validation loss = 7.9344  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 1.8096  Validation loss = 7.9333  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 1.8092  Validation loss = 7.9314  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 1.8083  Validation loss = 7.9258  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 1.8078  Validation loss = 7.9230  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 1.8072  Validation loss = 7.9192  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 1.8070  Validation loss = 7.9183  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 1.8064  Validation loss = 7.9154  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 1.8060  Validation loss = 7.9137  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 1.8058  Validation loss = 7.9119  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 1.8055  Validation loss = 7.9106  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 1.8053  Validation loss = 7.9093  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 1.8048  Validation loss = 7.9065  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 1.8043  Validation loss = 7.9044  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 1.8038  Validation loss = 7.9011  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 1.8033  Validation loss = 7.8992  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 1.8029  Validation loss = 7.8963  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 1.8024  Validation loss = 7.8936  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 1.8019  Validation loss = 7.8909  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 1.8017  Validation loss = 7.8901  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 1.8012  Validation loss = 7.8868  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 1.8005  Validation loss = 7.8831  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 1.8002  Validation loss = 7.8813  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 1.7996  Validation loss = 7.8785  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 1.7995  Validation loss = 7.8777  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 1.7989  Validation loss = 7.8745  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 1.7984  Validation loss = 7.8720  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 1.7980  Validation loss = 7.8696  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 1.7974  Validation loss = 7.8670  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 1.7970  Validation loss = 7.8646  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 1.7967  Validation loss = 7.8633  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 1.7962  Validation loss = 7.8609  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 1.7958  Validation loss = 7.8590  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 1.7954  Validation loss = 7.8571  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 1.7952  Validation loss = 7.8560  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 1.7948  Validation loss = 7.8537  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 1.7946  Validation loss = 7.8529  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 1.7941  Validation loss = 7.8499  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 1.7936  Validation loss = 7.8471  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 1.7931  Validation loss = 7.8448  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 1.7925  Validation loss = 7.8413  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 1.7920  Validation loss = 7.8386  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 1.7915  Validation loss = 7.8364  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 1.7908  Validation loss = 7.8323  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 1.7903  Validation loss = 7.8297  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 1.7900  Validation loss = 7.8280  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 1.7896  Validation loss = 7.8259  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 1.7892  Validation loss = 7.8239  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 1.7892  Validation loss = 7.8241  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 1.7888  Validation loss = 7.8220  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 1.7884  Validation loss = 7.8205  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 1.7879  Validation loss = 7.8174  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 1.7877  Validation loss = 7.8167  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 1.7875  Validation loss = 7.8158  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 1.7870  Validation loss = 7.8129  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 1.7866  Validation loss = 7.8109  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 1.7862  Validation loss = 7.8090  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 1.7856  Validation loss = 7.8051  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 1.7855  Validation loss = 7.8055  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 1.7851  Validation loss = 7.8035  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 1.7849  Validation loss = 7.8026  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 1.7845  Validation loss = 7.8004  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 1.7843  Validation loss = 7.8000  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 1.7839  Validation loss = 7.7978  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 1.7833  Validation loss = 7.7940  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 1.7827  Validation loss = 7.7907  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 1.7825  Validation loss = 7.7899  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 1.7819  Validation loss = 7.7870  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 1.7814  Validation loss = 7.7842  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 1.7810  Validation loss = 7.7822  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 1.7807  Validation loss = 7.7806  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 1.7802  Validation loss = 7.7780  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 1.7795  Validation loss = 7.7739  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 1.7790  Validation loss = 7.7711  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 1.7783  Validation loss = 7.7664  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 1.7779  Validation loss = 7.7648  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 1.7776  Validation loss = 7.7628  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 1.7772  Validation loss = 7.7607  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 1.7768  Validation loss = 7.7587  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 1.7768  Validation loss = 7.7588  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 1.7763  Validation loss = 7.7555  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 1.7760  Validation loss = 7.7538  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 1.7758  Validation loss = 7.7532  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 1.7754  Validation loss = 7.7509  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 1.7750  Validation loss = 7.7490  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 1.7747  Validation loss = 7.7480  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 1.7742  Validation loss = 7.7446  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 1.7738  Validation loss = 7.7419  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 1.7733  Validation loss = 7.7390  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 1.7729  Validation loss = 7.7366  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 1.7724  Validation loss = 7.7341  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 1.7722  Validation loss = 7.7330  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 1.7719  Validation loss = 7.7314  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 1.7718  Validation loss = 7.7316  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 1.7713  Validation loss = 7.7290  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 1.7709  Validation loss = 7.7271  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 1.7703  Validation loss = 7.7235  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 1.7698  Validation loss = 7.7205  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 1.7696  Validation loss = 7.7196  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 1.7693  Validation loss = 7.7182  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 1.7691  Validation loss = 7.7171  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 1.7688  Validation loss = 7.7161  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 1.7687  Validation loss = 7.7168  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 1.7685  Validation loss = 7.7156  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 1.7682  Validation loss = 7.7139  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 1.7679  Validation loss = 7.7128  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 1.7678  Validation loss = 7.7119  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 1.7673  Validation loss = 7.7089  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 1.7668  Validation loss = 7.7059  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 1.7667  Validation loss = 7.7056  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 1.7664  Validation loss = 7.7041  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 1.7660  Validation loss = 7.7021  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 1.7656  Validation loss = 7.6998  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 1.7652  Validation loss = 7.6976  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 1.7650  Validation loss = 7.6969  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 1.7647  Validation loss = 7.6953  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 1.7643  Validation loss = 7.6928  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 1.7640  Validation loss = 7.6917  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 1.7637  Validation loss = 7.6902  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 1.7632  Validation loss = 7.6871  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 1.7628  Validation loss = 7.6846  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 1.7627  Validation loss = 7.6847  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 1.7624  Validation loss = 7.6831  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 1.7621  Validation loss = 7.6817  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 1.7618  Validation loss = 7.6794  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 1.7616  Validation loss = 7.6793  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 1.7614  Validation loss = 7.6787  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 1.7611  Validation loss = 7.6766  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 1.7611  Validation loss = 7.6783  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 1.7607  Validation loss = 7.6758  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 1.7605  Validation loss = 7.6748  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 1.7604  Validation loss = 7.6747  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 1.7600  Validation loss = 7.6721  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 1.7596  Validation loss = 7.6701  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 1.7592  Validation loss = 7.6669  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 1.7590  Validation loss = 7.6650  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 1.7586  Validation loss = 7.6632  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 1.7581  Validation loss = 7.6598  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 1.7577  Validation loss = 7.6563  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 1.7575  Validation loss = 7.6556  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 1.7571  Validation loss = 7.6520  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 1.7568  Validation loss = 7.6509  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 1.7564  Validation loss = 7.6482  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 1.7563  Validation loss = 7.6479  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 1.7558  Validation loss = 7.6447  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 1.7555  Validation loss = 7.6423  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 1.7554  Validation loss = 7.6424  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 1.7550  Validation loss = 7.6387  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 1.7544  Validation loss = 7.6354  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 1.7542  Validation loss = 7.6341  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 1.7537  Validation loss = 7.6313  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 1.7533  Validation loss = 7.6291  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 1.7532  Validation loss = 7.6285  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 1.7530  Validation loss = 7.6274  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 1.7526  Validation loss = 7.6251  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 1.7523  Validation loss = 7.6230  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 1.7521  Validation loss = 7.6214  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 1.7519  Validation loss = 7.6207  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 1.7516  Validation loss = 7.6198  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 1.7514  Validation loss = 7.6182  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 1.7510  Validation loss = 7.6156  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 1.7508  Validation loss = 7.6152  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 1.7507  Validation loss = 7.6145  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 1.7504  Validation loss = 7.6129  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 1.7501  Validation loss = 7.6112  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 1.7499  Validation loss = 7.6103  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 1.7495  Validation loss = 7.6066  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 1.7492  Validation loss = 7.6047  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 1.7487  Validation loss = 7.6021  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 1.7484  Validation loss = 7.5991  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 1.7481  Validation loss = 7.5978  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 1.7480  Validation loss = 7.5974  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 1.7477  Validation loss = 7.5961  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 1.7474  Validation loss = 7.5951  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 1.7470  Validation loss = 7.5917  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 1.7467  Validation loss = 7.5910  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 1.7464  Validation loss = 7.5881  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 1.7459  Validation loss = 7.5841  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 1.7456  Validation loss = 7.5819  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 1.7454  Validation loss = 7.5814  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 1.7452  Validation loss = 7.5809  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 1.7449  Validation loss = 7.5785  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 1.7447  Validation loss = 7.5788  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 1.7445  Validation loss = 7.5772  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 1.7443  Validation loss = 7.5769  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 1.7439  Validation loss = 7.5736  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 1.7438  Validation loss = 7.5740  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 1.7435  Validation loss = 7.5724  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 1.7433  Validation loss = 7.5719  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 1.7430  Validation loss = 7.5703  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 1.7428  Validation loss = 7.5698  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 1.7425  Validation loss = 7.5676  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 1.7426  Validation loss = 7.5699  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 1.7421  Validation loss = 7.5672  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 1.7416  Validation loss = 7.5614  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 1.7413  Validation loss = 7.5600  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 1.7410  Validation loss = 7.5583  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 1.7407  Validation loss = 7.5560  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 1.7403  Validation loss = 7.5532  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 1.7400  Validation loss = 7.5517  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 1.7398  Validation loss = 7.5507  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 1.7394  Validation loss = 7.5466  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 1.7391  Validation loss = 7.5441  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 1.7388  Validation loss = 7.5413  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 1.7385  Validation loss = 7.5393  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 1.7383  Validation loss = 7.5382  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 1.7382  Validation loss = 7.5376  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 1.7380  Validation loss = 7.5365  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 1.7375  Validation loss = 7.5326  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 1.7373  Validation loss = 7.5302  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 1.7371  Validation loss = 7.5294  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 1.7369  Validation loss = 7.5274  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 1.7364  Validation loss = 7.5227  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 1.7363  Validation loss = 7.5214  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 1.7359  Validation loss = 7.5180  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 1.7355  Validation loss = 7.5162  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 1.7353  Validation loss = 7.5141  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 1.7351  Validation loss = 7.5135  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 1.7348  Validation loss = 7.5116  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 1.7345  Validation loss = 7.5098  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 1.7343  Validation loss = 7.5081  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 1.7339  Validation loss = 7.5055  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 1.7336  Validation loss = 7.5025  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 1.7333  Validation loss = 7.4994  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 1.7332  Validation loss = 7.5003  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 1.7328  Validation loss = 7.4965  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 1.7327  Validation loss = 7.4974  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 1.7326  Validation loss = 7.4970  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 1.7324  Validation loss = 7.4961  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 1.7323  Validation loss = 7.4955  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 1.7321  Validation loss = 7.4948  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 1.7316  Validation loss = 7.4910  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 1.7314  Validation loss = 7.4901  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 1.7310  Validation loss = 7.4865  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 1.7308  Validation loss = 7.4853  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 1.7305  Validation loss = 7.4826  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 1.7301  Validation loss = 7.4803  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 1.7296  Validation loss = 7.4751  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 1.7295  Validation loss = 7.4750  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 1.7291  Validation loss = 7.4720  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 1.7288  Validation loss = 7.4692  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 1.7286  Validation loss = 7.4692  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 1.7282  Validation loss = 7.4654  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 1.7279  Validation loss = 7.4632  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 1.7275  Validation loss = 7.4582  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 1.7273  Validation loss = 7.4595  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 1.7270  Validation loss = 7.4569  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 1.7267  Validation loss = 7.4557  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 1.7264  Validation loss = 7.4535  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 1.7262  Validation loss = 7.4534  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 1.7260  Validation loss = 7.4530  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 1.7257  Validation loss = 7.4499  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 1.7254  Validation loss = 7.4472  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 1.7251  Validation loss = 7.4434  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 1.7249  Validation loss = 7.4421  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 1.7246  Validation loss = 7.4394  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 1.7244  Validation loss = 7.4388  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 1.7241  Validation loss = 7.4368  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 1.7238  Validation loss = 7.4330  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 1.7237  Validation loss = 7.4345  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 1.7235  Validation loss = 7.4320  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 1.7232  Validation loss = 7.4312  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 1.7232  Validation loss = 7.4335  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 1.7229  Validation loss = 7.4321  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 1.7225  Validation loss = 7.4293  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 1.7222  Validation loss = 7.4260  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 1.7218  Validation loss = 7.4241  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 1.7213  Validation loss = 7.4188  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 1.7211  Validation loss = 7.4185  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 1.7210  Validation loss = 7.4174  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 1.7207  Validation loss = 7.4140  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 1.7205  Validation loss = 7.4130  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 1.7204  Validation loss = 7.4137  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 1.7203  Validation loss = 7.4126  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 1.7200  Validation loss = 7.4101  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 1.7198  Validation loss = 7.4080  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 1.7195  Validation loss = 7.4054  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 1.7193  Validation loss = 7.4041  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 1.7190  Validation loss = 7.4015  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 1.7188  Validation loss = 7.4009  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 1.7186  Validation loss = 7.4006  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 1.7183  Validation loss = 7.3979  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 1.7179  Validation loss = 7.3949  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 1.7177  Validation loss = 7.3927  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 1.7175  Validation loss = 7.3922  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 1.7173  Validation loss = 7.3921  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 1.7172  Validation loss = 7.3933  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 1.7170  Validation loss = 7.3925  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 1.7169  Validation loss = 7.3929  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 1.7167  Validation loss = 7.3917  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 1.7165  Validation loss = 7.3909  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 1.7163  Validation loss = 7.3881  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 1.7159  Validation loss = 7.3868  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 1.7159  Validation loss = 7.3873  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 1.7156  Validation loss = 7.3865  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 1.7154  Validation loss = 7.3862  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 1.7152  Validation loss = 7.3847  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 1.7149  Validation loss = 7.3820  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 1.7148  Validation loss = 7.3839  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 1.7147  Validation loss = 7.3851  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 1.7145  Validation loss = 7.3830  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 1.7143  Validation loss = 7.3824  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 1.7139  Validation loss = 7.3787  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 1.7135  Validation loss = 7.3750  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 1.7132  Validation loss = 7.3740  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 1.7129  Validation loss = 7.3719  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 1.7128  Validation loss = 7.3728  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 1.7124  Validation loss = 7.3684  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 1.7120  Validation loss = 7.3654  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 1.7118  Validation loss = 7.3643  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 1.7114  Validation loss = 7.3618  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 1.7111  Validation loss = 7.3589  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 1.7108  Validation loss = 7.3571  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 1.7105  Validation loss = 7.3553  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 1.7103  Validation loss = 7.3529  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 1.7101  Validation loss = 7.3536  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 1.7100  Validation loss = 7.3524  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 1.7098  Validation loss = 7.3521  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 1.7096  Validation loss = 7.3512  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 1.7095  Validation loss = 7.3527  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 1.7094  Validation loss = 7.3528  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 1.7092  Validation loss = 7.3516  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 1.7091  Validation loss = 7.3508  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 1.7089  Validation loss = 7.3495  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 1.7087  Validation loss = 7.3489  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 1.7084  Validation loss = 7.3466  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 1.7081  Validation loss = 7.3452  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 1.7077  Validation loss = 7.3422  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 1.7075  Validation loss = 7.3405  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 1.7072  Validation loss = 7.3397  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 1.7070  Validation loss = 7.3382  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 1.7068  Validation loss = 7.3374  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 1.7067  Validation loss = 7.3380  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 1.7064  Validation loss = 7.3363  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 1.7061  Validation loss = 7.3341  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 1.7058  Validation loss = 7.3326  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 1.7056  Validation loss = 7.3316  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 1.7055  Validation loss = 7.3317  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 1.7054  Validation loss = 7.3322  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 1.7052  Validation loss = 7.3324  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 1.7051  Validation loss = 7.3328  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 1.7049  Validation loss = 7.3304  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 1.7045  Validation loss = 7.3277  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 1.7042  Validation loss = 7.3256  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 1.7040  Validation loss = 7.3245  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 1.7037  Validation loss = 7.3225  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 1.7034  Validation loss = 7.3197  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 1.7032  Validation loss = 7.3189  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 1.7030  Validation loss = 7.3186  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 1.7027  Validation loss = 7.3166  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 1.7025  Validation loss = 7.3144  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 1.7021  Validation loss = 7.3118  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 1.7019  Validation loss = 7.3105  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 1.7018  Validation loss = 7.3112  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 1.7015  Validation loss = 7.3096  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 1.7013  Validation loss = 7.3098  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 1.7011  Validation loss = 7.3084  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 1.7010  Validation loss = 7.3082  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 1.7007  Validation loss = 7.3073  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 1.7004  Validation loss = 7.3037  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 1.7001  Validation loss = 7.3024  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 1.7000  Validation loss = 7.3006  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 1.6996  Validation loss = 7.2973  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 1.6994  Validation loss = 7.2956  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 1.6993  Validation loss = 7.2964  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 1.6990  Validation loss = 7.2950  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 1.6988  Validation loss = 7.2939  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 1.6987  Validation loss = 7.2933  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 1.6984  Validation loss = 7.2898  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 1.6982  Validation loss = 7.2897  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 1.6980  Validation loss = 7.2888  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 1.6977  Validation loss = 7.2870  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 1.6975  Validation loss = 7.2875  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 1.6973  Validation loss = 7.2851  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 1.6972  Validation loss = 7.2844  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 1.6971  Validation loss = 7.2837  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 1.6968  Validation loss = 7.2820  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 1.6965  Validation loss = 7.2793  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 1.6963  Validation loss = 7.2783  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 1.6961  Validation loss = 7.2768  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 1.6959  Validation loss = 7.2748  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 1.6958  Validation loss = 7.2750  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 1.6956  Validation loss = 7.2751  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 1.6954  Validation loss = 7.2747  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 1.6952  Validation loss = 7.2748  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 1.6950  Validation loss = 7.2725  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 1.6949  Validation loss = 7.2724  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 1.6947  Validation loss = 7.2711  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 1.6945  Validation loss = 7.2707  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 1.6943  Validation loss = 7.2715  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 1.6941  Validation loss = 7.2702  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 1.6940  Validation loss = 7.2712  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 1.6936  Validation loss = 7.2682  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 1.6935  Validation loss = 7.2674  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 1.6931  Validation loss = 7.2647  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 1.6929  Validation loss = 7.2640  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 1.6927  Validation loss = 7.2623  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 1.6924  Validation loss = 7.2619  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 1.6924  Validation loss = 7.2631  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 1.6922  Validation loss = 7.2630  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 1.6919  Validation loss = 7.2605  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 1.6918  Validation loss = 7.2609  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 1.6916  Validation loss = 7.2599  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 1.6915  Validation loss = 7.2613  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 1.6913  Validation loss = 7.2607  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 1.6910  Validation loss = 7.2597  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 1.6909  Validation loss = 7.2589  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 1.6907  Validation loss = 7.2584  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 1.6906  Validation loss = 7.2583  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 1.6905  Validation loss = 7.2592  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 1.6902  Validation loss = 7.2581  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 1.6900  Validation loss = 7.2571  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 1.6898  Validation loss = 7.2564  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 1.6896  Validation loss = 7.2555  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 1.6893  Validation loss = 7.2530  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 1.6890  Validation loss = 7.2513  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 1.6886  Validation loss = 7.2480  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 1.6884  Validation loss = 7.2461  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 1.6882  Validation loss = 7.2449  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 1.6878  Validation loss = 7.2423  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 1.6876  Validation loss = 7.2403  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 1.6873  Validation loss = 7.2380  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 1.6872  Validation loss = 7.2388  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 1.6871  Validation loss = 7.2384  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 1.6869  Validation loss = 7.2382  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 1.6868  Validation loss = 7.2376  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 1.6865  Validation loss = 7.2363  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 1.6864  Validation loss = 7.2367  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 1.6860  Validation loss = 7.2337  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 1.6860  Validation loss = 7.2339  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 1.6857  Validation loss = 7.2317  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 1.6855  Validation loss = 7.2301  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 1.6852  Validation loss = 7.2278  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 1.6850  Validation loss = 7.2272  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 1.6849  Validation loss = 7.2270  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 1.6847  Validation loss = 7.2269  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 1.6845  Validation loss = 7.2266  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 1.6842  Validation loss = 7.2243  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 1.6841  Validation loss = 7.2237  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 1.6839  Validation loss = 7.2223  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 1.6836  Validation loss = 7.2214  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 1.6834  Validation loss = 7.2190  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 1.6831  Validation loss = 7.2163  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 1.6830  Validation loss = 7.2177  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 1.6828  Validation loss = 7.2163  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 1.6827  Validation loss = 7.2167  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 1.6825  Validation loss = 7.2161  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 1.6824  Validation loss = 7.2168  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 1.6821  Validation loss = 7.2145  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 1.6818  Validation loss = 7.2113  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 1.6814  Validation loss = 7.2080  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.3963  Validation loss = 2.8381  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.3952  Validation loss = 2.8352  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.3931  Validation loss = 2.8298  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.3899  Validation loss = 2.8204  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.3889  Validation loss = 2.8176  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.3869  Validation loss = 2.8115  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.3856  Validation loss = 2.8083  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.3841  Validation loss = 2.8034  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 2.3821  Validation loss = 2.7969  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.3798  Validation loss = 2.7908  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.3774  Validation loss = 2.7845  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.3756  Validation loss = 2.7799  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.3742  Validation loss = 2.7765  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 2.3715  Validation loss = 2.7693  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 2.3704  Validation loss = 2.7670  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 2.3692  Validation loss = 2.7637  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 2.3682  Validation loss = 2.7617  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 2.3672  Validation loss = 2.7594  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 2.3650  Validation loss = 2.7543  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 2.3640  Validation loss = 2.7521  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 2.3611  Validation loss = 2.7483  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 2.3598  Validation loss = 2.7452  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 2.3566  Validation loss = 2.7361  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 2.3521  Validation loss = 2.7218  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 2.3500  Validation loss = 2.7159  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 2.3478  Validation loss = 2.7102  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 2.3461  Validation loss = 2.7060  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 2.3442  Validation loss = 2.7012  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 2.3434  Validation loss = 2.6990  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 2.3417  Validation loss = 2.6944  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 2.3401  Validation loss = 2.6905  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 2.3384  Validation loss = 2.6863  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 2.3380  Validation loss = 2.6854  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 2.3366  Validation loss = 2.6816  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 2.3349  Validation loss = 2.6772  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 2.3345  Validation loss = 2.6764  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 2.3337  Validation loss = 2.6746  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 2.3325  Validation loss = 2.6712  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 2.3312  Validation loss = 2.6675  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 2.3290  Validation loss = 2.6617  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 2.3281  Validation loss = 2.6593  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 2.3229  Validation loss = 2.6318  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 2.3223  Validation loss = 2.6300  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 2.3204  Validation loss = 2.6150  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 2.3169  Validation loss = 2.5917  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 2.3150  Validation loss = 2.5865  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 2.3139  Validation loss = 2.5837  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 2.3128  Validation loss = 2.5804  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 2.3121  Validation loss = 2.5791  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 2.3101  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 2.3088  Validation loss = 2.5695  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 2.3071  Validation loss = 2.5655  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 2.3049  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 2.3036  Validation loss = 2.5554  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 2.3024  Validation loss = 2.5515  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 2.3012  Validation loss = 2.5476  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 2.3006  Validation loss = 2.5459  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 2.2995  Validation loss = 2.5415  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 2.2974  Validation loss = 2.5276  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 2.2962  Validation loss = 2.5190  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 2.2949  Validation loss = 2.5067  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 2.2946  Validation loss = 2.5036  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 2.2917  Validation loss = 2.4779  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 2.2908  Validation loss = 2.4739  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 2.2891  Validation loss = 2.4666  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 2.2868  Validation loss = 2.4591  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 2.2853  Validation loss = 2.4548  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 2.2839  Validation loss = 2.4509  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 2.2838  Validation loss = 2.4511  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 2.2823  Validation loss = 2.4469  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 2.2820  Validation loss = 2.4464  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 2.2806  Validation loss = 2.4427  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 2.2792  Validation loss = 2.4383  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 2.2784  Validation loss = 2.4366  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 2.2763  Validation loss = 2.4292  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 2.2740  Validation loss = 2.4121  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 2.2740  Validation loss = 2.4120  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 2.2720  Validation loss = 2.3742  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 2.2699  Validation loss = 2.3578  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 2.2691  Validation loss = 2.3563  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 2.2679  Validation loss = 2.3515  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 2.2672  Validation loss = 2.3500  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 2.2657  Validation loss = 2.3454  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 2.2646  Validation loss = 2.3422  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 2.2631  Validation loss = 2.3376  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 2.2619  Validation loss = 2.3342  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 2.2603  Validation loss = 2.3291  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 2.2591  Validation loss = 2.3257  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 2.2582  Validation loss = 2.3234  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 2.2570  Validation loss = 2.3205  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 2.2565  Validation loss = 2.3196  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 2.2551  Validation loss = 2.3161  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 2.2536  Validation loss = 2.3126  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 2.2524  Validation loss = 2.3100  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 2.2507  Validation loss = 2.3057  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 2.2495  Validation loss = 2.3028  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 2.2480  Validation loss = 2.2988  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 2.2473  Validation loss = 2.2975  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 2.2463  Validation loss = 2.2947  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 2.2451  Validation loss = 2.2918  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 2.2444  Validation loss = 2.2907  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 2.2427  Validation loss = 2.2865  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 2.2408  Validation loss = 2.2817  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 2.2396  Validation loss = 2.2788  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 2.2381  Validation loss = 2.2746  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 2.2373  Validation loss = 2.2728  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 2.2355  Validation loss = 2.2679  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 2.2350  Validation loss = 2.2674  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 2.2328  Validation loss = 2.2611  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 2.2320  Validation loss = 2.2588  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 2.2300  Validation loss = 2.2541  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 2.2286  Validation loss = 2.2513  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 2.2278  Validation loss = 2.2489  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 2.2269  Validation loss = 2.2463  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 2.2248  Validation loss = 2.2410  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 2.2241  Validation loss = 2.2391  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 2.2232  Validation loss = 2.2370  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 2.2225  Validation loss = 2.2356  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 2.2202  Validation loss = 2.2294  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 2.2186  Validation loss = 2.2256  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 2.2172  Validation loss = 2.2222  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 2.2152  Validation loss = 2.2171  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 2.2143  Validation loss = 2.2147  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 2.2128  Validation loss = 2.2106  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 2.2117  Validation loss = 2.2083  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 2.2110  Validation loss = 2.2070  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 2.2106  Validation loss = 2.2065  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 2.2092  Validation loss = 2.2031  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 2.2075  Validation loss = 2.1990  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 2.2066  Validation loss = 2.1969  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 2.2055  Validation loss = 2.1947  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 2.2036  Validation loss = 2.1897  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 2.2024  Validation loss = 2.1869  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 2.2014  Validation loss = 2.1847  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 2.2003  Validation loss = 2.1819  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 2.1988  Validation loss = 2.1784  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 2.1970  Validation loss = 2.1735  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 2.1958  Validation loss = 2.1710  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 2.1951  Validation loss = 2.1702  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 2.1937  Validation loss = 2.1663  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 2.1926  Validation loss = 2.1639  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 2.1918  Validation loss = 2.1622  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 2.1905  Validation loss = 2.1596  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 2.1902  Validation loss = 2.1592  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 2.1886  Validation loss = 2.1559  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 2.1873  Validation loss = 2.1531  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 2.1863  Validation loss = 2.1504  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 2.1847  Validation loss = 2.1462  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 2.1842  Validation loss = 2.1451  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 2.1834  Validation loss = 2.1431  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 2.1824  Validation loss = 2.1407  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 2.1813  Validation loss = 2.1383  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 2.1796  Validation loss = 2.1342  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 2.1781  Validation loss = 2.1303  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 2.1768  Validation loss = 2.1276  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 2.1749  Validation loss = 2.1226  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 2.1731  Validation loss = 2.1183  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 2.1711  Validation loss = 2.1128  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 2.1700  Validation loss = 2.1097  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 2.1688  Validation loss = 2.1066  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 2.1681  Validation loss = 2.1049  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 2.1665  Validation loss = 2.0994  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 2.1620  Validation loss = 2.0746  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 2.1609  Validation loss = 2.0718  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 2.1602  Validation loss = 2.0698  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 2.1597  Validation loss = 2.0689  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 2.1587  Validation loss = 2.0663  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 2.1579  Validation loss = 2.0647  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 2.1571  Validation loss = 2.0634  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 2.1564  Validation loss = 2.0618  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 2.1563  Validation loss = 2.0622  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 2.1545  Validation loss = 2.0576  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 2.1538  Validation loss = 2.0554  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 2.1529  Validation loss = 2.0534  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 2.1520  Validation loss = 2.0516  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 2.1511  Validation loss = 2.0497  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 2.1504  Validation loss = 2.0485  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 2.1501  Validation loss = 2.0475  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 2.1495  Validation loss = 2.0459  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 2.1486  Validation loss = 2.0433  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 2.1480  Validation loss = 2.0425  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 2.1462  Validation loss = 2.0358  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 2.1448  Validation loss = 2.0262  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 2.1412  Validation loss = 1.9681  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 2.1407  Validation loss = 1.9676  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 2.1401  Validation loss = 1.9660  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 2.1396  Validation loss = 1.9649  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 2.1389  Validation loss = 1.9633  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 2.1381  Validation loss = 1.9612  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 2.1373  Validation loss = 1.9597  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 2.1363  Validation loss = 1.9567  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 2.1358  Validation loss = 1.9565  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 2.1347  Validation loss = 1.9540  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 2.1331  Validation loss = 1.9502  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 2.1320  Validation loss = 1.9474  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 2.1312  Validation loss = 1.9457  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 2.1303  Validation loss = 1.9442  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 2.1292  Validation loss = 1.9410  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 2.1288  Validation loss = 1.9401  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 2.1281  Validation loss = 1.9383  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 2.1267  Validation loss = 1.9349  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 2.1261  Validation loss = 1.9332  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 2.1253  Validation loss = 1.9313  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 2.1241  Validation loss = 1.9288  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 2.1235  Validation loss = 1.9275  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 2.1230  Validation loss = 1.9260  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 2.1226  Validation loss = 1.9257  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 2.1212  Validation loss = 1.9218  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 2.1199  Validation loss = 1.9184  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 2.1194  Validation loss = 1.9177  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 2.1177  Validation loss = 1.9135  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 2.1171  Validation loss = 1.9116  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 2.1159  Validation loss = 1.9087  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 2.1144  Validation loss = 1.9047  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 2.1125  Validation loss = 1.9007  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 2.1118  Validation loss = 1.8986  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 2.1110  Validation loss = 1.8968  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 2.1102  Validation loss = 1.8943  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 2.1093  Validation loss = 1.8929  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 2.1085  Validation loss = 1.8909  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 2.1077  Validation loss = 1.8894  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 2.1071  Validation loss = 1.8879  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 2.1058  Validation loss = 1.8849  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 2.1052  Validation loss = 1.8831  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 2.1040  Validation loss = 1.8804  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 2.1031  Validation loss = 1.8783  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 2.1021  Validation loss = 1.8759  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 2.1008  Validation loss = 1.8721  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 2.0994  Validation loss = 1.8681  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 2.0981  Validation loss = 1.8643  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 2.0974  Validation loss = 1.8630  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 2.0960  Validation loss = 1.8594  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 2.0957  Validation loss = 1.8595  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 2.0952  Validation loss = 1.8584  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 2.0946  Validation loss = 1.8574  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 2.0940  Validation loss = 1.8564  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 2.0932  Validation loss = 1.8547  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 2.0926  Validation loss = 1.8536  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 2.0920  Validation loss = 1.8527  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 2.0911  Validation loss = 1.8496  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 2.0903  Validation loss = 1.8480  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 2.0897  Validation loss = 1.8461  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 2.0891  Validation loss = 1.8447  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 2.0885  Validation loss = 1.8438  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 2.0872  Validation loss = 1.8403  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 2.0862  Validation loss = 1.8372  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 2.0855  Validation loss = 1.8349  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 2.0849  Validation loss = 1.8335  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 2.0843  Validation loss = 1.8320  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 2.0834  Validation loss = 1.8303  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 2.0827  Validation loss = 1.8297  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 2.0816  Validation loss = 1.8273  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 2.0805  Validation loss = 1.8242  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 2.0801  Validation loss = 1.8235  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 2.0789  Validation loss = 1.8213  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 2.0782  Validation loss = 1.8188  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 2.0772  Validation loss = 1.8156  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 2.0769  Validation loss = 1.8161  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 2.0762  Validation loss = 1.8146  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 2.0756  Validation loss = 1.8136  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 2.0749  Validation loss = 1.8128  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 2.0739  Validation loss = 1.8099  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 2.0726  Validation loss = 1.8071  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 2.0721  Validation loss = 1.8058  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 2.0720  Validation loss = 1.8061  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 2.0716  Validation loss = 1.8056  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 2.0706  Validation loss = 1.8044  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 2.0700  Validation loss = 1.8036  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 2.0694  Validation loss = 1.8011  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 2.0686  Validation loss = 1.7992  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 2.0674  Validation loss = 1.7969  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 2.0668  Validation loss = 1.7958  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 2.0657  Validation loss = 1.7910  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 2.0654  Validation loss = 1.7897  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 2.0644  Validation loss = 1.7872  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 2.0635  Validation loss = 1.7846  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 2.0625  Validation loss = 1.7814  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 2.0616  Validation loss = 1.7791  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 2.0605  Validation loss = 1.7777  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 2.0598  Validation loss = 1.7769  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 2.0592  Validation loss = 1.7760  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 2.0589  Validation loss = 1.7759  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 2.0583  Validation loss = 1.7732  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 2.0578  Validation loss = 1.7722  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 2.0565  Validation loss = 1.7670  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 2.0562  Validation loss = 1.7679  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 2.0555  Validation loss = 1.7645  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 2.0545  Validation loss = 1.7618  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 2.0535  Validation loss = 1.7576  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 2.0529  Validation loss = 1.7547  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 2.0524  Validation loss = 1.7520  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 2.0519  Validation loss = 1.7496  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 2.0506  Validation loss = 1.7426  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 2.0499  Validation loss = 1.7397  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 2.0493  Validation loss = 1.7378  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 2.0492  Validation loss = 1.7380  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 2.0486  Validation loss = 1.7353  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 2.0480  Validation loss = 1.7335  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 2.0472  Validation loss = 1.7302  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 2.0463  Validation loss = 1.7281  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 2.0461  Validation loss = 1.7288  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 2.0456  Validation loss = 1.7275  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 2.0449  Validation loss = 1.7251  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 2.0440  Validation loss = 1.7232  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 2.0428  Validation loss = 1.7173  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 2.0422  Validation loss = 1.7167  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 2.0419  Validation loss = 1.7160  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 2.0413  Validation loss = 1.7136  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 2.0409  Validation loss = 1.7124  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 2.0400  Validation loss = 1.7097  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 2.0388  Validation loss = 1.7060  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 2.0382  Validation loss = 1.7049  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 2.0366  Validation loss = 1.6937  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 2.0352  Validation loss = 1.6860  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 2.0341  Validation loss = 1.6830  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 2.0335  Validation loss = 1.6807  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 2.0332  Validation loss = 1.6798  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 2.0330  Validation loss = 1.6803  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 2.0327  Validation loss = 1.6794  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 2.0318  Validation loss = 1.6769  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 2.0312  Validation loss = 1.6746  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 2.0306  Validation loss = 1.6709  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 2.0293  Validation loss = 1.6636  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 2.0286  Validation loss = 1.6613  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 2.0276  Validation loss = 1.6586  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 2.0270  Validation loss = 1.6603  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 2.0263  Validation loss = 1.6601  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 2.0256  Validation loss = 1.6582  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 2.0249  Validation loss = 1.6576  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 2.0240  Validation loss = 1.6523  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 2.0237  Validation loss = 1.6509  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 2.0233  Validation loss = 1.6519  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 2.0226  Validation loss = 1.6474  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 2.0217  Validation loss = 1.6438  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 2.0209  Validation loss = 1.6405  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 2.0201  Validation loss = 1.6436  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 2.0190  Validation loss = 1.6430  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 2.0183  Validation loss = 1.6409  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 2.0179  Validation loss = 1.6402  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 2.0159  Validation loss = 1.6218  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 2.0151  Validation loss = 1.6205  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 2.0144  Validation loss = 1.6201  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 2.0137  Validation loss = 1.6154  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 2.0131  Validation loss = 1.6129  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 2.0125  Validation loss = 1.6089  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 2.0115  Validation loss = 1.6036  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 2.0109  Validation loss = 1.5986  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 2.0102  Validation loss = 1.5984  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 2.0098  Validation loss = 1.5908  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 2.0088  Validation loss = 1.5889  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 2.0080  Validation loss = 1.5878  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 2.0076  Validation loss = 1.5890  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 2.0071  Validation loss = 1.5893  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 2.0064  Validation loss = 1.5846  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 2.0057  Validation loss = 1.5766  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 2.0052  Validation loss = 1.5797  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 2.0041  Validation loss = 1.5834  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 2.0035  Validation loss = 1.5790  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 2.0027  Validation loss = 1.5810  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 2.0022  Validation loss = 1.5766  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 2.0021  Validation loss = 1.5776  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 2.0014  Validation loss = 1.5764  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 2.0007  Validation loss = 1.5785  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 2.0002  Validation loss = 1.5778  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 1.9997  Validation loss = 1.5778  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 1.9989  Validation loss = 1.5824  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 1.9980  Validation loss = 1.5806  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 1.9974  Validation loss = 1.5832  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 362  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.9854  Validation loss = 1.1891  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.9847  Validation loss = 1.1913  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.9842  Validation loss = 1.1901  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.9833  Validation loss = 1.1910  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.9828  Validation loss = 1.1929  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.9817  Validation loss = 1.1952  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.9812  Validation loss = 1.1946  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.9795  Validation loss = 1.1956  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.9783  Validation loss = 1.2009  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.9768  Validation loss = 1.2025  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.9739  Validation loss = 1.2046  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 1  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.9641  Validation loss = 1.0284  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.9636  Validation loss = 1.0288  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.9629  Validation loss = 1.0298  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.9624  Validation loss = 1.0307  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.9617  Validation loss = 1.0324  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.9607  Validation loss = 1.0342  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.9602  Validation loss = 1.0352  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.9596  Validation loss = 1.0367  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.9589  Validation loss = 1.0384  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.9577  Validation loss = 1.0412  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.9571  Validation loss = 1.0423  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 1  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.9403  Validation loss = 2.5994  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.9391  Validation loss = 2.5997  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.9380  Validation loss = 2.5938  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.9379  Validation loss = 2.5958  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.9373  Validation loss = 2.5924  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.9365  Validation loss = 2.5885  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.9358  Validation loss = 2.5854  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.9355  Validation loss = 2.5875  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.9349  Validation loss = 2.5823  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.9346  Validation loss = 2.5839  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.9340  Validation loss = 2.5822  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.9333  Validation loss = 2.5798  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 1.9327  Validation loss = 2.5761  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 1.9323  Validation loss = 2.5768  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 1.9318  Validation loss = 2.5736  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 1.9312  Validation loss = 2.5722  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 1.9309  Validation loss = 2.5730  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 1.9305  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 1.9305  Validation loss = 2.5758  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 1.9301  Validation loss = 2.5748  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 1.9298  Validation loss = 2.5765  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 1.9293  Validation loss = 2.5744  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 1.9289  Validation loss = 2.5739  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 1.9286  Validation loss = 2.5712  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 1.9280  Validation loss = 2.5682  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 1.9277  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 1.9272  Validation loss = 2.5665  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 1.9268  Validation loss = 2.5654  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 1.9263  Validation loss = 2.5634  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 1.9258  Validation loss = 2.5616  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 1.9252  Validation loss = 2.5593  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 1.9248  Validation loss = 2.5571  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 1.9244  Validation loss = 2.5572  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 1.9242  Validation loss = 2.5601  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 1.9237  Validation loss = 2.5603  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 1.9234  Validation loss = 2.5610  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 1.9230  Validation loss = 2.5595  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 1.9226  Validation loss = 2.5588  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 1.9223  Validation loss = 2.5574  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 1.9216  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 1.9212  Validation loss = 2.5520  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 1.9206  Validation loss = 2.5502  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 1.9203  Validation loss = 2.5512  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 1.9191  Validation loss = 2.5450  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 1.9185  Validation loss = 2.5466  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 1.9183  Validation loss = 2.5478  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 1.9180  Validation loss = 2.5492  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 1.9172  Validation loss = 2.5455  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 1.9167  Validation loss = 2.5462  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 1.9157  Validation loss = 2.5447  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 1.9156  Validation loss = 2.5474  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 1.9149  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 1.9144  Validation loss = 2.5467  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 1.9143  Validation loss = 2.5494  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 50  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.0111  Validation loss = 6.1009  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.0109  Validation loss = 6.1002  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.0094  Validation loss = 6.0953  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.0090  Validation loss = 6.0932  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.0086  Validation loss = 6.0912  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 2.0077  Validation loss = 6.0871  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.0068  Validation loss = 6.0828  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.0060  Validation loss = 6.0795  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.0054  Validation loss = 6.0776  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.0047  Validation loss = 6.0735  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.0042  Validation loss = 6.0708  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.0032  Validation loss = 6.0653  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.0020  Validation loss = 6.0594  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 2.0016  Validation loss = 6.0589  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.0007  Validation loss = 6.0548  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.0006  Validation loss = 6.0551  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.9991  Validation loss = 6.0472  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.9981  Validation loss = 6.0416  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.9972  Validation loss = 6.0375  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 1.9963  Validation loss = 6.0329  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 1.9953  Validation loss = 6.0288  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 1.9946  Validation loss = 6.0257  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 1.9937  Validation loss = 6.0218  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 1.9925  Validation loss = 6.0164  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 1.9923  Validation loss = 6.0157  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 1.9917  Validation loss = 6.0138  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 1.9913  Validation loss = 6.0117  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 1.9906  Validation loss = 6.0084  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 1.9901  Validation loss = 6.0054  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 1.9891  Validation loss = 6.0008  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 1.9885  Validation loss = 5.9992  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 1.9877  Validation loss = 5.9957  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 1.9872  Validation loss = 5.9932  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 1.9860  Validation loss = 5.9848  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 1.9855  Validation loss = 5.9827  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 1.9852  Validation loss = 5.9815  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 1.9847  Validation loss = 5.9792  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 1.9844  Validation loss = 5.9781  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 1.9838  Validation loss = 5.9748  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 1.9829  Validation loss = 5.9704  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 1.9825  Validation loss = 5.9684  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 1.9821  Validation loss = 5.9688  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 1.9820  Validation loss = 5.9693  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 1.9808  Validation loss = 5.9634  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 1.9805  Validation loss = 5.9622  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 1.9795  Validation loss = 5.9579  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 1.9792  Validation loss = 5.9564  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 1.9787  Validation loss = 5.9536  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 1.9783  Validation loss = 5.9527  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 1.9775  Validation loss = 5.9482  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 1.9768  Validation loss = 5.9446  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 1.9762  Validation loss = 5.9409  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 1.9758  Validation loss = 5.9396  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 1.9745  Validation loss = 5.9316  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 1.9746  Validation loss = 5.9330  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 1.9742  Validation loss = 5.9325  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 1.9741  Validation loss = 5.9324  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 1.9731  Validation loss = 5.9274  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 1.9726  Validation loss = 5.9247  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 1.9727  Validation loss = 5.9264  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 1.9720  Validation loss = 5.9227  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 1.9712  Validation loss = 5.9179  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 1.9709  Validation loss = 5.9181  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 1.9704  Validation loss = 5.9167  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 1.9700  Validation loss = 5.9150  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 1.9698  Validation loss = 5.9148  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 1.9693  Validation loss = 5.9112  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 1.9682  Validation loss = 5.9051  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 1.9679  Validation loss = 5.9036  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 1.9671  Validation loss = 5.8978  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 1.9668  Validation loss = 5.8969  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 1.9663  Validation loss = 5.8945  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 1.9656  Validation loss = 5.8910  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 1.9651  Validation loss = 5.8881  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 1.9648  Validation loss = 5.8866  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 1.9645  Validation loss = 5.8860  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 1.9642  Validation loss = 5.8835  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 1.9640  Validation loss = 5.8831  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 1.9636  Validation loss = 5.8818  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 1.9623  Validation loss = 5.8741  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 1.9617  Validation loss = 5.8708  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 1.9610  Validation loss = 5.8657  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 1.9607  Validation loss = 5.8653  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 1.9603  Validation loss = 5.8631  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 1.9603  Validation loss = 5.8650  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 1.9594  Validation loss = 5.8601  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 1.9590  Validation loss = 5.8567  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 1.9587  Validation loss = 5.8559  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 1.9583  Validation loss = 5.8511  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 1.9577  Validation loss = 5.8489  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 1.9574  Validation loss = 5.8483  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 1.9566  Validation loss = 5.8441  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 1.9563  Validation loss = 5.8450  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 1.9558  Validation loss = 5.8428  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 1.9552  Validation loss = 5.8390  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 1.9546  Validation loss = 5.8367  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 1.9540  Validation loss = 5.8325  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 1.9534  Validation loss = 5.8298  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 1.9530  Validation loss = 5.8273  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 1.9526  Validation loss = 5.8246  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 1.9522  Validation loss = 5.8246  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 1.9519  Validation loss = 5.8224  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 1.9516  Validation loss = 5.8204  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 1.9511  Validation loss = 5.8160  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 1.9509  Validation loss = 5.8164  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 1.9506  Validation loss = 5.8162  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 1.9501  Validation loss = 5.8129  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 1.9493  Validation loss = 5.8073  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 1.9487  Validation loss = 5.8041  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 1.9481  Validation loss = 5.8005  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 1.9475  Validation loss = 5.7962  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 1.9475  Validation loss = 5.7973  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 1.9473  Validation loss = 5.7982  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 1.9472  Validation loss = 5.8002  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 1.9465  Validation loss = 5.7950  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 1.9462  Validation loss = 5.7939  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 1.9459  Validation loss = 5.7930  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 1.9455  Validation loss = 5.7892  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 1.9449  Validation loss = 5.7862  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 1.9447  Validation loss = 5.7843  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 1.9441  Validation loss = 5.7812  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 1.9439  Validation loss = 5.7807  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 1.9430  Validation loss = 5.7732  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 1.9424  Validation loss = 5.7704  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 1.9415  Validation loss = 5.7627  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 1.9411  Validation loss = 5.7629  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 1.9406  Validation loss = 5.7606  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 1.9399  Validation loss = 5.7568  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 1.9395  Validation loss = 5.7529  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 1.9390  Validation loss = 5.7514  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 1.9383  Validation loss = 5.7476  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 1.9379  Validation loss = 5.7445  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 1.9377  Validation loss = 5.7432  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 1.9371  Validation loss = 5.7397  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 1.9366  Validation loss = 5.7356  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 1.9361  Validation loss = 5.7333  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 1.9354  Validation loss = 5.7290  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 1.9352  Validation loss = 5.7277  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 1.9349  Validation loss = 5.7269  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 1.9346  Validation loss = 5.7258  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 1.9345  Validation loss = 5.7255  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 1.9341  Validation loss = 5.7224  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 1.9332  Validation loss = 5.7199  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 1.9325  Validation loss = 5.7154  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 1.9322  Validation loss = 5.7134  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 1.9311  Validation loss = 5.7115  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 1.9312  Validation loss = 5.7137  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 1.9295  Validation loss = 5.7105  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 1.9289  Validation loss = 5.7102  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 1.9289  Validation loss = 5.7139  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 1.9291  Validation loss = 5.7167  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 1.9283  Validation loss = 5.7150  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 1.9279  Validation loss = 5.7127  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 1.9275  Validation loss = 5.7124  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 1.9271  Validation loss = 5.7085  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 1.9268  Validation loss = 5.7067  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 1.9265  Validation loss = 5.7053  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 1.9262  Validation loss = 5.7028  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 1.9257  Validation loss = 5.7009  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 1.9257  Validation loss = 5.7040  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 1.9251  Validation loss = 5.7005  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 1.9247  Validation loss = 5.6976  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 1.9247  Validation loss = 5.6988  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 1.9245  Validation loss = 5.6984  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 1.9251  Validation loss = 5.7009  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 1.9244  Validation loss = 5.7009  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 1.9238  Validation loss = 5.6952  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 1.9238  Validation loss = 5.6949  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 1.9233  Validation loss = 5.6932  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 1.9230  Validation loss = 5.6912  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 1.9227  Validation loss = 5.6900  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 1.9224  Validation loss = 5.6881  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 1.9221  Validation loss = 5.6857  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 1.9217  Validation loss = 5.6838  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 1.9216  Validation loss = 5.6846  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 1.9212  Validation loss = 5.6843  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 1.9210  Validation loss = 5.6828  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 1.9206  Validation loss = 5.6820  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 1.9204  Validation loss = 5.6822  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 1.9199  Validation loss = 5.6776  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 1.9197  Validation loss = 5.6787  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 1.9197  Validation loss = 5.6785  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 1.9194  Validation loss = 5.6782  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 1.9192  Validation loss = 5.6795  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 1.9192  Validation loss = 5.6814  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 1.9190  Validation loss = 5.6804  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 1.9186  Validation loss = 5.6770  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 1.9182  Validation loss = 5.6749  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 1.9176  Validation loss = 5.6706  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 1.9171  Validation loss = 5.6648  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 1.9171  Validation loss = 5.6681  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 1.9168  Validation loss = 5.6678  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 1.9161  Validation loss = 5.6638  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 1.9155  Validation loss = 5.6626  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 1.9149  Validation loss = 5.6574  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 1.9144  Validation loss = 5.6563  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 1.9144  Validation loss = 5.6578  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 1.9139  Validation loss = 5.6532  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 1.9132  Validation loss = 5.6486  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 1.9131  Validation loss = 5.6493  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 1.9128  Validation loss = 5.6484  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 1.9122  Validation loss = 5.6410  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 1.9118  Validation loss = 5.6378  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 1.9113  Validation loss = 5.6349  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 1.9110  Validation loss = 5.6328  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 1.9108  Validation loss = 5.6310  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 1.9107  Validation loss = 5.6323  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 1.9103  Validation loss = 5.6287  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 1.9098  Validation loss = 5.6246  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 1.9094  Validation loss = 5.6231  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 1.9090  Validation loss = 5.6211  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 1.9088  Validation loss = 5.6202  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 1.9085  Validation loss = 5.6213  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 1.9081  Validation loss = 5.6172  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 1.9074  Validation loss = 5.6093  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 1.9070  Validation loss = 5.6030  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 1.9063  Validation loss = 5.6001  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 1.9058  Validation loss = 5.5940  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 1.9053  Validation loss = 5.5927  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 1.9050  Validation loss = 5.5908  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 1.9046  Validation loss = 5.5909  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 1.9052  Validation loss = 5.5914  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 1.9049  Validation loss = 5.5856  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 1.9041  Validation loss = 5.5790  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 1.9036  Validation loss = 5.5801  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 1.9033  Validation loss = 5.5792  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 1.9029  Validation loss = 5.5771  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 1.9025  Validation loss = 5.5772  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 1.9022  Validation loss = 5.5762  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 1.9018  Validation loss = 5.5760  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 1.9013  Validation loss = 5.5724  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 1.9011  Validation loss = 5.5731  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 1.9007  Validation loss = 5.5740  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 1.9001  Validation loss = 5.5716  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 1.8996  Validation loss = 5.5700  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 1.8994  Validation loss = 5.5677  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 1.8989  Validation loss = 5.5619  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 1.8989  Validation loss = 5.5643  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 1.8984  Validation loss = 5.5618  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 1.8979  Validation loss = 5.5598  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 1.8978  Validation loss = 5.5581  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 1.8973  Validation loss = 5.5542  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 1.8960  Validation loss = 5.5513  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 1.8958  Validation loss = 5.5503  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 1.8955  Validation loss = 5.5500  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 1.8946  Validation loss = 5.5425  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 1.8941  Validation loss = 5.5398  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 1.8940  Validation loss = 5.5404  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 1.8936  Validation loss = 5.5365  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 1.8933  Validation loss = 5.5369  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 1.8930  Validation loss = 5.5322  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 1.8926  Validation loss = 5.5303  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 1.8922  Validation loss = 5.5301  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 1.8917  Validation loss = 5.5267  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 1.8915  Validation loss = 5.5268  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 1.8912  Validation loss = 5.5242  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 1.8910  Validation loss = 5.5238  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 1.8908  Validation loss = 5.5235  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 1.8907  Validation loss = 5.5225  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 1.8900  Validation loss = 5.5186  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 1.8895  Validation loss = 5.5161  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 1.8892  Validation loss = 5.5168  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 1.8889  Validation loss = 5.5144  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 1.8885  Validation loss = 5.5133  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 1.8881  Validation loss = 5.5114  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 1.8878  Validation loss = 5.5085  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 1.8874  Validation loss = 5.5035  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 1.8870  Validation loss = 5.5018  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 1.8866  Validation loss = 5.5005  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 1.8863  Validation loss = 5.4987  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 1.8859  Validation loss = 5.4952  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 1.8857  Validation loss = 5.4963  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 1.8855  Validation loss = 5.4989  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 1.8860  Validation loss = 5.5008  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 1.8852  Validation loss = 5.5010  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 1.8850  Validation loss = 5.5018  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 1.8849  Validation loss = 5.5000  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 1.8844  Validation loss = 5.4947  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 1.8842  Validation loss = 5.4930  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 1.8839  Validation loss = 5.4896  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 1.8837  Validation loss = 5.4855  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 1.8833  Validation loss = 5.4845  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 1.8830  Validation loss = 5.4810  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 1.8828  Validation loss = 5.4834  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 1.8826  Validation loss = 5.4807  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 1.8821  Validation loss = 5.4778  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 1.8819  Validation loss = 5.4749  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 1.8816  Validation loss = 5.4775  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 1.8814  Validation loss = 5.4784  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 1.8818  Validation loss = 5.4806  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 1.8812  Validation loss = 5.4774  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 1.8811  Validation loss = 5.4773  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 1.8809  Validation loss = 5.4757  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 1.8804  Validation loss = 5.4706  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 1.8798  Validation loss = 5.4666  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 1.8795  Validation loss = 5.4675  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 1.8791  Validation loss = 5.4664  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 1.8787  Validation loss = 5.4622  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 1.8784  Validation loss = 5.4568  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 1.8783  Validation loss = 5.4579  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 1.8781  Validation loss = 5.4570  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 1.8777  Validation loss = 5.4557  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 1.8773  Validation loss = 5.4532  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 1.8771  Validation loss = 5.4550  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 1.8766  Validation loss = 5.4523  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 1.8764  Validation loss = 5.4534  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 1.8763  Validation loss = 5.4548  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 1.8760  Validation loss = 5.4543  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 1.8756  Validation loss = 5.4472  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 1.8752  Validation loss = 5.4455  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 1.8748  Validation loss = 5.4435  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 1.8743  Validation loss = 5.4418  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 1.8740  Validation loss = 5.4407  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 1.8738  Validation loss = 5.4412  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 1.8736  Validation loss = 5.4400  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 1.8733  Validation loss = 5.4392  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 1.8732  Validation loss = 5.4394  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 1.8730  Validation loss = 5.4379  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 1.8728  Validation loss = 5.4364  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 1.8724  Validation loss = 5.4347  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 1.8722  Validation loss = 5.4353  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 1.8720  Validation loss = 5.4343  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 1.8730  Validation loss = 5.4415  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 322  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.2965  Validation loss = 5.4722  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.2946  Validation loss = 5.4648  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.2937  Validation loss = 5.4603  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.2920  Validation loss = 5.4565  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.2902  Validation loss = 5.4492  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.2897  Validation loss = 5.4482  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.2889  Validation loss = 5.4450  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.2873  Validation loss = 5.4389  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.2862  Validation loss = 5.4307  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.2850  Validation loss = 5.4240  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.2848  Validation loss = 5.4247  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.2838  Validation loss = 5.4245  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.2821  Validation loss = 5.4167  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.2799  Validation loss = 5.4086  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.2787  Validation loss = 5.4084  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.2770  Validation loss = 5.3997  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.2755  Validation loss = 5.3916  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 2.2741  Validation loss = 5.3857  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.2735  Validation loss = 5.3822  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.2729  Validation loss = 5.3825  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.2720  Validation loss = 5.3809  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 2.2702  Validation loss = 5.3730  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 2.2683  Validation loss = 5.3658  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.2680  Validation loss = 5.3641  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 2.2669  Validation loss = 5.3603  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 2.2662  Validation loss = 5.3598  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 2.2647  Validation loss = 5.3527  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 2.2637  Validation loss = 5.3454  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 2.2625  Validation loss = 5.3378  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 2.2620  Validation loss = 5.3383  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 2.2615  Validation loss = 5.3380  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 2.2605  Validation loss = 5.3342  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 2.2599  Validation loss = 5.3300  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 2.2588  Validation loss = 5.3264  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 2.2574  Validation loss = 5.3195  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 2.2560  Validation loss = 5.3138  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 2.2554  Validation loss = 5.3123  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 2.2544  Validation loss = 5.3043  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 2.2532  Validation loss = 5.3006  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 2.2516  Validation loss = 5.2982  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 2.2506  Validation loss = 5.2920  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 2.2499  Validation loss = 5.2919  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 2.2487  Validation loss = 5.2874  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 2.2482  Validation loss = 5.2844  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 2.2474  Validation loss = 5.2847  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 2.2466  Validation loss = 5.2823  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 2.2456  Validation loss = 5.2795  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 2.2444  Validation loss = 5.2734  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 2.2430  Validation loss = 5.2663  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 2.2423  Validation loss = 5.2650  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 2.2408  Validation loss = 5.2602  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 2.2401  Validation loss = 5.2634  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 2.2391  Validation loss = 5.2620  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 2.2374  Validation loss = 5.2556  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 2.2363  Validation loss = 5.2530  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 2.2357  Validation loss = 5.2537  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 2.2343  Validation loss = 5.2490  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 2.2327  Validation loss = 5.2414  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 2.2324  Validation loss = 5.2433  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 2.2309  Validation loss = 5.2372  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 2.2296  Validation loss = 5.2307  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 2.2292  Validation loss = 5.2280  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 2.2283  Validation loss = 5.2220  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 2.2276  Validation loss = 5.2194  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 2.2272  Validation loss = 5.2203  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 2.2259  Validation loss = 5.2124  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 2.2243  Validation loss = 5.2059  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 2.2238  Validation loss = 5.2015  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 2.2231  Validation loss = 5.1989  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 2.2227  Validation loss = 5.1990  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 2.2227  Validation loss = 5.2024  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 2.2218  Validation loss = 5.1969  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 2.2211  Validation loss = 5.1967  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 2.2202  Validation loss = 5.1948  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 2.2193  Validation loss = 5.1931  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 2.2185  Validation loss = 5.1907  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 2.2176  Validation loss = 5.1873  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 2.2166  Validation loss = 5.1804  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 2.2160  Validation loss = 5.1781  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 2.2149  Validation loss = 5.1737  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 2.2140  Validation loss = 5.1737  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 2.2129  Validation loss = 5.1657  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 2.2121  Validation loss = 5.1629  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 2.2112  Validation loss = 5.1591  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 2.2101  Validation loss = 5.1507  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 2.2092  Validation loss = 5.1496  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 2.2085  Validation loss = 5.1438  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 2.2074  Validation loss = 5.1393  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 2.2065  Validation loss = 5.1339  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 2.2058  Validation loss = 5.1296  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 2.2050  Validation loss = 5.1246  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 2.2042  Validation loss = 5.1208  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 2.2035  Validation loss = 5.1212  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 2.2030  Validation loss = 5.1226  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 2.2043  Validation loss = 5.1267  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 2.2049  Validation loss = 5.1209  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 2.2040  Validation loss = 5.1246  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 2.2035  Validation loss = 5.1270  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 2.2023  Validation loss = 5.1240  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 2.2007  Validation loss = 5.1188  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 2.1997  Validation loss = 5.1174  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 2.1993  Validation loss = 5.1206  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 2.1984  Validation loss = 5.1187  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 2.1973  Validation loss = 5.1137  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 2.1962  Validation loss = 5.1085  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 2.1953  Validation loss = 5.1039  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 2.1941  Validation loss = 5.1010  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 2.1932  Validation loss = 5.0958  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 2.1925  Validation loss = 5.0910  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 2.1923  Validation loss = 5.0942  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 2.1907  Validation loss = 5.0848  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 2.1892  Validation loss = 5.0839  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 2.1881  Validation loss = 5.0807  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 2.1872  Validation loss = 5.0769  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 2.1866  Validation loss = 5.0754  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 2.1857  Validation loss = 5.0728  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 2.1855  Validation loss = 5.0692  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 2.1848  Validation loss = 5.0688  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 2.1836  Validation loss = 5.0640  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 2.1824  Validation loss = 5.0599  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 2.1817  Validation loss = 5.0569  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 2.1812  Validation loss = 5.0593  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 2.1801  Validation loss = 5.0528  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 2.1795  Validation loss = 5.0504  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 2.1787  Validation loss = 5.0466  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 2.1784  Validation loss = 5.0477  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 2.1773  Validation loss = 5.0397  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 2.1768  Validation loss = 5.0405  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 2.1759  Validation loss = 5.0335  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 2.1750  Validation loss = 5.0266  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 2.1741  Validation loss = 5.0231  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 2.1737  Validation loss = 5.0209  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 2.1731  Validation loss = 5.0157  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 2.1723  Validation loss = 5.0138  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 2.1718  Validation loss = 5.0141  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 2.1713  Validation loss = 5.0110  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 2.1705  Validation loss = 5.0080  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 2.1703  Validation loss = 5.0081  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 2.1700  Validation loss = 5.0026  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 2.1692  Validation loss = 4.9996  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 2.1688  Validation loss = 4.9962  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 2.1677  Validation loss = 4.9945  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 2.1671  Validation loss = 4.9965  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 2.1661  Validation loss = 4.9956  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 2.1652  Validation loss = 4.9908  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 2.1643  Validation loss = 4.9864  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 2.1635  Validation loss = 4.9888  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 2.1629  Validation loss = 4.9862  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 2.1626  Validation loss = 4.9891  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 2.1624  Validation loss = 4.9877  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 2.1616  Validation loss = 4.9866  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 2.1605  Validation loss = 4.9765  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 2.1597  Validation loss = 4.9732  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 2.1586  Validation loss = 4.9739  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 2.1578  Validation loss = 4.9700  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 2.1570  Validation loss = 4.9718  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 2.1559  Validation loss = 4.9660  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 2.1551  Validation loss = 4.9646  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 2.1547  Validation loss = 4.9622  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 2.1535  Validation loss = 4.9567  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 2.1530  Validation loss = 4.9551  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 2.1521  Validation loss = 4.9518  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 2.1519  Validation loss = 4.9526  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 2.1514  Validation loss = 4.9507  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 2.1507  Validation loss = 4.9469  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 2.1497  Validation loss = 4.9435  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 2.1493  Validation loss = 4.9468  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 2.1511  Validation loss = 4.9505  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 2.1488  Validation loss = 4.9464  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 2.1481  Validation loss = 4.9410  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 2.1476  Validation loss = 4.9366  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 2.1469  Validation loss = 4.9313  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 2.1463  Validation loss = 4.9355  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 2.1457  Validation loss = 4.9328  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 2.1448  Validation loss = 4.9332  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 2.1441  Validation loss = 4.9287  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 2.1436  Validation loss = 4.9283  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 2.1427  Validation loss = 4.9249  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 2.1421  Validation loss = 4.9261  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 2.1412  Validation loss = 4.9232  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 2.1411  Validation loss = 4.9266  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 2.1401  Validation loss = 4.9222  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 2.1391  Validation loss = 4.9162  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 2.1383  Validation loss = 4.9130  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 2.1374  Validation loss = 4.9108  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 2.1366  Validation loss = 4.9048  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 2.1359  Validation loss = 4.9047  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 2.1351  Validation loss = 4.9031  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 2.1346  Validation loss = 4.9038  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 2.1341  Validation loss = 4.9024  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 2.1335  Validation loss = 4.9005  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 2.1332  Validation loss = 4.9028  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 2.1324  Validation loss = 4.8936  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 2.1320  Validation loss = 4.8947  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 2.1314  Validation loss = 4.8934  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 2.1308  Validation loss = 4.8902  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 2.1300  Validation loss = 4.8828  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 2.1294  Validation loss = 4.8801  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 2.1285  Validation loss = 4.8702  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 2.1281  Validation loss = 4.8710  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 2.1271  Validation loss = 4.8728  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 2.1267  Validation loss = 4.8721  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 2.1268  Validation loss = 4.8743  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 2.1262  Validation loss = 4.8682  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 2.1259  Validation loss = 4.8701  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 2.1253  Validation loss = 4.8682  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 2.1249  Validation loss = 4.8707  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 2.1243  Validation loss = 4.8641  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 2.1240  Validation loss = 4.8670  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 2.1233  Validation loss = 4.8620  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 2.1224  Validation loss = 4.8605  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 2.1223  Validation loss = 4.8642  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 2.1277  Validation loss = 4.8662  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 2.1215  Validation loss = 4.8583  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 2.1210  Validation loss = 4.8618  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 2.1198  Validation loss = 4.8604  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 2.1190  Validation loss = 4.8564  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 2.1184  Validation loss = 4.8557  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 2.1176  Validation loss = 4.8528  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 2.1207  Validation loss = 4.8612  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 2.1170  Validation loss = 4.8543  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 2.1169  Validation loss = 4.8568  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 2.1166  Validation loss = 4.8549  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 2.1158  Validation loss = 4.8489  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 2.1152  Validation loss = 4.8466  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 2.1143  Validation loss = 4.8396  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 2.1134  Validation loss = 4.8354  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 2.1128  Validation loss = 4.8290  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 2.1125  Validation loss = 4.8275  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 2.1118  Validation loss = 4.8256  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 2.1109  Validation loss = 4.8232  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 2.1105  Validation loss = 4.8242  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 2.1097  Validation loss = 4.8196  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 2.1091  Validation loss = 4.8163  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 2.1088  Validation loss = 4.8180  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 2.1084  Validation loss = 4.8199  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 2.1079  Validation loss = 4.8172  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 2.1072  Validation loss = 4.8163  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 2.1064  Validation loss = 4.8103  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 2.1064  Validation loss = 4.8148  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 2.1055  Validation loss = 4.8092  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 2.1054  Validation loss = 4.8131  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 2.1043  Validation loss = 4.8075  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 2.1041  Validation loss = 4.8083  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 2.1039  Validation loss = 4.8114  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 2.1036  Validation loss = 4.8111  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 2.1024  Validation loss = 4.8051  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 2.1015  Validation loss = 4.7986  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 2.1009  Validation loss = 4.7961  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 2.1001  Validation loss = 4.7867  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 2.0996  Validation loss = 4.7883  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 2.0993  Validation loss = 4.7888  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 2.0990  Validation loss = 4.7895  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 2.0990  Validation loss = 4.7945  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 2.0979  Validation loss = 4.7864  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 2.0974  Validation loss = 4.7862  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 2.0970  Validation loss = 4.7847  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 2.0965  Validation loss = 4.7846  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 2.0960  Validation loss = 4.7840  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 2.0950  Validation loss = 4.7788  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 2.0943  Validation loss = 4.7752  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 2.0938  Validation loss = 4.7708  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 2.0929  Validation loss = 4.7639  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 2.0925  Validation loss = 4.7603  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 2.0923  Validation loss = 4.7613  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 2.0913  Validation loss = 4.7588  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 2.0905  Validation loss = 4.7553  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 2.0899  Validation loss = 4.7558  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 2.0892  Validation loss = 4.7517  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 2.0886  Validation loss = 4.7469  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 2.0876  Validation loss = 4.7408  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 2.0870  Validation loss = 4.7373  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 2.0862  Validation loss = 4.7362  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 2.0855  Validation loss = 4.7310  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 2.0851  Validation loss = 4.7278  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 2.0845  Validation loss = 4.7274  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 2.0839  Validation loss = 4.7239  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 2.0836  Validation loss = 4.7247  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 2.0827  Validation loss = 4.7211  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 2.0824  Validation loss = 4.7251  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 2.0819  Validation loss = 4.7219  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 2.0815  Validation loss = 4.7215  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 2.0808  Validation loss = 4.7160  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 2.0806  Validation loss = 4.7163  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 2.0799  Validation loss = 4.7124  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 2.0796  Validation loss = 4.7167  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 2.0792  Validation loss = 4.7134  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 2.0782  Validation loss = 4.7068  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 2.0774  Validation loss = 4.7039  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 2.0769  Validation loss = 4.7022  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 2.0762  Validation loss = 4.6990  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 2.0755  Validation loss = 4.6978  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 2.0754  Validation loss = 4.6996  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 2.0750  Validation loss = 4.6950  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 2.0746  Validation loss = 4.6970  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 2.0747  Validation loss = 4.6998  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 2.0738  Validation loss = 4.6988  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 2.0735  Validation loss = 4.6974  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 2.0726  Validation loss = 4.6934  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 2.0719  Validation loss = 4.6903  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 2.0714  Validation loss = 4.6863  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 2.0709  Validation loss = 4.6812  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 2.0706  Validation loss = 4.6880  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 2.0708  Validation loss = 4.6906  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 2.0703  Validation loss = 4.6913  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 2.0693  Validation loss = 4.6832  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 2.0685  Validation loss = 4.6824  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 2.0677  Validation loss = 4.6784  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 2.0674  Validation loss = 4.6791  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 2.0670  Validation loss = 4.6784  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 2.0667  Validation loss = 4.6749  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 2.0665  Validation loss = 4.6766  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 2.0657  Validation loss = 4.6718  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 2.0653  Validation loss = 4.6708  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 2.0649  Validation loss = 4.6676  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 2.0638  Validation loss = 4.6597  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 2.0632  Validation loss = 4.6544  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 2.0626  Validation loss = 4.6506  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 2.0624  Validation loss = 4.6471  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 2.0620  Validation loss = 4.6452  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 2.0615  Validation loss = 4.6482  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 2.0610  Validation loss = 4.6468  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 2.0606  Validation loss = 4.6503  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 2.0598  Validation loss = 4.6469  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 2.0594  Validation loss = 4.6459  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 2.0593  Validation loss = 4.6451  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 2.0588  Validation loss = 4.6427  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 2.0586  Validation loss = 4.6436  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 2.0584  Validation loss = 4.6391  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 2.0579  Validation loss = 4.6371  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 2.0573  Validation loss = 4.6383  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 2.0568  Validation loss = 4.6397  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 2.0567  Validation loss = 4.6428  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 2.0563  Validation loss = 4.6427  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 2.0551  Validation loss = 4.6346  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 2.0545  Validation loss = 4.6257  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 2.0538  Validation loss = 4.6211  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 2.0531  Validation loss = 4.6221  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 2.0526  Validation loss = 4.6197  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 2.0519  Validation loss = 4.6222  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 2.0511  Validation loss = 4.6204  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 2.0505  Validation loss = 4.6122  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 2.0501  Validation loss = 4.6159  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 2.0496  Validation loss = 4.6108  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 2.0490  Validation loss = 4.6038  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 2.0483  Validation loss = 4.5983  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 2.0480  Validation loss = 4.5967  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 2.0476  Validation loss = 4.5938  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 2.0467  Validation loss = 4.5953  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 2.0465  Validation loss = 4.5940  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 2.0460  Validation loss = 4.5893  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 2.0455  Validation loss = 4.5912  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 2.0452  Validation loss = 4.5864  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 2.0445  Validation loss = 4.5814  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 2.0441  Validation loss = 4.5878  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 2.0438  Validation loss = 4.5908  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 2.0433  Validation loss = 4.5920  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 2.0428  Validation loss = 4.5906  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 2.0422  Validation loss = 4.5863  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 2.0419  Validation loss = 4.5871  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 2.0414  Validation loss = 4.5811  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 2.0410  Validation loss = 4.5816  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 2.0405  Validation loss = 4.5792  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 2.0403  Validation loss = 4.5714  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 2.0396  Validation loss = 4.5684  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 2.0394  Validation loss = 4.5753  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 2.0390  Validation loss = 4.5747  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 2.0396  Validation loss = 4.5784  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 2.0384  Validation loss = 4.5755  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 2.0376  Validation loss = 4.5721  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 2.0372  Validation loss = 4.5691  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 2.0376  Validation loss = 4.5720  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 2.0367  Validation loss = 4.5719  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 2.0363  Validation loss = 4.5689  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 2.0361  Validation loss = 4.5735  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 2.0370  Validation loss = 4.5713  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 2.0365  Validation loss = 4.5712  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 2.0359  Validation loss = 4.5691  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 2.0356  Validation loss = 4.5662  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 2.0353  Validation loss = 4.5646  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 2.0350  Validation loss = 4.5667  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 2.0344  Validation loss = 4.5645  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 2.0342  Validation loss = 4.5624  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 2.0340  Validation loss = 4.5614  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 2.0340  Validation loss = 4.5646  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 2.0333  Validation loss = 4.5610  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 2.0331  Validation loss = 4.5581  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 2.0330  Validation loss = 4.5530  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 2.0328  Validation loss = 4.5481  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 2.0323  Validation loss = 4.5478  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 2.0318  Validation loss = 4.5401  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 2.0312  Validation loss = 4.5411  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 2.0305  Validation loss = 4.5425  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 2.0300  Validation loss = 4.5433  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 2.0299  Validation loss = 4.5435  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 2.0295  Validation loss = 4.5392  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 2.0291  Validation loss = 4.5389  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 2.0287  Validation loss = 4.5372  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 2.0282  Validation loss = 4.5393  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 2.0275  Validation loss = 4.5365  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 2.0272  Validation loss = 4.5375  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 2.0266  Validation loss = 4.5332  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 2.0262  Validation loss = 4.5268  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 2.0255  Validation loss = 4.5242  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 2.0249  Validation loss = 4.5241  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 2.0246  Validation loss = 4.5225  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 2.0241  Validation loss = 4.5180  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 2.0243  Validation loss = 4.5137  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 2.0234  Validation loss = 4.5187  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 2.0229  Validation loss = 4.5209  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 2.0226  Validation loss = 4.5230  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 2.0225  Validation loss = 4.5262  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 2.0223  Validation loss = 4.5285  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 408  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.3055  Validation loss = 3.4996  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.3038  Validation loss = 3.4984  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.3020  Validation loss = 3.4965  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.3010  Validation loss = 3.4956  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.2993  Validation loss = 3.4904  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.2989  Validation loss = 3.4923  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.2990  Validation loss = 3.4978  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.2981  Validation loss = 3.4969  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.2976  Validation loss = 3.4975  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.2968  Validation loss = 3.4986  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.2966  Validation loss = 3.4996  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 5  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.4467  Validation loss = 3.0990  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.4444  Validation loss = 3.1002  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.4429  Validation loss = 3.1023  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.4408  Validation loss = 3.1047  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.4391  Validation loss = 3.1073  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.4369  Validation loss = 3.1107  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.4360  Validation loss = 3.1112  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.4352  Validation loss = 3.1098  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.4330  Validation loss = 3.1127  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.4315  Validation loss = 3.1131  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.4297  Validation loss = 3.1151  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 1  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.5409  Validation loss = 1.7147  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.5404  Validation loss = 1.7173  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.5396  Validation loss = 1.7163  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 2.5373  Validation loss = 1.7158  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.5359  Validation loss = 1.7149  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.5351  Validation loss = 1.7151  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.5327  Validation loss = 1.7125  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.5311  Validation loss = 1.7116  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.5301  Validation loss = 1.7121  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.5291  Validation loss = 1.7115  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.5277  Validation loss = 1.7105  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 2.5268  Validation loss = 1.7118  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 2.5256  Validation loss = 1.7141  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 2.5243  Validation loss = 1.7178  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 11  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.5022  Validation loss = 2.4483  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.5014  Validation loss = 2.4470  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.4992  Validation loss = 2.4454  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.4977  Validation loss = 2.4428  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.4970  Validation loss = 2.4422  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.4963  Validation loss = 2.4411  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.4954  Validation loss = 2.4388  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.4941  Validation loss = 2.4404  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.4927  Validation loss = 2.4402  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.4906  Validation loss = 2.4400  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.4894  Validation loss = 2.4379  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.4874  Validation loss = 2.4368  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 2.4879  Validation loss = 2.4373  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.4873  Validation loss = 2.4372  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 2.4864  Validation loss = 2.4375  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.4846  Validation loss = 2.4379  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 2.4830  Validation loss = 2.4350  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 2.4825  Validation loss = 2.4328  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 2.4813  Validation loss = 2.4313  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 2.4798  Validation loss = 2.4297  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 2.4790  Validation loss = 2.4297  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 2.4776  Validation loss = 2.4291  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 2.4767  Validation loss = 2.4288  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 2.4758  Validation loss = 2.4266  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 2.4743  Validation loss = 2.4261  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 2.4732  Validation loss = 2.4232  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 2.4723  Validation loss = 2.4224  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 2.4715  Validation loss = 2.4224  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 2.4707  Validation loss = 2.4203  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 2.4691  Validation loss = 2.4192  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 2.4675  Validation loss = 2.4192  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 2.4665  Validation loss = 2.4183  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 2.4654  Validation loss = 2.4185  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 2.4645  Validation loss = 2.4179  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 2.4630  Validation loss = 2.4147  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 2.4618  Validation loss = 2.4127  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 2.4610  Validation loss = 2.4140  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 2.4602  Validation loss = 2.4126  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 2.4597  Validation loss = 2.4118  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 2.4582  Validation loss = 2.4105  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 2.4576  Validation loss = 2.4093  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 2.4569  Validation loss = 2.4084  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 2.4563  Validation loss = 2.4063  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 2.4550  Validation loss = 2.4053  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 2.4536  Validation loss = 2.4050  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 2.4530  Validation loss = 2.4036  \n",
      "\n",
      "Fold: 19  Epoch: 47  Training loss = 2.4525  Validation loss = 2.4001  \n",
      "\n",
      "Fold: 19  Epoch: 48  Training loss = 2.4520  Validation loss = 2.4002  \n",
      "\n",
      "Fold: 19  Epoch: 49  Training loss = 2.4513  Validation loss = 2.3989  \n",
      "\n",
      "Fold: 19  Epoch: 50  Training loss = 2.4503  Validation loss = 2.4007  \n",
      "\n",
      "Fold: 19  Epoch: 51  Training loss = 2.4500  Validation loss = 2.3997  \n",
      "\n",
      "Fold: 19  Epoch: 52  Training loss = 2.4514  Validation loss = 2.3984  \n",
      "\n",
      "Fold: 19  Epoch: 53  Training loss = 2.4501  Validation loss = 2.3958  \n",
      "\n",
      "Fold: 19  Epoch: 54  Training loss = 2.4490  Validation loss = 2.3958  \n",
      "\n",
      "Fold: 19  Epoch: 55  Training loss = 2.4474  Validation loss = 2.3958  \n",
      "\n",
      "Fold: 19  Epoch: 56  Training loss = 2.4461  Validation loss = 2.3953  \n",
      "\n",
      "Fold: 19  Epoch: 57  Training loss = 2.4450  Validation loss = 2.3925  \n",
      "\n",
      "Fold: 19  Epoch: 58  Training loss = 2.4437  Validation loss = 2.3901  \n",
      "\n",
      "Fold: 19  Epoch: 59  Training loss = 2.4433  Validation loss = 2.3907  \n",
      "\n",
      "Fold: 19  Epoch: 60  Training loss = 2.4425  Validation loss = 2.3890  \n",
      "\n",
      "Fold: 19  Epoch: 61  Training loss = 2.4409  Validation loss = 2.3863  \n",
      "\n",
      "Fold: 19  Epoch: 62  Training loss = 2.4402  Validation loss = 2.3871  \n",
      "\n",
      "Fold: 19  Epoch: 63  Training loss = 2.4393  Validation loss = 2.3875  \n",
      "\n",
      "Fold: 19  Epoch: 64  Training loss = 2.4378  Validation loss = 2.3856  \n",
      "\n",
      "Fold: 19  Epoch: 65  Training loss = 2.4367  Validation loss = 2.3842  \n",
      "\n",
      "Fold: 19  Epoch: 66  Training loss = 2.4359  Validation loss = 2.3835  \n",
      "\n",
      "Fold: 19  Epoch: 67  Training loss = 2.4351  Validation loss = 2.3819  \n",
      "\n",
      "Fold: 19  Epoch: 68  Training loss = 2.4345  Validation loss = 2.3828  \n",
      "\n",
      "Fold: 19  Epoch: 69  Training loss = 2.4338  Validation loss = 2.3834  \n",
      "\n",
      "Fold: 19  Epoch: 70  Training loss = 2.4322  Validation loss = 2.3818  \n",
      "\n",
      "Fold: 19  Epoch: 71  Training loss = 2.4317  Validation loss = 2.3789  \n",
      "\n",
      "Fold: 19  Epoch: 72  Training loss = 2.4310  Validation loss = 2.3777  \n",
      "\n",
      "Fold: 19  Epoch: 73  Training loss = 2.4300  Validation loss = 2.3779  \n",
      "\n",
      "Fold: 19  Epoch: 74  Training loss = 2.4287  Validation loss = 2.3756  \n",
      "\n",
      "Fold: 19  Epoch: 75  Training loss = 2.4286  Validation loss = 2.3708  \n",
      "\n",
      "Fold: 19  Epoch: 76  Training loss = 2.4271  Validation loss = 2.3683  \n",
      "\n",
      "Fold: 19  Epoch: 77  Training loss = 2.4264  Validation loss = 2.3691  \n",
      "\n",
      "Fold: 19  Epoch: 78  Training loss = 2.4259  Validation loss = 2.3684  \n",
      "\n",
      "Fold: 19  Epoch: 79  Training loss = 2.4255  Validation loss = 2.3671  \n",
      "\n",
      "Fold: 19  Epoch: 80  Training loss = 2.4244  Validation loss = 2.3657  \n",
      "\n",
      "Fold: 19  Epoch: 81  Training loss = 2.4239  Validation loss = 2.3685  \n",
      "\n",
      "Fold: 19  Epoch: 82  Training loss = 2.4234  Validation loss = 2.3673  \n",
      "\n",
      "Fold: 19  Epoch: 83  Training loss = 2.4225  Validation loss = 2.3668  \n",
      "\n",
      "Fold: 19  Epoch: 84  Training loss = 2.4220  Validation loss = 2.3677  \n",
      "\n",
      "Fold: 19  Epoch: 85  Training loss = 2.4213  Validation loss = 2.3653  \n",
      "\n",
      "Fold: 19  Epoch: 86  Training loss = 2.4222  Validation loss = 2.3653  \n",
      "\n",
      "Fold: 19  Epoch: 87  Training loss = 2.4235  Validation loss = 2.3638  \n",
      "\n",
      "Fold: 19  Epoch: 88  Training loss = 2.4283  Validation loss = 2.3658  \n",
      "\n",
      "Fold: 19  Epoch: 89  Training loss = 2.4261  Validation loss = 2.3645  \n",
      "\n",
      "Fold: 19  Epoch: 90  Training loss = 2.4249  Validation loss = 2.3657  \n",
      "\n",
      "Fold: 19  Epoch: 91  Training loss = 2.4236  Validation loss = 2.3638  \n",
      "\n",
      "Fold: 19  Epoch: 92  Training loss = 2.4215  Validation loss = 2.3602  \n",
      "\n",
      "Fold: 19  Epoch: 93  Training loss = 2.4194  Validation loss = 2.3571  \n",
      "\n",
      "Fold: 19  Epoch: 94  Training loss = 2.4179  Validation loss = 2.3558  \n",
      "\n",
      "Fold: 19  Epoch: 95  Training loss = 2.4173  Validation loss = 2.3538  \n",
      "\n",
      "Fold: 19  Epoch: 96  Training loss = 2.4164  Validation loss = 2.3523  \n",
      "\n",
      "Fold: 19  Epoch: 97  Training loss = 2.4148  Validation loss = 2.3524  \n",
      "\n",
      "Fold: 19  Epoch: 98  Training loss = 2.4138  Validation loss = 2.3520  \n",
      "\n",
      "Fold: 19  Epoch: 99  Training loss = 2.4129  Validation loss = 2.3535  \n",
      "\n",
      "Fold: 19  Epoch: 100  Training loss = 2.4122  Validation loss = 2.3517  \n",
      "\n",
      "Fold: 19  Epoch: 101  Training loss = 2.4112  Validation loss = 2.3511  \n",
      "\n",
      "Fold: 19  Epoch: 102  Training loss = 2.4105  Validation loss = 2.3505  \n",
      "\n",
      "Fold: 19  Epoch: 103  Training loss = 2.4089  Validation loss = 2.3478  \n",
      "\n",
      "Fold: 19  Epoch: 104  Training loss = 2.4080  Validation loss = 2.3468  \n",
      "\n",
      "Fold: 19  Epoch: 105  Training loss = 2.4072  Validation loss = 2.3454  \n",
      "\n",
      "Fold: 19  Epoch: 106  Training loss = 2.4064  Validation loss = 2.3440  \n",
      "\n",
      "Fold: 19  Epoch: 107  Training loss = 2.4060  Validation loss = 2.3458  \n",
      "\n",
      "Fold: 19  Epoch: 108  Training loss = 2.4042  Validation loss = 2.3434  \n",
      "\n",
      "Fold: 19  Epoch: 109  Training loss = 2.4053  Validation loss = 2.3429  \n",
      "\n",
      "Fold: 19  Epoch: 110  Training loss = 2.4046  Validation loss = 2.3438  \n",
      "\n",
      "Fold: 19  Epoch: 111  Training loss = 2.4034  Validation loss = 2.3426  \n",
      "\n",
      "Fold: 19  Epoch: 112  Training loss = 2.4022  Validation loss = 2.3403  \n",
      "\n",
      "Fold: 19  Epoch: 113  Training loss = 2.4010  Validation loss = 2.3390  \n",
      "\n",
      "Fold: 19  Epoch: 114  Training loss = 2.3998  Validation loss = 2.3374  \n",
      "\n",
      "Fold: 19  Epoch: 115  Training loss = 2.3989  Validation loss = 2.3365  \n",
      "\n",
      "Fold: 19  Epoch: 116  Training loss = 2.3982  Validation loss = 2.3345  \n",
      "\n",
      "Fold: 19  Epoch: 117  Training loss = 2.3977  Validation loss = 2.3348  \n",
      "\n",
      "Fold: 19  Epoch: 118  Training loss = 2.3968  Validation loss = 2.3346  \n",
      "\n",
      "Fold: 19  Epoch: 119  Training loss = 2.3957  Validation loss = 2.3326  \n",
      "\n",
      "Fold: 19  Epoch: 120  Training loss = 2.3948  Validation loss = 2.3323  \n",
      "\n",
      "Fold: 19  Epoch: 121  Training loss = 2.3937  Validation loss = 2.3295  \n",
      "\n",
      "Fold: 19  Epoch: 122  Training loss = 2.3929  Validation loss = 2.3291  \n",
      "\n",
      "Fold: 19  Epoch: 123  Training loss = 2.3921  Validation loss = 2.3286  \n",
      "\n",
      "Fold: 19  Epoch: 124  Training loss = 2.3916  Validation loss = 2.3255  \n",
      "\n",
      "Fold: 19  Epoch: 125  Training loss = 2.3907  Validation loss = 2.3231  \n",
      "\n",
      "Fold: 19  Epoch: 126  Training loss = 2.3900  Validation loss = 2.3220  \n",
      "\n",
      "Fold: 19  Epoch: 127  Training loss = 2.3894  Validation loss = 2.3188  \n",
      "\n",
      "Fold: 19  Epoch: 128  Training loss = 2.3887  Validation loss = 2.3190  \n",
      "\n",
      "Fold: 19  Epoch: 129  Training loss = 2.3880  Validation loss = 2.3223  \n",
      "\n",
      "Fold: 19  Epoch: 130  Training loss = 2.3883  Validation loss = 2.3200  \n",
      "\n",
      "Fold: 19  Epoch: 131  Training loss = 2.3939  Validation loss = 2.3172  \n",
      "\n",
      "Fold: 19  Epoch: 132  Training loss = 2.3923  Validation loss = 2.3170  \n",
      "\n",
      "Fold: 19  Epoch: 133  Training loss = 2.3893  Validation loss = 2.3163  \n",
      "\n",
      "Fold: 19  Epoch: 134  Training loss = 2.3866  Validation loss = 2.3160  \n",
      "\n",
      "Fold: 19  Epoch: 135  Training loss = 2.3857  Validation loss = 2.3168  \n",
      "\n",
      "Fold: 19  Epoch: 136  Training loss = 2.3845  Validation loss = 2.3131  \n",
      "\n",
      "Fold: 19  Epoch: 137  Training loss = 2.3843  Validation loss = 2.3138  \n",
      "\n",
      "Fold: 19  Epoch: 138  Training loss = 2.3836  Validation loss = 2.3146  \n",
      "\n",
      "Fold: 19  Epoch: 139  Training loss = 2.3827  Validation loss = 2.3147  \n",
      "\n",
      "Fold: 19  Epoch: 140  Training loss = 2.3814  Validation loss = 2.3099  \n",
      "\n",
      "Fold: 19  Epoch: 141  Training loss = 2.3804  Validation loss = 2.3095  \n",
      "\n",
      "Fold: 19  Epoch: 142  Training loss = 2.3796  Validation loss = 2.3085  \n",
      "\n",
      "Fold: 19  Epoch: 143  Training loss = 2.3792  Validation loss = 2.3090  \n",
      "\n",
      "Fold: 19  Epoch: 144  Training loss = 2.3825  Validation loss = 2.3087  \n",
      "\n",
      "Fold: 19  Epoch: 145  Training loss = 2.3797  Validation loss = 2.3082  \n",
      "\n",
      "Fold: 19  Epoch: 146  Training loss = 2.3793  Validation loss = 2.3068  \n",
      "\n",
      "Fold: 19  Epoch: 147  Training loss = 2.3787  Validation loss = 2.3070  \n",
      "\n",
      "Fold: 19  Epoch: 148  Training loss = 2.3783  Validation loss = 2.3043  \n",
      "\n",
      "Fold: 19  Epoch: 149  Training loss = 2.3777  Validation loss = 2.3031  \n",
      "\n",
      "Fold: 19  Epoch: 150  Training loss = 2.3771  Validation loss = 2.3027  \n",
      "\n",
      "Fold: 19  Epoch: 151  Training loss = 2.3760  Validation loss = 2.3005  \n",
      "\n",
      "Fold: 19  Epoch: 152  Training loss = 2.3757  Validation loss = 2.2993  \n",
      "\n",
      "Fold: 19  Epoch: 153  Training loss = 2.3766  Validation loss = 2.2983  \n",
      "\n",
      "Fold: 19  Epoch: 154  Training loss = 2.3761  Validation loss = 2.2958  \n",
      "\n",
      "Fold: 19  Epoch: 155  Training loss = 2.3756  Validation loss = 2.2955  \n",
      "\n",
      "Fold: 19  Epoch: 156  Training loss = 2.3827  Validation loss = 2.2943  \n",
      "\n",
      "Fold: 19  Epoch: 157  Training loss = 2.3746  Validation loss = 2.2960  \n",
      "\n",
      "Fold: 19  Epoch: 158  Training loss = 2.3741  Validation loss = 2.2967  \n",
      "\n",
      "Fold: 19  Epoch: 159  Training loss = 2.3735  Validation loss = 2.2974  \n",
      "\n",
      "Fold: 19  Epoch: 160  Training loss = 2.3724  Validation loss = 2.2961  \n",
      "\n",
      "Fold: 19  Epoch: 161  Training loss = 2.3715  Validation loss = 2.2951  \n",
      "\n",
      "Fold: 19  Epoch: 162  Training loss = 2.3707  Validation loss = 2.2952  \n",
      "\n",
      "Fold: 19  Epoch: 163  Training loss = 2.3698  Validation loss = 2.2928  \n",
      "\n",
      "Fold: 19  Epoch: 164  Training loss = 2.3689  Validation loss = 2.2909  \n",
      "\n",
      "Fold: 19  Epoch: 165  Training loss = 2.3687  Validation loss = 2.2917  \n",
      "\n",
      "Fold: 19  Epoch: 166  Training loss = 2.3678  Validation loss = 2.2924  \n",
      "\n",
      "Fold: 19  Epoch: 167  Training loss = 2.3674  Validation loss = 2.2907  \n",
      "\n",
      "Fold: 19  Epoch: 168  Training loss = 2.3664  Validation loss = 2.2895  \n",
      "\n",
      "Fold: 19  Epoch: 169  Training loss = 2.3658  Validation loss = 2.2879  \n",
      "\n",
      "Fold: 19  Epoch: 170  Training loss = 2.3650  Validation loss = 2.2880  \n",
      "\n",
      "Fold: 19  Epoch: 171  Training loss = 2.3643  Validation loss = 2.2857  \n",
      "\n",
      "Fold: 19  Epoch: 172  Training loss = 2.3635  Validation loss = 2.2872  \n",
      "\n",
      "Fold: 19  Epoch: 173  Training loss = 2.3631  Validation loss = 2.2881  \n",
      "\n",
      "Fold: 19  Epoch: 174  Training loss = 2.3625  Validation loss = 2.2874  \n",
      "\n",
      "Fold: 19  Epoch: 175  Training loss = 2.3617  Validation loss = 2.2852  \n",
      "\n",
      "Fold: 19  Epoch: 176  Training loss = 2.3609  Validation loss = 2.2842  \n",
      "\n",
      "Fold: 19  Epoch: 177  Training loss = 2.3603  Validation loss = 2.2824  \n",
      "\n",
      "Fold: 19  Epoch: 178  Training loss = 2.3600  Validation loss = 2.2805  \n",
      "\n",
      "Fold: 19  Epoch: 179  Training loss = 2.3595  Validation loss = 2.2792  \n",
      "\n",
      "Fold: 19  Epoch: 180  Training loss = 2.3586  Validation loss = 2.2781  \n",
      "\n",
      "Fold: 19  Epoch: 181  Training loss = 2.3586  Validation loss = 2.2766  \n",
      "\n",
      "Fold: 19  Epoch: 182  Training loss = 2.3576  Validation loss = 2.2753  \n",
      "\n",
      "Fold: 19  Epoch: 183  Training loss = 2.3567  Validation loss = 2.2775  \n",
      "\n",
      "Fold: 19  Epoch: 184  Training loss = 2.3558  Validation loss = 2.2775  \n",
      "\n",
      "Fold: 19  Epoch: 185  Training loss = 2.3554  Validation loss = 2.2765  \n",
      "\n",
      "Fold: 19  Epoch: 186  Training loss = 2.3547  Validation loss = 2.2737  \n",
      "\n",
      "Fold: 19  Epoch: 187  Training loss = 2.3540  Validation loss = 2.2719  \n",
      "\n",
      "Fold: 19  Epoch: 188  Training loss = 2.3549  Validation loss = 2.2698  \n",
      "\n",
      "Fold: 19  Epoch: 189  Training loss = 2.3539  Validation loss = 2.2697  \n",
      "\n",
      "Fold: 19  Epoch: 190  Training loss = 2.3534  Validation loss = 2.2688  \n",
      "\n",
      "Fold: 19  Epoch: 191  Training loss = 2.3532  Validation loss = 2.2668  \n",
      "\n",
      "Fold: 19  Epoch: 192  Training loss = 2.3524  Validation loss = 2.2678  \n",
      "\n",
      "Fold: 19  Epoch: 193  Training loss = 2.3517  Validation loss = 2.2694  \n",
      "\n",
      "Fold: 19  Epoch: 194  Training loss = 2.3514  Validation loss = 2.2699  \n",
      "\n",
      "Fold: 19  Epoch: 195  Training loss = 2.3505  Validation loss = 2.2687  \n",
      "\n",
      "Fold: 19  Epoch: 196  Training loss = 2.3497  Validation loss = 2.2672  \n",
      "\n",
      "Fold: 19  Epoch: 197  Training loss = 2.3491  Validation loss = 2.2639  \n",
      "\n",
      "Fold: 19  Epoch: 198  Training loss = 2.3485  Validation loss = 2.2622  \n",
      "\n",
      "Fold: 19  Epoch: 199  Training loss = 2.3480  Validation loss = 2.2594  \n",
      "\n",
      "Fold: 19  Epoch: 200  Training loss = 2.3473  Validation loss = 2.2593  \n",
      "\n",
      "Fold: 19  Epoch: 201  Training loss = 2.3469  Validation loss = 2.2588  \n",
      "\n",
      "Fold: 19  Epoch: 202  Training loss = 2.3463  Validation loss = 2.2580  \n",
      "\n",
      "Fold: 19  Epoch: 203  Training loss = 2.3455  Validation loss = 2.2556  \n",
      "\n",
      "Fold: 19  Epoch: 204  Training loss = 2.3450  Validation loss = 2.2554  \n",
      "\n",
      "Fold: 19  Epoch: 205  Training loss = 2.3447  Validation loss = 2.2542  \n",
      "\n",
      "Fold: 19  Epoch: 206  Training loss = 2.3445  Validation loss = 2.2537  \n",
      "\n",
      "Fold: 19  Epoch: 207  Training loss = 2.3435  Validation loss = 2.2525  \n",
      "\n",
      "Fold: 19  Epoch: 208  Training loss = 2.3434  Validation loss = 2.2514  \n",
      "\n",
      "Fold: 19  Epoch: 209  Training loss = 2.3430  Validation loss = 2.2506  \n",
      "\n",
      "Fold: 19  Epoch: 210  Training loss = 2.3419  Validation loss = 2.2505  \n",
      "\n",
      "Fold: 19  Epoch: 211  Training loss = 2.3412  Validation loss = 2.2502  \n",
      "\n",
      "Fold: 19  Epoch: 212  Training loss = 2.3409  Validation loss = 2.2472  \n",
      "\n",
      "Fold: 19  Epoch: 213  Training loss = 2.3403  Validation loss = 2.2434  \n",
      "\n",
      "Fold: 19  Epoch: 214  Training loss = 2.3397  Validation loss = 2.2411  \n",
      "\n",
      "Fold: 19  Epoch: 215  Training loss = 2.3389  Validation loss = 2.2406  \n",
      "\n",
      "Fold: 19  Epoch: 216  Training loss = 2.3471  Validation loss = 2.2397  \n",
      "\n",
      "Fold: 19  Epoch: 217  Training loss = 2.3380  Validation loss = 2.2413  \n",
      "\n",
      "Fold: 19  Epoch: 218  Training loss = 2.3369  Validation loss = 2.2436  \n",
      "\n",
      "Fold: 19  Epoch: 219  Training loss = 2.3360  Validation loss = 2.2422  \n",
      "\n",
      "Fold: 19  Epoch: 220  Training loss = 2.3356  Validation loss = 2.2407  \n",
      "\n",
      "Fold: 19  Epoch: 221  Training loss = 2.3352  Validation loss = 2.2400  \n",
      "\n",
      "Fold: 19  Epoch: 222  Training loss = 2.3343  Validation loss = 2.2376  \n",
      "\n",
      "Fold: 19  Epoch: 223  Training loss = 2.3337  Validation loss = 2.2376  \n",
      "\n",
      "Fold: 19  Epoch: 224  Training loss = 2.3330  Validation loss = 2.2369  \n",
      "\n",
      "Fold: 19  Epoch: 225  Training loss = 2.3325  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 19  Epoch: 226  Training loss = 2.3323  Validation loss = 2.2363  \n",
      "\n",
      "Fold: 19  Epoch: 227  Training loss = 2.3315  Validation loss = 2.2336  \n",
      "\n",
      "Fold: 19  Epoch: 228  Training loss = 2.3305  Validation loss = 2.2331  \n",
      "\n",
      "Fold: 19  Epoch: 229  Training loss = 2.3300  Validation loss = 2.2325  \n",
      "\n",
      "Fold: 19  Epoch: 230  Training loss = 2.3298  Validation loss = 2.2336  \n",
      "\n",
      "Fold: 19  Epoch: 231  Training loss = 2.3296  Validation loss = 2.2341  \n",
      "\n",
      "Fold: 19  Epoch: 232  Training loss = 2.3288  Validation loss = 2.2344  \n",
      "\n",
      "Fold: 19  Epoch: 233  Training loss = 2.3284  Validation loss = 2.2341  \n",
      "\n",
      "Fold: 19  Epoch: 234  Training loss = 2.3275  Validation loss = 2.2349  \n",
      "\n",
      "Fold: 19  Epoch: 235  Training loss = 2.3271  Validation loss = 2.2335  \n",
      "\n",
      "Fold: 19  Epoch: 236  Training loss = 2.3266  Validation loss = 2.2328  \n",
      "\n",
      "Fold: 19  Epoch: 237  Training loss = 2.3260  Validation loss = 2.2300  \n",
      "\n",
      "Fold: 19  Epoch: 238  Training loss = 2.3254  Validation loss = 2.2298  \n",
      "\n",
      "Fold: 19  Epoch: 239  Training loss = 2.3251  Validation loss = 2.2282  \n",
      "\n",
      "Fold: 19  Epoch: 240  Training loss = 2.3245  Validation loss = 2.2260  \n",
      "\n",
      "Fold: 19  Epoch: 241  Training loss = 2.3242  Validation loss = 2.2249  \n",
      "\n",
      "Fold: 19  Epoch: 242  Training loss = 2.3238  Validation loss = 2.2220  \n",
      "\n",
      "Fold: 19  Epoch: 243  Training loss = 2.3237  Validation loss = 2.2204  \n",
      "\n",
      "Fold: 19  Epoch: 244  Training loss = 2.3232  Validation loss = 2.2204  \n",
      "\n",
      "Fold: 19  Epoch: 245  Training loss = 2.3229  Validation loss = 2.2171  \n",
      "\n",
      "Fold: 19  Epoch: 246  Training loss = 2.3218  Validation loss = 2.2163  \n",
      "\n",
      "Fold: 19  Epoch: 247  Training loss = 2.3210  Validation loss = 2.2137  \n",
      "\n",
      "Fold: 19  Epoch: 248  Training loss = 2.3208  Validation loss = 2.2125  \n",
      "\n",
      "Fold: 19  Epoch: 249  Training loss = 2.3205  Validation loss = 2.2108  \n",
      "\n",
      "Fold: 19  Epoch: 250  Training loss = 2.3198  Validation loss = 2.2093  \n",
      "\n",
      "Fold: 19  Epoch: 251  Training loss = 2.3197  Validation loss = 2.2075  \n",
      "\n",
      "Fold: 19  Epoch: 252  Training loss = 2.3186  Validation loss = 2.2070  \n",
      "\n",
      "Fold: 19  Epoch: 253  Training loss = 2.3190  Validation loss = 2.2069  \n",
      "\n",
      "Fold: 19  Epoch: 254  Training loss = 2.3306  Validation loss = 2.2033  \n",
      "\n",
      "Fold: 19  Epoch: 255  Training loss = 2.3192  Validation loss = 2.2055  \n",
      "\n",
      "Fold: 19  Epoch: 256  Training loss = 2.3190  Validation loss = 2.2050  \n",
      "\n",
      "Fold: 19  Epoch: 257  Training loss = 2.3175  Validation loss = 2.2041  \n",
      "\n",
      "Fold: 19  Epoch: 258  Training loss = 2.3171  Validation loss = 2.2045  \n",
      "\n",
      "Fold: 19  Epoch: 259  Training loss = 2.3164  Validation loss = 2.2011  \n",
      "\n",
      "Fold: 19  Epoch: 260  Training loss = 2.3158  Validation loss = 2.2004  \n",
      "\n",
      "Fold: 19  Epoch: 261  Training loss = 2.3150  Validation loss = 2.2019  \n",
      "\n",
      "Fold: 19  Epoch: 262  Training loss = 2.3148  Validation loss = 2.2044  \n",
      "\n",
      "Fold: 19  Epoch: 263  Training loss = 2.3148  Validation loss = 2.2047  \n",
      "\n",
      "Fold: 19  Epoch: 264  Training loss = 2.3141  Validation loss = 2.2039  \n",
      "\n",
      "Fold: 19  Epoch: 265  Training loss = 2.3139  Validation loss = 2.2045  \n",
      "\n",
      "Fold: 19  Epoch: 266  Training loss = 2.3127  Validation loss = 2.2031  \n",
      "\n",
      "Fold: 19  Epoch: 267  Training loss = 2.3123  Validation loss = 2.2028  \n",
      "\n",
      "Fold: 19  Epoch: 268  Training loss = 2.3116  Validation loss = 2.2012  \n",
      "\n",
      "Fold: 19  Epoch: 269  Training loss = 2.3114  Validation loss = 2.2000  \n",
      "\n",
      "Fold: 19  Epoch: 270  Training loss = 2.3117  Validation loss = 2.2006  \n",
      "\n",
      "Fold: 19  Epoch: 271  Training loss = 2.3101  Validation loss = 2.1977  \n",
      "\n",
      "Fold: 19  Epoch: 272  Training loss = 2.3093  Validation loss = 2.1958  \n",
      "\n",
      "Fold: 19  Epoch: 273  Training loss = 2.3090  Validation loss = 2.1931  \n",
      "\n",
      "Fold: 19  Epoch: 274  Training loss = 2.3082  Validation loss = 2.1924  \n",
      "\n",
      "Fold: 19  Epoch: 275  Training loss = 2.3075  Validation loss = 2.1902  \n",
      "\n",
      "Fold: 19  Epoch: 276  Training loss = 2.3069  Validation loss = 2.1909  \n",
      "\n",
      "Fold: 19  Epoch: 277  Training loss = 2.3066  Validation loss = 2.1915  \n",
      "\n",
      "Fold: 19  Epoch: 278  Training loss = 2.3060  Validation loss = 2.1908  \n",
      "\n",
      "Fold: 19  Epoch: 279  Training loss = 2.3055  Validation loss = 2.1894  \n",
      "\n",
      "Fold: 19  Epoch: 280  Training loss = 2.3052  Validation loss = 2.1883  \n",
      "\n",
      "Fold: 19  Epoch: 281  Training loss = 2.3124  Validation loss = 2.1872  \n",
      "\n",
      "Fold: 19  Epoch: 282  Training loss = 2.3048  Validation loss = 2.1862  \n",
      "\n",
      "Fold: 19  Epoch: 283  Training loss = 2.3043  Validation loss = 2.1855  \n",
      "\n",
      "Fold: 19  Epoch: 284  Training loss = 2.3033  Validation loss = 2.1884  \n",
      "\n",
      "Fold: 19  Epoch: 285  Training loss = 2.3028  Validation loss = 2.1851  \n",
      "\n",
      "Fold: 19  Epoch: 286  Training loss = 2.3060  Validation loss = 2.1847  \n",
      "\n",
      "Fold: 19  Epoch: 287  Training loss = 2.3100  Validation loss = 2.1823  \n",
      "\n",
      "Fold: 19  Epoch: 288  Training loss = 2.3094  Validation loss = 2.1804  \n",
      "\n",
      "Fold: 19  Epoch: 289  Training loss = 2.3030  Validation loss = 2.1770  \n",
      "\n",
      "Fold: 19  Epoch: 290  Training loss = 2.3033  Validation loss = 2.1774  \n",
      "\n",
      "Fold: 19  Epoch: 291  Training loss = 2.3022  Validation loss = 2.1765  \n",
      "\n",
      "Fold: 19  Epoch: 292  Training loss = 2.3015  Validation loss = 2.1743  \n",
      "\n",
      "Fold: 19  Epoch: 293  Training loss = 2.3009  Validation loss = 2.1735  \n",
      "\n",
      "Fold: 19  Epoch: 294  Training loss = 2.3004  Validation loss = 2.1712  \n",
      "\n",
      "Fold: 19  Epoch: 295  Training loss = 2.2999  Validation loss = 2.1714  \n",
      "\n",
      "Fold: 19  Epoch: 296  Training loss = 2.3005  Validation loss = 2.1681  \n",
      "\n",
      "Fold: 19  Epoch: 297  Training loss = 2.3005  Validation loss = 2.1672  \n",
      "\n",
      "Fold: 19  Epoch: 298  Training loss = 2.2999  Validation loss = 2.1667  \n",
      "\n",
      "Fold: 19  Epoch: 299  Training loss = 2.2994  Validation loss = 2.1655  \n",
      "\n",
      "Fold: 19  Epoch: 300  Training loss = 2.2988  Validation loss = 2.1639  \n",
      "\n",
      "Fold: 19  Epoch: 301  Training loss = 2.2979  Validation loss = 2.1618  \n",
      "\n",
      "Fold: 19  Epoch: 302  Training loss = 2.2972  Validation loss = 2.1621  \n",
      "\n",
      "Fold: 19  Epoch: 303  Training loss = 2.2965  Validation loss = 2.1590  \n",
      "\n",
      "Fold: 19  Epoch: 304  Training loss = 2.2957  Validation loss = 2.1590  \n",
      "\n",
      "Fold: 19  Epoch: 305  Training loss = 2.2934  Validation loss = 2.1594  \n",
      "\n",
      "Fold: 19  Epoch: 306  Training loss = 2.2920  Validation loss = 2.1588  \n",
      "\n",
      "Fold: 19  Epoch: 307  Training loss = 2.2916  Validation loss = 2.1605  \n",
      "\n",
      "Fold: 19  Epoch: 308  Training loss = 2.2910  Validation loss = 2.1598  \n",
      "\n",
      "Fold: 19  Epoch: 309  Training loss = 2.2901  Validation loss = 2.1572  \n",
      "\n",
      "Fold: 19  Epoch: 310  Training loss = 2.2890  Validation loss = 2.1563  \n",
      "\n",
      "Fold: 19  Epoch: 311  Training loss = 2.2884  Validation loss = 2.1550  \n",
      "\n",
      "Fold: 19  Epoch: 312  Training loss = 2.2880  Validation loss = 2.1546  \n",
      "\n",
      "Fold: 19  Epoch: 313  Training loss = 2.2877  Validation loss = 2.1551  \n",
      "\n",
      "Fold: 19  Epoch: 314  Training loss = 2.2874  Validation loss = 2.1533  \n",
      "\n",
      "Fold: 19  Epoch: 315  Training loss = 2.2866  Validation loss = 2.1533  \n",
      "\n",
      "Fold: 19  Epoch: 316  Training loss = 2.2857  Validation loss = 2.1529  \n",
      "\n",
      "Fold: 19  Epoch: 317  Training loss = 2.2851  Validation loss = 2.1518  \n",
      "\n",
      "Fold: 19  Epoch: 318  Training loss = 2.2847  Validation loss = 2.1517  \n",
      "\n",
      "Fold: 19  Epoch: 319  Training loss = 2.2840  Validation loss = 2.1496  \n",
      "\n",
      "Fold: 19  Epoch: 320  Training loss = 2.2834  Validation loss = 2.1518  \n",
      "\n",
      "Fold: 19  Epoch: 321  Training loss = 2.2830  Validation loss = 2.1532  \n",
      "\n",
      "Fold: 19  Epoch: 322  Training loss = 2.2824  Validation loss = 2.1547  \n",
      "\n",
      "Fold: 19  Epoch: 323  Training loss = 2.2822  Validation loss = 2.1563  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 319  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.3385  Validation loss = 1.2132  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.3381  Validation loss = 1.2072  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.3379  Validation loss = 1.2041  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.3406  Validation loss = 1.1984  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.3367  Validation loss = 1.2118  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.3365  Validation loss = 1.2051  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.3356  Validation loss = 1.2076  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.3347  Validation loss = 1.2007  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.3337  Validation loss = 1.1991  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.3335  Validation loss = 1.1962  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.3325  Validation loss = 1.1948  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.3325  Validation loss = 1.1823  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 2.3321  Validation loss = 1.1787  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.3317  Validation loss = 1.1695  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.3306  Validation loss = 1.1688  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.3299  Validation loss = 1.1672  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.3292  Validation loss = 1.1653  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.3285  Validation loss = 1.1684  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 2.3280  Validation loss = 1.1645  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 2.3274  Validation loss = 1.1656  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 2.3266  Validation loss = 1.1643  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 2.3265  Validation loss = 1.1611  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 2.3257  Validation loss = 1.1544  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 2.3250  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 2.3245  Validation loss = 1.1639  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 2.3240  Validation loss = 1.1606  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 2.3236  Validation loss = 1.1591  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 2.3233  Validation loss = 1.1631  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 2.3228  Validation loss = 1.1598  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 2.3223  Validation loss = 1.1594  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 2.3214  Validation loss = 1.1613  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 2.3207  Validation loss = 1.1498  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 2.3209  Validation loss = 1.1488  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 2.3194  Validation loss = 1.1552  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 2.3190  Validation loss = 1.1512  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 2.3183  Validation loss = 1.1489  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 2.3175  Validation loss = 1.1476  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 2.3170  Validation loss = 1.1430  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 2.3166  Validation loss = 1.1504  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 2.3159  Validation loss = 1.1498  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 2.3154  Validation loss = 1.1440  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 2.3149  Validation loss = 1.1389  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 2.3143  Validation loss = 1.1370  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 2.3141  Validation loss = 1.1369  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 2.3135  Validation loss = 1.1379  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 2.3129  Validation loss = 1.1361  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 2.3125  Validation loss = 1.1343  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 2.3119  Validation loss = 1.1264  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 2.3112  Validation loss = 1.1266  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 2.3108  Validation loss = 1.1220  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 2.3101  Validation loss = 1.1203  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 2.3095  Validation loss = 1.1258  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 2.3090  Validation loss = 1.1157  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 2.3084  Validation loss = 1.1137  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 2.3077  Validation loss = 1.1175  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 2.3075  Validation loss = 1.1140  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 2.3069  Validation loss = 1.1118  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 2.3066  Validation loss = 1.1138  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 2.3063  Validation loss = 1.1157  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 2.3058  Validation loss = 1.1135  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 2.3053  Validation loss = 1.1129  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 2.3049  Validation loss = 1.1120  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 2.3042  Validation loss = 1.1151  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 2.3037  Validation loss = 1.1145  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 2.3032  Validation loss = 1.1109  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 2.3024  Validation loss = 1.0972  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 2.3017  Validation loss = 1.1030  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 2.3011  Validation loss = 1.0980  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 2.3006  Validation loss = 1.1063  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 2.3000  Validation loss = 1.1084  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 2.2994  Validation loss = 1.1161  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 66  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.2997  Validation loss = 3.4079  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.2985  Validation loss = 3.4178  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.2987  Validation loss = 3.4129  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.2976  Validation loss = 3.4155  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.2965  Validation loss = 3.4247  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.2965  Validation loss = 3.4181  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.2957  Validation loss = 3.4223  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.2948  Validation loss = 3.4232  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.2937  Validation loss = 3.4312  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.2931  Validation loss = 3.4310  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.2921  Validation loss = 3.4369  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.3799  Validation loss = 2.7028  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.3799  Validation loss = 2.6952  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.3790  Validation loss = 2.6947  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.3783  Validation loss = 2.6864  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.3768  Validation loss = 2.7026  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.3756  Validation loss = 2.6892  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 2.3744  Validation loss = 2.7036  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.3735  Validation loss = 2.6926  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.3722  Validation loss = 2.7065  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.3717  Validation loss = 2.7010  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.3706  Validation loss = 2.7032  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.3706  Validation loss = 2.6767  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.3690  Validation loss = 2.6812  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 2.3686  Validation loss = 2.6875  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 2.3685  Validation loss = 2.6596  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 2.3677  Validation loss = 2.6518  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 2.3669  Validation loss = 2.6471  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 2.3680  Validation loss = 2.6260  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 2.3649  Validation loss = 2.6445  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 2.3643  Validation loss = 2.6415  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 2.3630  Validation loss = 2.6554  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 2.3620  Validation loss = 2.6721  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 2.3610  Validation loss = 2.6619  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 2.3623  Validation loss = 2.6253  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 2.3630  Validation loss = 2.6128  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 2.3626  Validation loss = 2.6051  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 2.3618  Validation loss = 2.6022  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 2.3608  Validation loss = 2.5872  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 2.3597  Validation loss = 2.5918  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 2.3590  Validation loss = 2.5896  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 2.3581  Validation loss = 2.6049  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 2.3578  Validation loss = 2.5860  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 2.3561  Validation loss = 2.5948  \n",
      "\n",
      "Fold: 22  Epoch: 34  Training loss = 2.3558  Validation loss = 2.5883  \n",
      "\n",
      "Fold: 22  Epoch: 35  Training loss = 2.3551  Validation loss = 2.5764  \n",
      "\n",
      "Fold: 22  Epoch: 36  Training loss = 2.3555  Validation loss = 2.5586  \n",
      "\n",
      "Fold: 22  Epoch: 37  Training loss = 2.3527  Validation loss = 2.5888  \n",
      "\n",
      "Fold: 22  Epoch: 38  Training loss = 2.3533  Validation loss = 2.5759  \n",
      "\n",
      "Fold: 22  Epoch: 39  Training loss = 2.3517  Validation loss = 2.5938  \n",
      "\n",
      "Fold: 22  Epoch: 40  Training loss = 2.3510  Validation loss = 2.5788  \n",
      "\n",
      "Fold: 22  Epoch: 41  Training loss = 2.3504  Validation loss = 2.5781  \n",
      "\n",
      "Fold: 22  Epoch: 42  Training loss = 2.3494  Validation loss = 2.5937  \n",
      "\n",
      "Fold: 22  Epoch: 43  Training loss = 2.3485  Validation loss = 2.6320  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 36  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.3893  Validation loss = 2.2073  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.3866  Validation loss = 2.1785  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.3854  Validation loss = 2.1627  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.3836  Validation loss = 2.1440  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.3818  Validation loss = 2.1635  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.3796  Validation loss = 2.1352  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.3791  Validation loss = 2.0609  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.3778  Validation loss = 2.0714  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.3795  Validation loss = 2.1534  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.3774  Validation loss = 2.1234  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.3768  Validation loss = 2.1598  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.3743  Validation loss = 2.1166  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 2.3729  Validation loss = 2.1660  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 7  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.3955  Validation loss = 1.5553  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.3918  Validation loss = 1.5480  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.3898  Validation loss = 1.5464  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.3869  Validation loss = 1.5387  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.3874  Validation loss = 1.5458  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 2.3908  Validation loss = 1.5674  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.3830  Validation loss = 1.5429  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.3840  Validation loss = 1.5464  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.3794  Validation loss = 1.5365  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.3755  Validation loss = 1.5232  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.3736  Validation loss = 1.5239  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.3710  Validation loss = 1.5153  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.3675  Validation loss = 1.5012  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.3661  Validation loss = 1.5011  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.3633  Validation loss = 1.4860  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.3638  Validation loss = 1.4858  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.3637  Validation loss = 1.4980  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.3631  Validation loss = 1.5045  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.3586  Validation loss = 1.4894  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 2.3603  Validation loss = 1.4832  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 2.3597  Validation loss = 1.4771  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 2.3635  Validation loss = 1.4535  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 2.3621  Validation loss = 1.4511  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 2.3599  Validation loss = 1.4455  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 2.3545  Validation loss = 1.4523  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 2.3506  Validation loss = 1.4503  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 2.3474  Validation loss = 1.4430  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 2.3487  Validation loss = 1.4370  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 2.3452  Validation loss = 1.4476  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 2.3432  Validation loss = 1.4499  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 2.3427  Validation loss = 1.4574  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 28  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.2861  Validation loss = 2.3021  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.2774  Validation loss = 2.2337  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.2775  Validation loss = 2.1948  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.2771  Validation loss = 2.1782  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.2751  Validation loss = 2.2046  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.2691  Validation loss = 2.1960  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.2673  Validation loss = 2.1805  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.2658  Validation loss = 2.1648  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.2658  Validation loss = 2.1854  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.2672  Validation loss = 2.2405  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.2644  Validation loss = 2.2213  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.2623  Validation loss = 2.1703  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.2600  Validation loss = 2.1642  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.2576  Validation loss = 2.1557  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.2576  Validation loss = 2.1927  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.2558  Validation loss = 2.1851  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 2.2540  Validation loss = 2.1645  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 2.2553  Validation loss = 2.1710  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 2.2554  Validation loss = 2.1646  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 2.2631  Validation loss = 2.1507  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 2.2555  Validation loss = 2.1442  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 2.2534  Validation loss = 2.1418  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 2.2578  Validation loss = 2.1350  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 2.2532  Validation loss = 2.1360  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 2.2476  Validation loss = 2.1348  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 2.2392  Validation loss = 2.1570  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 2.2380  Validation loss = 2.1498  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 2.2384  Validation loss = 2.1832  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 25  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.2457  Validation loss = 2.8157  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.2468  Validation loss = 2.7286  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.2512  Validation loss = 2.8323  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.2444  Validation loss = 2.6949  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.2414  Validation loss = 2.3232  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.2396  Validation loss = 2.7490  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.2356  Validation loss = 2.6156  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.2359  Validation loss = 2.7372  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.2370  Validation loss = 2.7805  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.2363  Validation loss = 2.8046  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.2344  Validation loss = 2.7314  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.2345  Validation loss = 2.7700  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.2277  Validation loss = 2.4416  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 2.2286  Validation loss = 2.0939  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 2.2254  Validation loss = 2.1283  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 2.2237  Validation loss = 2.3701  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 2.2348  Validation loss = 2.7965  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 2.2320  Validation loss = 2.7470  \n",
      "\n",
      "Fold: 26  Epoch: 19  Training loss = 2.2292  Validation loss = 2.5092  \n",
      "\n",
      "Fold: 26  Epoch: 20  Training loss = 2.2318  Validation loss = 2.6456  \n",
      "\n",
      "Fold: 26  Epoch: 21  Training loss = 2.2312  Validation loss = 2.3768  \n",
      "\n",
      "Fold: 26  Epoch: 22  Training loss = 2.2330  Validation loss = 2.1304  \n",
      "\n",
      "Fold: 26  Epoch: 23  Training loss = 2.2234  Validation loss = 2.6239  \n",
      "\n",
      "Fold: 26  Epoch: 24  Training loss = 2.2198  Validation loss = 2.7063  \n",
      "\n",
      "Fold: 26  Epoch: 25  Training loss = 2.2156  Validation loss = 2.5277  \n",
      "\n",
      "Fold: 26  Epoch: 26  Training loss = 2.2161  Validation loss = 2.4675  \n",
      "\n",
      "Fold: 26  Epoch: 27  Training loss = 2.2162  Validation loss = 2.2438  \n",
      "\n",
      "Fold: 26  Epoch: 28  Training loss = 2.2115  Validation loss = 2.5344  \n",
      "\n",
      "Fold: 26  Epoch: 29  Training loss = 2.2093  Validation loss = 2.5672  \n",
      "\n",
      "Fold: 26  Epoch: 30  Training loss = 2.2082  Validation loss = 2.7186  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 14  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.1291  Validation loss = 0.3685  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.1241  Validation loss = 0.3641  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.1745  Validation loss = 0.3171  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.1458  Validation loss = 0.3190  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.1280  Validation loss = 0.3310  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.1297  Validation loss = 0.3533  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.1100  Validation loss = 0.3333  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.1079  Validation loss = 0.3232  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.1258  Validation loss = 0.3104  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.1067  Validation loss = 0.3216  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.0986  Validation loss = 0.3271  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.0990  Validation loss = 0.3251  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.1031  Validation loss = 0.3061  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.1117  Validation loss = 0.3385  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.0935  Validation loss = 0.3207  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.1045  Validation loss = 0.3317  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.1012  Validation loss = 0.3240  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.0872  Validation loss = 0.3124  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.0927  Validation loss = 0.3306  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.1026  Validation loss = 0.2909  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 2.1097  Validation loss = 0.2845  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 2.0954  Validation loss = 0.2911  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 2.0835  Validation loss = 0.2967  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 2.0796  Validation loss = 0.3056  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 2.0939  Validation loss = 0.2866  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 2.0829  Validation loss = 0.2967  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 2.0937  Validation loss = 0.2865  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 2.0764  Validation loss = 0.3040  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 2.0765  Validation loss = 0.2969  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 2.0755  Validation loss = 0.2940  \n",
      "\n",
      "Fold: 27  Epoch: 31  Training loss = 2.0746  Validation loss = 0.2894  \n",
      "\n",
      "Fold: 27  Epoch: 32  Training loss = 2.0764  Validation loss = 0.2890  \n",
      "\n",
      "Fold: 27  Epoch: 33  Training loss = 2.0720  Validation loss = 0.2904  \n",
      "\n",
      "Fold: 27  Epoch: 34  Training loss = 2.0809  Validation loss = 0.2827  \n",
      "\n",
      "Fold: 27  Epoch: 35  Training loss = 2.0680  Validation loss = 0.2989  \n",
      "\n",
      "Fold: 27  Epoch: 36  Training loss = 2.0716  Validation loss = 0.2825  \n",
      "\n",
      "Fold: 27  Epoch: 37  Training loss = 2.0911  Validation loss = 0.2733  \n",
      "\n",
      "Fold: 27  Epoch: 38  Training loss = 2.0669  Validation loss = 0.2888  \n",
      "\n",
      "Fold: 27  Epoch: 39  Training loss = 2.0770  Validation loss = 0.2777  \n",
      "\n",
      "Fold: 27  Epoch: 40  Training loss = 2.0662  Validation loss = 0.2870  \n",
      "\n",
      "Fold: 27  Epoch: 41  Training loss = 2.0630  Validation loss = 0.2958  \n",
      "\n",
      "Fold: 27  Epoch: 42  Training loss = 2.0615  Validation loss = 0.2985  \n",
      "\n",
      "Fold: 27  Epoch: 43  Training loss = 2.0619  Validation loss = 0.2869  \n",
      "\n",
      "Fold: 27  Epoch: 44  Training loss = 2.0590  Validation loss = 0.2930  \n",
      "\n",
      "Fold: 27  Epoch: 45  Training loss = 2.0609  Validation loss = 0.2962  \n",
      "\n",
      "Fold: 27  Epoch: 46  Training loss = 2.0603  Validation loss = 0.3155  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 37  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.0232  Validation loss = 0.7767  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.0219  Validation loss = 0.7804  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.0310  Validation loss = 0.7710  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.0173  Validation loss = 0.7733  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.0156  Validation loss = 0.7680  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.0191  Validation loss = 0.7755  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.0232  Validation loss = 0.7585  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.0128  Validation loss = 0.7673  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.0207  Validation loss = 0.7540  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.0217  Validation loss = 0.7658  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.0111  Validation loss = 0.7567  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.0095  Validation loss = 0.7591  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.0079  Validation loss = 0.7596  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.0102  Validation loss = 0.7606  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.0155  Validation loss = 0.7468  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.0090  Validation loss = 0.7580  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 2.0044  Validation loss = 0.7567  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 2.0040  Validation loss = 0.7524  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 2.0035  Validation loss = 0.7569  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 2.0056  Validation loss = 0.7490  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 2.0021  Validation loss = 0.7470  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 2.0000  Validation loss = 0.7461  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 2.0087  Validation loss = 0.7425  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 2.0000  Validation loss = 0.7502  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 1.9983  Validation loss = 0.7455  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 2.0090  Validation loss = 0.7553  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 1.9967  Validation loss = 0.7460  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 1.9962  Validation loss = 0.7487  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 1.9958  Validation loss = 0.7452  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 2.0003  Validation loss = 0.7456  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 2.0030  Validation loss = 0.7439  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 1.9943  Validation loss = 0.7320  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 1.9948  Validation loss = 0.7406  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 1.9910  Validation loss = 0.7401  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 1.9931  Validation loss = 0.7307  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 2.0035  Validation loss = 0.7429  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 1.9958  Validation loss = 0.7350  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 1.9954  Validation loss = 0.7245  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 1.9881  Validation loss = 0.7326  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 2.0081  Validation loss = 0.7402  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 1.9852  Validation loss = 0.7260  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 2.0151  Validation loss = 0.7428  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 1.9870  Validation loss = 0.7248  \n",
      "\n",
      "Fold: 28  Epoch: 44  Training loss = 1.9861  Validation loss = 0.7180  \n",
      "\n",
      "Fold: 28  Epoch: 45  Training loss = 1.9875  Validation loss = 0.7147  \n",
      "\n",
      "Fold: 28  Epoch: 46  Training loss = 1.9890  Validation loss = 0.7119  \n",
      "\n",
      "Fold: 28  Epoch: 47  Training loss = 1.9827  Validation loss = 0.7157  \n",
      "\n",
      "Fold: 28  Epoch: 48  Training loss = 1.9833  Validation loss = 0.7192  \n",
      "\n",
      "Fold: 28  Epoch: 49  Training loss = 1.9789  Validation loss = 0.7154  \n",
      "\n",
      "Fold: 28  Epoch: 50  Training loss = 1.9822  Validation loss = 0.7225  \n",
      "\n",
      "Fold: 28  Epoch: 51  Training loss = 1.9856  Validation loss = 0.7246  \n",
      "\n",
      "Fold: 28  Epoch: 52  Training loss = 1.9876  Validation loss = 0.7243  \n",
      "\n",
      "Fold: 28  Epoch: 53  Training loss = 1.9792  Validation loss = 0.7154  \n",
      "\n",
      "Fold: 28  Epoch: 54  Training loss = 1.9797  Validation loss = 0.7081  \n",
      "\n",
      "Fold: 28  Epoch: 55  Training loss = 1.9824  Validation loss = 0.7200  \n",
      "\n",
      "Fold: 28  Epoch: 56  Training loss = 1.9879  Validation loss = 0.7049  \n",
      "\n",
      "Fold: 28  Epoch: 57  Training loss = 1.9835  Validation loss = 0.7059  \n",
      "\n",
      "Fold: 28  Epoch: 58  Training loss = 1.9760  Validation loss = 0.7056  \n",
      "\n",
      "Fold: 28  Epoch: 59  Training loss = 1.9801  Validation loss = 0.7036  \n",
      "\n",
      "Fold: 28  Epoch: 60  Training loss = 1.9781  Validation loss = 0.7151  \n",
      "\n",
      "Fold: 28  Epoch: 61  Training loss = 1.9734  Validation loss = 0.7111  \n",
      "\n",
      "Fold: 28  Epoch: 62  Training loss = 1.9734  Validation loss = 0.7016  \n",
      "\n",
      "Fold: 28  Epoch: 63  Training loss = 1.9780  Validation loss = 0.6994  \n",
      "\n",
      "Fold: 28  Epoch: 64  Training loss = 1.9739  Validation loss = 0.6991  \n",
      "\n",
      "Fold: 28  Epoch: 65  Training loss = 1.9720  Validation loss = 0.6981  \n",
      "\n",
      "Fold: 28  Epoch: 66  Training loss = 1.9874  Validation loss = 0.6923  \n",
      "\n",
      "Fold: 28  Epoch: 67  Training loss = 1.9731  Validation loss = 0.6961  \n",
      "\n",
      "Fold: 28  Epoch: 68  Training loss = 1.9738  Validation loss = 0.6927  \n",
      "\n",
      "Fold: 28  Epoch: 69  Training loss = 1.9700  Validation loss = 0.6915  \n",
      "\n",
      "Fold: 28  Epoch: 70  Training loss = 1.9715  Validation loss = 0.6924  \n",
      "\n",
      "Fold: 28  Epoch: 71  Training loss = 1.9721  Validation loss = 0.7005  \n",
      "\n",
      "Fold: 28  Epoch: 72  Training loss = 1.9684  Validation loss = 0.6996  \n",
      "\n",
      "Fold: 28  Epoch: 73  Training loss = 1.9794  Validation loss = 0.7010  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 69  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 1.9523  Validation loss = 0.8365  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 1.9427  Validation loss = 0.8414  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 1.9428  Validation loss = 0.8381  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 1.9498  Validation loss = 0.8330  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 1.9416  Validation loss = 0.8402  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 1.9400  Validation loss = 0.8429  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 1.9392  Validation loss = 0.8411  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 1.9390  Validation loss = 0.8372  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 1.9371  Validation loss = 0.8324  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.9397  Validation loss = 0.8344  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 1.9509  Validation loss = 0.8205  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 1.9393  Validation loss = 0.8267  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 1.9393  Validation loss = 0.8246  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 1.9391  Validation loss = 0.8254  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 1.9342  Validation loss = 0.8328  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 1.9335  Validation loss = 0.8274  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 1.9341  Validation loss = 0.8237  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 1.9690  Validation loss = 0.8411  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 11  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.9111  Validation loss = 1.2404  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 1.9109  Validation loss = 1.2427  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 1.9369  Validation loss = 1.2207  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 1.9248  Validation loss = 1.2908  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 1.9240  Validation loss = 1.2859  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.9058  Validation loss = 1.2454  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 1.9063  Validation loss = 1.2306  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 1.9024  Validation loss = 1.2352  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.9050  Validation loss = 1.2311  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 1.9011  Validation loss = 1.2342  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 1.9005  Validation loss = 1.2274  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 1.8985  Validation loss = 1.2224  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 1.8999  Validation loss = 1.2381  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 1.8980  Validation loss = 1.2200  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 1.8955  Validation loss = 1.2284  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 1.8969  Validation loss = 1.2134  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 1.9028  Validation loss = 1.2104  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 1.8967  Validation loss = 1.2087  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 1.9075  Validation loss = 1.2489  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 18  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 1.8514  Validation loss = 0.8219  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 1.8498  Validation loss = 0.7828  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 1.8491  Validation loss = 0.7710  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 1.8455  Validation loss = 0.8196  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 1.8434  Validation loss = 0.7992  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 1.8550  Validation loss = 0.7608  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 1.8440  Validation loss = 0.7871  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.8413  Validation loss = 0.8028  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 1.8404  Validation loss = 0.7952  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 1.8480  Validation loss = 0.8306  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.8431  Validation loss = 0.8162  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 1.8479  Validation loss = 0.7441  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 1.8370  Validation loss = 0.8053  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 1.8334  Validation loss = 0.7867  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 1.8334  Validation loss = 0.7587  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 1.8533  Validation loss = 0.8395  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 12  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.6280  Validation loss = 1.8276  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.6244  Validation loss = 1.8243  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.6221  Validation loss = 1.7642  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.6321  Validation loss = 1.6252  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.6290  Validation loss = 1.9678  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.6117  Validation loss = 1.7823  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.6120  Validation loss = 1.7048  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.6073  Validation loss = 1.7877  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.6088  Validation loss = 1.8406  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.6048  Validation loss = 1.8111  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.6016  Validation loss = 1.7402  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.6036  Validation loss = 1.8319  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.5994  Validation loss = 1.7613  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.5996  Validation loss = 1.6684  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.5999  Validation loss = 1.6260  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.5993  Validation loss = 1.6269  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.5945  Validation loss = 1.7149  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.5951  Validation loss = 1.7887  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.5925  Validation loss = 1.7370  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.5930  Validation loss = 1.6633  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 1.5918  Validation loss = 1.7510  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 1.5925  Validation loss = 1.6488  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 1.5897  Validation loss = 1.6933  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 1.5907  Validation loss = 1.6250  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 1.5939  Validation loss = 1.5552  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 1.5903  Validation loss = 1.5986  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 1.5962  Validation loss = 1.5091  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 1.5895  Validation loss = 1.5782  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 1.5858  Validation loss = 1.6325  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 1.5835  Validation loss = 1.6610  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 1.5823  Validation loss = 1.6847  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 1.5867  Validation loss = 1.8227  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 27  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 145\n",
      "Average validation error: 2.35295\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.5439  Test loss = 2.5266  \n",
      "\n",
      "Epoch: 2  Training loss = 1.5424  Test loss = 2.5218  \n",
      "\n",
      "Epoch: 3  Training loss = 1.5410  Test loss = 2.5172  \n",
      "\n",
      "Epoch: 4  Training loss = 1.5397  Test loss = 2.5129  \n",
      "\n",
      "Epoch: 5  Training loss = 1.5384  Test loss = 2.5088  \n",
      "\n",
      "Epoch: 6  Training loss = 1.5373  Test loss = 2.5049  \n",
      "\n",
      "Epoch: 7  Training loss = 1.5362  Test loss = 2.5012  \n",
      "\n",
      "Epoch: 8  Training loss = 1.5351  Test loss = 2.4977  \n",
      "\n",
      "Epoch: 9  Training loss = 1.5342  Test loss = 2.4943  \n",
      "\n",
      "Epoch: 10  Training loss = 1.5332  Test loss = 2.4911  \n",
      "\n",
      "Epoch: 11  Training loss = 1.5324  Test loss = 2.4880  \n",
      "\n",
      "Epoch: 12  Training loss = 1.5315  Test loss = 2.4851  \n",
      "\n",
      "Epoch: 13  Training loss = 1.5307  Test loss = 2.4822  \n",
      "\n",
      "Epoch: 14  Training loss = 1.5300  Test loss = 2.4795  \n",
      "\n",
      "Epoch: 15  Training loss = 1.5293  Test loss = 2.4770  \n",
      "\n",
      "Epoch: 16  Training loss = 1.5286  Test loss = 2.4745  \n",
      "\n",
      "Epoch: 17  Training loss = 1.5279  Test loss = 2.4721  \n",
      "\n",
      "Epoch: 18  Training loss = 1.5273  Test loss = 2.4698  \n",
      "\n",
      "Epoch: 19  Training loss = 1.5267  Test loss = 2.4676  \n",
      "\n",
      "Epoch: 20  Training loss = 1.5261  Test loss = 2.4655  \n",
      "\n",
      "Epoch: 21  Training loss = 1.5255  Test loss = 2.4634  \n",
      "\n",
      "Epoch: 22  Training loss = 1.5250  Test loss = 2.4615  \n",
      "\n",
      "Epoch: 23  Training loss = 1.5245  Test loss = 2.4596  \n",
      "\n",
      "Epoch: 24  Training loss = 1.5240  Test loss = 2.4578  \n",
      "\n",
      "Epoch: 25  Training loss = 1.5235  Test loss = 2.4560  \n",
      "\n",
      "Epoch: 26  Training loss = 1.5230  Test loss = 2.4544  \n",
      "\n",
      "Epoch: 27  Training loss = 1.5226  Test loss = 2.4527  \n",
      "\n",
      "Epoch: 28  Training loss = 1.5222  Test loss = 2.4512  \n",
      "\n",
      "Epoch: 29  Training loss = 1.5218  Test loss = 2.4497  \n",
      "\n",
      "Epoch: 30  Training loss = 1.5213  Test loss = 2.4482  \n",
      "\n",
      "Epoch: 31  Training loss = 1.5210  Test loss = 2.4468  \n",
      "\n",
      "Epoch: 32  Training loss = 1.5206  Test loss = 2.4455  \n",
      "\n",
      "Epoch: 33  Training loss = 1.5202  Test loss = 2.4441  \n",
      "\n",
      "Epoch: 34  Training loss = 1.5198  Test loss = 2.4429  \n",
      "\n",
      "Epoch: 35  Training loss = 1.5195  Test loss = 2.4417  \n",
      "\n",
      "Epoch: 36  Training loss = 1.5191  Test loss = 2.4405  \n",
      "\n",
      "Epoch: 37  Training loss = 1.5188  Test loss = 2.4394  \n",
      "\n",
      "Epoch: 38  Training loss = 1.5185  Test loss = 2.4383  \n",
      "\n",
      "Epoch: 39  Training loss = 1.5182  Test loss = 2.4372  \n",
      "\n",
      "Epoch: 40  Training loss = 1.5179  Test loss = 2.4362  \n",
      "\n",
      "Epoch: 41  Training loss = 1.5176  Test loss = 2.4352  \n",
      "\n",
      "Epoch: 42  Training loss = 1.5173  Test loss = 2.4342  \n",
      "\n",
      "Epoch: 43  Training loss = 1.5170  Test loss = 2.4333  \n",
      "\n",
      "Epoch: 44  Training loss = 1.5167  Test loss = 2.4324  \n",
      "\n",
      "Epoch: 45  Training loss = 1.5164  Test loss = 2.4315  \n",
      "\n",
      "Epoch: 46  Training loss = 1.5161  Test loss = 2.4307  \n",
      "\n",
      "Epoch: 47  Training loss = 1.5159  Test loss = 2.4299  \n",
      "\n",
      "Epoch: 48  Training loss = 1.5156  Test loss = 2.4291  \n",
      "\n",
      "Epoch: 49  Training loss = 1.5154  Test loss = 2.4284  \n",
      "\n",
      "Epoch: 50  Training loss = 1.5151  Test loss = 2.4276  \n",
      "\n",
      "Epoch: 51  Training loss = 1.5149  Test loss = 2.4269  \n",
      "\n",
      "Epoch: 52  Training loss = 1.5146  Test loss = 2.4262  \n",
      "\n",
      "Epoch: 53  Training loss = 1.5144  Test loss = 2.4256  \n",
      "\n",
      "Epoch: 54  Training loss = 1.5141  Test loss = 2.4249  \n",
      "\n",
      "Epoch: 55  Training loss = 1.5139  Test loss = 2.4243  \n",
      "\n",
      "Epoch: 56  Training loss = 1.5137  Test loss = 2.4237  \n",
      "\n",
      "Epoch: 57  Training loss = 1.5134  Test loss = 2.4232  \n",
      "\n",
      "Epoch: 58  Training loss = 1.5132  Test loss = 2.4226  \n",
      "\n",
      "Epoch: 59  Training loss = 1.5130  Test loss = 2.4221  \n",
      "\n",
      "Epoch: 60  Training loss = 1.5128  Test loss = 2.4215  \n",
      "\n",
      "Epoch: 61  Training loss = 1.5125  Test loss = 2.4210  \n",
      "\n",
      "Epoch: 62  Training loss = 1.5123  Test loss = 2.4206  \n",
      "\n",
      "Epoch: 63  Training loss = 1.5121  Test loss = 2.4201  \n",
      "\n",
      "Epoch: 64  Training loss = 1.5119  Test loss = 2.4196  \n",
      "\n",
      "Epoch: 65  Training loss = 1.5117  Test loss = 2.4192  \n",
      "\n",
      "Epoch: 66  Training loss = 1.5115  Test loss = 2.4188  \n",
      "\n",
      "Epoch: 67  Training loss = 1.5113  Test loss = 2.4184  \n",
      "\n",
      "Epoch: 68  Training loss = 1.5111  Test loss = 2.4180  \n",
      "\n",
      "Epoch: 69  Training loss = 1.5109  Test loss = 2.4176  \n",
      "\n",
      "Epoch: 70  Training loss = 1.5107  Test loss = 2.4172  \n",
      "\n",
      "Epoch: 71  Training loss = 1.5105  Test loss = 2.4168  \n",
      "\n",
      "Epoch: 72  Training loss = 1.5103  Test loss = 2.4165  \n",
      "\n",
      "Epoch: 73  Training loss = 1.5101  Test loss = 2.4162  \n",
      "\n",
      "Epoch: 74  Training loss = 1.5099  Test loss = 2.4158  \n",
      "\n",
      "Epoch: 75  Training loss = 1.5097  Test loss = 2.4155  \n",
      "\n",
      "Epoch: 76  Training loss = 1.5095  Test loss = 2.4152  \n",
      "\n",
      "Epoch: 77  Training loss = 1.5093  Test loss = 2.4149  \n",
      "\n",
      "Epoch: 78  Training loss = 1.5091  Test loss = 2.4147  \n",
      "\n",
      "Epoch: 79  Training loss = 1.5090  Test loss = 2.4144  \n",
      "\n",
      "Epoch: 80  Training loss = 1.5088  Test loss = 2.4141  \n",
      "\n",
      "Epoch: 81  Training loss = 1.5086  Test loss = 2.4139  \n",
      "\n",
      "Epoch: 82  Training loss = 1.5084  Test loss = 2.4136  \n",
      "\n",
      "Epoch: 83  Training loss = 1.5082  Test loss = 2.4134  \n",
      "\n",
      "Epoch: 84  Training loss = 1.5080  Test loss = 2.4132  \n",
      "\n",
      "Epoch: 85  Training loss = 1.5079  Test loss = 2.4129  \n",
      "\n",
      "Epoch: 86  Training loss = 1.5077  Test loss = 2.4127  \n",
      "\n",
      "Epoch: 87  Training loss = 1.5075  Test loss = 2.4125  \n",
      "\n",
      "Epoch: 88  Training loss = 1.5073  Test loss = 2.4123  \n",
      "\n",
      "Epoch: 89  Training loss = 1.5071  Test loss = 2.4121  \n",
      "\n",
      "Epoch: 90  Training loss = 1.5070  Test loss = 2.4120  \n",
      "\n",
      "Epoch: 91  Training loss = 1.5068  Test loss = 2.4118  \n",
      "\n",
      "Epoch: 92  Training loss = 1.5066  Test loss = 2.4116  \n",
      "\n",
      "Epoch: 93  Training loss = 1.5064  Test loss = 2.4114  \n",
      "\n",
      "Epoch: 94  Training loss = 1.5063  Test loss = 2.4113  \n",
      "\n",
      "Epoch: 95  Training loss = 1.5061  Test loss = 2.4111  \n",
      "\n",
      "Epoch: 96  Training loss = 1.5059  Test loss = 2.4110  \n",
      "\n",
      "Epoch: 97  Training loss = 1.5058  Test loss = 2.4108  \n",
      "\n",
      "Epoch: 98  Training loss = 1.5056  Test loss = 2.4107  \n",
      "\n",
      "Epoch: 99  Training loss = 1.5054  Test loss = 2.4106  \n",
      "\n",
      "Epoch: 100  Training loss = 1.5052  Test loss = 2.4104  \n",
      "\n",
      "Epoch: 101  Training loss = 1.5051  Test loss = 2.4103  \n",
      "\n",
      "Epoch: 102  Training loss = 1.5049  Test loss = 2.4102  \n",
      "\n",
      "Epoch: 103  Training loss = 1.5047  Test loss = 2.4101  \n",
      "\n",
      "Epoch: 104  Training loss = 1.5046  Test loss = 2.4100  \n",
      "\n",
      "Epoch: 105  Training loss = 1.5044  Test loss = 2.4099  \n",
      "\n",
      "Epoch: 106  Training loss = 1.5042  Test loss = 2.4098  \n",
      "\n",
      "Epoch: 107  Training loss = 1.5041  Test loss = 2.4097  \n",
      "\n",
      "Epoch: 108  Training loss = 1.5039  Test loss = 2.4096  \n",
      "\n",
      "Epoch: 109  Training loss = 1.5038  Test loss = 2.4095  \n",
      "\n",
      "Epoch: 110  Training loss = 1.5036  Test loss = 2.4094  \n",
      "\n",
      "Epoch: 111  Training loss = 1.5034  Test loss = 2.4093  \n",
      "\n",
      "Epoch: 112  Training loss = 1.5033  Test loss = 2.4092  \n",
      "\n",
      "Epoch: 113  Training loss = 1.5031  Test loss = 2.4092  \n",
      "\n",
      "Epoch: 114  Training loss = 1.5029  Test loss = 2.4091  \n",
      "\n",
      "Epoch: 115  Training loss = 1.5028  Test loss = 2.4090  \n",
      "\n",
      "Epoch: 116  Training loss = 1.5026  Test loss = 2.4090  \n",
      "\n",
      "Epoch: 117  Training loss = 1.5025  Test loss = 2.4089  \n",
      "\n",
      "Epoch: 118  Training loss = 1.5023  Test loss = 2.4088  \n",
      "\n",
      "Epoch: 119  Training loss = 1.5021  Test loss = 2.4088  \n",
      "\n",
      "Epoch: 120  Training loss = 1.5020  Test loss = 2.4087  \n",
      "\n",
      "Epoch: 121  Training loss = 1.5018  Test loss = 2.4087  \n",
      "\n",
      "Epoch: 122  Training loss = 1.5017  Test loss = 2.4086  \n",
      "\n",
      "Epoch: 123  Training loss = 1.5015  Test loss = 2.4086  \n",
      "\n",
      "Epoch: 124  Training loss = 1.5014  Test loss = 2.4085  \n",
      "\n",
      "Epoch: 125  Training loss = 1.5012  Test loss = 2.4085  \n",
      "\n",
      "Epoch: 126  Training loss = 1.5010  Test loss = 2.4084  \n",
      "\n",
      "Epoch: 127  Training loss = 1.5009  Test loss = 2.4084  \n",
      "\n",
      "Epoch: 128  Training loss = 1.5007  Test loss = 2.4084  \n",
      "\n",
      "Epoch: 129  Training loss = 1.5006  Test loss = 2.4083  \n",
      "\n",
      "Epoch: 130  Training loss = 1.5004  Test loss = 2.4083  \n",
      "\n",
      "Epoch: 131  Training loss = 1.5003  Test loss = 2.4083  \n",
      "\n",
      "Epoch: 132  Training loss = 1.5001  Test loss = 2.4082  \n",
      "\n",
      "Epoch: 133  Training loss = 1.5000  Test loss = 2.4082  \n",
      "\n",
      "Epoch: 134  Training loss = 1.4998  Test loss = 2.4082  \n",
      "\n",
      "Epoch: 135  Training loss = 1.4997  Test loss = 2.4081  \n",
      "\n",
      "Epoch: 136  Training loss = 1.4995  Test loss = 2.4081  \n",
      "\n",
      "Epoch: 137  Training loss = 1.4994  Test loss = 2.4081  \n",
      "\n",
      "Epoch: 138  Training loss = 1.4992  Test loss = 2.4081  \n",
      "\n",
      "Epoch: 139  Training loss = 1.4991  Test loss = 2.4081  \n",
      "\n",
      "Epoch: 140  Training loss = 1.4989  Test loss = 2.4080  \n",
      "\n",
      "Epoch: 141  Training loss = 1.4988  Test loss = 2.4080  \n",
      "\n",
      "Epoch: 142  Training loss = 1.4986  Test loss = 2.4080  \n",
      "\n",
      "Epoch: 143  Training loss = 1.4985  Test loss = 2.4080  \n",
      "\n",
      "Epoch: 144  Training loss = 1.4983  Test loss = 2.4080  \n",
      "\n",
      "Epoch: 145  Training loss = 1.4982  Test loss = 2.4080  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4VFX6xz8nPZkAIYUWSughIC0gTVRALLgq4OqiYkVE\n7L3rrquuDUSwrIJdWUFRxA7yA1SkSBAxEKpAaFJCQgqkz/v74+ZOJsm0JJOEzJzP8/CE3Dlz7pnJ\nzPe+93ve8x4lImg0Go3Gdwho6AFoNBqNxrtoYddoNBofQwu7RqPR+Bha2DUajcbH0MKu0Wg0PoYW\ndo1Go/ExtLBrNBqNj6GFXaPRaHwMLewajUbjYwQ1xEljY2MlISGhIU6t0Wg0jZb169dniEicu3YN\nIuwJCQmkpKQ0xKk1Go2m0aKUSveknbZiNBqNxsfQwq7RaDQ+hhZ2jUaj8TG0sGs0Go2PoYVdo9Fo\nfAwt7BqNRuNjaGHXaDQaH6NxCfvy5fD88w09Co1GozmlaVzC/u238MgjsGNHQ49Eo9FoTlkal7Df\ndx+EhsLTTzf0SDQajeaUpXEJe8uWMHUqzJ0LO3c29Gg0Go3mlMQrwq6UulsptVkptUkp9bFSKswb\n/Trk/vshOBieeabOTqHRaDSNmVoLu1IqHrgDGCAivYBAYEJt+3VKq1ZG1P7hh/Dnn3V2Go1Go2ms\neMuKCQLClVJBQARw0Ev9OuaBB3TUrtFoNE6otbCLyAFgGrAX+AvIFpElldsppW5SSqUopVKOHj1a\nu5O2agVTpsAHH8CuXbXrS6PRaHwMb1gxzYFLgI5AG8CilJpYuZ2IzBaRASIyIC7ObZ149zzwAAQF\n6ahdo9FoKuENK+YcYLeIHBWRYuBzYKgX+nVNmzblUfvu3XV+Oo1Go2kseEPY9wKDlVIRSikFjAK2\neKFf9zz4IAQGwksv1cvpNBqNpjHgDY99LbAA+A1ILetzdm379Yg2bWDgQEhNrZfTaTQaTWPAK3ue\nisg/gX96o69qEx8P69c3yKk1Go3mVKRxrTx1RNu2cOAAiDT0SDQajeaUoPELe3w85OdDVlZDj0Sj\n0WhOCXxD2MGI2jUajUajhV2j0Wh8jcYv7G3bGj+1sGs0Gg3gC8LeurXxc//+hh2HRqPRnCI0fmEP\nCYEWLXTErtFoNGU0fmEHw2fXwq7RaDSArwi7mcuu0Wg0Gh8R9vh47bFrNBpNGb4j7MeOQUGBw4fz\n8vJ4+eWXsVqt9TwwjUajqX98R9gBDjreuOnjjz/m7rvvZuPGjfU4KI0vkJGRwZ49e1y2KSwsZMKE\nCcyYMYOTJ0/Wz8A0Ghf4hrC7yWVPSUkBjMhdo6kODzzwABdddJHLNtu2bWP+/Pncc889dOrUSQu8\npsHxDWE3I3YnPrsp7CdOnKivEWl8hPT0dPbu3euyjbnV47PPPkuvXr1sAv/mm2/WxxA1mir4lrA7\niNgLCwtJLavXroVdU12OHDlCTk4OhYWFTttkZGQAcNFFF7F06VJ++uknOnXqxM0338y+ffvqa6ga\njQ3fEPamTcFicSjsqampFBcXA+jbY021MaNxU7xdtTH38h0+fDgPPfRQhcc0mvrEN4RdKae57Ovt\nNuHQEbumOlitVpuguxL2jIwMlFJER0fbjkVFRQFw/Pjxuh2kRuMA3xB2cJrLnpKSQnh4OKCFXVM9\nsrKyKC0tBVxH3kePHqV58+YEBZVvSKaFXdOQ+JawO4nYhwwZAmhh11SPI0eO2P7vStgzMjJsNoyJ\nFnZNQ9KohH3BggU8+uijjh+Mjzfy2O0WIRUUFJCamsqgQYMICQnRHrumWtiLubuIPTY2tsIxLeya\nhqRRCfvKlSt55ZVXHD/Yti2UlIBdlJWamkpJSQnJyclYLBYdsfsx9913H4sWLarWc+wjdneTp5Uj\n9sjISAICArSwaxqERiXssbGx5ObmOk49c5DyaOavDxgwQAu7H1NaWsrMmTP5/PPPq/U8M0oPDAx0\na8VUjtgDAgJo1qyZFnZNg9CohN2MihxGTw6Eff369cTExNC+fXssFou2YvyUgwcPUlJSQmZmZrWe\nZ0bsHTt2dCrsIuLQYwfDjtHCrmkIGqWwO/ySOYnYBwwYgFKKiIgIHbH7Kenp6QDVFvajR48SHR1N\n69atnVox2dnZlJSUVInYQQu7puFoVMJufnkcCnvLlhAYaEt5zM/PZ/PmzSQnJwNoK8aPMYt4HTt2\nrFrPO3LkCHFxccTFxTmN2CsvTrJHC7umoWhUwu7SigkMNPY/LYvY//jjD0pKShgwYACghd2fqU3E\n3qJFC5fCbn4WtbBrTiUapbA7nciyy2U3J07NiD0iIkJ77H6KGbFnZmYiIh4/zz5iP3bsmMN6/uZn\nUVsxmlOJRiXszZs3RynlPPXMTtjXr19PXFwc7dq1A3TE7s+Ywl5aWkpubq7HzzMj9tjYWKxWK1lZ\nWVXa6IhdcyrSqIQ9MDCQmJgY5xF727Y2j91+4hS0sPsz6enpts+Bpz57aWmpLdvF1Z2iu4g9NzeX\nkpKSmg5do6kRXhF2pVSUUmqBUmqrUmqLUmqIN/p1hCu/k/h4yM3l5OHDpKWl2WwYQKc7+ilWq5X0\n9HS6desGeO6zm7aN6bGDc2EPDw/HYrFUecxcfZqTk1PT4Ws0NcJbEftM4HsRSQT6AFu81G8VYmNj\nXVsxwLZlyygtLbVNnAK2dMfqeKyaxs/hw4cpKiqif//+gOfCbuawx8XFuczGcrQ4yUSXFdA0FLUW\ndqVUM+BM4G0AESkSkTr7JLuN2IH0VasAqkTsIkKBkw2vNb6J6a9XV9jNz5h9xO4ooHBUTsBEC7um\nofBGxN4ROAq8q5TaoJR6SylV9b7US8TGxrr22IGjGzbQsmVL4s1FS2C7VdY+u39hpjqawu6px24f\nsbuyYnTErjkV8YawBwH9gf+KSD/gBPBQ5UZKqZuUUilKqZTa7CrjKvXMjNhP7thBcnKybcIMDCsG\n9C5K/oYZsfft2xeoWcQeGhpKkyZNnHrsOmLXnGp4Q9j3A/tFZG3Z7wswhL4CIjJbRAaIyABnXwRP\niIuLc5p6Rng40rw5wUeOVLBhQEfs/kp6ejoxMTFER0cTGRlZLY9dKUVMTAzgfG5HR+yaU5FaC7uI\nHAL2KaW6lx0aBaTVtl9nuCwrABTFxtIGbFkQJlrY/ZM9e/bQoUMHAGJiYqoVscfExBAYGAg4ntsp\nLCwkNzdXR+yaU44g90084nZgrlIqBNgFXO+lfqvgsqwAkBsVRVsgr8xvNzGFvb6smFmzZmGxWJg0\naVK9nE/jmPT0dHr06AFAdHR0tTx2e8GOi4vj4MGDFdq4WpwEuia7puHwSrqjiPxeZrP0FpGxIuLA\nJ/EO7soKZIWHEw8VJk6h3GOvr4j95Zdf5o033qiXc2kcIyIVIvbo6OhqRewtWrSw/V5h0v7OO+Gj\nj1wuTgJdk13TcDSqlafg3oo5HBRESyDe7ksJ9WvFFBUVkZ6ebpu40zQMGRkZ5Ofnk5CQAFRP2B1F\n7BkZGUhBAbz2Grz1ltuIHXRZAU3D0OiE3Z0Vs7e0lAAgotJqv/oU9t27d2O1WsnIyCAvL6/Oz6dx\njHlhranHbh+xx8XFUVBQQP769VBaCuvXk3H4MOA8Ygct7JqGodEJe1hYGJGRkU4j9j/NbfPKasaY\n1Ge6486dO23/N/OoNfWP+d5XjtjdrT4uKSnh2LFjVSJ2gBOrVxsH8vIo3ry5wmOO0MKuaQi8NXla\nr7gqK5CWnW3855tvjEqPJ07AiRM0AxT1E7HbC/uePXvo2bNnnZ9TU5XKEXt0dDQlJSXk5ubStGlT\np88zJ1gre+wApb/9ZjsWsXkzSimaN2/utK+oqKgKnweNpj5olMLuqqzAb8eOUaIUQc88U+F4ODCE\n+hH2HTt2EBgYSGlpqfbZG5A9e/bQrFkzW9phdHQ0YCxSciXs9qtOTcz/B6WlQf/+sG0b0bt2VUiJ\ndERUVJTjNRcaTR3S6KwYcF5WoLi4mB1Hj/LGLbfAmjXwxx/w55/w++8ADAwKqjcrpnfv3oSGhmph\nb0DS09NtNgxgW2zkzme3X3VqYgp75K5d0K8fJCcTf/CgS38dtBWjaRgabcS+uczftOevv/5CRAjt\n0wcGDSp/QARiYuifl8ev9WTFDBgwgJMnT2phb0D27NlDp06dbL+bEbu7XHZHEXtsbCytgLDcXOjd\nG6KiSPj5Z1qV5cg7Iyoqiry8PEpKSggKapRfN00jpFFG7M6smANluye1rbQ4CaWgTx96i9S5FVNc\nXMyePXvo2rUrCQkJWtgbCBGpErHbWzGucBSxN23alP6m5dK7NwwYQIgIyaGhLvsybaBsc+5Ho6kH\nGqWwx8bGkp+fX0Wk95dlwlRenARAnz4kFheTX42t0WrCnj17KC0tpUuXLlrYG5CsrCxyc3NtE6fg\nubAfOXKEgIAAW3sApRRDyjKr6N0bBg4EoG9xscu+dFkBTUPQKIXdWS6704gdoG9fwkSIqkVlSU/Y\nsWMHgE3YdS57w1A51RGqF7HHxsYSEFDx69EvMJCjYWEQHY01IYFjQKKzQCEvDz77jKhmzQAt7Jr6\npVELe2U75sCBA4SFhTlOP+vTB4A2dSzsZmqbacWAzmVvCCqnOgKEhIQQGRnpkcfuKDc9qbiY7WFh\nABzPziYFaO/s8zRtGvz973Tcvt1or4VdU480SmF3VlZg//79xMfHV6jDbqNHD4qVokMdp57t3LmT\nJk2aEBcXZxN2bcfUP44idvCsrEDlVacAFBbS7uRJ/ij7bGVkZJACxP71F+TnV2xrtcL77xvn/+wz\nQAu7pn5plMLuyopxaMMAhISwv2lTOtWxLbJjxw66dOmCUsomKrt3767Tc2qqsmfPHiwWSwWfHDwT\ndocR+9atBInwa9nWikePHmUdEGC12tJpbfz0E+zZA4MG0WTtWvqihV1TvzRKYXcXsTvjQEwM3SpH\nV15m586ddO3aFYCWLVsSFhamI/YGwMyIqXz35km9GIcR+8aNAKzJz6eoqMgm7ACsW1ex7XvvQdOm\nsHAhEhnJfWhh19QvjVLYo6KiCAoKqhCxiwgHDx50HrEDf7VsScvSUijLU/Y2Zqpjly5dACOTokOH\nDlrYvcT27ds577zz2LRpk9u29uV67XFXk724uJisrKyqEfsff1ASFMQOjDz4jIwMDgKlcXGQklLe\nLi8PFiyACROgdWuYPJl/AKLnWTT1SKMUdqVUldWnx44do7Cw0GXEfswU/bLoy9ukp6dTUlJii9gB\nn055fO6555g0aZLj/We9zPHjx7noootYsmQJjz/+uNv2lXPYTdxZMWaw4Chiz2nfnlKMiN722Rs4\nsGLEvmCBUZ/ouusAUHfdBUD/n392O2aNxls0SmGHqmUFzBx2VxF7Vvv2AMiGDXUyJjMjxozYwbeF\n/bPPPuOdd97hX//6V52ep6SkhAkTJrB7924uvvhivvjiC7Zs2eK0fXZ2NllZWU4jdlcVHh2tOgXg\njz8o7G7s/nj06FEyMjKwWCwEDh4M27aBWSb6vfegWzcYPNj4vX17vrFYGLJpE2g7RlNPNFphNzc+\nMDFz2F1F7AFxceyjYoU+b2Kfw27SsWNHjh07Rm4dL4xqCNLT0wkNDeWpp57i888/r7PzPPDAAyxe\nvJjXX3+dt99+m/DwcF544QWX44KqGTFgeOwlJSVO1xY4WnXK4cOGfde7t62NmevOwIFGyYr162HX\nLvjxRyNat/P257VtS3hJCcyeXc1XrtHUjEYt7I4idlfCbrFY2AhGcbA6YOfOnURGRtKyZUvbMV/N\nZc/Pz+fo0aPcf//9DBo0iGuuucYj77u6vPPOO8yYMYM77riDG2+8kdjYWCZPnsxHH33Evn37HD7H\nlbC7qxfjMGIvs+7CTj8dMOyajIwMo82AAUablBT44AND0K++ukKfh9u0IaVZM5g5E4qKPHvhGk0t\naLTCXtmKOXDgAAEBAbRq1crpcyIiIvgdCNy+HcrS1lxRWlrK+PHj+emnnzwa086dO22pjia+mstu\nimq3bt347LPPaNKkCWPHjvVqidqVK1dy8803M3r0aKZPn247fu+99wJUOGaPo8VJJu5WnzqM2MsC\ngSbDhqGUqhixx8ZCQgL8+quRuz56NFSyA6OiongrKgoOHoR589y/cI2mljRaYY+LiyMrK4uSkhLA\niNhbtWrlsoKeGbGr0lJIS3N7jmPHjrFw4UJeeuklj8Zk5rDb46vCvnfvXgDat29PfHw8CxYsYO/e\nvVxxxRWUlpbWun8RYeLEiSQkJDB//vwKf9f27dtz1VVXMWfOHIcbrqSnpxMWFlZ1AhT3pXuPHDlC\nYGCgrcYLYETs8fEEtWxJ8+bNbR67LaofOBAWLTJy18smTe2Jiorim5IS6NULXnnF8zdBo6khjVrY\nofyW2uXipDIsFgu2pSSVF5U4IKdsQuz7779365GXlJSwe/fuChkxYER+vpjLbi/sAMOGDeOVV15h\n8eLFPPzww7Xu/+jRo6Snp3PLLbc4LBHxwAMPcPLkSV599dUKx1esWMHcuXPp3r27wxXInkTscXFx\nFevE/PGHzV83LUBbxA6GsBcXG7nrY8dW6TMqKorj2dlw/vmwaZPhyWs0dUijFfbKi5QOHDjg0l8H\nQ9j/BErDwjxKeTSFvbCwkG+++cZl271791JSUlIlYjdXoPqasKenp6OUqvCeT5kyhZtvvpkXX3yR\n9957r1b9p5XdUSUlJTl8PCkpiUsuuYRZs2bZ6p0/8cQTjBw5kqZNm/J+2ZL+ynjisVfw14uKYMsW\nW62huLg49u3bx4kTJ8rbmT77hAkQHl6lT7Mme2nbtoYFWEfrKDQak0Yr7JXLCuzfv99txB4REYEA\nOQkJ1RJ2gE8//dRlW0cZMSa+KOx79+6lTZs2hISEVDg+a9YsRo4cyZQpU/jll19q3L87YQd46KGH\nyMrK4sknn2TEiBE89dRTXHvttaxfv54+ZUJcGU8i9goWztatRjRuF7Fv3boVKA8uGDIEbrgB7rvP\nYZ+mrXPCbO9jE+maU49GK+z2EXteXh7Z2dkeRewAme3aGVaMm1tic3OEIUOG8O2337osv2tf1bEy\nvirspg1jT3BwMJ9++int27dn3LhxNX7dW7ZsoUmTJi7/poMHD+bss89m2rRpbNy4kblz5/Luu+8S\nGRnp9DlmhUdXHnuFiN3MoCoT9tjYWNvnwtYuLAzefhsc/O3BbrMN07fXwq6pYxqtsNuX7vUkhx3K\nhf1I69aQnQ1lPrEzzIj9hhtuoKCggO+++85p2x07dhAREeEwKychIcHnctmdCTsYUfFXX31FUVER\nF198cY1ed1paGklJSY4rddoxffp0rrzySjZs2MCVV17pUd+uVp9WiNj37YPPP4eQEChbnFR5uzxP\nMIU9w7zgaGHX1DGNVtjNL1VGRobrDTbsiCjbAeeg+cV1M4FqCvuFF15IixYtXNoxjlIdTXwtM8Zq\ntbJv3z6nwg6QmJjIp59+SlpaGhMnTqx22QFT2N3Rv39/5s6dS+fOnV03PHkSyjKonAl7YWEhTbKz\nuXDHDhg6FNq3h4ULYeJEKMvKsRd2RzXbHWEKe2ZJCTRrZmTPaDR1SKMV9uDgYJo1a1ajiH1fVJSx\nkMSNz24Ke3R0NOPHj+ebb77h5MmTDtvaV3WsjK8J+5EjRygsLHQp7ACjR4/m5Zdf5ssvv3Q6memI\nzMxMDh06RA83G0V7jNVqWCl33w04LwSW9+GHpAPnfvedUWP9mWdg+3bDZinDPkqvrrAfP37cyHnX\nEbumjmm0wg7lZQU8WXUK5RH78eJi6NLFrbBnZ2cTEhJCaGgol112GSdPnuT777+v0q6kpIRdu3Y5\nnDgFo6wA+I6wm6mOjhYAVebWW2+lb9++PP/88x5H7WYdGE8ido9ITYU//4S33oJjxxyX7hUhfPp0\ntgNLXn0VNmyARx6p4pubYl4l190FFYS9Qwct7Jo6p9ELuxmxN2/e3CbczggICCA8PNzYBLtvX+PL\n64KcnByaNm0KwJlnnklsbKxDO2bfvn0UFxc7Ffa4uDjCw8N9TtjdRexgpHs+9NBDbNu2jUWLFnnU\nv9eFffFi42dBAbz1lmMrZuVKIrZuZQZg6dvXaVemsMfExFTZE9UZWtg19Y3XhF0pFaiU2qCU+tpb\nfbrDLCvgSaqjSUREhGGnDB8Ou3cblfmcYC/sQUFBjBs3jq+//pr8Spt1uMqIgYbLZV+0aBGjRo3y\nelnd6gg7wKWXXkrnzp157rnnnFZVtCctLY3w8HCP7gg8YskSw4oZORJef53YqKiqFR5nzqTQYuFD\nXFss5mOeTpwCREZGEhAQUC7sOTm60qOmTvFmxH4n4LyWah1gWjGeLE4ysVgsRsQ+frxxYMECp23t\nhR3gsssuIy8vjyVLllRot63s4uAsYoeGSXn86quvWLZsGYcPH/Zqv3v37iUyMtJjKyIoKIj77ruP\nX3/9lR9//NFt+7S0NHr06OFxROySEyfg55/h3HPhjjtg714G/vUXxcXF5emr6emwcCGrevakNCSE\ndu3aOe3OFHRP/XUw7hSbNWtWLuzmOTWaOsIrwq6UagtcCLzljf48xbRiqhOx24Q9Pt7IfHCR6ZKd\nnU2zZs1sv5999tlER0fz6aefUlpayvfff8/48eO56667aNOmDa1bt3baV0MI+/bt2wHvV5ZMT0+n\nffv2blMR7bnuuuto2bIlzz33nOMGK1fCF18A5cLuFX780Vg9et558Le/QUICp69dC9gtUnrtNVCK\nafn5DB48mHAHq0dNwsPDsVgs1YrYoaysgBZ2TT3hrYj9ZeABoO630rEjNjaW4uJiDh065HHEbrNi\nAC67zJhALVs1WpnKEXtwcDBjx45l4cKFdO7cmQsuuICff/6Ze+65h5UrV7qMMBMSEsjMzKywmrWu\nMe8k9rrJ168ue/furbZNEhYWxl133cXixYvZUHluY+dOuOACGDeOwqeeYt++fd7z15csMZb5n3EG\nBAbCrbfSets2elMm7CdOwJw5FP3tb3y/eTMjR4502+WYMWM4++yzqzUMLeya+qTWwq6U+htwRETW\nu2l3k1IqRSmVUnkT6ppifztcbSsG4NJLjZ9O7JjKwg5w7bXXUlBQQNeuXZk/fz779+/nhRdesGW+\nOKO+67IfP37cVlvc2+d0tTjJFVOnTqVp06Y8//zz5QeLiuCKK4w88bFjCX3iCZ4CkrwVsS9eDGed\nZawOBZg0idKwMG6nTNg/+ACOH2ft4MFYrVZGjBjhtstPPvmE2267rVrDsAl7XJxxofGRiXTNqYk3\nIvZhwMVKqT3APGCkUuqjyo1EZLaIDBCRAdXxJ11hfztcbSsGoF07YwszJ3aMI2E/88wzyc/P54cf\nfuDyyy8nNDTUo/PWdy67acOAd4X95MmTZGRk1EjYmzVrxtSpU/n0009tE8488oixScU778CCBWw/\n80weA8764ovaV0Hcu9eo9XLuueXHmjcn+6KLuArI270bZs2C5GQWHDxIeHg4gwYNqt05nWATdqWM\nhU86YtfUIbUWdhF5WETaikgCMAFYJiITaz0yD6h1xA6GHbNhg5HnXImcnJwKHrtJ5cJXnmAK+0ZP\nNtIuLq52/5UxbRiLxeJVYTc32KiJsAPceeedBAcHM23aNPjuO5g+HaZOhXHjIDCQtwcNYlZAAM0/\n+AAmT4ba1HY3J7nPO6/CYeuttxIO9H/pJUP477yT5StWMGzYMI8v1NXFJuygUx41dU6jz2M3qXa6\no4kTO6agoICioqIqEXtNiYuLY9SoUTz99NP8+uuvzhvedx+0aeM2x94d27ZtIzAwkDPOOMOrwm72\nVVNhb926Nddeey3fv/su1muugdNOM8S9jLQtW3grKQkef9xY8Tl1as0j9yVLjEnySrZOk8GDWQq0\n27IFWrXi6IgRpKameuSv15QKwq5Xn/LBBx/w119/NfQwfBavCruIrBCRv3mzT1eYVkxYWJjDzRgc\nUSVi79ABTj+9ih1jTnJ6S9iVUsybN4/WrVszduxYDh48WLXR118bIpedbWyxtmkTBQUFTJo0ib59\n+3LppZfy4IMPMnv2bJYvX06xi8h+27ZtdOzYka5du3pV2Kuz6tQZt996K3OKiijNzja2irPLQklL\nS6NHUhL8+9+GTTNnTs12HSothaVLjWi9UvZOaGgos83IfOpUVqxeDeCRv15TzJrsJSUlxmfu6FGj\nfo0fcvDgQa699toqm6RovEejjtgjIyMJDQ2lbdu2HqfeVRF2MOwYc5f5Mrwt7GBciL788ktycnIY\nO3ZsxYVOf/0F119vrIj9/XcIDcU6ciQ3n30277zzDrGxsaSlpfHyyy8zZcoURo4cyQsvvOD0XNu3\nb6d79+506NCBnJyc8mjx55/Bwz1cHbF3714CAgJo06ZNzTooLqbXq68yGvh3TAxiF03n5+eze/fu\n8oyYp56CSy4xarz88EP1zpOSAllZFf11O9bExfHa2WfD/fezbNkymjRpwgBzw4w6wFa6Nzu7PDPG\ny9lKjQVz0/PU1NQGHonv0qiFXSlFXFycx/46GFZMfn5+xdWYph3z2We2Q6awO/LYa0RaGgwezGnz\n5jH3vfdYt24dN910k7H60WqFa64xUu8+/hiSksj67DOysrJ4Zu1aFk6bxtKlS9myZQsnT54kPT2d\nxMREVq5c6fBUVquVHTt20K1bN1tknZ6eblgTo0YZqYVOUjzdYW6wERwcXP0nZ2Ya28PNmcPvY8bw\n9KFDrC6LlsG4yxCRcmEPCIAPP4SkJLj8cqMgl6csXmxE6uec4/DhmNhYljRtCuHhLF++nOHDh7vc\nL7e2VCkrAH5rx2zevBkoF/j6YPv27Tz77LPesX927YLZs6GwsPZ91RGNWtjBKKk7ZswYj9ubFR4r\nRMsdOxrbm9nZMeZmCl6J2L/7zthlZ/Nm+M9/uOTFF3n17rv56KOPjEnE6dMN22DmTEhM5MCBA5wx\naRKjlSKuSRPGzpplE4HAwEDat2/PsGHDWLduncMl+vv27SM/P98WsQPk/PCDsdq2e3cIDTU2Xa7B\nxGRNUx2bdfmhAAAgAElEQVTZtg0GDTIWIr3/Pl3mzycyMpI5c+bYmjjcNalJE/jySyMd8uKLPV+K\nv2SJ8Tct27y6Mma9mIMHD7Jt27Y69dfh1BH2zMxMZsyY4dLGq2tMYd+9e7d39ij46y8jbdYFM2fO\n5JFHHqFjx47cdttttiSAGp1r5EiYMgX69YNa7BJWp4hIvf9LTk6WhuLVV18VQA4fPlzxgeeeEwGR\n3btFROSLL74QQNavX1/zk1mtIi+9JBIQINKvn8i+fSKffCISFSXWyEiZdfrpkgxSBLI0KkouHT9e\n7r33XklISJDIyEhZvny5yG+/iURFiYwaVaHrN954QwD5888/q5x28eLFAsjy5cvl0KFDkghy0mIR\n6dRJ5OBBkblzjdf63HPVfkmdO3eWCRMmVO9JS5aINGsmEhcn8ssvtsOTJ0+W8PBwOX78uIiIPPro\noxIYGCiFhYVV+1ixQiQoSOT880VKSlyf7/hxkcBAkccec9rk73//uyQlJclHH31U+7+zB/z4448C\nyNKlS43xBwWJPPxwnZ7TEVOmTBFAPv7443o/t8ngwYMlKChIAFm9enXtOsvIELFYRJKTRfbuddps\n+PDh0qtXL7nxxhslKChIgoODZfLkybJ///7yRoWFIldeKfLqq8Z3V0R27twpCQkJsnXrVpGcHJG+\nfY3zvfKKSIcOxvdo6lSR7OzavQ4PAVLEA431O2F/9913BZBdu3ZVfODPP42348UXRUTkgw8+EEB2\n7NhRsxMVForceKPR5/jxInl55Y+lp4sMHy4CUhgSIscsFrl0xAhJTEyUsLAwad26taxbt668/cMP\nG0JVJoAiIr/99psAMm/evCqnfuWVVwSQgwcPijU9XfaB5EREiOzcaTSwWkX+/neRkBCRP/7w+CWV\nlpZKSEiIPPjgg56/D8uXG2M/7TSRPXsqPPTrr78KIP/9739FRGTcuHHSvXt353298Ybxfj77rOtz\nfvaZ0e6nn5w2uemmm6Rly5Zyww03SPPmzaXE3cWilmzcuFEAWbBggXEgIcEQkZqyfr3x3laD7du3\nS2BgoABy1lln1fzctcBqtUrTpk1lzJgxAsjs2bNr1+Fbbxl/6/BwI3Bw8J5YrVaJioqSKVOmiIhI\nenq63HLLLRISEiIjR44sb/j880ZfIHL55SI5OfL6668LIDNeeEHk3HONz/J33xntc3NF7rpLRCmR\n+HiRpUtr91o8QAu7E+bPny+AbNq0qeqDyckivXuLWK22yP7IkSM1O9HVVxtv76OPipSWVn28pETk\nqaeMD+OKFbbDVqu1qsj8/LPR16ef2g4VFRVJWFiY3HPPPVW6vu222yQyMlKsR46IJCZKTkCA3Dd6\ndMVGR46ItGhhRCCOImQHHDx4UAB57bXXPGovGRnGB75bN4cRjdVqld69e0v//v1FRCQxMVHGjRvn\nus/x40VCQ0W2bXPeZsIEkSZNRIqKnDZ5+OGHJTg4WBISEmTs2LEevZzakJ6eLoC89dZbxoGzzhIZ\nNqz6Ha1eLTJmjPF5CAwUWbvW46defvnlYrFY5O677xZA0tLSqn/+WrJ3717bZ8hiscjtt99euw7P\nO0+kY0eRLVtEEhON92TmTFvELSKyb98+AeTVV1+t8NS7775bwsLCpKioyLibtlhE/vY34042IECk\ne3d5dOxYAWRZu3bGe/7OO1XHsGaN8Rlv0UIkP792r8cNWtid8PXXXwsgax19IcyIcNUqeeaZZwSQ\ngoKC6p+kqEgkIkJk8mT3be0+gE4pLjbsmOuvr3B4yJAhMnz48CrNR48eLZclJYl07iwSGir3JCfL\n6aefXrXfRYuM1+vCsrBnzZo1AshXX31lHCgtdT5+q1Vk3DiR4GAjunSCeXexZs0aCQwMlEcffdT1\nIA4eNN6L4cMdXzDfftt4TW5sjhdffFEAAWTWrFmuz+kFsrOzBZBp06YZB665RqRtW4+e+80338gd\nyclSePbZxmuLiRF5+mmRdu1EunateDfohJSUFAHk8ccfl8OHD0twcLDceeedtXlJsnv3bhkzZoxk\nZmZ6/JzvvvtOAPnxxx9l0KBBcvbZZ9d8AMeOGZbWAw8Yv2dni1xyifEeXX21SNl399tvv7Wd056P\nP/5YAPntt99E/vEPI2Awrc1ly0RatJATSsmCsije+q9/OR/L0qXGec0Ldx2hhd0Jy5cvN67Ay5ZV\nfTAnx4j0rr5aHnzwQQkJCanZSVatMt7azz6r3WDt+cc/RFq1qiCkd955p0REREhxcXGFppPj4uRk\nUJBIy5YiK1fKpEmTpGXLlo77ve46jyO/Tz75RADZuHGjceDaa41IZcOGqo3ffNN4D0whc0JmZqaE\nhYXJmWeeKYDMnTvX7TjknXeMvl9/veLxtWsNe+mcc4yLoQvefvttm7Cnpqa6P2ctKS0tlYCAAHnM\nvIg+8YQRFbq4qxARSfnmG/k0MFAE5ITFIvLCC4YFIGKID4jccovb859zzjkSGxsr2WV3ThMmTJCo\nqCg5efJkjV+TeVf7xRdfePycadOmCSAZGRly4403SkxMjFg9CW7EeA8nTpxYfvE3Pwf2tmVpqciT\nTxrH//53kZISef755wWocgHatWuXAPLl3Xcb7SsJ94kdO+TnMlF/E2S7q7tEq1WkTx+RpCTPgrUa\nooXdCWvXrhVAvv76a8cNpk4VCQ2V+66/XmJjY2t2kv/8x3hrjx6t+UAr8/77Rp+//WY7ZE782YS2\ntFSKHnlEBGR/mzbG7aWI/Pvf/xZA8h3dJh4/LtK+vRHd5+S4HIL5pczKyjKixLAwY0yhoUakYn6g\n09IMz3P0aMdRdSUmTpxoE9kNji4SlbFajb4jI435ChGRQ4cM2ychwbCA3LBw4UIBJC4uzmNhqS3N\nmzeX2267zfjFvLOoPNdjYrXKwWeekUylpBDk9VatpE+XLlXHes89Rj/ffuv0vD/88IPhE8+YYTu2\nYsUKAeS9996r8eu55ZZbBJB/uYpkK3H99dfbgoyZM2cKIH/99ZdHz33ppZcEkI4dOxoHLrjA+Hs7\n+vtNm2a8L1OmyMSrrpL4+PgqTaxWq7SKiZH9UVGGnVPpIvfzzz9LEMjHN94ogSDvvvuu6wF+8IFx\nTtODrwO0sDth06ZNAsj8+fMdN/jjDxGQj/r3l86dO9fsJOeeK9KrV80H6YjDh40/19NP2w5t3769\n3LfNzxcZO1YE5D2Q+e+/b2v3/vvvCyDbnEUcP/1kRI/XXutyCLfffrs0bdrU+GXhQmM8H39sRMhg\nPD8z04hcYmMN28QDzIwRpZTnEeTu3YYnesEFxhzB8OHGxcSTC4OI/PTTTwLI5Zdf7tn5vEDHjh1l\n4sSJxi/mrbujCdAdO6TgjDNEQFYFB0v64sXy3nvvCSAr7OZjRMT4u/fsadzNObigWa1WSU5Olvbt\n21ewFa1WqyQmJsrgwYNr/HrOOussAdzPi9gxcOBA24TlsmXLBJAlS5a4fd769eslODhYLBaLEVzs\n2mXYfPfd5/xJDz5oRNstWsj555/vsMmcxETj7/Dll1UemzFjhgBy4MABiY6OlkmTJrkeZGGhSJs2\nxvehjtDC7oTdu3cLIO84mgQxGTZMDkRESP++fat/gqIiQ3DMyMybDBwoMnSo7Vdztv+mm24SmT5d\nBGTDNdeU+4ZlmNGZyy/QE08YH4f//c9pk0suuUR6mRes6683UhiLioyJ4H/+08gOaNrU6Mf04T3A\narVKt27dqn8hnTnTONegQW7HXhnzovjmm29W75y1oF+/fnLhhRcav+zYYYy5csScni7WyEjJCQiQ\n20NCZF2ZRXbixAlp1qyZXOkok+b330WCg6Vk7Fg5npVVIao37TNHkfnLL7/s+V2SA+Li4ipG0G4o\nLS2tMGF65MgRAWT69Okun5ebmytdu3aV+Ph4+d///mdM/JaJtksL0WqV0uuvFwH5wj77xeTAASkI\nCZGvQHIc3K1eeeWVtkj/b3/7myQmJrp/kc8+a4zLvIv2MlrYnWB+mF555RXnjT78UATknt69q3+C\n1aulcgaL1/jnP43I2i4yGz16tAzq08eI2EaMkKeffloAyTV9WCm/mL3lamKnuNjI0mja1Kk90K9f\nPxkzZowh5HFxIldcUbHB4sWGr3/vvdV+aevWrTPy9qtDSYnIkCHG+12Dcy5ZssTIiKgnRowYIcPM\nTJiCAnHk65becYcUKyXdAwLku0q39LfeequEhoZKhoPIvPCpp0RAHgOJDguTTp06ybBhw6Rly5bS\nq1evqplWVqscX79epgQFyZquXasdiJjfoxYtWghg8+5dYX4O7S+mLVu2lOuuu87l866//npRSsmK\nFSvk8OHDAsifPXoYFqIbG23zxo3yWZlPLv/5j8isWSJ3323c3SYkSElwsHRyMufWtWtXW8bUc889\nJ4AcdWevZmYaiRNu7n5rihZ2J+Tl5Qkgzz//vPNG+fmSGRgov7RqVfWx7GyRBQuce8fmFbvyAihv\nsHZtlcj00UcflduUMo4vWyZXX311FT+xqKhIAgIC5PHHH3fd/549RhQ+eLDDSb2YmBi5+eabRVau\nNM7nIIfeE0/dq6Sni8yY4Xay9FRg3Lhx0rNnz/IDrVtXzHTKyJCS0FB5j6qpeSIiv//+exWv3OSu\n22+XL8sELC8sTD7v2VPGDRkip512mvzf//2fIYBpaSKzZxsZI2b6HkieKXzVWKRl2me33XabAPLz\nzz+7fY6ZkbZy5UrbsXPOOUeSk5MNK6RbN2Mxmx1mhP6YXeZWj9atpTggwJhfcMO8efMkFCRnwADb\n65XwcGOSc8wYySmbRH+u0mK9rKwsAeTpMuvz559/FkAWLVrk9pxy222GTXTggPu21UQLuxNKS0sF\nkCeeeMJluzebNZMSpUTsV6alphrpZa5u+887z/A864LSUiNSNn1aEVn06aeSDpJ92mkiVqucfvrp\nFRddlNG2bVu55ppr3J9j/nzj9VVKOzQviP/5z39E7r/f+ODaLZjSuOfWW2+ViIiI8rupwYNF7P9W\nZdkcgyIjHU90i8jpp58uSUlJFeyWlStXilJKbr3lFmO+5JJLDFssJETkqquM32NiyoWtRQtjAc7r\nr8vvH38sUSBFwcEiZQt4PMFcuLNq1Sr3d8BlmNkpWVlZtmN33323nBccLNbQUCM7KzRU5JtvRMTI\nWmnatKkMGTKkQubX9L59jdfhwarVxx57TAIDAyU/J8eYfzl8uEqU36VLFxk/fnyFY0uXLhVAFi9e\nLCIi+fn5EhISIvfff7/bc8rOncb7/8gj7ttWEy3sLoiIiJB73dy6D2je3Hh7nnzSOPDRR8YtVqtW\nRvaFg/xxKSoyMjU8SD+rMVdfbUxMlt1aZ734ogjIwilTxGq1SrNmzWTq1KlVnjZs2DDPVxvecIPx\nwVy1ynYoLS1NbOmI3bsbWSmaarFy5cqKltg//mFkI4mInDgh1thY+TYw0OUk3Zw5cwSQX8pKM5w8\neVK6desmHTp0qGC/yfbtxufQYjGCkRtuMNIDt2+vIGxWq1X69u0rc0ND5URgoEy56ip54IEHZNq0\nac4n28VuEZzVKjExMXLjjTe6ff3XXHONtGnTpsKxLx99VHJBCrp1M8bWv78RNHzxhVx99dUSGRkp\nu8vKfJhs6dZN0kFOeJC/f8kll7j1xu29dJNnn31WADl27Jjt2NChQ2Wo3RyXS8aPF2ne3KM1BtVB\nC7sLYmNjHYqfidVqleDgYNnWsaMh4rfcYrxVZ54p8tdf5UuPK+c/r1ljHP/kk7ob/McfG+dYs8a4\nkHTsKBuCg+XKK66w+Y+ObtWvvPJKSUhI8OwcubnG7P7pp9usle+//14ASTHrzHgQoWkqYrVapUeP\nHuWZKA88YETVpaXG+wkyDFzONeTm5kpkZKRcW+bh3n///QLIDz/84Oykbse1dOlSuadsruKB5s0l\nJCREADnHRXbHyJEjbYveRo0aJQMHDnR7nuTkZBltHxCkpkpx06ayE+Qb82KXlSUyaJBYg4LkiqAg\nuaVykHT8uJQEBclLGIva3NGpUye57LLLXLYxJ5Ht68Zceuml0qlTpwrt7r//fgkJCXF6N1UB066s\nvNailngq7I2+umNNcFiT3Y7CwkKKi4v5Y9gwOHAAXn/d2Nlo6VJo1cqomx4SAm++WfGJK1YYP886\nq+4Gf+65Rjnbb7+F//0Pdu/mu+Rk1qWk2LbD6969e5WndejQgf3791PqSUXHyEj4z3/g11+NMsKU\n75zUySy1evHF3nk9foRSihtvvJE1a9YYJWsTEoyqhPv3w/TppDVvTnrbtpx55plO+4iMjOSqq67i\nk08+YcmSJUyfPp3JkydzjpPyxJU3GXHEqFGjmP7LL9CrF8937kxBQQG33norq1evdloFMi0tzVaF\ns0+fPqSmphqbiDjBarWyZcsWevbsaRz4808YPZoAi4XRwLr9+43jUVGwZAl/tWvHhyUlPGyxGHsl\nHDwIJSXw1VcElpTwKfDbb7+5fF15eXns2rWL0047zWU7c5/bdevW2Y6tW7eOgQMHVmh3xhlnUFRU\nREpKisv+ABg61Nhb4d133betA7SwO8CsxX5k4EC47Tb4/HN48UUwa5DHxRmbc3zwAeTllT9xxQqj\ndniLFnU3+OhoowTwV18Z4tunD+rii9mxYwdr1qwBnAt7SUmJ452bHHH11ZCcDA89REFmJq+88gqt\nW7cm6scfjQ9sDbfG83euueYagoODeeutt8rL9774IuzZwyPZ2Vx11VUEBLj+Wk6ePJn8/Hwuuugi\n2rRpw4svvlj7gSlllKJNSUFt2MDw4cM5ceKEwz16MzMzOXTokE2k+/TpQ0FBATtc1Pjfs2cPJ0+e\nNJ5TXGzsbFVcTMDSpQR26VJh0w1p0oSxYWFsaNKEti++aJRfjo83gqlJk5D4eLY3b84GN9tHmuWB\n3Ql73759CQoKYu3atQAcOXKEvXv3VhH2oUOHAjjdB6ECShnfoXXrjJLV9YwWdgfYdk+Kjja2ZRs3\nrmqjqVMhJ8cW0VJSYtQar8to3WTMGGNP1O3b4bHHGHj66QD873//IyQkxOG2dRU23PCEgACYMQP2\n7+fHiy9m06ZNfPjSS6jVq41djTQ1IjY2lnHjxvHhhx9S2KqVcfD11znWqhVfWq1cddVVbvtITk6m\nf//+FBUVMXv2bO9tBjNxorFN4ezZDBs2DIBfHNQbr1w3v2/fvgD8/vvvTrs2RbZnz56waZMRsc+Y\nAUlJnHbaaRWEfc2aNazbsoWNL74Ia9bAwoXGXfPjj8O116JmzaJv//5uI3azT3fCHhYWRp8+fWx7\nEZsReeUdtWJjY0lMTHT4njjkiiuM79FHH3nW3ov4pbBX2dC6Eh5tsjF0KPTqBf/9r5Fr8NtvRvR+\n9tleHq0DzI1FkpJg/HjbB/D333+nS5cuBAYGVnmKKex7q7Md2/DhHD3rLM745RcenDiRUfn5xmvV\nNkytmDx5MpmZmXxpRsNWK69bLJzWu7dbETJ55ZVXeOONN7jgggu8N7CoKPjHP2DuXNpGRZGQkOAw\nOq0s7ImJiQQHBzuM7k1MYU9KSjKiWDC+QxjCu3PnTtvmN3PmzCEyMpJ/XHWVsTnL2LFGIPXkk8bO\nRePH079/f1JTU11uGJKamorFYqFjx45uX/qgQYNYt24dVquVdevWoZSif//+VdoNGzaMX375peIO\nbM5o3drYweujj4xd0uoRvxR2jyN2V8KulPFh27DB+KDWh79u0qcP3HADzJoFAQE0a9bMZr84smEA\n265H1dnYOicnh/E7dhAMPGW1GjsZtW1r7ByjqTEjR46kY8eO/PfDDyE6muJWrXjqzz+ZOHGix30M\nHTqUKVOmeH9wN91kBCgff8ywYcNYuXKlkWVhx+bNm4mIiLB9pkJCQujZs6dbYW/btq1xd7FunWEp\nduoEGMJutVpJS0sjOzubefPmceWVVxIZGem0v379+lFUVMSWLVuctklNTaVnz55urS2A008/ndzc\nXLZu3cq6devo0aMHTZo0qdLujDPOICsri61bt7rtEzDsmD17YNUqz9p7CS3sDvB4I+uJE8FiMaL2\nH3+ExERo2dKbQ3WMUvD228b+pWWcXmbHOBN2i8VCTExMtYT9rrvuYtWhQxy96iqC//c/Y8L24os9\nmpDTOCcgIIBJkyaxfPlyjtxxB/NHjaJEKa644oqGHhoMHmzcic6ezRlnnMGhQ4fYZbfJO5RPnNoL\nZp8+fVxaMZs2bSqfOF23zvDNyz5H5l3Kpk2bmDt3Lvn5+UyePNnlMM1o2pkdIyKkpqZ6fAdkfn/W\nrl1LSkqK043NTYvKI58djLuNiAhj7956xC+F3Z0V4/FG1k2bGuI+bx789FP92DBOMD+Y3bp1c9qm\nQ4cOHgv7okWLePfdd3nooYeIf/11Y8K4qEj7617i+uuvJyAggBkFBTy5di1nn302bdu2behhVZhE\nPSc6Gqjqs9tnxJj06dOHQ4cOceTIkSpdlpaWsnXrVnr16gUnTxoeu93EZJcuXQgLCyM1NZXZs2fT\nr18/kpOTXQ6za9euWCwWpxOohw8fJiMjwzinB3Tv3p2mTZvy+eefc/jw4SoTp/ZjbdGihec+e2Sk\nsdfwJ59AQYFnz/ECfins7iL2am1kffPNxh+svvx1J5x77rm0adOGM844w2kbT4X9+PHjTJ48mX79\n+vHPf/7TuIDNmmX4nfVhNfkBbdq04cILL2TmzJns3LmzWjZMnVM2idr5scd4PSSEgvffNzbeFuH4\n8eMcPXiQQfHxkJJi/BOxTaA6smN27dpFQUGBEbFv3Ghsom4nnIGBgSQlJTFv3jw2btzI5MmTUW7u\nCgMCAujTp49TYfd04tS+v4EDB/LNN98AOBV2pZTNovKYiRONTdi//dbz59QSLewO8NiKASP1b/Bg\n4/8NKHrdunXjwIEDdO3a1WkbU9gre6aV2bBhA0ePHuWZZ54hJCTEODhhgpGhEBrqzWH7NWbaYmho\nKJdeemlDD6ecqCh45x1Uq1ZcX1LCTcuWGTn3rVph6diRIuCWZ581xHngQHj+efr06QM4zoypkBFj\nTpxWsjp69erFgQMHiIiI4Morr/RomP3792fDhg0OJzKrK+xg3PWKCEFBQbbX44jBgweza9cusrKy\nPOt41Chj/Us92jF+KewREREUFBQ4XayTk5NDSEgIoZ6K2EsvwVNPGX+8U5gOHTpw8uRJjh075rKd\neWFrWR/zBX7MBRdcQIcOHbj00ku9l7LoLSZMgJ9+YuaTT5IMnHjuORgzhp19+vAEcPTpp2HRIiOL\n5uGHif7+e9q1a+cwYq+SEdO6tZGXbocpwBMmTPD4vejXrx95eXn8+eefVR5LTU2lRYsWtKjGmhJz\nodJpp51GWFiY03amDeVq4rYCQUFG6uM330BmpsfjqQ1+KewWiwXAll5VmZycnOp90YYMgcce88bQ\n6hRPc9k9nmPQ1IqgoCDWr1/PnDlzGnooThl61ln8BixLSoJ332VO//5MCw8n+qGHjIn099837lSv\nu46r4uOdCnuHDh2MLJd16yrYMCbDhw8nODiYW265xeOxmROojuyY6kycmpjzVM5sGJMePXoA1RB2\nMLJjiosNr70e8Gthd2bHZGdne2bDNDLM9DR3uezVmmPQ1IqYmBgiIiIaehhOGTBgAMHBwTZPOS0t\njcTExPK1EqGhxgKirl15YsMGVFoaBXaThJs2beLbb7+lX79+kJ1trMJ0IJyDBg0iOzvb7aSpPUlJ\nSQQHB1fJjCktLSUtLa3awt66dWumTZvG7bff7rJdQkICoaGh1RP2vn2hZ896s2O0sDsgJyfHJ0Wt\nuhG7L74HmuoRHh7OgAEDbMK+efPm8rRFk+bNjYnB8HC+slrZ8eOPgDFpeu6552KxWJgxY4ZR8wUc\nCrt5ruoQEhJCr169qkTs27ZtIz8/v9rCDnDvvfe6zaQJDAyke/fu1RN2pYxJ1FWroFL6aF1Qa2FX\nSrVTSi1XSqUppTYrpe70xsDqEjNCcpby6KvCbkaHngh7aGio53MMGp/mjDPOICUlhSNHjrB///4q\nqY4AdOjA0XffJQZoNXUqhw4e5Nxzz6WwsJAlS5aQkJDgdOK0NvQvKy1gJgR89dVXjBo1iuDgYIYP\nH+6181SmR48e1RL2oqIiZh07xg6lSFm4sM7GZeKNiL0EuFdEkoDBwK1KKQd/+VMHTyJ2X/SXlVIe\npTz6qhWlqRnDhg2jqKiID8tsBIfCDrS9+GLuCwkhbvdunixb3PTtt9+WR/gpKcZq05gYr42tX79+\nZGRkkJaWxnXXXcfFF19MixYt+PXXX11miNWWpKQk9uzZ43Sezp5ff/2VAQMGcOe0aTx+2WW0q4fU\n1loLu4j8JSK/lf0/F9gCxLt+VsPir1YMQHx8vNsKj778+jXVx6xqOHv2bICqVkwZAQEBpPXrx1/A\nxXv2sHDhQlumCVC+4tSLmBOoAwcO5KOPPuLRRx9l3bp1trz6uqJHjx6IiK1UtiNOnDjB3XffzeDB\ng8nMzGTRokXMmz+/XrLNvOqxK6USgH7AWm/2621MK8bfJk8BmjdvbpscdYav3rFoakZcXByJiYls\n376d0NBQl0W1+gwcyJvABSKMti/tfPSoscjJTcZJdenduzdNmjQhISGB1atX8/TTT5evvahD3GXG\niAhDhw7l5ZdfZurUqaSlpXFxPRbP85qwK6Uigc+Au0Qkx8HjNymlUpRSKUePHvXWaWuEGbE78thF\nxKcj1qioKI4fP+6yjS9f2DQ1w6yRUiEjxgH//Oc/ueS774za6a++Wv6A6a97WdgtFgvbtm1jw4YN\nbtMUvUnXrl2NO5SySpeV2b59O3/88QczZszgtddeq/fvk1eEXSkVjCHqc0Xkc0dtRGS2iAwQkQFx\ncXHeOG2NcWXFmLsn+WrE2qxZM7fC7ssXNk3NMEtVOPPXTWJjY+l3/vnGAqf33jNSHMEQdqXAQSnc\n2rh22AIAAA1tSURBVNK6det6n+gPDQ2lc+fOTiP2VWXVHM8777z6HJYNb2TFKOBtYIuIvFT7IdU9\nroTd11P9oqKiKCgooLCw0GkbbcVoKmMKu6dFtbjjDqN+krk13Lp10KMHOCiF21hxlRmzatUqoqKi\nnFZbrWu8EbEPA64GRiqlfi/7N8YL/dYZrtIdfX1xTlRUFIBLn11bMZrKdOnShc8//5ybb77Zsyck\nJ8OwYcYOZKWlTlecNmZ69OjBjh07HO71umrVKoYMGeJRLfi6wBtZMStFRIlIbxHpW/av/sqY1YDw\n8HCUUn4ZsZuRuDM7xtfnGDQ1Z9y4cUSXlfL1iDvvNBbjvPkmHDnik8JeXFxcpVbN8ePHSUtLs2UT\nNQR+ufJUKUVERIRLYfdVK8JdxF5QUEBJSYnPvn5NPTJ2rLHj1kMPGb97OdWxoXGWGWNuKq+FvQFw\nJ+y+GrGawu4sYvd1K0pTjwQHw623Qm6uUeHQRSncxkhiYiJQVdhXrVpFQECArahYQ+C3wm6xWPzS\nY3dnxfj6hU1Tz0yeDGFh0Lu38dOHaNq0KfHx8Q6FvXfv3i73bK1rghrszA2Ms802fF3Y3EXsvm5F\naeqZmBiYM8coFOaDJCUlVRD20tJS1q5dyzXXXNOAo/LziN2fhd2Zx+7rdyyaBmDiRLjwwoYeRZ3Q\no0cPtm7daitCtmnTJvLy8hrUXwc/FnZnG1r7emXDyMhIAgICtBWj0XiBHj16kJeXx/79+4HyhUlD\nhgxpyGH5r7A7i9h9PYdbKeVy9am2YjQaz6mcGbNq1Spatmzpsp5OfaCFvRL+kMMdFRWlrRiNxgtU\nFvbVq1czdOhQjAX5DYffCrurdEdfFzVXhcC0FaPReE5cXBzR0dGkpaVx+PBh/vzzzwb318GPhd1i\nsZCbm2ub9DDxhzop7qyY8PBwgoOD63lUGk3jQyllqxmzevVqoOH9dfBjYe/RowfZ2dns3r27wnF/\nidhdWTG+/vo1Gm9iCvuqVasIDg6u1obcdYXfCvvIkSMBWLZsWYXj/iBs7qwYX79j0Wi8SY8ePcjI\nyOCrr74iOTmZsFNgIZbfCntiYiKtWrVi+fLlFY77Q8TuyorxhwubRuNNzAnUrVu3nhL+OvixsCul\nGDFiBMuWLbP57GZlQ1+PWKOiosjNzaW0tLTKY/5wYdNovIkp7NCwhb/s8VthBxgxYgSHDh2ybUhr\n7p7k68Jmrj41M2Ds8YcLm0bjTdq3b2/b4+FUmDgFPxf2yj67v+RwuyoEpq0YjaZ6BAQEkJiYSIcO\nHWjTpk1DDwfwc2Hv1KkT7du3twm7v+Rwu6oXo60Yjab6PP3007z88ssNPQwbflvdEcp99q+//hqr\n1eo3y+mdVXj0lzkGjcbbXHDBBQ09hAr4dcQOhh1z7NgxUlNT/SZid2bFnDhxAqvV6vOvX6Pxdfxe\n2EeMGAEYPru/eOzOrBh/ubBpNL6O3wt7u3bt6NKlC8uXL/cbYXNmxfiLFaXR+Dp+L+xg2DE//vgj\nmZmZgO8Lm3nhqizs/nLHotH4OlrYMeyYnJwcVqxYAUCTJk0adkB1TFBQEJGRkdqK0Wh8FC3slPvs\nS5Ys8endk+xxVC9GWzEajW+ghR1o2bIlPXv2JD8/32+iVUfCrq0YjcY30MJehhm1+0u02qxZM23F\naDQ+ihb2MszyAv4iaq6sGH95DzQaX0ULexlnnXUWSim/ETVnVozFYiEwMLCBRqXRaLyBFvYyoqOj\nOfPMM+ncuXNDD6VecGbF+MuFTaPxZfy6Vkxlvv/+e4KC/OMtMSN2EbHtqK7rxGg0voFXInal1PlK\nqW1KqZ1KqYe80WdDEBYW5lfCXlpayokTJ2zHdMlejcY3qLWwK6UCgdeAC4Ak4AqlVFJt+9XULY4K\ngWkrRqPxDbwRsZ8O7BSRXSJSBMwDLvFCv5o6xFEhMG3FaDS+gTeEPR7YZ/f7/rJjmlMYR4XAtBWj\n0fgG9ZYVo5S6SSmVopRKOXr0aH2dVuMEbcVoNL6LN4T9ANDO7ve2ZccqICKzRWSAiAyIi4vzwmk1\ntaGyFWO1WsnNzdVWjEbjA3hD2NcBXZVSHZVSIcAE4Esv9KupQypbMXl5eYiIjtg1Gh+g1rl9IlKi\nlLoNWAwEAu+IyOZaj0xTp1S2YnQ5AY3Gd/BK0raIfAt8642+NPVDWFgYoaGhNitGl+zVaHwHXVLA\nj7GvF6NL9mo0voMWdj/GXti1FaPR+A5a2P0Y+0Jg2orRaHwHLex+jLZiNBrfRAu7H+PIitERu0bT\n+NHC7sfYWzHmz8jIyIYckkaj8QJa2P2YyhF7kyZNCAjQHwmNprGjv8V+TFRUFAUFBRQWFurKjhqN\nD6GF3Y8xhTw7O1tXdtRofAgt7H6Mfb0YXdlRo/EdtLD7MZWFXVsxGo1voIXdj9FWjEbjm2hh92O0\nFaPR+CZa2P0YbcVoNL6JFnY/xhTyzMxM8vLydMSu0fgIWtj9mMjISAICAti3z9iLXAu7RuMbaGH3\nY5RSREVFsXfvXkDXidFofAUt7H6OvbDriF2j8Q20sPs5zZo108Ku0fgYWtj9nKioKLKysgBtxWg0\nvoIWdj/HTHkEHbFrNL6CFnY/xz5K18Ku0fgGWtj9HPuIXVsxGo1voIXdzzGFXSmFxWJp4NFoNBpv\noIXdzzGj9KZNm6KUauDRaDQab6CF3c8xI3Ztw2g0voMWdj/HFHY9carR+A5a2P0ceytGo9H4BlrY\n/RxtxWg0vocWdj9HWzEaje9RK2FXSr2olNqqlPpDKbVQKRXl/lmaUwltxWg0vkdtI/YfgF4i0hvY\nDjxc+yFp6hMt7BqN7xFUmyeLyBK7X9cAf6/dcDT1TWBgINOnT+ecc85p6KFoNBovoUTEOx0p9RUw\nX0Q+cvL4TcBNAO3bt09OT0/3ynk1Go3GX1BKrReRAe7auY3YlVJLgVYOHnpURBaVtXkUKAHmOutH\nRGYDswEGDBjgnauJRqPRaKrgVthFxOU9ulLqOuBvwCjxVviv0Wg0mhpTK49dKXU+8ABwloic9M6Q\nNBqNRlMbapsV8yrQBPhBKfW7UuoNL4xJo9FoNLWgtlkxXbw1EI1Go9F4B73yVKPRaHwMLewajUbj\nY2hh12g0Gh/DawuUqnVSpY4CNV2hFAtkeHE49U1jHn9jHjs07vE35rGDHr+36CAice4aNYiw1wal\nVIonK69OVRrz+Bvz2KFxj78xjx30+OsbbcVoNBqNj6GFXaPRaHyMxijssxt6ALWkMY+/MY8dGvf4\nG/PYQY+/Xml0HrtGo9FoXNMYI3aNRqPRuKBRCbtS6nyl1Dal1E6l1EMNPR53KKXeUUodUUptsjsW\nrZT6QSm1o+xn84YcozOUUu2UUsuVUmlKqc1KqTvLjp/y41dKhSmlflVKbSwb+5NlxzsqpdaWfX7m\nK6VCGnqsrlBKBSqlNiilvi77vVGMXym1RymVWlY/KqXs2Cn/uTFRSkUppRaUbfu5RSk1pDGNHxqR\nsCulAoHXgAuAJOAKpVRSw47KLe8B51c69hDwfyLSFfi/st9PRUqAe0UkCRgM3Fr2fjeG8RcCI0Wk\nD9AXOF8pNRh4HphRVuMoC5jUgGP0hDuBLXa/N6bxjxCRvnYpgo3hc2MyE/heRBKBPhh/g8Y0fhCR\nRvEPGAIstvv9YeDhhh6XB+NOADbZ/b4NaF32/9bAtoYeo4evYxEwurGNH4gAfgMGYSwwCXL0eTrV\n/gFtMQRkJPA1oBrL+IE9QGylY43icwM0A3ZTNv/Y2MZv/ms0ETsQD+yz+/3/2zt31yiiKA5/v0JF\nohAVCYEIURCtJElhYxBBsAhiZSFYpLC0sRXBP0G0slGsRMFXCFYStY4ajBIN+ADBDYlrEwQrHz+L\ne1cWIbCmmbnD+WCY+5jiGzh7ZvbM7N5WHiuNAdvLub0CDFQp0wuShoFRYJZC/HMZYx5okxZd/wis\n2v6ZD6l7/FwmrXXwO/d3UI6/gUeS5vKSmFBI3AC7ga/AjVwGuyapj3L8gYJKMU3E6fJf69eSJG0B\n7gHnbH/rnquzv+1ftkdId74Hgf0VK/WMpONA2/Zc1S7rZNz2GKlselbS4e7JOscN6a/Mx4CrtkeB\n7/xTdqm5P1BWYl8CdnX1h/JYaXyRNAiQ9+2KfdZE0gZSUr9p+34eLsYfwPYq8JRUuuiX1FmDoM7x\ncwg4IekTcJtUjrlCIf62l/K+DTwgXVhLiZsW0LI9m/t3SYm+FH+grMT+HNib3wzYCJwCpit2Wg/T\nwGRuT5Jq17VDkoDrwKLtS11TtfeXtFNSf25vJj0bWCQl+JP5sFq6A9g+b3vI9jApzp/YPk0B/pL6\nJG3ttIFjwAIFxA2A7RXgs6R9eego8JZC/P9SdZH/Px9sTADvSPXSC1X79OB7C1gGfpDuBM6QaqWP\ngffADLC9as813MdJXzdfA/N5myjBHzgAvMzuC8DFPL4HeAZ8AO4Am6p27eFcjgAPS/HPjq/y9qbz\nOS0hbrrOYQR4keNnCthWkr/t+OVpEARB0yipFBMEQRD0QCT2IAiChhGJPQiCoGFEYg+CIGgYkdiD\nIAgaRiT2IAiChhGJPQiCoGFEYg+CIGgYfwCsl/PTwdRLbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc1f8fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE0EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcbf6cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.40797859961 \n",
      "Fixed scheme MAE:  1.48625614631\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.4982  Test loss = 1.5248  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.4960  Test loss = 1.1731  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.4089  Test loss = 0.1648  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.4082  Test loss = 0.4095  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.3385  Test loss = 0.3221  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.2870  Test loss = 0.7747  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.2318  Test loss = 0.0526  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.2108  Test loss = 0.2290  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.1706  Test loss = 0.6680  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.1604  Test loss = 0.3410  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.1303  Test loss = 1.0142  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.1355  Test loss = 1.9823  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.1322  Test loss = 0.6180  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.1336  Test loss = 1.1137  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.1418  Test loss = 2.2477  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.1716  Test loss = 2.8828  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.1927  Test loss = 0.6948  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.1919  Test loss = 0.5180  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.1877  Test loss = 0.8276  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.0559  Test loss = 0.6947  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.0375  Test loss = 1.9826  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.0657  Test loss = 3.7420  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.1505  Test loss = 0.3321  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.1413  Test loss = 1.5934  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.1162  Test loss = 0.9628  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.1201  Test loss = 0.0761  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.1186  Test loss = 0.4302  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.1136  Test loss = 1.6843  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.1138  Test loss = 0.4270  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.1073  Test loss = 0.1829  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.0999  Test loss = 3.6876  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.1711  Test loss = 0.3987  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.1364  Test loss = 1.5697  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.1529  Test loss = 0.0226  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.1033  Test loss = 0.0783  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.0965  Test loss = 5.3177  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.2242  Test loss = 1.0369  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2114  Test loss = 2.1238  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.2257  Test loss = 0.9731  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2317  Test loss = 2.1181  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.2126  Test loss = 1.1360  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.2206  Test loss = 2.0379  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.2461  Test loss = 2.9612  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.2981  Test loss = 12.7785  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0765  Test loss = 6.9171  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.2441  Test loss = 1.0597  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.2475  Test loss = 0.1023  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.2466  Test loss = 0.6703  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.0400  Test loss = 1.7069  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.0465  Test loss = 2.3280  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.0668  Test loss = 1.7422  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.0759  Test loss = 1.4387  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.0302  Test loss = 3.1891  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.0676  Test loss = 2.8750  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.0965  Test loss = 0.0124  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.0919  Test loss = 0.8384  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.0228  Test loss = 0.4295  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.0231  Test loss = 1.6465  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.0307  Test loss = 0.6817  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.0306  Test loss = 0.4935  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.9730  Test loss = 0.3636  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.9734  Test loss = 2.8683  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.0011  Test loss = 0.5761  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.9935  Test loss = 0.4617  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.9439  Test loss = 0.5794  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.9444  Test loss = 0.1226  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.9387  Test loss = 0.8470  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.9388  Test loss = 2.8780  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.9292  Test loss = 4.5876  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.0097  Test loss = 0.7927  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.0121  Test loss = 1.0558  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.0100  Test loss = 2.5776  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.9854  Test loss = 2.3522  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.0046  Test loss = 1.3926  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.0108  Test loss = 0.9662  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.0142  Test loss = 0.7588  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.9569  Test loss = 1.6366  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsCdJkvQZWdiTJEn6jH8AbO/k0GI0DLkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd8a8eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.36264198175 \n",
      "Updating scheme MAE:  1.51760296421\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
