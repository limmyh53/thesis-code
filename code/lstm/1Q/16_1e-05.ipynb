{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/16_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-5\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 16 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 16 \n",
      "Learning rate = 1e-05 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-05\n",
      "Fold: 1  Epoch: 1  Training loss = 3.2681  Validation loss = 3.5148  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.2671  Validation loss = 3.5127  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.2654  Validation loss = 3.5093  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.2641  Validation loss = 3.5065  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.2632  Validation loss = 3.5045  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.2621  Validation loss = 3.5022  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.2609  Validation loss = 3.4997  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.2601  Validation loss = 3.4978  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.2589  Validation loss = 3.4954  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.2577  Validation loss = 3.4929  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.2564  Validation loss = 3.4900  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.2554  Validation loss = 3.4880  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.2538  Validation loss = 3.4845  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.2529  Validation loss = 3.4826  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.2513  Validation loss = 3.4790  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.2505  Validation loss = 3.4773  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.2495  Validation loss = 3.4751  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.2483  Validation loss = 3.4726  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.2471  Validation loss = 3.4698  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.2459  Validation loss = 3.4672  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.2450  Validation loss = 3.4652  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.2439  Validation loss = 3.4631  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.2431  Validation loss = 3.4614  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.2421  Validation loss = 3.4591  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.2411  Validation loss = 3.4570  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.2401  Validation loss = 3.4549  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.2386  Validation loss = 3.4516  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.2377  Validation loss = 3.4496  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.2369  Validation loss = 3.4477  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.2359  Validation loss = 3.4455  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.2348  Validation loss = 3.4432  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.2338  Validation loss = 3.4410  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.2328  Validation loss = 3.4388  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.2315  Validation loss = 3.4359  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.2302  Validation loss = 3.4328  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.2288  Validation loss = 3.4299  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.2278  Validation loss = 3.4277  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.2267  Validation loss = 3.4252  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.2258  Validation loss = 3.4232  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.2248  Validation loss = 3.4209  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.2236  Validation loss = 3.4185  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.2228  Validation loss = 3.4166  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.2216  Validation loss = 3.4137  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.2206  Validation loss = 3.4116  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.2194  Validation loss = 3.4089  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.2184  Validation loss = 3.4067  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.2175  Validation loss = 3.4047  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.2165  Validation loss = 3.4023  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.2152  Validation loss = 3.3996  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.2145  Validation loss = 3.3979  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.2136  Validation loss = 3.3960  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.2129  Validation loss = 3.3944  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.2117  Validation loss = 3.3916  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.2108  Validation loss = 3.3895  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.2097  Validation loss = 3.3873  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.2087  Validation loss = 3.3850  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.2080  Validation loss = 3.3834  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.2072  Validation loss = 3.3814  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.2060  Validation loss = 3.3787  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.2051  Validation loss = 3.3769  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.2040  Validation loss = 3.3744  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.2033  Validation loss = 3.3728  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.2023  Validation loss = 3.3707  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.2013  Validation loss = 3.3684  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.2005  Validation loss = 3.3666  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.1994  Validation loss = 3.3641  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.1985  Validation loss = 3.3619  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.1976  Validation loss = 3.3600  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.1967  Validation loss = 3.3580  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.1960  Validation loss = 3.3564  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.1950  Validation loss = 3.3540  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.1941  Validation loss = 3.3520  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.1930  Validation loss = 3.3498  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.1924  Validation loss = 3.3484  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.1915  Validation loss = 3.3463  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.1906  Validation loss = 3.3441  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.1900  Validation loss = 3.3428  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.1891  Validation loss = 3.3409  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.1881  Validation loss = 3.3385  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.1874  Validation loss = 3.3371  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.1864  Validation loss = 3.3346  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.1855  Validation loss = 3.3325  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.1846  Validation loss = 3.3306  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.1834  Validation loss = 3.3279  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.1823  Validation loss = 3.3254  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.1814  Validation loss = 3.3233  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.1804  Validation loss = 3.3211  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.1795  Validation loss = 3.3190  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.1787  Validation loss = 3.3173  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.1777  Validation loss = 3.3149  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.1768  Validation loss = 3.3129  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.1756  Validation loss = 3.3102  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.1744  Validation loss = 3.3073  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.1738  Validation loss = 3.3059  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.1730  Validation loss = 3.3041  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.1721  Validation loss = 3.3021  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.1712  Validation loss = 3.3000  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.1703  Validation loss = 3.2980  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.1696  Validation loss = 3.2965  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.1689  Validation loss = 3.2949  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.1680  Validation loss = 3.2928  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.1672  Validation loss = 3.2911  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.1661  Validation loss = 3.2886  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.1653  Validation loss = 3.2865  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.1646  Validation loss = 3.2850  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.1638  Validation loss = 3.2831  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.1631  Validation loss = 3.2815  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.1620  Validation loss = 3.2790  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.1614  Validation loss = 3.2775  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.1607  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.1596  Validation loss = 3.2732  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.1587  Validation loss = 3.2712  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.1577  Validation loss = 3.2687  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.1567  Validation loss = 3.2666  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.1557  Validation loss = 3.2642  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.1549  Validation loss = 3.2622  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.1542  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.1536  Validation loss = 3.2593  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.1526  Validation loss = 3.2571  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.1517  Validation loss = 3.2548  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.1508  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.1503  Validation loss = 3.2517  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.1491  Validation loss = 3.2488  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.1483  Validation loss = 3.2470  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.1477  Validation loss = 3.2457  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.1468  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.1461  Validation loss = 3.2419  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.1451  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.1443  Validation loss = 3.2377  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.1434  Validation loss = 3.2357  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.1427  Validation loss = 3.2341  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.1418  Validation loss = 3.2319  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.1411  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.1399  Validation loss = 3.2276  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.1392  Validation loss = 3.2260  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.1385  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.1379  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.1372  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.1365  Validation loss = 3.2197  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.1359  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.1351  Validation loss = 3.2164  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.1341  Validation loss = 3.2139  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.1333  Validation loss = 3.2121  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.1322  Validation loss = 3.2093  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.1312  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.1306  Validation loss = 3.2056  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.1301  Validation loss = 3.2045  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.1294  Validation loss = 3.2028  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.1283  Validation loss = 3.2002  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.1274  Validation loss = 3.1981  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.1268  Validation loss = 3.1967  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.1264  Validation loss = 3.1956  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.1255  Validation loss = 3.1936  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.1247  Validation loss = 3.1915  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.1238  Validation loss = 3.1895  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.1229  Validation loss = 3.1874  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.1217  Validation loss = 3.1845  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.1209  Validation loss = 3.1824  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.1202  Validation loss = 3.1810  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.1192  Validation loss = 3.1785  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.1186  Validation loss = 3.1771  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.1179  Validation loss = 3.1753  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.1173  Validation loss = 3.1739  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.1165  Validation loss = 3.1722  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.1161  Validation loss = 3.1712  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.1154  Validation loss = 3.1696  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.1147  Validation loss = 3.1679  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.1139  Validation loss = 3.1662  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.1128  Validation loss = 3.1635  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.1115  Validation loss = 3.1603  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.1108  Validation loss = 3.1587  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.1101  Validation loss = 3.1570  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.1093  Validation loss = 3.1553  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.1087  Validation loss = 3.1537  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.1080  Validation loss = 3.1522  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.1074  Validation loss = 3.1508  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.1067  Validation loss = 3.1490  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.1058  Validation loss = 3.1470  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.1050  Validation loss = 3.1452  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.1038  Validation loss = 3.1421  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.1030  Validation loss = 3.1402  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.1024  Validation loss = 3.1388  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.1016  Validation loss = 3.1369  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.1012  Validation loss = 3.1360  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.1009  Validation loss = 3.1351  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.1003  Validation loss = 3.1337  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.0995  Validation loss = 3.1319  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.0988  Validation loss = 3.1302  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.0983  Validation loss = 3.1291  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.0975  Validation loss = 3.1272  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.0965  Validation loss = 3.1248  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.0960  Validation loss = 3.1235  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.0953  Validation loss = 3.1219  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.0944  Validation loss = 3.1197  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.0940  Validation loss = 3.1186  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.0934  Validation loss = 3.1172  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.0928  Validation loss = 3.1159  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.0921  Validation loss = 3.1143  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.0915  Validation loss = 3.1127  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.0910  Validation loss = 3.1115  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.0903  Validation loss = 3.1100  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.0896  Validation loss = 3.1084  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.0887  Validation loss = 3.1060  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.0880  Validation loss = 3.1044  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.0872  Validation loss = 3.1026  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.0863  Validation loss = 3.1003  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.0858  Validation loss = 3.0990  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.0850  Validation loss = 3.0973  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.0843  Validation loss = 3.0955  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.0835  Validation loss = 3.0936  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.0825  Validation loss = 3.0910  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.0816  Validation loss = 3.0888  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.0813  Validation loss = 3.0881  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.0805  Validation loss = 3.0861  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.0800  Validation loss = 3.0850  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.0793  Validation loss = 3.0833  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.0787  Validation loss = 3.0819  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.0782  Validation loss = 3.0807  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.0778  Validation loss = 3.0797  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.0772  Validation loss = 3.0784  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.0767  Validation loss = 3.0769  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.0760  Validation loss = 3.0753  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.0751  Validation loss = 3.0733  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.0744  Validation loss = 3.0715  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.0737  Validation loss = 3.0699  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.0730  Validation loss = 3.0681  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.0725  Validation loss = 3.0669  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.0717  Validation loss = 3.0652  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.0708  Validation loss = 3.0630  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.0700  Validation loss = 3.0608  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.0692  Validation loss = 3.0591  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.0684  Validation loss = 3.0571  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.0678  Validation loss = 3.0557  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.0674  Validation loss = 3.0546  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.0666  Validation loss = 3.0527  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.0660  Validation loss = 3.0511  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.0652  Validation loss = 3.0493  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.0646  Validation loss = 3.0478  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.0642  Validation loss = 3.0468  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.0633  Validation loss = 3.0447  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.0628  Validation loss = 3.0435  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.0621  Validation loss = 3.0419  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.0616  Validation loss = 3.0407  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.0607  Validation loss = 3.0385  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.0601  Validation loss = 3.0369  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.0594  Validation loss = 3.0352  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.0585  Validation loss = 3.0331  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.0579  Validation loss = 3.0317  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.0571  Validation loss = 3.0296  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.0567  Validation loss = 3.0287  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.0561  Validation loss = 3.0273  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.0556  Validation loss = 3.0261  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.0547  Validation loss = 3.0240  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.0539  Validation loss = 3.0221  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.0533  Validation loss = 3.0206  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.0526  Validation loss = 3.0188  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.0520  Validation loss = 3.0176  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.0515  Validation loss = 3.0163  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.0507  Validation loss = 3.0145  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.0502  Validation loss = 3.0132  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.0496  Validation loss = 3.0117  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.0491  Validation loss = 3.0105  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.0486  Validation loss = 3.0094  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.0480  Validation loss = 3.0080  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.0474  Validation loss = 3.0064  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.0465  Validation loss = 3.0042  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.0460  Validation loss = 3.0029  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.0451  Validation loss = 3.0008  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.0442  Validation loss = 2.9985  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.0435  Validation loss = 2.9970  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.0426  Validation loss = 2.9948  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.0418  Validation loss = 2.9928  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.0413  Validation loss = 2.9915  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.0408  Validation loss = 2.9903  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.0405  Validation loss = 2.9896  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.0400  Validation loss = 2.9884  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.0395  Validation loss = 2.9871  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.0388  Validation loss = 2.9855  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.0381  Validation loss = 2.9836  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.0376  Validation loss = 2.9826  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.0371  Validation loss = 2.9812  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.0364  Validation loss = 2.9795  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.0358  Validation loss = 2.9781  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.0351  Validation loss = 2.9764  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.0342  Validation loss = 2.9742  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.0335  Validation loss = 2.9724  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.0329  Validation loss = 2.9711  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.0325  Validation loss = 2.9700  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.0316  Validation loss = 2.9679  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.0309  Validation loss = 2.9661  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.0302  Validation loss = 2.9645  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.0297  Validation loss = 2.9632  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.0292  Validation loss = 2.9620  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.0288  Validation loss = 2.9612  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.0280  Validation loss = 2.9590  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.0272  Validation loss = 2.9573  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.0268  Validation loss = 2.9561  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.0260  Validation loss = 2.9544  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.0253  Validation loss = 2.9528  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.0248  Validation loss = 2.9514  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.0244  Validation loss = 2.9504  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.0236  Validation loss = 2.9484  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.0231  Validation loss = 2.9474  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.0224  Validation loss = 2.9457  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.0218  Validation loss = 2.9441  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.0212  Validation loss = 2.9427  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.0205  Validation loss = 2.9410  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.0197  Validation loss = 2.9392  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.0189  Validation loss = 2.9373  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.0183  Validation loss = 2.9359  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.0178  Validation loss = 2.9346  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.0171  Validation loss = 2.9329  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.0165  Validation loss = 2.9313  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.0157  Validation loss = 2.9292  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.0152  Validation loss = 2.9280  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.0140  Validation loss = 2.9252  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.0133  Validation loss = 2.9233  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.0126  Validation loss = 2.9217  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.0119  Validation loss = 2.9202  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.0113  Validation loss = 2.9188  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.0104  Validation loss = 2.9165  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.0098  Validation loss = 2.9151  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.0091  Validation loss = 2.9136  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.0088  Validation loss = 2.9129  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.0084  Validation loss = 2.9117  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.0076  Validation loss = 2.9098  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.0071  Validation loss = 2.9086  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.0065  Validation loss = 2.9070  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.0060  Validation loss = 2.9060  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.0055  Validation loss = 2.9046  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.0045  Validation loss = 2.9022  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.0040  Validation loss = 2.9011  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.0033  Validation loss = 2.8993  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.0027  Validation loss = 2.8977  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.0020  Validation loss = 2.8961  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.0018  Validation loss = 2.8956  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.0012  Validation loss = 2.8942  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.0005  Validation loss = 2.8926  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 2.9997  Validation loss = 2.8907  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 2.9992  Validation loss = 2.8894  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 2.9983  Validation loss = 2.8872  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 2.9975  Validation loss = 2.8854  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 2.9971  Validation loss = 2.8843  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 2.9963  Validation loss = 2.8824  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 2.9957  Validation loss = 2.8809  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 2.9948  Validation loss = 2.8788  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 2.9941  Validation loss = 2.8772  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 2.9938  Validation loss = 2.8764  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 2.9931  Validation loss = 2.8748  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 2.9927  Validation loss = 2.8736  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 2.9921  Validation loss = 2.8722  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 2.9916  Validation loss = 2.8710  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 2.9910  Validation loss = 2.8695  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 2.9904  Validation loss = 2.8680  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 2.9900  Validation loss = 2.8670  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 2.9894  Validation loss = 2.8655  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 2.9890  Validation loss = 2.8646  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 2.9883  Validation loss = 2.8629  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 2.9880  Validation loss = 2.8620  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 2.9875  Validation loss = 2.8608  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 2.9871  Validation loss = 2.8599  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 2.9865  Validation loss = 2.8583  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 2.9858  Validation loss = 2.8567  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 2.9851  Validation loss = 2.8551  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 2.9844  Validation loss = 2.8534  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 2.9840  Validation loss = 2.8524  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 2.9835  Validation loss = 2.8511  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 2.9829  Validation loss = 2.8495  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 2.9820  Validation loss = 2.8475  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 2.9817  Validation loss = 2.8466  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 2.9814  Validation loss = 2.8457  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 2.9808  Validation loss = 2.8443  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 2.9804  Validation loss = 2.8434  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 2.9799  Validation loss = 2.8421  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 2.9793  Validation loss = 2.8408  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 2.9787  Validation loss = 2.8394  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 2.9782  Validation loss = 2.8380  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 2.9776  Validation loss = 2.8366  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 2.9768  Validation loss = 2.8346  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 2.9763  Validation loss = 2.8333  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 2.9758  Validation loss = 2.8321  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 2.9755  Validation loss = 2.8312  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 2.9749  Validation loss = 2.8300  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 2.9743  Validation loss = 2.8283  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 2.9733  Validation loss = 2.8259  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 2.9727  Validation loss = 2.8246  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 2.9723  Validation loss = 2.8235  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 2.9717  Validation loss = 2.8222  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 2.9715  Validation loss = 2.8215  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 2.9708  Validation loss = 2.8197  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 2.9704  Validation loss = 2.8187  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 2.9700  Validation loss = 2.8176  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 2.9696  Validation loss = 2.8167  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 2.9688  Validation loss = 2.8148  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 2.9683  Validation loss = 2.8136  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 2.9677  Validation loss = 2.8121  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 2.9673  Validation loss = 2.8111  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 2.9668  Validation loss = 2.8100  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 2.9666  Validation loss = 2.8093  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 2.9661  Validation loss = 2.8082  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 2.9658  Validation loss = 2.8073  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 2.9649  Validation loss = 2.8051  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 2.9643  Validation loss = 2.8037  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 2.9637  Validation loss = 2.8021  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 2.9628  Validation loss = 2.7999  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 2.9623  Validation loss = 2.7987  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 2.9619  Validation loss = 2.7977  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 2.9612  Validation loss = 2.7961  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 2.9606  Validation loss = 2.7947  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 2.9601  Validation loss = 2.7934  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 2.9597  Validation loss = 2.7922  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 2.9591  Validation loss = 2.7909  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 2.9585  Validation loss = 2.7894  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 2.9581  Validation loss = 2.7884  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 2.9576  Validation loss = 2.7871  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 2.9572  Validation loss = 2.7860  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 2.9567  Validation loss = 2.7848  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 2.9561  Validation loss = 2.7833  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 2.9554  Validation loss = 2.7815  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 2.9549  Validation loss = 2.7802  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 2.9544  Validation loss = 2.7791  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 2.9538  Validation loss = 2.7774  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 2.9534  Validation loss = 2.7764  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 2.9529  Validation loss = 2.7753  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 2.9518  Validation loss = 2.7726  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 2.9513  Validation loss = 2.7712  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 2.9507  Validation loss = 2.7697  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 2.9502  Validation loss = 2.7684  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 2.9498  Validation loss = 2.7673  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 2.9494  Validation loss = 2.7665  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 2.9488  Validation loss = 2.7651  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 2.9484  Validation loss = 2.7639  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 2.9476  Validation loss = 2.7619  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 2.9469  Validation loss = 2.7603  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 2.9465  Validation loss = 2.7594  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 2.9457  Validation loss = 2.7574  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 2.9453  Validation loss = 2.7563  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 2.9447  Validation loss = 2.7548  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 2.9441  Validation loss = 2.7531  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 2.9435  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 2.9431  Validation loss = 2.7507  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 2.9424  Validation loss = 2.7489  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 2.9419  Validation loss = 2.7475  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 2.9415  Validation loss = 2.7467  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 2.9409  Validation loss = 2.7450  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 2.9406  Validation loss = 2.7442  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 2.9402  Validation loss = 2.7432  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 2.9398  Validation loss = 2.7422  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 2.9394  Validation loss = 2.7411  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 2.9391  Validation loss = 2.7404  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 2.9386  Validation loss = 2.7393  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 2.9383  Validation loss = 2.7384  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 2.9377  Validation loss = 2.7369  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 2.9372  Validation loss = 2.7356  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 2.9362  Validation loss = 2.7331  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 2.9358  Validation loss = 2.7323  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 2.9353  Validation loss = 2.7309  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 2.9350  Validation loss = 2.7302  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 2.9345  Validation loss = 2.7288  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 2.9340  Validation loss = 2.7275  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 2.9335  Validation loss = 2.7263  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 2.9328  Validation loss = 2.7244  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 2.9320  Validation loss = 2.7224  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 2.9315  Validation loss = 2.7211  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 2.9309  Validation loss = 2.7197  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 2.9306  Validation loss = 2.7190  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 2.9305  Validation loss = 2.7186  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 2.9296  Validation loss = 2.7164  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 2.9292  Validation loss = 2.7152  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 2.9290  Validation loss = 2.7147  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 2.9283  Validation loss = 2.7130  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 2.9278  Validation loss = 2.7116  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 2.9274  Validation loss = 2.7107  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 2.9269  Validation loss = 2.7093  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 2.9265  Validation loss = 2.7084  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 2.9262  Validation loss = 2.7074  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 2.9258  Validation loss = 2.7063  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 2.9253  Validation loss = 2.7051  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 2.9249  Validation loss = 2.7041  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 2.9243  Validation loss = 2.7025  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 2.9239  Validation loss = 2.7015  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 2.9234  Validation loss = 2.7001  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 2.9229  Validation loss = 2.6990  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 2.9226  Validation loss = 2.6981  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 2.9219  Validation loss = 2.6963  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 2.9213  Validation loss = 2.6948  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 2.9207  Validation loss = 2.6932  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 2.9204  Validation loss = 2.6925  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 2.9200  Validation loss = 2.6916  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 2.9195  Validation loss = 2.6901  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 2.9188  Validation loss = 2.6885  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 2.9185  Validation loss = 2.6877  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 2.9181  Validation loss = 2.6867  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 2.9178  Validation loss = 2.6858  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 2.9173  Validation loss = 2.6846  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 2.9167  Validation loss = 2.6830  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 2.9164  Validation loss = 2.6822  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 2.9160  Validation loss = 2.6812  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 2.9156  Validation loss = 2.6800  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 2.9151  Validation loss = 2.6788  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.8420  Validation loss = 2.7215  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.8414  Validation loss = 2.7202  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.8407  Validation loss = 2.7187  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.8404  Validation loss = 2.7179  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.8400  Validation loss = 2.7168  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.8394  Validation loss = 2.7158  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.8387  Validation loss = 2.7141  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.8382  Validation loss = 2.7132  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.8376  Validation loss = 2.7119  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.8370  Validation loss = 2.7105  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.8361  Validation loss = 2.7085  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.8355  Validation loss = 2.7073  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.8351  Validation loss = 2.7064  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.8344  Validation loss = 2.7049  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.8338  Validation loss = 2.7034  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.8333  Validation loss = 2.7025  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.8327  Validation loss = 2.7009  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.8320  Validation loss = 2.6994  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 2.8313  Validation loss = 2.6979  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 2.8309  Validation loss = 2.6971  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 2.8304  Validation loss = 2.6959  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 2.8300  Validation loss = 2.6949  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 2.8293  Validation loss = 2.6934  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 2.8291  Validation loss = 2.6927  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 2.8285  Validation loss = 2.6916  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 2.8281  Validation loss = 2.6905  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 2.8274  Validation loss = 2.6889  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 2.8270  Validation loss = 2.6878  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 2.8261  Validation loss = 2.6860  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 2.8254  Validation loss = 2.6844  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 2.8248  Validation loss = 2.6831  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 2.8240  Validation loss = 2.6814  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 2.8236  Validation loss = 2.6805  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 2.8230  Validation loss = 2.6789  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 2.8224  Validation loss = 2.6775  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 2.8219  Validation loss = 2.6765  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 2.8216  Validation loss = 2.6757  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 2.8214  Validation loss = 2.6751  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 2.8210  Validation loss = 2.6741  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 2.8204  Validation loss = 2.6729  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 2.8199  Validation loss = 2.6715  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 2.8194  Validation loss = 2.6703  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 2.8191  Validation loss = 2.6696  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 2.8186  Validation loss = 2.6683  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 2.8183  Validation loss = 2.6677  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 2.8179  Validation loss = 2.6668  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 2.8175  Validation loss = 2.6658  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 2.8170  Validation loss = 2.6646  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 2.8167  Validation loss = 2.6641  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 2.8160  Validation loss = 2.6626  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 2.8158  Validation loss = 2.6619  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 2.8152  Validation loss = 2.6605  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 2.8145  Validation loss = 2.6589  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 2.8141  Validation loss = 2.6579  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 2.8138  Validation loss = 2.6572  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 2.8135  Validation loss = 2.6564  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 2.8129  Validation loss = 2.6550  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 2.8123  Validation loss = 2.6534  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 2.8120  Validation loss = 2.6527  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 2.8117  Validation loss = 2.6518  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 2.8111  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 2.8108  Validation loss = 2.6497  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 2.8102  Validation loss = 2.6486  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 2.8098  Validation loss = 2.6477  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 2.8092  Validation loss = 2.6463  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 2.8085  Validation loss = 2.6447  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 2.8080  Validation loss = 2.6438  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 2.8077  Validation loss = 2.6429  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 2.8073  Validation loss = 2.6419  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 2.8070  Validation loss = 2.6411  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 2.8064  Validation loss = 2.6396  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 2.8060  Validation loss = 2.6385  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 2.8054  Validation loss = 2.6370  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 2.8050  Validation loss = 2.6362  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 2.8044  Validation loss = 2.6346  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 2.8038  Validation loss = 2.6333  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 2.8034  Validation loss = 2.6323  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 2.8030  Validation loss = 2.6311  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 2.8026  Validation loss = 2.6300  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 2.8020  Validation loss = 2.6286  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 2.8016  Validation loss = 2.6276  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 2.8012  Validation loss = 2.6265  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 2.8008  Validation loss = 2.6257  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 2.8004  Validation loss = 2.6249  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 2.8000  Validation loss = 2.6239  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 2.7998  Validation loss = 2.6234  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 2.7995  Validation loss = 2.6227  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 2.7990  Validation loss = 2.6216  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 2.7982  Validation loss = 2.6198  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 2.7979  Validation loss = 2.6191  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 2.7972  Validation loss = 2.6173  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 2.7969  Validation loss = 2.6166  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 2.7963  Validation loss = 2.6149  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 2.7959  Validation loss = 2.6139  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 2.7955  Validation loss = 2.6129  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 2.7950  Validation loss = 2.6119  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 2.7947  Validation loss = 2.6110  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 2.7942  Validation loss = 2.6096  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 2.7939  Validation loss = 2.6088  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 2.7934  Validation loss = 2.6075  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 2.7928  Validation loss = 2.6060  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 2.7925  Validation loss = 2.6052  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 2.7921  Validation loss = 2.6042  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 2.7917  Validation loss = 2.6034  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 2.7916  Validation loss = 2.6030  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 2.7913  Validation loss = 2.6022  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 2.7908  Validation loss = 2.6008  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 2.7901  Validation loss = 2.5993  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 2.7897  Validation loss = 2.5980  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 2.7894  Validation loss = 2.5974  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 2.7891  Validation loss = 2.5965  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 2.7886  Validation loss = 2.5952  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 2.7882  Validation loss = 2.5942  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 2.7876  Validation loss = 2.5926  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 2.7870  Validation loss = 2.5911  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 2.7865  Validation loss = 2.5898  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 2.7858  Validation loss = 2.5883  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 2.7852  Validation loss = 2.5869  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 2.7847  Validation loss = 2.5856  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 2.7843  Validation loss = 2.5847  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 2.7841  Validation loss = 2.5841  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 2.7837  Validation loss = 2.5832  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 2.7833  Validation loss = 2.5821  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 2.7829  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 2.7826  Validation loss = 2.5803  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 2.7822  Validation loss = 2.5792  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 2.7818  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 2.7815  Validation loss = 2.5776  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 2.7811  Validation loss = 2.5766  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 2.7805  Validation loss = 2.5750  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 2.7801  Validation loss = 2.5741  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 2.7800  Validation loss = 2.5737  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 2.7795  Validation loss = 2.5727  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 2.7792  Validation loss = 2.5717  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 2.7787  Validation loss = 2.5707  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 2.7784  Validation loss = 2.5699  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 2.7781  Validation loss = 2.5692  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 2.7776  Validation loss = 2.5680  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 2.7772  Validation loss = 2.5669  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 2.7766  Validation loss = 2.5658  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 2.7761  Validation loss = 2.5647  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 2.7758  Validation loss = 2.5637  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 2.7754  Validation loss = 2.5627  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 2.7748  Validation loss = 2.5613  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 2.7744  Validation loss = 2.5604  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 2.7738  Validation loss = 2.5588  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 2.7734  Validation loss = 2.5576  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 2.7729  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 2.7726  Validation loss = 2.5556  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 2.7720  Validation loss = 2.5541  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 2.7715  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 2.7710  Validation loss = 2.5515  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 2.7707  Validation loss = 2.5503  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 2.7703  Validation loss = 2.5492  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 2.7697  Validation loss = 2.5478  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 2.7693  Validation loss = 2.5469  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 2.7688  Validation loss = 2.5457  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 2.7684  Validation loss = 2.5445  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 2.7679  Validation loss = 2.5434  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 2.7675  Validation loss = 2.5424  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 2.7672  Validation loss = 2.5416  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 2.7666  Validation loss = 2.5402  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 2.7663  Validation loss = 2.5394  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 2.7656  Validation loss = 2.5375  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 2.7651  Validation loss = 2.5362  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 2.7648  Validation loss = 2.5353  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 2.7645  Validation loss = 2.5346  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 2.7641  Validation loss = 2.5335  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 2.7638  Validation loss = 2.5327  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 2.7635  Validation loss = 2.5317  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 2.7631  Validation loss = 2.5307  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 2.7625  Validation loss = 2.5292  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 2.7619  Validation loss = 2.5277  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 2.7615  Validation loss = 2.5265  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 2.7611  Validation loss = 2.5254  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 2.7606  Validation loss = 2.5241  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 2.7603  Validation loss = 2.5231  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 2.7597  Validation loss = 2.5216  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 2.7595  Validation loss = 2.5210  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 2.7589  Validation loss = 2.5193  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 2.7584  Validation loss = 2.5185  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 2.7580  Validation loss = 2.5171  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 2.7577  Validation loss = 2.5166  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 2.7574  Validation loss = 2.5156  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 2.7567  Validation loss = 2.5138  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 2.7565  Validation loss = 2.5132  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 2.7562  Validation loss = 2.5124  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 2.7559  Validation loss = 2.5116  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 2.7556  Validation loss = 2.5107  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 2.7552  Validation loss = 2.5096  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 2.7547  Validation loss = 2.5084  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 2.7544  Validation loss = 2.5073  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 2.7542  Validation loss = 2.5068  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 2.7537  Validation loss = 2.5055  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 2.7534  Validation loss = 2.5048  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 2.7531  Validation loss = 2.5039  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 2.7527  Validation loss = 2.5029  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 2.7522  Validation loss = 2.5017  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 2.7520  Validation loss = 2.5011  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 2.7515  Validation loss = 2.4998  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 2.7511  Validation loss = 2.4987  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 2.7507  Validation loss = 2.4975  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 2.7504  Validation loss = 2.4967  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 2.7499  Validation loss = 2.4954  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 2.7496  Validation loss = 2.4945  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 2.7493  Validation loss = 2.4935  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 2.7489  Validation loss = 2.4926  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 2.7486  Validation loss = 2.4916  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 2.7482  Validation loss = 2.4907  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 2.7476  Validation loss = 2.4891  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 2.7472  Validation loss = 2.4880  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 2.7467  Validation loss = 2.4864  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 2.7463  Validation loss = 2.4851  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 2.7458  Validation loss = 2.4839  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 2.7454  Validation loss = 2.4831  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 2.7452  Validation loss = 2.4824  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 2.7449  Validation loss = 2.4816  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 2.7444  Validation loss = 2.4802  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 2.7441  Validation loss = 2.4795  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 2.7438  Validation loss = 2.4786  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 2.7433  Validation loss = 2.4776  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 2.7428  Validation loss = 2.4762  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 2.7424  Validation loss = 2.4750  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 2.7419  Validation loss = 2.4738  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 2.7415  Validation loss = 2.4726  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 2.7412  Validation loss = 2.4718  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 2.7408  Validation loss = 2.4707  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 2.7403  Validation loss = 2.4694  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 2.7400  Validation loss = 2.4686  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 2.7395  Validation loss = 2.4675  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 2.7391  Validation loss = 2.4662  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 2.7386  Validation loss = 2.4650  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 2.7382  Validation loss = 2.4640  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 2.7379  Validation loss = 2.4632  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 2.7376  Validation loss = 2.4623  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 2.7373  Validation loss = 2.4616  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 2.7370  Validation loss = 2.4606  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 2.7365  Validation loss = 2.4594  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 2.7361  Validation loss = 2.4582  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 2.7360  Validation loss = 2.4576  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 2.7354  Validation loss = 2.4563  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 2.7351  Validation loss = 2.4555  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 2.7347  Validation loss = 2.4544  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 2.7345  Validation loss = 2.4536  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 2.7342  Validation loss = 2.4528  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 2.7339  Validation loss = 2.4521  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 2.7337  Validation loss = 2.4516  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 2.7332  Validation loss = 2.4505  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 2.7329  Validation loss = 2.4493  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 2.7327  Validation loss = 2.4486  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 2.7325  Validation loss = 2.4480  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 2.7320  Validation loss = 2.4468  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 2.7316  Validation loss = 2.4454  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 2.7310  Validation loss = 2.4437  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 2.7309  Validation loss = 2.4432  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 2.7307  Validation loss = 2.4428  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 2.7304  Validation loss = 2.4420  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 2.7301  Validation loss = 2.4412  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 2.7298  Validation loss = 2.4403  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 2.7296  Validation loss = 2.4397  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 2.7292  Validation loss = 2.4385  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 2.7289  Validation loss = 2.4374  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 2.7285  Validation loss = 2.4361  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 2.7282  Validation loss = 2.4354  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 2.7279  Validation loss = 2.4343  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 2.7274  Validation loss = 2.4329  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 2.7270  Validation loss = 2.4317  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 2.7268  Validation loss = 2.4314  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 2.7263  Validation loss = 2.4299  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 2.7260  Validation loss = 2.4290  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 2.7256  Validation loss = 2.4281  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 2.7253  Validation loss = 2.4274  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 2.7251  Validation loss = 2.4267  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 2.7248  Validation loss = 2.4259  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 2.7246  Validation loss = 2.4251  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 2.7243  Validation loss = 2.4244  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 2.7238  Validation loss = 2.4234  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 2.7236  Validation loss = 2.4228  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 2.7233  Validation loss = 2.4220  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 2.7230  Validation loss = 2.4211  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 2.7226  Validation loss = 2.4203  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 2.7224  Validation loss = 2.4196  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 2.7222  Validation loss = 2.4189  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 2.7218  Validation loss = 2.4179  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 2.7215  Validation loss = 2.4170  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 2.7212  Validation loss = 2.4161  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 2.7209  Validation loss = 2.4151  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 2.7208  Validation loss = 2.4146  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 2.7205  Validation loss = 2.4139  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 2.7203  Validation loss = 2.4131  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 2.7200  Validation loss = 2.4125  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 2.7196  Validation loss = 2.4113  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 2.7193  Validation loss = 2.4104  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 2.7190  Validation loss = 2.4095  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 2.7187  Validation loss = 2.4087  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 2.7185  Validation loss = 2.4079  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 2.7184  Validation loss = 2.4077  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 2.7182  Validation loss = 2.4069  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 2.7178  Validation loss = 2.4059  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 2.7174  Validation loss = 2.4048  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 2.7169  Validation loss = 2.4036  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 2.7167  Validation loss = 2.4029  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 2.7162  Validation loss = 2.4015  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 2.7159  Validation loss = 2.4006  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 2.7157  Validation loss = 2.3996  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 2.7155  Validation loss = 2.3990  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 2.7150  Validation loss = 2.3975  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 2.7147  Validation loss = 2.3966  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 2.7145  Validation loss = 2.3960  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 2.7141  Validation loss = 2.3951  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 2.7137  Validation loss = 2.3941  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 2.7135  Validation loss = 2.3933  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 2.7131  Validation loss = 2.3920  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 2.7127  Validation loss = 2.3909  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 2.7122  Validation loss = 2.3898  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 2.7119  Validation loss = 2.3888  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 2.7116  Validation loss = 2.3882  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 2.7114  Validation loss = 2.3878  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 2.7112  Validation loss = 2.3867  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 2.7107  Validation loss = 2.3858  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 2.7103  Validation loss = 2.3843  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 2.7100  Validation loss = 2.3835  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 2.7097  Validation loss = 2.3827  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 2.7093  Validation loss = 2.3816  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 2.7090  Validation loss = 2.3806  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 2.7088  Validation loss = 2.3800  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 2.7085  Validation loss = 2.3789  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 2.7082  Validation loss = 2.3779  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 2.7079  Validation loss = 2.3771  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 2.7075  Validation loss = 2.3755  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 2.7072  Validation loss = 2.3748  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 2.7070  Validation loss = 2.3741  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 2.7067  Validation loss = 2.3732  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 2.7063  Validation loss = 2.3718  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 2.7061  Validation loss = 2.3713  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 2.7058  Validation loss = 2.3704  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 2.7055  Validation loss = 2.3695  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 2.7050  Validation loss = 2.3682  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 2.7046  Validation loss = 2.3670  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 2.7044  Validation loss = 2.3663  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 2.7043  Validation loss = 2.3658  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 2.7041  Validation loss = 2.3654  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 2.7039  Validation loss = 2.3646  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 2.7036  Validation loss = 2.3641  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 2.7033  Validation loss = 2.3633  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 2.7030  Validation loss = 2.3621  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 2.7027  Validation loss = 2.3613  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 2.7025  Validation loss = 2.3607  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 2.7023  Validation loss = 2.3600  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 2.7019  Validation loss = 2.3587  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 2.7017  Validation loss = 2.3582  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 2.7014  Validation loss = 2.3571  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 2.7012  Validation loss = 2.3563  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 2.7009  Validation loss = 2.3553  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 2.7005  Validation loss = 2.3542  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 2.7001  Validation loss = 2.3528  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 2.6995  Validation loss = 2.3512  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 2.6990  Validation loss = 2.3494  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 2.6988  Validation loss = 2.3490  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 2.6985  Validation loss = 2.3479  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 2.6983  Validation loss = 2.3472  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 2.6980  Validation loss = 2.3464  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 2.6978  Validation loss = 2.3458  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 2.6975  Validation loss = 2.3450  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 2.6971  Validation loss = 2.3441  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 2.6970  Validation loss = 2.3439  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 2.6967  Validation loss = 2.3430  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 2.6965  Validation loss = 2.3423  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 2.6961  Validation loss = 2.3412  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 2.6958  Validation loss = 2.3404  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 2.6956  Validation loss = 2.3400  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 2.6954  Validation loss = 2.3393  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 2.6951  Validation loss = 2.3385  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 2.6948  Validation loss = 2.3377  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 2.6947  Validation loss = 2.3372  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 2.6944  Validation loss = 2.3363  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 2.6941  Validation loss = 2.3355  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 2.6940  Validation loss = 2.3353  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 2.6938  Validation loss = 2.3346  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 2.6934  Validation loss = 2.3335  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 2.6931  Validation loss = 2.3329  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 2.6929  Validation loss = 2.3322  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 2.6927  Validation loss = 2.3316  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 2.6924  Validation loss = 2.3309  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 2.6922  Validation loss = 2.3302  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 2.6920  Validation loss = 2.3299  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 2.6917  Validation loss = 2.3290  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 2.6913  Validation loss = 2.3278  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 2.6911  Validation loss = 2.3271  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 2.6908  Validation loss = 2.3264  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 2.6907  Validation loss = 2.3260  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 2.6905  Validation loss = 2.3254  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 2.6901  Validation loss = 2.3242  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 2.6899  Validation loss = 2.3236  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 2.6897  Validation loss = 2.3230  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 2.6895  Validation loss = 2.3224  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 2.6894  Validation loss = 2.3221  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 2.6891  Validation loss = 2.3214  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 2.6889  Validation loss = 2.3208  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 2.6885  Validation loss = 2.3199  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 2.6884  Validation loss = 2.3194  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 2.6880  Validation loss = 2.3182  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 2.6877  Validation loss = 2.3170  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 2.6874  Validation loss = 2.3162  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 2.6872  Validation loss = 2.3158  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 2.6871  Validation loss = 2.3154  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 2.6870  Validation loss = 2.3152  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 2.6867  Validation loss = 2.3140  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 2.6864  Validation loss = 2.3131  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 2.6860  Validation loss = 2.3122  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 2.6857  Validation loss = 2.3112  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 2.6854  Validation loss = 2.3103  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 2.6853  Validation loss = 2.3097  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 2.6850  Validation loss = 2.3089  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 2.6850  Validation loss = 2.3089  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 2.6848  Validation loss = 2.3085  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 2.6847  Validation loss = 2.3080  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 2.6844  Validation loss = 2.3072  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 2.6842  Validation loss = 2.3067  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 2.6841  Validation loss = 2.3062  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 2.6838  Validation loss = 2.3054  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 2.6836  Validation loss = 2.3046  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 2.6832  Validation loss = 2.3032  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 2.6831  Validation loss = 2.3028  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 2.6830  Validation loss = 2.3026  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 2.6827  Validation loss = 2.3018  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 2.6826  Validation loss = 2.3014  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 2.6824  Validation loss = 2.3009  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 2.6823  Validation loss = 2.3005  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 2.6820  Validation loss = 2.2998  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 2.6818  Validation loss = 2.2992  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 2.6814  Validation loss = 2.2980  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 2.6812  Validation loss = 2.2975  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 2.6811  Validation loss = 2.2969  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 2.6808  Validation loss = 2.2961  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 2.6804  Validation loss = 2.2948  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 2.6802  Validation loss = 2.2941  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 2.6800  Validation loss = 2.2935  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 2.6797  Validation loss = 2.2926  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 2.6796  Validation loss = 2.2923  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 2.6794  Validation loss = 2.2918  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 2.6791  Validation loss = 2.2905  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 2.6789  Validation loss = 2.2896  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 2.6785  Validation loss = 2.2884  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 2.6783  Validation loss = 2.2880  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 2.6782  Validation loss = 2.2877  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 2.6779  Validation loss = 2.2872  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 2.6777  Validation loss = 2.2865  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 2.6774  Validation loss = 2.2855  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 2.6771  Validation loss = 2.2847  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 2.6768  Validation loss = 2.2838  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 2.6767  Validation loss = 2.2833  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 2.6765  Validation loss = 2.2828  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 2.6763  Validation loss = 2.2821  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 2.6762  Validation loss = 2.2818  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 2.6760  Validation loss = 2.2811  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 2.6757  Validation loss = 2.2805  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 2.6755  Validation loss = 2.2796  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 2.6750  Validation loss = 2.2784  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 2.6747  Validation loss = 2.2776  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 2.6745  Validation loss = 2.2769  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 2.6743  Validation loss = 2.2763  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 2.6742  Validation loss = 2.2758  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 2.6738  Validation loss = 2.2748  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 2.6736  Validation loss = 2.2741  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 2.6732  Validation loss = 2.2730  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 2.6729  Validation loss = 2.2723  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 2.6726  Validation loss = 2.2714  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 2.6725  Validation loss = 2.2707  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 2.6722  Validation loss = 2.2699  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 2.6721  Validation loss = 2.2696  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 2.6720  Validation loss = 2.2693  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 2.6719  Validation loss = 2.2690  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 2.6717  Validation loss = 2.2682  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 2.6714  Validation loss = 2.2675  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 2.6713  Validation loss = 2.2671  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 2.6713  Validation loss = 2.2669  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 2.6712  Validation loss = 2.2666  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 2.6709  Validation loss = 2.2662  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 2.6708  Validation loss = 2.2657  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 2.6706  Validation loss = 2.2651  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 2.6703  Validation loss = 2.2641  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 2.6697  Validation loss = 2.2624  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 2.6696  Validation loss = 2.2618  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 2.6693  Validation loss = 2.2607  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 2.6692  Validation loss = 2.2602  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 2.6690  Validation loss = 2.2599  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 2.6687  Validation loss = 2.2589  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 2.6686  Validation loss = 2.2583  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 2.6684  Validation loss = 2.2578  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 2.6681  Validation loss = 2.2567  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 2.6679  Validation loss = 2.2563  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 2.6678  Validation loss = 2.2560  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 2.6677  Validation loss = 2.2556  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 2.6674  Validation loss = 2.2547  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 2.6672  Validation loss = 2.2540  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 2.6671  Validation loss = 2.2537  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 2.6671  Validation loss = 2.2533  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 2.6669  Validation loss = 2.2526  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 2.6668  Validation loss = 2.2523  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.6069  Validation loss = 3.4510  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.6068  Validation loss = 3.4504  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.6066  Validation loss = 3.4494  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.6063  Validation loss = 3.4482  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.6062  Validation loss = 3.4476  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.6060  Validation loss = 3.4469  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.6058  Validation loss = 3.4460  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.6056  Validation loss = 3.4451  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.6054  Validation loss = 3.4441  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.6053  Validation loss = 3.4436  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.6052  Validation loss = 3.4430  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.6050  Validation loss = 3.4423  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.6049  Validation loss = 3.4418  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.6047  Validation loss = 3.4410  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.6045  Validation loss = 3.4402  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.6044  Validation loss = 3.4394  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.6041  Validation loss = 3.4383  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.6039  Validation loss = 3.4371  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.6037  Validation loss = 3.4361  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.6035  Validation loss = 3.4354  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.6032  Validation loss = 3.4342  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.6031  Validation loss = 3.4336  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.6031  Validation loss = 3.4334  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.6030  Validation loss = 3.4329  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.6029  Validation loss = 3.4324  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.6028  Validation loss = 3.4319  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.6026  Validation loss = 3.4312  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.6024  Validation loss = 3.4302  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.6022  Validation loss = 3.4294  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.6021  Validation loss = 3.4290  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.6020  Validation loss = 3.4285  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.6018  Validation loss = 3.4276  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.6016  Validation loss = 3.4268  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.6014  Validation loss = 3.4258  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.6012  Validation loss = 3.4248  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.6011  Validation loss = 3.4243  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.6010  Validation loss = 3.4239  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.6010  Validation loss = 3.4237  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.6008  Validation loss = 3.4230  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.6007  Validation loss = 3.4224  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.6005  Validation loss = 3.4216  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.6005  Validation loss = 3.4213  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.6002  Validation loss = 3.4202  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.6001  Validation loss = 3.4197  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.5998  Validation loss = 3.4181  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.5996  Validation loss = 3.4173  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.5995  Validation loss = 3.4168  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.5994  Validation loss = 3.4162  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.5993  Validation loss = 3.4160  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.5992  Validation loss = 3.4154  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.5991  Validation loss = 3.4149  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.5990  Validation loss = 3.4144  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.5988  Validation loss = 3.4136  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.5986  Validation loss = 3.4127  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.5983  Validation loss = 3.4113  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.5980  Validation loss = 3.4099  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.5978  Validation loss = 3.4088  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 1.5977  Validation loss = 3.4083  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 1.5976  Validation loss = 3.4077  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 1.5974  Validation loss = 3.4071  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 1.5974  Validation loss = 3.4067  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 1.5973  Validation loss = 3.4062  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 1.5971  Validation loss = 3.4053  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 1.5969  Validation loss = 3.4044  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 1.5968  Validation loss = 3.4037  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 1.5966  Validation loss = 3.4028  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 1.5964  Validation loss = 3.4021  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 1.5963  Validation loss = 3.4015  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 1.5961  Validation loss = 3.4005  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 1.5961  Validation loss = 3.4003  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 1.5957  Validation loss = 3.3985  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 1.5957  Validation loss = 3.3985  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 1.5956  Validation loss = 3.3981  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 1.5955  Validation loss = 3.3976  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 1.5954  Validation loss = 3.3971  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 1.5953  Validation loss = 3.3964  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 1.5951  Validation loss = 3.3954  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 1.5949  Validation loss = 3.3945  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 1.5949  Validation loss = 3.3942  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 1.5947  Validation loss = 3.3936  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 1.5946  Validation loss = 3.3929  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 1.5944  Validation loss = 3.3919  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 1.5943  Validation loss = 3.3912  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 1.5941  Validation loss = 3.3906  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 1.5939  Validation loss = 3.3895  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 1.5937  Validation loss = 3.3886  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 1.5936  Validation loss = 3.3879  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 1.5935  Validation loss = 3.3873  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 1.5934  Validation loss = 3.3871  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 1.5932  Validation loss = 3.3862  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 1.5931  Validation loss = 3.3857  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 1.5930  Validation loss = 3.3853  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 1.5929  Validation loss = 3.3846  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 1.5928  Validation loss = 3.3840  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 1.5927  Validation loss = 3.3836  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 1.5926  Validation loss = 3.3829  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 1.5925  Validation loss = 3.3825  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 1.5924  Validation loss = 3.3819  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 1.5923  Validation loss = 3.3815  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 1.5922  Validation loss = 3.3812  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 1.5921  Validation loss = 3.3807  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 1.5920  Validation loss = 3.3800  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 1.5919  Validation loss = 3.3794  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 1.5917  Validation loss = 3.3786  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 1.5917  Validation loss = 3.3784  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 1.5916  Validation loss = 3.3782  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 1.5916  Validation loss = 3.3779  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 1.5914  Validation loss = 3.3771  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 1.5914  Validation loss = 3.3771  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 1.5913  Validation loss = 3.3764  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 1.5911  Validation loss = 3.3753  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 1.5909  Validation loss = 3.3746  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 1.5907  Validation loss = 3.3737  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 1.5906  Validation loss = 3.3730  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 1.5906  Validation loss = 3.3729  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 1.5905  Validation loss = 3.3726  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 1.5903  Validation loss = 3.3715  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 1.5902  Validation loss = 3.3708  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 1.5899  Validation loss = 3.3696  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 1.5898  Validation loss = 3.3692  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 1.5898  Validation loss = 3.3688  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 1.5896  Validation loss = 3.3680  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 1.5895  Validation loss = 3.3673  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 1.5893  Validation loss = 3.3662  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 1.5891  Validation loss = 3.3654  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 1.5890  Validation loss = 3.3651  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 1.5889  Validation loss = 3.3644  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 1.5888  Validation loss = 3.3639  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 1.5887  Validation loss = 3.3634  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 1.5885  Validation loss = 3.3625  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 1.5885  Validation loss = 3.3625  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 1.5883  Validation loss = 3.3614  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 1.5882  Validation loss = 3.3609  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 1.5881  Validation loss = 3.3603  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 1.5879  Validation loss = 3.3595  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 1.5879  Validation loss = 3.3593  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 1.5877  Validation loss = 3.3584  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 1.5876  Validation loss = 3.3579  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 1.5875  Validation loss = 3.3574  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 1.5874  Validation loss = 3.3570  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 1.5874  Validation loss = 3.3565  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 1.5872  Validation loss = 3.3559  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 1.5870  Validation loss = 3.3549  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 1.5870  Validation loss = 3.3545  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 1.5867  Validation loss = 3.3534  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 1.5867  Validation loss = 3.3531  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 1.5865  Validation loss = 3.3522  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 1.5864  Validation loss = 3.3516  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 1.5862  Validation loss = 3.3509  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 1.5861  Validation loss = 3.3503  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 1.5860  Validation loss = 3.3494  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 1.5859  Validation loss = 3.3492  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 1.5858  Validation loss = 3.3487  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 1.5857  Validation loss = 3.3481  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 1.5857  Validation loss = 3.3480  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 1.5856  Validation loss = 3.3478  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 1.5855  Validation loss = 3.3470  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 1.5853  Validation loss = 3.3460  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 1.5850  Validation loss = 3.3445  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 1.5849  Validation loss = 3.3442  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 1.5848  Validation loss = 3.3435  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 1.5846  Validation loss = 3.3425  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 1.5845  Validation loss = 3.3419  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 1.5844  Validation loss = 3.3413  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 1.5843  Validation loss = 3.3407  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 1.5841  Validation loss = 3.3397  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 1.5839  Validation loss = 3.3389  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 1.5838  Validation loss = 3.3383  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 1.5837  Validation loss = 3.3377  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 1.5836  Validation loss = 3.3371  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 1.5835  Validation loss = 3.3366  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 1.5834  Validation loss = 3.3362  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 1.5833  Validation loss = 3.3353  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 1.5832  Validation loss = 3.3348  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 1.5830  Validation loss = 3.3340  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 1.5830  Validation loss = 3.3338  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 1.5828  Validation loss = 3.3330  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 1.5827  Validation loss = 3.3323  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 1.5825  Validation loss = 3.3316  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 1.5824  Validation loss = 3.3309  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 1.5822  Validation loss = 3.3301  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 1.5822  Validation loss = 3.3295  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 1.5821  Validation loss = 3.3293  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 1.5821  Validation loss = 3.3291  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 1.5820  Validation loss = 3.3287  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 1.5820  Validation loss = 3.3286  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 1.5818  Validation loss = 3.3278  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 1.5816  Validation loss = 3.3269  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 1.5816  Validation loss = 3.3265  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 1.5814  Validation loss = 3.3257  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 1.5814  Validation loss = 3.3254  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 1.5813  Validation loss = 3.3250  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 1.5812  Validation loss = 3.3244  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 1.5810  Validation loss = 3.3234  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 1.5809  Validation loss = 3.3227  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 1.5808  Validation loss = 3.3222  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 1.5807  Validation loss = 3.3217  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 1.5806  Validation loss = 3.3213  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 1.5806  Validation loss = 3.3212  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 1.5805  Validation loss = 3.3210  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 1.5804  Validation loss = 3.3202  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 1.5802  Validation loss = 3.3193  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 1.5801  Validation loss = 3.3184  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 1.5799  Validation loss = 3.3173  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 1.5797  Validation loss = 3.3164  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 1.5796  Validation loss = 3.3160  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 1.5795  Validation loss = 3.3154  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 1.5795  Validation loss = 3.3151  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 1.5794  Validation loss = 3.3146  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 1.5793  Validation loss = 3.3141  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 1.5792  Validation loss = 3.3136  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 1.5791  Validation loss = 3.3131  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 1.5790  Validation loss = 3.3125  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 1.5789  Validation loss = 3.3122  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 1.5790  Validation loss = 3.3124  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 1.5789  Validation loss = 3.3119  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 1.5788  Validation loss = 3.3114  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 1.5787  Validation loss = 3.3108  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 1.5786  Validation loss = 3.3103  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 1.5785  Validation loss = 3.3099  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 1.5783  Validation loss = 3.3090  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 1.5782  Validation loss = 3.3085  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 1.5782  Validation loss = 3.3081  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 1.5781  Validation loss = 3.3075  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 1.5780  Validation loss = 3.3071  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 1.5779  Validation loss = 3.3065  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 1.5778  Validation loss = 3.3062  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 1.5777  Validation loss = 3.3059  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 1.5776  Validation loss = 3.3050  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 1.5776  Validation loss = 3.3048  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 1.5775  Validation loss = 3.3045  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 1.5775  Validation loss = 3.3043  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 1.5774  Validation loss = 3.3038  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 1.5772  Validation loss = 3.3033  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 1.5771  Validation loss = 3.3027  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 1.5770  Validation loss = 3.3021  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 1.5769  Validation loss = 3.3012  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 1.5768  Validation loss = 3.3008  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 1.5767  Validation loss = 3.3003  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 1.5766  Validation loss = 3.2997  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 1.5765  Validation loss = 3.2992  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 1.5764  Validation loss = 3.2987  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 1.5763  Validation loss = 3.2981  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 1.5762  Validation loss = 3.2974  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 1.5762  Validation loss = 3.2975  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 1.5761  Validation loss = 3.2968  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 1.5759  Validation loss = 3.2962  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 1.5758  Validation loss = 3.2954  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 1.5757  Validation loss = 3.2947  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 1.5755  Validation loss = 3.2938  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 1.5755  Validation loss = 3.2934  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 1.5754  Validation loss = 3.2930  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 1.5754  Validation loss = 3.2929  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 1.5753  Validation loss = 3.2924  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 1.5752  Validation loss = 3.2922  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 1.5752  Validation loss = 3.2919  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 1.5751  Validation loss = 3.2912  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 1.5749  Validation loss = 3.2901  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 1.5747  Validation loss = 3.2894  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 1.5747  Validation loss = 3.2892  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 1.5746  Validation loss = 3.2887  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 1.5745  Validation loss = 3.2882  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 1.5745  Validation loss = 3.2881  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 1.5744  Validation loss = 3.2876  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 1.5743  Validation loss = 3.2873  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 1.5742  Validation loss = 3.2863  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 1.5741  Validation loss = 3.2858  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 1.5739  Validation loss = 3.2851  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 1.5738  Validation loss = 3.2842  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 1.5738  Validation loss = 3.2843  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 1.5737  Validation loss = 3.2835  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 1.5736  Validation loss = 3.2830  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 1.5735  Validation loss = 3.2826  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 1.5734  Validation loss = 3.2822  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 1.5732  Validation loss = 3.2810  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 1.5732  Validation loss = 3.2809  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 1.5732  Validation loss = 3.2807  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 1.5730  Validation loss = 3.2800  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 1.5729  Validation loss = 3.2793  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 1.5728  Validation loss = 3.2787  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 1.5727  Validation loss = 3.2781  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 1.5725  Validation loss = 3.2768  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 1.5724  Validation loss = 3.2762  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 1.5723  Validation loss = 3.2759  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 1.5723  Validation loss = 3.2757  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 1.5722  Validation loss = 3.2750  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 1.5720  Validation loss = 3.2742  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 1.5720  Validation loss = 3.2740  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 1.5719  Validation loss = 3.2735  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 1.5718  Validation loss = 3.2728  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 1.5717  Validation loss = 3.2723  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 1.5717  Validation loss = 3.2722  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 1.5716  Validation loss = 3.2719  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 1.5715  Validation loss = 3.2712  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 1.5714  Validation loss = 3.2708  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 1.5714  Validation loss = 3.2704  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 1.5713  Validation loss = 3.2698  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 1.5712  Validation loss = 3.2692  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 1.5710  Validation loss = 3.2684  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 1.5709  Validation loss = 3.2676  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 1.5708  Validation loss = 3.2669  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 1.5707  Validation loss = 3.2669  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 1.5707  Validation loss = 3.2665  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 1.5706  Validation loss = 3.2661  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 1.5705  Validation loss = 3.2656  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 1.5704  Validation loss = 3.2652  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 1.5703  Validation loss = 3.2643  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 1.5702  Validation loss = 3.2635  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 1.5700  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 1.5698  Validation loss = 3.2616  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 1.5698  Validation loss = 3.2615  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 1.5698  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 1.5697  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 1.5696  Validation loss = 3.2606  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 1.5696  Validation loss = 3.2604  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 1.5695  Validation loss = 3.2599  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 1.5694  Validation loss = 3.2593  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 1.5693  Validation loss = 3.2587  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 1.5692  Validation loss = 3.2582  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 1.5691  Validation loss = 3.2573  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 1.5690  Validation loss = 3.2568  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 1.5689  Validation loss = 3.2561  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 1.5688  Validation loss = 3.2557  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 1.5687  Validation loss = 3.2555  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 1.5686  Validation loss = 3.2549  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 1.5686  Validation loss = 3.2546  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 1.5685  Validation loss = 3.2540  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 1.5684  Validation loss = 3.2533  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 1.5683  Validation loss = 3.2526  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 1.5682  Validation loss = 3.2522  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 1.5680  Validation loss = 3.2511  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 1.5679  Validation loss = 3.2506  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 1.5679  Validation loss = 3.2503  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 1.5677  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 1.5677  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 1.5676  Validation loss = 3.2489  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 1.5676  Validation loss = 3.2487  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 1.5675  Validation loss = 3.2482  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 1.5674  Validation loss = 3.2476  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 1.5674  Validation loss = 3.2474  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 1.5673  Validation loss = 3.2471  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 1.5672  Validation loss = 3.2466  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 1.5672  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 1.5671  Validation loss = 3.2457  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 1.5670  Validation loss = 3.2452  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 1.5668  Validation loss = 3.2444  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 1.5667  Validation loss = 3.2438  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 1.5666  Validation loss = 3.2432  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 1.5666  Validation loss = 3.2428  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 1.5665  Validation loss = 3.2422  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 1.5664  Validation loss = 3.2420  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 1.5664  Validation loss = 3.2417  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 1.5663  Validation loss = 3.2411  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 1.5663  Validation loss = 3.2410  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 1.5662  Validation loss = 3.2404  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 1.5661  Validation loss = 3.2403  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 1.5661  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 1.5660  Validation loss = 3.2395  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 1.5659  Validation loss = 3.2392  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 1.5659  Validation loss = 3.2387  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 1.5658  Validation loss = 3.2381  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 1.5657  Validation loss = 3.2376  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 1.5656  Validation loss = 3.2371  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 1.5655  Validation loss = 3.2365  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 1.5654  Validation loss = 3.2359  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 1.5653  Validation loss = 3.2352  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 1.5652  Validation loss = 3.2344  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 1.5651  Validation loss = 3.2338  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 1.5651  Validation loss = 3.2339  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 1.5650  Validation loss = 3.2333  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 1.5648  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 1.5647  Validation loss = 3.2318  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 1.5647  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 1.5647  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 1.5646  Validation loss = 3.2312  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 1.5645  Validation loss = 3.2308  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 1.5645  Validation loss = 3.2306  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 1.5644  Validation loss = 3.2299  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 1.5643  Validation loss = 3.2292  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 1.5642  Validation loss = 3.2289  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 1.5641  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 1.5640  Validation loss = 3.2278  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 1.5639  Validation loss = 3.2272  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 1.5638  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 1.5637  Validation loss = 3.2260  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 1.5636  Validation loss = 3.2252  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 1.5635  Validation loss = 3.2245  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 1.5634  Validation loss = 3.2241  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 1.5634  Validation loss = 3.2237  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 1.5633  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 1.5631  Validation loss = 3.2225  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 1.5630  Validation loss = 3.2219  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 1.5630  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 1.5629  Validation loss = 3.2211  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 1.5628  Validation loss = 3.2203  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 1.5627  Validation loss = 3.2197  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 1.5626  Validation loss = 3.2193  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 1.5626  Validation loss = 3.2190  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 1.5625  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 1.5624  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 1.5624  Validation loss = 3.2177  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 1.5623  Validation loss = 3.2172  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 1.5622  Validation loss = 3.2169  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 1.5622  Validation loss = 3.2164  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 1.5621  Validation loss = 3.2163  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 1.5620  Validation loss = 3.2158  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 1.5620  Validation loss = 3.2158  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 1.5620  Validation loss = 3.2155  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 1.5619  Validation loss = 3.2152  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 1.5618  Validation loss = 3.2146  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 1.5617  Validation loss = 3.2138  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 1.5617  Validation loss = 3.2137  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 1.5616  Validation loss = 3.2132  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 1.5615  Validation loss = 3.2129  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 1.5615  Validation loss = 3.2124  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 1.5614  Validation loss = 3.2117  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 1.5612  Validation loss = 3.2110  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 1.5612  Validation loss = 3.2106  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 1.5611  Validation loss = 3.2105  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 1.5610  Validation loss = 3.2097  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 1.5610  Validation loss = 3.2094  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 1.5609  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 1.5609  Validation loss = 3.2090  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 1.5609  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 1.5607  Validation loss = 3.2079  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 1.5607  Validation loss = 3.2076  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 1.5606  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 1.5605  Validation loss = 3.2066  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 1.5604  Validation loss = 3.2062  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 1.5605  Validation loss = 3.2065  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 1.5605  Validation loss = 3.2065  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 1.5604  Validation loss = 3.2064  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 1.5604  Validation loss = 3.2059  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 1.5603  Validation loss = 3.2055  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 1.5601  Validation loss = 3.2044  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 1.5601  Validation loss = 3.2039  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 1.5601  Validation loss = 3.2040  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 1.5600  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 1.5600  Validation loss = 3.2034  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 1.5599  Validation loss = 3.2029  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 1.5598  Validation loss = 3.2021  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 1.5597  Validation loss = 3.2018  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 1.5596  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 1.5596  Validation loss = 3.2012  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 1.5595  Validation loss = 3.2004  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 1.5593  Validation loss = 3.1995  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 1.5593  Validation loss = 3.1992  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 1.5592  Validation loss = 3.1988  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 1.5591  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 1.5591  Validation loss = 3.1981  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 1.5591  Validation loss = 3.1980  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 1.5590  Validation loss = 3.1978  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 1.5590  Validation loss = 3.1973  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 1.5589  Validation loss = 3.1971  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 1.5588  Validation loss = 3.1964  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 1.5588  Validation loss = 3.1961  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 1.5587  Validation loss = 3.1959  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 1.5587  Validation loss = 3.1956  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 1.5586  Validation loss = 3.1947  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 1.5585  Validation loss = 3.1943  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 1.5584  Validation loss = 3.1939  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 1.5583  Validation loss = 3.1934  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 1.5583  Validation loss = 3.1931  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 1.5582  Validation loss = 3.1929  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 1.5582  Validation loss = 3.1926  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 1.5582  Validation loss = 3.1924  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 1.5581  Validation loss = 3.1923  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 1.5580  Validation loss = 3.1916  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 1.5580  Validation loss = 3.1911  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 1.5579  Validation loss = 3.1907  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 1.5578  Validation loss = 3.1902  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 1.5577  Validation loss = 3.1895  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 1.5576  Validation loss = 3.1888  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 1.5575  Validation loss = 3.1882  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 1.5574  Validation loss = 3.1879  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 1.5574  Validation loss = 3.1874  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 1.5573  Validation loss = 3.1868  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 1.5572  Validation loss = 3.1867  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 1.5572  Validation loss = 3.1861  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 1.5571  Validation loss = 3.1856  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 1.5570  Validation loss = 3.1854  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 1.5569  Validation loss = 3.1849  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 1.5569  Validation loss = 3.1844  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 1.5568  Validation loss = 3.1840  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 1.5567  Validation loss = 3.1836  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 1.5567  Validation loss = 3.1830  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 1.5566  Validation loss = 3.1827  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 1.5565  Validation loss = 3.1819  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 1.5564  Validation loss = 3.1815  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 1.5563  Validation loss = 3.1808  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 1.5563  Validation loss = 3.1807  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 1.5562  Validation loss = 3.1801  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 1.5561  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 1.5560  Validation loss = 3.1791  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 1.5560  Validation loss = 3.1788  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 1.5559  Validation loss = 3.1780  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 1.5558  Validation loss = 3.1773  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 1.5557  Validation loss = 3.1772  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 1.5556  Validation loss = 3.1765  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 1.5556  Validation loss = 3.1763  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.6314  Validation loss = 4.5037  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.6312  Validation loss = 4.5028  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.6311  Validation loss = 4.5025  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.6309  Validation loss = 4.5018  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.6308  Validation loss = 4.5013  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.6307  Validation loss = 4.5010  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.6305  Validation loss = 4.5004  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.6305  Validation loss = 4.5002  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.6304  Validation loss = 4.4997  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.6302  Validation loss = 4.4989  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.6302  Validation loss = 4.4989  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.6299  Validation loss = 4.4980  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.6298  Validation loss = 4.4975  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.6296  Validation loss = 4.4966  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.6294  Validation loss = 4.4960  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.6293  Validation loss = 4.4956  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.6292  Validation loss = 4.4950  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.6291  Validation loss = 4.4944  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.6289  Validation loss = 4.4937  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.6288  Validation loss = 4.4932  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.6288  Validation loss = 4.4934  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.6287  Validation loss = 4.4931  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.6286  Validation loss = 4.4928  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.6283  Validation loss = 4.4915  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.6282  Validation loss = 4.4910  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.6280  Validation loss = 4.4902  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.6279  Validation loss = 4.4899  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.6278  Validation loss = 4.4898  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.6278  Validation loss = 4.4895  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.6277  Validation loss = 4.4891  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.6276  Validation loss = 4.4887  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.6274  Validation loss = 4.4880  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.6272  Validation loss = 4.4870  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.6271  Validation loss = 4.4866  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.6269  Validation loss = 4.4861  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.6268  Validation loss = 4.4856  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.6266  Validation loss = 4.4847  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.6264  Validation loss = 4.4838  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.6263  Validation loss = 4.4832  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.6261  Validation loss = 4.4826  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.6260  Validation loss = 4.4821  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.6259  Validation loss = 4.4816  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.6258  Validation loss = 4.4814  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.6257  Validation loss = 4.4813  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.6256  Validation loss = 4.4808  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.6255  Validation loss = 4.4804  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 1.6253  Validation loss = 4.4797  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 1.6252  Validation loss = 4.4791  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 1.6250  Validation loss = 4.4783  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 1.6250  Validation loss = 4.4780  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 1.6249  Validation loss = 4.4778  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 1.6248  Validation loss = 4.4774  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 1.6248  Validation loss = 4.4774  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 1.6247  Validation loss = 4.4769  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 1.6245  Validation loss = 4.4763  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 1.6244  Validation loss = 4.4757  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 1.6242  Validation loss = 4.4748  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 1.6240  Validation loss = 4.4741  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 1.6239  Validation loss = 4.4737  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 1.6237  Validation loss = 4.4730  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 1.6237  Validation loss = 4.4729  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 1.6237  Validation loss = 4.4728  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 1.6235  Validation loss = 4.4720  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 1.6233  Validation loss = 4.4713  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 1.6233  Validation loss = 4.4711  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 1.6231  Validation loss = 4.4704  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 1.6229  Validation loss = 4.4697  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 1.6228  Validation loss = 4.4692  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 1.6227  Validation loss = 4.4687  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 1.6226  Validation loss = 4.4683  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 1.6225  Validation loss = 4.4680  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 1.6224  Validation loss = 4.4675  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 1.6222  Validation loss = 4.4670  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 1.6221  Validation loss = 4.4662  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 1.6219  Validation loss = 4.4656  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 1.6217  Validation loss = 4.4646  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 1.6215  Validation loss = 4.4636  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 1.6214  Validation loss = 4.4631  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 1.6213  Validation loss = 4.4629  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 1.6212  Validation loss = 4.4626  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 1.6210  Validation loss = 4.4617  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 1.6210  Validation loss = 4.4614  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 1.6208  Validation loss = 4.4605  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 1.6207  Validation loss = 4.4601  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 1.6205  Validation loss = 4.4596  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 1.6205  Validation loss = 4.4594  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 1.6203  Validation loss = 4.4586  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 1.6201  Validation loss = 4.4579  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 1.6201  Validation loss = 4.4580  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 1.6199  Validation loss = 4.4570  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 1.6199  Validation loss = 4.4572  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 1.6198  Validation loss = 4.4567  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 1.6197  Validation loss = 4.4562  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 1.6196  Validation loss = 4.4561  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 1.6195  Validation loss = 4.4555  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 1.6194  Validation loss = 4.4548  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 1.6192  Validation loss = 4.4543  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 1.6191  Validation loss = 4.4535  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 1.6189  Validation loss = 4.4529  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 1.6189  Validation loss = 4.4526  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 1.6187  Validation loss = 4.4517  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 1.6186  Validation loss = 4.4514  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 1.6185  Validation loss = 4.4512  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 1.6184  Validation loss = 4.4507  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 1.6182  Validation loss = 4.4497  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 1.6181  Validation loss = 4.4493  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 1.6180  Validation loss = 4.4486  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 1.6178  Validation loss = 4.4481  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 1.6178  Validation loss = 4.4479  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 1.6178  Validation loss = 4.4480  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 1.6175  Validation loss = 4.4468  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 1.6173  Validation loss = 4.4461  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 1.6172  Validation loss = 4.4456  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 1.6172  Validation loss = 4.4454  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 1.6171  Validation loss = 4.4451  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 1.6170  Validation loss = 4.4448  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 1.6170  Validation loss = 4.4444  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 1.6169  Validation loss = 4.4441  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 1.6168  Validation loss = 4.4436  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 1.6167  Validation loss = 4.4435  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 1.6167  Validation loss = 4.4432  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 1.6165  Validation loss = 4.4425  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 1.6164  Validation loss = 4.4419  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 1.6163  Validation loss = 4.4416  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 1.6162  Validation loss = 4.4415  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 1.6161  Validation loss = 4.4410  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 1.6160  Validation loss = 4.4405  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 1.6159  Validation loss = 4.4399  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 1.6158  Validation loss = 4.4392  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 1.6156  Validation loss = 4.4383  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 1.6155  Validation loss = 4.4380  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 1.6153  Validation loss = 4.4371  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 1.6151  Validation loss = 4.4361  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 1.6150  Validation loss = 4.4356  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 1.6148  Validation loss = 4.4349  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 1.6148  Validation loss = 4.4346  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 1.6146  Validation loss = 4.4339  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 1.6145  Validation loss = 4.4335  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 1.6144  Validation loss = 4.4330  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 1.6143  Validation loss = 4.4327  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 1.6142  Validation loss = 4.4321  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 1.6141  Validation loss = 4.4317  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 1.6141  Validation loss = 4.4322  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 1.6141  Validation loss = 4.4317  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 1.6139  Validation loss = 4.4311  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 1.6138  Validation loss = 4.4308  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 1.6137  Validation loss = 4.4303  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 1.6136  Validation loss = 4.4299  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 1.6135  Validation loss = 4.4295  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 1.6134  Validation loss = 4.4289  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 1.6133  Validation loss = 4.4287  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 1.6133  Validation loss = 4.4285  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 1.6132  Validation loss = 4.4281  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 1.6130  Validation loss = 4.4275  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 1.6129  Validation loss = 4.4271  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 1.6128  Validation loss = 4.4263  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 1.6127  Validation loss = 4.4259  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 1.6126  Validation loss = 4.4257  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 1.6126  Validation loss = 4.4257  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 1.6125  Validation loss = 4.4249  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 1.6123  Validation loss = 4.4242  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 1.6121  Validation loss = 4.4234  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 1.6120  Validation loss = 4.4225  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 1.6119  Validation loss = 4.4221  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 1.6117  Validation loss = 4.4216  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 1.6116  Validation loss = 4.4211  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 1.6116  Validation loss = 4.4208  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 1.6115  Validation loss = 4.4208  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 1.6115  Validation loss = 4.4206  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 1.6114  Validation loss = 4.4203  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 1.6112  Validation loss = 4.4194  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 1.6111  Validation loss = 4.4189  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 1.6110  Validation loss = 4.4183  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 1.6109  Validation loss = 4.4179  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 1.6108  Validation loss = 4.4173  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 1.6107  Validation loss = 4.4174  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 1.6106  Validation loss = 4.4165  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 1.6105  Validation loss = 4.4160  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 1.6103  Validation loss = 4.4154  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 1.6102  Validation loss = 4.4149  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 1.6101  Validation loss = 4.4144  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 1.6100  Validation loss = 4.4142  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 1.6099  Validation loss = 4.4136  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 1.6098  Validation loss = 4.4131  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 1.6098  Validation loss = 4.4130  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 1.6097  Validation loss = 4.4124  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 1.6095  Validation loss = 4.4115  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 1.6094  Validation loss = 4.4112  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 1.6092  Validation loss = 4.4101  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 1.6091  Validation loss = 4.4097  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 1.6089  Validation loss = 4.4089  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 1.6088  Validation loss = 4.4085  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 1.6088  Validation loss = 4.4082  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 1.6087  Validation loss = 4.4078  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 1.6085  Validation loss = 4.4070  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 1.6085  Validation loss = 4.4066  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 1.6084  Validation loss = 4.4061  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 1.6082  Validation loss = 4.4055  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 1.6081  Validation loss = 4.4049  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 1.6080  Validation loss = 4.4044  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 1.6079  Validation loss = 4.4039  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 1.6078  Validation loss = 4.4038  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 1.6077  Validation loss = 4.4033  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 1.6076  Validation loss = 4.4027  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 1.6075  Validation loss = 4.4021  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 1.6073  Validation loss = 4.4011  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 1.6071  Validation loss = 4.4003  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 1.6070  Validation loss = 4.3995  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 1.6069  Validation loss = 4.3992  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 1.6068  Validation loss = 4.3987  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 1.6066  Validation loss = 4.3978  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 1.6065  Validation loss = 4.3972  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 1.6064  Validation loss = 4.3969  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 1.6063  Validation loss = 4.3963  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 1.6063  Validation loss = 4.3963  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 1.6062  Validation loss = 4.3958  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 1.6062  Validation loss = 4.3957  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 1.6061  Validation loss = 4.3953  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 1.6059  Validation loss = 4.3947  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 1.6058  Validation loss = 4.3942  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 1.6057  Validation loss = 4.3935  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 1.6055  Validation loss = 4.3927  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 1.6055  Validation loss = 4.3926  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 1.6054  Validation loss = 4.3925  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 1.6053  Validation loss = 4.3920  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 1.6052  Validation loss = 4.3915  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 1.6051  Validation loss = 4.3909  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 1.6051  Validation loss = 4.3908  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 1.6049  Validation loss = 4.3896  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 1.6048  Validation loss = 4.3894  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 1.6047  Validation loss = 4.3888  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 1.6045  Validation loss = 4.3879  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 1.6044  Validation loss = 4.3876  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 1.6043  Validation loss = 4.3869  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 1.6042  Validation loss = 4.3867  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 1.6042  Validation loss = 4.3867  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 1.6041  Validation loss = 4.3863  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 1.6041  Validation loss = 4.3862  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 1.6040  Validation loss = 4.3861  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 1.6040  Validation loss = 4.3860  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 1.6039  Validation loss = 4.3857  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 1.6038  Validation loss = 4.3854  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 1.6037  Validation loss = 4.3850  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 1.6035  Validation loss = 4.3840  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 1.6034  Validation loss = 4.3831  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 1.6033  Validation loss = 4.3827  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 1.6032  Validation loss = 4.3823  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 1.6030  Validation loss = 4.3814  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 1.6030  Validation loss = 4.3811  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 1.6028  Validation loss = 4.3802  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 1.6026  Validation loss = 4.3794  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 1.6025  Validation loss = 4.3787  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 1.6024  Validation loss = 4.3780  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 1.6023  Validation loss = 4.3778  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 1.6022  Validation loss = 4.3770  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 1.6020  Validation loss = 4.3761  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 1.6020  Validation loss = 4.3760  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 1.6019  Validation loss = 4.3756  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 1.6018  Validation loss = 4.3754  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 1.6017  Validation loss = 4.3748  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 1.6016  Validation loss = 4.3744  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 1.6015  Validation loss = 4.3738  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 1.6014  Validation loss = 4.3735  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 1.6014  Validation loss = 4.3736  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 1.6013  Validation loss = 4.3732  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 1.6012  Validation loss = 4.3729  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 1.6011  Validation loss = 4.3719  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 1.6010  Validation loss = 4.3717  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 1.6009  Validation loss = 4.3715  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 1.6008  Validation loss = 4.3708  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 1.6007  Validation loss = 4.3702  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 1.6006  Validation loss = 4.3699  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 1.6006  Validation loss = 4.3698  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 1.6005  Validation loss = 4.3693  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 1.6004  Validation loss = 4.3691  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 1.6002  Validation loss = 4.3682  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 1.6001  Validation loss = 4.3677  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 1.6000  Validation loss = 4.3672  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 1.6000  Validation loss = 4.3674  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 1.6000  Validation loss = 4.3675  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 1.5999  Validation loss = 4.3670  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 1.5998  Validation loss = 4.3663  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 1.5998  Validation loss = 4.3661  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 1.5996  Validation loss = 4.3654  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 1.5996  Validation loss = 4.3656  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 1.5995  Validation loss = 4.3649  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 1.5994  Validation loss = 4.3643  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 1.5993  Validation loss = 4.3639  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 1.5992  Validation loss = 4.3636  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 1.5991  Validation loss = 4.3631  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 1.5990  Validation loss = 4.3628  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 1.5989  Validation loss = 4.3621  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 1.5988  Validation loss = 4.3615  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 1.5987  Validation loss = 4.3608  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 1.5986  Validation loss = 4.3604  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 1.5985  Validation loss = 4.3599  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 1.5983  Validation loss = 4.3593  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 1.5983  Validation loss = 4.3593  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 1.5982  Validation loss = 4.3587  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 1.5981  Validation loss = 4.3583  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 1.5980  Validation loss = 4.3581  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 1.5980  Validation loss = 4.3581  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 1.5979  Validation loss = 4.3576  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 1.5978  Validation loss = 4.3569  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 1.5977  Validation loss = 4.3565  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 1.5976  Validation loss = 4.3559  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 1.5975  Validation loss = 4.3553  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 1.5974  Validation loss = 4.3548  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 1.5973  Validation loss = 4.3542  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 1.5972  Validation loss = 4.3539  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 1.5971  Validation loss = 4.3537  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 1.5970  Validation loss = 4.3533  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 1.5970  Validation loss = 4.3529  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 1.5968  Validation loss = 4.3517  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 1.5967  Validation loss = 4.3513  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 1.5967  Validation loss = 4.3511  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 1.5966  Validation loss = 4.3507  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 1.5965  Validation loss = 4.3502  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 1.5965  Validation loss = 4.3501  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 1.5964  Validation loss = 4.3500  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 1.5964  Validation loss = 4.3497  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 1.5963  Validation loss = 4.3496  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 1.5963  Validation loss = 4.3493  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 1.5962  Validation loss = 4.3493  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 1.5962  Validation loss = 4.3492  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 1.5962  Validation loss = 4.3490  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 1.5961  Validation loss = 4.3489  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 1.5960  Validation loss = 4.3481  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 1.5959  Validation loss = 4.3477  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 1.5958  Validation loss = 4.3471  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 1.5957  Validation loss = 4.3465  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 1.5955  Validation loss = 4.3456  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 1.5954  Validation loss = 4.3454  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 1.5953  Validation loss = 4.3449  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 1.5953  Validation loss = 4.3448  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 1.5952  Validation loss = 4.3443  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 1.5951  Validation loss = 4.3442  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 1.5950  Validation loss = 4.3434  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 1.5949  Validation loss = 4.3429  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 1.5948  Validation loss = 4.3427  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 1.5947  Validation loss = 4.3421  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 1.5946  Validation loss = 4.3415  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 1.5945  Validation loss = 4.3405  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 1.5944  Validation loss = 4.3401  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 1.5943  Validation loss = 4.3399  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 1.5943  Validation loss = 4.3397  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 1.5942  Validation loss = 4.3393  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 1.5940  Validation loss = 4.3385  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 1.5939  Validation loss = 4.3377  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 1.5939  Validation loss = 4.3376  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 1.5937  Validation loss = 4.3368  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 1.5936  Validation loss = 4.3361  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 1.5935  Validation loss = 4.3359  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 1.5935  Validation loss = 4.3356  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 1.5934  Validation loss = 4.3352  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 1.5934  Validation loss = 4.3355  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 1.5933  Validation loss = 4.3349  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 1.5931  Validation loss = 4.3338  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 1.5931  Validation loss = 4.3339  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 1.5930  Validation loss = 4.3339  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 1.5930  Validation loss = 4.3336  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 1.5929  Validation loss = 4.3332  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 1.5928  Validation loss = 4.3326  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 1.5928  Validation loss = 4.3329  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 1.5928  Validation loss = 4.3330  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 1.5927  Validation loss = 4.3329  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 1.5926  Validation loss = 4.3322  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 1.5925  Validation loss = 4.3316  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 1.5923  Validation loss = 4.3306  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 1.5922  Validation loss = 4.3299  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 1.5921  Validation loss = 4.3295  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 1.5921  Validation loss = 4.3293  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 1.5920  Validation loss = 4.3288  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 1.5919  Validation loss = 4.3285  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 1.5918  Validation loss = 4.3282  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 1.5918  Validation loss = 4.3282  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 1.5917  Validation loss = 4.3276  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 1.5915  Validation loss = 4.3266  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 1.5914  Validation loss = 4.3260  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 1.5913  Validation loss = 4.3255  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 1.5913  Validation loss = 4.3251  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 1.5911  Validation loss = 4.3241  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 1.5910  Validation loss = 4.3238  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 1.5910  Validation loss = 4.3235  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 1.5908  Validation loss = 4.3228  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 1.5908  Validation loss = 4.3225  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 1.5906  Validation loss = 4.3217  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 1.5905  Validation loss = 4.3213  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 1.5904  Validation loss = 4.3207  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 1.5904  Validation loss = 4.3205  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 1.5903  Validation loss = 4.3203  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 1.5902  Validation loss = 4.3197  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 1.5901  Validation loss = 4.3192  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 1.5900  Validation loss = 4.3188  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 1.5900  Validation loss = 4.3186  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 1.5899  Validation loss = 4.3182  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 1.5899  Validation loss = 4.3180  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 1.5898  Validation loss = 4.3175  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 1.5897  Validation loss = 4.3171  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 1.5896  Validation loss = 4.3168  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 1.5895  Validation loss = 4.3162  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 1.5894  Validation loss = 4.3157  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 1.5894  Validation loss = 4.3154  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 1.5894  Validation loss = 4.3156  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 1.5893  Validation loss = 4.3154  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 1.5892  Validation loss = 4.3153  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 1.5892  Validation loss = 4.3149  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 1.5891  Validation loss = 4.3144  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 1.5890  Validation loss = 4.3142  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 1.5889  Validation loss = 4.3137  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 1.5889  Validation loss = 4.3133  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 1.5888  Validation loss = 4.3130  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 1.5887  Validation loss = 4.3126  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 1.5886  Validation loss = 4.3117  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 1.5885  Validation loss = 4.3116  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 1.5884  Validation loss = 4.3108  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 1.5883  Validation loss = 4.3106  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 1.5883  Validation loss = 4.3104  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 1.5882  Validation loss = 4.3101  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 1.5882  Validation loss = 4.3101  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 1.5881  Validation loss = 4.3096  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 1.5880  Validation loss = 4.3092  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 1.5880  Validation loss = 4.3095  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 1.5879  Validation loss = 4.3089  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 1.5878  Validation loss = 4.3087  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 1.5878  Validation loss = 4.3086  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 1.5877  Validation loss = 4.3080  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 1.5876  Validation loss = 4.3078  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 1.5875  Validation loss = 4.3073  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 1.5875  Validation loss = 4.3073  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 1.5874  Validation loss = 4.3072  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 1.5874  Validation loss = 4.3069  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 1.5874  Validation loss = 4.3067  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 1.5873  Validation loss = 4.3062  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 1.5871  Validation loss = 4.3055  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 1.5871  Validation loss = 4.3052  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 1.5870  Validation loss = 4.3050  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 1.5870  Validation loss = 4.3046  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 1.5869  Validation loss = 4.3043  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 1.5868  Validation loss = 4.3042  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 1.5867  Validation loss = 4.3036  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 1.5866  Validation loss = 4.3030  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 1.5866  Validation loss = 4.3027  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 1.5866  Validation loss = 4.3028  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 1.5865  Validation loss = 4.3025  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 1.5865  Validation loss = 4.3026  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 1.5864  Validation loss = 4.3020  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 1.5863  Validation loss = 4.3014  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 1.5861  Validation loss = 4.3004  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 1.5860  Validation loss = 4.3000  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 1.5860  Validation loss = 4.2999  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 1.5859  Validation loss = 4.2994  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 1.5858  Validation loss = 4.2989  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 1.5858  Validation loss = 4.2985  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 1.5857  Validation loss = 4.2983  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 1.5856  Validation loss = 4.2977  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 1.5855  Validation loss = 4.2971  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 1.5854  Validation loss = 4.2965  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 1.5853  Validation loss = 4.2962  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 1.5853  Validation loss = 4.2959  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 1.5852  Validation loss = 4.2955  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 1.5851  Validation loss = 4.2954  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 1.5851  Validation loss = 4.2952  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 1.5851  Validation loss = 4.2950  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 1.5850  Validation loss = 4.2950  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 1.5849  Validation loss = 4.2946  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 1.5850  Validation loss = 4.2949  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 1.5849  Validation loss = 4.2946  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 1.5849  Validation loss = 4.2944  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 1.5848  Validation loss = 4.2938  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 1.5847  Validation loss = 4.2935  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 1.5846  Validation loss = 4.2934  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 1.5845  Validation loss = 4.2928  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 1.5845  Validation loss = 4.2924  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 1.5844  Validation loss = 4.2919  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 1.5843  Validation loss = 4.2918  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 1.5842  Validation loss = 4.2912  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 1.5842  Validation loss = 4.2909  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 1.5841  Validation loss = 4.2904  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 1.5840  Validation loss = 4.2900  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 1.5839  Validation loss = 4.2895  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 1.5839  Validation loss = 4.2894  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 1.5838  Validation loss = 4.2885  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 1.5837  Validation loss = 4.2881  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 1.5836  Validation loss = 4.2878  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 1.5837  Validation loss = 4.2883  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 1.5835  Validation loss = 4.2876  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 1.5835  Validation loss = 4.2871  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 1.5834  Validation loss = 4.2868  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 1.5834  Validation loss = 4.2865  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 1.5833  Validation loss = 4.2860  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 1.5832  Validation loss = 4.2860  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 1.5831  Validation loss = 4.2852  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 1.5831  Validation loss = 4.2849  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 1.5829  Validation loss = 4.2834  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 1.5828  Validation loss = 4.2835  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 1.5828  Validation loss = 4.2830  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 1.5827  Validation loss = 4.2827  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 1.5826  Validation loss = 4.2823  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 1.5826  Validation loss = 4.2821  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 500  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.8609  Validation loss = 4.1078  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.8605  Validation loss = 4.1067  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.8602  Validation loss = 4.1056  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.8599  Validation loss = 4.1048  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.8596  Validation loss = 4.1037  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.8591  Validation loss = 4.1022  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.8589  Validation loss = 4.1015  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.8585  Validation loss = 4.1003  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.8582  Validation loss = 4.0995  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.8580  Validation loss = 4.0987  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.8577  Validation loss = 4.0980  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.8575  Validation loss = 4.0973  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.8574  Validation loss = 4.0968  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.8571  Validation loss = 4.0958  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.8568  Validation loss = 4.0951  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.8568  Validation loss = 4.0949  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.8566  Validation loss = 4.0942  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.8564  Validation loss = 4.0936  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.8560  Validation loss = 4.0925  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.8558  Validation loss = 4.0914  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.8556  Validation loss = 4.0910  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.8554  Validation loss = 4.0901  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.8550  Validation loss = 4.0890  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.8549  Validation loss = 4.0887  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.8546  Validation loss = 4.0876  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.8542  Validation loss = 4.0862  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.8537  Validation loss = 4.0848  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.8535  Validation loss = 4.0841  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.8531  Validation loss = 4.0826  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.8528  Validation loss = 4.0816  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.8526  Validation loss = 4.0811  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.8525  Validation loss = 4.0810  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 1.8524  Validation loss = 4.0806  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 1.8522  Validation loss = 4.0798  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 1.8520  Validation loss = 4.0793  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 1.8516  Validation loss = 4.0782  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 1.8513  Validation loss = 4.0771  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 1.8510  Validation loss = 4.0759  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 1.8506  Validation loss = 4.0747  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 1.8503  Validation loss = 4.0736  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 1.8501  Validation loss = 4.0731  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 1.8498  Validation loss = 4.0720  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 1.8497  Validation loss = 4.0717  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 1.8494  Validation loss = 4.0708  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 1.8492  Validation loss = 4.0701  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 1.8491  Validation loss = 4.0696  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 1.8489  Validation loss = 4.0690  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 1.8487  Validation loss = 4.0683  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 1.8484  Validation loss = 4.0675  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 1.8483  Validation loss = 4.0670  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 1.8480  Validation loss = 4.0663  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 1.8478  Validation loss = 4.0657  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 1.8477  Validation loss = 4.0653  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 1.8475  Validation loss = 4.0647  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 1.8473  Validation loss = 4.0641  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 1.8471  Validation loss = 4.0635  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 1.8469  Validation loss = 4.0626  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 1.8466  Validation loss = 4.0619  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 1.8464  Validation loss = 4.0612  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 1.8461  Validation loss = 4.0603  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 1.8459  Validation loss = 4.0597  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 1.8457  Validation loss = 4.0586  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 1.8455  Validation loss = 4.0581  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 1.8453  Validation loss = 4.0573  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 1.8451  Validation loss = 4.0567  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 1.8448  Validation loss = 4.0560  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 1.8445  Validation loss = 4.0550  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 1.8443  Validation loss = 4.0543  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 1.8440  Validation loss = 4.0532  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 1.8437  Validation loss = 4.0522  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 1.8433  Validation loss = 4.0510  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 1.8431  Validation loss = 4.0504  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 1.8430  Validation loss = 4.0501  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 1.8426  Validation loss = 4.0488  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 1.8424  Validation loss = 4.0483  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 1.8422  Validation loss = 4.0474  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 1.8420  Validation loss = 4.0466  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 1.8417  Validation loss = 4.0456  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 1.8414  Validation loss = 4.0446  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 1.8411  Validation loss = 4.0435  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 1.8410  Validation loss = 4.0433  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 1.8407  Validation loss = 4.0423  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 1.8405  Validation loss = 4.0418  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 1.8403  Validation loss = 4.0411  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 1.8400  Validation loss = 4.0400  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 1.8397  Validation loss = 4.0388  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 1.8395  Validation loss = 4.0379  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 1.8394  Validation loss = 4.0377  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 1.8393  Validation loss = 4.0376  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 1.8391  Validation loss = 4.0367  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 1.8389  Validation loss = 4.0359  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 1.8385  Validation loss = 4.0346  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 1.8383  Validation loss = 4.0338  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 1.8380  Validation loss = 4.0326  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 1.8377  Validation loss = 4.0316  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 1.8374  Validation loss = 4.0305  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 1.8373  Validation loss = 4.0303  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 1.8371  Validation loss = 4.0295  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 1.8370  Validation loss = 4.0292  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 1.8368  Validation loss = 4.0286  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 1.8365  Validation loss = 4.0275  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 1.8363  Validation loss = 4.0270  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 1.8361  Validation loss = 4.0261  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 1.8357  Validation loss = 4.0249  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 1.8355  Validation loss = 4.0241  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 1.8353  Validation loss = 4.0236  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 1.8351  Validation loss = 4.0230  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 1.8351  Validation loss = 4.0228  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 1.8348  Validation loss = 4.0218  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 1.8346  Validation loss = 4.0212  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 1.8342  Validation loss = 4.0198  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 1.8341  Validation loss = 4.0196  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 1.8340  Validation loss = 4.0190  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 1.8336  Validation loss = 4.0179  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 1.8335  Validation loss = 4.0173  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 1.8333  Validation loss = 4.0166  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 1.8329  Validation loss = 4.0154  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 1.8326  Validation loss = 4.0145  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 1.8325  Validation loss = 4.0140  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 1.8322  Validation loss = 4.0130  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 1.8320  Validation loss = 4.0123  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 1.8318  Validation loss = 4.0117  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 1.8315  Validation loss = 4.0106  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 1.8313  Validation loss = 4.0099  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 1.8311  Validation loss = 4.0093  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 1.8310  Validation loss = 4.0089  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 1.8307  Validation loss = 4.0078  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 1.8302  Validation loss = 4.0062  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 1.8300  Validation loss = 4.0053  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 1.8298  Validation loss = 4.0047  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 1.8296  Validation loss = 4.0040  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 1.8294  Validation loss = 4.0034  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 1.8292  Validation loss = 4.0027  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 1.8289  Validation loss = 4.0017  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 1.8287  Validation loss = 4.0011  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 1.8286  Validation loss = 4.0007  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 1.8283  Validation loss = 3.9997  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 1.8280  Validation loss = 3.9987  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 1.8277  Validation loss = 3.9978  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 1.8275  Validation loss = 3.9972  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 1.8274  Validation loss = 3.9968  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 1.8273  Validation loss = 3.9967  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 1.8270  Validation loss = 3.9955  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 1.8267  Validation loss = 3.9945  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 1.8264  Validation loss = 3.9937  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 1.8263  Validation loss = 3.9931  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 1.8260  Validation loss = 3.9921  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 1.8258  Validation loss = 3.9914  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 1.8257  Validation loss = 3.9910  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 1.8255  Validation loss = 3.9905  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 1.8254  Validation loss = 3.9900  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 1.8252  Validation loss = 3.9896  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 1.8249  Validation loss = 3.9884  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 1.8246  Validation loss = 3.9873  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 1.8245  Validation loss = 3.9868  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 1.8242  Validation loss = 3.9858  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 1.8241  Validation loss = 3.9859  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 1.8240  Validation loss = 3.9854  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 1.8238  Validation loss = 3.9845  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 1.8235  Validation loss = 3.9836  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 1.8233  Validation loss = 3.9830  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 1.8231  Validation loss = 3.9824  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 1.8230  Validation loss = 3.9817  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 1.8228  Validation loss = 3.9811  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 1.8226  Validation loss = 3.9805  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 1.8225  Validation loss = 3.9803  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 1.8224  Validation loss = 3.9799  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 1.8222  Validation loss = 3.9793  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 1.8220  Validation loss = 3.9785  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 1.8219  Validation loss = 3.9780  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 1.8217  Validation loss = 3.9775  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 1.8215  Validation loss = 3.9765  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 1.8213  Validation loss = 3.9758  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 1.8211  Validation loss = 3.9749  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 1.8209  Validation loss = 3.9742  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 1.8208  Validation loss = 3.9738  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 1.8206  Validation loss = 3.9730  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 1.8205  Validation loss = 3.9727  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 1.8202  Validation loss = 3.9718  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 1.8200  Validation loss = 3.9711  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 1.8198  Validation loss = 3.9702  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 1.8197  Validation loss = 3.9699  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 1.8195  Validation loss = 3.9692  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 1.8193  Validation loss = 3.9683  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 1.8191  Validation loss = 3.9676  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 1.8191  Validation loss = 3.9675  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 1.8188  Validation loss = 3.9667  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 1.8186  Validation loss = 3.9658  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 1.8184  Validation loss = 3.9649  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 1.8181  Validation loss = 3.9639  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 1.8179  Validation loss = 3.9632  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 1.8176  Validation loss = 3.9623  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 1.8174  Validation loss = 3.9616  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 1.8172  Validation loss = 3.9610  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 1.8170  Validation loss = 3.9604  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 1.8168  Validation loss = 3.9596  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 1.8166  Validation loss = 3.9588  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 1.8164  Validation loss = 3.9583  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 1.8162  Validation loss = 3.9576  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 1.8160  Validation loss = 3.9566  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 1.8157  Validation loss = 3.9555  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 1.8155  Validation loss = 3.9545  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 1.8153  Validation loss = 3.9536  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 1.8151  Validation loss = 3.9530  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 1.8149  Validation loss = 3.9522  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 1.8146  Validation loss = 3.9508  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 1.8143  Validation loss = 3.9499  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 1.8142  Validation loss = 3.9492  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 1.8141  Validation loss = 3.9489  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 1.8138  Validation loss = 3.9479  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 1.8136  Validation loss = 3.9473  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 1.8135  Validation loss = 3.9469  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 1.8133  Validation loss = 3.9459  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 1.8130  Validation loss = 3.9451  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 1.8129  Validation loss = 3.9447  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 1.8126  Validation loss = 3.9436  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 1.8122  Validation loss = 3.9422  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 1.8121  Validation loss = 3.9418  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 1.8119  Validation loss = 3.9414  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 1.8117  Validation loss = 3.9407  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 1.8115  Validation loss = 3.9397  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 1.8112  Validation loss = 3.9385  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 1.8111  Validation loss = 3.9380  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 1.8110  Validation loss = 3.9376  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 1.8108  Validation loss = 3.9371  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 1.8106  Validation loss = 3.9363  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 1.8103  Validation loss = 3.9353  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 1.8101  Validation loss = 3.9344  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 1.8099  Validation loss = 3.9335  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 1.8097  Validation loss = 3.9329  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 1.8095  Validation loss = 3.9324  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 1.8094  Validation loss = 3.9320  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 1.8093  Validation loss = 3.9317  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 1.8093  Validation loss = 3.9315  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 1.8091  Validation loss = 3.9311  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 1.8089  Validation loss = 3.9300  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 1.8087  Validation loss = 3.9293  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 1.8085  Validation loss = 3.9285  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 1.8084  Validation loss = 3.9283  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 1.8083  Validation loss = 3.9277  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 1.8080  Validation loss = 3.9263  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 1.8078  Validation loss = 3.9256  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 1.8076  Validation loss = 3.9248  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 1.8073  Validation loss = 3.9240  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 1.8071  Validation loss = 3.9229  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 1.8069  Validation loss = 3.9225  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 1.8068  Validation loss = 3.9221  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 1.8067  Validation loss = 3.9218  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 1.8065  Validation loss = 3.9207  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 1.8063  Validation loss = 3.9204  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 1.8062  Validation loss = 3.9198  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 1.8059  Validation loss = 3.9185  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 1.8057  Validation loss = 3.9177  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 1.8055  Validation loss = 3.9173  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 1.8053  Validation loss = 3.9165  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 1.8051  Validation loss = 3.9158  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 1.8050  Validation loss = 3.9154  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 1.8049  Validation loss = 3.9150  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 1.8047  Validation loss = 3.9143  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 1.8045  Validation loss = 3.9131  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 1.8041  Validation loss = 3.9114  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 1.8040  Validation loss = 3.9111  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 1.8038  Validation loss = 3.9104  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 1.8036  Validation loss = 3.9096  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 1.8035  Validation loss = 3.9092  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 1.8033  Validation loss = 3.9084  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 1.8031  Validation loss = 3.9076  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 1.8030  Validation loss = 3.9071  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 1.8027  Validation loss = 3.9060  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 1.8024  Validation loss = 3.9048  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 1.8023  Validation loss = 3.9043  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 1.8020  Validation loss = 3.9029  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 1.8018  Validation loss = 3.9022  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 1.8017  Validation loss = 3.9016  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 1.8015  Validation loss = 3.9010  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 1.8012  Validation loss = 3.8998  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 1.8011  Validation loss = 3.8993  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 1.8008  Validation loss = 3.8984  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 1.8005  Validation loss = 3.8970  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 1.8004  Validation loss = 3.8966  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 1.8002  Validation loss = 3.8960  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 1.7999  Validation loss = 3.8947  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 1.7998  Validation loss = 3.8940  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 1.7996  Validation loss = 3.8931  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 1.7993  Validation loss = 3.8920  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 1.7991  Validation loss = 3.8915  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 1.7990  Validation loss = 3.8908  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 1.7987  Validation loss = 3.8899  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 1.7984  Validation loss = 3.8887  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 1.7983  Validation loss = 3.8880  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 1.7981  Validation loss = 3.8872  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 1.7979  Validation loss = 3.8866  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 1.7977  Validation loss = 3.8857  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 1.7975  Validation loss = 3.8849  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 1.7973  Validation loss = 3.8839  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 1.7970  Validation loss = 3.8828  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 1.7967  Validation loss = 3.8816  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 1.7965  Validation loss = 3.8806  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 1.7963  Validation loss = 3.8798  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 1.7962  Validation loss = 3.8794  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 1.7960  Validation loss = 3.8786  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 1.7959  Validation loss = 3.8781  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 1.7958  Validation loss = 3.8777  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 1.7956  Validation loss = 3.8771  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 1.7954  Validation loss = 3.8762  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 1.7953  Validation loss = 3.8757  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 1.7951  Validation loss = 3.8750  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 1.7949  Validation loss = 3.8742  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 1.7947  Validation loss = 3.8731  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 1.7946  Validation loss = 3.8731  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 1.7944  Validation loss = 3.8721  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 1.7943  Validation loss = 3.8717  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 1.7941  Validation loss = 3.8713  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 1.7939  Validation loss = 3.8702  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 1.7938  Validation loss = 3.8697  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 1.7936  Validation loss = 3.8689  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 1.7933  Validation loss = 3.8675  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 1.7932  Validation loss = 3.8670  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 1.7929  Validation loss = 3.8661  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 1.7927  Validation loss = 3.8651  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 1.7927  Validation loss = 3.8651  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 1.7925  Validation loss = 3.8645  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 1.7924  Validation loss = 3.8640  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 1.7922  Validation loss = 3.8635  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 1.7920  Validation loss = 3.8625  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 1.7919  Validation loss = 3.8617  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 1.7916  Validation loss = 3.8606  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 1.7914  Validation loss = 3.8597  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 1.7913  Validation loss = 3.8594  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 1.7912  Validation loss = 3.8589  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 1.7910  Validation loss = 3.8578  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 1.7907  Validation loss = 3.8568  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 1.7905  Validation loss = 3.8557  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 1.7904  Validation loss = 3.8551  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 1.7902  Validation loss = 3.8545  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 1.7901  Validation loss = 3.8541  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 1.7899  Validation loss = 3.8531  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 1.7897  Validation loss = 3.8525  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 1.7896  Validation loss = 3.8521  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 1.7895  Validation loss = 3.8520  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 1.7894  Validation loss = 3.8514  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 1.7892  Validation loss = 3.8502  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 1.7890  Validation loss = 3.8498  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 1.7890  Validation loss = 3.8497  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 1.7889  Validation loss = 3.8492  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 1.7886  Validation loss = 3.8482  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 1.7885  Validation loss = 3.8477  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 1.7883  Validation loss = 3.8471  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 1.7882  Validation loss = 3.8466  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 1.7881  Validation loss = 3.8463  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 1.7879  Validation loss = 3.8454  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 1.7878  Validation loss = 3.8451  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 1.7877  Validation loss = 3.8446  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 1.7876  Validation loss = 3.8442  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 1.7875  Validation loss = 3.8438  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 1.7872  Validation loss = 3.8428  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 1.7871  Validation loss = 3.8422  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 1.7869  Validation loss = 3.8417  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 1.7868  Validation loss = 3.8411  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 1.7866  Validation loss = 3.8402  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 1.7864  Validation loss = 3.8395  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 1.7863  Validation loss = 3.8392  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 1.7863  Validation loss = 3.8393  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 1.7861  Validation loss = 3.8383  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 1.7859  Validation loss = 3.8373  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 1.7858  Validation loss = 3.8369  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 1.7856  Validation loss = 3.8362  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 1.7855  Validation loss = 3.8355  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 1.7852  Validation loss = 3.8344  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 1.7851  Validation loss = 3.8338  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 1.7848  Validation loss = 3.8324  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 1.7846  Validation loss = 3.8315  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 1.7845  Validation loss = 3.8310  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 1.7843  Validation loss = 3.8304  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 1.7841  Validation loss = 3.8294  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 1.7840  Validation loss = 3.8290  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 1.7839  Validation loss = 3.8288  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 1.7838  Validation loss = 3.8282  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 1.7836  Validation loss = 3.8274  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 1.7835  Validation loss = 3.8272  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 1.7834  Validation loss = 3.8266  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 1.7833  Validation loss = 3.8265  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 1.7832  Validation loss = 3.8259  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 1.7830  Validation loss = 3.8254  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 1.7829  Validation loss = 3.8249  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 1.7828  Validation loss = 3.8244  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 1.7827  Validation loss = 3.8242  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 1.7826  Validation loss = 3.8237  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 1.7824  Validation loss = 3.8229  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 1.7823  Validation loss = 3.8227  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 1.7821  Validation loss = 3.8218  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 1.7819  Validation loss = 3.8211  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 1.7817  Validation loss = 3.8198  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 1.7816  Validation loss = 3.8196  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 1.7815  Validation loss = 3.8190  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 1.7814  Validation loss = 3.8189  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 1.7813  Validation loss = 3.8186  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 1.7813  Validation loss = 3.8185  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 1.7812  Validation loss = 3.8180  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 1.7810  Validation loss = 3.8173  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 1.7808  Validation loss = 3.8162  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 1.7807  Validation loss = 3.8161  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 1.7805  Validation loss = 3.8151  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 1.7803  Validation loss = 3.8144  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 1.7799  Validation loss = 3.8129  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 1.7798  Validation loss = 3.8123  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 1.7796  Validation loss = 3.8114  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 1.7795  Validation loss = 3.8109  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 1.7792  Validation loss = 3.8097  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 1.7791  Validation loss = 3.8092  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 1.7788  Validation loss = 3.8077  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 1.7786  Validation loss = 3.8067  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 1.7785  Validation loss = 3.8064  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 1.7783  Validation loss = 3.8056  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 1.7782  Validation loss = 3.8050  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 1.7780  Validation loss = 3.8046  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 1.7778  Validation loss = 3.8036  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 1.7777  Validation loss = 3.8028  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 1.7776  Validation loss = 3.8026  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 1.7773  Validation loss = 3.8013  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 1.7772  Validation loss = 3.8008  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 1.7770  Validation loss = 3.7998  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 1.7768  Validation loss = 3.7991  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 1.7767  Validation loss = 3.7986  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 1.7766  Validation loss = 3.7981  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 1.7764  Validation loss = 3.7976  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 1.7763  Validation loss = 3.7966  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 1.7761  Validation loss = 3.7959  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 1.7759  Validation loss = 3.7949  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 1.7757  Validation loss = 3.7941  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 1.7755  Validation loss = 3.7932  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 1.7754  Validation loss = 3.7925  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 1.7752  Validation loss = 3.7916  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 1.7750  Validation loss = 3.7908  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 1.7749  Validation loss = 3.7904  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 1.7746  Validation loss = 3.7890  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 1.7744  Validation loss = 3.7883  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 1.7741  Validation loss = 3.7869  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 1.7740  Validation loss = 3.7864  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 1.7739  Validation loss = 3.7860  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 1.7738  Validation loss = 3.7855  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 1.7736  Validation loss = 3.7849  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 1.7735  Validation loss = 3.7844  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 1.7733  Validation loss = 3.7834  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 1.7731  Validation loss = 3.7828  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 1.7730  Validation loss = 3.7822  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 1.7728  Validation loss = 3.7812  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 1.7727  Validation loss = 3.7809  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 1.7725  Validation loss = 3.7800  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 1.7724  Validation loss = 3.7796  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 1.7723  Validation loss = 3.7789  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 1.7721  Validation loss = 3.7783  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 1.7719  Validation loss = 3.7774  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 1.7717  Validation loss = 3.7761  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 1.7715  Validation loss = 3.7752  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 1.7712  Validation loss = 3.7741  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 1.7711  Validation loss = 3.7735  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 1.7709  Validation loss = 3.7725  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 1.7707  Validation loss = 3.7716  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 1.7705  Validation loss = 3.7707  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 1.7703  Validation loss = 3.7699  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 1.7702  Validation loss = 3.7693  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 1.7701  Validation loss = 3.7691  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 1.7700  Validation loss = 3.7685  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 1.7698  Validation loss = 3.7678  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 1.7696  Validation loss = 3.7668  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 1.7694  Validation loss = 3.7657  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 1.7693  Validation loss = 3.7653  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 1.7692  Validation loss = 3.7647  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 1.7691  Validation loss = 3.7643  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 1.7689  Validation loss = 3.7639  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 1.7688  Validation loss = 3.7631  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 1.7687  Validation loss = 3.7628  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 1.7685  Validation loss = 3.7620  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 1.7684  Validation loss = 3.7617  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 1.7684  Validation loss = 3.7615  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 1.7683  Validation loss = 3.7612  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 1.7682  Validation loss = 3.7606  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 1.7680  Validation loss = 3.7600  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 1.7679  Validation loss = 3.7594  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 1.7677  Validation loss = 3.7587  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 1.7676  Validation loss = 3.7583  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 1.7675  Validation loss = 3.7578  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 1.7674  Validation loss = 3.7575  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 1.7672  Validation loss = 3.7566  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 1.7671  Validation loss = 3.7560  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 1.7669  Validation loss = 3.7556  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 1.7668  Validation loss = 3.7550  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 1.7667  Validation loss = 3.7545  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 1.7665  Validation loss = 3.7536  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 1.7663  Validation loss = 3.7529  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 1.7662  Validation loss = 3.7523  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 1.7660  Validation loss = 3.7519  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 1.7660  Validation loss = 3.7518  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 1.7659  Validation loss = 3.7512  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 1.7657  Validation loss = 3.7505  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 1.7655  Validation loss = 3.7497  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 1.7655  Validation loss = 3.7493  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 1.7653  Validation loss = 3.7488  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 1.7652  Validation loss = 3.7484  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.9597  Validation loss = 1.5354  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.9592  Validation loss = 1.5342  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.9589  Validation loss = 1.5331  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.9583  Validation loss = 1.5317  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.9578  Validation loss = 1.5305  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.9574  Validation loss = 1.5294  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.9573  Validation loss = 1.5290  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.9569  Validation loss = 1.5281  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.9567  Validation loss = 1.5275  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.9562  Validation loss = 1.5260  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.9558  Validation loss = 1.5250  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.9552  Validation loss = 1.5236  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.9546  Validation loss = 1.5220  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 1.9542  Validation loss = 1.5208  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 1.9536  Validation loss = 1.5191  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 1.9531  Validation loss = 1.5179  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 1.9528  Validation loss = 1.5170  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 1.9525  Validation loss = 1.5160  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 1.9523  Validation loss = 1.5157  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 1.9518  Validation loss = 1.5144  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 1.9516  Validation loss = 1.5137  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 1.9511  Validation loss = 1.5123  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 1.9508  Validation loss = 1.5116  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 1.9504  Validation loss = 1.5104  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 1.9501  Validation loss = 1.5098  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 1.9497  Validation loss = 1.5086  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 1.9494  Validation loss = 1.5079  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 1.9491  Validation loss = 1.5073  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 1.9488  Validation loss = 1.5065  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 1.9485  Validation loss = 1.5058  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 1.9480  Validation loss = 1.5045  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 1.9478  Validation loss = 1.5041  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 1.9475  Validation loss = 1.5036  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 1.9471  Validation loss = 1.5026  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 1.9468  Validation loss = 1.5015  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 1.9462  Validation loss = 1.5000  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 1.9458  Validation loss = 1.4991  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 1.9455  Validation loss = 1.4983  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 1.9449  Validation loss = 1.4966  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 1.9447  Validation loss = 1.4958  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 1.9441  Validation loss = 1.4945  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 1.9440  Validation loss = 1.4943  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 1.9434  Validation loss = 1.4926  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 1.9431  Validation loss = 1.4918  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 1.9427  Validation loss = 1.4904  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 1.9423  Validation loss = 1.4894  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 1.9417  Validation loss = 1.4881  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 1.9412  Validation loss = 1.4867  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 1.9408  Validation loss = 1.4855  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 1.9405  Validation loss = 1.4846  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 1.9401  Validation loss = 1.4835  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 1.9398  Validation loss = 1.4828  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 1.9396  Validation loss = 1.4822  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 1.9394  Validation loss = 1.4818  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 1.9391  Validation loss = 1.4811  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 1.9388  Validation loss = 1.4801  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 1.9385  Validation loss = 1.4793  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 1.9381  Validation loss = 1.4781  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 1.9378  Validation loss = 1.4774  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 1.9376  Validation loss = 1.4768  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 1.9372  Validation loss = 1.4758  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 1.9368  Validation loss = 1.4749  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 1.9363  Validation loss = 1.4733  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 1.9359  Validation loss = 1.4721  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 1.9354  Validation loss = 1.4710  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 1.9349  Validation loss = 1.4696  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 1.9345  Validation loss = 1.4684  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 1.9341  Validation loss = 1.4676  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 1.9339  Validation loss = 1.4668  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 1.9334  Validation loss = 1.4656  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 1.9329  Validation loss = 1.4646  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 1.9327  Validation loss = 1.4639  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 1.9324  Validation loss = 1.4633  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 1.9322  Validation loss = 1.4629  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 1.9317  Validation loss = 1.4613  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 1.9312  Validation loss = 1.4600  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 1.9310  Validation loss = 1.4593  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 1.9305  Validation loss = 1.4581  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 1.9300  Validation loss = 1.4566  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 1.9297  Validation loss = 1.4559  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 1.9294  Validation loss = 1.4551  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 1.9290  Validation loss = 1.4540  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 1.9288  Validation loss = 1.4535  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 1.9284  Validation loss = 1.4526  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 1.9281  Validation loss = 1.4518  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 1.9278  Validation loss = 1.4511  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 1.9275  Validation loss = 1.4503  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 1.9272  Validation loss = 1.4496  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 1.9269  Validation loss = 1.4489  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 1.9267  Validation loss = 1.4484  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 1.9264  Validation loss = 1.4476  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 1.9260  Validation loss = 1.4466  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 1.9257  Validation loss = 1.4459  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 1.9255  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 1.9251  Validation loss = 1.4443  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 1.9246  Validation loss = 1.4430  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 1.9244  Validation loss = 1.4424  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 1.9241  Validation loss = 1.4415  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 1.9236  Validation loss = 1.4407  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 1.9231  Validation loss = 1.4394  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 1.9228  Validation loss = 1.4386  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 1.9226  Validation loss = 1.4381  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 1.9221  Validation loss = 1.4368  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 1.9216  Validation loss = 1.4354  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 1.9212  Validation loss = 1.4345  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 1.9209  Validation loss = 1.4340  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 1.9206  Validation loss = 1.4330  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 1.9203  Validation loss = 1.4325  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 1.9200  Validation loss = 1.4317  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 1.9198  Validation loss = 1.4313  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 1.9195  Validation loss = 1.4303  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 1.9190  Validation loss = 1.4292  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 1.9188  Validation loss = 1.4285  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 1.9183  Validation loss = 1.4273  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 1.9179  Validation loss = 1.4262  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 1.9175  Validation loss = 1.4252  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 1.9173  Validation loss = 1.4245  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 1.9170  Validation loss = 1.4237  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 1.9167  Validation loss = 1.4230  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 1.9162  Validation loss = 1.4217  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 1.9159  Validation loss = 1.4207  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 1.9153  Validation loss = 1.4189  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 1.9151  Validation loss = 1.4186  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 1.9147  Validation loss = 1.4175  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 1.9143  Validation loss = 1.4164  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 1.9140  Validation loss = 1.4154  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 1.9137  Validation loss = 1.4144  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 1.9133  Validation loss = 1.4134  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 1.9131  Validation loss = 1.4131  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 1.9128  Validation loss = 1.4125  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 1.9126  Validation loss = 1.4121  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 1.9123  Validation loss = 1.4113  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 1.9122  Validation loss = 1.4110  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 1.9118  Validation loss = 1.4101  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 1.9114  Validation loss = 1.4090  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 1.9112  Validation loss = 1.4082  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 1.9107  Validation loss = 1.4069  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 1.9105  Validation loss = 1.4063  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 1.9102  Validation loss = 1.4058  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 1.9099  Validation loss = 1.4051  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 1.9096  Validation loss = 1.4042  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 1.9095  Validation loss = 1.4042  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 1.9091  Validation loss = 1.4033  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 1.9089  Validation loss = 1.4025  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 1.9085  Validation loss = 1.4015  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 1.9082  Validation loss = 1.4007  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 1.9078  Validation loss = 1.3998  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 1.9076  Validation loss = 1.3992  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 1.9071  Validation loss = 1.3980  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 1.9069  Validation loss = 1.3977  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 1.9065  Validation loss = 1.3966  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 1.9062  Validation loss = 1.3960  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 1.9058  Validation loss = 1.3947  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 1.9055  Validation loss = 1.3940  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 1.9053  Validation loss = 1.3935  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 1.9050  Validation loss = 1.3927  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 1.9046  Validation loss = 1.3915  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 1.9043  Validation loss = 1.3908  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 1.9039  Validation loss = 1.3894  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 1.9034  Validation loss = 1.3882  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 1.9030  Validation loss = 1.3872  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 1.9027  Validation loss = 1.3865  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 1.9025  Validation loss = 1.3861  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 1.9021  Validation loss = 1.3851  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 1.9019  Validation loss = 1.3846  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 1.9015  Validation loss = 1.3834  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 1.9011  Validation loss = 1.3825  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 1.9009  Validation loss = 1.3821  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 1.9006  Validation loss = 1.3812  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 1.9002  Validation loss = 1.3802  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 1.9001  Validation loss = 1.3800  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 1.8999  Validation loss = 1.3794  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 1.8996  Validation loss = 1.3791  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 1.8993  Validation loss = 1.3783  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 1.8989  Validation loss = 1.3773  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 1.8987  Validation loss = 1.3769  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 1.8984  Validation loss = 1.3762  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 1.8981  Validation loss = 1.3753  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 1.8978  Validation loss = 1.3749  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 1.8974  Validation loss = 1.3739  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 1.8972  Validation loss = 1.3734  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 1.8970  Validation loss = 1.3730  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 1.8968  Validation loss = 1.3727  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 1.8964  Validation loss = 1.3716  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 1.8961  Validation loss = 1.3707  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 1.8959  Validation loss = 1.3702  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 1.8954  Validation loss = 1.3686  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 1.8951  Validation loss = 1.3678  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 1.8949  Validation loss = 1.3677  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 1.8946  Validation loss = 1.3672  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 1.8944  Validation loss = 1.3670  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 1.8941  Validation loss = 1.3665  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 1.8938  Validation loss = 1.3656  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 1.8936  Validation loss = 1.3652  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 1.8933  Validation loss = 1.3646  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 1.8930  Validation loss = 1.3638  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 1.8928  Validation loss = 1.3633  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 1.8923  Validation loss = 1.3623  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 1.8920  Validation loss = 1.3614  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 1.8917  Validation loss = 1.3607  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 1.8915  Validation loss = 1.3601  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 1.8912  Validation loss = 1.3593  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 1.8909  Validation loss = 1.3585  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 1.8906  Validation loss = 1.3579  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 1.8902  Validation loss = 1.3570  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 1.8900  Validation loss = 1.3568  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 1.8897  Validation loss = 1.3563  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 1.8893  Validation loss = 1.3553  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 1.8890  Validation loss = 1.3547  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 1.8887  Validation loss = 1.3540  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 1.8883  Validation loss = 1.3529  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 1.8880  Validation loss = 1.3522  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 1.8875  Validation loss = 1.3508  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 1.8872  Validation loss = 1.3501  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 1.8870  Validation loss = 1.3496  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 1.8866  Validation loss = 1.3486  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 1.8863  Validation loss = 1.3478  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 1.8860  Validation loss = 1.3470  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 1.8856  Validation loss = 1.3463  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 1.8854  Validation loss = 1.3462  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 1.8852  Validation loss = 1.3459  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 1.8849  Validation loss = 1.3451  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 1.8845  Validation loss = 1.3441  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 1.8843  Validation loss = 1.3433  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 1.8840  Validation loss = 1.3423  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 1.8837  Validation loss = 1.3416  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 1.8834  Validation loss = 1.3410  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 1.8832  Validation loss = 1.3406  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 1.8829  Validation loss = 1.3397  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 1.8827  Validation loss = 1.3395  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 1.8825  Validation loss = 1.3389  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 1.8822  Validation loss = 1.3380  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 1.8819  Validation loss = 1.3373  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 1.8814  Validation loss = 1.3362  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 1.8811  Validation loss = 1.3355  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 1.8808  Validation loss = 1.3347  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 1.8806  Validation loss = 1.3343  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 1.8805  Validation loss = 1.3339  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 1.8801  Validation loss = 1.3331  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 1.8797  Validation loss = 1.3320  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 1.8794  Validation loss = 1.3314  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 1.8793  Validation loss = 1.3313  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 1.8789  Validation loss = 1.3302  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 1.8786  Validation loss = 1.3294  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 1.8782  Validation loss = 1.3283  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 1.8781  Validation loss = 1.3281  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 1.8776  Validation loss = 1.3268  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 1.8773  Validation loss = 1.3258  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 1.8770  Validation loss = 1.3253  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 1.8768  Validation loss = 1.3245  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 1.8763  Validation loss = 1.3234  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 1.8760  Validation loss = 1.3227  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 1.8757  Validation loss = 1.3222  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 1.8755  Validation loss = 1.3215  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 1.8753  Validation loss = 1.3209  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 1.8749  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 1.8746  Validation loss = 1.3192  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 1.8742  Validation loss = 1.3181  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 1.8739  Validation loss = 1.3173  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 1.8737  Validation loss = 1.3167  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 1.8734  Validation loss = 1.3161  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 1.8733  Validation loss = 1.3158  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 1.8731  Validation loss = 1.3157  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 1.8729  Validation loss = 1.3152  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 1.8726  Validation loss = 1.3144  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 1.8722  Validation loss = 1.3132  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 1.8720  Validation loss = 1.3132  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 1.8717  Validation loss = 1.3122  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 1.8713  Validation loss = 1.3112  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 1.8710  Validation loss = 1.3104  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 1.8707  Validation loss = 1.3097  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 1.8705  Validation loss = 1.3092  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 1.8701  Validation loss = 1.3082  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 1.8697  Validation loss = 1.3072  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 1.8696  Validation loss = 1.3072  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 1.8693  Validation loss = 1.3061  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 1.8689  Validation loss = 1.3052  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 1.8686  Validation loss = 1.3045  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 1.8682  Validation loss = 1.3035  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 1.8679  Validation loss = 1.3027  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 1.8676  Validation loss = 1.3021  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 1.8673  Validation loss = 1.3017  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 1.8671  Validation loss = 1.3010  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 1.8668  Validation loss = 1.3006  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 1.8666  Validation loss = 1.3000  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 1.8663  Validation loss = 1.2992  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 1.8660  Validation loss = 1.2986  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 1.8657  Validation loss = 1.2977  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 1.8656  Validation loss = 1.2976  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 1.8652  Validation loss = 1.2963  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 1.8648  Validation loss = 1.2953  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 1.8645  Validation loss = 1.2947  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 1.8643  Validation loss = 1.2941  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 1.8641  Validation loss = 1.2935  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 1.8638  Validation loss = 1.2931  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 1.8636  Validation loss = 1.2927  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 1.8634  Validation loss = 1.2921  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 1.8630  Validation loss = 1.2908  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 1.8627  Validation loss = 1.2905  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 1.8624  Validation loss = 1.2896  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 1.8620  Validation loss = 1.2886  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 1.8618  Validation loss = 1.2884  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 1.8617  Validation loss = 1.2884  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 1.8614  Validation loss = 1.2875  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 1.8610  Validation loss = 1.2866  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 1.8608  Validation loss = 1.2862  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 1.8604  Validation loss = 1.2855  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 1.8602  Validation loss = 1.2851  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 1.8599  Validation loss = 1.2844  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 1.8596  Validation loss = 1.2836  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 1.8594  Validation loss = 1.2830  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 1.8590  Validation loss = 1.2820  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 1.8587  Validation loss = 1.2816  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 1.8585  Validation loss = 1.2812  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 1.8584  Validation loss = 1.2813  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 1.8582  Validation loss = 1.2809  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 1.8582  Validation loss = 1.2811  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 1.8578  Validation loss = 1.2801  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 1.8577  Validation loss = 1.2799  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 1.8575  Validation loss = 1.2795  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 1.8572  Validation loss = 1.2790  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 1.8569  Validation loss = 1.2783  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 1.8567  Validation loss = 1.2778  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 1.8564  Validation loss = 1.2770  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 1.8562  Validation loss = 1.2766  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 1.8560  Validation loss = 1.2758  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 1.8556  Validation loss = 1.2746  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 1.8553  Validation loss = 1.2741  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 1.8550  Validation loss = 1.2732  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 1.8549  Validation loss = 1.2732  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 1.8545  Validation loss = 1.2721  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 1.8541  Validation loss = 1.2710  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 1.8538  Validation loss = 1.2701  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 1.8534  Validation loss = 1.2692  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 1.8532  Validation loss = 1.2685  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 1.8530  Validation loss = 1.2684  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 1.8528  Validation loss = 1.2679  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 1.8525  Validation loss = 1.2675  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 1.8521  Validation loss = 1.2666  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 1.8518  Validation loss = 1.2657  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 1.8514  Validation loss = 1.2649  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 1.8512  Validation loss = 1.2643  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 1.8507  Validation loss = 1.2631  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 1.8505  Validation loss = 1.2626  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 1.8501  Validation loss = 1.2617  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 1.8498  Validation loss = 1.2610  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 1.8496  Validation loss = 1.2604  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 1.8492  Validation loss = 1.2595  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 1.8488  Validation loss = 1.2580  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 1.8487  Validation loss = 1.2581  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 1.8486  Validation loss = 1.2578  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 1.8483  Validation loss = 1.2572  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 1.8480  Validation loss = 1.2565  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 1.8478  Validation loss = 1.2559  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 1.8475  Validation loss = 1.2551  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 1.8471  Validation loss = 1.2540  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 1.8468  Validation loss = 1.2533  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 1.8464  Validation loss = 1.2523  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 1.8462  Validation loss = 1.2519  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 1.8459  Validation loss = 1.2512  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 1.8455  Validation loss = 1.2504  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 1.8451  Validation loss = 1.2496  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 1.8449  Validation loss = 1.2492  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 1.8446  Validation loss = 1.2487  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 1.8444  Validation loss = 1.2481  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 1.8441  Validation loss = 1.2474  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 1.8437  Validation loss = 1.2465  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 1.8434  Validation loss = 1.2457  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 1.8431  Validation loss = 1.2450  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 1.8428  Validation loss = 1.2445  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 1.8425  Validation loss = 1.2437  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 1.8422  Validation loss = 1.2432  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 1.8419  Validation loss = 1.2424  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 1.8417  Validation loss = 1.2417  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 1.8414  Validation loss = 1.2411  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 1.8411  Validation loss = 1.2405  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 1.8407  Validation loss = 1.2396  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 1.8405  Validation loss = 1.2392  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 1.8401  Validation loss = 1.2383  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 1.8398  Validation loss = 1.2373  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 1.8395  Validation loss = 1.2367  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 1.8394  Validation loss = 1.2368  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 1.8392  Validation loss = 1.2365  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 1.8390  Validation loss = 1.2358  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 1.8388  Validation loss = 1.2356  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 1.8386  Validation loss = 1.2350  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 1.8382  Validation loss = 1.2342  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 1.8380  Validation loss = 1.2337  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 1.8378  Validation loss = 1.2334  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 1.8375  Validation loss = 1.2323  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 1.8372  Validation loss = 1.2320  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 1.8370  Validation loss = 1.2317  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 1.8367  Validation loss = 1.2312  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 1.8366  Validation loss = 1.2307  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 1.8363  Validation loss = 1.2300  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 1.8360  Validation loss = 1.2297  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 1.8357  Validation loss = 1.2289  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 1.8355  Validation loss = 1.2285  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 1.8353  Validation loss = 1.2286  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 1.8350  Validation loss = 1.2277  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 1.8348  Validation loss = 1.2272  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 1.8347  Validation loss = 1.2269  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 1.8343  Validation loss = 1.2262  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 1.8341  Validation loss = 1.2255  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 1.8338  Validation loss = 1.2248  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 1.8333  Validation loss = 1.2237  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 1.8331  Validation loss = 1.2229  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 1.8329  Validation loss = 1.2226  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 1.8327  Validation loss = 1.2223  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 1.8324  Validation loss = 1.2216  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 1.8321  Validation loss = 1.2207  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 1.8318  Validation loss = 1.2203  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 1.8315  Validation loss = 1.2195  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 1.8313  Validation loss = 1.2193  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 1.8311  Validation loss = 1.2192  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 1.8309  Validation loss = 1.2186  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 1.8306  Validation loss = 1.2180  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 1.8305  Validation loss = 1.2180  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 1.8304  Validation loss = 1.2177  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 1.8301  Validation loss = 1.2174  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 1.8299  Validation loss = 1.2169  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 1.8297  Validation loss = 1.2166  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 1.8295  Validation loss = 1.2160  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 1.8292  Validation loss = 1.2152  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 1.8289  Validation loss = 1.2148  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 1.8287  Validation loss = 1.2145  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 1.8283  Validation loss = 1.2139  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 1.8281  Validation loss = 1.2135  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 1.8279  Validation loss = 1.2135  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 1.8276  Validation loss = 1.2128  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 1.8274  Validation loss = 1.2124  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 1.8272  Validation loss = 1.2123  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 1.8270  Validation loss = 1.2120  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 1.8269  Validation loss = 1.2118  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 1.8268  Validation loss = 1.2118  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 1.8265  Validation loss = 1.2116  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 1.8263  Validation loss = 1.2112  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 1.8261  Validation loss = 1.2109  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 1.8257  Validation loss = 1.2103  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 1.8255  Validation loss = 1.2096  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 1.8253  Validation loss = 1.2094  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 1.8250  Validation loss = 1.2083  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 1.8247  Validation loss = 1.2076  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 1.8244  Validation loss = 1.2071  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 1.8242  Validation loss = 1.2070  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 1.8239  Validation loss = 1.2062  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 1.8236  Validation loss = 1.2056  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 1.8233  Validation loss = 1.2047  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 1.8231  Validation loss = 1.2043  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 1.8229  Validation loss = 1.2045  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 1.8228  Validation loss = 1.2048  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 1.8225  Validation loss = 1.2042  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 1.8222  Validation loss = 1.2038  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 1.8220  Validation loss = 1.2033  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 1.8216  Validation loss = 1.2027  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 1.8214  Validation loss = 1.2020  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 1.8212  Validation loss = 1.2020  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 1.8210  Validation loss = 1.2018  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 1.8209  Validation loss = 1.2014  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 1.8207  Validation loss = 1.2012  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 1.8204  Validation loss = 1.2008  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 1.8203  Validation loss = 1.2007  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 1.8200  Validation loss = 1.2002  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 1.8197  Validation loss = 1.1997  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 1.8193  Validation loss = 1.1987  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 1.8190  Validation loss = 1.1982  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 1.8187  Validation loss = 1.1979  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 1.8185  Validation loss = 1.1976  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 1.8183  Validation loss = 1.1971  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 1.8180  Validation loss = 1.1963  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 1.8177  Validation loss = 1.1955  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 1.8175  Validation loss = 1.1950  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 1.8172  Validation loss = 1.1941  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 1.8167  Validation loss = 1.1931  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 1.8165  Validation loss = 1.1927  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 1.8163  Validation loss = 1.1923  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 1.8160  Validation loss = 1.1915  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 1.8156  Validation loss = 1.1901  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 1.8153  Validation loss = 1.1896  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 1.8150  Validation loss = 1.1890  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 1.8147  Validation loss = 1.1883  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 1.8144  Validation loss = 1.1877  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 1.8141  Validation loss = 1.1871  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 1.8138  Validation loss = 1.1867  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 1.8136  Validation loss = 1.1864  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 1.8133  Validation loss = 1.1859  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 1.8130  Validation loss = 1.1849  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 1.8128  Validation loss = 1.1845  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 1.8125  Validation loss = 1.1841  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 1.8123  Validation loss = 1.1838  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 1.8119  Validation loss = 1.1830  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 1.8116  Validation loss = 1.1825  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 1.8113  Validation loss = 1.1818  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 1.8109  Validation loss = 1.1809  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 1.8107  Validation loss = 1.1805  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 1.8104  Validation loss = 1.1799  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 1.8100  Validation loss = 1.1791  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 1.8097  Validation loss = 1.1782  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 1.8093  Validation loss = 1.1773  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 1.8091  Validation loss = 1.1770  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.7444  Validation loss = 1.0985  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.7440  Validation loss = 1.0978  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.7438  Validation loss = 1.0975  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.7434  Validation loss = 1.0967  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.7430  Validation loss = 1.0959  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.7429  Validation loss = 1.0960  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.7426  Validation loss = 1.0956  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.7424  Validation loss = 1.0953  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.7417  Validation loss = 1.0941  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.7413  Validation loss = 1.0934  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.7409  Validation loss = 1.0927  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.7406  Validation loss = 1.0920  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.7402  Validation loss = 1.0913  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.7399  Validation loss = 1.0907  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.7394  Validation loss = 1.0898  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.7390  Validation loss = 1.0889  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.7386  Validation loss = 1.0884  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.7384  Validation loss = 1.0884  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.7383  Validation loss = 1.0881  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.7379  Validation loss = 1.0877  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 1.7375  Validation loss = 1.0869  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 1.7372  Validation loss = 1.0865  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 1.7368  Validation loss = 1.0857  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 1.7362  Validation loss = 1.0847  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 1.7357  Validation loss = 1.0838  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 1.7354  Validation loss = 1.0830  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 1.7351  Validation loss = 1.0826  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 1.7347  Validation loss = 1.0820  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 1.7343  Validation loss = 1.0814  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 1.7339  Validation loss = 1.0808  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 1.7336  Validation loss = 1.0803  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 1.7333  Validation loss = 1.0799  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 1.7328  Validation loss = 1.0792  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 1.7326  Validation loss = 1.0789  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 1.7324  Validation loss = 1.0787  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 1.7320  Validation loss = 1.0781  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 1.7314  Validation loss = 1.0769  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 1.7310  Validation loss = 1.0762  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 1.7307  Validation loss = 1.0757  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 1.7303  Validation loss = 1.0752  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 1.7301  Validation loss = 1.0749  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 1.7298  Validation loss = 1.0744  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 1.7294  Validation loss = 1.0739  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 1.7291  Validation loss = 1.0733  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 1.7284  Validation loss = 1.0720  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 1.7278  Validation loss = 1.0711  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 1.7275  Validation loss = 1.0710  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 1.7272  Validation loss = 1.0706  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 1.7268  Validation loss = 1.0701  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 1.7264  Validation loss = 1.0696  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 1.7259  Validation loss = 1.0687  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 1.7255  Validation loss = 1.0681  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 1.7252  Validation loss = 1.0675  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 1.7250  Validation loss = 1.0673  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 1.7245  Validation loss = 1.0665  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 1.7242  Validation loss = 1.0660  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 1.7237  Validation loss = 1.0653  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 1.7234  Validation loss = 1.0648  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 1.7232  Validation loss = 1.0646  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 1.7227  Validation loss = 1.0640  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 1.7223  Validation loss = 1.0633  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 1.7219  Validation loss = 1.0626  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 1.7216  Validation loss = 1.0621  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 1.7213  Validation loss = 1.0618  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 1.7209  Validation loss = 1.0615  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 1.7206  Validation loss = 1.0608  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 1.7204  Validation loss = 1.0603  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 1.7198  Validation loss = 1.0597  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 1.7194  Validation loss = 1.0595  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 1.7187  Validation loss = 1.0586  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 1.7184  Validation loss = 1.0581  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 1.7180  Validation loss = 1.0579  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 1.7176  Validation loss = 1.0574  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 1.7174  Validation loss = 1.0571  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 1.7168  Validation loss = 1.0561  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 1.7163  Validation loss = 1.0551  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 1.7157  Validation loss = 1.0544  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 1.7150  Validation loss = 1.0533  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 1.7148  Validation loss = 1.0535  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 1.7143  Validation loss = 1.0528  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 1.7141  Validation loss = 1.0525  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 1.7138  Validation loss = 1.0520  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 1.7135  Validation loss = 1.0515  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 1.7130  Validation loss = 1.0510  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 1.7128  Validation loss = 1.0508  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 1.7123  Validation loss = 1.0500  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 1.7118  Validation loss = 1.0494  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 1.7115  Validation loss = 1.0489  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 1.7112  Validation loss = 1.0484  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 1.7108  Validation loss = 1.0479  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 1.7104  Validation loss = 1.0475  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 1.7102  Validation loss = 1.0473  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 1.7100  Validation loss = 1.0476  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 1.7093  Validation loss = 1.0467  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 1.7092  Validation loss = 1.0468  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 1.7088  Validation loss = 1.0464  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 1.7083  Validation loss = 1.0455  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 1.7079  Validation loss = 1.0448  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 1.7074  Validation loss = 1.0440  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 1.7066  Validation loss = 1.0433  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 1.7063  Validation loss = 1.0428  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 1.7059  Validation loss = 1.0424  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 1.7054  Validation loss = 1.0416  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 1.7048  Validation loss = 1.0409  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 1.7042  Validation loss = 1.0401  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 1.7037  Validation loss = 1.0394  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 1.7033  Validation loss = 1.0390  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 1.7027  Validation loss = 1.0380  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 1.7025  Validation loss = 1.0376  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 1.7018  Validation loss = 1.0368  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 1.7013  Validation loss = 1.0361  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 1.7005  Validation loss = 1.0352  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 1.7001  Validation loss = 1.0349  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 1.6994  Validation loss = 1.0337  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 1.6991  Validation loss = 1.0333  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 1.6987  Validation loss = 1.0332  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 1.6984  Validation loss = 1.0331  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 1.6982  Validation loss = 1.0329  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 1.6979  Validation loss = 1.0327  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 1.6976  Validation loss = 1.0329  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 1.6972  Validation loss = 1.0323  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 1.6968  Validation loss = 1.0322  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 1.6963  Validation loss = 1.0314  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 1.6959  Validation loss = 1.0312  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 1.6955  Validation loss = 1.0303  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 1.6951  Validation loss = 1.0297  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 1.6949  Validation loss = 1.0297  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 1.6946  Validation loss = 1.0291  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 1.6943  Validation loss = 1.0287  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 1.6940  Validation loss = 1.0286  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 1.6937  Validation loss = 1.0279  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 1.6932  Validation loss = 1.0276  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 1.6927  Validation loss = 1.0269  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 1.6922  Validation loss = 1.0262  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 1.6916  Validation loss = 1.0255  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 1.6911  Validation loss = 1.0249  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 1.6906  Validation loss = 1.0244  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 1.6900  Validation loss = 1.0237  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 1.6896  Validation loss = 1.0233  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 1.6894  Validation loss = 1.0232  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 1.6889  Validation loss = 1.0224  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 1.6887  Validation loss = 1.0222  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 1.6882  Validation loss = 1.0216  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 1.6879  Validation loss = 1.0214  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 1.6873  Validation loss = 1.0210  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 1.6872  Validation loss = 1.0213  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 1.6868  Validation loss = 1.0212  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 1.6863  Validation loss = 1.0204  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 1.6859  Validation loss = 1.0200  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 1.6855  Validation loss = 1.0192  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 1.6848  Validation loss = 1.0184  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 1.6841  Validation loss = 1.0175  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 1.6837  Validation loss = 1.0174  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 1.6833  Validation loss = 1.0168  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 1.6828  Validation loss = 1.0160  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 1.6822  Validation loss = 1.0154  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 1.6819  Validation loss = 1.0150  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 1.6817  Validation loss = 1.0148  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 1.6814  Validation loss = 1.0146  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 1.6809  Validation loss = 1.0140  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 1.6805  Validation loss = 1.0136  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 1.6801  Validation loss = 1.0133  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 1.6797  Validation loss = 1.0126  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 1.6795  Validation loss = 1.0124  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 1.6792  Validation loss = 1.0123  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 1.6791  Validation loss = 1.0122  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 1.6788  Validation loss = 1.0118  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 1.6781  Validation loss = 1.0111  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 1.6777  Validation loss = 1.0106  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 1.6774  Validation loss = 1.0105  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 1.6768  Validation loss = 1.0096  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 1.6764  Validation loss = 1.0092  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 1.6759  Validation loss = 1.0090  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 1.6759  Validation loss = 1.0091  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 1.6756  Validation loss = 1.0086  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 1.6754  Validation loss = 1.0085  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 1.6750  Validation loss = 1.0078  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 1.6746  Validation loss = 1.0074  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 1.6743  Validation loss = 1.0070  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 1.6740  Validation loss = 1.0070  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 1.6736  Validation loss = 1.0062  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 1.6732  Validation loss = 1.0056  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 1.6727  Validation loss = 1.0051  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 1.6724  Validation loss = 1.0046  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 1.6720  Validation loss = 1.0040  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 1.6716  Validation loss = 1.0035  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 1.6713  Validation loss = 1.0030  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 1.6711  Validation loss = 1.0030  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 1.6709  Validation loss = 1.0028  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 1.6706  Validation loss = 1.0024  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 1.6703  Validation loss = 1.0017  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 1.6699  Validation loss = 1.0015  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 1.6697  Validation loss = 1.0011  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 1.6694  Validation loss = 1.0005  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 1.6691  Validation loss = 1.0001  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 1.6687  Validation loss = 0.9994  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 1.6683  Validation loss = 0.9986  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 1.6680  Validation loss = 0.9983  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 1.6677  Validation loss = 0.9976  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 1.6675  Validation loss = 0.9976  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 1.6673  Validation loss = 0.9975  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 1.6670  Validation loss = 0.9969  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 1.6665  Validation loss = 0.9959  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 1.6663  Validation loss = 0.9957  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 1.6660  Validation loss = 0.9952  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 1.6657  Validation loss = 0.9947  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 1.6654  Validation loss = 0.9945  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 1.6650  Validation loss = 0.9940  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 1.6644  Validation loss = 0.9931  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 1.6642  Validation loss = 0.9928  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 1.6639  Validation loss = 0.9923  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 1.6636  Validation loss = 0.9921  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 1.6633  Validation loss = 0.9915  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 1.6629  Validation loss = 0.9909  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 1.6624  Validation loss = 0.9902  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 1.6622  Validation loss = 0.9898  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 1.6620  Validation loss = 0.9900  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 1.6617  Validation loss = 0.9895  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 1.6615  Validation loss = 0.9893  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 1.6613  Validation loss = 0.9891  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 1.6610  Validation loss = 0.9886  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 1.6609  Validation loss = 0.9887  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 1.6606  Validation loss = 0.9880  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 1.6605  Validation loss = 0.9881  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 1.6602  Validation loss = 0.9878  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 1.6598  Validation loss = 0.9871  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 1.6596  Validation loss = 0.9868  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 1.6594  Validation loss = 0.9865  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 1.6591  Validation loss = 0.9861  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 1.6590  Validation loss = 0.9860  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 1.6588  Validation loss = 0.9858  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 1.6585  Validation loss = 0.9853  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 1.6583  Validation loss = 0.9849  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 1.6580  Validation loss = 0.9849  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 1.6579  Validation loss = 0.9848  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 1.6576  Validation loss = 0.9844  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 1.6573  Validation loss = 0.9840  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 1.6571  Validation loss = 0.9835  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 1.6568  Validation loss = 0.9832  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 1.6565  Validation loss = 0.9826  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 1.6562  Validation loss = 0.9820  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 1.6560  Validation loss = 0.9813  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 1.6558  Validation loss = 0.9811  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 1.6556  Validation loss = 0.9808  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 1.6553  Validation loss = 0.9804  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 1.6550  Validation loss = 0.9799  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 1.6548  Validation loss = 0.9797  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 1.6544  Validation loss = 0.9790  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 1.6541  Validation loss = 0.9786  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 1.6539  Validation loss = 0.9787  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 1.6536  Validation loss = 0.9782  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 1.6534  Validation loss = 0.9783  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 1.6532  Validation loss = 0.9777  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 1.6530  Validation loss = 0.9772  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 1.6526  Validation loss = 0.9765  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 1.6524  Validation loss = 0.9761  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 1.6522  Validation loss = 0.9760  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 1.6519  Validation loss = 0.9754  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 1.6517  Validation loss = 0.9753  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 1.6514  Validation loss = 0.9750  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 1.6511  Validation loss = 0.9745  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 1.6509  Validation loss = 0.9745  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 1.6509  Validation loss = 0.9747  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 1.6507  Validation loss = 0.9746  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 1.6503  Validation loss = 0.9738  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 1.6501  Validation loss = 0.9736  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 1.6498  Validation loss = 0.9730  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 1.6496  Validation loss = 0.9725  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 1.6494  Validation loss = 0.9723  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 1.6492  Validation loss = 0.9720  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 1.6490  Validation loss = 0.9717  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 1.6488  Validation loss = 0.9716  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 1.6486  Validation loss = 0.9712  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 1.6484  Validation loss = 0.9711  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 1.6482  Validation loss = 0.9708  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 1.6479  Validation loss = 0.9708  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 1.6477  Validation loss = 0.9704  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 1.6475  Validation loss = 0.9701  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 1.6471  Validation loss = 0.9692  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 1.6468  Validation loss = 0.9687  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 1.6465  Validation loss = 0.9683  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 1.6463  Validation loss = 0.9681  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 1.6461  Validation loss = 0.9677  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 1.6458  Validation loss = 0.9671  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 1.6456  Validation loss = 0.9668  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 1.6454  Validation loss = 0.9666  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 1.6453  Validation loss = 0.9664  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 1.6451  Validation loss = 0.9660  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 1.6448  Validation loss = 0.9657  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 1.6446  Validation loss = 0.9651  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 1.6443  Validation loss = 0.9649  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 1.6440  Validation loss = 0.9645  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 1.6438  Validation loss = 0.9643  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 1.6436  Validation loss = 0.9641  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 1.6434  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 1.6432  Validation loss = 0.9636  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 1.6430  Validation loss = 0.9634  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 1.6429  Validation loss = 0.9633  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 1.6425  Validation loss = 0.9629  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 1.6423  Validation loss = 0.9626  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 1.6422  Validation loss = 0.9626  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 1.6420  Validation loss = 0.9625  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 1.6417  Validation loss = 0.9618  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 1.6416  Validation loss = 0.9618  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 1.6413  Validation loss = 0.9614  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 1.6411  Validation loss = 0.9609  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 1.6408  Validation loss = 0.9605  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 1.6406  Validation loss = 0.9604  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 1.6404  Validation loss = 0.9604  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 1.6402  Validation loss = 0.9600  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 1.6399  Validation loss = 0.9592  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 1.6398  Validation loss = 0.9591  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 1.6396  Validation loss = 0.9589  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 1.6394  Validation loss = 0.9587  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 1.6391  Validation loss = 0.9585  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 1.6390  Validation loss = 0.9585  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 1.6387  Validation loss = 0.9581  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 1.6385  Validation loss = 0.9578  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 1.6383  Validation loss = 0.9576  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 1.6381  Validation loss = 0.9575  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 1.6379  Validation loss = 0.9574  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 1.6377  Validation loss = 0.9572  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 1.6375  Validation loss = 0.9569  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 1.6372  Validation loss = 0.9563  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 1.6371  Validation loss = 0.9565  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 1.6369  Validation loss = 0.9562  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 1.6366  Validation loss = 0.9553  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 1.6364  Validation loss = 0.9552  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 1.6363  Validation loss = 0.9551  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 1.6362  Validation loss = 0.9551  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 1.6359  Validation loss = 0.9546  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 1.6359  Validation loss = 0.9549  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 1.6357  Validation loss = 0.9550  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 1.6355  Validation loss = 0.9547  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 1.6352  Validation loss = 0.9541  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 1.6351  Validation loss = 0.9539  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 1.6349  Validation loss = 0.9535  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 1.6348  Validation loss = 0.9538  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 1.6346  Validation loss = 0.9537  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 1.6343  Validation loss = 0.9529  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 1.6340  Validation loss = 0.9525  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 1.6339  Validation loss = 0.9523  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 1.6336  Validation loss = 0.9517  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 1.6333  Validation loss = 0.9510  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 1.6330  Validation loss = 0.9505  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 1.6330  Validation loss = 0.9505  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 1.6328  Validation loss = 0.9503  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 1.6326  Validation loss = 0.9501  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 1.6323  Validation loss = 0.9496  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 1.6322  Validation loss = 0.9494  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 1.6319  Validation loss = 0.9490  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 1.6317  Validation loss = 0.9486  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 1.6314  Validation loss = 0.9482  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 1.6313  Validation loss = 0.9481  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 1.6311  Validation loss = 0.9478  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 1.6309  Validation loss = 0.9478  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 1.6307  Validation loss = 0.9474  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 1.6306  Validation loss = 0.9475  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 1.6303  Validation loss = 0.9470  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 1.6300  Validation loss = 0.9463  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 1.6298  Validation loss = 0.9460  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 1.6296  Validation loss = 0.9457  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 1.6294  Validation loss = 0.9451  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 1.6291  Validation loss = 0.9446  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 1.6290  Validation loss = 0.9448  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 1.6289  Validation loss = 0.9450  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 1.6288  Validation loss = 0.9448  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 1.6286  Validation loss = 0.9448  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 1.6285  Validation loss = 0.9449  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 1.6282  Validation loss = 0.9447  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 1.6279  Validation loss = 0.9439  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 1.6276  Validation loss = 0.9432  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 1.6275  Validation loss = 0.9434  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 1.6273  Validation loss = 0.9434  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 1.6270  Validation loss = 0.9427  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 1.6268  Validation loss = 0.9423  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 1.6265  Validation loss = 0.9417  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 1.6263  Validation loss = 0.9414  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 1.6260  Validation loss = 0.9407  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 1.6257  Validation loss = 0.9403  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 1.6255  Validation loss = 0.9400  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 1.6254  Validation loss = 0.9402  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 1.6252  Validation loss = 0.9398  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 1.6249  Validation loss = 0.9394  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 1.6247  Validation loss = 0.9391  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 1.6245  Validation loss = 0.9388  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 1.6243  Validation loss = 0.9385  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 1.6240  Validation loss = 0.9380  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 1.6237  Validation loss = 0.9376  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 1.6235  Validation loss = 0.9374  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 1.6234  Validation loss = 0.9375  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 1.6232  Validation loss = 0.9372  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 1.6230  Validation loss = 0.9372  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 1.6229  Validation loss = 0.9368  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 1.6226  Validation loss = 0.9365  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 1.6224  Validation loss = 0.9363  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 1.6223  Validation loss = 0.9363  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 1.6221  Validation loss = 0.9359  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 1.6218  Validation loss = 0.9353  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 1.6216  Validation loss = 0.9353  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 1.6214  Validation loss = 0.9352  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 1.6211  Validation loss = 0.9346  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 1.6209  Validation loss = 0.9342  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 1.6207  Validation loss = 0.9339  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 1.6205  Validation loss = 0.9339  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 1.6204  Validation loss = 0.9337  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 1.6202  Validation loss = 0.9335  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 1.6199  Validation loss = 0.9328  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 1.6198  Validation loss = 0.9328  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 1.6196  Validation loss = 0.9324  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 1.6193  Validation loss = 0.9320  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 1.6193  Validation loss = 0.9322  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 1.6191  Validation loss = 0.9319  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 1.6189  Validation loss = 0.9318  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 1.6186  Validation loss = 0.9314  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 1.6184  Validation loss = 0.9312  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 1.6182  Validation loss = 0.9308  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 1.6180  Validation loss = 0.9308  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 1.6178  Validation loss = 0.9304  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 1.6177  Validation loss = 0.9304  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 1.6175  Validation loss = 0.9301  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 1.6172  Validation loss = 0.9294  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 1.6170  Validation loss = 0.9290  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 1.6168  Validation loss = 0.9289  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 1.6167  Validation loss = 0.9289  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 1.6165  Validation loss = 0.9287  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 1.6163  Validation loss = 0.9286  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 1.6162  Validation loss = 0.9285  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 1.6160  Validation loss = 0.9279  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 1.6157  Validation loss = 0.9276  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 1.6156  Validation loss = 0.9276  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 1.6154  Validation loss = 0.9272  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 1.6153  Validation loss = 0.9272  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 1.6151  Validation loss = 0.9271  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 1.6151  Validation loss = 0.9273  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 1.6148  Validation loss = 0.9269  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 1.6147  Validation loss = 0.9268  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 1.6145  Validation loss = 0.9268  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 1.6145  Validation loss = 0.9270  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 1.6143  Validation loss = 0.9269  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 1.6140  Validation loss = 0.9265  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 1.6138  Validation loss = 0.9262  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 1.6136  Validation loss = 0.9260  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 1.6134  Validation loss = 0.9256  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 1.6132  Validation loss = 0.9255  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 1.6130  Validation loss = 0.9255  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 1.6128  Validation loss = 0.9253  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 1.6127  Validation loss = 0.9250  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 1.6125  Validation loss = 0.9250  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 1.6123  Validation loss = 0.9246  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 1.6122  Validation loss = 0.9245  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 1.6121  Validation loss = 0.9245  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 1.6118  Validation loss = 0.9239  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 1.6116  Validation loss = 0.9236  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 1.6114  Validation loss = 0.9233  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 1.6111  Validation loss = 0.9225  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 1.6109  Validation loss = 0.9224  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 1.6109  Validation loss = 0.9226  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 1.6107  Validation loss = 0.9223  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 1.6105  Validation loss = 0.9222  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 1.6103  Validation loss = 0.9221  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 1.6101  Validation loss = 0.9216  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 1.6100  Validation loss = 0.9217  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 1.6098  Validation loss = 0.9216  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 1.6097  Validation loss = 0.9215  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 1.6095  Validation loss = 0.9213  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 1.6093  Validation loss = 0.9211  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 1.6091  Validation loss = 0.9207  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 1.6089  Validation loss = 0.9207  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 1.6089  Validation loss = 0.9208  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 1.6087  Validation loss = 0.9209  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 1.6084  Validation loss = 0.9203  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 1.6083  Validation loss = 0.9201  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 1.6081  Validation loss = 0.9198  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 1.6079  Validation loss = 0.9196  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 1.6077  Validation loss = 0.9192  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 1.6075  Validation loss = 0.9189  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 1.6073  Validation loss = 0.9189  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 1.6071  Validation loss = 0.9190  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 1.6069  Validation loss = 0.9186  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 1.6067  Validation loss = 0.9180  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 1.6065  Validation loss = 0.9176  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 1.6063  Validation loss = 0.9170  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 1.6061  Validation loss = 0.9169  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 1.6059  Validation loss = 0.9168  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 1.6058  Validation loss = 0.9170  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 1.6057  Validation loss = 0.9169  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 1.6054  Validation loss = 0.9164  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 1.6052  Validation loss = 0.9160  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 1.6050  Validation loss = 0.9159  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 1.6048  Validation loss = 0.9158  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 1.6047  Validation loss = 0.9155  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 1.6045  Validation loss = 0.9153  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 1.6044  Validation loss = 0.9158  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 1.6043  Validation loss = 0.9160  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 1.6041  Validation loss = 0.9154  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 1.6038  Validation loss = 0.9147  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 1.6036  Validation loss = 0.9145  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 1.6034  Validation loss = 0.9143  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 1.6032  Validation loss = 0.9142  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 500  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 1.5652  Validation loss = 5.9958  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 1.5650  Validation loss = 5.9952  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 1.5648  Validation loss = 5.9951  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 1.5647  Validation loss = 5.9949  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 1.5644  Validation loss = 5.9943  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 1.5643  Validation loss = 5.9944  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 1.5642  Validation loss = 5.9947  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.5640  Validation loss = 5.9936  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.5637  Validation loss = 5.9929  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 1.5635  Validation loss = 5.9924  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 1.5633  Validation loss = 5.9921  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 1.5632  Validation loss = 5.9921  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 1.5630  Validation loss = 5.9917  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 1.5628  Validation loss = 5.9911  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 1.5625  Validation loss = 5.9903  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.5623  Validation loss = 5.9895  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 1.5621  Validation loss = 5.9893  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 1.5619  Validation loss = 5.9886  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 1.5617  Validation loss = 5.9885  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 1.5615  Validation loss = 5.9877  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 1.5613  Validation loss = 5.9872  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 1.5611  Validation loss = 5.9869  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 1.5609  Validation loss = 5.9862  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 1.5608  Validation loss = 5.9859  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 1.5606  Validation loss = 5.9854  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 1.5605  Validation loss = 5.9850  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 1.5604  Validation loss = 5.9852  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 1.5602  Validation loss = 5.9848  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 1.5601  Validation loss = 5.9841  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 1.5600  Validation loss = 5.9845  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 1.5598  Validation loss = 5.9842  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 1.5597  Validation loss = 5.9839  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 1.5595  Validation loss = 5.9830  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 1.5593  Validation loss = 5.9829  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 1.5591  Validation loss = 5.9826  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 1.5589  Validation loss = 5.9817  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 1.5586  Validation loss = 5.9806  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 1.5584  Validation loss = 5.9803  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 1.5582  Validation loss = 5.9792  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 1.5580  Validation loss = 5.9790  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 1.5578  Validation loss = 5.9785  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 1.5576  Validation loss = 5.9778  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 1.5574  Validation loss = 5.9772  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 1.5572  Validation loss = 5.9770  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 1.5571  Validation loss = 5.9773  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 1.5569  Validation loss = 5.9768  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 1.5568  Validation loss = 5.9765  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 1.5566  Validation loss = 5.9763  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 1.5564  Validation loss = 5.9757  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 1.5562  Validation loss = 5.9754  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 1.5560  Validation loss = 5.9745  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 1.5558  Validation loss = 5.9738  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 1.5556  Validation loss = 5.9733  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 1.5554  Validation loss = 5.9731  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 1.5553  Validation loss = 5.9732  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 1.5552  Validation loss = 5.9733  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 1.5550  Validation loss = 5.9728  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 1.5548  Validation loss = 5.9726  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 1.5546  Validation loss = 5.9719  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 1.5544  Validation loss = 5.9712  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 1.5543  Validation loss = 5.9709  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 1.5541  Validation loss = 5.9704  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 1.5540  Validation loss = 5.9701  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 1.5537  Validation loss = 5.9691  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 1.5535  Validation loss = 5.9685  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 1.5532  Validation loss = 5.9675  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 1.5531  Validation loss = 5.9672  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 1.5529  Validation loss = 5.9669  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 1.5527  Validation loss = 5.9664  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 1.5525  Validation loss = 5.9652  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 1.5522  Validation loss = 5.9647  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 1.5521  Validation loss = 5.9648  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 1.5520  Validation loss = 5.9648  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 1.5519  Validation loss = 5.9645  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 1.5516  Validation loss = 5.9637  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 1.5514  Validation loss = 5.9631  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 1.5512  Validation loss = 5.9623  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 1.5510  Validation loss = 5.9616  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 1.5508  Validation loss = 5.9608  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 1.5505  Validation loss = 5.9602  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 1.5504  Validation loss = 5.9601  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 1.5502  Validation loss = 5.9596  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 1.5501  Validation loss = 5.9597  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 1.5499  Validation loss = 5.9589  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 1.5497  Validation loss = 5.9585  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 1.5495  Validation loss = 5.9578  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 1.5492  Validation loss = 5.9565  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 1.5491  Validation loss = 5.9565  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 1.5489  Validation loss = 5.9560  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 1.5487  Validation loss = 5.9559  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 1.5486  Validation loss = 5.9554  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 1.5484  Validation loss = 5.9548  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 1.5483  Validation loss = 5.9549  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 1.5481  Validation loss = 5.9547  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 1.5480  Validation loss = 5.9545  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 1.5478  Validation loss = 5.9540  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 1.5477  Validation loss = 5.9541  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 1.5475  Validation loss = 5.9538  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 1.5474  Validation loss = 5.9535  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 1.5472  Validation loss = 5.9533  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 1.5470  Validation loss = 5.9527  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 1.5469  Validation loss = 5.9524  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 1.5467  Validation loss = 5.9520  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 1.5465  Validation loss = 5.9515  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 1.5463  Validation loss = 5.9512  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 1.5462  Validation loss = 5.9512  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 1.5461  Validation loss = 5.9508  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 1.5459  Validation loss = 5.9503  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 1.5457  Validation loss = 5.9495  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 1.5456  Validation loss = 5.9492  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 1.5455  Validation loss = 5.9491  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 1.5454  Validation loss = 5.9491  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 1.5452  Validation loss = 5.9483  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 1.5450  Validation loss = 5.9484  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 1.5449  Validation loss = 5.9479  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 1.5447  Validation loss = 5.9476  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 1.5446  Validation loss = 5.9477  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 1.5445  Validation loss = 5.9475  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 1.5443  Validation loss = 5.9470  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 1.5442  Validation loss = 5.9469  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 1.5441  Validation loss = 5.9470  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 1.5440  Validation loss = 5.9469  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 1.5438  Validation loss = 5.9467  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 1.5436  Validation loss = 5.9461  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 1.5434  Validation loss = 5.9451  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 1.5432  Validation loss = 5.9444  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 1.5431  Validation loss = 5.9443  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 1.5429  Validation loss = 5.9440  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 1.5427  Validation loss = 5.9432  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 1.5425  Validation loss = 5.9431  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 1.5424  Validation loss = 5.9428  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 1.5423  Validation loss = 5.9428  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 1.5421  Validation loss = 5.9424  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 1.5418  Validation loss = 5.9412  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 1.5416  Validation loss = 5.9407  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 1.5415  Validation loss = 5.9410  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 1.5414  Validation loss = 5.9411  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 1.5412  Validation loss = 5.9405  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 1.5410  Validation loss = 5.9404  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 1.5408  Validation loss = 5.9395  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 1.5405  Validation loss = 5.9386  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 1.5403  Validation loss = 5.9380  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 1.5402  Validation loss = 5.9379  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 1.5401  Validation loss = 5.9375  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 1.5399  Validation loss = 5.9371  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 1.5397  Validation loss = 5.9364  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 1.5397  Validation loss = 5.9367  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 1.5395  Validation loss = 5.9364  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 1.5393  Validation loss = 5.9357  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 1.5391  Validation loss = 5.9353  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 1.5389  Validation loss = 5.9351  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 1.5387  Validation loss = 5.9342  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 1.5386  Validation loss = 5.9341  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 1.5383  Validation loss = 5.9335  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 1.5382  Validation loss = 5.9332  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 1.5381  Validation loss = 5.9331  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 1.5378  Validation loss = 5.9322  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 1.5376  Validation loss = 5.9314  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 1.5376  Validation loss = 5.9316  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 1.5374  Validation loss = 5.9314  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 1.5372  Validation loss = 5.9307  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 1.5371  Validation loss = 5.9311  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 1.5370  Validation loss = 5.9308  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 1.5368  Validation loss = 5.9305  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 1.5366  Validation loss = 5.9301  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 1.5365  Validation loss = 5.9299  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 1.5363  Validation loss = 5.9296  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 1.5361  Validation loss = 5.9289  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 1.5359  Validation loss = 5.9280  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 1.5357  Validation loss = 5.9278  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 1.5356  Validation loss = 5.9275  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 1.5354  Validation loss = 5.9270  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 1.5353  Validation loss = 5.9265  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 1.5351  Validation loss = 5.9255  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 1.5349  Validation loss = 5.9254  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 1.5348  Validation loss = 5.9252  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 1.5346  Validation loss = 5.9244  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 1.5344  Validation loss = 5.9241  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 1.5342  Validation loss = 5.9236  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 1.5341  Validation loss = 5.9228  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 1.5339  Validation loss = 5.9223  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 1.5338  Validation loss = 5.9220  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 1.5336  Validation loss = 5.9217  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 1.5334  Validation loss = 5.9215  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 1.5333  Validation loss = 5.9219  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 1.5332  Validation loss = 5.9214  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 1.5330  Validation loss = 5.9211  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 1.5328  Validation loss = 5.9207  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 1.5327  Validation loss = 5.9202  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 1.5325  Validation loss = 5.9199  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 1.5324  Validation loss = 5.9196  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 1.5323  Validation loss = 5.9195  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 1.5322  Validation loss = 5.9194  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 1.5321  Validation loss = 5.9198  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 1.5320  Validation loss = 5.9199  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 1.5318  Validation loss = 5.9194  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 1.5316  Validation loss = 5.9194  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 1.5314  Validation loss = 5.9184  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 1.5312  Validation loss = 5.9183  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 1.5311  Validation loss = 5.9183  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 1.5309  Validation loss = 5.9175  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 1.5307  Validation loss = 5.9168  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 1.5306  Validation loss = 5.9167  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 1.5305  Validation loss = 5.9166  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 1.5304  Validation loss = 5.9173  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 1.5303  Validation loss = 5.9169  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 1.5300  Validation loss = 5.9160  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 1.5299  Validation loss = 5.9154  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 1.5296  Validation loss = 5.9143  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 1.5294  Validation loss = 5.9139  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 1.5293  Validation loss = 5.9144  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 1.5292  Validation loss = 5.9141  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 1.5290  Validation loss = 5.9141  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 1.5289  Validation loss = 5.9141  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 1.5288  Validation loss = 5.9140  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 1.5287  Validation loss = 5.9135  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 1.5285  Validation loss = 5.9129  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 1.5284  Validation loss = 5.9128  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 1.5282  Validation loss = 5.9126  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 1.5280  Validation loss = 5.9124  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 1.5279  Validation loss = 5.9120  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 1.5278  Validation loss = 5.9125  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 1.5276  Validation loss = 5.9118  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 1.5274  Validation loss = 5.9115  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 1.5272  Validation loss = 5.9111  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 1.5271  Validation loss = 5.9111  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 1.5270  Validation loss = 5.9109  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 1.5267  Validation loss = 5.9097  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 1.5265  Validation loss = 5.9087  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 1.5264  Validation loss = 5.9087  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 1.5263  Validation loss = 5.9089  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 1.5262  Validation loss = 5.9086  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 1.5260  Validation loss = 5.9083  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 1.5259  Validation loss = 5.9082  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 1.5258  Validation loss = 5.9078  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 1.5256  Validation loss = 5.9077  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 1.5255  Validation loss = 5.9075  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 1.5254  Validation loss = 5.9082  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 1.5253  Validation loss = 5.9080  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 1.5250  Validation loss = 5.9068  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 1.5249  Validation loss = 5.9065  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 1.5247  Validation loss = 5.9061  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 1.5246  Validation loss = 5.9056  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 1.5244  Validation loss = 5.9048  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 1.5242  Validation loss = 5.9042  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 1.5241  Validation loss = 5.9035  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 1.5239  Validation loss = 5.9032  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 1.5237  Validation loss = 5.9029  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 1.5237  Validation loss = 5.9035  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 1.5235  Validation loss = 5.9031  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 1.5233  Validation loss = 5.9024  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 1.5231  Validation loss = 5.9019  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 1.5230  Validation loss = 5.9019  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 1.5229  Validation loss = 5.9022  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 1.5227  Validation loss = 5.9018  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 1.5227  Validation loss = 5.9024  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 1.5226  Validation loss = 5.9021  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 1.5224  Validation loss = 5.9019  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 1.5222  Validation loss = 5.9011  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 1.5221  Validation loss = 5.9010  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 1.5220  Validation loss = 5.9010  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 1.5217  Validation loss = 5.9002  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 1.5216  Validation loss = 5.9000  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 1.5215  Validation loss = 5.8999  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 1.5213  Validation loss = 5.8995  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 1.5212  Validation loss = 5.8994  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 1.5211  Validation loss = 5.8996  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 1.5209  Validation loss = 5.8986  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 1.5207  Validation loss = 5.8985  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 1.5206  Validation loss = 5.8984  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 1.5206  Validation loss = 5.8994  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 1.5205  Validation loss = 5.8989  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 1.5203  Validation loss = 5.8987  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 1.5203  Validation loss = 5.8992  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 1.5201  Validation loss = 5.8989  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 1.5199  Validation loss = 5.8989  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 1.5198  Validation loss = 5.8990  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 1.5197  Validation loss = 5.8985  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 1.5195  Validation loss = 5.8983  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 1.5194  Validation loss = 5.8985  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 1.5192  Validation loss = 5.8983  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 1.5191  Validation loss = 5.8978  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 1.5189  Validation loss = 5.8975  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 1.5188  Validation loss = 5.8973  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 1.5186  Validation loss = 5.8967  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 1.5185  Validation loss = 5.8961  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 1.5183  Validation loss = 5.8959  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 1.5182  Validation loss = 5.8959  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 1.5180  Validation loss = 5.8956  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 1.5178  Validation loss = 5.8950  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 1.5177  Validation loss = 5.8948  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 1.5176  Validation loss = 5.8947  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 1.5174  Validation loss = 5.8945  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 1.5173  Validation loss = 5.8945  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 1.5171  Validation loss = 5.8941  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 1.5170  Validation loss = 5.8942  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 1.5168  Validation loss = 5.8935  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 1.5166  Validation loss = 5.8925  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 1.5165  Validation loss = 5.8925  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 1.5164  Validation loss = 5.8926  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 1.5162  Validation loss = 5.8926  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 1.5161  Validation loss = 5.8917  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 1.5160  Validation loss = 5.8918  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 1.5159  Validation loss = 5.8918  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 1.5158  Validation loss = 5.8920  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 1.5156  Validation loss = 5.8921  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 1.5154  Validation loss = 5.8910  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 1.5153  Validation loss = 5.8907  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 1.5152  Validation loss = 5.8909  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 1.5149  Validation loss = 5.8898  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 1.5147  Validation loss = 5.8887  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 1.5145  Validation loss = 5.8882  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 1.5144  Validation loss = 5.8880  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 1.5142  Validation loss = 5.8877  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 1.5140  Validation loss = 5.8874  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 1.5139  Validation loss = 5.8869  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 1.5137  Validation loss = 5.8867  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 1.5136  Validation loss = 5.8869  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 1.5135  Validation loss = 5.8870  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 1.5133  Validation loss = 5.8865  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 1.5131  Validation loss = 5.8858  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 1.5130  Validation loss = 5.8864  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 1.5128  Validation loss = 5.8858  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 1.5127  Validation loss = 5.8855  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 1.5126  Validation loss = 5.8862  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 1.5125  Validation loss = 5.8868  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 1.5124  Validation loss = 5.8869  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 1.5122  Validation loss = 5.8862  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 1.5120  Validation loss = 5.8860  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 1.5119  Validation loss = 5.8854  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 1.5117  Validation loss = 5.8854  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 1.5116  Validation loss = 5.8851  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 1.5114  Validation loss = 5.8849  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 1.5112  Validation loss = 5.8837  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 1.5111  Validation loss = 5.8837  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 1.5110  Validation loss = 5.8834  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 1.5108  Validation loss = 5.8829  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 1.5107  Validation loss = 5.8831  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 1.5105  Validation loss = 5.8821  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 1.5102  Validation loss = 5.8812  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 1.5101  Validation loss = 5.8806  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 1.5100  Validation loss = 5.8805  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 1.5098  Validation loss = 5.8800  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 1.5095  Validation loss = 5.8789  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 1.5094  Validation loss = 5.8787  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 1.5092  Validation loss = 5.8781  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 1.5090  Validation loss = 5.8780  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 1.5089  Validation loss = 5.8785  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 1.5088  Validation loss = 5.8784  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 1.5086  Validation loss = 5.8775  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 1.5085  Validation loss = 5.8777  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 1.5083  Validation loss = 5.8770  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 1.5081  Validation loss = 5.8765  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 1.5080  Validation loss = 5.8763  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 1.5078  Validation loss = 5.8763  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 1.5077  Validation loss = 5.8761  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 1.5075  Validation loss = 5.8764  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 1.5074  Validation loss = 5.8765  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 1.5072  Validation loss = 5.8757  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 1.5071  Validation loss = 5.8754  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 1.5070  Validation loss = 5.8750  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 1.5069  Validation loss = 5.8750  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 1.5068  Validation loss = 5.8749  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 1.5066  Validation loss = 5.8743  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 1.5065  Validation loss = 5.8738  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 1.5063  Validation loss = 5.8736  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 1.5062  Validation loss = 5.8732  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 1.5060  Validation loss = 5.8732  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 1.5059  Validation loss = 5.8730  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 1.5058  Validation loss = 5.8731  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 1.5057  Validation loss = 5.8731  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 1.5056  Validation loss = 5.8732  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 1.5055  Validation loss = 5.8735  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 1.5054  Validation loss = 5.8739  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 369  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 2.0781  Validation loss = 8.7220  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 2.0778  Validation loss = 8.7209  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 2.0775  Validation loss = 8.7198  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 2.0773  Validation loss = 8.7189  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 2.0769  Validation loss = 8.7177  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 2.0769  Validation loss = 8.7174  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.0765  Validation loss = 8.7159  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 2.0761  Validation loss = 8.7143  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 2.0758  Validation loss = 8.7135  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 2.0757  Validation loss = 8.7131  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 2.0753  Validation loss = 8.7114  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 2.0750  Validation loss = 8.7106  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 2.0747  Validation loss = 8.7094  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 2.0747  Validation loss = 8.7091  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 2.0744  Validation loss = 8.7082  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 2.0742  Validation loss = 8.7076  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 2.0738  Validation loss = 8.7062  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 2.0736  Validation loss = 8.7052  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 2.0733  Validation loss = 8.7044  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 2.0731  Validation loss = 8.7037  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 2.0729  Validation loss = 8.7028  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 2.0725  Validation loss = 8.7015  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 2.0723  Validation loss = 8.7008  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 2.0719  Validation loss = 8.6993  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 2.0716  Validation loss = 8.6980  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 2.0714  Validation loss = 8.6973  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 2.0712  Validation loss = 8.6963  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 2.0709  Validation loss = 8.6953  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 2.0710  Validation loss = 8.6956  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 2.0707  Validation loss = 8.6946  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 2.0703  Validation loss = 8.6932  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 2.0700  Validation loss = 8.6919  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 2.0698  Validation loss = 8.6913  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 2.0693  Validation loss = 8.6895  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 2.0692  Validation loss = 8.6889  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 2.0691  Validation loss = 8.6885  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 2.0689  Validation loss = 8.6877  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 2.0685  Validation loss = 8.6864  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 2.0682  Validation loss = 8.6851  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 2.0680  Validation loss = 8.6843  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 2.0677  Validation loss = 8.6831  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 2.0674  Validation loss = 8.6823  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 2.0671  Validation loss = 8.6808  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 2.0667  Validation loss = 8.6796  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 2.0664  Validation loss = 8.6783  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 2.0662  Validation loss = 8.6778  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 2.0659  Validation loss = 8.6765  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 2.0653  Validation loss = 8.6740  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 2.0649  Validation loss = 8.6726  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 2.0648  Validation loss = 8.6722  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 2.0645  Validation loss = 8.6709  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 2.0642  Validation loss = 8.6700  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 2.0637  Validation loss = 8.6678  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 2.0633  Validation loss = 8.6661  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 2.0630  Validation loss = 8.6651  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 2.0628  Validation loss = 8.6643  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 2.0625  Validation loss = 8.6635  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 2.0623  Validation loss = 8.6625  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 2.0619  Validation loss = 8.6609  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 2.0616  Validation loss = 8.6598  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 2.0614  Validation loss = 8.6590  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 2.0610  Validation loss = 8.6575  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 2.0607  Validation loss = 8.6564  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 2.0606  Validation loss = 8.6557  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 2.0601  Validation loss = 8.6540  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 2.0598  Validation loss = 8.6527  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 2.0595  Validation loss = 8.6516  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 2.0593  Validation loss = 8.6508  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 2.0591  Validation loss = 8.6498  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 2.0588  Validation loss = 8.6489  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 2.0586  Validation loss = 8.6480  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 2.0584  Validation loss = 8.6471  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 2.0582  Validation loss = 8.6463  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 2.0578  Validation loss = 8.6450  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 2.0575  Validation loss = 8.6437  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 2.0573  Validation loss = 8.6430  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 2.0571  Validation loss = 8.6421  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 2.0566  Validation loss = 8.6401  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 2.0561  Validation loss = 8.6383  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 2.0560  Validation loss = 8.6377  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 2.0558  Validation loss = 8.6370  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 2.0555  Validation loss = 8.6360  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 2.0554  Validation loss = 8.6355  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 2.0553  Validation loss = 8.6353  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 2.0552  Validation loss = 8.6347  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 2.0550  Validation loss = 8.6338  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 2.0547  Validation loss = 8.6328  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 2.0544  Validation loss = 8.6317  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 2.0541  Validation loss = 8.6305  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 2.0539  Validation loss = 8.6295  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 2.0537  Validation loss = 8.6287  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 2.0534  Validation loss = 8.6276  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 2.0533  Validation loss = 8.6272  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 2.0531  Validation loss = 8.6266  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 2.0529  Validation loss = 8.6259  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 2.0527  Validation loss = 8.6249  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 2.0523  Validation loss = 8.6234  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 2.0519  Validation loss = 8.6219  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 2.0517  Validation loss = 8.6211  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 2.0515  Validation loss = 8.6204  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 2.0513  Validation loss = 8.6193  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 2.0509  Validation loss = 8.6180  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 2.0507  Validation loss = 8.6171  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 2.0503  Validation loss = 8.6154  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 2.0500  Validation loss = 8.6144  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 2.0497  Validation loss = 8.6129  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 2.0494  Validation loss = 8.6120  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 2.0491  Validation loss = 8.6106  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 2.0489  Validation loss = 8.6101  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 2.0487  Validation loss = 8.6089  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 2.0483  Validation loss = 8.6073  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 2.0481  Validation loss = 8.6065  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 2.0480  Validation loss = 8.6061  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 2.0476  Validation loss = 8.6047  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 2.0473  Validation loss = 8.6036  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 2.0472  Validation loss = 8.6030  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 2.0468  Validation loss = 8.6011  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 2.0465  Validation loss = 8.6002  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 2.0463  Validation loss = 8.5991  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 2.0461  Validation loss = 8.5985  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 2.0458  Validation loss = 8.5972  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 2.0455  Validation loss = 8.5959  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 2.0453  Validation loss = 8.5951  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 2.0449  Validation loss = 8.5936  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 2.0448  Validation loss = 8.5931  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 2.0445  Validation loss = 8.5921  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 2.0442  Validation loss = 8.5908  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 2.0437  Validation loss = 8.5889  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 2.0435  Validation loss = 8.5876  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 2.0432  Validation loss = 8.5867  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 2.0429  Validation loss = 8.5852  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 2.0425  Validation loss = 8.5835  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 2.0422  Validation loss = 8.5824  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 2.0420  Validation loss = 8.5815  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 2.0419  Validation loss = 8.5811  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 2.0417  Validation loss = 8.5806  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 2.0415  Validation loss = 8.5799  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 2.0413  Validation loss = 8.5793  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 2.0412  Validation loss = 8.5787  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 2.0410  Validation loss = 8.5779  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 2.0408  Validation loss = 8.5771  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 2.0404  Validation loss = 8.5752  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 2.0402  Validation loss = 8.5744  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 2.0399  Validation loss = 8.5736  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 2.0397  Validation loss = 8.5726  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 2.0396  Validation loss = 8.5722  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 2.0393  Validation loss = 8.5711  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 2.0390  Validation loss = 8.5698  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 2.0387  Validation loss = 8.5683  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 2.0385  Validation loss = 8.5675  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 2.0381  Validation loss = 8.5661  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 2.0380  Validation loss = 8.5655  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 2.0378  Validation loss = 8.5650  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 2.0377  Validation loss = 8.5643  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 2.0373  Validation loss = 8.5626  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 2.0371  Validation loss = 8.5621  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 2.0369  Validation loss = 8.5611  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 2.0367  Validation loss = 8.5603  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 2.0365  Validation loss = 8.5597  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 2.0363  Validation loss = 8.5586  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 2.0360  Validation loss = 8.5575  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 2.0358  Validation loss = 8.5566  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 2.0355  Validation loss = 8.5554  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 2.0352  Validation loss = 8.5542  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 2.0350  Validation loss = 8.5533  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 2.0348  Validation loss = 8.5527  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 2.0347  Validation loss = 8.5520  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 2.0344  Validation loss = 8.5511  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 2.0342  Validation loss = 8.5500  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 2.0340  Validation loss = 8.5491  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 2.0338  Validation loss = 8.5488  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 2.0338  Validation loss = 8.5488  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 2.0335  Validation loss = 8.5475  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 2.0333  Validation loss = 8.5465  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 2.0330  Validation loss = 8.5453  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 2.0328  Validation loss = 8.5446  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 2.0326  Validation loss = 8.5437  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 2.0324  Validation loss = 8.5426  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 2.0321  Validation loss = 8.5417  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 2.0320  Validation loss = 8.5411  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 2.0319  Validation loss = 8.5408  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 2.0316  Validation loss = 8.5398  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 2.0315  Validation loss = 8.5392  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 2.0312  Validation loss = 8.5378  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 2.0309  Validation loss = 8.5368  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 2.0307  Validation loss = 8.5358  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 2.0303  Validation loss = 8.5340  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 2.0301  Validation loss = 8.5331  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 2.0297  Validation loss = 8.5316  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 2.0293  Validation loss = 8.5297  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 2.0292  Validation loss = 8.5294  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 2.0290  Validation loss = 8.5285  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 2.0288  Validation loss = 8.5278  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 2.0285  Validation loss = 8.5262  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 2.0282  Validation loss = 8.5252  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 2.0281  Validation loss = 8.5246  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 2.0279  Validation loss = 8.5238  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 2.0276  Validation loss = 8.5228  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 2.0274  Validation loss = 8.5220  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 2.0274  Validation loss = 8.5218  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 2.0271  Validation loss = 8.5206  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 2.0267  Validation loss = 8.5189  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 2.0264  Validation loss = 8.5173  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 2.0260  Validation loss = 8.5160  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 2.0258  Validation loss = 8.5149  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 2.0256  Validation loss = 8.5140  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 2.0253  Validation loss = 8.5127  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 2.0251  Validation loss = 8.5119  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 2.0247  Validation loss = 8.5103  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 2.0245  Validation loss = 8.5094  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 2.0244  Validation loss = 8.5092  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 2.0241  Validation loss = 8.5078  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 2.0238  Validation loss = 8.5064  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 2.0234  Validation loss = 8.5045  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 2.0231  Validation loss = 8.5034  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 2.0229  Validation loss = 8.5021  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 2.0228  Validation loss = 8.5016  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 2.0225  Validation loss = 8.5007  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 2.0223  Validation loss = 8.5000  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 2.0221  Validation loss = 8.4992  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 2.0219  Validation loss = 8.4980  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 2.0218  Validation loss = 8.4983  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 2.0217  Validation loss = 8.4975  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 2.0214  Validation loss = 8.4962  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 2.0211  Validation loss = 8.4950  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 2.0208  Validation loss = 8.4938  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 2.0203  Validation loss = 8.4913  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 2.0199  Validation loss = 8.4897  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 2.0198  Validation loss = 8.4890  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 2.0195  Validation loss = 8.4879  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 2.0193  Validation loss = 8.4868  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 2.0192  Validation loss = 8.4865  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 2.0190  Validation loss = 8.4858  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 2.0187  Validation loss = 8.4848  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 2.0185  Validation loss = 8.4838  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 2.0182  Validation loss = 8.4827  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 2.0180  Validation loss = 8.4813  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 2.0176  Validation loss = 8.4799  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 2.0174  Validation loss = 8.4788  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 2.0172  Validation loss = 8.4778  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 2.0170  Validation loss = 8.4770  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 2.0168  Validation loss = 8.4766  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 2.0165  Validation loss = 8.4752  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 2.0163  Validation loss = 8.4742  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 2.0162  Validation loss = 8.4738  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 2.0160  Validation loss = 8.4731  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 2.0157  Validation loss = 8.4718  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 2.0155  Validation loss = 8.4709  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 2.0154  Validation loss = 8.4707  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 2.0151  Validation loss = 8.4696  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 2.0149  Validation loss = 8.4685  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 2.0148  Validation loss = 8.4681  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 2.0146  Validation loss = 8.4676  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 2.0145  Validation loss = 8.4674  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 2.0143  Validation loss = 8.4666  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 2.0141  Validation loss = 8.4656  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 2.0139  Validation loss = 8.4652  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 2.0137  Validation loss = 8.4641  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 2.0136  Validation loss = 8.4639  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 2.0134  Validation loss = 8.4632  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 2.0133  Validation loss = 8.4630  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 2.0132  Validation loss = 8.4626  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 2.0129  Validation loss = 8.4613  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 2.0127  Validation loss = 8.4604  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 2.0124  Validation loss = 8.4594  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 2.0123  Validation loss = 8.4588  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 2.0121  Validation loss = 8.4579  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 2.0120  Validation loss = 8.4581  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 2.0118  Validation loss = 8.4572  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 2.0117  Validation loss = 8.4565  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 2.0114  Validation loss = 8.4555  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 2.0112  Validation loss = 8.4545  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 2.0109  Validation loss = 8.4531  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 2.0107  Validation loss = 8.4525  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 2.0106  Validation loss = 8.4518  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 2.0104  Validation loss = 8.4515  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 2.0103  Validation loss = 8.4508  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 2.0100  Validation loss = 8.4499  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 2.0097  Validation loss = 8.4484  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 2.0095  Validation loss = 8.4477  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 2.0093  Validation loss = 8.4470  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 2.0092  Validation loss = 8.4466  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 2.0090  Validation loss = 8.4456  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 2.0088  Validation loss = 8.4447  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 2.0085  Validation loss = 8.4437  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 2.0083  Validation loss = 8.4424  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 2.0080  Validation loss = 8.4411  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 2.0078  Validation loss = 8.4404  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 2.0078  Validation loss = 8.4410  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 2.0077  Validation loss = 8.4407  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 2.0076  Validation loss = 8.4402  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 2.0074  Validation loss = 8.4398  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 2.0073  Validation loss = 8.4392  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 2.0071  Validation loss = 8.4386  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 2.0068  Validation loss = 8.4371  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 2.0066  Validation loss = 8.4362  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 2.0063  Validation loss = 8.4349  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 2.0063  Validation loss = 8.4352  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 2.0062  Validation loss = 8.4349  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 2.0059  Validation loss = 8.4337  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 2.0059  Validation loss = 8.4338  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 2.0056  Validation loss = 8.4327  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 2.0055  Validation loss = 8.4324  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 2.0054  Validation loss = 8.4318  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 2.0051  Validation loss = 8.4307  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 2.0050  Validation loss = 8.4305  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 2.0048  Validation loss = 8.4295  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 2.0046  Validation loss = 8.4288  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 2.0043  Validation loss = 8.4278  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 2.0042  Validation loss = 8.4274  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 2.0040  Validation loss = 8.4265  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 2.0037  Validation loss = 8.4251  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 2.0035  Validation loss = 8.4246  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 2.0033  Validation loss = 8.4240  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 2.0030  Validation loss = 8.4222  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 2.0028  Validation loss = 8.4213  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 2.0026  Validation loss = 8.4208  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 2.0025  Validation loss = 8.4204  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 2.0022  Validation loss = 8.4190  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 2.0019  Validation loss = 8.4176  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 2.0018  Validation loss = 8.4172  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 2.0015  Validation loss = 8.4164  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 2.0014  Validation loss = 8.4157  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 2.0012  Validation loss = 8.4151  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 2.0011  Validation loss = 8.4145  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 2.0008  Validation loss = 8.4133  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 2.0005  Validation loss = 8.4121  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 2.0003  Validation loss = 8.4115  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 2.0001  Validation loss = 8.4102  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 1.9997  Validation loss = 8.4086  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 1.9996  Validation loss = 8.4079  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 1.9994  Validation loss = 8.4073  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 1.9992  Validation loss = 8.4063  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 1.9989  Validation loss = 8.4052  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 1.9988  Validation loss = 8.4050  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 1.9987  Validation loss = 8.4046  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 1.9985  Validation loss = 8.4037  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 1.9983  Validation loss = 8.4029  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 1.9982  Validation loss = 8.4028  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 1.9980  Validation loss = 8.4020  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 1.9978  Validation loss = 8.4013  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 1.9977  Validation loss = 8.4005  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 1.9974  Validation loss = 8.3993  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 1.9973  Validation loss = 8.3990  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 1.9971  Validation loss = 8.3983  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 1.9968  Validation loss = 8.3968  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 1.9966  Validation loss = 8.3960  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 1.9964  Validation loss = 8.3949  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 1.9962  Validation loss = 8.3942  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 1.9960  Validation loss = 8.3935  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 1.9958  Validation loss = 8.3923  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 1.9955  Validation loss = 8.3908  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 1.9953  Validation loss = 8.3903  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 1.9949  Validation loss = 8.3888  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 1.9947  Validation loss = 8.3876  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 1.9946  Validation loss = 8.3873  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 1.9944  Validation loss = 8.3864  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 1.9940  Validation loss = 8.3847  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 1.9939  Validation loss = 8.3843  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 1.9938  Validation loss = 8.3837  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 1.9936  Validation loss = 8.3834  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 1.9934  Validation loss = 8.3824  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 1.9933  Validation loss = 8.3822  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 1.9932  Validation loss = 8.3822  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 1.9931  Validation loss = 8.3817  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 1.9929  Validation loss = 8.3815  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 1.9927  Validation loss = 8.3808  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 1.9925  Validation loss = 8.3797  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 1.9924  Validation loss = 8.3789  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 1.9922  Validation loss = 8.3786  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 1.9919  Validation loss = 8.3771  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 1.9918  Validation loss = 8.3764  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 1.9917  Validation loss = 8.3760  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 1.9914  Validation loss = 8.3747  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 1.9911  Validation loss = 8.3736  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 1.9909  Validation loss = 8.3730  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 1.9907  Validation loss = 8.3717  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 1.9904  Validation loss = 8.3705  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 1.9902  Validation loss = 8.3696  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 1.9899  Validation loss = 8.3685  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 1.9898  Validation loss = 8.3678  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 1.9896  Validation loss = 8.3671  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 1.9894  Validation loss = 8.3666  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 1.9892  Validation loss = 8.3656  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 1.9890  Validation loss = 8.3649  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 1.9888  Validation loss = 8.3645  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 1.9886  Validation loss = 8.3632  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 1.9884  Validation loss = 8.3625  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 1.9882  Validation loss = 8.3615  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 1.9880  Validation loss = 8.3605  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 1.9877  Validation loss = 8.3592  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 1.9875  Validation loss = 8.3588  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 1.9873  Validation loss = 8.3578  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 1.9870  Validation loss = 8.3562  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 1.9868  Validation loss = 8.3554  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 1.9867  Validation loss = 8.3550  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 1.9866  Validation loss = 8.3552  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 1.9864  Validation loss = 8.3541  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 1.9863  Validation loss = 8.3538  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 1.9861  Validation loss = 8.3524  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 1.9858  Validation loss = 8.3515  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 1.9857  Validation loss = 8.3510  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 1.9857  Validation loss = 8.3514  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 1.9855  Validation loss = 8.3507  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 1.9853  Validation loss = 8.3500  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 1.9850  Validation loss = 8.3486  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 1.9848  Validation loss = 8.3478  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 1.9847  Validation loss = 8.3468  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 1.9845  Validation loss = 8.3461  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 1.9842  Validation loss = 8.3448  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 1.9840  Validation loss = 8.3441  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 1.9838  Validation loss = 8.3431  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 1.9836  Validation loss = 8.3418  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 1.9833  Validation loss = 8.3407  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 1.9831  Validation loss = 8.3398  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 1.9830  Validation loss = 8.3393  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 1.9828  Validation loss = 8.3384  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 1.9825  Validation loss = 8.3370  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 1.9823  Validation loss = 8.3363  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 1.9823  Validation loss = 8.3365  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 1.9821  Validation loss = 8.3357  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 1.9820  Validation loss = 8.3352  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 1.9819  Validation loss = 8.3349  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 1.9817  Validation loss = 8.3345  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 1.9815  Validation loss = 8.3333  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 1.9814  Validation loss = 8.3330  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 1.9813  Validation loss = 8.3330  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 1.9811  Validation loss = 8.3322  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 1.9810  Validation loss = 8.3320  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 1.9808  Validation loss = 8.3314  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 1.9806  Validation loss = 8.3303  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 1.9805  Validation loss = 8.3299  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 1.9804  Validation loss = 8.3299  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 1.9803  Validation loss = 8.3296  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 1.9801  Validation loss = 8.3292  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 1.9799  Validation loss = 8.3284  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 1.9797  Validation loss = 8.3273  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 1.9796  Validation loss = 8.3270  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 1.9793  Validation loss = 8.3260  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 1.9792  Validation loss = 8.3254  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 1.9790  Validation loss = 8.3245  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 1.9788  Validation loss = 8.3239  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 1.9786  Validation loss = 8.3231  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 1.9785  Validation loss = 8.3226  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 1.9783  Validation loss = 8.3220  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 1.9780  Validation loss = 8.3208  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 1.9779  Validation loss = 8.3202  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 1.9775  Validation loss = 8.3185  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 1.9773  Validation loss = 8.3173  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 1.9772  Validation loss = 8.3170  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 1.9771  Validation loss = 8.3170  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 1.9769  Validation loss = 8.3164  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 1.9767  Validation loss = 8.3156  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 1.9767  Validation loss = 8.3155  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 1.9766  Validation loss = 8.3157  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 1.9764  Validation loss = 8.3152  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 1.9762  Validation loss = 8.3143  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 1.9760  Validation loss = 8.3136  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 1.9759  Validation loss = 8.3132  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 1.9757  Validation loss = 8.3127  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 1.9754  Validation loss = 8.3111  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 1.9753  Validation loss = 8.3105  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 1.9750  Validation loss = 8.3096  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 1.9749  Validation loss = 8.3088  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 1.9747  Validation loss = 8.3080  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 1.9745  Validation loss = 8.3074  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 1.9744  Validation loss = 8.3075  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 1.9742  Validation loss = 8.3068  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 1.9740  Validation loss = 8.3058  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 1.9739  Validation loss = 8.3052  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 1.9737  Validation loss = 8.3046  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 1.9736  Validation loss = 8.3040  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 1.9734  Validation loss = 8.3036  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 1.9732  Validation loss = 8.3026  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 1.9730  Validation loss = 8.3018  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 1.9729  Validation loss = 8.3011  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 1.9727  Validation loss = 8.3003  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 1.9724  Validation loss = 8.2987  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 1.9722  Validation loss = 8.2983  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 1.9721  Validation loss = 8.2981  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 1.9719  Validation loss = 8.2975  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 1.9716  Validation loss = 8.2964  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 1.9714  Validation loss = 8.2956  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 1.9713  Validation loss = 8.2950  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 1.9710  Validation loss = 8.2940  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 1.9708  Validation loss = 8.2931  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 1.9707  Validation loss = 8.2927  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 1.9706  Validation loss = 8.2922  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 1.9702  Validation loss = 8.2905  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 1.9701  Validation loss = 8.2902  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 1.9699  Validation loss = 8.2893  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 1.9699  Validation loss = 8.2898  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 1.9696  Validation loss = 8.2883  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 1.9692  Validation loss = 8.2866  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 1.9691  Validation loss = 8.2862  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 1.9690  Validation loss = 8.2859  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 1.9688  Validation loss = 8.2851  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 1.9686  Validation loss = 8.2847  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 1.9684  Validation loss = 8.2838  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 1.9683  Validation loss = 8.2831  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.8084  Validation loss = 3.9957  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 2.8081  Validation loss = 3.9951  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 2.8074  Validation loss = 3.9936  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 2.8063  Validation loss = 3.9906  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 2.8056  Validation loss = 3.9891  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.8045  Validation loss = 3.9861  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 2.8034  Validation loss = 3.9832  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.8029  Validation loss = 3.9822  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 2.8021  Validation loss = 3.9801  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 2.8015  Validation loss = 3.9786  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 2.8006  Validation loss = 3.9763  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.8000  Validation loss = 3.9748  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 2.7989  Validation loss = 3.9722  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 2.7980  Validation loss = 3.9699  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 2.7975  Validation loss = 3.9685  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 2.7966  Validation loss = 3.9661  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 2.7959  Validation loss = 3.9645  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 2.7949  Validation loss = 3.9619  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 2.7945  Validation loss = 3.9609  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 2.7938  Validation loss = 3.9591  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 2.7930  Validation loss = 3.9573  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 2.7928  Validation loss = 3.9570  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 2.7924  Validation loss = 3.9560  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 2.7917  Validation loss = 3.9542  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 2.7911  Validation loss = 3.9528  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 2.7906  Validation loss = 3.9516  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 2.7902  Validation loss = 3.9506  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 2.7899  Validation loss = 3.9498  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 2.7893  Validation loss = 3.9481  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 2.7885  Validation loss = 3.9459  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 2.7882  Validation loss = 3.9454  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 2.7875  Validation loss = 3.9435  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 2.7841  Validation loss = 3.9316  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 2.7833  Validation loss = 3.9295  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 2.7825  Validation loss = 3.9277  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 2.7819  Validation loss = 3.9262  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 2.7814  Validation loss = 3.9252  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 2.7806  Validation loss = 3.9232  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 2.7802  Validation loss = 3.9222  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 2.7798  Validation loss = 3.9212  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 2.7789  Validation loss = 3.9190  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 2.7785  Validation loss = 3.9178  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 2.7778  Validation loss = 3.9160  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 2.7771  Validation loss = 3.9141  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 2.7767  Validation loss = 3.9131  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 2.7761  Validation loss = 3.9118  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 2.7753  Validation loss = 3.9095  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 2.7745  Validation loss = 3.9076  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 2.7741  Validation loss = 3.9065  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 2.7736  Validation loss = 3.9055  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 2.7733  Validation loss = 3.9047  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 2.7727  Validation loss = 3.9034  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 2.7719  Validation loss = 3.9011  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 2.7710  Validation loss = 3.8989  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 2.7701  Validation loss = 3.8965  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 2.7696  Validation loss = 3.8950  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 2.7691  Validation loss = 3.8939  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 2.7682  Validation loss = 3.8917  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 2.7675  Validation loss = 3.8899  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 2.7671  Validation loss = 3.8889  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 2.7667  Validation loss = 3.8879  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 2.7662  Validation loss = 3.8867  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 2.7657  Validation loss = 3.8854  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 2.7650  Validation loss = 3.8834  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 2.7642  Validation loss = 3.8815  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 2.7636  Validation loss = 3.8799  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 2.7631  Validation loss = 3.8788  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 2.7627  Validation loss = 3.8779  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 2.7622  Validation loss = 3.8765  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 2.7617  Validation loss = 3.8753  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 2.7612  Validation loss = 3.8742  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 2.7608  Validation loss = 3.8733  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 2.7600  Validation loss = 3.8711  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 2.7594  Validation loss = 3.8695  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 2.7589  Validation loss = 3.8682  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 2.7583  Validation loss = 3.8669  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 2.7580  Validation loss = 3.8663  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 2.7573  Validation loss = 3.8644  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 2.7566  Validation loss = 3.8625  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 2.7560  Validation loss = 3.8611  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 2.7552  Validation loss = 3.8590  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 2.7548  Validation loss = 3.8579  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 2.7541  Validation loss = 3.8564  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 2.7533  Validation loss = 3.8542  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 2.7526  Validation loss = 3.8526  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 2.7507  Validation loss = 3.8503  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 2.7503  Validation loss = 3.8493  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 2.7498  Validation loss = 3.8482  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 2.7495  Validation loss = 3.8475  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 2.7493  Validation loss = 3.8473  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 2.7487  Validation loss = 3.8457  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 2.7481  Validation loss = 3.8443  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 2.7476  Validation loss = 3.8430  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 2.7469  Validation loss = 3.8410  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 2.7464  Validation loss = 3.8399  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 2.7457  Validation loss = 3.8381  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 2.7452  Validation loss = 3.8368  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 2.7448  Validation loss = 3.8356  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 2.7443  Validation loss = 3.8347  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 2.7437  Validation loss = 3.8329  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 2.7429  Validation loss = 3.8308  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 2.7424  Validation loss = 3.8294  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 2.7418  Validation loss = 3.8281  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 2.7416  Validation loss = 3.8276  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 2.7411  Validation loss = 3.8265  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 2.7403  Validation loss = 3.8242  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 2.7398  Validation loss = 3.8231  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 2.7393  Validation loss = 3.8219  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 2.7388  Validation loss = 3.8207  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 2.7384  Validation loss = 3.8196  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 2.7379  Validation loss = 3.8185  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 2.7372  Validation loss = 3.8169  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 2.7365  Validation loss = 3.8148  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 2.7358  Validation loss = 3.8130  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 2.7350  Validation loss = 3.8112  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 2.7348  Validation loss = 3.8105  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 2.7341  Validation loss = 3.8090  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 2.7338  Validation loss = 3.8081  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 2.7333  Validation loss = 3.8069  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 2.7327  Validation loss = 3.8054  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 2.7321  Validation loss = 3.8035  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 2.7316  Validation loss = 3.8023  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 2.7311  Validation loss = 3.8009  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 2.7301  Validation loss = 3.7981  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 2.7295  Validation loss = 3.7963  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 2.7291  Validation loss = 3.7954  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 2.7283  Validation loss = 3.7926  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 2.7279  Validation loss = 3.7894  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 2.7273  Validation loss = 3.7850  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 2.7268  Validation loss = 3.7745  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 2.7265  Validation loss = 3.7783  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 2.7258  Validation loss = 3.7290  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 2.7253  Validation loss = 3.6104  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 2.7249  Validation loss = 3.6884  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 2.7247  Validation loss = 3.6005  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 2.7238  Validation loss = 3.7641  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 2.7233  Validation loss = 3.6780  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 2.7230  Validation loss = 3.7504  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 2.7226  Validation loss = 3.7482  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 2.7221  Validation loss = 3.7582  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 2.7216  Validation loss = 3.7536  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 2.7210  Validation loss = 3.7488  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 2.7205  Validation loss = 3.7647  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 135  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 2.8190  Validation loss = 1.6302  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 2.8180  Validation loss = 1.6275  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 2.8174  Validation loss = 1.6266  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 2.8166  Validation loss = 1.6244  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 2.8158  Validation loss = 1.6225  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 2.8149  Validation loss = 1.6202  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 2.8136  Validation loss = 1.6167  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 2.8128  Validation loss = 1.6145  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 2.8120  Validation loss = 1.6127  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 2.8108  Validation loss = 1.6096  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 2.8105  Validation loss = 1.6087  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 2.8097  Validation loss = 1.6066  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 2.8086  Validation loss = 1.6039  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 2.8076  Validation loss = 1.6009  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 2.8068  Validation loss = 1.5990  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 2.8058  Validation loss = 1.5966  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 2.8052  Validation loss = 1.5958  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 2.8039  Validation loss = 1.5922  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 2.8032  Validation loss = 1.5908  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 2.8020  Validation loss = 1.5880  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 2.8007  Validation loss = 1.5846  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 2.7998  Validation loss = 1.5820  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 2.7989  Validation loss = 1.5797  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 2.7980  Validation loss = 1.5769  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 2.7972  Validation loss = 1.5749  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 2.7966  Validation loss = 1.5730  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 2.7956  Validation loss = 1.5706  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 2.7946  Validation loss = 1.5683  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 2.7937  Validation loss = 1.5658  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 2.7929  Validation loss = 1.5638  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 2.7926  Validation loss = 1.5632  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 2.7921  Validation loss = 1.5621  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 2.7914  Validation loss = 1.5600  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 2.7910  Validation loss = 1.5595  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 2.7905  Validation loss = 1.5584  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 2.7900  Validation loss = 1.5569  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 2.7894  Validation loss = 1.5556  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 2.7886  Validation loss = 1.5537  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 2.7876  Validation loss = 1.5505  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 2.7869  Validation loss = 1.5488  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 2.7856  Validation loss = 1.5453  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 2.7849  Validation loss = 1.5443  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 2.7839  Validation loss = 1.5418  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 2.7831  Validation loss = 1.5399  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 2.7826  Validation loss = 1.5385  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 2.7819  Validation loss = 1.5364  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 2.7813  Validation loss = 1.5346  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 2.7803  Validation loss = 1.5317  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 2.7792  Validation loss = 1.5286  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 2.7786  Validation loss = 1.5278  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 2.7782  Validation loss = 1.5271  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 2.7778  Validation loss = 1.5264  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 2.7772  Validation loss = 1.5249  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 2.7767  Validation loss = 1.5241  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 2.7757  Validation loss = 1.5213  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 2.7747  Validation loss = 1.5184  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 2.7736  Validation loss = 1.5157  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 2.7727  Validation loss = 1.5133  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 2.7720  Validation loss = 1.5117  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 2.7711  Validation loss = 1.5093  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 2.7701  Validation loss = 1.5073  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 2.7696  Validation loss = 1.5064  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 2.7690  Validation loss = 1.5051  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 2.7685  Validation loss = 1.5038  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 2.7676  Validation loss = 1.5014  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 2.7669  Validation loss = 1.4993  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 2.7660  Validation loss = 1.4968  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 2.7651  Validation loss = 1.4942  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 2.7642  Validation loss = 1.4919  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 2.7633  Validation loss = 1.4894  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 2.7621  Validation loss = 1.4864  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 2.7613  Validation loss = 1.4847  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 2.7608  Validation loss = 1.4833  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 2.7597  Validation loss = 1.4804  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 2.7585  Validation loss = 1.4766  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 2.7580  Validation loss = 1.4755  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 2.7571  Validation loss = 1.4730  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 2.7562  Validation loss = 1.4709  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 2.7551  Validation loss = 1.4679  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 2.7538  Validation loss = 1.4646  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 2.7529  Validation loss = 1.4623  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 2.7523  Validation loss = 1.4611  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 2.7517  Validation loss = 1.4596  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 2.7506  Validation loss = 1.4569  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 2.7504  Validation loss = 1.4567  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 2.7496  Validation loss = 1.4549  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 2.7490  Validation loss = 1.4539  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 2.7479  Validation loss = 1.4513  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 2.7474  Validation loss = 1.4499  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 2.7466  Validation loss = 1.4483  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 2.7459  Validation loss = 1.4467  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 2.7451  Validation loss = 1.4452  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 2.7443  Validation loss = 1.4437  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 2.7436  Validation loss = 1.4419  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 2.7431  Validation loss = 1.4409  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 2.7422  Validation loss = 1.4391  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 2.7411  Validation loss = 1.4358  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 2.7400  Validation loss = 1.4332  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 2.7397  Validation loss = 1.4329  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 2.7391  Validation loss = 1.4318  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 2.7381  Validation loss = 1.4296  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 2.7374  Validation loss = 1.4281  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 2.7369  Validation loss = 1.4269  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 2.7360  Validation loss = 1.4243  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 2.7351  Validation loss = 1.4223  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 2.7342  Validation loss = 1.4197  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 2.7332  Validation loss = 1.4172  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 2.7326  Validation loss = 1.4159  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 2.7317  Validation loss = 1.4133  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 2.7310  Validation loss = 1.4118  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 2.7304  Validation loss = 1.4111  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 2.7294  Validation loss = 1.4086  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 2.7285  Validation loss = 1.4069  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 2.7277  Validation loss = 1.4046  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 2.7270  Validation loss = 1.4026  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 2.7262  Validation loss = 1.4012  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 2.7251  Validation loss = 1.3985  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 2.7247  Validation loss = 1.3979  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 2.7241  Validation loss = 1.3968  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 2.7236  Validation loss = 1.3960  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 2.7227  Validation loss = 1.3932  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 2.7220  Validation loss = 1.3919  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 2.7212  Validation loss = 1.3900  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 2.7204  Validation loss = 1.3883  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 2.7199  Validation loss = 1.3875  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 2.7187  Validation loss = 1.3847  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 2.7182  Validation loss = 1.3833  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 2.7175  Validation loss = 1.3817  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 2.7172  Validation loss = 1.3816  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 2.7165  Validation loss = 1.3800  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 2.7159  Validation loss = 1.3786  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 2.7148  Validation loss = 1.3758  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 2.7144  Validation loss = 1.3749  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 2.7141  Validation loss = 1.3743  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 2.7134  Validation loss = 1.3726  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 2.7130  Validation loss = 1.3722  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 2.7120  Validation loss = 1.3697  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 2.7110  Validation loss = 1.3664  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 2.7105  Validation loss = 1.3649  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 2.7097  Validation loss = 1.3636  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 2.7092  Validation loss = 1.3626  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 2.7082  Validation loss = 1.3603  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 2.7072  Validation loss = 1.3584  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 2.7066  Validation loss = 1.3576  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 2.7062  Validation loss = 1.3567  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 2.7054  Validation loss = 1.3548  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 2.7050  Validation loss = 1.3544  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 2.7041  Validation loss = 1.3520  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 2.7031  Validation loss = 1.3495  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 2.7022  Validation loss = 1.3476  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 2.7016  Validation loss = 1.3464  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 2.7009  Validation loss = 1.3453  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 2.7004  Validation loss = 1.3445  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 2.6999  Validation loss = 1.3440  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 2.6995  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 2.6986  Validation loss = 1.3412  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 2.6981  Validation loss = 1.3402  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 2.6975  Validation loss = 1.3393  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 2.6972  Validation loss = 1.3389  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 2.6966  Validation loss = 1.3379  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 2.6958  Validation loss = 1.3357  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 2.6953  Validation loss = 1.3350  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 2.6947  Validation loss = 1.3333  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 2.6940  Validation loss = 1.3323  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 2.6936  Validation loss = 1.3314  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 2.6928  Validation loss = 1.3296  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 2.6922  Validation loss = 1.3279  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 2.6916  Validation loss = 1.3269  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 2.6912  Validation loss = 1.3265  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 2.6901  Validation loss = 1.3239  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 2.6891  Validation loss = 1.3208  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 2.6886  Validation loss = 1.3199  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 2.6879  Validation loss = 1.3184  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 2.6872  Validation loss = 1.3164  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 2.6866  Validation loss = 1.3154  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 2.6858  Validation loss = 1.3131  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 2.6851  Validation loss = 1.3120  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 2.6844  Validation loss = 1.3097  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 2.6838  Validation loss = 1.3081  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 2.6831  Validation loss = 1.3064  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 2.6824  Validation loss = 1.3048  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 2.6818  Validation loss = 1.3031  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 2.6809  Validation loss = 1.3014  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 2.6802  Validation loss = 1.3000  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 2.6796  Validation loss = 1.2991  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 2.6792  Validation loss = 1.2984  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 2.6786  Validation loss = 1.2967  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 2.6780  Validation loss = 1.2952  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 2.6775  Validation loss = 1.2946  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 2.6769  Validation loss = 1.2929  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 2.6762  Validation loss = 1.2916  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 2.6757  Validation loss = 1.2907  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 2.6750  Validation loss = 1.2894  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 2.6744  Validation loss = 1.2880  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 2.6739  Validation loss = 1.2873  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 2.6733  Validation loss = 1.2861  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 2.6728  Validation loss = 1.2849  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 2.6724  Validation loss = 1.2846  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 2.6717  Validation loss = 1.2828  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 2.6710  Validation loss = 1.2816  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 2.6700  Validation loss = 1.2788  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 2.6693  Validation loss = 1.2771  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 2.6685  Validation loss = 1.2751  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 2.6677  Validation loss = 1.2739  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 2.6674  Validation loss = 1.2741  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 2.6670  Validation loss = 1.2734  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 2.6664  Validation loss = 1.2719  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 2.6658  Validation loss = 1.2707  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 2.6650  Validation loss = 1.2684  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 2.6646  Validation loss = 1.2682  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 2.6637  Validation loss = 1.2664  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 2.6631  Validation loss = 1.2652  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 2.6625  Validation loss = 1.2641  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 2.6617  Validation loss = 1.2625  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 2.6608  Validation loss = 1.2603  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 2.6604  Validation loss = 1.2595  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 2.6595  Validation loss = 1.2572  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 2.6589  Validation loss = 1.2560  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 2.6584  Validation loss = 1.2553  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 2.6579  Validation loss = 1.2543  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 2.6574  Validation loss = 1.2534  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 2.6567  Validation loss = 1.2519  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 2.6562  Validation loss = 1.2507  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 2.6556  Validation loss = 1.2503  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 2.6552  Validation loss = 1.2494  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 2.6545  Validation loss = 1.2477  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 2.6541  Validation loss = 1.2469  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 2.6535  Validation loss = 1.2456  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 2.6529  Validation loss = 1.2451  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 2.6522  Validation loss = 1.2437  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 2.6516  Validation loss = 1.2429  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 2.6511  Validation loss = 1.2420  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 2.6507  Validation loss = 1.2412  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 2.6500  Validation loss = 1.2390  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 2.6492  Validation loss = 1.2373  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 2.6488  Validation loss = 1.2368  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 2.6481  Validation loss = 1.2356  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 2.6474  Validation loss = 1.2339  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 2.6463  Validation loss = 1.2319  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 2.6455  Validation loss = 1.2303  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 2.6447  Validation loss = 1.2278  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 2.6441  Validation loss = 1.2272  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 2.6435  Validation loss = 1.2260  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 2.6430  Validation loss = 1.2245  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 2.6424  Validation loss = 1.2237  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 2.6419  Validation loss = 1.2235  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 2.6414  Validation loss = 1.2229  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 2.6405  Validation loss = 1.2202  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 2.6401  Validation loss = 1.2197  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 2.6395  Validation loss = 1.2186  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 2.6387  Validation loss = 1.2163  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 2.6381  Validation loss = 1.2148  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 2.6372  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 2.6365  Validation loss = 1.2119  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 2.6355  Validation loss = 1.2096  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 2.6349  Validation loss = 1.2095  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 2.6344  Validation loss = 1.2085  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 2.6340  Validation loss = 1.2088  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 2.6332  Validation loss = 1.2075  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 2.6327  Validation loss = 1.2059  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 2.6317  Validation loss = 1.2039  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 2.6313  Validation loss = 1.2031  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 2.6307  Validation loss = 1.2021  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 2.6301  Validation loss = 1.2007  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 2.6295  Validation loss = 1.1998  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 2.6289  Validation loss = 1.1989  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 2.6283  Validation loss = 1.1974  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 2.6279  Validation loss = 1.1973  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 2.6275  Validation loss = 1.1968  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 2.6269  Validation loss = 1.1954  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 2.6265  Validation loss = 1.1956  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 2.6264  Validation loss = 1.1964  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 2.6256  Validation loss = 1.1948  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 2.6251  Validation loss = 1.1943  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 2.6246  Validation loss = 1.1950  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 2.6239  Validation loss = 1.1933  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 2.6235  Validation loss = 1.1929  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 2.6230  Validation loss = 1.1925  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 2.6224  Validation loss = 1.1916  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 2.6216  Validation loss = 1.1893  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 2.6208  Validation loss = 1.1878  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 2.6203  Validation loss = 1.1869  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 2.6198  Validation loss = 1.1860  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 2.6192  Validation loss = 1.1846  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 2.6187  Validation loss = 1.1832  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 2.6179  Validation loss = 1.1820  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 2.6173  Validation loss = 1.1805  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 2.6168  Validation loss = 1.1795  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 2.6161  Validation loss = 1.1787  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 2.6154  Validation loss = 1.1776  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 2.6148  Validation loss = 1.1767  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 2.6142  Validation loss = 1.1763  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 2.6133  Validation loss = 1.1734  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 2.6127  Validation loss = 1.1728  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 2.6122  Validation loss = 1.1717  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 2.6115  Validation loss = 1.1711  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 2.6112  Validation loss = 1.1717  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 2.6102  Validation loss = 1.1691  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 2.6095  Validation loss = 1.1677  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 2.6088  Validation loss = 1.1659  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 2.6080  Validation loss = 1.1645  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 2.6076  Validation loss = 1.1642  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 2.6068  Validation loss = 1.1620  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 2.6060  Validation loss = 1.1600  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 2.6053  Validation loss = 1.1589  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 2.6049  Validation loss = 1.1590  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 2.6041  Validation loss = 1.1576  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 2.6037  Validation loss = 1.1577  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 2.6032  Validation loss = 1.1564  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 2.6025  Validation loss = 1.1563  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 2.6018  Validation loss = 1.1541  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 2.6013  Validation loss = 1.1531  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 2.6009  Validation loss = 1.1528  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 2.6001  Validation loss = 1.1510  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 2.5998  Validation loss = 1.1512  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 2.5992  Validation loss = 1.1502  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 2.5986  Validation loss = 1.1490  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 2.5977  Validation loss = 1.1470  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 2.5972  Validation loss = 1.1469  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 2.5968  Validation loss = 1.1477  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 2.5963  Validation loss = 1.1462  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 2.5959  Validation loss = 1.1460  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 2.5951  Validation loss = 1.1444  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 2.5946  Validation loss = 1.1434  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 2.5940  Validation loss = 1.1431  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 2.5936  Validation loss = 1.1424  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 2.5929  Validation loss = 1.1410  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 2.5922  Validation loss = 1.1397  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 2.5917  Validation loss = 1.1398  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 2.5912  Validation loss = 1.1392  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 2.5908  Validation loss = 1.1393  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 2.5903  Validation loss = 1.1394  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 2.5896  Validation loss = 1.1373  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 2.5890  Validation loss = 1.1358  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 2.5883  Validation loss = 1.1344  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 2.5877  Validation loss = 1.1330  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 2.5871  Validation loss = 1.1327  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 2.5867  Validation loss = 1.1334  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 2.5859  Validation loss = 1.1324  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 2.5858  Validation loss = 1.1336  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 2.5852  Validation loss = 1.1315  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 2.5849  Validation loss = 1.1317  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 2.5844  Validation loss = 1.1309  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 2.5840  Validation loss = 1.1311  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 2.5833  Validation loss = 1.1308  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 2.5830  Validation loss = 1.1311  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 2.5823  Validation loss = 1.1293  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 2.5816  Validation loss = 1.1284  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 2.5812  Validation loss = 1.1287  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 2.5808  Validation loss = 1.1283  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 2.5802  Validation loss = 1.1268  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 2.5798  Validation loss = 1.1266  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 2.5795  Validation loss = 1.1272  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 2.5788  Validation loss = 1.1259  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 2.5783  Validation loss = 1.1244  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 2.5777  Validation loss = 1.1242  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 2.5770  Validation loss = 1.1226  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 2.5766  Validation loss = 1.1234  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 2.5761  Validation loss = 1.1229  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 2.5757  Validation loss = 1.1235  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 2.5752  Validation loss = 1.1221  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 2.5748  Validation loss = 1.1227  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 2.5742  Validation loss = 1.1210  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 2.5737  Validation loss = 1.1207  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 2.5732  Validation loss = 1.1196  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 2.5724  Validation loss = 1.1205  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 2.5714  Validation loss = 1.1174  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 2.5710  Validation loss = 1.1181  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 2.5703  Validation loss = 1.1164  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 2.5697  Validation loss = 1.1164  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 2.5693  Validation loss = 1.1154  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 2.5688  Validation loss = 1.1147  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 2.5682  Validation loss = 1.1138  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 2.5676  Validation loss = 1.1127  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 2.5672  Validation loss = 1.1135  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 2.5666  Validation loss = 1.1121  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 2.5662  Validation loss = 1.1117  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 2.5657  Validation loss = 1.1116  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 2.5652  Validation loss = 1.1122  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 2.5646  Validation loss = 1.1113  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 2.5643  Validation loss = 1.1133  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 2.5636  Validation loss = 1.1113  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 2.5632  Validation loss = 1.1113  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 2.5625  Validation loss = 1.1108  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 2.5620  Validation loss = 1.1104  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 2.5613  Validation loss = 1.1083  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 2.5606  Validation loss = 1.1078  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 2.5603  Validation loss = 1.1078  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 2.5597  Validation loss = 1.1065  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 2.5590  Validation loss = 1.1039  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 2.5586  Validation loss = 1.1061  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 2.5582  Validation loss = 1.1051  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 2.5578  Validation loss = 1.1054  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 2.5573  Validation loss = 1.1051  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 2.5570  Validation loss = 1.1054  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 2.5565  Validation loss = 1.1040  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 2.5558  Validation loss = 1.1025  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 2.5555  Validation loss = 1.1027  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 2.5549  Validation loss = 1.1014  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 2.5544  Validation loss = 1.1007  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 2.5538  Validation loss = 1.0995  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 2.5532  Validation loss = 1.0984  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 2.5525  Validation loss = 1.0973  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 2.5519  Validation loss = 1.0960  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 2.5514  Validation loss = 1.0940  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 2.5511  Validation loss = 1.0963  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 2.5505  Validation loss = 1.0958  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 2.5499  Validation loss = 1.0947  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 2.5494  Validation loss = 1.0966  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 2.5490  Validation loss = 1.0950  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 2.5486  Validation loss = 1.0957  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 2.5482  Validation loss = 1.0970  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 2.5478  Validation loss = 1.0983  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 405  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 2.5297  Validation loss = 1.9685  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 2.5289  Validation loss = 1.9585  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 2.5281  Validation loss = 1.9590  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 2.5272  Validation loss = 1.9543  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 2.5268  Validation loss = 1.9596  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 2.5263  Validation loss = 1.9582  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 2.5252  Validation loss = 1.9527  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 2.5246  Validation loss = 1.9497  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 2.5239  Validation loss = 1.9450  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 2.5234  Validation loss = 1.9451  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 2.5229  Validation loss = 1.9416  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 2.5221  Validation loss = 1.9376  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 2.5217  Validation loss = 1.9335  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 2.5213  Validation loss = 1.9350  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 2.5207  Validation loss = 1.9346  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 2.5203  Validation loss = 1.9353  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 2.5195  Validation loss = 1.9305  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 2.5188  Validation loss = 1.9277  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 2.5181  Validation loss = 1.9229  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 2.5177  Validation loss = 1.9163  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 2.5173  Validation loss = 1.9235  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 2.5167  Validation loss = 1.9207  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 2.5165  Validation loss = 1.9171  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 2.5161  Validation loss = 1.9191  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 2.5156  Validation loss = 1.9175  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 2.5151  Validation loss = 1.9193  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 2.5142  Validation loss = 1.9173  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 2.5136  Validation loss = 1.9132  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 2.5131  Validation loss = 1.9122  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 2.5124  Validation loss = 1.9124  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 2.5122  Validation loss = 1.9157  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 2.5118  Validation loss = 1.9187  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 2.5114  Validation loss = 1.9155  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 2.5105  Validation loss = 1.9046  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 2.5100  Validation loss = 1.9028  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 2.5091  Validation loss = 1.8982  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 2.5086  Validation loss = 1.8927  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 2.5083  Validation loss = 1.8924  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 2.5077  Validation loss = 1.8935  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 2.5073  Validation loss = 1.8941  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 2.5067  Validation loss = 1.8911  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 2.5061  Validation loss = 1.8885  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 2.5056  Validation loss = 1.8985  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 2.5053  Validation loss = 1.8927  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 2.5046  Validation loss = 1.8900  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 2.5041  Validation loss = 1.8845  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 2.5035  Validation loss = 1.8828  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 2.5030  Validation loss = 1.8797  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 2.5023  Validation loss = 1.8775  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 2.5021  Validation loss = 1.8769  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 2.5015  Validation loss = 1.8787  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 2.5007  Validation loss = 1.8737  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 2.4999  Validation loss = 1.8735  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 2.4996  Validation loss = 1.8749  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 2.4989  Validation loss = 1.8663  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 2.4985  Validation loss = 1.8644  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 2.4979  Validation loss = 1.8635  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 2.4970  Validation loss = 1.8627  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 2.4966  Validation loss = 1.8654  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 2.4961  Validation loss = 1.8622  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 2.4954  Validation loss = 1.8652  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 2.4948  Validation loss = 1.8643  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 2.4941  Validation loss = 1.8636  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 2.4937  Validation loss = 1.8650  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 2.4934  Validation loss = 1.8682  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 60  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 2.4903  Validation loss = 3.9485  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 2.4891  Validation loss = 3.9457  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 2.4878  Validation loss = 3.9426  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 2.4867  Validation loss = 3.9393  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 2.4854  Validation loss = 3.9359  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 2.4841  Validation loss = 3.9320  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 2.4832  Validation loss = 3.9290  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 2.4826  Validation loss = 3.9273  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 2.4821  Validation loss = 3.9258  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 2.4813  Validation loss = 3.9235  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 2.4806  Validation loss = 3.9212  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 2.4800  Validation loss = 3.9191  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 2.4789  Validation loss = 3.9154  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 2.4785  Validation loss = 3.9143  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 2.4784  Validation loss = 3.9145  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 2.4780  Validation loss = 3.9132  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 2.4774  Validation loss = 3.9112  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 2.4767  Validation loss = 3.9091  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 2.4759  Validation loss = 3.9063  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 2.4753  Validation loss = 3.9048  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 2.4745  Validation loss = 3.9027  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 2.4738  Validation loss = 3.9007  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 2.4727  Validation loss = 3.8973  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 2.4717  Validation loss = 3.8942  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 2.4712  Validation loss = 3.8925  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 2.4703  Validation loss = 3.8898  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 2.4696  Validation loss = 3.8874  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 2.4688  Validation loss = 3.8849  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 2.4681  Validation loss = 3.8823  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 2.4676  Validation loss = 3.8809  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 2.4668  Validation loss = 3.8788  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 2.4662  Validation loss = 3.8772  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 2.4652  Validation loss = 3.8740  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 2.4646  Validation loss = 3.8725  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 2.4638  Validation loss = 3.8697  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 2.4630  Validation loss = 3.8668  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 2.4622  Validation loss = 3.8641  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 2.4617  Validation loss = 3.8622  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 2.4614  Validation loss = 3.8620  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 2.4606  Validation loss = 3.8593  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 2.4602  Validation loss = 3.8588  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 2.4595  Validation loss = 3.8564  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 2.4588  Validation loss = 3.8540  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 2.4582  Validation loss = 3.8522  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 2.4573  Validation loss = 3.8494  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 2.4569  Validation loss = 3.8486  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 2.4561  Validation loss = 3.8459  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 2.4553  Validation loss = 3.8435  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 2.4546  Validation loss = 3.8418  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 2.4540  Validation loss = 3.8394  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 2.4529  Validation loss = 3.8355  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 2.4524  Validation loss = 3.8339  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 2.4516  Validation loss = 3.8318  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 2.4511  Validation loss = 3.8301  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 2.4504  Validation loss = 3.8277  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 2.4497  Validation loss = 3.8255  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 2.4490  Validation loss = 3.8230  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 2.4484  Validation loss = 3.8214  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 2.4478  Validation loss = 3.8198  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 2.4469  Validation loss = 3.8166  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 2.4464  Validation loss = 3.8154  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 2.4459  Validation loss = 3.8141  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 2.4454  Validation loss = 3.8128  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 2.4446  Validation loss = 3.8103  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 2.4441  Validation loss = 3.8092  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 2.4436  Validation loss = 3.8080  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 2.4434  Validation loss = 3.8076  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 2.4428  Validation loss = 3.8052  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 2.4422  Validation loss = 3.8031  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 2.4415  Validation loss = 3.8011  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 2.4410  Validation loss = 3.7994  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 2.4404  Validation loss = 3.7980  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 2.4399  Validation loss = 3.7964  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 2.4390  Validation loss = 3.7935  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 2.4385  Validation loss = 3.7926  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 2.4380  Validation loss = 3.7908  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 2.4375  Validation loss = 3.7894  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 2.4371  Validation loss = 3.7883  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 2.4367  Validation loss = 3.7875  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 2.4362  Validation loss = 3.7859  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 2.4355  Validation loss = 3.7837  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 2.4348  Validation loss = 3.7813  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 2.4342  Validation loss = 3.7797  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 2.4337  Validation loss = 3.7778  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 2.4329  Validation loss = 3.7748  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 2.4321  Validation loss = 3.7727  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 2.4312  Validation loss = 3.7695  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 2.4306  Validation loss = 3.7675  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 2.4302  Validation loss = 3.7666  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 2.4295  Validation loss = 3.7639  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 2.4286  Validation loss = 3.7610  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 2.4279  Validation loss = 3.7585  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 2.4271  Validation loss = 3.7563  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 2.4266  Validation loss = 3.7546  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 2.4256  Validation loss = 3.7512  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 2.4250  Validation loss = 3.7497  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 2.4243  Validation loss = 3.7475  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 2.4236  Validation loss = 3.7452  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 2.4203  Validation loss = 3.7433  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 2.4196  Validation loss = 3.7418  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 2.4192  Validation loss = 3.7409  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 2.4184  Validation loss = 3.7387  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 2.4181  Validation loss = 3.7381  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 2.4175  Validation loss = 3.7360  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 2.4167  Validation loss = 3.7329  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 2.4162  Validation loss = 3.7314  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 2.4157  Validation loss = 3.7305  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 2.4151  Validation loss = 3.7287  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 2.4144  Validation loss = 3.7266  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 2.4139  Validation loss = 3.7248  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 2.4135  Validation loss = 3.7236  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 2.4130  Validation loss = 3.7227  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 2.4129  Validation loss = 3.7230  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 2.4125  Validation loss = 3.7221  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 2.4121  Validation loss = 3.7202  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 2.4114  Validation loss = 3.7178  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 2.4110  Validation loss = 3.7163  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 2.4107  Validation loss = 3.7159  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 2.4102  Validation loss = 3.7146  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 2.4098  Validation loss = 3.7135  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 2.4091  Validation loss = 3.7114  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 2.4086  Validation loss = 3.7094  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 2.4080  Validation loss = 3.7074  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 2.4075  Validation loss = 3.7061  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 2.4068  Validation loss = 3.7040  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 2.4061  Validation loss = 3.7015  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 2.4056  Validation loss = 3.7002  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 2.4053  Validation loss = 3.6996  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 2.4049  Validation loss = 3.6988  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 2.4041  Validation loss = 3.6963  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 2.4036  Validation loss = 3.6944  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 2.4032  Validation loss = 3.6931  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 2.4025  Validation loss = 3.6905  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 2.4021  Validation loss = 3.6897  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 2.4017  Validation loss = 3.6890  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 2.4012  Validation loss = 3.6876  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 2.4004  Validation loss = 3.6851  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 2.3999  Validation loss = 3.6839  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 2.3992  Validation loss = 3.6815  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 2.3989  Validation loss = 3.6810  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 2.3986  Validation loss = 3.6805  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 2.3984  Validation loss = 3.6809  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 2.3977  Validation loss = 3.6775  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 2.3972  Validation loss = 3.6754  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 2.3969  Validation loss = 3.6752  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 2.3965  Validation loss = 3.6751  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 2.3959  Validation loss = 3.6737  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 2.3953  Validation loss = 3.6720  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 2.3949  Validation loss = 3.6704  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 2.3944  Validation loss = 3.6681  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 2.3939  Validation loss = 3.6673  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 2.3931  Validation loss = 3.6646  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 2.3922  Validation loss = 3.6611  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 2.3917  Validation loss = 3.6591  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 2.3912  Validation loss = 3.6574  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 2.3908  Validation loss = 3.6561  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 2.3904  Validation loss = 3.6548  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 2.3901  Validation loss = 3.6546  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 2.3898  Validation loss = 3.6545  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 2.3896  Validation loss = 3.6540  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 2.3889  Validation loss = 3.6524  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 2.3884  Validation loss = 3.6508  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 2.3880  Validation loss = 3.6498  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 2.3873  Validation loss = 3.6472  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 2.3870  Validation loss = 3.6471  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 2.3863  Validation loss = 3.6447  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 2.3859  Validation loss = 3.6439  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 2.3854  Validation loss = 3.6423  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 2.3850  Validation loss = 3.6406  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 2.3845  Validation loss = 3.6397  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 2.3840  Validation loss = 3.6378  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 2.3834  Validation loss = 3.6352  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 2.3825  Validation loss = 3.6318  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 2.3822  Validation loss = 3.6312  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 2.3820  Validation loss = 3.6316  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 2.3814  Validation loss = 3.6299  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 2.3808  Validation loss = 3.6280  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 2.3805  Validation loss = 3.6269  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 2.3798  Validation loss = 3.6244  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 2.3797  Validation loss = 3.6245  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 2.3791  Validation loss = 3.6225  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 2.3787  Validation loss = 3.6212  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 2.3784  Validation loss = 3.6208  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 2.3777  Validation loss = 3.6186  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 2.3771  Validation loss = 3.6162  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 2.3765  Validation loss = 3.6139  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 2.3760  Validation loss = 3.6126  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 2.3756  Validation loss = 3.6119  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 2.3752  Validation loss = 3.6115  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 2.3746  Validation loss = 3.6086  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 2.3740  Validation loss = 3.6069  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 2.3735  Validation loss = 3.6054  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 2.3733  Validation loss = 3.6052  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 2.3727  Validation loss = 3.6029  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 2.3723  Validation loss = 3.6014  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 2.3718  Validation loss = 3.5996  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 2.3712  Validation loss = 3.5986  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 2.3709  Validation loss = 3.5985  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 2.3701  Validation loss = 3.5952  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 2.3696  Validation loss = 3.5953  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 2.3690  Validation loss = 3.5926  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 2.3682  Validation loss = 3.5890  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 2.3676  Validation loss = 3.5869  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 2.3671  Validation loss = 3.5849  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 2.3666  Validation loss = 3.5839  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 2.3660  Validation loss = 3.5822  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 2.3655  Validation loss = 3.5795  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 2.3652  Validation loss = 3.5796  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 2.3649  Validation loss = 3.5797  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 2.3644  Validation loss = 3.5777  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 2.3637  Validation loss = 3.5754  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 2.3632  Validation loss = 3.5737  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 2.3624  Validation loss = 3.5712  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 2.3621  Validation loss = 3.5711  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 2.3615  Validation loss = 3.5691  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 2.3608  Validation loss = 3.5666  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 2.3604  Validation loss = 3.5666  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 2.3601  Validation loss = 3.5658  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 2.3598  Validation loss = 3.5647  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 2.3596  Validation loss = 3.5639  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 2.3590  Validation loss = 3.5612  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 2.3585  Validation loss = 3.5600  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 2.3580  Validation loss = 3.5584  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 2.3575  Validation loss = 3.5568  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 2.3568  Validation loss = 3.5540  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 2.3563  Validation loss = 3.5523  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 2.3557  Validation loss = 3.5495  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 2.3552  Validation loss = 3.5478  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 2.3549  Validation loss = 3.5466  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 2.3543  Validation loss = 3.5456  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 2.3538  Validation loss = 3.5439  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 2.3534  Validation loss = 3.5436  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 2.3528  Validation loss = 3.5412  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 2.3524  Validation loss = 3.5399  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 2.3518  Validation loss = 3.5377  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 2.3517  Validation loss = 3.5387  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 2.3510  Validation loss = 3.5357  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 2.3506  Validation loss = 3.5353  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 2.3502  Validation loss = 3.5336  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 2.3497  Validation loss = 3.5321  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 2.3491  Validation loss = 3.5297  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 2.3489  Validation loss = 3.5315  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 2.3486  Validation loss = 3.5314  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 2.3482  Validation loss = 3.5299  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 2.3479  Validation loss = 3.5304  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 2.3476  Validation loss = 3.5283  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 2.3472  Validation loss = 3.5276  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 2.3466  Validation loss = 3.5240  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 2.3462  Validation loss = 3.5236  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 2.3457  Validation loss = 3.5213  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 2.3453  Validation loss = 3.5195  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 2.3449  Validation loss = 3.5190  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 2.3443  Validation loss = 3.5170  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 2.3438  Validation loss = 3.5156  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 2.3433  Validation loss = 3.5148  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 2.3427  Validation loss = 3.5129  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 2.3424  Validation loss = 3.5126  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 2.3422  Validation loss = 3.5120  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 2.3418  Validation loss = 3.5110  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 2.3413  Validation loss = 3.5091  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 2.3407  Validation loss = 3.5076  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 2.3401  Validation loss = 3.5050  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 2.3398  Validation loss = 3.5043  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 2.3393  Validation loss = 3.5033  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 2.3388  Validation loss = 3.5001  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 2.3384  Validation loss = 3.4988  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 2.3378  Validation loss = 3.4963  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 2.3374  Validation loss = 3.4957  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 2.3372  Validation loss = 3.4943  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 2.3368  Validation loss = 3.4936  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 2.3363  Validation loss = 3.4926  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 2.3359  Validation loss = 3.4925  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 2.3356  Validation loss = 3.4917  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 2.3353  Validation loss = 3.4908  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 2.3350  Validation loss = 3.4889  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 2.3344  Validation loss = 3.4877  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 2.3342  Validation loss = 3.4865  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 2.3336  Validation loss = 3.4846  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 2.3331  Validation loss = 3.4815  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 2.3327  Validation loss = 3.4816  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 2.3324  Validation loss = 3.4809  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 2.3320  Validation loss = 3.4800  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 2.3315  Validation loss = 3.4791  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 2.3308  Validation loss = 3.4756  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 2.3305  Validation loss = 3.4743  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 2.3301  Validation loss = 3.4732  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 2.3295  Validation loss = 3.4716  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 2.3291  Validation loss = 3.4703  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 2.3286  Validation loss = 3.4690  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 2.3282  Validation loss = 3.4662  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 2.3277  Validation loss = 3.4637  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 2.3273  Validation loss = 3.4618  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 2.3268  Validation loss = 3.4608  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 2.3263  Validation loss = 3.4602  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 2.3258  Validation loss = 3.4578  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 2.3254  Validation loss = 3.4561  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 2.3249  Validation loss = 3.4559  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 2.3243  Validation loss = 3.4530  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 2.3241  Validation loss = 3.4535  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 2.3237  Validation loss = 3.4531  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 2.3234  Validation loss = 3.4520  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 2.3230  Validation loss = 3.4508  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 2.3227  Validation loss = 3.4484  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 2.3224  Validation loss = 3.4475  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 2.3218  Validation loss = 3.4460  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 2.3215  Validation loss = 3.4447  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 2.3209  Validation loss = 3.4420  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 2.3201  Validation loss = 3.4401  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 2.3197  Validation loss = 3.4383  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 2.3190  Validation loss = 3.4354  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 2.3187  Validation loss = 3.4364  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 2.3186  Validation loss = 3.4371  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 2.3182  Validation loss = 3.4351  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 2.3176  Validation loss = 3.4338  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 2.3171  Validation loss = 3.4331  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 2.3167  Validation loss = 3.4327  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 2.3163  Validation loss = 3.4329  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 2.3160  Validation loss = 3.4328  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 2.3155  Validation loss = 3.4304  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 2.3150  Validation loss = 3.4299  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 2.3146  Validation loss = 3.4301  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 2.3138  Validation loss = 3.4283  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 2.3135  Validation loss = 3.4271  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 2.3133  Validation loss = 3.4279  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 2.3129  Validation loss = 3.4253  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 2.3123  Validation loss = 3.4236  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 2.3119  Validation loss = 3.4239  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 2.3116  Validation loss = 3.4235  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 2.3113  Validation loss = 3.4220  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 2.3110  Validation loss = 3.4215  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 2.3105  Validation loss = 3.4204  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 2.3100  Validation loss = 3.4173  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 2.3094  Validation loss = 3.4152  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 2.3091  Validation loss = 3.4139  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 2.3087  Validation loss = 3.4136  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 2.3082  Validation loss = 3.4103  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 2.3079  Validation loss = 3.4077  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 2.3073  Validation loss = 3.4032  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 2.3066  Validation loss = 3.4019  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 2.3062  Validation loss = 3.4013  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 2.3059  Validation loss = 3.4016  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 2.3056  Validation loss = 3.4014  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 2.3052  Validation loss = 3.3986  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 2.3045  Validation loss = 3.3966  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 2.3041  Validation loss = 3.3945  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 2.3036  Validation loss = 3.3932  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 2.3034  Validation loss = 3.3929  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 2.3031  Validation loss = 3.3928  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 2.3026  Validation loss = 3.3906  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 2.3020  Validation loss = 3.3862  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 2.3018  Validation loss = 3.3863  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 2.3013  Validation loss = 3.3857  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 2.3009  Validation loss = 3.3835  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 2.3005  Validation loss = 3.3821  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 2.2999  Validation loss = 3.3799  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 2.2994  Validation loss = 3.3793  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 2.2992  Validation loss = 3.3774  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 2.2988  Validation loss = 3.3759  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 2.2985  Validation loss = 3.3743  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 2.2980  Validation loss = 3.3752  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 2.2976  Validation loss = 3.3746  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 2.2972  Validation loss = 3.3765  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 2.2968  Validation loss = 3.3744  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 2.2963  Validation loss = 3.3715  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 2.2955  Validation loss = 3.3696  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 2.2951  Validation loss = 3.3694  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 2.2948  Validation loss = 3.3693  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 2.2944  Validation loss = 3.3679  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 2.2939  Validation loss = 3.3649  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 2.2936  Validation loss = 3.3646  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 2.2931  Validation loss = 3.3631  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 2.2929  Validation loss = 3.3623  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 2.2926  Validation loss = 3.3617  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 2.2922  Validation loss = 3.3600  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 2.2916  Validation loss = 3.3583  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 2.2911  Validation loss = 3.3563  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 2.2906  Validation loss = 3.3548  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 2.2903  Validation loss = 3.3546  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 2.2899  Validation loss = 3.3536  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 2.2896  Validation loss = 3.3532  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 2.2892  Validation loss = 3.3530  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 2.2889  Validation loss = 3.3526  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 2.2883  Validation loss = 3.3508  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 2.2878  Validation loss = 3.3483  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 2.2876  Validation loss = 3.3481  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 2.2872  Validation loss = 3.3475  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 2.2866  Validation loss = 3.3454  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 2.2863  Validation loss = 3.3460  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 2.2859  Validation loss = 3.3459  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 2.2854  Validation loss = 3.3426  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 2.2850  Validation loss = 3.3400  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 2.2846  Validation loss = 3.3394  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 2.2842  Validation loss = 3.3390  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 2.2837  Validation loss = 3.3370  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 2.2835  Validation loss = 3.3347  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 2.2834  Validation loss = 3.3383  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 2.2829  Validation loss = 3.3358  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 2.2823  Validation loss = 3.3340  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 2.2819  Validation loss = 3.3312  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 2.2814  Validation loss = 3.3307  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 2.2811  Validation loss = 3.3310  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 2.2805  Validation loss = 3.3286  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 2.2801  Validation loss = 3.3254  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 2.2797  Validation loss = 3.3241  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 2.2791  Validation loss = 3.3213  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 2.2786  Validation loss = 3.3203  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 2.2781  Validation loss = 3.3195  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 2.2779  Validation loss = 3.3182  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 2.2774  Validation loss = 3.3143  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 2.2770  Validation loss = 3.3158  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 2.2767  Validation loss = 3.3143  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 2.2764  Validation loss = 3.3150  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 2.2760  Validation loss = 3.3146  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 2.2755  Validation loss = 3.3142  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 2.2752  Validation loss = 3.3133  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 2.2750  Validation loss = 3.3127  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 2.2746  Validation loss = 3.3120  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 2.2742  Validation loss = 3.3109  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 2.2739  Validation loss = 3.3122  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 2.2735  Validation loss = 3.3094  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 2.2733  Validation loss = 3.3091  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 2.2728  Validation loss = 3.3094  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 2.2725  Validation loss = 3.3068  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 2.2722  Validation loss = 3.3067  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 2.2718  Validation loss = 3.3064  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 2.2712  Validation loss = 3.3029  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 2.2706  Validation loss = 3.2990  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 2.2703  Validation loss = 3.2966  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 2.2696  Validation loss = 3.2948  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 2.2693  Validation loss = 3.2914  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 2.2689  Validation loss = 3.2904  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 2.2686  Validation loss = 3.2876  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 2.2681  Validation loss = 3.2876  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 2.2677  Validation loss = 3.2862  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 2.2670  Validation loss = 3.2871  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 2.2669  Validation loss = 3.2850  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 2.2665  Validation loss = 3.2823  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 2.2661  Validation loss = 3.2819  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 2.2658  Validation loss = 3.2794  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 2.2653  Validation loss = 3.2795  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 2.2650  Validation loss = 3.2767  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 2.2647  Validation loss = 3.2762  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 2.2645  Validation loss = 3.2746  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 2.2640  Validation loss = 3.2731  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 2.2635  Validation loss = 3.2731  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 2.2629  Validation loss = 3.2704  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 2.2625  Validation loss = 3.2680  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 2.2622  Validation loss = 3.2679  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 2.2618  Validation loss = 3.2665  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 2.2613  Validation loss = 3.2649  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 2.2608  Validation loss = 3.2666  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 2.2604  Validation loss = 3.2656  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 2.2600  Validation loss = 3.2653  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 2.2597  Validation loss = 3.2625  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 2.2594  Validation loss = 3.2647  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 2.2589  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 2.2585  Validation loss = 3.2636  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 2.2580  Validation loss = 3.2633  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 2.2575  Validation loss = 3.2633  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 2.2571  Validation loss = 3.2636  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 2.2567  Validation loss = 3.2635  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 2.2561  Validation loss = 3.2598  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 2.2557  Validation loss = 3.2585  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 2.2554  Validation loss = 3.2567  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 2.2552  Validation loss = 3.2575  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 2.2548  Validation loss = 3.2571  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 2.2544  Validation loss = 3.2551  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 2.2539  Validation loss = 3.2542  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 2.2534  Validation loss = 3.2526  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 2.2529  Validation loss = 3.2470  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 2.2525  Validation loss = 3.2455  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 2.2520  Validation loss = 3.2406  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 2.2518  Validation loss = 3.2392  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 2.2516  Validation loss = 3.2394  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 2.2513  Validation loss = 3.2378  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 2.2508  Validation loss = 3.2371  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 2.2504  Validation loss = 3.2353  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 2.2500  Validation loss = 3.2351  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 2.2494  Validation loss = 3.2354  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 2.2489  Validation loss = 3.2337  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 2.2487  Validation loss = 3.2312  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 2.2484  Validation loss = 3.2308  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 2.2481  Validation loss = 3.2293  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 2.2477  Validation loss = 3.2300  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 2.2474  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 2.2470  Validation loss = 3.2331  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 2.2467  Validation loss = 3.2318  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 2.2462  Validation loss = 3.2291  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 2.2460  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 2.2454  Validation loss = 3.2292  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 2.2451  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 2.2447  Validation loss = 3.2279  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 2.2443  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 2.2439  Validation loss = 3.2257  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 2.2435  Validation loss = 3.2251  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 2.2432  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 2.2427  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 2.2423  Validation loss = 3.2171  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 2.2420  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 2.2417  Validation loss = 3.2164  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 500  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.3556  Validation loss = 6.7940  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 2.3555  Validation loss = 6.7933  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.3550  Validation loss = 6.7913  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 2.3547  Validation loss = 6.7905  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.3538  Validation loss = 6.7882  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 2.3530  Validation loss = 6.7860  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 2.3526  Validation loss = 6.7848  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.3517  Validation loss = 6.7824  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.3512  Validation loss = 6.7807  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.3504  Validation loss = 6.7780  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.3496  Validation loss = 6.7751  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.3494  Validation loss = 6.7744  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.3489  Validation loss = 6.7727  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 2.3480  Validation loss = 6.7701  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 2.3477  Validation loss = 6.7695  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 2.3471  Validation loss = 6.7676  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 2.3466  Validation loss = 6.7658  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 2.3461  Validation loss = 6.7641  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 2.3456  Validation loss = 6.7620  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.3448  Validation loss = 6.7596  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 2.3444  Validation loss = 6.7582  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 2.3435  Validation loss = 6.7559  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 2.3430  Validation loss = 6.7539  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 2.3424  Validation loss = 6.7520  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 2.3419  Validation loss = 6.7502  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 2.3414  Validation loss = 6.7486  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 2.3410  Validation loss = 6.7470  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 2.3404  Validation loss = 6.7448  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 2.3399  Validation loss = 6.7432  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 2.3393  Validation loss = 6.7406  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 2.3386  Validation loss = 6.7382  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 2.3379  Validation loss = 6.7356  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 2.3375  Validation loss = 6.7339  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 2.3369  Validation loss = 6.7321  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 2.3363  Validation loss = 6.7305  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 2.3359  Validation loss = 6.7291  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 2.3354  Validation loss = 6.7272  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 2.3349  Validation loss = 6.7252  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 2.3343  Validation loss = 6.7237  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 2.3339  Validation loss = 6.7230  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 2.3332  Validation loss = 6.7204  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 2.3328  Validation loss = 6.7189  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 2.3325  Validation loss = 6.7177  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 2.3322  Validation loss = 6.7166  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 2.3315  Validation loss = 6.7136  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 2.3308  Validation loss = 6.7114  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 2.3305  Validation loss = 6.7104  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 2.3299  Validation loss = 6.7090  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 2.3296  Validation loss = 6.7080  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 2.3290  Validation loss = 6.7060  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 2.3286  Validation loss = 6.7043  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 2.3281  Validation loss = 6.7033  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 2.3275  Validation loss = 6.7005  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 2.3269  Validation loss = 6.6978  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 2.3264  Validation loss = 6.6970  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 2.3261  Validation loss = 6.6960  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 2.3255  Validation loss = 6.6945  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 2.3249  Validation loss = 6.6924  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 2.3243  Validation loss = 6.6902  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 2.3239  Validation loss = 6.6888  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 2.3235  Validation loss = 6.6877  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 2.3229  Validation loss = 6.6852  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 2.3224  Validation loss = 6.6835  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 2.3220  Validation loss = 6.6819  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 2.3217  Validation loss = 6.6818  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 2.3213  Validation loss = 6.6804  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 2.3210  Validation loss = 6.6793  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 2.3206  Validation loss = 6.6778  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 2.3203  Validation loss = 6.6767  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 2.3194  Validation loss = 6.6738  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 2.3188  Validation loss = 6.6715  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 2.3182  Validation loss = 6.6694  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 2.3178  Validation loss = 6.6683  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 2.3175  Validation loss = 6.6679  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 2.3171  Validation loss = 6.6664  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 2.3163  Validation loss = 6.6637  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 2.3154  Validation loss = 6.6604  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 2.3152  Validation loss = 6.6604  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 2.3147  Validation loss = 6.6587  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 2.3141  Validation loss = 6.6571  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 2.3138  Validation loss = 6.6566  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 2.3133  Validation loss = 6.6553  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 2.3126  Validation loss = 6.6528  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 2.3124  Validation loss = 6.6523  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 2.3119  Validation loss = 6.6507  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 2.3114  Validation loss = 6.6490  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 2.3109  Validation loss = 6.6471  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 2.3106  Validation loss = 6.6461  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 2.3103  Validation loss = 6.6458  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 2.3098  Validation loss = 6.6442  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 2.3095  Validation loss = 6.6435  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 2.3088  Validation loss = 6.6407  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 2.3080  Validation loss = 6.6382  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 2.3076  Validation loss = 6.6363  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 2.3073  Validation loss = 6.6352  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 2.3067  Validation loss = 6.6328  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 2.3061  Validation loss = 6.6309  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 2.3054  Validation loss = 6.6290  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 2.3050  Validation loss = 6.6274  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 2.3044  Validation loss = 6.6255  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 2.3040  Validation loss = 6.6244  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 2.3035  Validation loss = 6.6222  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 2.3030  Validation loss = 6.6207  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 2.3024  Validation loss = 6.6190  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 2.3021  Validation loss = 6.6182  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 2.3014  Validation loss = 6.6156  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 2.3010  Validation loss = 6.6146  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 2.3001  Validation loss = 6.6114  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 2.2995  Validation loss = 6.6095  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 2.2990  Validation loss = 6.6077  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 2.2984  Validation loss = 6.6058  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 2.2981  Validation loss = 6.6051  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 2.2974  Validation loss = 6.6021  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 2.2968  Validation loss = 6.6001  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 2.2966  Validation loss = 6.5993  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 2.2961  Validation loss = 6.5970  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 2.2953  Validation loss = 6.5944  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 2.2950  Validation loss = 6.5939  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 2.2946  Validation loss = 6.5931  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 2.2941  Validation loss = 6.5910  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 2.2936  Validation loss = 6.5898  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 2.2929  Validation loss = 6.5879  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 2.2925  Validation loss = 6.5865  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 2.2922  Validation loss = 6.5853  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 2.2918  Validation loss = 6.5842  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 2.2913  Validation loss = 6.5842  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 2.2908  Validation loss = 6.5823  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 2.2904  Validation loss = 6.5818  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 2.2901  Validation loss = 6.5807  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 2.2896  Validation loss = 6.5786  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 2.2890  Validation loss = 6.5755  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 2.2885  Validation loss = 6.5731  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 2.2880  Validation loss = 6.5711  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 2.2878  Validation loss = 6.5716  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 2.2873  Validation loss = 6.5699  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 2.2869  Validation loss = 6.5682  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 2.2865  Validation loss = 6.5677  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 2.2860  Validation loss = 6.5663  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 2.2858  Validation loss = 6.5660  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 2.2852  Validation loss = 6.5643  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 2.2849  Validation loss = 6.5632  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 2.2846  Validation loss = 6.5623  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 2.2843  Validation loss = 6.5611  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 2.2840  Validation loss = 6.5601  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 2.2832  Validation loss = 6.5579  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 2.2826  Validation loss = 6.5564  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 2.2823  Validation loss = 6.5547  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 2.2818  Validation loss = 6.5539  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 2.2812  Validation loss = 6.5515  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 2.2807  Validation loss = 6.5497  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 2.2804  Validation loss = 6.5495  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 2.2799  Validation loss = 6.5473  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 2.2795  Validation loss = 6.5453  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 2.2794  Validation loss = 6.5462  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 2.2788  Validation loss = 6.5442  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 2.2784  Validation loss = 6.5426  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 2.2780  Validation loss = 6.5413  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 2.2776  Validation loss = 6.5403  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 2.2772  Validation loss = 6.5387  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 2.2768  Validation loss = 6.5376  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 2.2762  Validation loss = 6.5357  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 2.2759  Validation loss = 6.5348  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 2.2752  Validation loss = 6.5327  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 2.2748  Validation loss = 6.5319  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 2.2746  Validation loss = 6.5315  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 2.2739  Validation loss = 6.5290  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 2.2733  Validation loss = 6.5270  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 2.2724  Validation loss = 6.5234  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 2.2719  Validation loss = 6.5214  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 2.2714  Validation loss = 6.5199  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 2.2712  Validation loss = 6.5195  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 2.2706  Validation loss = 6.5171  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 2.2702  Validation loss = 6.5155  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 2.2698  Validation loss = 6.5144  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 2.2698  Validation loss = 6.5144  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 2.2694  Validation loss = 6.5134  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 2.2690  Validation loss = 6.5121  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 2.2686  Validation loss = 6.5115  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 2.2682  Validation loss = 6.5107  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 2.2678  Validation loss = 6.5095  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 2.2674  Validation loss = 6.5086  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 2.2668  Validation loss = 6.5059  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 2.2662  Validation loss = 6.5047  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 2.2656  Validation loss = 6.5024  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 2.2649  Validation loss = 6.5002  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 2.2643  Validation loss = 6.4982  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 2.2636  Validation loss = 6.4954  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 2.2632  Validation loss = 6.4942  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 2.2628  Validation loss = 6.4931  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 2.2622  Validation loss = 6.4909  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 2.2619  Validation loss = 6.4909  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 2.2615  Validation loss = 6.4894  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 2.2613  Validation loss = 6.4880  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 2.2610  Validation loss = 6.4873  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 2.2603  Validation loss = 6.4863  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 2.2604  Validation loss = 6.4866  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 2.2599  Validation loss = 6.4854  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 2.2596  Validation loss = 6.4846  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 2.2592  Validation loss = 6.4842  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 2.2588  Validation loss = 6.4837  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 2.2582  Validation loss = 6.4819  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 2.2580  Validation loss = 6.4809  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 2.2575  Validation loss = 6.4797  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 2.2572  Validation loss = 6.4783  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 2.2570  Validation loss = 6.4783  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 2.2563  Validation loss = 6.4759  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 2.2557  Validation loss = 6.4738  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 2.2550  Validation loss = 6.4710  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 2.2542  Validation loss = 6.4680  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 2.2538  Validation loss = 6.4666  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 2.2532  Validation loss = 6.4641  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 2.2527  Validation loss = 6.4614  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 2.2524  Validation loss = 6.4603  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 2.2520  Validation loss = 6.4589  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 2.2518  Validation loss = 6.4570  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 2.2514  Validation loss = 6.4556  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 2.2509  Validation loss = 6.4536  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 2.2504  Validation loss = 6.4515  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 2.2500  Validation loss = 6.4494  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 2.2494  Validation loss = 6.4483  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 2.2489  Validation loss = 6.4468  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 2.2485  Validation loss = 6.4464  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 2.2480  Validation loss = 6.4447  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 2.2475  Validation loss = 6.4432  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 2.2469  Validation loss = 6.4415  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 2.2463  Validation loss = 6.4398  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 2.2460  Validation loss = 6.4387  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 2.2455  Validation loss = 6.4376  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 2.2449  Validation loss = 6.4355  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 2.2444  Validation loss = 6.4338  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 2.2440  Validation loss = 6.4319  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 2.2437  Validation loss = 6.4311  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 2.2434  Validation loss = 6.4304  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 2.2429  Validation loss = 6.4283  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 2.2423  Validation loss = 6.4267  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 2.2421  Validation loss = 6.4251  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 2.2413  Validation loss = 6.4229  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 2.2409  Validation loss = 6.4210  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 2.2403  Validation loss = 6.4187  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 2.2398  Validation loss = 6.4177  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 2.2396  Validation loss = 6.4166  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 2.2391  Validation loss = 6.4154  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 2.2387  Validation loss = 6.4141  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 2.2386  Validation loss = 6.4122  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 2.2382  Validation loss = 6.4111  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 2.2379  Validation loss = 6.4104  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 2.2374  Validation loss = 6.4095  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 2.2371  Validation loss = 6.4094  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 2.2364  Validation loss = 6.4074  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 2.2358  Validation loss = 6.4048  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 2.2355  Validation loss = 6.4054  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 2.2351  Validation loss = 6.4028  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 2.2347  Validation loss = 6.4023  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 2.2343  Validation loss = 6.4005  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 2.2339  Validation loss = 6.4000  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 2.2333  Validation loss = 6.3987  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 2.2329  Validation loss = 6.3975  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 2.2328  Validation loss = 6.3976  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 2.2326  Validation loss = 6.3964  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 2.2321  Validation loss = 6.3949  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 2.2315  Validation loss = 6.3932  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 2.2311  Validation loss = 6.3927  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 2.2306  Validation loss = 6.3906  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 2.2301  Validation loss = 6.3884  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 2.2299  Validation loss = 6.3866  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 2.2295  Validation loss = 6.3858  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 2.2294  Validation loss = 6.3844  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 2.2289  Validation loss = 6.3824  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 2.2285  Validation loss = 6.3807  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 2.2281  Validation loss = 6.3803  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 2.2276  Validation loss = 6.3795  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 2.2271  Validation loss = 6.3779  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 2.2267  Validation loss = 6.3761  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 2.2261  Validation loss = 6.3758  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 2.2258  Validation loss = 6.3748  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 2.2254  Validation loss = 6.3734  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 2.2248  Validation loss = 6.3714  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 2.2245  Validation loss = 6.3689  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 2.2240  Validation loss = 6.3665  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 2.2235  Validation loss = 6.3653  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 2.2229  Validation loss = 6.3639  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 2.2224  Validation loss = 6.3622  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 2.2220  Validation loss = 6.3618  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 2.2217  Validation loss = 6.3606  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 2.2210  Validation loss = 6.3595  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 2.2207  Validation loss = 6.3593  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 2.2203  Validation loss = 6.3582  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 2.2200  Validation loss = 6.3569  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 2.2196  Validation loss = 6.3557  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 2.2189  Validation loss = 6.3544  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 2.2187  Validation loss = 6.3547  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 2.2179  Validation loss = 6.3519  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 2.2173  Validation loss = 6.3499  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 2.2167  Validation loss = 6.3476  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 2.2164  Validation loss = 6.3468  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 2.2160  Validation loss = 6.3451  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 2.2158  Validation loss = 6.3438  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 2.2151  Validation loss = 6.3423  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 2.2146  Validation loss = 6.3404  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 2.2139  Validation loss = 6.3382  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 2.2136  Validation loss = 6.3375  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 2.2130  Validation loss = 6.3362  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 2.2125  Validation loss = 6.3341  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 2.2123  Validation loss = 6.3343  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 2.2120  Validation loss = 6.3333  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 2.2112  Validation loss = 6.3315  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 2.2107  Validation loss = 6.3294  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 2.2104  Validation loss = 6.3266  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 2.2101  Validation loss = 6.3251  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 2.2095  Validation loss = 6.3247  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 2.2089  Validation loss = 6.3228  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 2.2084  Validation loss = 6.3205  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 2.2079  Validation loss = 6.3184  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 2.2074  Validation loss = 6.3167  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 2.2067  Validation loss = 6.3149  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 2.2063  Validation loss = 6.3141  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 2.2060  Validation loss = 6.3139  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 2.2052  Validation loss = 6.3109  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 2.2050  Validation loss = 6.3093  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 2.2042  Validation loss = 6.3075  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 2.2038  Validation loss = 6.3058  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 2.2032  Validation loss = 6.3030  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 2.2029  Validation loss = 6.3017  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 2.2026  Validation loss = 6.3016  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 2.2022  Validation loss = 6.3017  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 2.2020  Validation loss = 6.3016  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 2.2014  Validation loss = 6.2997  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 2.2013  Validation loss = 6.2989  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 2.2005  Validation loss = 6.2968  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 2.2000  Validation loss = 6.2955  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 2.1996  Validation loss = 6.2950  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 2.1992  Validation loss = 6.2941  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 2.1989  Validation loss = 6.2929  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 2.1984  Validation loss = 6.2925  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 2.1977  Validation loss = 6.2914  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 2.1971  Validation loss = 6.2893  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 2.1970  Validation loss = 6.2897  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 2.1963  Validation loss = 6.2870  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 2.1956  Validation loss = 6.2854  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 2.1952  Validation loss = 6.2846  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 2.1948  Validation loss = 6.2839  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 2.1945  Validation loss = 6.2829  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 2.1942  Validation loss = 6.2814  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 2.1934  Validation loss = 6.2779  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 2.1929  Validation loss = 6.2778  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 2.1927  Validation loss = 6.2772  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 2.1923  Validation loss = 6.2769  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 2.1920  Validation loss = 6.2757  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 2.1913  Validation loss = 6.2738  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 2.1912  Validation loss = 6.2735  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 2.1908  Validation loss = 6.2718  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 2.1904  Validation loss = 6.2717  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 2.1901  Validation loss = 6.2701  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 2.1896  Validation loss = 6.2694  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 2.1887  Validation loss = 6.2673  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 2.1886  Validation loss = 6.2667  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 2.1885  Validation loss = 6.2653  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 2.1882  Validation loss = 6.2642  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 2.1876  Validation loss = 6.2634  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 2.1872  Validation loss = 6.2636  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 2.1868  Validation loss = 6.2622  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 2.1863  Validation loss = 6.2612  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 2.1861  Validation loss = 6.2612  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 2.1856  Validation loss = 6.2608  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 2.1852  Validation loss = 6.2599  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 2.1846  Validation loss = 6.2581  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 2.1842  Validation loss = 6.2572  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 2.1837  Validation loss = 6.2564  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 2.1835  Validation loss = 6.2541  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 2.1828  Validation loss = 6.2532  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 2.1825  Validation loss = 6.2521  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 2.1821  Validation loss = 6.2515  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 2.1816  Validation loss = 6.2505  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 2.1813  Validation loss = 6.2501  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 2.1809  Validation loss = 6.2495  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 2.1807  Validation loss = 6.2491  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 2.1801  Validation loss = 6.2474  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 2.1798  Validation loss = 6.2468  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 2.1794  Validation loss = 6.2447  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 2.1789  Validation loss = 6.2436  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 2.1787  Validation loss = 6.2426  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 2.1782  Validation loss = 6.2417  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 2.1774  Validation loss = 6.2399  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 2.1771  Validation loss = 6.2386  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 2.1764  Validation loss = 6.2374  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 2.1760  Validation loss = 6.2364  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 2.1749  Validation loss = 6.2343  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 2.1743  Validation loss = 6.2323  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 2.1739  Validation loss = 6.2299  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 2.1730  Validation loss = 6.2270  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 2.1726  Validation loss = 6.2239  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 2.1720  Validation loss = 6.2226  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 2.1714  Validation loss = 6.2209  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 2.1707  Validation loss = 6.2203  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 2.1702  Validation loss = 6.2199  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 2.1695  Validation loss = 6.2177  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 2.1689  Validation loss = 6.2166  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 2.1685  Validation loss = 6.2159  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 2.1680  Validation loss = 6.2154  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 2.1678  Validation loss = 6.2140  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 2.1670  Validation loss = 6.2116  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 2.1668  Validation loss = 6.2116  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 2.1663  Validation loss = 6.2108  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 2.1659  Validation loss = 6.2101  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 2.1657  Validation loss = 6.2087  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 2.1655  Validation loss = 6.2082  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 2.1647  Validation loss = 6.2060  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 2.1641  Validation loss = 6.2049  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 2.1639  Validation loss = 6.2045  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 2.1634  Validation loss = 6.2041  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 2.1628  Validation loss = 6.2029  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 2.1618  Validation loss = 6.2003  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 2.1611  Validation loss = 6.1980  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 2.1607  Validation loss = 6.1970  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 2.1603  Validation loss = 6.1964  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 2.1598  Validation loss = 6.1958  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 2.1595  Validation loss = 6.1951  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 2.1590  Validation loss = 6.1934  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 2.1581  Validation loss = 6.1896  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 2.1577  Validation loss = 6.1878  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 2.1573  Validation loss = 6.1869  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 2.1569  Validation loss = 6.1861  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 2.1565  Validation loss = 6.1844  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 2.1563  Validation loss = 6.1840  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 2.1557  Validation loss = 6.1821  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 2.1552  Validation loss = 6.1806  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 2.1549  Validation loss = 6.1802  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 2.1546  Validation loss = 6.1800  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 2.1541  Validation loss = 6.1786  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 2.1537  Validation loss = 6.1772  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 2.1534  Validation loss = 6.1759  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 2.1531  Validation loss = 6.1739  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 2.1529  Validation loss = 6.1744  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 2.1526  Validation loss = 6.1738  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 2.1522  Validation loss = 6.1727  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 2.1518  Validation loss = 6.1712  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 2.1513  Validation loss = 6.1687  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 2.1507  Validation loss = 6.1669  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 2.1503  Validation loss = 6.1666  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 2.1498  Validation loss = 6.1647  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 2.1495  Validation loss = 6.1637  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 2.1491  Validation loss = 6.1629  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 2.1487  Validation loss = 6.1615  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 2.1482  Validation loss = 6.1602  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 2.1481  Validation loss = 6.1609  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 2.1474  Validation loss = 6.1596  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 2.1471  Validation loss = 6.1595  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 2.1466  Validation loss = 6.1577  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 2.1463  Validation loss = 6.1574  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 2.1458  Validation loss = 6.1551  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 2.1453  Validation loss = 6.1536  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 2.1449  Validation loss = 6.1525  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 2.1446  Validation loss = 6.1520  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 2.1444  Validation loss = 6.1510  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 2.1439  Validation loss = 6.1504  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 2.1433  Validation loss = 6.1498  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 2.1429  Validation loss = 6.1478  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 2.1427  Validation loss = 6.1464  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 2.1423  Validation loss = 6.1453  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 2.1419  Validation loss = 6.1439  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 2.1414  Validation loss = 6.1428  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 2.1408  Validation loss = 6.1411  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 2.1403  Validation loss = 6.1400  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 2.1400  Validation loss = 6.1394  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 2.1396  Validation loss = 6.1392  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 2.1391  Validation loss = 6.1376  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 2.1389  Validation loss = 6.1372  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 2.1386  Validation loss = 6.1348  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 2.1383  Validation loss = 6.1337  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 2.1379  Validation loss = 6.1322  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 2.1375  Validation loss = 6.1309  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 2.1370  Validation loss = 6.1301  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 2.1368  Validation loss = 6.1302  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 2.1364  Validation loss = 6.1301  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 2.1360  Validation loss = 6.1288  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 2.1357  Validation loss = 6.1282  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 2.1355  Validation loss = 6.1273  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 2.1354  Validation loss = 6.1268  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 2.1348  Validation loss = 6.1238  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 2.1342  Validation loss = 6.1213  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 2.1338  Validation loss = 6.1197  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 2.1331  Validation loss = 6.1167  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 2.1327  Validation loss = 6.1157  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 2.1322  Validation loss = 6.1143  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 2.1319  Validation loss = 6.1140  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 2.1316  Validation loss = 6.1116  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 2.1312  Validation loss = 6.1111  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 2.1307  Validation loss = 6.1103  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 2.1304  Validation loss = 6.1088  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 2.1302  Validation loss = 6.1068  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 2.1298  Validation loss = 6.1052  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 2.1294  Validation loss = 6.1051  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 2.1289  Validation loss = 6.1036  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 2.1286  Validation loss = 6.1024  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 2.1283  Validation loss = 6.1010  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 2.1279  Validation loss = 6.0998  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 2.1277  Validation loss = 6.0992  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 2.1271  Validation loss = 6.0982  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 2.1266  Validation loss = 6.0963  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 2.1264  Validation loss = 6.0947  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 500  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.5934  Validation loss = 6.6746  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.5924  Validation loss = 6.6712  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.5915  Validation loss = 6.6690  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.5909  Validation loss = 6.6671  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.5904  Validation loss = 6.6660  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.5896  Validation loss = 6.6633  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.5885  Validation loss = 6.6601  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.5880  Validation loss = 6.6585  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.5873  Validation loss = 6.6551  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.5868  Validation loss = 6.6535  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.5864  Validation loss = 6.6520  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.5853  Validation loss = 6.6483  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.5846  Validation loss = 6.6463  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.5840  Validation loss = 6.6442  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.5834  Validation loss = 6.6421  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 2.5821  Validation loss = 6.6380  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 2.5814  Validation loss = 6.6356  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 2.5807  Validation loss = 6.6335  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 2.5799  Validation loss = 6.6313  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 2.5790  Validation loss = 6.6278  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.5779  Validation loss = 6.6257  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 2.5770  Validation loss = 6.6224  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 2.5764  Validation loss = 6.6206  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.5755  Validation loss = 6.6173  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 2.5744  Validation loss = 6.6142  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 2.5736  Validation loss = 6.6113  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 2.5729  Validation loss = 6.6082  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 2.5725  Validation loss = 6.6076  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 2.5718  Validation loss = 6.6042  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 2.5710  Validation loss = 6.6019  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 2.5706  Validation loss = 6.6006  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 2.5699  Validation loss = 6.5987  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 2.5692  Validation loss = 6.5968  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 2.5687  Validation loss = 6.5954  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 2.5682  Validation loss = 6.5938  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 2.5673  Validation loss = 6.5914  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 2.5666  Validation loss = 6.5884  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 2.5659  Validation loss = 6.5861  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 2.5650  Validation loss = 6.5824  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 2.5643  Validation loss = 6.5810  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 2.5635  Validation loss = 6.5778  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 2.5628  Validation loss = 6.5754  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 2.5625  Validation loss = 6.5741  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 2.5616  Validation loss = 6.5725  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 2.5606  Validation loss = 6.5690  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 2.5596  Validation loss = 6.5656  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 2.5587  Validation loss = 6.5621  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 2.5580  Validation loss = 6.5595  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 2.5573  Validation loss = 6.5576  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 2.5565  Validation loss = 6.5543  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 2.5556  Validation loss = 6.5518  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 2.5543  Validation loss = 6.5461  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 2.5536  Validation loss = 6.5439  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 2.5529  Validation loss = 6.5412  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 2.5525  Validation loss = 6.5396  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 2.5516  Validation loss = 6.5362  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 2.5507  Validation loss = 6.5335  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 2.5498  Validation loss = 6.5307  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 2.5489  Validation loss = 6.5282  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 2.5481  Validation loss = 6.5256  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 2.5475  Validation loss = 6.5225  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 2.5471  Validation loss = 6.5214  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 2.5463  Validation loss = 6.5182  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 2.5454  Validation loss = 6.5146  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 2.5447  Validation loss = 6.5125  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 2.5439  Validation loss = 6.5106  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 2.5431  Validation loss = 6.5089  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 2.5425  Validation loss = 6.5069  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 2.5421  Validation loss = 6.5034  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 2.5419  Validation loss = 6.5009  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 2.5409  Validation loss = 6.4990  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 2.5397  Validation loss = 6.4970  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 2.5387  Validation loss = 6.4945  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 2.5383  Validation loss = 6.4938  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 2.5376  Validation loss = 6.4918  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 2.5368  Validation loss = 6.4889  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 2.5362  Validation loss = 6.4873  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 2.5354  Validation loss = 6.4847  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 2.5350  Validation loss = 6.4832  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 2.5346  Validation loss = 6.4818  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 2.5336  Validation loss = 6.4787  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 2.5328  Validation loss = 6.4761  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 2.5320  Validation loss = 6.4729  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 2.5310  Validation loss = 6.4692  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 2.5303  Validation loss = 6.4670  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 2.5298  Validation loss = 6.4635  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 2.5294  Validation loss = 6.4613  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 2.5292  Validation loss = 6.4595  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 2.5285  Validation loss = 6.4567  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 2.5274  Validation loss = 6.4540  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 2.5267  Validation loss = 6.4517  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 2.5256  Validation loss = 6.4504  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 2.5247  Validation loss = 6.4481  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 2.5242  Validation loss = 6.4469  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 2.5233  Validation loss = 6.4444  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 2.5229  Validation loss = 6.4427  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 2.5224  Validation loss = 6.4406  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 2.5217  Validation loss = 6.4375  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 2.5208  Validation loss = 6.4361  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 2.5202  Validation loss = 6.4331  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 2.5194  Validation loss = 6.4310  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 2.5186  Validation loss = 6.4296  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 2.5182  Validation loss = 6.4284  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 2.5180  Validation loss = 6.4277  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 2.5174  Validation loss = 6.4260  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 2.5170  Validation loss = 6.4252  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 2.5163  Validation loss = 6.4240  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 2.5159  Validation loss = 6.4222  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 2.5157  Validation loss = 6.4210  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 2.5152  Validation loss = 6.4199  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 2.5149  Validation loss = 6.4188  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 2.5142  Validation loss = 6.4165  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 2.5139  Validation loss = 6.4151  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 2.5135  Validation loss = 6.4133  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 2.5128  Validation loss = 6.4110  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 2.5119  Validation loss = 6.4092  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 2.5113  Validation loss = 6.4073  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 2.5106  Validation loss = 6.4056  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 2.5098  Validation loss = 6.4033  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 2.5092  Validation loss = 6.4014  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 2.5083  Validation loss = 6.3989  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 2.5078  Validation loss = 6.3973  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 2.5073  Validation loss = 6.3964  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 2.5070  Validation loss = 6.3944  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 2.5067  Validation loss = 6.3933  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 2.5062  Validation loss = 6.3925  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 2.5059  Validation loss = 6.3914  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 2.5054  Validation loss = 6.3908  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 2.5051  Validation loss = 6.3900  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 2.5042  Validation loss = 6.3878  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 2.5032  Validation loss = 6.3844  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 2.5025  Validation loss = 6.3826  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 2.5018  Validation loss = 6.3802  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 2.5014  Validation loss = 6.3794  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 2.5011  Validation loss = 6.3775  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 2.4999  Validation loss = 6.3740  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 2.4997  Validation loss = 6.3726  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 2.4991  Validation loss = 6.3704  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 2.4987  Validation loss = 6.3692  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 2.4988  Validation loss = 6.3684  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 2.4974  Validation loss = 6.3662  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 2.4966  Validation loss = 6.3644  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 2.4958  Validation loss = 6.3618  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 2.4954  Validation loss = 6.3604  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 2.4947  Validation loss = 6.3582  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 2.4939  Validation loss = 6.3560  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 2.4931  Validation loss = 6.3541  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 2.4930  Validation loss = 6.3530  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 2.4931  Validation loss = 6.3528  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 2.4921  Validation loss = 6.3512  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 2.4914  Validation loss = 6.3489  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 2.4906  Validation loss = 6.3466  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 2.4901  Validation loss = 6.3452  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 2.4896  Validation loss = 6.3440  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 2.4893  Validation loss = 6.3426  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 2.4888  Validation loss = 6.3406  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 2.4883  Validation loss = 6.3394  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 2.4882  Validation loss = 6.3386  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 2.4876  Validation loss = 6.3371  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 2.4870  Validation loss = 6.3358  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 2.4867  Validation loss = 6.3348  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 2.4859  Validation loss = 6.3333  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 2.4852  Validation loss = 6.3309  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 2.4848  Validation loss = 6.3300  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 2.4840  Validation loss = 6.3278  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 2.4834  Validation loss = 6.3259  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 2.4830  Validation loss = 6.3249  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 2.4823  Validation loss = 6.3228  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 2.4814  Validation loss = 6.3205  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 2.4810  Validation loss = 6.3190  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 2.4801  Validation loss = 6.3165  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 2.4794  Validation loss = 6.3137  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 2.4787  Validation loss = 6.3121  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 2.4782  Validation loss = 6.3111  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 2.4780  Validation loss = 6.3106  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 2.4775  Validation loss = 6.3090  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 2.4772  Validation loss = 6.3082  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 2.4761  Validation loss = 6.3056  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 2.4755  Validation loss = 6.3037  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 2.4750  Validation loss = 6.3022  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 2.4742  Validation loss = 6.3004  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 2.4738  Validation loss = 6.2993  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 2.4732  Validation loss = 6.2966  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 2.4724  Validation loss = 6.2949  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 2.4719  Validation loss = 6.2931  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 2.4713  Validation loss = 6.2912  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 2.4708  Validation loss = 6.2903  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 2.4712  Validation loss = 6.2890  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 2.4706  Validation loss = 6.2877  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 2.4696  Validation loss = 6.2850  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 2.4688  Validation loss = 6.2839  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 2.4680  Validation loss = 6.2817  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 2.4673  Validation loss = 6.2808  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 2.4667  Validation loss = 6.2788  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 2.4660  Validation loss = 6.2768  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 2.4657  Validation loss = 6.2752  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 2.4654  Validation loss = 6.2729  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 2.4648  Validation loss = 6.2711  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 2.4637  Validation loss = 6.2698  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 2.4633  Validation loss = 6.2689  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 2.4625  Validation loss = 6.2673  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 2.4624  Validation loss = 6.2668  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 2.4618  Validation loss = 6.2652  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 2.4613  Validation loss = 6.2641  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 2.4607  Validation loss = 6.2611  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 2.4605  Validation loss = 6.2586  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 2.4605  Validation loss = 6.2573  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 2.4597  Validation loss = 6.2554  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 2.4587  Validation loss = 6.2530  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 2.4578  Validation loss = 6.2507  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 2.4571  Validation loss = 6.2492  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 2.4565  Validation loss = 6.2477  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 2.4558  Validation loss = 6.2469  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 2.4554  Validation loss = 6.2460  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 2.4548  Validation loss = 6.2447  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 2.4541  Validation loss = 6.2422  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 2.4538  Validation loss = 6.2405  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 2.4530  Validation loss = 6.2403  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 2.4524  Validation loss = 6.2390  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 2.4517  Validation loss = 6.2369  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 2.4510  Validation loss = 6.2345  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 2.4503  Validation loss = 6.2330  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 2.4498  Validation loss = 6.2318  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 2.4493  Validation loss = 6.2304  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 2.4486  Validation loss = 6.2284  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 2.4481  Validation loss = 6.2266  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 2.4475  Validation loss = 6.2252  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 2.4470  Validation loss = 6.2241  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 2.4466  Validation loss = 6.2234  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 2.4459  Validation loss = 6.2215  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 2.4451  Validation loss = 6.2192  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 2.4446  Validation loss = 6.2175  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 2.4438  Validation loss = 6.2155  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 2.4435  Validation loss = 6.2150  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 2.4432  Validation loss = 6.2147  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 2.4425  Validation loss = 6.2129  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 2.4424  Validation loss = 6.2122  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 2.4416  Validation loss = 6.2095  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 2.4408  Validation loss = 6.2075  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 2.4403  Validation loss = 6.2064  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 2.4398  Validation loss = 6.2047  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 2.4399  Validation loss = 6.2042  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 2.4395  Validation loss = 6.2029  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 2.4393  Validation loss = 6.2017  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 2.4384  Validation loss = 6.2003  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 2.4339  Validation loss = 6.1972  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 2.4329  Validation loss = 6.1959  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 2.4319  Validation loss = 6.1936  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 2.4313  Validation loss = 6.1922  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 2.4304  Validation loss = 6.1908  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 2.4301  Validation loss = 6.1901  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 2.4292  Validation loss = 6.1881  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 2.4288  Validation loss = 6.1875  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 2.4278  Validation loss = 6.1850  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 2.4271  Validation loss = 6.1829  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 2.4261  Validation loss = 6.1814  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 2.4258  Validation loss = 6.1802  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 2.4252  Validation loss = 6.1783  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 2.4248  Validation loss = 6.1775  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 2.4244  Validation loss = 6.1768  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 2.4238  Validation loss = 6.1750  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 2.4233  Validation loss = 6.1734  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 2.4226  Validation loss = 6.1717  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 2.4223  Validation loss = 6.1704  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 2.4220  Validation loss = 6.1700  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 2.4219  Validation loss = 6.1687  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 2.4216  Validation loss = 6.1663  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 2.4209  Validation loss = 6.1648  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 2.4205  Validation loss = 6.1641  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 2.4202  Validation loss = 6.1636  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 2.4198  Validation loss = 6.1632  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 2.4194  Validation loss = 6.1607  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 2.4181  Validation loss = 6.1593  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 2.4178  Validation loss = 6.1579  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 2.4175  Validation loss = 6.1566  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 2.4171  Validation loss = 6.1556  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 2.4164  Validation loss = 6.1537  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 2.4158  Validation loss = 6.1528  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 2.4154  Validation loss = 6.1524  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 2.4146  Validation loss = 6.1493  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 2.4140  Validation loss = 6.1477  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 2.4136  Validation loss = 6.1468  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 2.4133  Validation loss = 6.1464  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 2.4122  Validation loss = 6.1431  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 2.4121  Validation loss = 6.1420  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 2.4116  Validation loss = 6.1409  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 2.4112  Validation loss = 6.1394  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 2.4105  Validation loss = 6.1379  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 2.4096  Validation loss = 6.1360  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 2.4091  Validation loss = 6.1344  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 2.4092  Validation loss = 6.1333  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 2.4087  Validation loss = 6.1324  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 2.4077  Validation loss = 6.1302  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 2.4072  Validation loss = 6.1297  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 2.4066  Validation loss = 6.1286  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 2.4060  Validation loss = 6.1263  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 2.4055  Validation loss = 6.1253  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 2.4055  Validation loss = 6.1243  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 2.4047  Validation loss = 6.1228  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 2.4041  Validation loss = 6.1215  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 2.4036  Validation loss = 6.1193  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 2.4038  Validation loss = 6.1186  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 2.4033  Validation loss = 6.1170  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 2.4028  Validation loss = 6.1150  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 2.4020  Validation loss = 6.1136  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 2.4011  Validation loss = 6.1125  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 2.4004  Validation loss = 6.1111  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 2.3998  Validation loss = 6.1101  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 2.3992  Validation loss = 6.1082  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 2.3988  Validation loss = 6.1070  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 2.3980  Validation loss = 6.1056  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 2.3974  Validation loss = 6.1032  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 2.3971  Validation loss = 6.1016  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 2.3968  Validation loss = 6.1000  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 2.3964  Validation loss = 6.0984  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 2.3957  Validation loss = 6.0968  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 2.3950  Validation loss = 6.0966  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 2.3943  Validation loss = 6.0960  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 2.3939  Validation loss = 6.0951  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 2.3932  Validation loss = 6.0935  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 2.3929  Validation loss = 6.0924  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 2.3926  Validation loss = 6.0911  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 2.3928  Validation loss = 6.0900  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 2.3914  Validation loss = 6.0880  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 2.3911  Validation loss = 6.0867  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 2.3902  Validation loss = 6.0849  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 2.3897  Validation loss = 6.0836  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 2.3890  Validation loss = 6.0822  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 2.3885  Validation loss = 6.0808  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 2.3880  Validation loss = 6.0795  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 2.3871  Validation loss = 6.0772  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 2.3874  Validation loss = 6.0766  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 2.3875  Validation loss = 6.0751  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 2.3870  Validation loss = 6.0739  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 2.3869  Validation loss = 6.0729  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 2.3872  Validation loss = 6.0711  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 2.3840  Validation loss = 6.0680  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 2.3841  Validation loss = 6.0672  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 2.3843  Validation loss = 6.0660  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 2.3840  Validation loss = 6.0644  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 2.3834  Validation loss = 6.0631  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 2.3810  Validation loss = 6.0605  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 2.3807  Validation loss = 6.0593  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 2.3799  Validation loss = 6.0579  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 2.3793  Validation loss = 6.0561  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 2.3790  Validation loss = 6.0554  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 2.3787  Validation loss = 6.0535  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 2.3785  Validation loss = 6.0514  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 2.3785  Validation loss = 6.0501  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 2.3780  Validation loss = 6.0484  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 2.3772  Validation loss = 6.0475  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 2.3764  Validation loss = 6.0459  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 2.3762  Validation loss = 6.0447  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 2.3764  Validation loss = 6.0426  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 2.3752  Validation loss = 6.0421  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 2.3746  Validation loss = 6.0410  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 2.3740  Validation loss = 6.0387  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 2.3732  Validation loss = 6.0377  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 2.3721  Validation loss = 6.0360  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 2.3709  Validation loss = 6.0336  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 2.3703  Validation loss = 6.0321  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 2.3698  Validation loss = 6.0307  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 2.3696  Validation loss = 6.0286  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 2.3691  Validation loss = 6.0273  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 2.3682  Validation loss = 6.0261  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 2.3676  Validation loss = 6.0250  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 2.3671  Validation loss = 6.0236  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 2.3666  Validation loss = 6.0218  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 2.3654  Validation loss = 6.0200  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 2.3651  Validation loss = 6.0189  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 2.3644  Validation loss = 6.0167  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 2.3638  Validation loss = 6.0159  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 2.3634  Validation loss = 6.0152  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 2.3628  Validation loss = 6.0134  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 2.3625  Validation loss = 6.0113  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 2.3615  Validation loss = 6.0098  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 2.3612  Validation loss = 6.0086  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 2.3604  Validation loss = 6.0081  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 2.3600  Validation loss = 6.0073  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 2.3594  Validation loss = 6.0069  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 2.3587  Validation loss = 6.0053  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 2.3581  Validation loss = 6.0041  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 2.3578  Validation loss = 6.0033  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 2.3573  Validation loss = 6.0025  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 2.3568  Validation loss = 6.0019  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 2.3560  Validation loss = 5.9991  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 2.3554  Validation loss = 5.9974  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 2.3551  Validation loss = 5.9957  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 2.3546  Validation loss = 5.9950  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 2.3542  Validation loss = 5.9950  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 2.3538  Validation loss = 5.9935  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 2.3530  Validation loss = 5.9917  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 2.3525  Validation loss = 5.9907  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 2.3521  Validation loss = 5.9891  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 2.3517  Validation loss = 5.9877  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 2.3506  Validation loss = 5.9858  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 2.3500  Validation loss = 5.9849  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 2.3492  Validation loss = 5.9831  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 2.3482  Validation loss = 5.9816  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 2.3481  Validation loss = 5.9812  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 2.3474  Validation loss = 5.9801  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 2.3467  Validation loss = 5.9779  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 2.3460  Validation loss = 5.9763  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 2.3466  Validation loss = 5.9763  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 2.3464  Validation loss = 5.9749  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 2.3464  Validation loss = 5.9737  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 2.3459  Validation loss = 5.9720  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 2.3440  Validation loss = 5.9711  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 2.3430  Validation loss = 5.9694  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 2.3417  Validation loss = 5.9665  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 2.3410  Validation loss = 5.9649  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 2.3408  Validation loss = 5.9642  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 2.3410  Validation loss = 5.9639  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 2.3398  Validation loss = 5.9621  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 2.3394  Validation loss = 5.9600  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 2.3399  Validation loss = 5.9591  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 2.3393  Validation loss = 5.9590  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 2.3386  Validation loss = 5.9576  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 2.3375  Validation loss = 5.9565  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 2.3365  Validation loss = 5.9556  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 2.3358  Validation loss = 5.9540  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 2.3352  Validation loss = 5.9520  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 2.3348  Validation loss = 5.9514  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 2.3352  Validation loss = 5.9508  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 2.3344  Validation loss = 5.9491  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 2.3338  Validation loss = 5.9484  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 2.3330  Validation loss = 5.9475  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 2.3322  Validation loss = 5.9451  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 2.3320  Validation loss = 5.9447  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 2.3318  Validation loss = 5.9445  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 2.3312  Validation loss = 5.9436  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 2.3306  Validation loss = 5.9422  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 2.3299  Validation loss = 5.9407  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 2.3296  Validation loss = 5.9398  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 2.3290  Validation loss = 5.9382  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 2.3284  Validation loss = 5.9367  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 2.3282  Validation loss = 5.9370  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 2.3279  Validation loss = 5.9357  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 2.3279  Validation loss = 5.9346  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 2.3274  Validation loss = 5.9334  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 2.3277  Validation loss = 5.9323  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 2.3262  Validation loss = 5.9307  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 2.3257  Validation loss = 5.9290  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 2.3242  Validation loss = 5.9260  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 2.3236  Validation loss = 5.9243  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 2.3229  Validation loss = 5.9226  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 2.3220  Validation loss = 5.9200  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 2.3215  Validation loss = 5.9181  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 2.3210  Validation loss = 5.9165  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 2.3205  Validation loss = 5.9145  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 2.3201  Validation loss = 5.9135  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 2.3194  Validation loss = 5.9123  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 2.3191  Validation loss = 5.9117  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 2.3188  Validation loss = 5.9103  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 2.3183  Validation loss = 5.9090  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 2.3179  Validation loss = 5.9074  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 2.3177  Validation loss = 5.9061  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 2.3171  Validation loss = 5.9049  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 2.3172  Validation loss = 5.9039  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 2.3161  Validation loss = 5.9023  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 2.3161  Validation loss = 5.9015  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 2.3154  Validation loss = 5.9004  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 2.3146  Validation loss = 5.8977  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 2.3140  Validation loss = 5.8962  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 2.3137  Validation loss = 5.8940  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 2.3133  Validation loss = 5.8939  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 2.3128  Validation loss = 5.8923  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 2.3125  Validation loss = 5.8917  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 2.3122  Validation loss = 5.8907  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 2.3120  Validation loss = 5.8898  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 2.3114  Validation loss = 5.8870  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 2.3116  Validation loss = 5.8859  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 2.3112  Validation loss = 5.8850  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 2.3116  Validation loss = 5.8839  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 2.3110  Validation loss = 5.8829  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 2.3092  Validation loss = 5.8805  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 2.3093  Validation loss = 5.8790  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 2.3083  Validation loss = 5.8770  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 2.3084  Validation loss = 5.8759  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 2.3075  Validation loss = 5.8740  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 2.3074  Validation loss = 5.8730  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 2.3065  Validation loss = 5.8705  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 2.3060  Validation loss = 5.8683  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 2.3057  Validation loss = 5.8675  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 2.3055  Validation loss = 5.8666  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 2.3045  Validation loss = 5.8646  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 2.3048  Validation loss = 5.8635  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 2.3055  Validation loss = 5.8620  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 2.3043  Validation loss = 5.8613  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 2.3050  Validation loss = 5.8593  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 2.3045  Validation loss = 5.8576  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 2.3041  Validation loss = 5.8561  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 2.3022  Validation loss = 5.8560  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 2.3023  Validation loss = 5.8550  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 2.3019  Validation loss = 5.8540  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 2.3011  Validation loss = 5.8531  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 2.3009  Validation loss = 5.8521  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 2.3011  Validation loss = 5.8527  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 2.3004  Validation loss = 5.8505  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 2.2999  Validation loss = 5.8500  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.7037  Validation loss = 4.5706  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.7034  Validation loss = 4.5684  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.7023  Validation loss = 4.5684  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.7010  Validation loss = 4.5679  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.7004  Validation loss = 4.5678  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.6995  Validation loss = 4.5653  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.6994  Validation loss = 4.5635  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.6977  Validation loss = 4.5593  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.6973  Validation loss = 4.5619  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.6967  Validation loss = 4.5607  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.6954  Validation loss = 4.5539  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.6942  Validation loss = 4.5551  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.6933  Validation loss = 4.5514  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.6927  Validation loss = 4.5505  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.6922  Validation loss = 4.5483  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.6913  Validation loss = 4.5516  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.6913  Validation loss = 4.5467  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 2.6896  Validation loss = 4.5493  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 2.6888  Validation loss = 4.5472  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 2.6885  Validation loss = 4.5463  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 2.6879  Validation loss = 4.5511  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 2.6869  Validation loss = 4.5504  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 2.6867  Validation loss = 4.5539  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 20  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.9092  Validation loss = 3.1145  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.9081  Validation loss = 3.1122  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.9066  Validation loss = 3.1098  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.9055  Validation loss = 3.1076  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.9039  Validation loss = 3.1053  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.9021  Validation loss = 3.1035  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.9009  Validation loss = 3.1030  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.9000  Validation loss = 3.1016  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.8996  Validation loss = 3.1010  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.8990  Validation loss = 3.0994  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.8980  Validation loss = 3.0979  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.8969  Validation loss = 3.0964  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.8965  Validation loss = 3.0957  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.8949  Validation loss = 3.0926  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 2.8928  Validation loss = 3.0938  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 2.8918  Validation loss = 3.0924  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 2.8896  Validation loss = 3.0909  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 2.8895  Validation loss = 3.0919  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 2.8877  Validation loss = 3.0891  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 2.8867  Validation loss = 3.0875  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 2.8849  Validation loss = 3.0872  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 2.8841  Validation loss = 3.0887  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 2.8829  Validation loss = 3.0865  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 2.8822  Validation loss = 3.0838  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 2.8803  Validation loss = 3.0789  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 2.8805  Validation loss = 3.0774  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 2.8781  Validation loss = 3.0765  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 2.8771  Validation loss = 3.0740  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 2.8758  Validation loss = 3.0736  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 2.8752  Validation loss = 3.0736  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 2.8738  Validation loss = 3.0730  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 2.8735  Validation loss = 3.0715  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 2.8724  Validation loss = 3.0719  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 2.8712  Validation loss = 3.0701  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 2.8697  Validation loss = 3.0689  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 2.8689  Validation loss = 3.0687  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 2.8687  Validation loss = 3.0663  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 2.8671  Validation loss = 3.0650  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 2.8659  Validation loss = 3.0652  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 2.8652  Validation loss = 3.0633  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 2.8653  Validation loss = 3.0596  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 2.8629  Validation loss = 3.0567  \n",
      "\n",
      "Fold: 17  Epoch: 43  Training loss = 2.8611  Validation loss = 3.0561  \n",
      "\n",
      "Fold: 17  Epoch: 44  Training loss = 2.8594  Validation loss = 3.0548  \n",
      "\n",
      "Fold: 17  Epoch: 45  Training loss = 2.8584  Validation loss = 3.0525  \n",
      "\n",
      "Fold: 17  Epoch: 46  Training loss = 2.8572  Validation loss = 3.0501  \n",
      "\n",
      "Fold: 17  Epoch: 47  Training loss = 2.8560  Validation loss = 3.0512  \n",
      "\n",
      "Fold: 17  Epoch: 48  Training loss = 2.8543  Validation loss = 3.0509  \n",
      "\n",
      "Fold: 17  Epoch: 49  Training loss = 2.8533  Validation loss = 3.0507  \n",
      "\n",
      "Fold: 17  Epoch: 50  Training loss = 2.8518  Validation loss = 3.0498  \n",
      "\n",
      "Fold: 17  Epoch: 51  Training loss = 2.8515  Validation loss = 3.0520  \n",
      "\n",
      "Fold: 17  Epoch: 52  Training loss = 2.8507  Validation loss = 3.0512  \n",
      "\n",
      "Fold: 17  Epoch: 53  Training loss = 2.8496  Validation loss = 3.0509  \n",
      "\n",
      "Fold: 17  Epoch: 54  Training loss = 2.8485  Validation loss = 3.0464  \n",
      "\n",
      "Fold: 17  Epoch: 55  Training loss = 2.8485  Validation loss = 3.0441  \n",
      "\n",
      "Fold: 17  Epoch: 56  Training loss = 2.8473  Validation loss = 3.0444  \n",
      "\n",
      "Fold: 17  Epoch: 57  Training loss = 2.8461  Validation loss = 3.0447  \n",
      "\n",
      "Fold: 17  Epoch: 58  Training loss = 2.8453  Validation loss = 3.0444  \n",
      "\n",
      "Fold: 17  Epoch: 59  Training loss = 2.8440  Validation loss = 3.0461  \n",
      "\n",
      "Fold: 17  Epoch: 60  Training loss = 2.8428  Validation loss = 3.0484  \n",
      "\n",
      "Fold: 17  Epoch: 61  Training loss = 2.8420  Validation loss = 3.0495  \n",
      "\n",
      "Fold: 17  Epoch: 62  Training loss = 2.8409  Validation loss = 3.0493  \n",
      "\n",
      "Fold: 17  Epoch: 63  Training loss = 2.8399  Validation loss = 3.0486  \n",
      "\n",
      "Fold: 17  Epoch: 64  Training loss = 2.8388  Validation loss = 3.0473  \n",
      "\n",
      "Fold: 17  Epoch: 65  Training loss = 2.8383  Validation loss = 3.0451  \n",
      "\n",
      "Fold: 17  Epoch: 66  Training loss = 2.8376  Validation loss = 3.0457  \n",
      "\n",
      "Fold: 17  Epoch: 67  Training loss = 2.8363  Validation loss = 3.0460  \n",
      "\n",
      "Fold: 17  Epoch: 68  Training loss = 2.8349  Validation loss = 3.0473  \n",
      "\n",
      "Fold: 17  Epoch: 69  Training loss = 2.8334  Validation loss = 3.0455  \n",
      "\n",
      "Fold: 17  Epoch: 70  Training loss = 2.8329  Validation loss = 3.0480  \n",
      "\n",
      "Fold: 17  Epoch: 71  Training loss = 2.8317  Validation loss = 3.0488  \n",
      "\n",
      "Fold: 17  Epoch: 72  Training loss = 2.8306  Validation loss = 3.0461  \n",
      "\n",
      "Fold: 17  Epoch: 73  Training loss = 2.8288  Validation loss = 3.0425  \n",
      "\n",
      "Fold: 17  Epoch: 74  Training loss = 2.8280  Validation loss = 3.0415  \n",
      "\n",
      "Fold: 17  Epoch: 75  Training loss = 2.8265  Validation loss = 3.0411  \n",
      "\n",
      "Fold: 17  Epoch: 76  Training loss = 2.8251  Validation loss = 3.0402  \n",
      "\n",
      "Fold: 17  Epoch: 77  Training loss = 2.8244  Validation loss = 3.0416  \n",
      "\n",
      "Fold: 17  Epoch: 78  Training loss = 2.8232  Validation loss = 3.0408  \n",
      "\n",
      "Fold: 17  Epoch: 79  Training loss = 2.8225  Validation loss = 3.0372  \n",
      "\n",
      "Fold: 17  Epoch: 80  Training loss = 2.8217  Validation loss = 3.0363  \n",
      "\n",
      "Fold: 17  Epoch: 81  Training loss = 2.8206  Validation loss = 3.0331  \n",
      "\n",
      "Fold: 17  Epoch: 82  Training loss = 2.8199  Validation loss = 3.0319  \n",
      "\n",
      "Fold: 17  Epoch: 83  Training loss = 2.8195  Validation loss = 3.0313  \n",
      "\n",
      "Fold: 17  Epoch: 84  Training loss = 2.8189  Validation loss = 3.0289  \n",
      "\n",
      "Fold: 17  Epoch: 85  Training loss = 2.8177  Validation loss = 3.0261  \n",
      "\n",
      "Fold: 17  Epoch: 86  Training loss = 2.8167  Validation loss = 3.0259  \n",
      "\n",
      "Fold: 17  Epoch: 87  Training loss = 2.8130  Validation loss = 3.0272  \n",
      "\n",
      "Fold: 17  Epoch: 88  Training loss = 2.8129  Validation loss = 3.0231  \n",
      "\n",
      "Fold: 17  Epoch: 89  Training loss = 2.8115  Validation loss = 3.0249  \n",
      "\n",
      "Fold: 17  Epoch: 90  Training loss = 2.8114  Validation loss = 3.0208  \n",
      "\n",
      "Fold: 17  Epoch: 91  Training loss = 2.8085  Validation loss = 3.0265  \n",
      "\n",
      "Fold: 17  Epoch: 92  Training loss = 2.8072  Validation loss = 3.0238  \n",
      "\n",
      "Fold: 17  Epoch: 93  Training loss = 2.8066  Validation loss = 3.0226  \n",
      "\n",
      "Fold: 17  Epoch: 94  Training loss = 2.8052  Validation loss = 3.0237  \n",
      "\n",
      "Fold: 17  Epoch: 95  Training loss = 2.8049  Validation loss = 3.0228  \n",
      "\n",
      "Fold: 17  Epoch: 96  Training loss = 2.8039  Validation loss = 3.0229  \n",
      "\n",
      "Fold: 17  Epoch: 97  Training loss = 2.8015  Validation loss = 3.0239  \n",
      "\n",
      "Fold: 17  Epoch: 98  Training loss = 2.7998  Validation loss = 3.0234  \n",
      "\n",
      "Fold: 17  Epoch: 99  Training loss = 2.7987  Validation loss = 3.0198  \n",
      "\n",
      "Fold: 17  Epoch: 100  Training loss = 2.8000  Validation loss = 3.0179  \n",
      "\n",
      "Fold: 17  Epoch: 101  Training loss = 2.7964  Validation loss = 3.0241  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 100  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.8920  Validation loss = 1.2009  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.8901  Validation loss = 1.2059  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.8897  Validation loss = 1.2105  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 2.8882  Validation loss = 1.2083  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.8879  Validation loss = 1.2123  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.8867  Validation loss = 1.2116  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.8848  Validation loss = 1.2074  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.8841  Validation loss = 1.2078  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.8835  Validation loss = 1.2117  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.8823  Validation loss = 1.2108  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.8803  Validation loss = 1.2050  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 2.8791  Validation loss = 1.2059  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 2.8782  Validation loss = 1.2041  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 2.8768  Validation loss = 1.2093  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 2.8754  Validation loss = 1.2084  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 2.8741  Validation loss = 1.2097  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 2.8745  Validation loss = 1.2196  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 1  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.8323  Validation loss = 2.2773  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.8286  Validation loss = 2.2767  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.8273  Validation loss = 2.2763  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.8251  Validation loss = 2.2749  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.8221  Validation loss = 2.2748  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.8201  Validation loss = 2.2749  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.8186  Validation loss = 2.2743  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 2.8171  Validation loss = 2.2735  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.8148  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 2.8113  Validation loss = 2.2699  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.8102  Validation loss = 2.2683  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.8086  Validation loss = 2.2673  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 2.8065  Validation loss = 2.2653  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.8047  Validation loss = 2.2635  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 2.8032  Validation loss = 2.2628  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.8020  Validation loss = 2.2632  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 2.8008  Validation loss = 2.2627  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 2.7990  Validation loss = 2.2614  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 2.7980  Validation loss = 2.2615  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 2.7977  Validation loss = 2.2610  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 2.7964  Validation loss = 2.2602  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 2.7952  Validation loss = 2.2601  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 2.7944  Validation loss = 2.2594  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 2.7932  Validation loss = 2.2587  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 2.7919  Validation loss = 2.2591  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 2.7911  Validation loss = 2.2600  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 2.7895  Validation loss = 2.2602  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 2.7878  Validation loss = 2.2621  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 24  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.8321  Validation loss = 1.1399  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.8313  Validation loss = 1.1375  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.8292  Validation loss = 1.1336  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.8264  Validation loss = 1.1296  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.8254  Validation loss = 1.1293  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.8234  Validation loss = 1.1267  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.8213  Validation loss = 1.1223  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.8196  Validation loss = 1.1194  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.8179  Validation loss = 1.1156  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.8166  Validation loss = 1.1153  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.8160  Validation loss = 1.1153  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.8142  Validation loss = 1.1142  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 2.8127  Validation loss = 1.1106  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.8106  Validation loss = 1.1066  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.8097  Validation loss = 1.1074  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.8090  Validation loss = 1.1080  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.8077  Validation loss = 1.1064  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.8060  Validation loss = 1.1040  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 2.8056  Validation loss = 1.1017  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 2.8045  Validation loss = 1.1023  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 2.8033  Validation loss = 1.1002  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 2.8026  Validation loss = 1.0998  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 2.8015  Validation loss = 1.0970  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 2.8010  Validation loss = 1.0953  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 2.7989  Validation loss = 1.0931  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 2.7990  Validation loss = 1.0933  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 2.7985  Validation loss = 1.0942  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 2.7969  Validation loss = 1.0927  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 2.7953  Validation loss = 1.0907  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 2.7946  Validation loss = 1.0904  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 2.7930  Validation loss = 1.0882  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 2.7922  Validation loss = 1.0871  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 2.7911  Validation loss = 1.0862  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 2.7885  Validation loss = 1.0812  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 2.7877  Validation loss = 1.0800  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 2.7862  Validation loss = 1.0779  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 2.7849  Validation loss = 1.0762  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 2.7832  Validation loss = 1.0740  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 2.7837  Validation loss = 1.0769  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 2.7840  Validation loss = 1.0779  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 2.7812  Validation loss = 1.0735  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 2.7802  Validation loss = 1.0717  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 2.7788  Validation loss = 1.0704  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 2.7786  Validation loss = 1.0707  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 2.7776  Validation loss = 1.0694  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 2.7778  Validation loss = 1.0699  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 2.7757  Validation loss = 1.0667  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 2.7744  Validation loss = 1.0639  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 2.7734  Validation loss = 1.0620  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 2.7728  Validation loss = 1.0628  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 2.7723  Validation loss = 1.0625  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 2.7710  Validation loss = 1.0602  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 2.7699  Validation loss = 1.0592  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 2.7694  Validation loss = 1.0604  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 2.7686  Validation loss = 1.0589  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 2.7672  Validation loss = 1.0556  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 2.7668  Validation loss = 1.0541  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 2.7657  Validation loss = 1.0511  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 2.7645  Validation loss = 1.0485  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 2.7631  Validation loss = 1.0476  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 2.7618  Validation loss = 1.0463  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 2.7613  Validation loss = 1.0454  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 2.7626  Validation loss = 1.0454  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 2.7603  Validation loss = 1.0445  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 2.7595  Validation loss = 1.0433  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 2.7574  Validation loss = 1.0382  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 2.7567  Validation loss = 1.0386  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 2.7560  Validation loss = 1.0382  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 2.7553  Validation loss = 1.0384  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 2.7550  Validation loss = 1.0379  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 2.7543  Validation loss = 1.0348  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 2.7538  Validation loss = 1.0334  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 2.7528  Validation loss = 1.0322  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 2.7517  Validation loss = 1.0319  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 2.7514  Validation loss = 1.0294  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 2.7493  Validation loss = 1.0254  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 2.7480  Validation loss = 1.0216  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 2.7474  Validation loss = 1.0193  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 2.7463  Validation loss = 1.0188  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 2.7453  Validation loss = 1.0165  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 2.7444  Validation loss = 1.0163  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 2.7429  Validation loss = 1.0131  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 2.7418  Validation loss = 1.0110  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 2.7408  Validation loss = 1.0098  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 2.7398  Validation loss = 1.0084  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 2.7393  Validation loss = 1.0083  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 2.7378  Validation loss = 1.0047  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 2.7368  Validation loss = 1.0025  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 2.7359  Validation loss = 1.0005  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 2.7349  Validation loss = 0.9985  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 2.7339  Validation loss = 0.9972  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 2.7333  Validation loss = 0.9944  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 2.7326  Validation loss = 0.9942  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 2.7318  Validation loss = 0.9924  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 2.7317  Validation loss = 0.9901  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 2.7312  Validation loss = 0.9883  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 2.7307  Validation loss = 0.9872  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 2.7294  Validation loss = 0.9859  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 2.7288  Validation loss = 0.9843  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 2.7281  Validation loss = 0.9816  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 2.7263  Validation loss = 0.9802  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 2.7252  Validation loss = 0.9781  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 2.7250  Validation loss = 0.9764  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 2.7245  Validation loss = 0.9753  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 2.7222  Validation loss = 0.9748  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 2.7206  Validation loss = 0.9734  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 2.7204  Validation loss = 0.9729  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 2.7198  Validation loss = 0.9716  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 2.7202  Validation loss = 0.9701  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 2.7202  Validation loss = 0.9665  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 2.7181  Validation loss = 0.9656  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 2.7173  Validation loss = 0.9642  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 2.7164  Validation loss = 0.9643  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 2.7165  Validation loss = 0.9633  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 2.7158  Validation loss = 0.9635  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 2.7145  Validation loss = 0.9639  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 2.7137  Validation loss = 0.9630  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 2.7131  Validation loss = 0.9623  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 2.7125  Validation loss = 0.9616  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 2.7122  Validation loss = 0.9608  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 2.7114  Validation loss = 0.9581  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 2.7132  Validation loss = 0.9590  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 2.7089  Validation loss = 0.9567  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 2.7079  Validation loss = 0.9544  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 2.7071  Validation loss = 0.9540  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 2.7064  Validation loss = 0.9522  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 2.7057  Validation loss = 0.9510  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 2.7053  Validation loss = 0.9496  \n",
      "\n",
      "Fold: 20  Epoch: 129  Training loss = 2.7051  Validation loss = 0.9494  \n",
      "\n",
      "Fold: 20  Epoch: 130  Training loss = 2.7042  Validation loss = 0.9491  \n",
      "\n",
      "Fold: 20  Epoch: 131  Training loss = 2.7039  Validation loss = 0.9476  \n",
      "\n",
      "Fold: 20  Epoch: 132  Training loss = 2.7028  Validation loss = 0.9455  \n",
      "\n",
      "Fold: 20  Epoch: 133  Training loss = 2.7017  Validation loss = 0.9442  \n",
      "\n",
      "Fold: 20  Epoch: 134  Training loss = 2.7018  Validation loss = 0.9449  \n",
      "\n",
      "Fold: 20  Epoch: 135  Training loss = 2.7017  Validation loss = 0.9455  \n",
      "\n",
      "Fold: 20  Epoch: 136  Training loss = 2.7007  Validation loss = 0.9433  \n",
      "\n",
      "Fold: 20  Epoch: 137  Training loss = 2.6996  Validation loss = 0.9413  \n",
      "\n",
      "Fold: 20  Epoch: 138  Training loss = 2.6988  Validation loss = 0.9385  \n",
      "\n",
      "Fold: 20  Epoch: 139  Training loss = 2.6982  Validation loss = 0.9393  \n",
      "\n",
      "Fold: 20  Epoch: 140  Training loss = 2.7009  Validation loss = 0.9396  \n",
      "\n",
      "Fold: 20  Epoch: 141  Training loss = 2.6980  Validation loss = 0.9396  \n",
      "\n",
      "Fold: 20  Epoch: 142  Training loss = 2.6968  Validation loss = 0.9403  \n",
      "\n",
      "Fold: 20  Epoch: 143  Training loss = 2.6961  Validation loss = 0.9388  \n",
      "\n",
      "Fold: 20  Epoch: 144  Training loss = 2.6957  Validation loss = 0.9387  \n",
      "\n",
      "Fold: 20  Epoch: 145  Training loss = 2.6945  Validation loss = 0.9361  \n",
      "\n",
      "Fold: 20  Epoch: 146  Training loss = 2.6933  Validation loss = 0.9337  \n",
      "\n",
      "Fold: 20  Epoch: 147  Training loss = 2.6924  Validation loss = 0.9309  \n",
      "\n",
      "Fold: 20  Epoch: 148  Training loss = 2.6917  Validation loss = 0.9307  \n",
      "\n",
      "Fold: 20  Epoch: 149  Training loss = 2.6918  Validation loss = 0.9306  \n",
      "\n",
      "Fold: 20  Epoch: 150  Training loss = 2.6906  Validation loss = 0.9291  \n",
      "\n",
      "Fold: 20  Epoch: 151  Training loss = 2.6901  Validation loss = 0.9289  \n",
      "\n",
      "Fold: 20  Epoch: 152  Training loss = 2.6886  Validation loss = 0.9267  \n",
      "\n",
      "Fold: 20  Epoch: 153  Training loss = 2.6882  Validation loss = 0.9256  \n",
      "\n",
      "Fold: 20  Epoch: 154  Training loss = 2.6881  Validation loss = 0.9246  \n",
      "\n",
      "Fold: 20  Epoch: 155  Training loss = 2.6873  Validation loss = 0.9233  \n",
      "\n",
      "Fold: 20  Epoch: 156  Training loss = 2.6865  Validation loss = 0.9218  \n",
      "\n",
      "Fold: 20  Epoch: 157  Training loss = 2.6869  Validation loss = 0.9232  \n",
      "\n",
      "Fold: 20  Epoch: 158  Training loss = 2.6870  Validation loss = 0.9242  \n",
      "\n",
      "Fold: 20  Epoch: 159  Training loss = 2.6854  Validation loss = 0.9252  \n",
      "\n",
      "Fold: 20  Epoch: 160  Training loss = 2.6838  Validation loss = 0.9217  \n",
      "\n",
      "Fold: 20  Epoch: 161  Training loss = 2.6829  Validation loss = 0.9199  \n",
      "\n",
      "Fold: 20  Epoch: 162  Training loss = 2.6820  Validation loss = 0.9186  \n",
      "\n",
      "Fold: 20  Epoch: 163  Training loss = 2.6811  Validation loss = 0.9182  \n",
      "\n",
      "Fold: 20  Epoch: 164  Training loss = 2.6804  Validation loss = 0.9165  \n",
      "\n",
      "Fold: 20  Epoch: 165  Training loss = 2.6796  Validation loss = 0.9152  \n",
      "\n",
      "Fold: 20  Epoch: 166  Training loss = 2.6791  Validation loss = 0.9155  \n",
      "\n",
      "Fold: 20  Epoch: 167  Training loss = 2.6790  Validation loss = 0.9147  \n",
      "\n",
      "Fold: 20  Epoch: 168  Training loss = 2.6776  Validation loss = 0.9128  \n",
      "\n",
      "Fold: 20  Epoch: 169  Training loss = 2.6769  Validation loss = 0.9120  \n",
      "\n",
      "Fold: 20  Epoch: 170  Training loss = 2.6769  Validation loss = 0.9109  \n",
      "\n",
      "Fold: 20  Epoch: 171  Training loss = 2.6752  Validation loss = 0.9101  \n",
      "\n",
      "Fold: 20  Epoch: 172  Training loss = 2.6743  Validation loss = 0.9082  \n",
      "\n",
      "Fold: 20  Epoch: 173  Training loss = 2.6739  Validation loss = 0.9062  \n",
      "\n",
      "Fold: 20  Epoch: 174  Training loss = 2.6739  Validation loss = 0.9068  \n",
      "\n",
      "Fold: 20  Epoch: 175  Training loss = 2.6750  Validation loss = 0.9075  \n",
      "\n",
      "Fold: 20  Epoch: 176  Training loss = 2.6725  Validation loss = 0.9040  \n",
      "\n",
      "Fold: 20  Epoch: 177  Training loss = 2.6711  Validation loss = 0.9029  \n",
      "\n",
      "Fold: 20  Epoch: 178  Training loss = 2.6702  Validation loss = 0.9017  \n",
      "\n",
      "Fold: 20  Epoch: 179  Training loss = 2.6696  Validation loss = 0.9005  \n",
      "\n",
      "Fold: 20  Epoch: 180  Training loss = 2.6691  Validation loss = 0.9007  \n",
      "\n",
      "Fold: 20  Epoch: 181  Training loss = 2.6683  Validation loss = 0.8992  \n",
      "\n",
      "Fold: 20  Epoch: 182  Training loss = 2.6686  Validation loss = 0.8978  \n",
      "\n",
      "Fold: 20  Epoch: 183  Training loss = 2.6676  Validation loss = 0.8960  \n",
      "\n",
      "Fold: 20  Epoch: 184  Training loss = 2.6661  Validation loss = 0.8949  \n",
      "\n",
      "Fold: 20  Epoch: 185  Training loss = 2.6658  Validation loss = 0.8942  \n",
      "\n",
      "Fold: 20  Epoch: 186  Training loss = 2.6653  Validation loss = 0.8941  \n",
      "\n",
      "Fold: 20  Epoch: 187  Training loss = 2.6648  Validation loss = 0.8923  \n",
      "\n",
      "Fold: 20  Epoch: 188  Training loss = 2.6636  Validation loss = 0.8914  \n",
      "\n",
      "Fold: 20  Epoch: 189  Training loss = 2.6632  Validation loss = 0.8911  \n",
      "\n",
      "Fold: 20  Epoch: 190  Training loss = 2.6614  Validation loss = 0.8906  \n",
      "\n",
      "Fold: 20  Epoch: 191  Training loss = 2.6608  Validation loss = 0.8895  \n",
      "\n",
      "Fold: 20  Epoch: 192  Training loss = 2.6604  Validation loss = 0.8889  \n",
      "\n",
      "Fold: 20  Epoch: 193  Training loss = 2.6598  Validation loss = 0.8878  \n",
      "\n",
      "Fold: 20  Epoch: 194  Training loss = 2.6594  Validation loss = 0.8876  \n",
      "\n",
      "Fold: 20  Epoch: 195  Training loss = 2.6584  Validation loss = 0.8854  \n",
      "\n",
      "Fold: 20  Epoch: 196  Training loss = 2.6580  Validation loss = 0.8845  \n",
      "\n",
      "Fold: 20  Epoch: 197  Training loss = 2.6574  Validation loss = 0.8820  \n",
      "\n",
      "Fold: 20  Epoch: 198  Training loss = 2.6561  Validation loss = 0.8801  \n",
      "\n",
      "Fold: 20  Epoch: 199  Training loss = 2.6550  Validation loss = 0.8783  \n",
      "\n",
      "Fold: 20  Epoch: 200  Training loss = 2.6564  Validation loss = 0.8797  \n",
      "\n",
      "Fold: 20  Epoch: 201  Training loss = 2.6540  Validation loss = 0.8778  \n",
      "\n",
      "Fold: 20  Epoch: 202  Training loss = 2.6529  Validation loss = 0.8759  \n",
      "\n",
      "Fold: 20  Epoch: 203  Training loss = 2.6523  Validation loss = 0.8752  \n",
      "\n",
      "Fold: 20  Epoch: 204  Training loss = 2.6519  Validation loss = 0.8759  \n",
      "\n",
      "Fold: 20  Epoch: 205  Training loss = 2.6515  Validation loss = 0.8763  \n",
      "\n",
      "Fold: 20  Epoch: 206  Training loss = 2.6509  Validation loss = 0.8748  \n",
      "\n",
      "Fold: 20  Epoch: 207  Training loss = 2.6508  Validation loss = 0.8751  \n",
      "\n",
      "Fold: 20  Epoch: 208  Training loss = 2.6501  Validation loss = 0.8742  \n",
      "\n",
      "Fold: 20  Epoch: 209  Training loss = 2.6494  Validation loss = 0.8719  \n",
      "\n",
      "Fold: 20  Epoch: 210  Training loss = 2.6486  Validation loss = 0.8701  \n",
      "\n",
      "Fold: 20  Epoch: 211  Training loss = 2.6476  Validation loss = 0.8688  \n",
      "\n",
      "Fold: 20  Epoch: 212  Training loss = 2.6469  Validation loss = 0.8681  \n",
      "\n",
      "Fold: 20  Epoch: 213  Training loss = 2.6499  Validation loss = 0.8685  \n",
      "\n",
      "Fold: 20  Epoch: 214  Training loss = 2.6479  Validation loss = 0.8679  \n",
      "\n",
      "Fold: 20  Epoch: 215  Training loss = 2.6456  Validation loss = 0.8678  \n",
      "\n",
      "Fold: 20  Epoch: 216  Training loss = 2.6447  Validation loss = 0.8670  \n",
      "\n",
      "Fold: 20  Epoch: 217  Training loss = 2.6442  Validation loss = 0.8673  \n",
      "\n",
      "Fold: 20  Epoch: 218  Training loss = 2.6436  Validation loss = 0.8673  \n",
      "\n",
      "Fold: 20  Epoch: 219  Training loss = 2.6431  Validation loss = 0.8656  \n",
      "\n",
      "Fold: 20  Epoch: 220  Training loss = 2.6425  Validation loss = 0.8636  \n",
      "\n",
      "Fold: 20  Epoch: 221  Training loss = 2.6415  Validation loss = 0.8624  \n",
      "\n",
      "Fold: 20  Epoch: 222  Training loss = 2.6408  Validation loss = 0.8621  \n",
      "\n",
      "Fold: 20  Epoch: 223  Training loss = 2.6396  Validation loss = 0.8607  \n",
      "\n",
      "Fold: 20  Epoch: 224  Training loss = 2.6386  Validation loss = 0.8593  \n",
      "\n",
      "Fold: 20  Epoch: 225  Training loss = 2.6378  Validation loss = 0.8584  \n",
      "\n",
      "Fold: 20  Epoch: 226  Training loss = 2.6374  Validation loss = 0.8558  \n",
      "\n",
      "Fold: 20  Epoch: 227  Training loss = 2.6364  Validation loss = 0.8548  \n",
      "\n",
      "Fold: 20  Epoch: 228  Training loss = 2.6357  Validation loss = 0.8527  \n",
      "\n",
      "Fold: 20  Epoch: 229  Training loss = 2.6351  Validation loss = 0.8520  \n",
      "\n",
      "Fold: 20  Epoch: 230  Training loss = 2.6348  Validation loss = 0.8509  \n",
      "\n",
      "Fold: 20  Epoch: 231  Training loss = 2.6341  Validation loss = 0.8509  \n",
      "\n",
      "Fold: 20  Epoch: 232  Training loss = 2.6334  Validation loss = 0.8511  \n",
      "\n",
      "Fold: 20  Epoch: 233  Training loss = 2.6327  Validation loss = 0.8517  \n",
      "\n",
      "Fold: 20  Epoch: 234  Training loss = 2.6326  Validation loss = 0.8527  \n",
      "\n",
      "Fold: 20  Epoch: 235  Training loss = 2.6319  Validation loss = 0.8521  \n",
      "\n",
      "Fold: 20  Epoch: 236  Training loss = 2.6315  Validation loss = 0.8510  \n",
      "\n",
      "Fold: 20  Epoch: 237  Training loss = 2.6302  Validation loss = 0.8485  \n",
      "\n",
      "Fold: 20  Epoch: 238  Training loss = 2.6298  Validation loss = 0.8491  \n",
      "\n",
      "Fold: 20  Epoch: 239  Training loss = 2.6294  Validation loss = 0.8484  \n",
      "\n",
      "Fold: 20  Epoch: 240  Training loss = 2.6289  Validation loss = 0.8463  \n",
      "\n",
      "Fold: 20  Epoch: 241  Training loss = 2.6278  Validation loss = 0.8456  \n",
      "\n",
      "Fold: 20  Epoch: 242  Training loss = 2.6271  Validation loss = 0.8442  \n",
      "\n",
      "Fold: 20  Epoch: 243  Training loss = 2.6268  Validation loss = 0.8432  \n",
      "\n",
      "Fold: 20  Epoch: 244  Training loss = 2.6274  Validation loss = 0.8416  \n",
      "\n",
      "Fold: 20  Epoch: 245  Training loss = 2.6262  Validation loss = 0.8416  \n",
      "\n",
      "Fold: 20  Epoch: 246  Training loss = 2.6259  Validation loss = 0.8401  \n",
      "\n",
      "Fold: 20  Epoch: 247  Training loss = 2.6246  Validation loss = 0.8400  \n",
      "\n",
      "Fold: 20  Epoch: 248  Training loss = 2.6246  Validation loss = 0.8402  \n",
      "\n",
      "Fold: 20  Epoch: 249  Training loss = 2.6234  Validation loss = 0.8391  \n",
      "\n",
      "Fold: 20  Epoch: 250  Training loss = 2.6226  Validation loss = 0.8385  \n",
      "\n",
      "Fold: 20  Epoch: 251  Training loss = 2.6221  Validation loss = 0.8369  \n",
      "\n",
      "Fold: 20  Epoch: 252  Training loss = 2.6215  Validation loss = 0.8370  \n",
      "\n",
      "Fold: 20  Epoch: 253  Training loss = 2.6212  Validation loss = 0.8364  \n",
      "\n",
      "Fold: 20  Epoch: 254  Training loss = 2.6211  Validation loss = 0.8363  \n",
      "\n",
      "Fold: 20  Epoch: 255  Training loss = 2.6206  Validation loss = 0.8352  \n",
      "\n",
      "Fold: 20  Epoch: 256  Training loss = 2.6204  Validation loss = 0.8331  \n",
      "\n",
      "Fold: 20  Epoch: 257  Training loss = 2.6206  Validation loss = 0.8327  \n",
      "\n",
      "Fold: 20  Epoch: 258  Training loss = 2.6211  Validation loss = 0.8320  \n",
      "\n",
      "Fold: 20  Epoch: 259  Training loss = 2.6206  Validation loss = 0.8319  \n",
      "\n",
      "Fold: 20  Epoch: 260  Training loss = 2.6224  Validation loss = 0.8303  \n",
      "\n",
      "Fold: 20  Epoch: 261  Training loss = 2.6217  Validation loss = 0.8292  \n",
      "\n",
      "Fold: 20  Epoch: 262  Training loss = 2.6230  Validation loss = 0.8285  \n",
      "\n",
      "Fold: 20  Epoch: 263  Training loss = 2.6204  Validation loss = 0.8281  \n",
      "\n",
      "Fold: 20  Epoch: 264  Training loss = 2.6191  Validation loss = 0.8271  \n",
      "\n",
      "Fold: 20  Epoch: 265  Training loss = 2.6159  Validation loss = 0.8262  \n",
      "\n",
      "Fold: 20  Epoch: 266  Training loss = 2.6151  Validation loss = 0.8261  \n",
      "\n",
      "Fold: 20  Epoch: 267  Training loss = 2.6145  Validation loss = 0.8249  \n",
      "\n",
      "Fold: 20  Epoch: 268  Training loss = 2.6143  Validation loss = 0.8244  \n",
      "\n",
      "Fold: 20  Epoch: 269  Training loss = 2.6135  Validation loss = 0.8228  \n",
      "\n",
      "Fold: 20  Epoch: 270  Training loss = 2.6127  Validation loss = 0.8211  \n",
      "\n",
      "Fold: 20  Epoch: 271  Training loss = 2.6124  Validation loss = 0.8208  \n",
      "\n",
      "Fold: 20  Epoch: 272  Training loss = 2.6114  Validation loss = 0.8192  \n",
      "\n",
      "Fold: 20  Epoch: 273  Training loss = 2.6114  Validation loss = 0.8171  \n",
      "\n",
      "Fold: 20  Epoch: 274  Training loss = 2.6107  Validation loss = 0.8165  \n",
      "\n",
      "Fold: 20  Epoch: 275  Training loss = 2.6104  Validation loss = 0.8161  \n",
      "\n",
      "Fold: 20  Epoch: 276  Training loss = 2.6111  Validation loss = 0.8147  \n",
      "\n",
      "Fold: 20  Epoch: 277  Training loss = 2.6118  Validation loss = 0.8152  \n",
      "\n",
      "Fold: 20  Epoch: 278  Training loss = 2.6120  Validation loss = 0.8145  \n",
      "\n",
      "Fold: 20  Epoch: 279  Training loss = 2.6084  Validation loss = 0.8149  \n",
      "\n",
      "Fold: 20  Epoch: 280  Training loss = 2.6079  Validation loss = 0.8149  \n",
      "\n",
      "Fold: 20  Epoch: 281  Training loss = 2.6070  Validation loss = 0.8137  \n",
      "\n",
      "Fold: 20  Epoch: 282  Training loss = 2.6069  Validation loss = 0.8122  \n",
      "\n",
      "Fold: 20  Epoch: 283  Training loss = 2.6062  Validation loss = 0.8123  \n",
      "\n",
      "Fold: 20  Epoch: 284  Training loss = 2.6058  Validation loss = 0.8117  \n",
      "\n",
      "Fold: 20  Epoch: 285  Training loss = 2.6060  Validation loss = 0.8117  \n",
      "\n",
      "Fold: 20  Epoch: 286  Training loss = 2.6053  Validation loss = 0.8111  \n",
      "\n",
      "Fold: 20  Epoch: 287  Training loss = 2.6044  Validation loss = 0.8097  \n",
      "\n",
      "Fold: 20  Epoch: 288  Training loss = 2.6033  Validation loss = 0.8084  \n",
      "\n",
      "Fold: 20  Epoch: 289  Training loss = 2.6029  Validation loss = 0.8087  \n",
      "\n",
      "Fold: 20  Epoch: 290  Training loss = 2.6025  Validation loss = 0.8077  \n",
      "\n",
      "Fold: 20  Epoch: 291  Training loss = 2.6026  Validation loss = 0.8059  \n",
      "\n",
      "Fold: 20  Epoch: 292  Training loss = 2.6037  Validation loss = 0.8054  \n",
      "\n",
      "Fold: 20  Epoch: 293  Training loss = 2.6014  Validation loss = 0.8028  \n",
      "\n",
      "Fold: 20  Epoch: 294  Training loss = 2.6010  Validation loss = 0.8019  \n",
      "\n",
      "Fold: 20  Epoch: 295  Training loss = 2.5996  Validation loss = 0.8014  \n",
      "\n",
      "Fold: 20  Epoch: 296  Training loss = 2.5990  Validation loss = 0.8007  \n",
      "\n",
      "Fold: 20  Epoch: 297  Training loss = 2.5986  Validation loss = 0.7994  \n",
      "\n",
      "Fold: 20  Epoch: 298  Training loss = 2.5986  Validation loss = 0.7996  \n",
      "\n",
      "Fold: 20  Epoch: 299  Training loss = 2.5977  Validation loss = 0.7989  \n",
      "\n",
      "Fold: 20  Epoch: 300  Training loss = 2.5967  Validation loss = 0.7981  \n",
      "\n",
      "Fold: 20  Epoch: 301  Training loss = 2.5963  Validation loss = 0.7970  \n",
      "\n",
      "Fold: 20  Epoch: 302  Training loss = 2.5954  Validation loss = 0.7981  \n",
      "\n",
      "Fold: 20  Epoch: 303  Training loss = 2.5949  Validation loss = 0.7968  \n",
      "\n",
      "Fold: 20  Epoch: 304  Training loss = 2.5944  Validation loss = 0.7953  \n",
      "\n",
      "Fold: 20  Epoch: 305  Training loss = 2.5938  Validation loss = 0.7947  \n",
      "\n",
      "Fold: 20  Epoch: 306  Training loss = 2.5937  Validation loss = 0.7939  \n",
      "\n",
      "Fold: 20  Epoch: 307  Training loss = 2.5925  Validation loss = 0.7939  \n",
      "\n",
      "Fold: 20  Epoch: 308  Training loss = 2.5924  Validation loss = 0.7929  \n",
      "\n",
      "Fold: 20  Epoch: 309  Training loss = 2.5916  Validation loss = 0.7929  \n",
      "\n",
      "Fold: 20  Epoch: 310  Training loss = 2.5913  Validation loss = 0.7919  \n",
      "\n",
      "Fold: 20  Epoch: 311  Training loss = 2.5925  Validation loss = 0.7915  \n",
      "\n",
      "Fold: 20  Epoch: 312  Training loss = 2.5912  Validation loss = 0.7921  \n",
      "\n",
      "Fold: 20  Epoch: 313  Training loss = 2.5933  Validation loss = 0.7923  \n",
      "\n",
      "Fold: 20  Epoch: 314  Training loss = 2.5924  Validation loss = 0.7909  \n",
      "\n",
      "Fold: 20  Epoch: 315  Training loss = 2.5899  Validation loss = 0.7898  \n",
      "\n",
      "Fold: 20  Epoch: 316  Training loss = 2.5893  Validation loss = 0.7894  \n",
      "\n",
      "Fold: 20  Epoch: 317  Training loss = 2.5877  Validation loss = 0.7891  \n",
      "\n",
      "Fold: 20  Epoch: 318  Training loss = 2.5867  Validation loss = 0.7890  \n",
      "\n",
      "Fold: 20  Epoch: 319  Training loss = 2.5860  Validation loss = 0.7883  \n",
      "\n",
      "Fold: 20  Epoch: 320  Training loss = 2.5854  Validation loss = 0.7877  \n",
      "\n",
      "Fold: 20  Epoch: 321  Training loss = 2.5848  Validation loss = 0.7871  \n",
      "\n",
      "Fold: 20  Epoch: 322  Training loss = 2.5845  Validation loss = 0.7858  \n",
      "\n",
      "Fold: 20  Epoch: 323  Training loss = 2.5839  Validation loss = 0.7863  \n",
      "\n",
      "Fold: 20  Epoch: 324  Training loss = 2.5841  Validation loss = 0.7864  \n",
      "\n",
      "Fold: 20  Epoch: 325  Training loss = 2.5827  Validation loss = 0.7862  \n",
      "\n",
      "Fold: 20  Epoch: 326  Training loss = 2.5821  Validation loss = 0.7841  \n",
      "\n",
      "Fold: 20  Epoch: 327  Training loss = 2.5816  Validation loss = 0.7855  \n",
      "\n",
      "Fold: 20  Epoch: 328  Training loss = 2.5813  Validation loss = 0.7870  \n",
      "\n",
      "Fold: 20  Epoch: 329  Training loss = 2.5808  Validation loss = 0.7863  \n",
      "\n",
      "Fold: 20  Epoch: 330  Training loss = 2.5800  Validation loss = 0.7843  \n",
      "\n",
      "Fold: 20  Epoch: 331  Training loss = 2.5793  Validation loss = 0.7835  \n",
      "\n",
      "Fold: 20  Epoch: 332  Training loss = 2.5787  Validation loss = 0.7832  \n",
      "\n",
      "Fold: 20  Epoch: 333  Training loss = 2.5786  Validation loss = 0.7835  \n",
      "\n",
      "Fold: 20  Epoch: 334  Training loss = 2.5780  Validation loss = 0.7823  \n",
      "\n",
      "Fold: 20  Epoch: 335  Training loss = 2.5778  Validation loss = 0.7817  \n",
      "\n",
      "Fold: 20  Epoch: 336  Training loss = 2.5770  Validation loss = 0.7807  \n",
      "\n",
      "Fold: 20  Epoch: 337  Training loss = 2.5761  Validation loss = 0.7801  \n",
      "\n",
      "Fold: 20  Epoch: 338  Training loss = 2.5759  Validation loss = 0.7791  \n",
      "\n",
      "Fold: 20  Epoch: 339  Training loss = 2.5756  Validation loss = 0.7789  \n",
      "\n",
      "Fold: 20  Epoch: 340  Training loss = 2.5744  Validation loss = 0.7776  \n",
      "\n",
      "Fold: 20  Epoch: 341  Training loss = 2.5736  Validation loss = 0.7761  \n",
      "\n",
      "Fold: 20  Epoch: 342  Training loss = 2.5733  Validation loss = 0.7757  \n",
      "\n",
      "Fold: 20  Epoch: 343  Training loss = 2.5734  Validation loss = 0.7764  \n",
      "\n",
      "Fold: 20  Epoch: 344  Training loss = 2.5725  Validation loss = 0.7751  \n",
      "\n",
      "Fold: 20  Epoch: 345  Training loss = 2.5721  Validation loss = 0.7741  \n",
      "\n",
      "Fold: 20  Epoch: 346  Training loss = 2.5717  Validation loss = 0.7750  \n",
      "\n",
      "Fold: 20  Epoch: 347  Training loss = 2.5712  Validation loss = 0.7741  \n",
      "\n",
      "Fold: 20  Epoch: 348  Training loss = 2.5705  Validation loss = 0.7731  \n",
      "\n",
      "Fold: 20  Epoch: 349  Training loss = 2.5702  Validation loss = 0.7724  \n",
      "\n",
      "Fold: 20  Epoch: 350  Training loss = 2.5697  Validation loss = 0.7705  \n",
      "\n",
      "Fold: 20  Epoch: 351  Training loss = 2.5695  Validation loss = 0.7706  \n",
      "\n",
      "Fold: 20  Epoch: 352  Training loss = 2.5689  Validation loss = 0.7695  \n",
      "\n",
      "Fold: 20  Epoch: 353  Training loss = 2.5684  Validation loss = 0.7694  \n",
      "\n",
      "Fold: 20  Epoch: 354  Training loss = 2.5678  Validation loss = 0.7688  \n",
      "\n",
      "Fold: 20  Epoch: 355  Training loss = 2.5672  Validation loss = 0.7674  \n",
      "\n",
      "Fold: 20  Epoch: 356  Training loss = 2.5670  Validation loss = 0.7677  \n",
      "\n",
      "Fold: 20  Epoch: 357  Training loss = 2.5667  Validation loss = 0.7669  \n",
      "\n",
      "Fold: 20  Epoch: 358  Training loss = 2.5669  Validation loss = 0.7675  \n",
      "\n",
      "Fold: 20  Epoch: 359  Training loss = 2.5670  Validation loss = 0.7663  \n",
      "\n",
      "Fold: 20  Epoch: 360  Training loss = 2.5677  Validation loss = 0.7655  \n",
      "\n",
      "Fold: 20  Epoch: 361  Training loss = 2.5673  Validation loss = 0.7645  \n",
      "\n",
      "Fold: 20  Epoch: 362  Training loss = 2.5675  Validation loss = 0.7640  \n",
      "\n",
      "Fold: 20  Epoch: 363  Training loss = 2.5639  Validation loss = 0.7618  \n",
      "\n",
      "Fold: 20  Epoch: 364  Training loss = 2.5633  Validation loss = 0.7606  \n",
      "\n",
      "Fold: 20  Epoch: 365  Training loss = 2.5628  Validation loss = 0.7594  \n",
      "\n",
      "Fold: 20  Epoch: 366  Training loss = 2.5624  Validation loss = 0.7592  \n",
      "\n",
      "Fold: 20  Epoch: 367  Training loss = 2.5624  Validation loss = 0.7585  \n",
      "\n",
      "Fold: 20  Epoch: 368  Training loss = 2.5621  Validation loss = 0.7591  \n",
      "\n",
      "Fold: 20  Epoch: 369  Training loss = 2.5613  Validation loss = 0.7572  \n",
      "\n",
      "Fold: 20  Epoch: 370  Training loss = 2.5613  Validation loss = 0.7570  \n",
      "\n",
      "Fold: 20  Epoch: 371  Training loss = 2.5604  Validation loss = 0.7554  \n",
      "\n",
      "Fold: 20  Epoch: 372  Training loss = 2.5599  Validation loss = 0.7556  \n",
      "\n",
      "Fold: 20  Epoch: 373  Training loss = 2.5608  Validation loss = 0.7551  \n",
      "\n",
      "Fold: 20  Epoch: 374  Training loss = 2.5596  Validation loss = 0.7556  \n",
      "\n",
      "Fold: 20  Epoch: 375  Training loss = 2.5588  Validation loss = 0.7557  \n",
      "\n",
      "Fold: 20  Epoch: 376  Training loss = 2.5587  Validation loss = 0.7552  \n",
      "\n",
      "Fold: 20  Epoch: 377  Training loss = 2.5584  Validation loss = 0.7545  \n",
      "\n",
      "Fold: 20  Epoch: 378  Training loss = 2.5577  Validation loss = 0.7544  \n",
      "\n",
      "Fold: 20  Epoch: 379  Training loss = 2.5579  Validation loss = 0.7540  \n",
      "\n",
      "Fold: 20  Epoch: 380  Training loss = 2.5568  Validation loss = 0.7527  \n",
      "\n",
      "Fold: 20  Epoch: 381  Training loss = 2.5564  Validation loss = 0.7503  \n",
      "\n",
      "Fold: 20  Epoch: 382  Training loss = 2.5552  Validation loss = 0.7496  \n",
      "\n",
      "Fold: 20  Epoch: 383  Training loss = 2.5544  Validation loss = 0.7483  \n",
      "\n",
      "Fold: 20  Epoch: 384  Training loss = 2.5540  Validation loss = 0.7484  \n",
      "\n",
      "Fold: 20  Epoch: 385  Training loss = 2.5536  Validation loss = 0.7483  \n",
      "\n",
      "Fold: 20  Epoch: 386  Training loss = 2.5549  Validation loss = 0.7490  \n",
      "\n",
      "Fold: 20  Epoch: 387  Training loss = 2.5547  Validation loss = 0.7481  \n",
      "\n",
      "Fold: 20  Epoch: 388  Training loss = 2.5525  Validation loss = 0.7475  \n",
      "\n",
      "Fold: 20  Epoch: 389  Training loss = 2.5516  Validation loss = 0.7473  \n",
      "\n",
      "Fold: 20  Epoch: 390  Training loss = 2.5521  Validation loss = 0.7473  \n",
      "\n",
      "Fold: 20  Epoch: 391  Training loss = 2.5509  Validation loss = 0.7469  \n",
      "\n",
      "Fold: 20  Epoch: 392  Training loss = 2.5517  Validation loss = 0.7462  \n",
      "\n",
      "Fold: 20  Epoch: 393  Training loss = 2.5510  Validation loss = 0.7458  \n",
      "\n",
      "Fold: 20  Epoch: 394  Training loss = 2.5507  Validation loss = 0.7464  \n",
      "\n",
      "Fold: 20  Epoch: 395  Training loss = 2.5528  Validation loss = 0.7458  \n",
      "\n",
      "Fold: 20  Epoch: 396  Training loss = 2.5525  Validation loss = 0.7452  \n",
      "\n",
      "Fold: 20  Epoch: 397  Training loss = 2.5491  Validation loss = 0.7451  \n",
      "\n",
      "Fold: 20  Epoch: 398  Training loss = 2.5480  Validation loss = 0.7448  \n",
      "\n",
      "Fold: 20  Epoch: 399  Training loss = 2.5484  Validation loss = 0.7447  \n",
      "\n",
      "Fold: 20  Epoch: 400  Training loss = 2.5474  Validation loss = 0.7441  \n",
      "\n",
      "Fold: 20  Epoch: 401  Training loss = 2.5469  Validation loss = 0.7438  \n",
      "\n",
      "Fold: 20  Epoch: 402  Training loss = 2.5468  Validation loss = 0.7434  \n",
      "\n",
      "Fold: 20  Epoch: 403  Training loss = 2.5459  Validation loss = 0.7425  \n",
      "\n",
      "Fold: 20  Epoch: 404  Training loss = 2.5456  Validation loss = 0.7422  \n",
      "\n",
      "Fold: 20  Epoch: 405  Training loss = 2.5453  Validation loss = 0.7427  \n",
      "\n",
      "Fold: 20  Epoch: 406  Training loss = 2.5445  Validation loss = 0.7421  \n",
      "\n",
      "Fold: 20  Epoch: 407  Training loss = 2.5439  Validation loss = 0.7423  \n",
      "\n",
      "Fold: 20  Epoch: 408  Training loss = 2.5441  Validation loss = 0.7418  \n",
      "\n",
      "Fold: 20  Epoch: 409  Training loss = 2.5428  Validation loss = 0.7403  \n",
      "\n",
      "Fold: 20  Epoch: 410  Training loss = 2.5429  Validation loss = 0.7402  \n",
      "\n",
      "Fold: 20  Epoch: 411  Training loss = 2.5432  Validation loss = 0.7398  \n",
      "\n",
      "Fold: 20  Epoch: 412  Training loss = 2.5416  Validation loss = 0.7389  \n",
      "\n",
      "Fold: 20  Epoch: 413  Training loss = 2.5410  Validation loss = 0.7387  \n",
      "\n",
      "Fold: 20  Epoch: 414  Training loss = 2.5406  Validation loss = 0.7384  \n",
      "\n",
      "Fold: 20  Epoch: 415  Training loss = 2.5402  Validation loss = 0.7368  \n",
      "\n",
      "Fold: 20  Epoch: 416  Training loss = 2.5393  Validation loss = 0.7359  \n",
      "\n",
      "Fold: 20  Epoch: 417  Training loss = 2.5391  Validation loss = 0.7348  \n",
      "\n",
      "Fold: 20  Epoch: 418  Training loss = 2.5386  Validation loss = 0.7351  \n",
      "\n",
      "Fold: 20  Epoch: 419  Training loss = 2.5391  Validation loss = 0.7351  \n",
      "\n",
      "Fold: 20  Epoch: 420  Training loss = 2.5383  Validation loss = 0.7344  \n",
      "\n",
      "Fold: 20  Epoch: 421  Training loss = 2.5396  Validation loss = 0.7349  \n",
      "\n",
      "Fold: 20  Epoch: 422  Training loss = 2.5394  Validation loss = 0.7350  \n",
      "\n",
      "Fold: 20  Epoch: 423  Training loss = 2.5389  Validation loss = 0.7350  \n",
      "\n",
      "Fold: 20  Epoch: 424  Training loss = 2.5369  Validation loss = 0.7337  \n",
      "\n",
      "Fold: 20  Epoch: 425  Training loss = 2.5390  Validation loss = 0.7333  \n",
      "\n",
      "Fold: 20  Epoch: 426  Training loss = 2.5373  Validation loss = 0.7325  \n",
      "\n",
      "Fold: 20  Epoch: 427  Training loss = 2.5377  Validation loss = 0.7331  \n",
      "\n",
      "Fold: 20  Epoch: 428  Training loss = 2.5362  Validation loss = 0.7317  \n",
      "\n",
      "Fold: 20  Epoch: 429  Training loss = 2.5346  Validation loss = 0.7309  \n",
      "\n",
      "Fold: 20  Epoch: 430  Training loss = 2.5353  Validation loss = 0.7301  \n",
      "\n",
      "Fold: 20  Epoch: 431  Training loss = 2.5356  Validation loss = 0.7293  \n",
      "\n",
      "Fold: 20  Epoch: 432  Training loss = 2.5334  Validation loss = 0.7291  \n",
      "\n",
      "Fold: 20  Epoch: 433  Training loss = 2.5331  Validation loss = 0.7297  \n",
      "\n",
      "Fold: 20  Epoch: 434  Training loss = 2.5323  Validation loss = 0.7292  \n",
      "\n",
      "Fold: 20  Epoch: 435  Training loss = 2.5323  Validation loss = 0.7300  \n",
      "\n",
      "Fold: 20  Epoch: 436  Training loss = 2.5316  Validation loss = 0.7280  \n",
      "\n",
      "Fold: 20  Epoch: 437  Training loss = 2.5319  Validation loss = 0.7284  \n",
      "\n",
      "Fold: 20  Epoch: 438  Training loss = 2.5308  Validation loss = 0.7278  \n",
      "\n",
      "Fold: 20  Epoch: 439  Training loss = 2.5304  Validation loss = 0.7281  \n",
      "\n",
      "Fold: 20  Epoch: 440  Training loss = 2.5299  Validation loss = 0.7270  \n",
      "\n",
      "Fold: 20  Epoch: 441  Training loss = 2.5301  Validation loss = 0.7263  \n",
      "\n",
      "Fold: 20  Epoch: 442  Training loss = 2.5303  Validation loss = 0.7262  \n",
      "\n",
      "Fold: 20  Epoch: 443  Training loss = 2.5291  Validation loss = 0.7264  \n",
      "\n",
      "Fold: 20  Epoch: 444  Training loss = 2.5304  Validation loss = 0.7259  \n",
      "\n",
      "Fold: 20  Epoch: 445  Training loss = 2.5288  Validation loss = 0.7266  \n",
      "\n",
      "Fold: 20  Epoch: 446  Training loss = 2.5286  Validation loss = 0.7260  \n",
      "\n",
      "Fold: 20  Epoch: 447  Training loss = 2.5283  Validation loss = 0.7254  \n",
      "\n",
      "Fold: 20  Epoch: 448  Training loss = 2.5282  Validation loss = 0.7240  \n",
      "\n",
      "Fold: 20  Epoch: 449  Training loss = 2.5294  Validation loss = 0.7234  \n",
      "\n",
      "Fold: 20  Epoch: 450  Training loss = 2.5265  Validation loss = 0.7233  \n",
      "\n",
      "Fold: 20  Epoch: 451  Training loss = 2.5260  Validation loss = 0.7233  \n",
      "\n",
      "Fold: 20  Epoch: 452  Training loss = 2.5254  Validation loss = 0.7230  \n",
      "\n",
      "Fold: 20  Epoch: 453  Training loss = 2.5255  Validation loss = 0.7232  \n",
      "\n",
      "Fold: 20  Epoch: 454  Training loss = 2.5258  Validation loss = 0.7230  \n",
      "\n",
      "Fold: 20  Epoch: 455  Training loss = 2.5277  Validation loss = 0.7239  \n",
      "\n",
      "Fold: 20  Epoch: 456  Training loss = 2.5253  Validation loss = 0.7229  \n",
      "\n",
      "Fold: 20  Epoch: 457  Training loss = 2.5266  Validation loss = 0.7237  \n",
      "\n",
      "Fold: 20  Epoch: 458  Training loss = 2.5244  Validation loss = 0.7227  \n",
      "\n",
      "Fold: 20  Epoch: 459  Training loss = 2.5241  Validation loss = 0.7230  \n",
      "\n",
      "Fold: 20  Epoch: 460  Training loss = 2.5259  Validation loss = 0.7234  \n",
      "\n",
      "Fold: 20  Epoch: 461  Training loss = 2.5227  Validation loss = 0.7219  \n",
      "\n",
      "Fold: 20  Epoch: 462  Training loss = 2.5216  Validation loss = 0.7213  \n",
      "\n",
      "Fold: 20  Epoch: 463  Training loss = 2.5216  Validation loss = 0.7220  \n",
      "\n",
      "Fold: 20  Epoch: 464  Training loss = 2.5214  Validation loss = 0.7208  \n",
      "\n",
      "Fold: 20  Epoch: 465  Training loss = 2.5240  Validation loss = 0.7205  \n",
      "\n",
      "Fold: 20  Epoch: 466  Training loss = 2.5235  Validation loss = 0.7206  \n",
      "\n",
      "Fold: 20  Epoch: 467  Training loss = 2.5241  Validation loss = 0.7205  \n",
      "\n",
      "Fold: 20  Epoch: 468  Training loss = 2.5222  Validation loss = 0.7193  \n",
      "\n",
      "Fold: 20  Epoch: 469  Training loss = 2.5224  Validation loss = 0.7195  \n",
      "\n",
      "Fold: 20  Epoch: 470  Training loss = 2.5209  Validation loss = 0.7200  \n",
      "\n",
      "Fold: 20  Epoch: 471  Training loss = 2.5200  Validation loss = 0.7200  \n",
      "\n",
      "Fold: 20  Epoch: 472  Training loss = 2.5195  Validation loss = 0.7200  \n",
      "\n",
      "Fold: 20  Epoch: 473  Training loss = 2.5196  Validation loss = 0.7204  \n",
      "\n",
      "Fold: 20  Epoch: 474  Training loss = 2.5198  Validation loss = 0.7200  \n",
      "\n",
      "Fold: 20  Epoch: 475  Training loss = 2.5195  Validation loss = 0.7200  \n",
      "\n",
      "Fold: 20  Epoch: 476  Training loss = 2.5206  Validation loss = 0.7199  \n",
      "\n",
      "Fold: 20  Epoch: 477  Training loss = 2.5197  Validation loss = 0.7197  \n",
      "\n",
      "Fold: 20  Epoch: 478  Training loss = 2.5178  Validation loss = 0.7184  \n",
      "\n",
      "Fold: 20  Epoch: 479  Training loss = 2.5173  Validation loss = 0.7172  \n",
      "\n",
      "Fold: 20  Epoch: 480  Training loss = 2.5161  Validation loss = 0.7174  \n",
      "\n",
      "Fold: 20  Epoch: 481  Training loss = 2.5159  Validation loss = 0.7172  \n",
      "\n",
      "Fold: 20  Epoch: 482  Training loss = 2.5155  Validation loss = 0.7160  \n",
      "\n",
      "Fold: 20  Epoch: 483  Training loss = 2.5158  Validation loss = 0.7155  \n",
      "\n",
      "Fold: 20  Epoch: 484  Training loss = 2.5155  Validation loss = 0.7161  \n",
      "\n",
      "Fold: 20  Epoch: 485  Training loss = 2.5142  Validation loss = 0.7143  \n",
      "\n",
      "Fold: 20  Epoch: 486  Training loss = 2.5131  Validation loss = 0.7143  \n",
      "\n",
      "Fold: 20  Epoch: 487  Training loss = 2.5120  Validation loss = 0.7122  \n",
      "\n",
      "Fold: 20  Epoch: 488  Training loss = 2.5118  Validation loss = 0.7125  \n",
      "\n",
      "Fold: 20  Epoch: 489  Training loss = 2.5112  Validation loss = 0.7115  \n",
      "\n",
      "Fold: 20  Epoch: 490  Training loss = 2.5109  Validation loss = 0.7109  \n",
      "\n",
      "Fold: 20  Epoch: 491  Training loss = 2.5105  Validation loss = 0.7103  \n",
      "\n",
      "Fold: 20  Epoch: 492  Training loss = 2.5108  Validation loss = 0.7101  \n",
      "\n",
      "Fold: 20  Epoch: 493  Training loss = 2.5113  Validation loss = 0.7098  \n",
      "\n",
      "Fold: 20  Epoch: 494  Training loss = 2.5104  Validation loss = 0.7103  \n",
      "\n",
      "Fold: 20  Epoch: 495  Training loss = 2.5126  Validation loss = 0.7089  \n",
      "\n",
      "Fold: 20  Epoch: 496  Training loss = 2.5101  Validation loss = 0.7095  \n",
      "\n",
      "Fold: 20  Epoch: 497  Training loss = 2.5095  Validation loss = 0.7087  \n",
      "\n",
      "Fold: 20  Epoch: 498  Training loss = 2.5092  Validation loss = 0.7088  \n",
      "\n",
      "Fold: 20  Epoch: 499  Training loss = 2.5092  Validation loss = 0.7087  \n",
      "\n",
      "Fold: 20  Epoch: 500  Training loss = 2.5089  Validation loss = 0.7078  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 500  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.4823  Validation loss = 3.5980  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.4822  Validation loss = 3.5955  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.4811  Validation loss = 3.6014  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.4806  Validation loss = 3.6032  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.4794  Validation loss = 3.6244  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.4787  Validation loss = 3.6249  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.4782  Validation loss = 3.6093  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.4778  Validation loss = 3.6075  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.4771  Validation loss = 3.5786  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.4772  Validation loss = 3.5454  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.4758  Validation loss = 3.5529  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.4754  Validation loss = 3.6315  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 10  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.5502  Validation loss = 2.6877  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.5471  Validation loss = 2.6796  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 2.5439  Validation loss = 2.6265  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.5406  Validation loss = 2.4943  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.5426  Validation loss = 2.6256  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 2.5390  Validation loss = 2.5378  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 2.5380  Validation loss = 2.4807  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.5369  Validation loss = 2.4774  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 2.5365  Validation loss = 2.5568  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 2.5355  Validation loss = 2.4449  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 2.5347  Validation loss = 2.5258  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.5349  Validation loss = 2.6014  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.5326  Validation loss = 2.4603  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 2.5323  Validation loss = 2.4586  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 2.5327  Validation loss = 2.3295  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 2.5337  Validation loss = 2.2077  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 2.5303  Validation loss = 2.3654  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 2.5297  Validation loss = 2.3362  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 2.5292  Validation loss = 2.5131  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 2.5278  Validation loss = 2.4195  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 2.5281  Validation loss = 2.4867  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 2.5269  Validation loss = 2.3238  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 2.5277  Validation loss = 2.2440  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 2.5269  Validation loss = 2.2208  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 2.5245  Validation loss = 2.3914  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 2.5244  Validation loss = 2.5055  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 2.5239  Validation loss = 2.2967  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 2.5225  Validation loss = 2.4368  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 2.5227  Validation loss = 2.5679  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 16  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.5304  Validation loss = 1.9961  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.5251  Validation loss = 1.9618  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.5209  Validation loss = 1.8520  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.5187  Validation loss = 1.7687  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.5159  Validation loss = 1.8469  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.5131  Validation loss = 1.8531  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.5296  Validation loss = 1.6758  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.5276  Validation loss = 2.1839  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.5105  Validation loss = 1.9191  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.5126  Validation loss = 2.0429  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.5041  Validation loss = 1.7662  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.5046  Validation loss = 1.8931  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 2.5084  Validation loss = 2.0235  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 2.5068  Validation loss = 2.0098  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 2.5028  Validation loss = 1.9312  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 2.5003  Validation loss = 1.8686  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 2.5127  Validation loss = 1.6794  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 2.5007  Validation loss = 1.8763  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 2.5056  Validation loss = 2.0403  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 2.5022  Validation loss = 1.9857  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 2.4967  Validation loss = 1.8029  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 2.4977  Validation loss = 1.9009  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 2.4967  Validation loss = 1.9083  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 2.4930  Validation loss = 1.8189  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 2.4993  Validation loss = 1.9970  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 2.4914  Validation loss = 1.7523  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 2.4921  Validation loss = 1.8651  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 2.4957  Validation loss = 1.9989  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 2.4878  Validation loss = 1.7524  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 2.4868  Validation loss = 1.8036  \n",
      "\n",
      "Fold: 23  Epoch: 31  Training loss = 2.4867  Validation loss = 1.6978  \n",
      "\n",
      "Fold: 23  Epoch: 32  Training loss = 2.4852  Validation loss = 1.8204  \n",
      "\n",
      "Fold: 23  Epoch: 33  Training loss = 2.4885  Validation loss = 1.9578  \n",
      "\n",
      "Fold: 23  Epoch: 34  Training loss = 2.4824  Validation loss = 1.7405  \n",
      "\n",
      "Fold: 23  Epoch: 35  Training loss = 2.4811  Validation loss = 1.7695  \n",
      "\n",
      "Fold: 23  Epoch: 36  Training loss = 2.5105  Validation loss = 2.2232  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 7  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.5105  Validation loss = 1.2884  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.4994  Validation loss = 1.2687  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.4858  Validation loss = 1.2278  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.4935  Validation loss = 1.1610  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.4924  Validation loss = 1.1426  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 2.4901  Validation loss = 1.1445  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.4886  Validation loss = 1.1789  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.4849  Validation loss = 1.2449  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.4976  Validation loss = 1.1441  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.4888  Validation loss = 1.1903  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.4843  Validation loss = 1.2805  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 5  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.4232  Validation loss = 2.2788  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.4211  Validation loss = 2.3252  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.4097  Validation loss = 2.3322  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.4140  Validation loss = 2.2969  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.4158  Validation loss = 2.2431  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.4148  Validation loss = 2.2385  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.4113  Validation loss = 2.2427  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.4074  Validation loss = 2.2462  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.3946  Validation loss = 2.2876  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.4003  Validation loss = 2.2485  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.3960  Validation loss = 2.2448  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.4070  Validation loss = 2.2439  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.3881  Validation loss = 2.2715  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.3871  Validation loss = 2.2821  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 2.3857  Validation loss = 2.2559  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.3906  Validation loss = 2.3217  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 6  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.3707  Validation loss = 2.6191  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.3706  Validation loss = 2.6731  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.3616  Validation loss = 2.9538  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.3639  Validation loss = 2.8950  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.3598  Validation loss = 2.7770  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.3608  Validation loss = 2.8248  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.3584  Validation loss = 2.7213  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.3579  Validation loss = 2.8525  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.3587  Validation loss = 2.9083  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.3575  Validation loss = 2.8006  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 2.3547  Validation loss = 2.7562  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 2.3548  Validation loss = 2.8092  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.3576  Validation loss = 2.7063  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 2.3548  Validation loss = 2.8616  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 2.3543  Validation loss = 2.8296  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 2.3558  Validation loss = 2.9567  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 1  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.3198  Validation loss = 0.7173  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.3248  Validation loss = 0.7107  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.3033  Validation loss = 0.6799  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.3053  Validation loss = 0.6993  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.3153  Validation loss = 0.7305  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.3073  Validation loss = 0.7178  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.3093  Validation loss = 0.7273  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.3042  Validation loss = 0.7096  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.2983  Validation loss = 0.6995  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 2.2955  Validation loss = 0.6891  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.2977  Validation loss = 0.6863  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.3062  Validation loss = 0.7186  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.2965  Validation loss = 0.6786  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.2956  Validation loss = 0.6824  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.2933  Validation loss = 0.6939  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.2940  Validation loss = 0.7074  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.2897  Validation loss = 0.6970  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.3151  Validation loss = 0.6657  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.2927  Validation loss = 0.6809  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.2928  Validation loss = 0.7125  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 2.2855  Validation loss = 0.7038  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 2.2848  Validation loss = 0.7092  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 2.2843  Validation loss = 0.7103  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 2.3050  Validation loss = 0.7421  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 18  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.2782  Validation loss = 0.9399  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.2743  Validation loss = 0.9392  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.2727  Validation loss = 0.9264  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.2739  Validation loss = 0.9311  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.2670  Validation loss = 0.9039  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.2647  Validation loss = 0.9089  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.2617  Validation loss = 0.9165  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.2650  Validation loss = 0.9048  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.2618  Validation loss = 0.9119  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.2842  Validation loss = 0.9390  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.2603  Validation loss = 0.9165  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.2609  Validation loss = 0.9075  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.2618  Validation loss = 0.9016  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.2661  Validation loss = 0.9290  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.2624  Validation loss = 0.9239  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.2543  Validation loss = 0.9046  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 2.2577  Validation loss = 0.9196  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 2.2530  Validation loss = 0.9115  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 2.2517  Validation loss = 0.8987  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 2.2503  Validation loss = 0.8932  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 2.2509  Validation loss = 0.8870  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 2.2512  Validation loss = 0.9005  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 2.2494  Validation loss = 0.8976  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 2.2628  Validation loss = 0.9283  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 21  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.2180  Validation loss = 0.7435  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.2313  Validation loss = 0.7407  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.2168  Validation loss = 0.7428  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.2146  Validation loss = 0.7451  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.2139  Validation loss = 0.7441  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.2313  Validation loss = 0.7397  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.2140  Validation loss = 0.7405  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.2094  Validation loss = 0.7411  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.2073  Validation loss = 0.7408  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 2.2129  Validation loss = 0.7385  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.2057  Validation loss = 0.7412  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.2415  Validation loss = 0.7438  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.2096  Validation loss = 0.7416  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 2.2044  Validation loss = 0.7403  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 2.2161  Validation loss = 0.7338  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.2041  Validation loss = 0.7432  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 2.2015  Validation loss = 0.7421  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 2.2004  Validation loss = 0.7364  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 2.1975  Validation loss = 0.7378  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 2.2005  Validation loss = 0.7344  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 2.2576  Validation loss = 0.7492  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 15  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 2.1723  Validation loss = 1.3145  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.1710  Validation loss = 1.3207  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.1705  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.1701  Validation loss = 1.2966  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.1693  Validation loss = 1.3436  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 2.1661  Validation loss = 1.3018  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.1681  Validation loss = 1.2833  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.1658  Validation loss = 1.2882  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 2.1707  Validation loss = 1.3446  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.1620  Validation loss = 1.3193  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.1653  Validation loss = 1.3284  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.1620  Validation loss = 1.2954  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 2.1602  Validation loss = 1.3019  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 2.1619  Validation loss = 1.3282  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 2.1582  Validation loss = 1.3216  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 2.1626  Validation loss = 1.3427  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 2.1623  Validation loss = 1.3402  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 2.1574  Validation loss = 1.3240  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 2.1542  Validation loss = 1.2827  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 2.1535  Validation loss = 1.3080  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 2.1531  Validation loss = 1.3131  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 2.1523  Validation loss = 1.2777  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 2.1491  Validation loss = 1.3034  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 2.1474  Validation loss = 1.2909  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 2.1636  Validation loss = 1.3271  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 2.1443  Validation loss = 1.2710  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 2.1494  Validation loss = 1.2482  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 2.1548  Validation loss = 1.2333  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 2.1451  Validation loss = 1.2566  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 2.1425  Validation loss = 1.2721  \n",
      "\n",
      "Fold: 30  Epoch: 31  Training loss = 2.1415  Validation loss = 1.2838  \n",
      "\n",
      "Fold: 30  Epoch: 32  Training loss = 2.1441  Validation loss = 1.2608  \n",
      "\n",
      "Fold: 30  Epoch: 33  Training loss = 2.1464  Validation loss = 1.2446  \n",
      "\n",
      "Fold: 30  Epoch: 34  Training loss = 2.1424  Validation loss = 1.3008  \n",
      "\n",
      "Fold: 30  Epoch: 35  Training loss = 2.1375  Validation loss = 1.2682  \n",
      "\n",
      "Fold: 30  Epoch: 36  Training loss = 2.1691  Validation loss = 1.3389  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 28  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.0476  Validation loss = 0.7415  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.0565  Validation loss = 0.8310  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.0448  Validation loss = 0.7799  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.0435  Validation loss = 0.7397  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.0384  Validation loss = 0.7020  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.0380  Validation loss = 0.7250  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.0369  Validation loss = 0.7456  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.0574  Validation loss = 0.8318  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.0347  Validation loss = 0.7354  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.0415  Validation loss = 0.7815  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.0371  Validation loss = 0.7625  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.0334  Validation loss = 0.7151  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.0322  Validation loss = 0.7247  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.0318  Validation loss = 0.7150  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.0325  Validation loss = 0.7446  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.0408  Validation loss = 0.7024  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 2.0414  Validation loss = 0.7767  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 2.0308  Validation loss = 0.7481  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 2.0427  Validation loss = 0.8023  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 5  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.6779  Validation loss = 2.0349  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.6759  Validation loss = 2.0123  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.6828  Validation loss = 1.7524  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.6840  Validation loss = 1.7380  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.6793  Validation loss = 1.7734  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.6715  Validation loss = 1.9813  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.6758  Validation loss = 2.1666  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.6738  Validation loss = 1.8416  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.6765  Validation loss = 1.7840  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.6880  Validation loss = 1.6889  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.6809  Validation loss = 1.7353  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.6787  Validation loss = 1.7483  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.6708  Validation loss = 1.8607  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.6690  Validation loss = 1.9758  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.6682  Validation loss = 1.9623  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.6687  Validation loss = 2.0412  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.6678  Validation loss = 1.8933  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.6722  Validation loss = 1.7881  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.6676  Validation loss = 1.9596  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.6667  Validation loss = 1.9406  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 1.6668  Validation loss = 1.9974  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 1.6678  Validation loss = 2.0175  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 1.6702  Validation loss = 2.1282  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 10  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 226\n",
      "Average validation error: 2.74113\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.5662  Test loss = 2.5701  \n",
      "\n",
      "Epoch: 2  Training loss = 1.5627  Test loss = 2.5618  \n",
      "\n",
      "Epoch: 3  Training loss = 1.5597  Test loss = 2.5540  \n",
      "\n",
      "Epoch: 4  Training loss = 1.5571  Test loss = 2.5467  \n",
      "\n",
      "Epoch: 5  Training loss = 1.5548  Test loss = 2.5399  \n",
      "\n",
      "Epoch: 6  Training loss = 1.5529  Test loss = 2.5336  \n",
      "\n",
      "Epoch: 7  Training loss = 1.5512  Test loss = 2.5277  \n",
      "\n",
      "Epoch: 8  Training loss = 1.5498  Test loss = 2.5222  \n",
      "\n",
      "Epoch: 9  Training loss = 1.5486  Test loss = 2.5172  \n",
      "\n",
      "Epoch: 10  Training loss = 1.5475  Test loss = 2.5125  \n",
      "\n",
      "Epoch: 11  Training loss = 1.5466  Test loss = 2.5081  \n",
      "\n",
      "Epoch: 12  Training loss = 1.5458  Test loss = 2.5041  \n",
      "\n",
      "Epoch: 13  Training loss = 1.5450  Test loss = 2.5003  \n",
      "\n",
      "Epoch: 14  Training loss = 1.5444  Test loss = 2.4969  \n",
      "\n",
      "Epoch: 15  Training loss = 1.5439  Test loss = 2.4937  \n",
      "\n",
      "Epoch: 16  Training loss = 1.5434  Test loss = 2.4907  \n",
      "\n",
      "Epoch: 17  Training loss = 1.5429  Test loss = 2.4880  \n",
      "\n",
      "Epoch: 18  Training loss = 1.5426  Test loss = 2.4854  \n",
      "\n",
      "Epoch: 19  Training loss = 1.5422  Test loss = 2.4831  \n",
      "\n",
      "Epoch: 20  Training loss = 1.5419  Test loss = 2.4809  \n",
      "\n",
      "Epoch: 21  Training loss = 1.5416  Test loss = 2.4789  \n",
      "\n",
      "Epoch: 22  Training loss = 1.5413  Test loss = 2.4771  \n",
      "\n",
      "Epoch: 23  Training loss = 1.5410  Test loss = 2.4753  \n",
      "\n",
      "Epoch: 24  Training loss = 1.5408  Test loss = 2.4738  \n",
      "\n",
      "Epoch: 25  Training loss = 1.5405  Test loss = 2.4723  \n",
      "\n",
      "Epoch: 26  Training loss = 1.5403  Test loss = 2.4709  \n",
      "\n",
      "Epoch: 27  Training loss = 1.5401  Test loss = 2.4697  \n",
      "\n",
      "Epoch: 28  Training loss = 1.5399  Test loss = 2.4685  \n",
      "\n",
      "Epoch: 29  Training loss = 1.5397  Test loss = 2.4674  \n",
      "\n",
      "Epoch: 30  Training loss = 1.5395  Test loss = 2.4664  \n",
      "\n",
      "Epoch: 31  Training loss = 1.5393  Test loss = 2.4655  \n",
      "\n",
      "Epoch: 32  Training loss = 1.5392  Test loss = 2.4647  \n",
      "\n",
      "Epoch: 33  Training loss = 1.5390  Test loss = 2.4639  \n",
      "\n",
      "Epoch: 34  Training loss = 1.5388  Test loss = 2.4631  \n",
      "\n",
      "Epoch: 35  Training loss = 1.5386  Test loss = 2.4624  \n",
      "\n",
      "Epoch: 36  Training loss = 1.5385  Test loss = 2.4618  \n",
      "\n",
      "Epoch: 37  Training loss = 1.5383  Test loss = 2.4612  \n",
      "\n",
      "Epoch: 38  Training loss = 1.5381  Test loss = 2.4607  \n",
      "\n",
      "Epoch: 39  Training loss = 1.5380  Test loss = 2.4602  \n",
      "\n",
      "Epoch: 40  Training loss = 1.5378  Test loss = 2.4597  \n",
      "\n",
      "Epoch: 41  Training loss = 1.5377  Test loss = 2.4593  \n",
      "\n",
      "Epoch: 42  Training loss = 1.5375  Test loss = 2.4589  \n",
      "\n",
      "Epoch: 43  Training loss = 1.5374  Test loss = 2.4585  \n",
      "\n",
      "Epoch: 44  Training loss = 1.5372  Test loss = 2.4581  \n",
      "\n",
      "Epoch: 45  Training loss = 1.5371  Test loss = 2.4578  \n",
      "\n",
      "Epoch: 46  Training loss = 1.5369  Test loss = 2.4575  \n",
      "\n",
      "Epoch: 47  Training loss = 1.5368  Test loss = 2.4572  \n",
      "\n",
      "Epoch: 48  Training loss = 1.5366  Test loss = 2.4569  \n",
      "\n",
      "Epoch: 49  Training loss = 1.5365  Test loss = 2.4567  \n",
      "\n",
      "Epoch: 50  Training loss = 1.5363  Test loss = 2.4564  \n",
      "\n",
      "Epoch: 51  Training loss = 1.5362  Test loss = 2.4562  \n",
      "\n",
      "Epoch: 52  Training loss = 1.5360  Test loss = 2.4560  \n",
      "\n",
      "Epoch: 53  Training loss = 1.5359  Test loss = 2.4558  \n",
      "\n",
      "Epoch: 54  Training loss = 1.5358  Test loss = 2.4556  \n",
      "\n",
      "Epoch: 55  Training loss = 1.5356  Test loss = 2.4554  \n",
      "\n",
      "Epoch: 56  Training loss = 1.5355  Test loss = 2.4552  \n",
      "\n",
      "Epoch: 57  Training loss = 1.5353  Test loss = 2.4551  \n",
      "\n",
      "Epoch: 58  Training loss = 1.5352  Test loss = 2.4549  \n",
      "\n",
      "Epoch: 59  Training loss = 1.5351  Test loss = 2.4548  \n",
      "\n",
      "Epoch: 60  Training loss = 1.5349  Test loss = 2.4547  \n",
      "\n",
      "Epoch: 61  Training loss = 1.5348  Test loss = 2.4545  \n",
      "\n",
      "Epoch: 62  Training loss = 1.5347  Test loss = 2.4544  \n",
      "\n",
      "Epoch: 63  Training loss = 1.5345  Test loss = 2.4543  \n",
      "\n",
      "Epoch: 64  Training loss = 1.5344  Test loss = 2.4542  \n",
      "\n",
      "Epoch: 65  Training loss = 1.5343  Test loss = 2.4541  \n",
      "\n",
      "Epoch: 66  Training loss = 1.5341  Test loss = 2.4540  \n",
      "\n",
      "Epoch: 67  Training loss = 1.5340  Test loss = 2.4539  \n",
      "\n",
      "Epoch: 68  Training loss = 1.5339  Test loss = 2.4538  \n",
      "\n",
      "Epoch: 69  Training loss = 1.5337  Test loss = 2.4537  \n",
      "\n",
      "Epoch: 70  Training loss = 1.5336  Test loss = 2.4536  \n",
      "\n",
      "Epoch: 71  Training loss = 1.5335  Test loss = 2.4535  \n",
      "\n",
      "Epoch: 72  Training loss = 1.5333  Test loss = 2.4534  \n",
      "\n",
      "Epoch: 73  Training loss = 1.5332  Test loss = 2.4533  \n",
      "\n",
      "Epoch: 74  Training loss = 1.5331  Test loss = 2.4532  \n",
      "\n",
      "Epoch: 75  Training loss = 1.5329  Test loss = 2.4532  \n",
      "\n",
      "Epoch: 76  Training loss = 1.5328  Test loss = 2.4531  \n",
      "\n",
      "Epoch: 77  Training loss = 1.5327  Test loss = 2.4530  \n",
      "\n",
      "Epoch: 78  Training loss = 1.5326  Test loss = 2.4529  \n",
      "\n",
      "Epoch: 79  Training loss = 1.5324  Test loss = 2.4529  \n",
      "\n",
      "Epoch: 80  Training loss = 1.5323  Test loss = 2.4528  \n",
      "\n",
      "Epoch: 81  Training loss = 1.5322  Test loss = 2.4527  \n",
      "\n",
      "Epoch: 82  Training loss = 1.5321  Test loss = 2.4526  \n",
      "\n",
      "Epoch: 83  Training loss = 1.5319  Test loss = 2.4526  \n",
      "\n",
      "Epoch: 84  Training loss = 1.5318  Test loss = 2.4525  \n",
      "\n",
      "Epoch: 85  Training loss = 1.5317  Test loss = 2.4524  \n",
      "\n",
      "Epoch: 86  Training loss = 1.5316  Test loss = 2.4524  \n",
      "\n",
      "Epoch: 87  Training loss = 1.5314  Test loss = 2.4523  \n",
      "\n",
      "Epoch: 88  Training loss = 1.5313  Test loss = 2.4522  \n",
      "\n",
      "Epoch: 89  Training loss = 1.5312  Test loss = 2.4522  \n",
      "\n",
      "Epoch: 90  Training loss = 1.5311  Test loss = 2.4521  \n",
      "\n",
      "Epoch: 91  Training loss = 1.5310  Test loss = 2.4521  \n",
      "\n",
      "Epoch: 92  Training loss = 1.5308  Test loss = 2.4520  \n",
      "\n",
      "Epoch: 93  Training loss = 1.5307  Test loss = 2.4519  \n",
      "\n",
      "Epoch: 94  Training loss = 1.5306  Test loss = 2.4519  \n",
      "\n",
      "Epoch: 95  Training loss = 1.5305  Test loss = 2.4518  \n",
      "\n",
      "Epoch: 96  Training loss = 1.5304  Test loss = 2.4517  \n",
      "\n",
      "Epoch: 97  Training loss = 1.5303  Test loss = 2.4517  \n",
      "\n",
      "Epoch: 98  Training loss = 1.5301  Test loss = 2.4516  \n",
      "\n",
      "Epoch: 99  Training loss = 1.5300  Test loss = 2.4516  \n",
      "\n",
      "Epoch: 100  Training loss = 1.5299  Test loss = 2.4515  \n",
      "\n",
      "Epoch: 101  Training loss = 1.5298  Test loss = 2.4514  \n",
      "\n",
      "Epoch: 102  Training loss = 1.5297  Test loss = 2.4514  \n",
      "\n",
      "Epoch: 103  Training loss = 1.5296  Test loss = 2.4513  \n",
      "\n",
      "Epoch: 104  Training loss = 1.5294  Test loss = 2.4513  \n",
      "\n",
      "Epoch: 105  Training loss = 1.5293  Test loss = 2.4512  \n",
      "\n",
      "Epoch: 106  Training loss = 1.5292  Test loss = 2.4512  \n",
      "\n",
      "Epoch: 107  Training loss = 1.5291  Test loss = 2.4511  \n",
      "\n",
      "Epoch: 108  Training loss = 1.5290  Test loss = 2.4510  \n",
      "\n",
      "Epoch: 109  Training loss = 1.5289  Test loss = 2.4510  \n",
      "\n",
      "Epoch: 110  Training loss = 1.5288  Test loss = 2.4509  \n",
      "\n",
      "Epoch: 111  Training loss = 1.5287  Test loss = 2.4509  \n",
      "\n",
      "Epoch: 112  Training loss = 1.5286  Test loss = 2.4508  \n",
      "\n",
      "Epoch: 113  Training loss = 1.5284  Test loss = 2.4508  \n",
      "\n",
      "Epoch: 114  Training loss = 1.5283  Test loss = 2.4507  \n",
      "\n",
      "Epoch: 115  Training loss = 1.5282  Test loss = 2.4506  \n",
      "\n",
      "Epoch: 116  Training loss = 1.5281  Test loss = 2.4506  \n",
      "\n",
      "Epoch: 117  Training loss = 1.5280  Test loss = 2.4505  \n",
      "\n",
      "Epoch: 118  Training loss = 1.5279  Test loss = 2.4505  \n",
      "\n",
      "Epoch: 119  Training loss = 1.5278  Test loss = 2.4504  \n",
      "\n",
      "Epoch: 120  Training loss = 1.5277  Test loss = 2.4504  \n",
      "\n",
      "Epoch: 121  Training loss = 1.5276  Test loss = 2.4503  \n",
      "\n",
      "Epoch: 122  Training loss = 1.5275  Test loss = 2.4503  \n",
      "\n",
      "Epoch: 123  Training loss = 1.5274  Test loss = 2.4502  \n",
      "\n",
      "Epoch: 124  Training loss = 1.5273  Test loss = 2.4502  \n",
      "\n",
      "Epoch: 125  Training loss = 1.5272  Test loss = 2.4501  \n",
      "\n",
      "Epoch: 126  Training loss = 1.5271  Test loss = 2.4500  \n",
      "\n",
      "Epoch: 127  Training loss = 1.5270  Test loss = 2.4500  \n",
      "\n",
      "Epoch: 128  Training loss = 1.5269  Test loss = 2.4499  \n",
      "\n",
      "Epoch: 129  Training loss = 1.5267  Test loss = 2.4499  \n",
      "\n",
      "Epoch: 130  Training loss = 1.5266  Test loss = 2.4498  \n",
      "\n",
      "Epoch: 131  Training loss = 1.5265  Test loss = 2.4498  \n",
      "\n",
      "Epoch: 132  Training loss = 1.5264  Test loss = 2.4497  \n",
      "\n",
      "Epoch: 133  Training loss = 1.5263  Test loss = 2.4497  \n",
      "\n",
      "Epoch: 134  Training loss = 1.5262  Test loss = 2.4496  \n",
      "\n",
      "Epoch: 135  Training loss = 1.5261  Test loss = 2.4496  \n",
      "\n",
      "Epoch: 136  Training loss = 1.5260  Test loss = 2.4495  \n",
      "\n",
      "Epoch: 137  Training loss = 1.5259  Test loss = 2.4495  \n",
      "\n",
      "Epoch: 138  Training loss = 1.5258  Test loss = 2.4494  \n",
      "\n",
      "Epoch: 139  Training loss = 1.5257  Test loss = 2.4494  \n",
      "\n",
      "Epoch: 140  Training loss = 1.5256  Test loss = 2.4493  \n",
      "\n",
      "Epoch: 141  Training loss = 1.5255  Test loss = 2.4493  \n",
      "\n",
      "Epoch: 142  Training loss = 1.5254  Test loss = 2.4492  \n",
      "\n",
      "Epoch: 143  Training loss = 1.5253  Test loss = 2.4492  \n",
      "\n",
      "Epoch: 144  Training loss = 1.5252  Test loss = 2.4491  \n",
      "\n",
      "Epoch: 145  Training loss = 1.5252  Test loss = 2.4491  \n",
      "\n",
      "Epoch: 146  Training loss = 1.5251  Test loss = 2.4490  \n",
      "\n",
      "Epoch: 147  Training loss = 1.5250  Test loss = 2.4490  \n",
      "\n",
      "Epoch: 148  Training loss = 1.5249  Test loss = 2.4489  \n",
      "\n",
      "Epoch: 149  Training loss = 1.5248  Test loss = 2.4489  \n",
      "\n",
      "Epoch: 150  Training loss = 1.5247  Test loss = 2.4488  \n",
      "\n",
      "Epoch: 151  Training loss = 1.5246  Test loss = 2.4488  \n",
      "\n",
      "Epoch: 152  Training loss = 1.5245  Test loss = 2.4487  \n",
      "\n",
      "Epoch: 153  Training loss = 1.5244  Test loss = 2.4487  \n",
      "\n",
      "Epoch: 154  Training loss = 1.5243  Test loss = 2.4486  \n",
      "\n",
      "Epoch: 155  Training loss = 1.5242  Test loss = 2.4486  \n",
      "\n",
      "Epoch: 156  Training loss = 1.5241  Test loss = 2.4485  \n",
      "\n",
      "Epoch: 157  Training loss = 1.5240  Test loss = 2.4485  \n",
      "\n",
      "Epoch: 158  Training loss = 1.5239  Test loss = 2.4484  \n",
      "\n",
      "Epoch: 159  Training loss = 1.5238  Test loss = 2.4484  \n",
      "\n",
      "Epoch: 160  Training loss = 1.5237  Test loss = 2.4483  \n",
      "\n",
      "Epoch: 161  Training loss = 1.5236  Test loss = 2.4483  \n",
      "\n",
      "Epoch: 162  Training loss = 1.5236  Test loss = 2.4483  \n",
      "\n",
      "Epoch: 163  Training loss = 1.5235  Test loss = 2.4482  \n",
      "\n",
      "Epoch: 164  Training loss = 1.5234  Test loss = 2.4482  \n",
      "\n",
      "Epoch: 165  Training loss = 1.5233  Test loss = 2.4481  \n",
      "\n",
      "Epoch: 166  Training loss = 1.5232  Test loss = 2.4481  \n",
      "\n",
      "Epoch: 167  Training loss = 1.5231  Test loss = 2.4480  \n",
      "\n",
      "Epoch: 168  Training loss = 1.5230  Test loss = 2.4480  \n",
      "\n",
      "Epoch: 169  Training loss = 1.5229  Test loss = 2.4479  \n",
      "\n",
      "Epoch: 170  Training loss = 1.5228  Test loss = 2.4479  \n",
      "\n",
      "Epoch: 171  Training loss = 1.5228  Test loss = 2.4478  \n",
      "\n",
      "Epoch: 172  Training loss = 1.5227  Test loss = 2.4478  \n",
      "\n",
      "Epoch: 173  Training loss = 1.5226  Test loss = 2.4478  \n",
      "\n",
      "Epoch: 174  Training loss = 1.5225  Test loss = 2.4477  \n",
      "\n",
      "Epoch: 175  Training loss = 1.5224  Test loss = 2.4477  \n",
      "\n",
      "Epoch: 176  Training loss = 1.5223  Test loss = 2.4476  \n",
      "\n",
      "Epoch: 177  Training loss = 1.5222  Test loss = 2.4476  \n",
      "\n",
      "Epoch: 178  Training loss = 1.5221  Test loss = 2.4475  \n",
      "\n",
      "Epoch: 179  Training loss = 1.5221  Test loss = 2.4475  \n",
      "\n",
      "Epoch: 180  Training loss = 1.5220  Test loss = 2.4475  \n",
      "\n",
      "Epoch: 181  Training loss = 1.5219  Test loss = 2.4474  \n",
      "\n",
      "Epoch: 182  Training loss = 1.5218  Test loss = 2.4474  \n",
      "\n",
      "Epoch: 183  Training loss = 1.5217  Test loss = 2.4473  \n",
      "\n",
      "Epoch: 184  Training loss = 1.5216  Test loss = 2.4473  \n",
      "\n",
      "Epoch: 185  Training loss = 1.5215  Test loss = 2.4473  \n",
      "\n",
      "Epoch: 186  Training loss = 1.5215  Test loss = 2.4472  \n",
      "\n",
      "Epoch: 187  Training loss = 1.5214  Test loss = 2.4472  \n",
      "\n",
      "Epoch: 188  Training loss = 1.5213  Test loss = 2.4471  \n",
      "\n",
      "Epoch: 189  Training loss = 1.5212  Test loss = 2.4471  \n",
      "\n",
      "Epoch: 190  Training loss = 1.5211  Test loss = 2.4471  \n",
      "\n",
      "Epoch: 191  Training loss = 1.5210  Test loss = 2.4470  \n",
      "\n",
      "Epoch: 192  Training loss = 1.5210  Test loss = 2.4470  \n",
      "\n",
      "Epoch: 193  Training loss = 1.5209  Test loss = 2.4469  \n",
      "\n",
      "Epoch: 194  Training loss = 1.5208  Test loss = 2.4469  \n",
      "\n",
      "Epoch: 195  Training loss = 1.5207  Test loss = 2.4469  \n",
      "\n",
      "Epoch: 196  Training loss = 1.5206  Test loss = 2.4468  \n",
      "\n",
      "Epoch: 197  Training loss = 1.5206  Test loss = 2.4468  \n",
      "\n",
      "Epoch: 198  Training loss = 1.5205  Test loss = 2.4467  \n",
      "\n",
      "Epoch: 199  Training loss = 1.5204  Test loss = 2.4467  \n",
      "\n",
      "Epoch: 200  Training loss = 1.5203  Test loss = 2.4467  \n",
      "\n",
      "Epoch: 201  Training loss = 1.5202  Test loss = 2.4466  \n",
      "\n",
      "Epoch: 202  Training loss = 1.5202  Test loss = 2.4466  \n",
      "\n",
      "Epoch: 203  Training loss = 1.5201  Test loss = 2.4466  \n",
      "\n",
      "Epoch: 204  Training loss = 1.5200  Test loss = 2.4465  \n",
      "\n",
      "Epoch: 205  Training loss = 1.5199  Test loss = 2.4465  \n",
      "\n",
      "Epoch: 206  Training loss = 1.5198  Test loss = 2.4465  \n",
      "\n",
      "Epoch: 207  Training loss = 1.5198  Test loss = 2.4464  \n",
      "\n",
      "Epoch: 208  Training loss = 1.5197  Test loss = 2.4464  \n",
      "\n",
      "Epoch: 209  Training loss = 1.5196  Test loss = 2.4463  \n",
      "\n",
      "Epoch: 210  Training loss = 1.5195  Test loss = 2.4463  \n",
      "\n",
      "Epoch: 211  Training loss = 1.5195  Test loss = 2.4463  \n",
      "\n",
      "Epoch: 212  Training loss = 1.5194  Test loss = 2.4462  \n",
      "\n",
      "Epoch: 213  Training loss = 1.5193  Test loss = 2.4462  \n",
      "\n",
      "Epoch: 214  Training loss = 1.5192  Test loss = 2.4462  \n",
      "\n",
      "Epoch: 215  Training loss = 1.5191  Test loss = 2.4461  \n",
      "\n",
      "Epoch: 216  Training loss = 1.5191  Test loss = 2.4461  \n",
      "\n",
      "Epoch: 217  Training loss = 1.5190  Test loss = 2.4461  \n",
      "\n",
      "Epoch: 218  Training loss = 1.5189  Test loss = 2.4460  \n",
      "\n",
      "Epoch: 219  Training loss = 1.5188  Test loss = 2.4460  \n",
      "\n",
      "Epoch: 220  Training loss = 1.5188  Test loss = 2.4460  \n",
      "\n",
      "Epoch: 221  Training loss = 1.5187  Test loss = 2.4459  \n",
      "\n",
      "Epoch: 222  Training loss = 1.5186  Test loss = 2.4459  \n",
      "\n",
      "Epoch: 223  Training loss = 1.5185  Test loss = 2.4459  \n",
      "\n",
      "Epoch: 224  Training loss = 1.5185  Test loss = 2.4458  \n",
      "\n",
      "Epoch: 225  Training loss = 1.5184  Test loss = 2.4458  \n",
      "\n",
      "Epoch: 226  Training loss = 1.5183  Test loss = 2.4458  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb71cdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTMaRx+ce5WsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc8e0c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.44577845109 \n",
      "Fixed scheme MAE:  1.53974314554\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.5183  Test loss = 2.0989  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.5356  Test loss = 1.4189  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.4989  Test loss = 0.7083  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.4929  Test loss = 0.5616  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.4243  Test loss = 0.2393  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.3825  Test loss = 0.4899  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.3341  Test loss = 0.5310  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.3186  Test loss = 0.3879  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.2797  Test loss = 0.5295  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.2797  Test loss = 1.0186  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.2554  Test loss = 0.9627  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.2604  Test loss = 2.0202  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.2441  Test loss = 0.5389  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.2459  Test loss = 1.8446  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.2665  Test loss = 2.6493  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.3017  Test loss = 3.2584  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.3205  Test loss = 0.1789  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.3166  Test loss = 0.0434  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.3093  Test loss = 1.2940  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.1550  Test loss = 0.8236  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.1385  Test loss = 1.4891  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.1528  Test loss = 3.5257  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.2193  Test loss = 0.2187  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.2090  Test loss = 1.9336  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.1924  Test loss = 0.4094  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.1880  Test loss = 0.0645  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.1880  Test loss = 0.6743  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.1795  Test loss = 1.2482  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.1467  Test loss = 0.7414  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.1446  Test loss = 0.0087  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.1374  Test loss = 3.6116  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.1896  Test loss = 0.5096  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.1600  Test loss = 1.3590  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.1722  Test loss = 0.4219  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.1227  Test loss = 0.2265  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.1197  Test loss = 5.0658  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.2247  Test loss = 0.9315  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.1975  Test loss = 1.6700  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.1987  Test loss = 1.3353  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2097  Test loss = 2.0695  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.1786  Test loss = 1.1295  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.1867  Test loss = 1.4458  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.1999  Test loss = 2.0812  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.2263  Test loss = 13.1248  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0149  Test loss = 6.5554  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1711  Test loss = 0.4872  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1715  Test loss = 0.7232  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1725  Test loss = 1.0116  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.9258  Test loss = 1.7984  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.9319  Test loss = 3.0023  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.9673  Test loss = 1.7113  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.9753  Test loss = 0.6321  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.9447  Test loss = 1.7981  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.9572  Test loss = 2.3763  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.9782  Test loss = 0.1456  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.9728  Test loss = 0.5735  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.9533  Test loss = 0.3517  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.9538  Test loss = 1.5997  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.9627  Test loss = 0.6017  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.9626  Test loss = 0.3178  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.9430  Test loss = 0.6288  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.9446  Test loss = 2.6533  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.9686  Test loss = 0.0313  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.9580  Test loss = 0.7902  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.9147  Test loss = 0.1012  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.9115  Test loss = 0.3832  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.9045  Test loss = 1.0156  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.9073  Test loss = 2.9104  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.9174  Test loss = 4.7057  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.0039  Test loss = 1.3442  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.0108  Test loss = 0.7986  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.0103  Test loss = 1.9135  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.9949  Test loss = 1.9881  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.0078  Test loss = 1.3097  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.0127  Test loss = 0.1101  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.0111  Test loss = 1.4707  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.9932  Test loss = 1.3912  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xca80320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.33091771056 \n",
      "Updating scheme MAE:  1.48214290717\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
