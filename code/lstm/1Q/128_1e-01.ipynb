{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/128_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-1\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 128 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 128 \n",
      "Learning rate = 0.1 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.1\n",
      "Fold: 1  Epoch: 1  Training loss = 2.8561  Validation loss = 2.2229  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.8061  Validation loss = 0.6901  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.6663  Validation loss = 1.5316  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.6788  Validation loss = 1.7933  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.6216  Validation loss = 1.3409  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.5489  Validation loss = 1.4914  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.5467  Validation loss = 0.9482  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.7511  Validation loss = 2.2085  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.5603  Validation loss = 2.1784  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.6493  Validation loss = 3.0605  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.1499  Validation loss = 1.9865  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.1274  Validation loss = 1.6172  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.0957  Validation loss = 0.4907  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 1.9849  Validation loss = 0.8000  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 1.6877  Validation loss = 0.9005  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 1.7620  Validation loss = 2.0734  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 1.6322  Validation loss = 1.1798  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 1.4127  Validation loss = 1.4187  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 1.5243  Validation loss = 1.2800  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 1.5032  Validation loss = 1.4909  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 1.5874  Validation loss = 0.8233  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 1.4712  Validation loss = 1.0633  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 1.3568  Validation loss = 1.7531  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 1.3738  Validation loss = 1.4075  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 1.4271  Validation loss = 2.2975  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 13  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 1.3741  Validation loss = 2.4085  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 1.3746  Validation loss = 2.2477  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 1.3278  Validation loss = 2.2177  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 1.3114  Validation loss = 1.9474  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 1.4295  Validation loss = 2.6038  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 1.3167  Validation loss = 1.9695  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 1.2362  Validation loss = 2.1727  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 1.3579  Validation loss = 1.9587  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 1.3273  Validation loss = 1.7323  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 1.2133  Validation loss = 1.8688  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 1.1616  Validation loss = 2.0995  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 1.2420  Validation loss = 2.0319  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 1.2311  Validation loss = 1.6641  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 1.1805  Validation loss = 1.9238  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 1.5588  Validation loss = 3.0606  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 13  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.1589  Validation loss = 1.5271  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.2995  Validation loss = 0.8344  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.0634  Validation loss = 1.1692  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.0585  Validation loss = 0.8743  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.0491  Validation loss = 0.9332  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.1411  Validation loss = 0.5771  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.0717  Validation loss = 1.0307  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.0450  Validation loss = 0.8020  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.1802  Validation loss = 1.1469  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.2424  Validation loss = 1.5001  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.0392  Validation loss = 0.9419  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.0218  Validation loss = 1.0446  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.0303  Validation loss = 0.7790  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 0.9872  Validation loss = 0.5218  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 0.9604  Validation loss = 0.7673  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.0078  Validation loss = 0.9707  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.0038  Validation loss = 0.6184  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 0.9532  Validation loss = 0.6425  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 0.9272  Validation loss = 0.9918  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 0.9197  Validation loss = 0.8191  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 0.9700  Validation loss = 0.7100  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 0.9307  Validation loss = 0.8931  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.0243  Validation loss = 0.7590  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 0.9421  Validation loss = 0.3292  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 0.8688  Validation loss = 0.5463  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 0.8761  Validation loss = 0.7412  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 0.9541  Validation loss = 0.7246  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 0.9321  Validation loss = 0.8802  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 0.8802  Validation loss = 0.6976  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 0.8537  Validation loss = 0.6582  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 0.8751  Validation loss = 0.6829  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.0328  Validation loss = 1.5295  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 24  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 0.9163  Validation loss = 2.9865  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 0.9503  Validation loss = 3.0691  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 0.8808  Validation loss = 2.4389  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 0.8485  Validation loss = 3.0519  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 0.8206  Validation loss = 2.1647  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 0.8254  Validation loss = 3.2791  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 0.8977  Validation loss = 2.9708  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 0.7697  Validation loss = 2.8257  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 0.8562  Validation loss = 2.8331  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 0.9252  Validation loss = 1.8472  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 0.8454  Validation loss = 2.7703  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 0.8476  Validation loss = 3.2670  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 0.7690  Validation loss = 3.1296  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 0.8138  Validation loss = 2.7392  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 0.7332  Validation loss = 2.7316  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 0.7729  Validation loss = 2.6644  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 0.6995  Validation loss = 2.7302  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 0.9236  Validation loss = 2.1008  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 0.8585  Validation loss = 1.8611  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 0.7707  Validation loss = 3.5979  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 10  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.0031  Validation loss = 1.2710  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 0.8467  Validation loss = 1.1933  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 0.9311  Validation loss = 1.0918  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 0.9078  Validation loss = 1.6376  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 0.9251  Validation loss = 1.5459  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.0285  Validation loss = 2.3555  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 0.8682  Validation loss = 1.7674  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 0.8245  Validation loss = 1.6847  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 0.9056  Validation loss = 2.1585  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 0.8255  Validation loss = 1.8672  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.8595  Validation loss = 1.8404  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 0.9615  Validation loss = 1.4200  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 0.8389  Validation loss = 1.8290  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 0.7586  Validation loss = 2.0339  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.7618  Validation loss = 1.8536  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 0.9027  Validation loss = 2.2554  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 3  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 0.9326  Validation loss = 1.5938  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.0368  Validation loss = 1.7350  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.9346  Validation loss = 2.1557  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.8028  Validation loss = 1.7840  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.7667  Validation loss = 1.7232  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.9597  Validation loss = 1.7884  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.7715  Validation loss = 1.2551  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.7152  Validation loss = 1.2652  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.6866  Validation loss = 1.5814  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.6603  Validation loss = 1.4954  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.7902  Validation loss = 1.6016  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.6583  Validation loss = 1.6185  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.7895  Validation loss = 1.5738  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.9949  Validation loss = 1.8751  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 7  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.1717  Validation loss = 0.9709  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.8059  Validation loss = 1.7751  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.8737  Validation loss = 2.0117  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.7594  Validation loss = 1.3623  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.8770  Validation loss = 0.4428  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.7846  Validation loss = 1.5247  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.7610  Validation loss = 1.2660  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.8855  Validation loss = 0.6157  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.6928  Validation loss = 1.3367  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.6864  Validation loss = 1.3011  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.8324  Validation loss = 1.0608  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.7561  Validation loss = 1.2785  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.6688  Validation loss = 0.7069  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.9120  Validation loss = 0.7242  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 0.6555  Validation loss = 1.2708  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 0.7212  Validation loss = 1.3024  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 0.8941  Validation loss = 1.2225  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 0.7942  Validation loss = 1.0998  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 0.8360  Validation loss = 0.5748  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 0.6245  Validation loss = 1.1351  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 0.5598  Validation loss = 0.8470  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 0.8047  Validation loss = 0.5161  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 0.5841  Validation loss = 0.5142  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 0.5966  Validation loss = 1.1453  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 0.6740  Validation loss = 1.4331  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 5  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.7578  Validation loss = 4.7716  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.7228  Validation loss = 4.7778  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.6843  Validation loss = 4.3633  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.6804  Validation loss = 5.0598  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.8347  Validation loss = 5.3217  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.6594  Validation loss = 4.8960  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.6089  Validation loss = 5.1883  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.6013  Validation loss = 4.8639  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.7048  Validation loss = 4.5155  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.5683  Validation loss = 4.9521  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.6430  Validation loss = 4.9764  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.7179  Validation loss = 5.4629  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 3  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.4156  Validation loss = 6.6916  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.5497  Validation loss = 5.6540  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.5280  Validation loss = 5.3023  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.4415  Validation loss = 6.4459  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.4607  Validation loss = 6.1752  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.0955  Validation loss = 6.8004  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 2.1496  Validation loss = 7.4570  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.0524  Validation loss = 7.5703  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.0469  Validation loss = 6.9675  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.1290  Validation loss = 6.9943  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.1375  Validation loss = 7.3350  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 0.9891  Validation loss = 7.5926  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 3  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 1.8721  Validation loss = 2.7244  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.4572  Validation loss = 1.9425  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.6832  Validation loss = 2.8862  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.9312  Validation loss = 3.5960  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.7788  Validation loss = 2.5461  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 2.5620  Validation loss = 3.5097  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.6063  Validation loss = 1.7316  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 2.2886  Validation loss = 3.5608  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.6996  Validation loss = 3.7119  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.5654  Validation loss = 3.8441  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.7708  Validation loss = 2.7395  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 2.0603  Validation loss = 4.2078  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 7  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.4670  Validation loss = 1.4269  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.6414  Validation loss = 2.6779  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.2185  Validation loss = 2.2640  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.5113  Validation loss = 1.8762  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.7322  Validation loss = 1.5562  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.7811  Validation loss = 3.1240  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.4729  Validation loss = 3.1280  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.5804  Validation loss = 1.8288  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.3191  Validation loss = 2.7115  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.2241  Validation loss = 4.4550  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.3537  Validation loss = 2.8439  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.4125  Validation loss = 2.9540  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.3133  Validation loss = 2.1595  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.3699  Validation loss = 1.7834  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 1.3449  Validation loss = 3.2240  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 1.4417  Validation loss = 4.7869  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 1  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.2369  Validation loss = 2.2515  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.6129  Validation loss = 1.6344  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.7845  Validation loss = 1.3202  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 2.9737  Validation loss = 2.6771  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.7689  Validation loss = 0.9084  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 2.5383  Validation loss = 1.7408  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.7094  Validation loss = 2.1706  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.6986  Validation loss = 3.0439  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.5050  Validation loss = 2.1019  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.5896  Validation loss = 1.4982  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.3457  Validation loss = 2.8755  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.4799  Validation loss = 2.6105  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 2.0801  Validation loss = 4.0277  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 5  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.5583  Validation loss = 3.9244  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.6861  Validation loss = 4.2243  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 2.3311  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.4241  Validation loss = 2.3731  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.3571  Validation loss = 2.7026  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.3633  Validation loss = 2.2843  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.4390  Validation loss = 2.4458  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.8622  Validation loss = 3.7703  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.5685  Validation loss = 3.6909  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.7869  Validation loss = 4.0541  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.7244  Validation loss = 1.9532  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.7839  Validation loss = 2.4079  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 2.1125  Validation loss = 3.4763  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 2.0194  Validation loss = 3.9874  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 2.1039  Validation loss = 2.5217  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 2.2182  Validation loss = 1.3244  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 1.7605  Validation loss = 2.6547  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 1.6103  Validation loss = 2.7302  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 1.6261  Validation loss = 2.8415  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 1.7749  Validation loss = 2.3942  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 1.8111  Validation loss = 3.2266  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 2.1715  Validation loss = 3.0921  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 2.0095  Validation loss = 2.5236  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 1.6017  Validation loss = 2.9159  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 2.1307  Validation loss = 3.7292  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 3  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 2.1790  Validation loss = 4.5080  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.9852  Validation loss = 6.6342  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 2.0787  Validation loss = 4.6164  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.9351  Validation loss = 6.2202  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 2.5098  Validation loss = 4.5062  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.9500  Validation loss = 5.8086  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.9349  Validation loss = 3.9597  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 2.2911  Validation loss = 6.8784  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 2.0082  Validation loss = 6.6687  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 2.3681  Validation loss = 6.0972  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 2.1091  Validation loss = 3.9173  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 2.5875  Validation loss = 4.0057  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.1673  Validation loss = 3.7407  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.8543  Validation loss = 5.7390  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.8740  Validation loss = 6.3701  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 1.8408  Validation loss = 4.5599  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 2.1612  Validation loss = 3.5922  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.7841  Validation loss = 3.7766  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.7796  Validation loss = 5.3279  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 2.2467  Validation loss = 6.5484  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 17  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 2.3300  Validation loss = 6.2975  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 2.6769  Validation loss = 5.3529  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.4572  Validation loss = 3.3963  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 2.0566  Validation loss = 4.7405  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 2.2616  Validation loss = 4.9742  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 2.2343  Validation loss = 5.0656  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.2753  Validation loss = 3.2835  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 2.3011  Validation loss = 3.5623  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 2.4219  Validation loss = 3.7902  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.3380  Validation loss = 5.2014  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 2.3170  Validation loss = 4.1703  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 2.5161  Validation loss = 3.5839  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.5055  Validation loss = 3.1510  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.1631  Validation loss = 4.5739  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 2.2329  Validation loss = 5.3117  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 13  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.8346  Validation loss = 5.1222  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.1194  Validation loss = 6.2147  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.2053  Validation loss = 7.7952  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.5403  Validation loss = 5.0608  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.5099  Validation loss = 4.8323  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 2.2308  Validation loss = 5.8427  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.2947  Validation loss = 3.7735  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 3.0064  Validation loss = 6.6475  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.5628  Validation loss = 6.0095  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.5181  Validation loss = 4.7985  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.2492  Validation loss = 4.6051  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 2.3067  Validation loss = 4.7188  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 2.4015  Validation loss = 4.7864  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.6114  Validation loss = 5.8840  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 2.0217  Validation loss = 5.4029  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 2.2857  Validation loss = 4.8346  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 2.5892  Validation loss = 6.7596  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 7  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.8693  Validation loss = 3.2612  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.4733  Validation loss = 2.8681  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.3754  Validation loss = 3.1071  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.7007  Validation loss = 3.9070  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.5404  Validation loss = 1.5340  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.4362  Validation loss = 1.4395  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.4462  Validation loss = 1.6293  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.5633  Validation loss = 2.4933  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.3393  Validation loss = 2.4579  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.2040  Validation loss = 2.5515  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.3532  Validation loss = 2.8074  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.2340  Validation loss = 3.0018  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.2604  Validation loss = 1.7454  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.5596  Validation loss = 3.9404  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 6  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.7514  Validation loss = 1.7419  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.4940  Validation loss = 2.2160  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 2.3139  Validation loss = 2.8232  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 3.3825  Validation loss = 3.3775  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.3368  Validation loss = 2.7277  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.4879  Validation loss = 2.3126  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 2.5030  Validation loss = 2.5680  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.9690  Validation loss = 2.8596  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 2.2982  Validation loss = 2.5301  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 2.3123  Validation loss = 2.8228  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 3.7233  Validation loss = 3.8535  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 1  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.7790  Validation loss = 5.5562  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 3.5406  Validation loss = 9.9406  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.1888  Validation loss = 6.5315  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.3064  Validation loss = 7.6574  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 3.0383  Validation loss = 8.7912  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.2213  Validation loss = 6.3205  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.1167  Validation loss = 6.8267  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 3.0113  Validation loss = 8.0703  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.2994  Validation loss = 5.8721  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 3.0887  Validation loss = 8.8344  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 2.2785  Validation loss = 6.3058  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 2.5617  Validation loss = 7.9469  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 2.2180  Validation loss = 6.8586  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 2.5672  Validation loss = 5.6761  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 2.3311  Validation loss = 5.5761  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 2.1252  Validation loss = 6.1905  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 2.5595  Validation loss = 6.2430  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 2.2098  Validation loss = 5.2456  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 2.1102  Validation loss = 4.9907  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 2.2819  Validation loss = 5.2104  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 2.3771  Validation loss = 7.5733  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 2.4910  Validation loss = 5.8835  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 2.2188  Validation loss = 6.6398  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 2.2988  Validation loss = 6.5987  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 2.3889  Validation loss = 8.4070  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 19  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.7274  Validation loss = 4.2076  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.5590  Validation loss = 5.2824  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.8445  Validation loss = 5.1211  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 3.0354  Validation loss = 2.2845  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.6874  Validation loss = 4.4242  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.4480  Validation loss = 2.4081  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.2978  Validation loss = 1.9071  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.2231  Validation loss = 2.1086  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 2.3558  Validation loss = 1.4454  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.1555  Validation loss = 1.7476  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.3163  Validation loss = 2.0321  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.9948  Validation loss = 2.2432  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 3.3584  Validation loss = 3.9660  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.4292  Validation loss = 1.4457  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.6042  Validation loss = 1.9640  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.2635  Validation loss = 3.2178  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 2.3415  Validation loss = 0.9963  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 2.2878  Validation loss = 1.6492  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 2.2119  Validation loss = 1.4917  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 3.1992  Validation loss = 3.9179  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 2.0880  Validation loss = 3.1599  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 2.8999  Validation loss = 3.8260  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 3.1502  Validation loss = 2.3971  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 2.2935  Validation loss = 2.3594  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 2.4302  Validation loss = 3.2146  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 2.6362  Validation loss = 3.2307  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 2.2574  Validation loss = 3.6203  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 2.3775  Validation loss = 2.5302  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 2.1618  Validation loss = 3.1757  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 2.2178  Validation loss = 2.2467  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 2.0323  Validation loss = 2.4381  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 2.9852  Validation loss = 4.2888  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 17  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.2917  Validation loss = 5.1726  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 2.4400  Validation loss = 4.4003  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.5214  Validation loss = 3.9355  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 2.4620  Validation loss = 5.4976  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.3530  Validation loss = 5.0323  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.4123  Validation loss = 3.5855  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.4002  Validation loss = 5.1877  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.1369  Validation loss = 3.8648  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 2.3457  Validation loss = 5.3824  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 2.3197  Validation loss = 4.5320  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 2.5818  Validation loss = 3.1950  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.3820  Validation loss = 3.9841  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 2.3183  Validation loss = 3.8082  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 2.4058  Validation loss = 4.4792  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 2.3574  Validation loss = 2.3140  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 3.5888  Validation loss = 1.4524  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 3.7778  Validation loss = 1.5660  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 2.2650  Validation loss = 4.6695  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 2.2424  Validation loss = 3.5155  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 2.3097  Validation loss = 3.3193  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 2.0981  Validation loss = 3.8876  \n",
      "\n",
      "Fold: 21  Epoch: 22  Training loss = 2.0519  Validation loss = 3.2993  \n",
      "\n",
      "Fold: 21  Epoch: 23  Training loss = 2.0106  Validation loss = 3.4138  \n",
      "\n",
      "Fold: 21  Epoch: 24  Training loss = 2.1352  Validation loss = 4.0983  \n",
      "\n",
      "Fold: 21  Epoch: 25  Training loss = 2.0759  Validation loss = 3.7462  \n",
      "\n",
      "Fold: 21  Epoch: 26  Training loss = 2.3051  Validation loss = 2.5428  \n",
      "\n",
      "Fold: 21  Epoch: 27  Training loss = 2.4426  Validation loss = 4.0717  \n",
      "\n",
      "Fold: 21  Epoch: 28  Training loss = 2.2591  Validation loss = 2.0849  \n",
      "\n",
      "Fold: 21  Epoch: 29  Training loss = 2.0077  Validation loss = 3.7691  \n",
      "\n",
      "Fold: 21  Epoch: 30  Training loss = 2.3248  Validation loss = 3.6539  \n",
      "\n",
      "Fold: 21  Epoch: 31  Training loss = 2.2565  Validation loss = 4.7979  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 16  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 2.0114  Validation loss = 4.4702  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 2.1000  Validation loss = 4.0282  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 1.7802  Validation loss = 4.4234  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.2385  Validation loss = 2.8142  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.2253  Validation loss = 3.9064  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 1.7547  Validation loss = 4.4790  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 1.7844  Validation loss = 4.6637  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 1.7851  Validation loss = 4.5040  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 1.7461  Validation loss = 3.3623  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 1.7620  Validation loss = 3.9116  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 1.6025  Validation loss = 2.9404  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 2.0274  Validation loss = 2.4131  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 2.2684  Validation loss = 4.6003  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 1.5562  Validation loss = 4.1160  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 1.5692  Validation loss = 3.7757  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 1.5250  Validation loss = 3.5482  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 1.4933  Validation loss = 3.2987  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 1.6826  Validation loss = 3.6141  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 1.4469  Validation loss = 3.8767  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 1.7220  Validation loss = 3.4891  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 1.5346  Validation loss = 3.1644  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 1.4772  Validation loss = 3.8090  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 1.5467  Validation loss = 3.5495  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 1.5618  Validation loss = 3.3484  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 2.1213  Validation loss = 2.2480  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 1.6895  Validation loss = 3.0535  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 1.5412  Validation loss = 3.0733  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 1.8503  Validation loss = 4.3358  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 25  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.2425  Validation loss = 1.4884  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.8981  Validation loss = 3.7406  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.1142  Validation loss = 2.4696  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.0981  Validation loss = 2.3775  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.2238  Validation loss = 1.5050  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.1580  Validation loss = 0.7889  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.4826  Validation loss = 1.1467  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.4584  Validation loss = 2.4185  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.0959  Validation loss = 1.6479  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 1.8772  Validation loss = 1.1271  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 2.3633  Validation loss = 2.8698  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.1653  Validation loss = 2.1479  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 1.8587  Validation loss = 0.9576  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 1.8496  Validation loss = 0.5322  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 3.5295  Validation loss = 3.4993  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 14  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.4473  Validation loss = 3.6694  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 2.4779  Validation loss = 3.0101  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.7343  Validation loss = 2.7336  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 2.3856  Validation loss = 3.0642  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.2985  Validation loss = 3.2389  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 2.4599  Validation loss = 3.3693  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.2886  Validation loss = 2.7343  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 5.2874  Validation loss = 4.5892  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.5067  Validation loss = 2.7905  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.3629  Validation loss = 3.1122  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.4061  Validation loss = 3.1885  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.5703  Validation loss = 2.8129  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 3.7255  Validation loss = 3.4764  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 1.8380  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.2435  Validation loss = 2.8096  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 2.6239  Validation loss = 2.8910  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.0604  Validation loss = 3.1982  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 1.9347  Validation loss = 2.4172  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 1.9378  Validation loss = 2.7635  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 2.6551  Validation loss = 3.0706  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 2.1216  Validation loss = 2.3218  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 2.2994  Validation loss = 4.1052  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 21  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.9198  Validation loss = 4.2204  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 1.9662  Validation loss = 2.1583  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.0153  Validation loss = 3.0758  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 3.1265  Validation loss = 1.8817  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.1462  Validation loss = 1.4130  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.5881  Validation loss = 2.0731  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.3879  Validation loss = 2.2953  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.3860  Validation loss = 1.6001  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.8547  Validation loss = 3.2968  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 3.8759  Validation loss = 2.3700  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.0560  Validation loss = 1.5960  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.2718  Validation loss = 2.3025  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.2414  Validation loss = 2.9174  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 2.1419  Validation loss = 2.3751  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 1.8398  Validation loss = 2.9587  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 2.0081  Validation loss = 2.0705  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 2.7549  Validation loss = 4.0419  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 5  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.1989  Validation loss = 1.6025  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.2366  Validation loss = 3.6579  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.2240  Validation loss = 3.3816  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.8306  Validation loss = 2.3066  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.3051  Validation loss = 1.9663  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.0508  Validation loss = 1.0211  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.1774  Validation loss = 3.0672  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 1.9817  Validation loss = 2.3070  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.1843  Validation loss = 1.6556  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.1095  Validation loss = 1.3343  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 4.3588  Validation loss = 5.0802  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 6  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.0156  Validation loss = 2.0012  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.8690  Validation loss = 3.8098  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 1.8940  Validation loss = 1.5285  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.1469  Validation loss = 1.5814  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 5.1296  Validation loss = 4.5417  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.9997  Validation loss = 5.9652  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.4359  Validation loss = 2.2159  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 1.8682  Validation loss = 1.4641  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 2.0475  Validation loss = 1.2989  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.9757  Validation loss = 1.3771  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.3148  Validation loss = 3.3511  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 3.9147  Validation loss = 2.9182  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 1.9132  Validation loss = 2.1895  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 1.9163  Validation loss = 1.3821  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.2954  Validation loss = 1.9272  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.0713  Validation loss = 1.5780  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.2092  Validation loss = 1.2861  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 1.9491  Validation loss = 2.3183  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 1.9329  Validation loss = 1.3247  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.0121  Validation loss = 2.6098  \n",
      "\n",
      "Fold: 27  Epoch: 21  Training loss = 1.7694  Validation loss = 1.0083  \n",
      "\n",
      "Fold: 27  Epoch: 22  Training loss = 2.4544  Validation loss = 1.9418  \n",
      "\n",
      "Fold: 27  Epoch: 23  Training loss = 2.0288  Validation loss = 1.4945  \n",
      "\n",
      "Fold: 27  Epoch: 24  Training loss = 2.6104  Validation loss = 1.3116  \n",
      "\n",
      "Fold: 27  Epoch: 25  Training loss = 2.0880  Validation loss = 1.5204  \n",
      "\n",
      "Fold: 27  Epoch: 26  Training loss = 1.6318  Validation loss = 1.1054  \n",
      "\n",
      "Fold: 27  Epoch: 27  Training loss = 2.6359  Validation loss = 2.3507  \n",
      "\n",
      "Fold: 27  Epoch: 28  Training loss = 2.4221  Validation loss = 1.3728  \n",
      "\n",
      "Fold: 27  Epoch: 29  Training loss = 1.8227  Validation loss = 0.4907  \n",
      "\n",
      "Fold: 27  Epoch: 30  Training loss = 1.8224  Validation loss = 1.1040  \n",
      "\n",
      "Fold: 27  Epoch: 31  Training loss = 2.8775  Validation loss = 3.4913  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 29  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.1125  Validation loss = 2.2542  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 1.9909  Validation loss = 1.0679  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.3796  Validation loss = 3.8263  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 1.6569  Validation loss = 2.1029  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.0831  Validation loss = 1.8783  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 1.6550  Validation loss = 2.1243  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 1.7127  Validation loss = 2.5851  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.2036  Validation loss = 1.6138  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 1.8819  Validation loss = 1.7000  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.8865  Validation loss = 1.1134  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.0432  Validation loss = 1.4457  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.1045  Validation loss = 2.3899  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 1.9847  Validation loss = 2.7492  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 2  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.2982  Validation loss = 2.1477  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 4.9303  Validation loss = 1.3561  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.1040  Validation loss = 1.1465  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.0569  Validation loss = 2.0669  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 1.9780  Validation loss = 1.7642  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.3932  Validation loss = 2.3521  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.1456  Validation loss = 3.4947  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.7162  Validation loss = 5.1139  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.5934  Validation loss = 2.9841  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 1.8734  Validation loss = 2.7806  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.0589  Validation loss = 3.5402  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 1.8077  Validation loss = 2.2036  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.2583  Validation loss = 2.3321  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 1.8134  Validation loss = 2.9383  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 2.3798  Validation loss = 2.8363  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 2.6896  Validation loss = 2.2220  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 2.1519  Validation loss = 3.0451  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 3.5174  Validation loss = 2.9026  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 2.6207  Validation loss = 2.4710  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 2.1535  Validation loss = 2.9116  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 2.3047  Validation loss = 2.7141  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 1.6597  Validation loss = 3.2630  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 3  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 1.9047  Validation loss = 2.5174  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.4376  Validation loss = 3.6610  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 1.8210  Validation loss = 1.3116  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.6580  Validation loss = 3.8468  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.1240  Validation loss = 3.0434  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 1.8457  Validation loss = 2.0818  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.0698  Validation loss = 2.5599  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.0082  Validation loss = 0.8951  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 1.6172  Validation loss = 2.0852  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.0111  Validation loss = 1.0786  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.7219  Validation loss = 1.7675  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 4.1561  Validation loss = 5.8950  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 8  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.6039  Validation loss = 2.9556  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.9700  Validation loss = 4.8539  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 1.8442  Validation loss = 2.6429  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.0060  Validation loss = 4.0285  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 3.2614  Validation loss = 3.2415  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 3.9385  Validation loss = 3.9041  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 3.4633  Validation loss = 3.4331  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 1.9744  Validation loss = 4.2350  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 1.7302  Validation loss = 3.4628  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 1.8433  Validation loss = 3.4380  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 1.7483  Validation loss = 2.9847  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.0064  Validation loss = 1.9700  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.0523  Validation loss = 3.2003  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 2.0060  Validation loss = 3.6110  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 2.2581  Validation loss = 3.4049  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 2.1838  Validation loss = 2.8885  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 5.5616  Validation loss = 6.0191  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 12  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.6188  Validation loss = 2.7286  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.6383  Validation loss = 3.9692  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.5998  Validation loss = 2.5546  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.3125  Validation loss = 2.9879  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.5190  Validation loss = 2.7378  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.7182  Validation loss = 1.1537  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.3313  Validation loss = 2.5934  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.3496  Validation loss = 1.7091  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 3.3360  Validation loss = 2.5717  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.6004  Validation loss = 2.9929  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 3.4327  Validation loss = 6.9361  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 6  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 10\n",
      "Average validation error: 4.34936\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.6856  Test loss = 2.7536  \n",
      "\n",
      "Epoch: 2  Training loss = 1.3223  Test loss = 3.1332  \n",
      "\n",
      "Epoch: 3  Training loss = 1.2607  Test loss = 2.8970  \n",
      "\n",
      "Epoch: 4  Training loss = 1.2482  Test loss = 2.9713  \n",
      "\n",
      "Epoch: 5  Training loss = 1.2430  Test loss = 2.9360  \n",
      "\n",
      "Epoch: 6  Training loss = 1.2389  Test loss = 2.9440  \n",
      "\n",
      "Epoch: 7  Training loss = 1.2351  Test loss = 2.9362  \n",
      "\n",
      "Epoch: 8  Training loss = 1.2313  Test loss = 2.9350  \n",
      "\n",
      "Epoch: 9  Training loss = 1.2275  Test loss = 2.9320  \n",
      "\n",
      "Epoch: 10  Training loss = 1.2235  Test loss = 2.9306  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZlYYF7uZWWH+CyFAf8/zo4SSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc1f8c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd0f0f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.93060485302 \n",
      "Fixed scheme MAE:  2.13118128306\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.2235  Test loss = 2.7768  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.2710  Test loss = 2.6647  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.3132  Test loss = 0.0602  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.3130  Test loss = 4.2251  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.1985  Test loss = 2.3071  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.2322  Test loss = 0.7222  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.1759  Test loss = 0.9044  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.1812  Test loss = 0.2922  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.9400  Test loss = 1.5682  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.9598  Test loss = 0.3376  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 0.9565  Test loss = 0.7405  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 0.9607  Test loss = 1.0117  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.9274  Test loss = 2.7262  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.9861  Test loss = 1.2952  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 0.9989  Test loss = 2.3215  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.0395  Test loss = 2.2028  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.9578  Test loss = 1.5443  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 0.9763  Test loss = 0.7414  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 0.9804  Test loss = 1.6484  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.0009  Test loss = 0.0909  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.8924  Test loss = 2.4254  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.9382  Test loss = 3.4243  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.0285  Test loss = 4.8238  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.1888  Test loss = 0.5289  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.8794  Test loss = 0.8835  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.8819  Test loss = 1.0866  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 0.8904  Test loss = 0.8523  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 0.8960  Test loss = 3.2455  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.8974  Test loss = 1.0114  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.9015  Test loss = 0.3165  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.8960  Test loss = 3.1507  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.9608  Test loss = 0.7356  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.7950  Test loss = 0.8738  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.8020  Test loss = 0.2955  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.7000  Test loss = 0.0115  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.6997  Test loss = 7.0558  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.1484  Test loss = 0.7327  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.1201  Test loss = 0.1478  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.1009  Test loss = 0.0125  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.1006  Test loss = 2.5813  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.6586  Test loss = 4.7875  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.8841  Test loss = 1.7569  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.9104  Test loss = 2.7846  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 0.9730  Test loss = 12.6148  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.6756  Test loss = 5.9868  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 1.8327  Test loss = 1.0871  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 1.8377  Test loss = 1.4748  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 1.8467  Test loss = 5.5335  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.4265  Test loss = 2.0669  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.4493  Test loss = 4.0058  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.5318  Test loss = 1.0617  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.5374  Test loss = 1.9801  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.3288  Test loss = 6.0351  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.5243  Test loss = 1.2266  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.5314  Test loss = 0.0274  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.5191  Test loss = 0.1686  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.2113  Test loss = 0.5809  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.2134  Test loss = 2.6403  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.2568  Test loss = 3.4378  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.3262  Test loss = 0.5577  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.1871  Test loss = 0.4024  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.1874  Test loss = 2.2307  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.2128  Test loss = 0.8521  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.2171  Test loss = 1.1686  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.1017  Test loss = 4.4306  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.2310  Test loss = 7.2403  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.5229  Test loss = 0.9245  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.5272  Test loss = 2.0626  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.1138  Test loss = 4.5074  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.2462  Test loss = 1.9219  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.2688  Test loss = 1.9542  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.2917  Test loss = 3.2319  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.0914  Test loss = 3.1341  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.1586  Test loss = 0.2387  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.1583  Test loss = 0.1635  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.1568  Test loss = 1.5360  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.0897  Test loss = 2.8937  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZl3KBWBm1qVcAGZmXcoFYGbWpf4PB+IDiiVXsrcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd4c9cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.97429183918 \n",
      "Updating scheme MAE:  2.11798563879\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
