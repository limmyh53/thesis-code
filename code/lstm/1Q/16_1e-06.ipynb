{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/16_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-6\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 16 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 16 \n",
      "Learning rate = 1e-06 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 1e-06\n",
      "Fold: 1  Epoch: 1  Training loss = 3.2689  Validation loss = 3.5168  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 3.2688  Validation loss = 3.5165  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 3.2687  Validation loss = 3.5162  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 3.2686  Validation loss = 3.5160  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 3.2685  Validation loss = 3.5158  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 3.2683  Validation loss = 3.5155  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 3.2682  Validation loss = 3.5152  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 3.2681  Validation loss = 3.5149  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 3.2680  Validation loss = 3.5147  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 3.2679  Validation loss = 3.5145  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 3.2678  Validation loss = 3.5143  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 3.2676  Validation loss = 3.5140  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 3.2675  Validation loss = 3.5137  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 3.2674  Validation loss = 3.5134  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 3.2672  Validation loss = 3.5132  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 3.2671  Validation loss = 3.5130  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 3.2670  Validation loss = 3.5126  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 3.2669  Validation loss = 3.5124  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 3.2667  Validation loss = 3.5121  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 3.2666  Validation loss = 3.5119  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 3.2665  Validation loss = 3.5116  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 3.2664  Validation loss = 3.5114  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 3.2663  Validation loss = 3.5111  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 3.2662  Validation loss = 3.5109  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 3.2660  Validation loss = 3.5106  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 3.2659  Validation loss = 3.5104  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 3.2658  Validation loss = 3.5102  \n",
      "\n",
      "Fold: 1  Epoch: 28  Training loss = 3.2657  Validation loss = 3.5099  \n",
      "\n",
      "Fold: 1  Epoch: 29  Training loss = 3.2656  Validation loss = 3.5097  \n",
      "\n",
      "Fold: 1  Epoch: 30  Training loss = 3.2655  Validation loss = 3.5095  \n",
      "\n",
      "Fold: 1  Epoch: 31  Training loss = 3.2654  Validation loss = 3.5092  \n",
      "\n",
      "Fold: 1  Epoch: 32  Training loss = 3.2653  Validation loss = 3.5089  \n",
      "\n",
      "Fold: 1  Epoch: 33  Training loss = 3.2652  Validation loss = 3.5087  \n",
      "\n",
      "Fold: 1  Epoch: 34  Training loss = 3.2650  Validation loss = 3.5084  \n",
      "\n",
      "Fold: 1  Epoch: 35  Training loss = 3.2649  Validation loss = 3.5082  \n",
      "\n",
      "Fold: 1  Epoch: 36  Training loss = 3.2648  Validation loss = 3.5080  \n",
      "\n",
      "Fold: 1  Epoch: 37  Training loss = 3.2647  Validation loss = 3.5078  \n",
      "\n",
      "Fold: 1  Epoch: 38  Training loss = 3.2646  Validation loss = 3.5074  \n",
      "\n",
      "Fold: 1  Epoch: 39  Training loss = 3.2645  Validation loss = 3.5073  \n",
      "\n",
      "Fold: 1  Epoch: 40  Training loss = 3.2643  Validation loss = 3.5070  \n",
      "\n",
      "Fold: 1  Epoch: 41  Training loss = 3.2642  Validation loss = 3.5066  \n",
      "\n",
      "Fold: 1  Epoch: 42  Training loss = 3.2641  Validation loss = 3.5064  \n",
      "\n",
      "Fold: 1  Epoch: 43  Training loss = 3.2639  Validation loss = 3.5061  \n",
      "\n",
      "Fold: 1  Epoch: 44  Training loss = 3.2638  Validation loss = 3.5058  \n",
      "\n",
      "Fold: 1  Epoch: 45  Training loss = 3.2637  Validation loss = 3.5055  \n",
      "\n",
      "Fold: 1  Epoch: 46  Training loss = 3.2635  Validation loss = 3.5052  \n",
      "\n",
      "Fold: 1  Epoch: 47  Training loss = 3.2634  Validation loss = 3.5049  \n",
      "\n",
      "Fold: 1  Epoch: 48  Training loss = 3.2633  Validation loss = 3.5047  \n",
      "\n",
      "Fold: 1  Epoch: 49  Training loss = 3.2631  Validation loss = 3.5044  \n",
      "\n",
      "Fold: 1  Epoch: 50  Training loss = 3.2630  Validation loss = 3.5041  \n",
      "\n",
      "Fold: 1  Epoch: 51  Training loss = 3.2629  Validation loss = 3.5038  \n",
      "\n",
      "Fold: 1  Epoch: 52  Training loss = 3.2628  Validation loss = 3.5036  \n",
      "\n",
      "Fold: 1  Epoch: 53  Training loss = 3.2627  Validation loss = 3.5033  \n",
      "\n",
      "Fold: 1  Epoch: 54  Training loss = 3.2626  Validation loss = 3.5032  \n",
      "\n",
      "Fold: 1  Epoch: 55  Training loss = 3.2625  Validation loss = 3.5029  \n",
      "\n",
      "Fold: 1  Epoch: 56  Training loss = 3.2624  Validation loss = 3.5027  \n",
      "\n",
      "Fold: 1  Epoch: 57  Training loss = 3.2623  Validation loss = 3.5024  \n",
      "\n",
      "Fold: 1  Epoch: 58  Training loss = 3.2621  Validation loss = 3.5022  \n",
      "\n",
      "Fold: 1  Epoch: 59  Training loss = 3.2620  Validation loss = 3.5019  \n",
      "\n",
      "Fold: 1  Epoch: 60  Training loss = 3.2619  Validation loss = 3.5017  \n",
      "\n",
      "Fold: 1  Epoch: 61  Training loss = 3.2618  Validation loss = 3.5015  \n",
      "\n",
      "Fold: 1  Epoch: 62  Training loss = 3.2617  Validation loss = 3.5013  \n",
      "\n",
      "Fold: 1  Epoch: 63  Training loss = 3.2616  Validation loss = 3.5010  \n",
      "\n",
      "Fold: 1  Epoch: 64  Training loss = 3.2615  Validation loss = 3.5008  \n",
      "\n",
      "Fold: 1  Epoch: 65  Training loss = 3.2614  Validation loss = 3.5006  \n",
      "\n",
      "Fold: 1  Epoch: 66  Training loss = 3.2613  Validation loss = 3.5003  \n",
      "\n",
      "Fold: 1  Epoch: 67  Training loss = 3.2611  Validation loss = 3.5000  \n",
      "\n",
      "Fold: 1  Epoch: 68  Training loss = 3.2610  Validation loss = 3.4998  \n",
      "\n",
      "Fold: 1  Epoch: 69  Training loss = 3.2609  Validation loss = 3.4996  \n",
      "\n",
      "Fold: 1  Epoch: 70  Training loss = 3.2608  Validation loss = 3.4993  \n",
      "\n",
      "Fold: 1  Epoch: 71  Training loss = 3.2607  Validation loss = 3.4990  \n",
      "\n",
      "Fold: 1  Epoch: 72  Training loss = 3.2606  Validation loss = 3.4989  \n",
      "\n",
      "Fold: 1  Epoch: 73  Training loss = 3.2605  Validation loss = 3.4986  \n",
      "\n",
      "Fold: 1  Epoch: 74  Training loss = 3.2603  Validation loss = 3.4983  \n",
      "\n",
      "Fold: 1  Epoch: 75  Training loss = 3.2602  Validation loss = 3.4980  \n",
      "\n",
      "Fold: 1  Epoch: 76  Training loss = 3.2600  Validation loss = 3.4977  \n",
      "\n",
      "Fold: 1  Epoch: 77  Training loss = 3.2599  Validation loss = 3.4974  \n",
      "\n",
      "Fold: 1  Epoch: 78  Training loss = 3.2598  Validation loss = 3.4971  \n",
      "\n",
      "Fold: 1  Epoch: 79  Training loss = 3.2597  Validation loss = 3.4968  \n",
      "\n",
      "Fold: 1  Epoch: 80  Training loss = 3.2595  Validation loss = 3.4965  \n",
      "\n",
      "Fold: 1  Epoch: 81  Training loss = 3.2594  Validation loss = 3.4963  \n",
      "\n",
      "Fold: 1  Epoch: 82  Training loss = 3.2593  Validation loss = 3.4961  \n",
      "\n",
      "Fold: 1  Epoch: 83  Training loss = 3.2592  Validation loss = 3.4958  \n",
      "\n",
      "Fold: 1  Epoch: 84  Training loss = 3.2591  Validation loss = 3.4956  \n",
      "\n",
      "Fold: 1  Epoch: 85  Training loss = 3.2590  Validation loss = 3.4954  \n",
      "\n",
      "Fold: 1  Epoch: 86  Training loss = 3.2589  Validation loss = 3.4951  \n",
      "\n",
      "Fold: 1  Epoch: 87  Training loss = 3.2588  Validation loss = 3.4949  \n",
      "\n",
      "Fold: 1  Epoch: 88  Training loss = 3.2586  Validation loss = 3.4947  \n",
      "\n",
      "Fold: 1  Epoch: 89  Training loss = 3.2585  Validation loss = 3.4944  \n",
      "\n",
      "Fold: 1  Epoch: 90  Training loss = 3.2584  Validation loss = 3.4941  \n",
      "\n",
      "Fold: 1  Epoch: 91  Training loss = 3.2583  Validation loss = 3.4939  \n",
      "\n",
      "Fold: 1  Epoch: 92  Training loss = 3.2582  Validation loss = 3.4937  \n",
      "\n",
      "Fold: 1  Epoch: 93  Training loss = 3.2581  Validation loss = 3.4934  \n",
      "\n",
      "Fold: 1  Epoch: 94  Training loss = 3.2579  Validation loss = 3.4932  \n",
      "\n",
      "Fold: 1  Epoch: 95  Training loss = 3.2578  Validation loss = 3.4929  \n",
      "\n",
      "Fold: 1  Epoch: 96  Training loss = 3.2577  Validation loss = 3.4926  \n",
      "\n",
      "Fold: 1  Epoch: 97  Training loss = 3.2576  Validation loss = 3.4924  \n",
      "\n",
      "Fold: 1  Epoch: 98  Training loss = 3.2575  Validation loss = 3.4921  \n",
      "\n",
      "Fold: 1  Epoch: 99  Training loss = 3.2573  Validation loss = 3.4919  \n",
      "\n",
      "Fold: 1  Epoch: 100  Training loss = 3.2573  Validation loss = 3.4917  \n",
      "\n",
      "Fold: 1  Epoch: 101  Training loss = 3.2571  Validation loss = 3.4913  \n",
      "\n",
      "Fold: 1  Epoch: 102  Training loss = 3.2570  Validation loss = 3.4911  \n",
      "\n",
      "Fold: 1  Epoch: 103  Training loss = 3.2568  Validation loss = 3.4908  \n",
      "\n",
      "Fold: 1  Epoch: 104  Training loss = 3.2567  Validation loss = 3.4905  \n",
      "\n",
      "Fold: 1  Epoch: 105  Training loss = 3.2566  Validation loss = 3.4902  \n",
      "\n",
      "Fold: 1  Epoch: 106  Training loss = 3.2565  Validation loss = 3.4900  \n",
      "\n",
      "Fold: 1  Epoch: 107  Training loss = 3.2564  Validation loss = 3.4899  \n",
      "\n",
      "Fold: 1  Epoch: 108  Training loss = 3.2563  Validation loss = 3.4896  \n",
      "\n",
      "Fold: 1  Epoch: 109  Training loss = 3.2562  Validation loss = 3.4894  \n",
      "\n",
      "Fold: 1  Epoch: 110  Training loss = 3.2560  Validation loss = 3.4891  \n",
      "\n",
      "Fold: 1  Epoch: 111  Training loss = 3.2559  Validation loss = 3.4888  \n",
      "\n",
      "Fold: 1  Epoch: 112  Training loss = 3.2558  Validation loss = 3.4886  \n",
      "\n",
      "Fold: 1  Epoch: 113  Training loss = 3.2557  Validation loss = 3.4884  \n",
      "\n",
      "Fold: 1  Epoch: 114  Training loss = 3.2556  Validation loss = 3.4881  \n",
      "\n",
      "Fold: 1  Epoch: 115  Training loss = 3.2555  Validation loss = 3.4879  \n",
      "\n",
      "Fold: 1  Epoch: 116  Training loss = 3.2554  Validation loss = 3.4877  \n",
      "\n",
      "Fold: 1  Epoch: 117  Training loss = 3.2553  Validation loss = 3.4875  \n",
      "\n",
      "Fold: 1  Epoch: 118  Training loss = 3.2552  Validation loss = 3.4872  \n",
      "\n",
      "Fold: 1  Epoch: 119  Training loss = 3.2551  Validation loss = 3.4871  \n",
      "\n",
      "Fold: 1  Epoch: 120  Training loss = 3.2550  Validation loss = 3.4869  \n",
      "\n",
      "Fold: 1  Epoch: 121  Training loss = 3.2549  Validation loss = 3.4866  \n",
      "\n",
      "Fold: 1  Epoch: 122  Training loss = 3.2548  Validation loss = 3.4863  \n",
      "\n",
      "Fold: 1  Epoch: 123  Training loss = 3.2547  Validation loss = 3.4861  \n",
      "\n",
      "Fold: 1  Epoch: 124  Training loss = 3.2546  Validation loss = 3.4859  \n",
      "\n",
      "Fold: 1  Epoch: 125  Training loss = 3.2545  Validation loss = 3.4857  \n",
      "\n",
      "Fold: 1  Epoch: 126  Training loss = 3.2543  Validation loss = 3.4854  \n",
      "\n",
      "Fold: 1  Epoch: 127  Training loss = 3.2543  Validation loss = 3.4852  \n",
      "\n",
      "Fold: 1  Epoch: 128  Training loss = 3.2541  Validation loss = 3.4850  \n",
      "\n",
      "Fold: 1  Epoch: 129  Training loss = 3.2540  Validation loss = 3.4847  \n",
      "\n",
      "Fold: 1  Epoch: 130  Training loss = 3.2539  Validation loss = 3.4845  \n",
      "\n",
      "Fold: 1  Epoch: 131  Training loss = 3.2538  Validation loss = 3.4843  \n",
      "\n",
      "Fold: 1  Epoch: 132  Training loss = 3.2537  Validation loss = 3.4841  \n",
      "\n",
      "Fold: 1  Epoch: 133  Training loss = 3.2536  Validation loss = 3.4839  \n",
      "\n",
      "Fold: 1  Epoch: 134  Training loss = 3.2535  Validation loss = 3.4837  \n",
      "\n",
      "Fold: 1  Epoch: 135  Training loss = 3.2534  Validation loss = 3.4834  \n",
      "\n",
      "Fold: 1  Epoch: 136  Training loss = 3.2533  Validation loss = 3.4831  \n",
      "\n",
      "Fold: 1  Epoch: 137  Training loss = 3.2532  Validation loss = 3.4829  \n",
      "\n",
      "Fold: 1  Epoch: 138  Training loss = 3.2531  Validation loss = 3.4827  \n",
      "\n",
      "Fold: 1  Epoch: 139  Training loss = 3.2530  Validation loss = 3.4825  \n",
      "\n",
      "Fold: 1  Epoch: 140  Training loss = 3.2529  Validation loss = 3.4823  \n",
      "\n",
      "Fold: 1  Epoch: 141  Training loss = 3.2528  Validation loss = 3.4820  \n",
      "\n",
      "Fold: 1  Epoch: 142  Training loss = 3.2526  Validation loss = 3.4817  \n",
      "\n",
      "Fold: 1  Epoch: 143  Training loss = 3.2525  Validation loss = 3.4815  \n",
      "\n",
      "Fold: 1  Epoch: 144  Training loss = 3.2525  Validation loss = 3.4813  \n",
      "\n",
      "Fold: 1  Epoch: 145  Training loss = 3.2524  Validation loss = 3.4812  \n",
      "\n",
      "Fold: 1  Epoch: 146  Training loss = 3.2523  Validation loss = 3.4809  \n",
      "\n",
      "Fold: 1  Epoch: 147  Training loss = 3.2522  Validation loss = 3.4807  \n",
      "\n",
      "Fold: 1  Epoch: 148  Training loss = 3.2520  Validation loss = 3.4804  \n",
      "\n",
      "Fold: 1  Epoch: 149  Training loss = 3.2519  Validation loss = 3.4802  \n",
      "\n",
      "Fold: 1  Epoch: 150  Training loss = 3.2518  Validation loss = 3.4800  \n",
      "\n",
      "Fold: 1  Epoch: 151  Training loss = 3.2517  Validation loss = 3.4797  \n",
      "\n",
      "Fold: 1  Epoch: 152  Training loss = 3.2516  Validation loss = 3.4795  \n",
      "\n",
      "Fold: 1  Epoch: 153  Training loss = 3.2515  Validation loss = 3.4793  \n",
      "\n",
      "Fold: 1  Epoch: 154  Training loss = 3.2514  Validation loss = 3.4790  \n",
      "\n",
      "Fold: 1  Epoch: 155  Training loss = 3.2513  Validation loss = 3.4788  \n",
      "\n",
      "Fold: 1  Epoch: 156  Training loss = 3.2511  Validation loss = 3.4785  \n",
      "\n",
      "Fold: 1  Epoch: 157  Training loss = 3.2510  Validation loss = 3.4782  \n",
      "\n",
      "Fold: 1  Epoch: 158  Training loss = 3.2509  Validation loss = 3.4780  \n",
      "\n",
      "Fold: 1  Epoch: 159  Training loss = 3.2508  Validation loss = 3.4778  \n",
      "\n",
      "Fold: 1  Epoch: 160  Training loss = 3.2507  Validation loss = 3.4775  \n",
      "\n",
      "Fold: 1  Epoch: 161  Training loss = 3.2505  Validation loss = 3.4772  \n",
      "\n",
      "Fold: 1  Epoch: 162  Training loss = 3.2504  Validation loss = 3.4770  \n",
      "\n",
      "Fold: 1  Epoch: 163  Training loss = 3.2503  Validation loss = 3.4768  \n",
      "\n",
      "Fold: 1  Epoch: 164  Training loss = 3.2502  Validation loss = 3.4766  \n",
      "\n",
      "Fold: 1  Epoch: 165  Training loss = 3.2501  Validation loss = 3.4763  \n",
      "\n",
      "Fold: 1  Epoch: 166  Training loss = 3.2500  Validation loss = 3.4761  \n",
      "\n",
      "Fold: 1  Epoch: 167  Training loss = 3.2499  Validation loss = 3.4758  \n",
      "\n",
      "Fold: 1  Epoch: 168  Training loss = 3.2498  Validation loss = 3.4756  \n",
      "\n",
      "Fold: 1  Epoch: 169  Training loss = 3.2496  Validation loss = 3.4752  \n",
      "\n",
      "Fold: 1  Epoch: 170  Training loss = 3.2495  Validation loss = 3.4750  \n",
      "\n",
      "Fold: 1  Epoch: 171  Training loss = 3.2494  Validation loss = 3.4747  \n",
      "\n",
      "Fold: 1  Epoch: 172  Training loss = 3.2493  Validation loss = 3.4744  \n",
      "\n",
      "Fold: 1  Epoch: 173  Training loss = 3.2491  Validation loss = 3.4742  \n",
      "\n",
      "Fold: 1  Epoch: 174  Training loss = 3.2490  Validation loss = 3.4740  \n",
      "\n",
      "Fold: 1  Epoch: 175  Training loss = 3.2489  Validation loss = 3.4737  \n",
      "\n",
      "Fold: 1  Epoch: 176  Training loss = 3.2488  Validation loss = 3.4734  \n",
      "\n",
      "Fold: 1  Epoch: 177  Training loss = 3.2487  Validation loss = 3.4732  \n",
      "\n",
      "Fold: 1  Epoch: 178  Training loss = 3.2486  Validation loss = 3.4730  \n",
      "\n",
      "Fold: 1  Epoch: 179  Training loss = 3.2485  Validation loss = 3.4727  \n",
      "\n",
      "Fold: 1  Epoch: 180  Training loss = 3.2483  Validation loss = 3.4724  \n",
      "\n",
      "Fold: 1  Epoch: 181  Training loss = 3.2482  Validation loss = 3.4722  \n",
      "\n",
      "Fold: 1  Epoch: 182  Training loss = 3.2481  Validation loss = 3.4720  \n",
      "\n",
      "Fold: 1  Epoch: 183  Training loss = 3.2480  Validation loss = 3.4717  \n",
      "\n",
      "Fold: 1  Epoch: 184  Training loss = 3.2479  Validation loss = 3.4715  \n",
      "\n",
      "Fold: 1  Epoch: 185  Training loss = 3.2478  Validation loss = 3.4712  \n",
      "\n",
      "Fold: 1  Epoch: 186  Training loss = 3.2477  Validation loss = 3.4709  \n",
      "\n",
      "Fold: 1  Epoch: 187  Training loss = 3.2475  Validation loss = 3.4706  \n",
      "\n",
      "Fold: 1  Epoch: 188  Training loss = 3.2474  Validation loss = 3.4704  \n",
      "\n",
      "Fold: 1  Epoch: 189  Training loss = 3.2473  Validation loss = 3.4702  \n",
      "\n",
      "Fold: 1  Epoch: 190  Training loss = 3.2472  Validation loss = 3.4699  \n",
      "\n",
      "Fold: 1  Epoch: 191  Training loss = 3.2471  Validation loss = 3.4696  \n",
      "\n",
      "Fold: 1  Epoch: 192  Training loss = 3.2470  Validation loss = 3.4695  \n",
      "\n",
      "Fold: 1  Epoch: 193  Training loss = 3.2469  Validation loss = 3.4692  \n",
      "\n",
      "Fold: 1  Epoch: 194  Training loss = 3.2468  Validation loss = 3.4691  \n",
      "\n",
      "Fold: 1  Epoch: 195  Training loss = 3.2467  Validation loss = 3.4689  \n",
      "\n",
      "Fold: 1  Epoch: 196  Training loss = 3.2466  Validation loss = 3.4686  \n",
      "\n",
      "Fold: 1  Epoch: 197  Training loss = 3.2465  Validation loss = 3.4684  \n",
      "\n",
      "Fold: 1  Epoch: 198  Training loss = 3.2464  Validation loss = 3.4682  \n",
      "\n",
      "Fold: 1  Epoch: 199  Training loss = 3.2463  Validation loss = 3.4680  \n",
      "\n",
      "Fold: 1  Epoch: 200  Training loss = 3.2462  Validation loss = 3.4677  \n",
      "\n",
      "Fold: 1  Epoch: 201  Training loss = 3.2460  Validation loss = 3.4674  \n",
      "\n",
      "Fold: 1  Epoch: 202  Training loss = 3.2459  Validation loss = 3.4672  \n",
      "\n",
      "Fold: 1  Epoch: 203  Training loss = 3.2458  Validation loss = 3.4670  \n",
      "\n",
      "Fold: 1  Epoch: 204  Training loss = 3.2457  Validation loss = 3.4668  \n",
      "\n",
      "Fold: 1  Epoch: 205  Training loss = 3.2456  Validation loss = 3.4665  \n",
      "\n",
      "Fold: 1  Epoch: 206  Training loss = 3.2455  Validation loss = 3.4662  \n",
      "\n",
      "Fold: 1  Epoch: 207  Training loss = 3.2454  Validation loss = 3.4661  \n",
      "\n",
      "Fold: 1  Epoch: 208  Training loss = 3.2453  Validation loss = 3.4658  \n",
      "\n",
      "Fold: 1  Epoch: 209  Training loss = 3.2452  Validation loss = 3.4656  \n",
      "\n",
      "Fold: 1  Epoch: 210  Training loss = 3.2451  Validation loss = 3.4653  \n",
      "\n",
      "Fold: 1  Epoch: 211  Training loss = 3.2450  Validation loss = 3.4652  \n",
      "\n",
      "Fold: 1  Epoch: 212  Training loss = 3.2449  Validation loss = 3.4650  \n",
      "\n",
      "Fold: 1  Epoch: 213  Training loss = 3.2448  Validation loss = 3.4647  \n",
      "\n",
      "Fold: 1  Epoch: 214  Training loss = 3.2447  Validation loss = 3.4644  \n",
      "\n",
      "Fold: 1  Epoch: 215  Training loss = 3.2445  Validation loss = 3.4641  \n",
      "\n",
      "Fold: 1  Epoch: 216  Training loss = 3.2444  Validation loss = 3.4639  \n",
      "\n",
      "Fold: 1  Epoch: 217  Training loss = 3.2443  Validation loss = 3.4637  \n",
      "\n",
      "Fold: 1  Epoch: 218  Training loss = 3.2442  Validation loss = 3.4634  \n",
      "\n",
      "Fold: 1  Epoch: 219  Training loss = 3.2441  Validation loss = 3.4632  \n",
      "\n",
      "Fold: 1  Epoch: 220  Training loss = 3.2440  Validation loss = 3.4630  \n",
      "\n",
      "Fold: 1  Epoch: 221  Training loss = 3.2439  Validation loss = 3.4627  \n",
      "\n",
      "Fold: 1  Epoch: 222  Training loss = 3.2438  Validation loss = 3.4625  \n",
      "\n",
      "Fold: 1  Epoch: 223  Training loss = 3.2436  Validation loss = 3.4622  \n",
      "\n",
      "Fold: 1  Epoch: 224  Training loss = 3.2435  Validation loss = 3.4619  \n",
      "\n",
      "Fold: 1  Epoch: 225  Training loss = 3.2434  Validation loss = 3.4617  \n",
      "\n",
      "Fold: 1  Epoch: 226  Training loss = 3.2433  Validation loss = 3.4615  \n",
      "\n",
      "Fold: 1  Epoch: 227  Training loss = 3.2432  Validation loss = 3.4613  \n",
      "\n",
      "Fold: 1  Epoch: 228  Training loss = 3.2431  Validation loss = 3.4610  \n",
      "\n",
      "Fold: 1  Epoch: 229  Training loss = 3.2430  Validation loss = 3.4607  \n",
      "\n",
      "Fold: 1  Epoch: 230  Training loss = 3.2429  Validation loss = 3.4605  \n",
      "\n",
      "Fold: 1  Epoch: 231  Training loss = 3.2428  Validation loss = 3.4603  \n",
      "\n",
      "Fold: 1  Epoch: 232  Training loss = 3.2427  Validation loss = 3.4601  \n",
      "\n",
      "Fold: 1  Epoch: 233  Training loss = 3.2425  Validation loss = 3.4597  \n",
      "\n",
      "Fold: 1  Epoch: 234  Training loss = 3.2424  Validation loss = 3.4595  \n",
      "\n",
      "Fold: 1  Epoch: 235  Training loss = 3.2423  Validation loss = 3.4593  \n",
      "\n",
      "Fold: 1  Epoch: 236  Training loss = 3.2422  Validation loss = 3.4591  \n",
      "\n",
      "Fold: 1  Epoch: 237  Training loss = 3.2421  Validation loss = 3.4588  \n",
      "\n",
      "Fold: 1  Epoch: 238  Training loss = 3.2420  Validation loss = 3.4585  \n",
      "\n",
      "Fold: 1  Epoch: 239  Training loss = 3.2419  Validation loss = 3.4583  \n",
      "\n",
      "Fold: 1  Epoch: 240  Training loss = 3.2417  Validation loss = 3.4580  \n",
      "\n",
      "Fold: 1  Epoch: 241  Training loss = 3.2416  Validation loss = 3.4578  \n",
      "\n",
      "Fold: 1  Epoch: 242  Training loss = 3.2415  Validation loss = 3.4576  \n",
      "\n",
      "Fold: 1  Epoch: 243  Training loss = 3.2414  Validation loss = 3.4573  \n",
      "\n",
      "Fold: 1  Epoch: 244  Training loss = 3.2413  Validation loss = 3.4570  \n",
      "\n",
      "Fold: 1  Epoch: 245  Training loss = 3.2411  Validation loss = 3.4567  \n",
      "\n",
      "Fold: 1  Epoch: 246  Training loss = 3.2411  Validation loss = 3.4565  \n",
      "\n",
      "Fold: 1  Epoch: 247  Training loss = 3.2409  Validation loss = 3.4563  \n",
      "\n",
      "Fold: 1  Epoch: 248  Training loss = 3.2408  Validation loss = 3.4560  \n",
      "\n",
      "Fold: 1  Epoch: 249  Training loss = 3.2407  Validation loss = 3.4558  \n",
      "\n",
      "Fold: 1  Epoch: 250  Training loss = 3.2406  Validation loss = 3.4555  \n",
      "\n",
      "Fold: 1  Epoch: 251  Training loss = 3.2405  Validation loss = 3.4553  \n",
      "\n",
      "Fold: 1  Epoch: 252  Training loss = 3.2404  Validation loss = 3.4550  \n",
      "\n",
      "Fold: 1  Epoch: 253  Training loss = 3.2403  Validation loss = 3.4548  \n",
      "\n",
      "Fold: 1  Epoch: 254  Training loss = 3.2402  Validation loss = 3.4546  \n",
      "\n",
      "Fold: 1  Epoch: 255  Training loss = 3.2401  Validation loss = 3.4544  \n",
      "\n",
      "Fold: 1  Epoch: 256  Training loss = 3.2399  Validation loss = 3.4541  \n",
      "\n",
      "Fold: 1  Epoch: 257  Training loss = 3.2398  Validation loss = 3.4537  \n",
      "\n",
      "Fold: 1  Epoch: 258  Training loss = 3.2397  Validation loss = 3.4535  \n",
      "\n",
      "Fold: 1  Epoch: 259  Training loss = 3.2396  Validation loss = 3.4534  \n",
      "\n",
      "Fold: 1  Epoch: 260  Training loss = 3.2395  Validation loss = 3.4532  \n",
      "\n",
      "Fold: 1  Epoch: 261  Training loss = 3.2394  Validation loss = 3.4530  \n",
      "\n",
      "Fold: 1  Epoch: 262  Training loss = 3.2393  Validation loss = 3.4527  \n",
      "\n",
      "Fold: 1  Epoch: 263  Training loss = 3.2392  Validation loss = 3.4525  \n",
      "\n",
      "Fold: 1  Epoch: 264  Training loss = 3.2391  Validation loss = 3.4523  \n",
      "\n",
      "Fold: 1  Epoch: 265  Training loss = 3.2390  Validation loss = 3.4520  \n",
      "\n",
      "Fold: 1  Epoch: 266  Training loss = 3.2389  Validation loss = 3.4519  \n",
      "\n",
      "Fold: 1  Epoch: 267  Training loss = 3.2388  Validation loss = 3.4516  \n",
      "\n",
      "Fold: 1  Epoch: 268  Training loss = 3.2386  Validation loss = 3.4513  \n",
      "\n",
      "Fold: 1  Epoch: 269  Training loss = 3.2385  Validation loss = 3.4511  \n",
      "\n",
      "Fold: 1  Epoch: 270  Training loss = 3.2384  Validation loss = 3.4508  \n",
      "\n",
      "Fold: 1  Epoch: 271  Training loss = 3.2383  Validation loss = 3.4505  \n",
      "\n",
      "Fold: 1  Epoch: 272  Training loss = 3.2382  Validation loss = 3.4503  \n",
      "\n",
      "Fold: 1  Epoch: 273  Training loss = 3.2381  Validation loss = 3.4501  \n",
      "\n",
      "Fold: 1  Epoch: 274  Training loss = 3.2380  Validation loss = 3.4498  \n",
      "\n",
      "Fold: 1  Epoch: 275  Training loss = 3.2378  Validation loss = 3.4496  \n",
      "\n",
      "Fold: 1  Epoch: 276  Training loss = 3.2378  Validation loss = 3.4493  \n",
      "\n",
      "Fold: 1  Epoch: 277  Training loss = 3.2376  Validation loss = 3.4491  \n",
      "\n",
      "Fold: 1  Epoch: 278  Training loss = 3.2375  Validation loss = 3.4487  \n",
      "\n",
      "Fold: 1  Epoch: 279  Training loss = 3.2374  Validation loss = 3.4485  \n",
      "\n",
      "Fold: 1  Epoch: 280  Training loss = 3.2373  Validation loss = 3.4483  \n",
      "\n",
      "Fold: 1  Epoch: 281  Training loss = 3.2372  Validation loss = 3.4480  \n",
      "\n",
      "Fold: 1  Epoch: 282  Training loss = 3.2371  Validation loss = 3.4478  \n",
      "\n",
      "Fold: 1  Epoch: 283  Training loss = 3.2370  Validation loss = 3.4476  \n",
      "\n",
      "Fold: 1  Epoch: 284  Training loss = 3.2369  Validation loss = 3.4474  \n",
      "\n",
      "Fold: 1  Epoch: 285  Training loss = 3.2368  Validation loss = 3.4472  \n",
      "\n",
      "Fold: 1  Epoch: 286  Training loss = 3.2367  Validation loss = 3.4469  \n",
      "\n",
      "Fold: 1  Epoch: 287  Training loss = 3.2365  Validation loss = 3.4467  \n",
      "\n",
      "Fold: 1  Epoch: 288  Training loss = 3.2364  Validation loss = 3.4464  \n",
      "\n",
      "Fold: 1  Epoch: 289  Training loss = 3.2363  Validation loss = 3.4461  \n",
      "\n",
      "Fold: 1  Epoch: 290  Training loss = 3.2362  Validation loss = 3.4460  \n",
      "\n",
      "Fold: 1  Epoch: 291  Training loss = 3.2361  Validation loss = 3.4457  \n",
      "\n",
      "Fold: 1  Epoch: 292  Training loss = 3.2360  Validation loss = 3.4455  \n",
      "\n",
      "Fold: 1  Epoch: 293  Training loss = 3.2359  Validation loss = 3.4453  \n",
      "\n",
      "Fold: 1  Epoch: 294  Training loss = 3.2358  Validation loss = 3.4451  \n",
      "\n",
      "Fold: 1  Epoch: 295  Training loss = 3.2357  Validation loss = 3.4448  \n",
      "\n",
      "Fold: 1  Epoch: 296  Training loss = 3.2355  Validation loss = 3.4445  \n",
      "\n",
      "Fold: 1  Epoch: 297  Training loss = 3.2354  Validation loss = 3.4442  \n",
      "\n",
      "Fold: 1  Epoch: 298  Training loss = 3.2353  Validation loss = 3.4440  \n",
      "\n",
      "Fold: 1  Epoch: 299  Training loss = 3.2352  Validation loss = 3.4438  \n",
      "\n",
      "Fold: 1  Epoch: 300  Training loss = 3.2351  Validation loss = 3.4436  \n",
      "\n",
      "Fold: 1  Epoch: 301  Training loss = 3.2350  Validation loss = 3.4434  \n",
      "\n",
      "Fold: 1  Epoch: 302  Training loss = 3.2349  Validation loss = 3.4432  \n",
      "\n",
      "Fold: 1  Epoch: 303  Training loss = 3.2349  Validation loss = 3.4430  \n",
      "\n",
      "Fold: 1  Epoch: 304  Training loss = 3.2348  Validation loss = 3.4428  \n",
      "\n",
      "Fold: 1  Epoch: 305  Training loss = 3.2347  Validation loss = 3.4426  \n",
      "\n",
      "Fold: 1  Epoch: 306  Training loss = 3.2346  Validation loss = 3.4423  \n",
      "\n",
      "Fold: 1  Epoch: 307  Training loss = 3.2345  Validation loss = 3.4421  \n",
      "\n",
      "Fold: 1  Epoch: 308  Training loss = 3.2344  Validation loss = 3.4419  \n",
      "\n",
      "Fold: 1  Epoch: 309  Training loss = 3.2343  Validation loss = 3.4417  \n",
      "\n",
      "Fold: 1  Epoch: 310  Training loss = 3.2341  Validation loss = 3.4414  \n",
      "\n",
      "Fold: 1  Epoch: 311  Training loss = 3.2340  Validation loss = 3.4412  \n",
      "\n",
      "Fold: 1  Epoch: 312  Training loss = 3.2339  Validation loss = 3.4410  \n",
      "\n",
      "Fold: 1  Epoch: 313  Training loss = 3.2338  Validation loss = 3.4408  \n",
      "\n",
      "Fold: 1  Epoch: 314  Training loss = 3.2337  Validation loss = 3.4405  \n",
      "\n",
      "Fold: 1  Epoch: 315  Training loss = 3.2336  Validation loss = 3.4402  \n",
      "\n",
      "Fold: 1  Epoch: 316  Training loss = 3.2335  Validation loss = 3.4400  \n",
      "\n",
      "Fold: 1  Epoch: 317  Training loss = 3.2334  Validation loss = 3.4398  \n",
      "\n",
      "Fold: 1  Epoch: 318  Training loss = 3.2333  Validation loss = 3.4395  \n",
      "\n",
      "Fold: 1  Epoch: 319  Training loss = 3.2332  Validation loss = 3.4393  \n",
      "\n",
      "Fold: 1  Epoch: 320  Training loss = 3.2331  Validation loss = 3.4391  \n",
      "\n",
      "Fold: 1  Epoch: 321  Training loss = 3.2330  Validation loss = 3.4389  \n",
      "\n",
      "Fold: 1  Epoch: 322  Training loss = 3.2329  Validation loss = 3.4387  \n",
      "\n",
      "Fold: 1  Epoch: 323  Training loss = 3.2328  Validation loss = 3.4384  \n",
      "\n",
      "Fold: 1  Epoch: 324  Training loss = 3.2327  Validation loss = 3.4382  \n",
      "\n",
      "Fold: 1  Epoch: 325  Training loss = 3.2326  Validation loss = 3.4380  \n",
      "\n",
      "Fold: 1  Epoch: 326  Training loss = 3.2324  Validation loss = 3.4377  \n",
      "\n",
      "Fold: 1  Epoch: 327  Training loss = 3.2323  Validation loss = 3.4374  \n",
      "\n",
      "Fold: 1  Epoch: 328  Training loss = 3.2322  Validation loss = 3.4372  \n",
      "\n",
      "Fold: 1  Epoch: 329  Training loss = 3.2321  Validation loss = 3.4369  \n",
      "\n",
      "Fold: 1  Epoch: 330  Training loss = 3.2320  Validation loss = 3.4368  \n",
      "\n",
      "Fold: 1  Epoch: 331  Training loss = 3.2319  Validation loss = 3.4366  \n",
      "\n",
      "Fold: 1  Epoch: 332  Training loss = 3.2318  Validation loss = 3.4364  \n",
      "\n",
      "Fold: 1  Epoch: 333  Training loss = 3.2317  Validation loss = 3.4361  \n",
      "\n",
      "Fold: 1  Epoch: 334  Training loss = 3.2316  Validation loss = 3.4358  \n",
      "\n",
      "Fold: 1  Epoch: 335  Training loss = 3.2314  Validation loss = 3.4355  \n",
      "\n",
      "Fold: 1  Epoch: 336  Training loss = 3.2313  Validation loss = 3.4353  \n",
      "\n",
      "Fold: 1  Epoch: 337  Training loss = 3.2312  Validation loss = 3.4351  \n",
      "\n",
      "Fold: 1  Epoch: 338  Training loss = 3.2311  Validation loss = 3.4348  \n",
      "\n",
      "Fold: 1  Epoch: 339  Training loss = 3.2310  Validation loss = 3.4347  \n",
      "\n",
      "Fold: 1  Epoch: 340  Training loss = 3.2310  Validation loss = 3.4345  \n",
      "\n",
      "Fold: 1  Epoch: 341  Training loss = 3.2309  Validation loss = 3.4343  \n",
      "\n",
      "Fold: 1  Epoch: 342  Training loss = 3.2308  Validation loss = 3.4340  \n",
      "\n",
      "Fold: 1  Epoch: 343  Training loss = 3.2306  Validation loss = 3.4338  \n",
      "\n",
      "Fold: 1  Epoch: 344  Training loss = 3.2306  Validation loss = 3.4336  \n",
      "\n",
      "Fold: 1  Epoch: 345  Training loss = 3.2305  Validation loss = 3.4334  \n",
      "\n",
      "Fold: 1  Epoch: 346  Training loss = 3.2304  Validation loss = 3.4332  \n",
      "\n",
      "Fold: 1  Epoch: 347  Training loss = 3.2303  Validation loss = 3.4330  \n",
      "\n",
      "Fold: 1  Epoch: 348  Training loss = 3.2302  Validation loss = 3.4328  \n",
      "\n",
      "Fold: 1  Epoch: 349  Training loss = 3.2301  Validation loss = 3.4326  \n",
      "\n",
      "Fold: 1  Epoch: 350  Training loss = 3.2300  Validation loss = 3.4324  \n",
      "\n",
      "Fold: 1  Epoch: 351  Training loss = 3.2299  Validation loss = 3.4322  \n",
      "\n",
      "Fold: 1  Epoch: 352  Training loss = 3.2298  Validation loss = 3.4320  \n",
      "\n",
      "Fold: 1  Epoch: 353  Training loss = 3.2297  Validation loss = 3.4318  \n",
      "\n",
      "Fold: 1  Epoch: 354  Training loss = 3.2297  Validation loss = 3.4316  \n",
      "\n",
      "Fold: 1  Epoch: 355  Training loss = 3.2296  Validation loss = 3.4314  \n",
      "\n",
      "Fold: 1  Epoch: 356  Training loss = 3.2295  Validation loss = 3.4313  \n",
      "\n",
      "Fold: 1  Epoch: 357  Training loss = 3.2294  Validation loss = 3.4310  \n",
      "\n",
      "Fold: 1  Epoch: 358  Training loss = 3.2293  Validation loss = 3.4308  \n",
      "\n",
      "Fold: 1  Epoch: 359  Training loss = 3.2292  Validation loss = 3.4305  \n",
      "\n",
      "Fold: 1  Epoch: 360  Training loss = 3.2291  Validation loss = 3.4303  \n",
      "\n",
      "Fold: 1  Epoch: 361  Training loss = 3.2290  Validation loss = 3.4301  \n",
      "\n",
      "Fold: 1  Epoch: 362  Training loss = 3.2288  Validation loss = 3.4298  \n",
      "\n",
      "Fold: 1  Epoch: 363  Training loss = 3.2288  Validation loss = 3.4296  \n",
      "\n",
      "Fold: 1  Epoch: 364  Training loss = 3.2286  Validation loss = 3.4294  \n",
      "\n",
      "Fold: 1  Epoch: 365  Training loss = 3.2285  Validation loss = 3.4291  \n",
      "\n",
      "Fold: 1  Epoch: 366  Training loss = 3.2284  Validation loss = 3.4289  \n",
      "\n",
      "Fold: 1  Epoch: 367  Training loss = 3.2283  Validation loss = 3.4287  \n",
      "\n",
      "Fold: 1  Epoch: 368  Training loss = 3.2282  Validation loss = 3.4285  \n",
      "\n",
      "Fold: 1  Epoch: 369  Training loss = 3.2281  Validation loss = 3.4283  \n",
      "\n",
      "Fold: 1  Epoch: 370  Training loss = 3.2281  Validation loss = 3.4281  \n",
      "\n",
      "Fold: 1  Epoch: 371  Training loss = 3.2280  Validation loss = 3.4279  \n",
      "\n",
      "Fold: 1  Epoch: 372  Training loss = 3.2279  Validation loss = 3.4277  \n",
      "\n",
      "Fold: 1  Epoch: 373  Training loss = 3.2278  Validation loss = 3.4275  \n",
      "\n",
      "Fold: 1  Epoch: 374  Training loss = 3.2277  Validation loss = 3.4273  \n",
      "\n",
      "Fold: 1  Epoch: 375  Training loss = 3.2276  Validation loss = 3.4270  \n",
      "\n",
      "Fold: 1  Epoch: 376  Training loss = 3.2275  Validation loss = 3.4268  \n",
      "\n",
      "Fold: 1  Epoch: 377  Training loss = 3.2274  Validation loss = 3.4267  \n",
      "\n",
      "Fold: 1  Epoch: 378  Training loss = 3.2273  Validation loss = 3.4265  \n",
      "\n",
      "Fold: 1  Epoch: 379  Training loss = 3.2272  Validation loss = 3.4263  \n",
      "\n",
      "Fold: 1  Epoch: 380  Training loss = 3.2271  Validation loss = 3.4260  \n",
      "\n",
      "Fold: 1  Epoch: 381  Training loss = 3.2270  Validation loss = 3.4257  \n",
      "\n",
      "Fold: 1  Epoch: 382  Training loss = 3.2268  Validation loss = 3.4254  \n",
      "\n",
      "Fold: 1  Epoch: 383  Training loss = 3.2267  Validation loss = 3.4252  \n",
      "\n",
      "Fold: 1  Epoch: 384  Training loss = 3.2266  Validation loss = 3.4250  \n",
      "\n",
      "Fold: 1  Epoch: 385  Training loss = 3.2266  Validation loss = 3.4248  \n",
      "\n",
      "Fold: 1  Epoch: 386  Training loss = 3.2264  Validation loss = 3.4245  \n",
      "\n",
      "Fold: 1  Epoch: 387  Training loss = 3.2263  Validation loss = 3.4243  \n",
      "\n",
      "Fold: 1  Epoch: 388  Training loss = 3.2262  Validation loss = 3.4240  \n",
      "\n",
      "Fold: 1  Epoch: 389  Training loss = 3.2261  Validation loss = 3.4238  \n",
      "\n",
      "Fold: 1  Epoch: 390  Training loss = 3.2260  Validation loss = 3.4236  \n",
      "\n",
      "Fold: 1  Epoch: 391  Training loss = 3.2259  Validation loss = 3.4234  \n",
      "\n",
      "Fold: 1  Epoch: 392  Training loss = 3.2259  Validation loss = 3.4232  \n",
      "\n",
      "Fold: 1  Epoch: 393  Training loss = 3.2257  Validation loss = 3.4230  \n",
      "\n",
      "Fold: 1  Epoch: 394  Training loss = 3.2257  Validation loss = 3.4228  \n",
      "\n",
      "Fold: 1  Epoch: 395  Training loss = 3.2255  Validation loss = 3.4226  \n",
      "\n",
      "Fold: 1  Epoch: 396  Training loss = 3.2254  Validation loss = 3.4223  \n",
      "\n",
      "Fold: 1  Epoch: 397  Training loss = 3.2254  Validation loss = 3.4222  \n",
      "\n",
      "Fold: 1  Epoch: 398  Training loss = 3.2253  Validation loss = 3.4219  \n",
      "\n",
      "Fold: 1  Epoch: 399  Training loss = 3.2252  Validation loss = 3.4217  \n",
      "\n",
      "Fold: 1  Epoch: 400  Training loss = 3.2250  Validation loss = 3.4214  \n",
      "\n",
      "Fold: 1  Epoch: 401  Training loss = 3.2249  Validation loss = 3.4212  \n",
      "\n",
      "Fold: 1  Epoch: 402  Training loss = 3.2248  Validation loss = 3.4209  \n",
      "\n",
      "Fold: 1  Epoch: 403  Training loss = 3.2247  Validation loss = 3.4207  \n",
      "\n",
      "Fold: 1  Epoch: 404  Training loss = 3.2246  Validation loss = 3.4204  \n",
      "\n",
      "Fold: 1  Epoch: 405  Training loss = 3.2245  Validation loss = 3.4202  \n",
      "\n",
      "Fold: 1  Epoch: 406  Training loss = 3.2244  Validation loss = 3.4201  \n",
      "\n",
      "Fold: 1  Epoch: 407  Training loss = 3.2243  Validation loss = 3.4199  \n",
      "\n",
      "Fold: 1  Epoch: 408  Training loss = 3.2242  Validation loss = 3.4196  \n",
      "\n",
      "Fold: 1  Epoch: 409  Training loss = 3.2241  Validation loss = 3.4194  \n",
      "\n",
      "Fold: 1  Epoch: 410  Training loss = 3.2240  Validation loss = 3.4191  \n",
      "\n",
      "Fold: 1  Epoch: 411  Training loss = 3.2239  Validation loss = 3.4189  \n",
      "\n",
      "Fold: 1  Epoch: 412  Training loss = 3.2238  Validation loss = 3.4186  \n",
      "\n",
      "Fold: 1  Epoch: 413  Training loss = 3.2237  Validation loss = 3.4184  \n",
      "\n",
      "Fold: 1  Epoch: 414  Training loss = 3.2236  Validation loss = 3.4182  \n",
      "\n",
      "Fold: 1  Epoch: 415  Training loss = 3.2235  Validation loss = 3.4180  \n",
      "\n",
      "Fold: 1  Epoch: 416  Training loss = 3.2234  Validation loss = 3.4178  \n",
      "\n",
      "Fold: 1  Epoch: 417  Training loss = 3.2233  Validation loss = 3.4177  \n",
      "\n",
      "Fold: 1  Epoch: 418  Training loss = 3.2233  Validation loss = 3.4175  \n",
      "\n",
      "Fold: 1  Epoch: 419  Training loss = 3.2231  Validation loss = 3.4172  \n",
      "\n",
      "Fold: 1  Epoch: 420  Training loss = 3.2231  Validation loss = 3.4170  \n",
      "\n",
      "Fold: 1  Epoch: 421  Training loss = 3.2230  Validation loss = 3.4168  \n",
      "\n",
      "Fold: 1  Epoch: 422  Training loss = 3.2229  Validation loss = 3.4166  \n",
      "\n",
      "Fold: 1  Epoch: 423  Training loss = 3.2228  Validation loss = 3.4164  \n",
      "\n",
      "Fold: 1  Epoch: 424  Training loss = 3.2227  Validation loss = 3.4162  \n",
      "\n",
      "Fold: 1  Epoch: 425  Training loss = 3.2226  Validation loss = 3.4160  \n",
      "\n",
      "Fold: 1  Epoch: 426  Training loss = 3.2225  Validation loss = 3.4158  \n",
      "\n",
      "Fold: 1  Epoch: 427  Training loss = 3.2224  Validation loss = 3.4155  \n",
      "\n",
      "Fold: 1  Epoch: 428  Training loss = 3.2222  Validation loss = 3.4152  \n",
      "\n",
      "Fold: 1  Epoch: 429  Training loss = 3.2222  Validation loss = 3.4150  \n",
      "\n",
      "Fold: 1  Epoch: 430  Training loss = 3.2221  Validation loss = 3.4148  \n",
      "\n",
      "Fold: 1  Epoch: 431  Training loss = 3.2220  Validation loss = 3.4146  \n",
      "\n",
      "Fold: 1  Epoch: 432  Training loss = 3.2219  Validation loss = 3.4144  \n",
      "\n",
      "Fold: 1  Epoch: 433  Training loss = 3.2218  Validation loss = 3.4142  \n",
      "\n",
      "Fold: 1  Epoch: 434  Training loss = 3.2217  Validation loss = 3.4140  \n",
      "\n",
      "Fold: 1  Epoch: 435  Training loss = 3.2216  Validation loss = 3.4138  \n",
      "\n",
      "Fold: 1  Epoch: 436  Training loss = 3.2215  Validation loss = 3.4135  \n",
      "\n",
      "Fold: 1  Epoch: 437  Training loss = 3.2214  Validation loss = 3.4133  \n",
      "\n",
      "Fold: 1  Epoch: 438  Training loss = 3.2213  Validation loss = 3.4131  \n",
      "\n",
      "Fold: 1  Epoch: 439  Training loss = 3.2212  Validation loss = 3.4129  \n",
      "\n",
      "Fold: 1  Epoch: 440  Training loss = 3.2211  Validation loss = 3.4127  \n",
      "\n",
      "Fold: 1  Epoch: 441  Training loss = 3.2210  Validation loss = 3.4124  \n",
      "\n",
      "Fold: 1  Epoch: 442  Training loss = 3.2209  Validation loss = 3.4122  \n",
      "\n",
      "Fold: 1  Epoch: 443  Training loss = 3.2208  Validation loss = 3.4120  \n",
      "\n",
      "Fold: 1  Epoch: 444  Training loss = 3.2206  Validation loss = 3.4117  \n",
      "\n",
      "Fold: 1  Epoch: 445  Training loss = 3.2205  Validation loss = 3.4114  \n",
      "\n",
      "Fold: 1  Epoch: 446  Training loss = 3.2204  Validation loss = 3.4112  \n",
      "\n",
      "Fold: 1  Epoch: 447  Training loss = 3.2203  Validation loss = 3.4109  \n",
      "\n",
      "Fold: 1  Epoch: 448  Training loss = 3.2202  Validation loss = 3.4107  \n",
      "\n",
      "Fold: 1  Epoch: 449  Training loss = 3.2201  Validation loss = 3.4105  \n",
      "\n",
      "Fold: 1  Epoch: 450  Training loss = 3.2200  Validation loss = 3.4103  \n",
      "\n",
      "Fold: 1  Epoch: 451  Training loss = 3.2199  Validation loss = 3.4101  \n",
      "\n",
      "Fold: 1  Epoch: 452  Training loss = 3.2199  Validation loss = 3.4100  \n",
      "\n",
      "Fold: 1  Epoch: 453  Training loss = 3.2198  Validation loss = 3.4098  \n",
      "\n",
      "Fold: 1  Epoch: 454  Training loss = 3.2197  Validation loss = 3.4096  \n",
      "\n",
      "Fold: 1  Epoch: 455  Training loss = 3.2196  Validation loss = 3.4093  \n",
      "\n",
      "Fold: 1  Epoch: 456  Training loss = 3.2195  Validation loss = 3.4091  \n",
      "\n",
      "Fold: 1  Epoch: 457  Training loss = 3.2194  Validation loss = 3.4090  \n",
      "\n",
      "Fold: 1  Epoch: 458  Training loss = 3.2193  Validation loss = 3.4088  \n",
      "\n",
      "Fold: 1  Epoch: 459  Training loss = 3.2192  Validation loss = 3.4086  \n",
      "\n",
      "Fold: 1  Epoch: 460  Training loss = 3.2191  Validation loss = 3.4084  \n",
      "\n",
      "Fold: 1  Epoch: 461  Training loss = 3.2190  Validation loss = 3.4082  \n",
      "\n",
      "Fold: 1  Epoch: 462  Training loss = 3.2190  Validation loss = 3.4080  \n",
      "\n",
      "Fold: 1  Epoch: 463  Training loss = 3.2189  Validation loss = 3.4078  \n",
      "\n",
      "Fold: 1  Epoch: 464  Training loss = 3.2188  Validation loss = 3.4075  \n",
      "\n",
      "Fold: 1  Epoch: 465  Training loss = 3.2187  Validation loss = 3.4073  \n",
      "\n",
      "Fold: 1  Epoch: 466  Training loss = 3.2185  Validation loss = 3.4070  \n",
      "\n",
      "Fold: 1  Epoch: 467  Training loss = 3.2184  Validation loss = 3.4068  \n",
      "\n",
      "Fold: 1  Epoch: 468  Training loss = 3.2183  Validation loss = 3.4065  \n",
      "\n",
      "Fold: 1  Epoch: 469  Training loss = 3.2182  Validation loss = 3.4063  \n",
      "\n",
      "Fold: 1  Epoch: 470  Training loss = 3.2181  Validation loss = 3.4061  \n",
      "\n",
      "Fold: 1  Epoch: 471  Training loss = 3.2180  Validation loss = 3.4059  \n",
      "\n",
      "Fold: 1  Epoch: 472  Training loss = 3.2179  Validation loss = 3.4057  \n",
      "\n",
      "Fold: 1  Epoch: 473  Training loss = 3.2178  Validation loss = 3.4055  \n",
      "\n",
      "Fold: 1  Epoch: 474  Training loss = 3.2177  Validation loss = 3.4053  \n",
      "\n",
      "Fold: 1  Epoch: 475  Training loss = 3.2176  Validation loss = 3.4050  \n",
      "\n",
      "Fold: 1  Epoch: 476  Training loss = 3.2175  Validation loss = 3.4048  \n",
      "\n",
      "Fold: 1  Epoch: 477  Training loss = 3.2174  Validation loss = 3.4045  \n",
      "\n",
      "Fold: 1  Epoch: 478  Training loss = 3.2173  Validation loss = 3.4043  \n",
      "\n",
      "Fold: 1  Epoch: 479  Training loss = 3.2172  Validation loss = 3.4041  \n",
      "\n",
      "Fold: 1  Epoch: 480  Training loss = 3.2171  Validation loss = 3.4038  \n",
      "\n",
      "Fold: 1  Epoch: 481  Training loss = 3.2170  Validation loss = 3.4036  \n",
      "\n",
      "Fold: 1  Epoch: 482  Training loss = 3.2169  Validation loss = 3.4034  \n",
      "\n",
      "Fold: 1  Epoch: 483  Training loss = 3.2168  Validation loss = 3.4031  \n",
      "\n",
      "Fold: 1  Epoch: 484  Training loss = 3.2166  Validation loss = 3.4029  \n",
      "\n",
      "Fold: 1  Epoch: 485  Training loss = 3.2165  Validation loss = 3.4026  \n",
      "\n",
      "Fold: 1  Epoch: 486  Training loss = 3.2164  Validation loss = 3.4024  \n",
      "\n",
      "Fold: 1  Epoch: 487  Training loss = 3.2163  Validation loss = 3.4021  \n",
      "\n",
      "Fold: 1  Epoch: 488  Training loss = 3.2163  Validation loss = 3.4020  \n",
      "\n",
      "Fold: 1  Epoch: 489  Training loss = 3.2161  Validation loss = 3.4017  \n",
      "\n",
      "Fold: 1  Epoch: 490  Training loss = 3.2161  Validation loss = 3.4016  \n",
      "\n",
      "Fold: 1  Epoch: 491  Training loss = 3.2160  Validation loss = 3.4014  \n",
      "\n",
      "Fold: 1  Epoch: 492  Training loss = 3.2159  Validation loss = 3.4012  \n",
      "\n",
      "Fold: 1  Epoch: 493  Training loss = 3.2158  Validation loss = 3.4010  \n",
      "\n",
      "Fold: 1  Epoch: 494  Training loss = 3.2157  Validation loss = 3.4007  \n",
      "\n",
      "Fold: 1  Epoch: 495  Training loss = 3.2156  Validation loss = 3.4006  \n",
      "\n",
      "Fold: 1  Epoch: 496  Training loss = 3.2155  Validation loss = 3.4004  \n",
      "\n",
      "Fold: 1  Epoch: 497  Training loss = 3.2154  Validation loss = 3.4001  \n",
      "\n",
      "Fold: 1  Epoch: 498  Training loss = 3.2153  Validation loss = 3.3998  \n",
      "\n",
      "Fold: 1  Epoch: 499  Training loss = 3.2151  Validation loss = 3.3995  \n",
      "\n",
      "Fold: 1  Epoch: 500  Training loss = 3.2150  Validation loss = 3.3992  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 500  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 3.1712  Validation loss = 3.2742  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 3.1711  Validation loss = 3.2740  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 3.1709  Validation loss = 3.2739  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 3.1708  Validation loss = 3.2737  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 3.1707  Validation loss = 3.2736  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 3.1706  Validation loss = 3.2734  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 3.1705  Validation loss = 3.2733  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 3.1703  Validation loss = 3.2731  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 3.1702  Validation loss = 3.2729  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 3.1701  Validation loss = 3.2727  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 3.1700  Validation loss = 3.2726  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 3.1699  Validation loss = 3.2724  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 3.1697  Validation loss = 3.2722  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 3.1696  Validation loss = 3.2720  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 3.1695  Validation loss = 3.2719  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 3.1694  Validation loss = 3.2717  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 3.1692  Validation loss = 3.2715  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 3.1691  Validation loss = 3.2714  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 3.1690  Validation loss = 3.2713  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 3.1689  Validation loss = 3.2711  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 3.1688  Validation loss = 3.2710  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 3.1687  Validation loss = 3.2708  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 3.1686  Validation loss = 3.2707  \n",
      "\n",
      "Fold: 2  Epoch: 24  Training loss = 3.1685  Validation loss = 3.2705  \n",
      "\n",
      "Fold: 2  Epoch: 25  Training loss = 3.1684  Validation loss = 3.2704  \n",
      "\n",
      "Fold: 2  Epoch: 26  Training loss = 3.1683  Validation loss = 3.2702  \n",
      "\n",
      "Fold: 2  Epoch: 27  Training loss = 3.1681  Validation loss = 3.2700  \n",
      "\n",
      "Fold: 2  Epoch: 28  Training loss = 3.1680  Validation loss = 3.2699  \n",
      "\n",
      "Fold: 2  Epoch: 29  Training loss = 3.1679  Validation loss = 3.2698  \n",
      "\n",
      "Fold: 2  Epoch: 30  Training loss = 3.1678  Validation loss = 3.2696  \n",
      "\n",
      "Fold: 2  Epoch: 31  Training loss = 3.1677  Validation loss = 3.2695  \n",
      "\n",
      "Fold: 2  Epoch: 32  Training loss = 3.1676  Validation loss = 3.2693  \n",
      "\n",
      "Fold: 2  Epoch: 33  Training loss = 3.1675  Validation loss = 3.2692  \n",
      "\n",
      "Fold: 2  Epoch: 34  Training loss = 3.1674  Validation loss = 3.2690  \n",
      "\n",
      "Fold: 2  Epoch: 35  Training loss = 3.1672  Validation loss = 3.2688  \n",
      "\n",
      "Fold: 2  Epoch: 36  Training loss = 3.1671  Validation loss = 3.2687  \n",
      "\n",
      "Fold: 2  Epoch: 37  Training loss = 3.1670  Validation loss = 3.2685  \n",
      "\n",
      "Fold: 2  Epoch: 38  Training loss = 3.1669  Validation loss = 3.2683  \n",
      "\n",
      "Fold: 2  Epoch: 39  Training loss = 3.1668  Validation loss = 3.2681  \n",
      "\n",
      "Fold: 2  Epoch: 40  Training loss = 3.1666  Validation loss = 3.2680  \n",
      "\n",
      "Fold: 2  Epoch: 41  Training loss = 3.1665  Validation loss = 3.2678  \n",
      "\n",
      "Fold: 2  Epoch: 42  Training loss = 3.1664  Validation loss = 3.2677  \n",
      "\n",
      "Fold: 2  Epoch: 43  Training loss = 3.1663  Validation loss = 3.2676  \n",
      "\n",
      "Fold: 2  Epoch: 44  Training loss = 3.1662  Validation loss = 3.2675  \n",
      "\n",
      "Fold: 2  Epoch: 45  Training loss = 3.1661  Validation loss = 3.2673  \n",
      "\n",
      "Fold: 2  Epoch: 46  Training loss = 3.1660  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 2  Epoch: 47  Training loss = 3.1659  Validation loss = 3.2670  \n",
      "\n",
      "Fold: 2  Epoch: 48  Training loss = 3.1658  Validation loss = 3.2668  \n",
      "\n",
      "Fold: 2  Epoch: 49  Training loss = 3.1657  Validation loss = 3.2667  \n",
      "\n",
      "Fold: 2  Epoch: 50  Training loss = 3.1656  Validation loss = 3.2665  \n",
      "\n",
      "Fold: 2  Epoch: 51  Training loss = 3.1654  Validation loss = 3.2664  \n",
      "\n",
      "Fold: 2  Epoch: 52  Training loss = 3.1653  Validation loss = 3.2662  \n",
      "\n",
      "Fold: 2  Epoch: 53  Training loss = 3.1652  Validation loss = 3.2661  \n",
      "\n",
      "Fold: 2  Epoch: 54  Training loss = 3.1651  Validation loss = 3.2659  \n",
      "\n",
      "Fold: 2  Epoch: 55  Training loss = 3.1649  Validation loss = 3.2657  \n",
      "\n",
      "Fold: 2  Epoch: 56  Training loss = 3.1648  Validation loss = 3.2656  \n",
      "\n",
      "Fold: 2  Epoch: 57  Training loss = 3.1647  Validation loss = 3.2654  \n",
      "\n",
      "Fold: 2  Epoch: 58  Training loss = 3.1646  Validation loss = 3.2653  \n",
      "\n",
      "Fold: 2  Epoch: 59  Training loss = 3.1645  Validation loss = 3.2651  \n",
      "\n",
      "Fold: 2  Epoch: 60  Training loss = 3.1644  Validation loss = 3.2650  \n",
      "\n",
      "Fold: 2  Epoch: 61  Training loss = 3.1643  Validation loss = 3.2649  \n",
      "\n",
      "Fold: 2  Epoch: 62  Training loss = 3.1642  Validation loss = 3.2647  \n",
      "\n",
      "Fold: 2  Epoch: 63  Training loss = 3.1641  Validation loss = 3.2646  \n",
      "\n",
      "Fold: 2  Epoch: 64  Training loss = 3.1640  Validation loss = 3.2644  \n",
      "\n",
      "Fold: 2  Epoch: 65  Training loss = 3.1638  Validation loss = 3.2642  \n",
      "\n",
      "Fold: 2  Epoch: 66  Training loss = 3.1637  Validation loss = 3.2640  \n",
      "\n",
      "Fold: 2  Epoch: 67  Training loss = 3.1636  Validation loss = 3.2639  \n",
      "\n",
      "Fold: 2  Epoch: 68  Training loss = 3.1635  Validation loss = 3.2637  \n",
      "\n",
      "Fold: 2  Epoch: 69  Training loss = 3.1634  Validation loss = 3.2636  \n",
      "\n",
      "Fold: 2  Epoch: 70  Training loss = 3.1633  Validation loss = 3.2634  \n",
      "\n",
      "Fold: 2  Epoch: 71  Training loss = 3.1632  Validation loss = 3.2633  \n",
      "\n",
      "Fold: 2  Epoch: 72  Training loss = 3.1631  Validation loss = 3.2631  \n",
      "\n",
      "Fold: 2  Epoch: 73  Training loss = 3.1630  Validation loss = 3.2630  \n",
      "\n",
      "Fold: 2  Epoch: 74  Training loss = 3.1629  Validation loss = 3.2628  \n",
      "\n",
      "Fold: 2  Epoch: 75  Training loss = 3.1627  Validation loss = 3.2626  \n",
      "\n",
      "Fold: 2  Epoch: 76  Training loss = 3.1626  Validation loss = 3.2625  \n",
      "\n",
      "Fold: 2  Epoch: 77  Training loss = 3.1625  Validation loss = 3.2624  \n",
      "\n",
      "Fold: 2  Epoch: 78  Training loss = 3.1624  Validation loss = 3.2622  \n",
      "\n",
      "Fold: 2  Epoch: 79  Training loss = 3.1623  Validation loss = 3.2620  \n",
      "\n",
      "Fold: 2  Epoch: 80  Training loss = 3.1622  Validation loss = 3.2619  \n",
      "\n",
      "Fold: 2  Epoch: 81  Training loss = 3.1621  Validation loss = 3.2618  \n",
      "\n",
      "Fold: 2  Epoch: 82  Training loss = 3.1619  Validation loss = 3.2615  \n",
      "\n",
      "Fold: 2  Epoch: 83  Training loss = 3.1618  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 2  Epoch: 84  Training loss = 3.1617  Validation loss = 3.2612  \n",
      "\n",
      "Fold: 2  Epoch: 85  Training loss = 3.1616  Validation loss = 3.2610  \n",
      "\n",
      "Fold: 2  Epoch: 86  Training loss = 3.1615  Validation loss = 3.2609  \n",
      "\n",
      "Fold: 2  Epoch: 87  Training loss = 3.1614  Validation loss = 3.2607  \n",
      "\n",
      "Fold: 2  Epoch: 88  Training loss = 3.1613  Validation loss = 3.2606  \n",
      "\n",
      "Fold: 2  Epoch: 89  Training loss = 3.1612  Validation loss = 3.2605  \n",
      "\n",
      "Fold: 2  Epoch: 90  Training loss = 3.1610  Validation loss = 3.2603  \n",
      "\n",
      "Fold: 2  Epoch: 91  Training loss = 3.1609  Validation loss = 3.2602  \n",
      "\n",
      "Fold: 2  Epoch: 92  Training loss = 3.1608  Validation loss = 3.2600  \n",
      "\n",
      "Fold: 2  Epoch: 93  Training loss = 3.1607  Validation loss = 3.2598  \n",
      "\n",
      "Fold: 2  Epoch: 94  Training loss = 3.1606  Validation loss = 3.2597  \n",
      "\n",
      "Fold: 2  Epoch: 95  Training loss = 3.1604  Validation loss = 3.2595  \n",
      "\n",
      "Fold: 2  Epoch: 96  Training loss = 3.1603  Validation loss = 3.2594  \n",
      "\n",
      "Fold: 2  Epoch: 97  Training loss = 3.1602  Validation loss = 3.2592  \n",
      "\n",
      "Fold: 2  Epoch: 98  Training loss = 3.1601  Validation loss = 3.2591  \n",
      "\n",
      "Fold: 2  Epoch: 99  Training loss = 3.1600  Validation loss = 3.2589  \n",
      "\n",
      "Fold: 2  Epoch: 100  Training loss = 3.1599  Validation loss = 3.2588  \n",
      "\n",
      "Fold: 2  Epoch: 101  Training loss = 3.1597  Validation loss = 3.2586  \n",
      "\n",
      "Fold: 2  Epoch: 102  Training loss = 3.1596  Validation loss = 3.2584  \n",
      "\n",
      "Fold: 2  Epoch: 103  Training loss = 3.1595  Validation loss = 3.2583  \n",
      "\n",
      "Fold: 2  Epoch: 104  Training loss = 3.1594  Validation loss = 3.2581  \n",
      "\n",
      "Fold: 2  Epoch: 105  Training loss = 3.1593  Validation loss = 3.2579  \n",
      "\n",
      "Fold: 2  Epoch: 106  Training loss = 3.1592  Validation loss = 3.2578  \n",
      "\n",
      "Fold: 2  Epoch: 107  Training loss = 3.1590  Validation loss = 3.2576  \n",
      "\n",
      "Fold: 2  Epoch: 108  Training loss = 3.1589  Validation loss = 3.2574  \n",
      "\n",
      "Fold: 2  Epoch: 109  Training loss = 3.1589  Validation loss = 3.2573  \n",
      "\n",
      "Fold: 2  Epoch: 110  Training loss = 3.1587  Validation loss = 3.2572  \n",
      "\n",
      "Fold: 2  Epoch: 111  Training loss = 3.1586  Validation loss = 3.2570  \n",
      "\n",
      "Fold: 2  Epoch: 112  Training loss = 3.1585  Validation loss = 3.2568  \n",
      "\n",
      "Fold: 2  Epoch: 113  Training loss = 3.1584  Validation loss = 3.2566  \n",
      "\n",
      "Fold: 2  Epoch: 114  Training loss = 3.1583  Validation loss = 3.2565  \n",
      "\n",
      "Fold: 2  Epoch: 115  Training loss = 3.1582  Validation loss = 3.2564  \n",
      "\n",
      "Fold: 2  Epoch: 116  Training loss = 3.1581  Validation loss = 3.2563  \n",
      "\n",
      "Fold: 2  Epoch: 117  Training loss = 3.1580  Validation loss = 3.2561  \n",
      "\n",
      "Fold: 2  Epoch: 118  Training loss = 3.1578  Validation loss = 3.2559  \n",
      "\n",
      "Fold: 2  Epoch: 119  Training loss = 3.1577  Validation loss = 3.2558  \n",
      "\n",
      "Fold: 2  Epoch: 120  Training loss = 3.1576  Validation loss = 3.2556  \n",
      "\n",
      "Fold: 2  Epoch: 121  Training loss = 3.1575  Validation loss = 3.2555  \n",
      "\n",
      "Fold: 2  Epoch: 122  Training loss = 3.1574  Validation loss = 3.2552  \n",
      "\n",
      "Fold: 2  Epoch: 123  Training loss = 3.1573  Validation loss = 3.2551  \n",
      "\n",
      "Fold: 2  Epoch: 124  Training loss = 3.1572  Validation loss = 3.2550  \n",
      "\n",
      "Fold: 2  Epoch: 125  Training loss = 3.1570  Validation loss = 3.2548  \n",
      "\n",
      "Fold: 2  Epoch: 126  Training loss = 3.1570  Validation loss = 3.2547  \n",
      "\n",
      "Fold: 2  Epoch: 127  Training loss = 3.1569  Validation loss = 3.2545  \n",
      "\n",
      "Fold: 2  Epoch: 128  Training loss = 3.1567  Validation loss = 3.2544  \n",
      "\n",
      "Fold: 2  Epoch: 129  Training loss = 3.1566  Validation loss = 3.2542  \n",
      "\n",
      "Fold: 2  Epoch: 130  Training loss = 3.1565  Validation loss = 3.2541  \n",
      "\n",
      "Fold: 2  Epoch: 131  Training loss = 3.1564  Validation loss = 3.2539  \n",
      "\n",
      "Fold: 2  Epoch: 132  Training loss = 3.1563  Validation loss = 3.2537  \n",
      "\n",
      "Fold: 2  Epoch: 133  Training loss = 3.1562  Validation loss = 3.2536  \n",
      "\n",
      "Fold: 2  Epoch: 134  Training loss = 3.1561  Validation loss = 3.2534  \n",
      "\n",
      "Fold: 2  Epoch: 135  Training loss = 3.1560  Validation loss = 3.2532  \n",
      "\n",
      "Fold: 2  Epoch: 136  Training loss = 3.1558  Validation loss = 3.2531  \n",
      "\n",
      "Fold: 2  Epoch: 137  Training loss = 3.1557  Validation loss = 3.2529  \n",
      "\n",
      "Fold: 2  Epoch: 138  Training loss = 3.1556  Validation loss = 3.2528  \n",
      "\n",
      "Fold: 2  Epoch: 139  Training loss = 3.1555  Validation loss = 3.2526  \n",
      "\n",
      "Fold: 2  Epoch: 140  Training loss = 3.1554  Validation loss = 3.2524  \n",
      "\n",
      "Fold: 2  Epoch: 141  Training loss = 3.1553  Validation loss = 3.2523  \n",
      "\n",
      "Fold: 2  Epoch: 142  Training loss = 3.1551  Validation loss = 3.2521  \n",
      "\n",
      "Fold: 2  Epoch: 143  Training loss = 3.1550  Validation loss = 3.2520  \n",
      "\n",
      "Fold: 2  Epoch: 144  Training loss = 3.1549  Validation loss = 3.2518  \n",
      "\n",
      "Fold: 2  Epoch: 145  Training loss = 3.1548  Validation loss = 3.2516  \n",
      "\n",
      "Fold: 2  Epoch: 146  Training loss = 3.1547  Validation loss = 3.2515  \n",
      "\n",
      "Fold: 2  Epoch: 147  Training loss = 3.1546  Validation loss = 3.2513  \n",
      "\n",
      "Fold: 2  Epoch: 148  Training loss = 3.1545  Validation loss = 3.2512  \n",
      "\n",
      "Fold: 2  Epoch: 149  Training loss = 3.1544  Validation loss = 3.2510  \n",
      "\n",
      "Fold: 2  Epoch: 150  Training loss = 3.1542  Validation loss = 3.2509  \n",
      "\n",
      "Fold: 2  Epoch: 151  Training loss = 3.1541  Validation loss = 3.2507  \n",
      "\n",
      "Fold: 2  Epoch: 152  Training loss = 3.1540  Validation loss = 3.2506  \n",
      "\n",
      "Fold: 2  Epoch: 153  Training loss = 3.1539  Validation loss = 3.2504  \n",
      "\n",
      "Fold: 2  Epoch: 154  Training loss = 3.1538  Validation loss = 3.2503  \n",
      "\n",
      "Fold: 2  Epoch: 155  Training loss = 3.1537  Validation loss = 3.2502  \n",
      "\n",
      "Fold: 2  Epoch: 156  Training loss = 3.1536  Validation loss = 3.2500  \n",
      "\n",
      "Fold: 2  Epoch: 157  Training loss = 3.1535  Validation loss = 3.2499  \n",
      "\n",
      "Fold: 2  Epoch: 158  Training loss = 3.1534  Validation loss = 3.2497  \n",
      "\n",
      "Fold: 2  Epoch: 159  Training loss = 3.1533  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 2  Epoch: 160  Training loss = 3.1532  Validation loss = 3.2494  \n",
      "\n",
      "Fold: 2  Epoch: 161  Training loss = 3.1530  Validation loss = 3.2492  \n",
      "\n",
      "Fold: 2  Epoch: 162  Training loss = 3.1529  Validation loss = 3.2491  \n",
      "\n",
      "Fold: 2  Epoch: 163  Training loss = 3.1528  Validation loss = 3.2489  \n",
      "\n",
      "Fold: 2  Epoch: 164  Training loss = 3.1527  Validation loss = 3.2488  \n",
      "\n",
      "Fold: 2  Epoch: 165  Training loss = 3.1526  Validation loss = 3.2486  \n",
      "\n",
      "Fold: 2  Epoch: 166  Training loss = 3.1525  Validation loss = 3.2485  \n",
      "\n",
      "Fold: 2  Epoch: 167  Training loss = 3.1524  Validation loss = 3.2483  \n",
      "\n",
      "Fold: 2  Epoch: 168  Training loss = 3.1523  Validation loss = 3.2482  \n",
      "\n",
      "Fold: 2  Epoch: 169  Training loss = 3.1522  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 2  Epoch: 170  Training loss = 3.1521  Validation loss = 3.2479  \n",
      "\n",
      "Fold: 2  Epoch: 171  Training loss = 3.1520  Validation loss = 3.2478  \n",
      "\n",
      "Fold: 2  Epoch: 172  Training loss = 3.1519  Validation loss = 3.2476  \n",
      "\n",
      "Fold: 2  Epoch: 173  Training loss = 3.1518  Validation loss = 3.2475  \n",
      "\n",
      "Fold: 2  Epoch: 174  Training loss = 3.1517  Validation loss = 3.2473  \n",
      "\n",
      "Fold: 2  Epoch: 175  Training loss = 3.1515  Validation loss = 3.2471  \n",
      "\n",
      "Fold: 2  Epoch: 176  Training loss = 3.1514  Validation loss = 3.2469  \n",
      "\n",
      "Fold: 2  Epoch: 177  Training loss = 3.1513  Validation loss = 3.2468  \n",
      "\n",
      "Fold: 2  Epoch: 178  Training loss = 3.1512  Validation loss = 3.2466  \n",
      "\n",
      "Fold: 2  Epoch: 179  Training loss = 3.1511  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 2  Epoch: 180  Training loss = 3.1509  Validation loss = 3.2463  \n",
      "\n",
      "Fold: 2  Epoch: 181  Training loss = 3.1508  Validation loss = 3.2461  \n",
      "\n",
      "Fold: 2  Epoch: 182  Training loss = 3.1507  Validation loss = 3.2460  \n",
      "\n",
      "Fold: 2  Epoch: 183  Training loss = 3.1506  Validation loss = 3.2458  \n",
      "\n",
      "Fold: 2  Epoch: 184  Training loss = 3.1505  Validation loss = 3.2457  \n",
      "\n",
      "Fold: 2  Epoch: 185  Training loss = 3.1504  Validation loss = 3.2455  \n",
      "\n",
      "Fold: 2  Epoch: 186  Training loss = 3.1503  Validation loss = 3.2454  \n",
      "\n",
      "Fold: 2  Epoch: 187  Training loss = 3.1502  Validation loss = 3.2452  \n",
      "\n",
      "Fold: 2  Epoch: 188  Training loss = 3.1501  Validation loss = 3.2450  \n",
      "\n",
      "Fold: 2  Epoch: 189  Training loss = 3.1500  Validation loss = 3.2449  \n",
      "\n",
      "Fold: 2  Epoch: 190  Training loss = 3.1498  Validation loss = 3.2447  \n",
      "\n",
      "Fold: 2  Epoch: 191  Training loss = 3.1498  Validation loss = 3.2446  \n",
      "\n",
      "Fold: 2  Epoch: 192  Training loss = 3.1497  Validation loss = 3.2445  \n",
      "\n",
      "Fold: 2  Epoch: 193  Training loss = 3.1496  Validation loss = 3.2443  \n",
      "\n",
      "Fold: 2  Epoch: 194  Training loss = 3.1495  Validation loss = 3.2442  \n",
      "\n",
      "Fold: 2  Epoch: 195  Training loss = 3.1494  Validation loss = 3.2440  \n",
      "\n",
      "Fold: 2  Epoch: 196  Training loss = 3.1493  Validation loss = 3.2439  \n",
      "\n",
      "Fold: 2  Epoch: 197  Training loss = 3.1491  Validation loss = 3.2437  \n",
      "\n",
      "Fold: 2  Epoch: 198  Training loss = 3.1490  Validation loss = 3.2435  \n",
      "\n",
      "Fold: 2  Epoch: 199  Training loss = 3.1489  Validation loss = 3.2434  \n",
      "\n",
      "Fold: 2  Epoch: 200  Training loss = 3.1488  Validation loss = 3.2432  \n",
      "\n",
      "Fold: 2  Epoch: 201  Training loss = 3.1487  Validation loss = 3.2431  \n",
      "\n",
      "Fold: 2  Epoch: 202  Training loss = 3.1486  Validation loss = 3.2429  \n",
      "\n",
      "Fold: 2  Epoch: 203  Training loss = 3.1484  Validation loss = 3.2427  \n",
      "\n",
      "Fold: 2  Epoch: 204  Training loss = 3.1483  Validation loss = 3.2426  \n",
      "\n",
      "Fold: 2  Epoch: 205  Training loss = 3.1482  Validation loss = 3.2424  \n",
      "\n",
      "Fold: 2  Epoch: 206  Training loss = 3.1481  Validation loss = 3.2423  \n",
      "\n",
      "Fold: 2  Epoch: 207  Training loss = 3.1480  Validation loss = 3.2421  \n",
      "\n",
      "Fold: 2  Epoch: 208  Training loss = 3.1479  Validation loss = 3.2420  \n",
      "\n",
      "Fold: 2  Epoch: 209  Training loss = 3.1478  Validation loss = 3.2419  \n",
      "\n",
      "Fold: 2  Epoch: 210  Training loss = 3.1477  Validation loss = 3.2417  \n",
      "\n",
      "Fold: 2  Epoch: 211  Training loss = 3.1476  Validation loss = 3.2416  \n",
      "\n",
      "Fold: 2  Epoch: 212  Training loss = 3.1475  Validation loss = 3.2414  \n",
      "\n",
      "Fold: 2  Epoch: 213  Training loss = 3.1474  Validation loss = 3.2413  \n",
      "\n",
      "Fold: 2  Epoch: 214  Training loss = 3.1473  Validation loss = 3.2411  \n",
      "\n",
      "Fold: 2  Epoch: 215  Training loss = 3.1471  Validation loss = 3.2409  \n",
      "\n",
      "Fold: 2  Epoch: 216  Training loss = 3.1470  Validation loss = 3.2407  \n",
      "\n",
      "Fold: 2  Epoch: 217  Training loss = 3.1469  Validation loss = 3.2406  \n",
      "\n",
      "Fold: 2  Epoch: 218  Training loss = 3.1468  Validation loss = 3.2405  \n",
      "\n",
      "Fold: 2  Epoch: 219  Training loss = 3.1467  Validation loss = 3.2403  \n",
      "\n",
      "Fold: 2  Epoch: 220  Training loss = 3.1466  Validation loss = 3.2402  \n",
      "\n",
      "Fold: 2  Epoch: 221  Training loss = 3.1465  Validation loss = 3.2400  \n",
      "\n",
      "Fold: 2  Epoch: 222  Training loss = 3.1464  Validation loss = 3.2399  \n",
      "\n",
      "Fold: 2  Epoch: 223  Training loss = 3.1463  Validation loss = 3.2397  \n",
      "\n",
      "Fold: 2  Epoch: 224  Training loss = 3.1462  Validation loss = 3.2396  \n",
      "\n",
      "Fold: 2  Epoch: 225  Training loss = 3.1461  Validation loss = 3.2394  \n",
      "\n",
      "Fold: 2  Epoch: 226  Training loss = 3.1460  Validation loss = 3.2393  \n",
      "\n",
      "Fold: 2  Epoch: 227  Training loss = 3.1459  Validation loss = 3.2391  \n",
      "\n",
      "Fold: 2  Epoch: 228  Training loss = 3.1458  Validation loss = 3.2390  \n",
      "\n",
      "Fold: 2  Epoch: 229  Training loss = 3.1456  Validation loss = 3.2388  \n",
      "\n",
      "Fold: 2  Epoch: 230  Training loss = 3.1455  Validation loss = 3.2387  \n",
      "\n",
      "Fold: 2  Epoch: 231  Training loss = 3.1454  Validation loss = 3.2385  \n",
      "\n",
      "Fold: 2  Epoch: 232  Training loss = 3.1453  Validation loss = 3.2384  \n",
      "\n",
      "Fold: 2  Epoch: 233  Training loss = 3.1452  Validation loss = 3.2382  \n",
      "\n",
      "Fold: 2  Epoch: 234  Training loss = 3.1451  Validation loss = 3.2381  \n",
      "\n",
      "Fold: 2  Epoch: 235  Training loss = 3.1450  Validation loss = 3.2379  \n",
      "\n",
      "Fold: 2  Epoch: 236  Training loss = 3.1449  Validation loss = 3.2378  \n",
      "\n",
      "Fold: 2  Epoch: 237  Training loss = 3.1447  Validation loss = 3.2376  \n",
      "\n",
      "Fold: 2  Epoch: 238  Training loss = 3.1446  Validation loss = 3.2374  \n",
      "\n",
      "Fold: 2  Epoch: 239  Training loss = 3.1445  Validation loss = 3.2373  \n",
      "\n",
      "Fold: 2  Epoch: 240  Training loss = 3.1445  Validation loss = 3.2372  \n",
      "\n",
      "Fold: 2  Epoch: 241  Training loss = 3.1443  Validation loss = 3.2370  \n",
      "\n",
      "Fold: 2  Epoch: 242  Training loss = 3.1442  Validation loss = 3.2368  \n",
      "\n",
      "Fold: 2  Epoch: 243  Training loss = 3.1440  Validation loss = 3.2366  \n",
      "\n",
      "Fold: 2  Epoch: 244  Training loss = 3.1439  Validation loss = 3.2364  \n",
      "\n",
      "Fold: 2  Epoch: 245  Training loss = 3.1438  Validation loss = 3.2363  \n",
      "\n",
      "Fold: 2  Epoch: 246  Training loss = 3.1437  Validation loss = 3.2362  \n",
      "\n",
      "Fold: 2  Epoch: 247  Training loss = 3.1437  Validation loss = 3.2360  \n",
      "\n",
      "Fold: 2  Epoch: 248  Training loss = 3.1436  Validation loss = 3.2359  \n",
      "\n",
      "Fold: 2  Epoch: 249  Training loss = 3.1434  Validation loss = 3.2358  \n",
      "\n",
      "Fold: 2  Epoch: 250  Training loss = 3.1433  Validation loss = 3.2356  \n",
      "\n",
      "Fold: 2  Epoch: 251  Training loss = 3.1432  Validation loss = 3.2354  \n",
      "\n",
      "Fold: 2  Epoch: 252  Training loss = 3.1431  Validation loss = 3.2353  \n",
      "\n",
      "Fold: 2  Epoch: 253  Training loss = 3.1430  Validation loss = 3.2351  \n",
      "\n",
      "Fold: 2  Epoch: 254  Training loss = 3.1429  Validation loss = 3.2350  \n",
      "\n",
      "Fold: 2  Epoch: 255  Training loss = 3.1428  Validation loss = 3.2349  \n",
      "\n",
      "Fold: 2  Epoch: 256  Training loss = 3.1427  Validation loss = 3.2347  \n",
      "\n",
      "Fold: 2  Epoch: 257  Training loss = 3.1426  Validation loss = 3.2346  \n",
      "\n",
      "Fold: 2  Epoch: 258  Training loss = 3.1426  Validation loss = 3.2344  \n",
      "\n",
      "Fold: 2  Epoch: 259  Training loss = 3.1425  Validation loss = 3.2343  \n",
      "\n",
      "Fold: 2  Epoch: 260  Training loss = 3.1423  Validation loss = 3.2341  \n",
      "\n",
      "Fold: 2  Epoch: 261  Training loss = 3.1422  Validation loss = 3.2340  \n",
      "\n",
      "Fold: 2  Epoch: 262  Training loss = 3.1421  Validation loss = 3.2338  \n",
      "\n",
      "Fold: 2  Epoch: 263  Training loss = 3.1420  Validation loss = 3.2337  \n",
      "\n",
      "Fold: 2  Epoch: 264  Training loss = 3.1419  Validation loss = 3.2336  \n",
      "\n",
      "Fold: 2  Epoch: 265  Training loss = 3.1418  Validation loss = 3.2333  \n",
      "\n",
      "Fold: 2  Epoch: 266  Training loss = 3.1416  Validation loss = 3.2332  \n",
      "\n",
      "Fold: 2  Epoch: 267  Training loss = 3.1416  Validation loss = 3.2330  \n",
      "\n",
      "Fold: 2  Epoch: 268  Training loss = 3.1414  Validation loss = 3.2329  \n",
      "\n",
      "Fold: 2  Epoch: 269  Training loss = 3.1413  Validation loss = 3.2327  \n",
      "\n",
      "Fold: 2  Epoch: 270  Training loss = 3.1412  Validation loss = 3.2326  \n",
      "\n",
      "Fold: 2  Epoch: 271  Training loss = 3.1411  Validation loss = 3.2324  \n",
      "\n",
      "Fold: 2  Epoch: 272  Training loss = 3.1410  Validation loss = 3.2323  \n",
      "\n",
      "Fold: 2  Epoch: 273  Training loss = 3.1409  Validation loss = 3.2321  \n",
      "\n",
      "Fold: 2  Epoch: 274  Training loss = 3.1408  Validation loss = 3.2320  \n",
      "\n",
      "Fold: 2  Epoch: 275  Training loss = 3.1407  Validation loss = 3.2319  \n",
      "\n",
      "Fold: 2  Epoch: 276  Training loss = 3.1406  Validation loss = 3.2317  \n",
      "\n",
      "Fold: 2  Epoch: 277  Training loss = 3.1406  Validation loss = 3.2316  \n",
      "\n",
      "Fold: 2  Epoch: 278  Training loss = 3.1405  Validation loss = 3.2315  \n",
      "\n",
      "Fold: 2  Epoch: 279  Training loss = 3.1404  Validation loss = 3.2313  \n",
      "\n",
      "Fold: 2  Epoch: 280  Training loss = 3.1403  Validation loss = 3.2312  \n",
      "\n",
      "Fold: 2  Epoch: 281  Training loss = 3.1402  Validation loss = 3.2311  \n",
      "\n",
      "Fold: 2  Epoch: 282  Training loss = 3.1401  Validation loss = 3.2309  \n",
      "\n",
      "Fold: 2  Epoch: 283  Training loss = 3.1399  Validation loss = 3.2307  \n",
      "\n",
      "Fold: 2  Epoch: 284  Training loss = 3.1398  Validation loss = 3.2306  \n",
      "\n",
      "Fold: 2  Epoch: 285  Training loss = 3.1397  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 2  Epoch: 286  Training loss = 3.1396  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 2  Epoch: 287  Training loss = 3.1395  Validation loss = 3.2301  \n",
      "\n",
      "Fold: 2  Epoch: 288  Training loss = 3.1394  Validation loss = 3.2300  \n",
      "\n",
      "Fold: 2  Epoch: 289  Training loss = 3.1393  Validation loss = 3.2298  \n",
      "\n",
      "Fold: 2  Epoch: 290  Training loss = 3.1392  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 2  Epoch: 291  Training loss = 3.1391  Validation loss = 3.2296  \n",
      "\n",
      "Fold: 2  Epoch: 292  Training loss = 3.1390  Validation loss = 3.2294  \n",
      "\n",
      "Fold: 2  Epoch: 293  Training loss = 3.1389  Validation loss = 3.2293  \n",
      "\n",
      "Fold: 2  Epoch: 294  Training loss = 3.1388  Validation loss = 3.2291  \n",
      "\n",
      "Fold: 2  Epoch: 295  Training loss = 3.1387  Validation loss = 3.2290  \n",
      "\n",
      "Fold: 2  Epoch: 296  Training loss = 3.1386  Validation loss = 3.2288  \n",
      "\n",
      "Fold: 2  Epoch: 297  Training loss = 3.1384  Validation loss = 3.2286  \n",
      "\n",
      "Fold: 2  Epoch: 298  Training loss = 3.1383  Validation loss = 3.2284  \n",
      "\n",
      "Fold: 2  Epoch: 299  Training loss = 3.1382  Validation loss = 3.2282  \n",
      "\n",
      "Fold: 2  Epoch: 300  Training loss = 3.1381  Validation loss = 3.2281  \n",
      "\n",
      "Fold: 2  Epoch: 301  Training loss = 3.1380  Validation loss = 3.2280  \n",
      "\n",
      "Fold: 2  Epoch: 302  Training loss = 3.1379  Validation loss = 3.2278  \n",
      "\n",
      "Fold: 2  Epoch: 303  Training loss = 3.1377  Validation loss = 3.2276  \n",
      "\n",
      "Fold: 2  Epoch: 304  Training loss = 3.1376  Validation loss = 3.2274  \n",
      "\n",
      "Fold: 2  Epoch: 305  Training loss = 3.1375  Validation loss = 3.2273  \n",
      "\n",
      "Fold: 2  Epoch: 306  Training loss = 3.1374  Validation loss = 3.2272  \n",
      "\n",
      "Fold: 2  Epoch: 307  Training loss = 3.1373  Validation loss = 3.2270  \n",
      "\n",
      "Fold: 2  Epoch: 308  Training loss = 3.1372  Validation loss = 3.2268  \n",
      "\n",
      "Fold: 2  Epoch: 309  Training loss = 3.1371  Validation loss = 3.2267  \n",
      "\n",
      "Fold: 2  Epoch: 310  Training loss = 3.1370  Validation loss = 3.2265  \n",
      "\n",
      "Fold: 2  Epoch: 311  Training loss = 3.1369  Validation loss = 3.2264  \n",
      "\n",
      "Fold: 2  Epoch: 312  Training loss = 3.1368  Validation loss = 3.2262  \n",
      "\n",
      "Fold: 2  Epoch: 313  Training loss = 3.1366  Validation loss = 3.2260  \n",
      "\n",
      "Fold: 2  Epoch: 314  Training loss = 3.1365  Validation loss = 3.2259  \n",
      "\n",
      "Fold: 2  Epoch: 315  Training loss = 3.1364  Validation loss = 3.2257  \n",
      "\n",
      "Fold: 2  Epoch: 316  Training loss = 3.1363  Validation loss = 3.2256  \n",
      "\n",
      "Fold: 2  Epoch: 317  Training loss = 3.1362  Validation loss = 3.2254  \n",
      "\n",
      "Fold: 2  Epoch: 318  Training loss = 3.1361  Validation loss = 3.2252  \n",
      "\n",
      "Fold: 2  Epoch: 319  Training loss = 3.1360  Validation loss = 3.2251  \n",
      "\n",
      "Fold: 2  Epoch: 320  Training loss = 3.1359  Validation loss = 3.2249  \n",
      "\n",
      "Fold: 2  Epoch: 321  Training loss = 3.1358  Validation loss = 3.2247  \n",
      "\n",
      "Fold: 2  Epoch: 322  Training loss = 3.1357  Validation loss = 3.2246  \n",
      "\n",
      "Fold: 2  Epoch: 323  Training loss = 3.1356  Validation loss = 3.2245  \n",
      "\n",
      "Fold: 2  Epoch: 324  Training loss = 3.1355  Validation loss = 3.2244  \n",
      "\n",
      "Fold: 2  Epoch: 325  Training loss = 3.1354  Validation loss = 3.2242  \n",
      "\n",
      "Fold: 2  Epoch: 326  Training loss = 3.1352  Validation loss = 3.2240  \n",
      "\n",
      "Fold: 2  Epoch: 327  Training loss = 3.1351  Validation loss = 3.2238  \n",
      "\n",
      "Fold: 2  Epoch: 328  Training loss = 3.1350  Validation loss = 3.2236  \n",
      "\n",
      "Fold: 2  Epoch: 329  Training loss = 3.1349  Validation loss = 3.2235  \n",
      "\n",
      "Fold: 2  Epoch: 330  Training loss = 3.1348  Validation loss = 3.2234  \n",
      "\n",
      "Fold: 2  Epoch: 331  Training loss = 3.1347  Validation loss = 3.2233  \n",
      "\n",
      "Fold: 2  Epoch: 332  Training loss = 3.1346  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 2  Epoch: 333  Training loss = 3.1345  Validation loss = 3.2230  \n",
      "\n",
      "Fold: 2  Epoch: 334  Training loss = 3.1344  Validation loss = 3.2228  \n",
      "\n",
      "Fold: 2  Epoch: 335  Training loss = 3.1343  Validation loss = 3.2227  \n",
      "\n",
      "Fold: 2  Epoch: 336  Training loss = 3.1342  Validation loss = 3.2225  \n",
      "\n",
      "Fold: 2  Epoch: 337  Training loss = 3.1341  Validation loss = 3.2223  \n",
      "\n",
      "Fold: 2  Epoch: 338  Training loss = 3.1340  Validation loss = 3.2222  \n",
      "\n",
      "Fold: 2  Epoch: 339  Training loss = 3.1339  Validation loss = 3.2221  \n",
      "\n",
      "Fold: 2  Epoch: 340  Training loss = 3.1338  Validation loss = 3.2219  \n",
      "\n",
      "Fold: 2  Epoch: 341  Training loss = 3.1337  Validation loss = 3.2218  \n",
      "\n",
      "Fold: 2  Epoch: 342  Training loss = 3.1336  Validation loss = 3.2217  \n",
      "\n",
      "Fold: 2  Epoch: 343  Training loss = 3.1335  Validation loss = 3.2215  \n",
      "\n",
      "Fold: 2  Epoch: 344  Training loss = 3.1334  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 2  Epoch: 345  Training loss = 3.1333  Validation loss = 3.2212  \n",
      "\n",
      "Fold: 2  Epoch: 346  Training loss = 3.1332  Validation loss = 3.2210  \n",
      "\n",
      "Fold: 2  Epoch: 347  Training loss = 3.1331  Validation loss = 3.2209  \n",
      "\n",
      "Fold: 2  Epoch: 348  Training loss = 3.1329  Validation loss = 3.2207  \n",
      "\n",
      "Fold: 2  Epoch: 349  Training loss = 3.1329  Validation loss = 3.2206  \n",
      "\n",
      "Fold: 2  Epoch: 350  Training loss = 3.1328  Validation loss = 3.2205  \n",
      "\n",
      "Fold: 2  Epoch: 351  Training loss = 3.1327  Validation loss = 3.2204  \n",
      "\n",
      "Fold: 2  Epoch: 352  Training loss = 3.1326  Validation loss = 3.2202  \n",
      "\n",
      "Fold: 2  Epoch: 353  Training loss = 3.1325  Validation loss = 3.2201  \n",
      "\n",
      "Fold: 2  Epoch: 354  Training loss = 3.1324  Validation loss = 3.2199  \n",
      "\n",
      "Fold: 2  Epoch: 355  Training loss = 3.1323  Validation loss = 3.2198  \n",
      "\n",
      "Fold: 2  Epoch: 356  Training loss = 3.1322  Validation loss = 3.2196  \n",
      "\n",
      "Fold: 2  Epoch: 357  Training loss = 3.1321  Validation loss = 3.2194  \n",
      "\n",
      "Fold: 2  Epoch: 358  Training loss = 3.1319  Validation loss = 3.2193  \n",
      "\n",
      "Fold: 2  Epoch: 359  Training loss = 3.1318  Validation loss = 3.2191  \n",
      "\n",
      "Fold: 2  Epoch: 360  Training loss = 3.1318  Validation loss = 3.2190  \n",
      "\n",
      "Fold: 2  Epoch: 361  Training loss = 3.1317  Validation loss = 3.2189  \n",
      "\n",
      "Fold: 2  Epoch: 362  Training loss = 3.1316  Validation loss = 3.2188  \n",
      "\n",
      "Fold: 2  Epoch: 363  Training loss = 3.1315  Validation loss = 3.2187  \n",
      "\n",
      "Fold: 2  Epoch: 364  Training loss = 3.1314  Validation loss = 3.2185  \n",
      "\n",
      "Fold: 2  Epoch: 365  Training loss = 3.1313  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 2  Epoch: 366  Training loss = 3.1312  Validation loss = 3.2182  \n",
      "\n",
      "Fold: 2  Epoch: 367  Training loss = 3.1311  Validation loss = 3.2180  \n",
      "\n",
      "Fold: 2  Epoch: 368  Training loss = 3.1309  Validation loss = 3.2178  \n",
      "\n",
      "Fold: 2  Epoch: 369  Training loss = 3.1308  Validation loss = 3.2177  \n",
      "\n",
      "Fold: 2  Epoch: 370  Training loss = 3.1307  Validation loss = 3.2175  \n",
      "\n",
      "Fold: 2  Epoch: 371  Training loss = 3.1306  Validation loss = 3.2174  \n",
      "\n",
      "Fold: 2  Epoch: 372  Training loss = 3.1306  Validation loss = 3.2173  \n",
      "\n",
      "Fold: 2  Epoch: 373  Training loss = 3.1304  Validation loss = 3.2172  \n",
      "\n",
      "Fold: 2  Epoch: 374  Training loss = 3.1303  Validation loss = 3.2170  \n",
      "\n",
      "Fold: 2  Epoch: 375  Training loss = 3.1303  Validation loss = 3.2169  \n",
      "\n",
      "Fold: 2  Epoch: 376  Training loss = 3.1302  Validation loss = 3.2167  \n",
      "\n",
      "Fold: 2  Epoch: 377  Training loss = 3.1301  Validation loss = 3.2166  \n",
      "\n",
      "Fold: 2  Epoch: 378  Training loss = 3.1300  Validation loss = 3.2164  \n",
      "\n",
      "Fold: 2  Epoch: 379  Training loss = 3.1299  Validation loss = 3.2163  \n",
      "\n",
      "Fold: 2  Epoch: 380  Training loss = 3.1297  Validation loss = 3.2161  \n",
      "\n",
      "Fold: 2  Epoch: 381  Training loss = 3.1296  Validation loss = 3.2160  \n",
      "\n",
      "Fold: 2  Epoch: 382  Training loss = 3.1295  Validation loss = 3.2158  \n",
      "\n",
      "Fold: 2  Epoch: 383  Training loss = 3.1294  Validation loss = 3.2157  \n",
      "\n",
      "Fold: 2  Epoch: 384  Training loss = 3.1293  Validation loss = 3.2155  \n",
      "\n",
      "Fold: 2  Epoch: 385  Training loss = 3.1292  Validation loss = 3.2154  \n",
      "\n",
      "Fold: 2  Epoch: 386  Training loss = 3.1291  Validation loss = 3.2153  \n",
      "\n",
      "Fold: 2  Epoch: 387  Training loss = 3.1290  Validation loss = 3.2151  \n",
      "\n",
      "Fold: 2  Epoch: 388  Training loss = 3.1289  Validation loss = 3.2149  \n",
      "\n",
      "Fold: 2  Epoch: 389  Training loss = 3.1288  Validation loss = 3.2148  \n",
      "\n",
      "Fold: 2  Epoch: 390  Training loss = 3.1287  Validation loss = 3.2146  \n",
      "\n",
      "Fold: 2  Epoch: 391  Training loss = 3.1286  Validation loss = 3.2145  \n",
      "\n",
      "Fold: 2  Epoch: 392  Training loss = 3.1285  Validation loss = 3.2143  \n",
      "\n",
      "Fold: 2  Epoch: 393  Training loss = 3.1284  Validation loss = 3.2142  \n",
      "\n",
      "Fold: 2  Epoch: 394  Training loss = 3.1283  Validation loss = 3.2141  \n",
      "\n",
      "Fold: 2  Epoch: 395  Training loss = 3.1282  Validation loss = 3.2139  \n",
      "\n",
      "Fold: 2  Epoch: 396  Training loss = 3.1281  Validation loss = 3.2138  \n",
      "\n",
      "Fold: 2  Epoch: 397  Training loss = 3.1280  Validation loss = 3.2136  \n",
      "\n",
      "Fold: 2  Epoch: 398  Training loss = 3.1279  Validation loss = 3.2135  \n",
      "\n",
      "Fold: 2  Epoch: 399  Training loss = 3.1278  Validation loss = 3.2133  \n",
      "\n",
      "Fold: 2  Epoch: 400  Training loss = 3.1276  Validation loss = 3.2131  \n",
      "\n",
      "Fold: 2  Epoch: 401  Training loss = 3.1275  Validation loss = 3.2129  \n",
      "\n",
      "Fold: 2  Epoch: 402  Training loss = 3.1274  Validation loss = 3.2128  \n",
      "\n",
      "Fold: 2  Epoch: 403  Training loss = 3.1273  Validation loss = 3.2126  \n",
      "\n",
      "Fold: 2  Epoch: 404  Training loss = 3.1272  Validation loss = 3.2125  \n",
      "\n",
      "Fold: 2  Epoch: 405  Training loss = 3.1271  Validation loss = 3.2123  \n",
      "\n",
      "Fold: 2  Epoch: 406  Training loss = 3.1270  Validation loss = 3.2122  \n",
      "\n",
      "Fold: 2  Epoch: 407  Training loss = 3.1269  Validation loss = 3.2120  \n",
      "\n",
      "Fold: 2  Epoch: 408  Training loss = 3.1268  Validation loss = 3.2119  \n",
      "\n",
      "Fold: 2  Epoch: 409  Training loss = 3.1267  Validation loss = 3.2118  \n",
      "\n",
      "Fold: 2  Epoch: 410  Training loss = 3.1266  Validation loss = 3.2116  \n",
      "\n",
      "Fold: 2  Epoch: 411  Training loss = 3.1265  Validation loss = 3.2114  \n",
      "\n",
      "Fold: 2  Epoch: 412  Training loss = 3.1264  Validation loss = 3.2113  \n",
      "\n",
      "Fold: 2  Epoch: 413  Training loss = 3.1263  Validation loss = 3.2112  \n",
      "\n",
      "Fold: 2  Epoch: 414  Training loss = 3.1262  Validation loss = 3.2110  \n",
      "\n",
      "Fold: 2  Epoch: 415  Training loss = 3.1261  Validation loss = 3.2109  \n",
      "\n",
      "Fold: 2  Epoch: 416  Training loss = 3.1260  Validation loss = 3.2107  \n",
      "\n",
      "Fold: 2  Epoch: 417  Training loss = 3.1259  Validation loss = 3.2106  \n",
      "\n",
      "Fold: 2  Epoch: 418  Training loss = 3.1258  Validation loss = 3.2104  \n",
      "\n",
      "Fold: 2  Epoch: 419  Training loss = 3.1257  Validation loss = 3.2103  \n",
      "\n",
      "Fold: 2  Epoch: 420  Training loss = 3.1255  Validation loss = 3.2101  \n",
      "\n",
      "Fold: 2  Epoch: 421  Training loss = 3.1254  Validation loss = 3.2099  \n",
      "\n",
      "Fold: 2  Epoch: 422  Training loss = 3.1253  Validation loss = 3.2098  \n",
      "\n",
      "Fold: 2  Epoch: 423  Training loss = 3.1252  Validation loss = 3.2096  \n",
      "\n",
      "Fold: 2  Epoch: 424  Training loss = 3.1251  Validation loss = 3.2095  \n",
      "\n",
      "Fold: 2  Epoch: 425  Training loss = 3.1250  Validation loss = 3.2093  \n",
      "\n",
      "Fold: 2  Epoch: 426  Training loss = 3.1249  Validation loss = 3.2092  \n",
      "\n",
      "Fold: 2  Epoch: 427  Training loss = 3.1248  Validation loss = 3.2091  \n",
      "\n",
      "Fold: 2  Epoch: 428  Training loss = 3.1247  Validation loss = 3.2090  \n",
      "\n",
      "Fold: 2  Epoch: 429  Training loss = 3.1247  Validation loss = 3.2088  \n",
      "\n",
      "Fold: 2  Epoch: 430  Training loss = 3.1245  Validation loss = 3.2087  \n",
      "\n",
      "Fold: 2  Epoch: 431  Training loss = 3.1245  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 2  Epoch: 432  Training loss = 3.1244  Validation loss = 3.2084  \n",
      "\n",
      "Fold: 2  Epoch: 433  Training loss = 3.1243  Validation loss = 3.2083  \n",
      "\n",
      "Fold: 2  Epoch: 434  Training loss = 3.1242  Validation loss = 3.2082  \n",
      "\n",
      "Fold: 2  Epoch: 435  Training loss = 3.1241  Validation loss = 3.2081  \n",
      "\n",
      "Fold: 2  Epoch: 436  Training loss = 3.1240  Validation loss = 3.2079  \n",
      "\n",
      "Fold: 2  Epoch: 437  Training loss = 3.1239  Validation loss = 3.2078  \n",
      "\n",
      "Fold: 2  Epoch: 438  Training loss = 3.1238  Validation loss = 3.2076  \n",
      "\n",
      "Fold: 2  Epoch: 439  Training loss = 3.1237  Validation loss = 3.2075  \n",
      "\n",
      "Fold: 2  Epoch: 440  Training loss = 3.1236  Validation loss = 3.2073  \n",
      "\n",
      "Fold: 2  Epoch: 441  Training loss = 3.1235  Validation loss = 3.2071  \n",
      "\n",
      "Fold: 2  Epoch: 442  Training loss = 3.1234  Validation loss = 3.2070  \n",
      "\n",
      "Fold: 2  Epoch: 443  Training loss = 3.1233  Validation loss = 3.2069  \n",
      "\n",
      "Fold: 2  Epoch: 444  Training loss = 3.1232  Validation loss = 3.2067  \n",
      "\n",
      "Fold: 2  Epoch: 445  Training loss = 3.1231  Validation loss = 3.2066  \n",
      "\n",
      "Fold: 2  Epoch: 446  Training loss = 3.1230  Validation loss = 3.2065  \n",
      "\n",
      "Fold: 2  Epoch: 447  Training loss = 3.1229  Validation loss = 3.2063  \n",
      "\n",
      "Fold: 2  Epoch: 448  Training loss = 3.1228  Validation loss = 3.2061  \n",
      "\n",
      "Fold: 2  Epoch: 449  Training loss = 3.1226  Validation loss = 3.2059  \n",
      "\n",
      "Fold: 2  Epoch: 450  Training loss = 3.1225  Validation loss = 3.2058  \n",
      "\n",
      "Fold: 2  Epoch: 451  Training loss = 3.1224  Validation loss = 3.2056  \n",
      "\n",
      "Fold: 2  Epoch: 452  Training loss = 3.1223  Validation loss = 3.2055  \n",
      "\n",
      "Fold: 2  Epoch: 453  Training loss = 3.1222  Validation loss = 3.2053  \n",
      "\n",
      "Fold: 2  Epoch: 454  Training loss = 3.1221  Validation loss = 3.2052  \n",
      "\n",
      "Fold: 2  Epoch: 455  Training loss = 3.1220  Validation loss = 3.2050  \n",
      "\n",
      "Fold: 2  Epoch: 456  Training loss = 3.1219  Validation loss = 3.2049  \n",
      "\n",
      "Fold: 2  Epoch: 457  Training loss = 3.1219  Validation loss = 3.2048  \n",
      "\n",
      "Fold: 2  Epoch: 458  Training loss = 3.1218  Validation loss = 3.2046  \n",
      "\n",
      "Fold: 2  Epoch: 459  Training loss = 3.1216  Validation loss = 3.2045  \n",
      "\n",
      "Fold: 2  Epoch: 460  Training loss = 3.1215  Validation loss = 3.2043  \n",
      "\n",
      "Fold: 2  Epoch: 461  Training loss = 3.1215  Validation loss = 3.2042  \n",
      "\n",
      "Fold: 2  Epoch: 462  Training loss = 3.1213  Validation loss = 3.2040  \n",
      "\n",
      "Fold: 2  Epoch: 463  Training loss = 3.1212  Validation loss = 3.2038  \n",
      "\n",
      "Fold: 2  Epoch: 464  Training loss = 3.1211  Validation loss = 3.2036  \n",
      "\n",
      "Fold: 2  Epoch: 465  Training loss = 3.1210  Validation loss = 3.2035  \n",
      "\n",
      "Fold: 2  Epoch: 466  Training loss = 3.1209  Validation loss = 3.2033  \n",
      "\n",
      "Fold: 2  Epoch: 467  Training loss = 3.1208  Validation loss = 3.2032  \n",
      "\n",
      "Fold: 2  Epoch: 468  Training loss = 3.1207  Validation loss = 3.2031  \n",
      "\n",
      "Fold: 2  Epoch: 469  Training loss = 3.1207  Validation loss = 3.2030  \n",
      "\n",
      "Fold: 2  Epoch: 470  Training loss = 3.1206  Validation loss = 3.2029  \n",
      "\n",
      "Fold: 2  Epoch: 471  Training loss = 3.1205  Validation loss = 3.2027  \n",
      "\n",
      "Fold: 2  Epoch: 472  Training loss = 3.1203  Validation loss = 3.2026  \n",
      "\n",
      "Fold: 2  Epoch: 473  Training loss = 3.1203  Validation loss = 3.2024  \n",
      "\n",
      "Fold: 2  Epoch: 474  Training loss = 3.1202  Validation loss = 3.2023  \n",
      "\n",
      "Fold: 2  Epoch: 475  Training loss = 3.1201  Validation loss = 3.2022  \n",
      "\n",
      "Fold: 2  Epoch: 476  Training loss = 3.1200  Validation loss = 3.2020  \n",
      "\n",
      "Fold: 2  Epoch: 477  Training loss = 3.1199  Validation loss = 3.2019  \n",
      "\n",
      "Fold: 2  Epoch: 478  Training loss = 3.1198  Validation loss = 3.2018  \n",
      "\n",
      "Fold: 2  Epoch: 479  Training loss = 3.1197  Validation loss = 3.2017  \n",
      "\n",
      "Fold: 2  Epoch: 480  Training loss = 3.1196  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 2  Epoch: 481  Training loss = 3.1194  Validation loss = 3.2013  \n",
      "\n",
      "Fold: 2  Epoch: 482  Training loss = 3.1193  Validation loss = 3.2011  \n",
      "\n",
      "Fold: 2  Epoch: 483  Training loss = 3.1192  Validation loss = 3.2010  \n",
      "\n",
      "Fold: 2  Epoch: 484  Training loss = 3.1192  Validation loss = 3.2009  \n",
      "\n",
      "Fold: 2  Epoch: 485  Training loss = 3.1191  Validation loss = 3.2007  \n",
      "\n",
      "Fold: 2  Epoch: 486  Training loss = 3.1190  Validation loss = 3.2006  \n",
      "\n",
      "Fold: 2  Epoch: 487  Training loss = 3.1188  Validation loss = 3.2004  \n",
      "\n",
      "Fold: 2  Epoch: 488  Training loss = 3.1187  Validation loss = 3.2003  \n",
      "\n",
      "Fold: 2  Epoch: 489  Training loss = 3.1186  Validation loss = 3.2001  \n",
      "\n",
      "Fold: 2  Epoch: 490  Training loss = 3.1186  Validation loss = 3.2000  \n",
      "\n",
      "Fold: 2  Epoch: 491  Training loss = 3.1185  Validation loss = 3.1999  \n",
      "\n",
      "Fold: 2  Epoch: 492  Training loss = 3.1184  Validation loss = 3.1998  \n",
      "\n",
      "Fold: 2  Epoch: 493  Training loss = 3.1183  Validation loss = 3.1996  \n",
      "\n",
      "Fold: 2  Epoch: 494  Training loss = 3.1182  Validation loss = 3.1995  \n",
      "\n",
      "Fold: 2  Epoch: 495  Training loss = 3.1181  Validation loss = 3.1993  \n",
      "\n",
      "Fold: 2  Epoch: 496  Training loss = 3.1180  Validation loss = 3.1992  \n",
      "\n",
      "Fold: 2  Epoch: 497  Training loss = 3.1179  Validation loss = 3.1991  \n",
      "\n",
      "Fold: 2  Epoch: 498  Training loss = 3.1178  Validation loss = 3.1989  \n",
      "\n",
      "Fold: 2  Epoch: 499  Training loss = 3.1177  Validation loss = 3.1988  \n",
      "\n",
      "Fold: 2  Epoch: 500  Training loss = 3.1176  Validation loss = 3.1987  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 500  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 2.1389  Validation loss = 4.5858  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 2.1388  Validation loss = 4.5857  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 2.1387  Validation loss = 4.5856  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 2.1386  Validation loss = 4.5854  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 2.1385  Validation loss = 4.5853  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 2.1384  Validation loss = 4.5852  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 2.1383  Validation loss = 4.5850  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 2.1382  Validation loss = 4.5848  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 2.1381  Validation loss = 4.5846  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 2.1380  Validation loss = 4.5845  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 2.1379  Validation loss = 4.5844  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 2.1378  Validation loss = 4.5842  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 2.1376  Validation loss = 4.5841  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 2.1376  Validation loss = 4.5839  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 2.1374  Validation loss = 4.5837  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 2.1373  Validation loss = 4.5836  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 2.1372  Validation loss = 4.5834  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 2.1371  Validation loss = 4.5833  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 2.1370  Validation loss = 4.5831  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 2.1369  Validation loss = 4.5830  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 2.1368  Validation loss = 4.5828  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 2.1367  Validation loss = 4.5826  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 2.1366  Validation loss = 4.5825  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 2.1364  Validation loss = 4.5822  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 2.1363  Validation loss = 4.5821  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 2.1362  Validation loss = 4.5819  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 2.1361  Validation loss = 4.5818  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 2.1360  Validation loss = 4.5816  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 2.1359  Validation loss = 4.5815  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 2.1358  Validation loss = 4.5814  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 2.1357  Validation loss = 4.5812  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 2.1356  Validation loss = 4.5811  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 2.1355  Validation loss = 4.5810  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 2.1354  Validation loss = 4.5808  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 2.1353  Validation loss = 4.5806  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 2.1352  Validation loss = 4.5805  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 2.1351  Validation loss = 4.5803  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 2.1350  Validation loss = 4.5802  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 2.1349  Validation loss = 4.5800  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 2.1348  Validation loss = 4.5799  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 2.1346  Validation loss = 4.5797  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 2.1345  Validation loss = 4.5795  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 2.1344  Validation loss = 4.5794  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 2.1343  Validation loss = 4.5792  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 2.1342  Validation loss = 4.5790  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 2.1341  Validation loss = 4.5789  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 2.1340  Validation loss = 4.5788  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 2.1339  Validation loss = 4.5786  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 2.1338  Validation loss = 4.5785  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 2.1337  Validation loss = 4.5783  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 2.1336  Validation loss = 4.5781  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 2.1335  Validation loss = 4.5780  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 2.1334  Validation loss = 4.5779  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 2.1333  Validation loss = 4.5778  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 2.1332  Validation loss = 4.5776  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 2.1331  Validation loss = 4.5775  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 2.1329  Validation loss = 4.5773  \n",
      "\n",
      "Fold: 3  Epoch: 58  Training loss = 2.1328  Validation loss = 4.5771  \n",
      "\n",
      "Fold: 3  Epoch: 59  Training loss = 2.1327  Validation loss = 4.5770  \n",
      "\n",
      "Fold: 3  Epoch: 60  Training loss = 2.1326  Validation loss = 4.5768  \n",
      "\n",
      "Fold: 3  Epoch: 61  Training loss = 2.1325  Validation loss = 4.5767  \n",
      "\n",
      "Fold: 3  Epoch: 62  Training loss = 2.1324  Validation loss = 4.5765  \n",
      "\n",
      "Fold: 3  Epoch: 63  Training loss = 2.1323  Validation loss = 4.5764  \n",
      "\n",
      "Fold: 3  Epoch: 64  Training loss = 2.1322  Validation loss = 4.5762  \n",
      "\n",
      "Fold: 3  Epoch: 65  Training loss = 2.1321  Validation loss = 4.5761  \n",
      "\n",
      "Fold: 3  Epoch: 66  Training loss = 2.1320  Validation loss = 4.5759  \n",
      "\n",
      "Fold: 3  Epoch: 67  Training loss = 2.1319  Validation loss = 4.5758  \n",
      "\n",
      "Fold: 3  Epoch: 68  Training loss = 2.1318  Validation loss = 4.5757  \n",
      "\n",
      "Fold: 3  Epoch: 69  Training loss = 2.1317  Validation loss = 4.5755  \n",
      "\n",
      "Fold: 3  Epoch: 70  Training loss = 2.1316  Validation loss = 4.5754  \n",
      "\n",
      "Fold: 3  Epoch: 71  Training loss = 2.1315  Validation loss = 4.5752  \n",
      "\n",
      "Fold: 3  Epoch: 72  Training loss = 2.1314  Validation loss = 4.5751  \n",
      "\n",
      "Fold: 3  Epoch: 73  Training loss = 2.1313  Validation loss = 4.5749  \n",
      "\n",
      "Fold: 3  Epoch: 74  Training loss = 2.1312  Validation loss = 4.5748  \n",
      "\n",
      "Fold: 3  Epoch: 75  Training loss = 2.1311  Validation loss = 4.5746  \n",
      "\n",
      "Fold: 3  Epoch: 76  Training loss = 2.1310  Validation loss = 4.5745  \n",
      "\n",
      "Fold: 3  Epoch: 77  Training loss = 2.1309  Validation loss = 4.5743  \n",
      "\n",
      "Fold: 3  Epoch: 78  Training loss = 2.1308  Validation loss = 4.5742  \n",
      "\n",
      "Fold: 3  Epoch: 79  Training loss = 2.1307  Validation loss = 4.5740  \n",
      "\n",
      "Fold: 3  Epoch: 80  Training loss = 2.1306  Validation loss = 4.5739  \n",
      "\n",
      "Fold: 3  Epoch: 81  Training loss = 2.1305  Validation loss = 4.5737  \n",
      "\n",
      "Fold: 3  Epoch: 82  Training loss = 2.1304  Validation loss = 4.5735  \n",
      "\n",
      "Fold: 3  Epoch: 83  Training loss = 2.1303  Validation loss = 4.5734  \n",
      "\n",
      "Fold: 3  Epoch: 84  Training loss = 2.1302  Validation loss = 4.5732  \n",
      "\n",
      "Fold: 3  Epoch: 85  Training loss = 2.1301  Validation loss = 4.5731  \n",
      "\n",
      "Fold: 3  Epoch: 86  Training loss = 2.1300  Validation loss = 4.5730  \n",
      "\n",
      "Fold: 3  Epoch: 87  Training loss = 2.1299  Validation loss = 4.5728  \n",
      "\n",
      "Fold: 3  Epoch: 88  Training loss = 2.1297  Validation loss = 4.5727  \n",
      "\n",
      "Fold: 3  Epoch: 89  Training loss = 2.1296  Validation loss = 4.5725  \n",
      "\n",
      "Fold: 3  Epoch: 90  Training loss = 2.1295  Validation loss = 4.5723  \n",
      "\n",
      "Fold: 3  Epoch: 91  Training loss = 2.1294  Validation loss = 4.5722  \n",
      "\n",
      "Fold: 3  Epoch: 92  Training loss = 2.1293  Validation loss = 4.5721  \n",
      "\n",
      "Fold: 3  Epoch: 93  Training loss = 2.1292  Validation loss = 4.5720  \n",
      "\n",
      "Fold: 3  Epoch: 94  Training loss = 2.1291  Validation loss = 4.5718  \n",
      "\n",
      "Fold: 3  Epoch: 95  Training loss = 2.1291  Validation loss = 4.5717  \n",
      "\n",
      "Fold: 3  Epoch: 96  Training loss = 2.1289  Validation loss = 4.5715  \n",
      "\n",
      "Fold: 3  Epoch: 97  Training loss = 2.1288  Validation loss = 4.5713  \n",
      "\n",
      "Fold: 3  Epoch: 98  Training loss = 2.1288  Validation loss = 4.5712  \n",
      "\n",
      "Fold: 3  Epoch: 99  Training loss = 2.1287  Validation loss = 4.5711  \n",
      "\n",
      "Fold: 3  Epoch: 100  Training loss = 2.1286  Validation loss = 4.5710  \n",
      "\n",
      "Fold: 3  Epoch: 101  Training loss = 2.1285  Validation loss = 4.5708  \n",
      "\n",
      "Fold: 3  Epoch: 102  Training loss = 2.1284  Validation loss = 4.5707  \n",
      "\n",
      "Fold: 3  Epoch: 103  Training loss = 2.1282  Validation loss = 4.5705  \n",
      "\n",
      "Fold: 3  Epoch: 104  Training loss = 2.1281  Validation loss = 4.5703  \n",
      "\n",
      "Fold: 3  Epoch: 105  Training loss = 2.1280  Validation loss = 4.5702  \n",
      "\n",
      "Fold: 3  Epoch: 106  Training loss = 2.1279  Validation loss = 4.5700  \n",
      "\n",
      "Fold: 3  Epoch: 107  Training loss = 2.1278  Validation loss = 4.5698  \n",
      "\n",
      "Fold: 3  Epoch: 108  Training loss = 2.1277  Validation loss = 4.5697  \n",
      "\n",
      "Fold: 3  Epoch: 109  Training loss = 2.1276  Validation loss = 4.5696  \n",
      "\n",
      "Fold: 3  Epoch: 110  Training loss = 2.1275  Validation loss = 4.5694  \n",
      "\n",
      "Fold: 3  Epoch: 111  Training loss = 2.1274  Validation loss = 4.5692  \n",
      "\n",
      "Fold: 3  Epoch: 112  Training loss = 2.1273  Validation loss = 4.5691  \n",
      "\n",
      "Fold: 3  Epoch: 113  Training loss = 2.1272  Validation loss = 4.5690  \n",
      "\n",
      "Fold: 3  Epoch: 114  Training loss = 2.1271  Validation loss = 4.5688  \n",
      "\n",
      "Fold: 3  Epoch: 115  Training loss = 2.1270  Validation loss = 4.5687  \n",
      "\n",
      "Fold: 3  Epoch: 116  Training loss = 2.1269  Validation loss = 4.5685  \n",
      "\n",
      "Fold: 3  Epoch: 117  Training loss = 2.1268  Validation loss = 4.5684  \n",
      "\n",
      "Fold: 3  Epoch: 118  Training loss = 2.1267  Validation loss = 4.5682  \n",
      "\n",
      "Fold: 3  Epoch: 119  Training loss = 2.1265  Validation loss = 4.5680  \n",
      "\n",
      "Fold: 3  Epoch: 120  Training loss = 2.1265  Validation loss = 4.5679  \n",
      "\n",
      "Fold: 3  Epoch: 121  Training loss = 2.1264  Validation loss = 4.5678  \n",
      "\n",
      "Fold: 3  Epoch: 122  Training loss = 2.1263  Validation loss = 4.5676  \n",
      "\n",
      "Fold: 3  Epoch: 123  Training loss = 2.1262  Validation loss = 4.5674  \n",
      "\n",
      "Fold: 3  Epoch: 124  Training loss = 2.1261  Validation loss = 4.5673  \n",
      "\n",
      "Fold: 3  Epoch: 125  Training loss = 2.1260  Validation loss = 4.5671  \n",
      "\n",
      "Fold: 3  Epoch: 126  Training loss = 2.1259  Validation loss = 4.5670  \n",
      "\n",
      "Fold: 3  Epoch: 127  Training loss = 2.1258  Validation loss = 4.5669  \n",
      "\n",
      "Fold: 3  Epoch: 128  Training loss = 2.1256  Validation loss = 4.5667  \n",
      "\n",
      "Fold: 3  Epoch: 129  Training loss = 2.1256  Validation loss = 4.5666  \n",
      "\n",
      "Fold: 3  Epoch: 130  Training loss = 2.1254  Validation loss = 4.5664  \n",
      "\n",
      "Fold: 3  Epoch: 131  Training loss = 2.1253  Validation loss = 4.5663  \n",
      "\n",
      "Fold: 3  Epoch: 132  Training loss = 2.1252  Validation loss = 4.5661  \n",
      "\n",
      "Fold: 3  Epoch: 133  Training loss = 2.1251  Validation loss = 4.5660  \n",
      "\n",
      "Fold: 3  Epoch: 134  Training loss = 2.1250  Validation loss = 4.5658  \n",
      "\n",
      "Fold: 3  Epoch: 135  Training loss = 2.1250  Validation loss = 4.5657  \n",
      "\n",
      "Fold: 3  Epoch: 136  Training loss = 2.1248  Validation loss = 4.5656  \n",
      "\n",
      "Fold: 3  Epoch: 137  Training loss = 2.1248  Validation loss = 4.5655  \n",
      "\n",
      "Fold: 3  Epoch: 138  Training loss = 2.1246  Validation loss = 4.5653  \n",
      "\n",
      "Fold: 3  Epoch: 139  Training loss = 2.1245  Validation loss = 4.5651  \n",
      "\n",
      "Fold: 3  Epoch: 140  Training loss = 2.1244  Validation loss = 4.5650  \n",
      "\n",
      "Fold: 3  Epoch: 141  Training loss = 2.1243  Validation loss = 4.5648  \n",
      "\n",
      "Fold: 3  Epoch: 142  Training loss = 2.1242  Validation loss = 4.5647  \n",
      "\n",
      "Fold: 3  Epoch: 143  Training loss = 2.1241  Validation loss = 4.5646  \n",
      "\n",
      "Fold: 3  Epoch: 144  Training loss = 2.1240  Validation loss = 4.5644  \n",
      "\n",
      "Fold: 3  Epoch: 145  Training loss = 2.1239  Validation loss = 4.5642  \n",
      "\n",
      "Fold: 3  Epoch: 146  Training loss = 2.1238  Validation loss = 4.5640  \n",
      "\n",
      "Fold: 3  Epoch: 147  Training loss = 2.1237  Validation loss = 4.5639  \n",
      "\n",
      "Fold: 3  Epoch: 148  Training loss = 2.1236  Validation loss = 4.5637  \n",
      "\n",
      "Fold: 3  Epoch: 149  Training loss = 2.1235  Validation loss = 4.5636  \n",
      "\n",
      "Fold: 3  Epoch: 150  Training loss = 2.1234  Validation loss = 4.5635  \n",
      "\n",
      "Fold: 3  Epoch: 151  Training loss = 2.1233  Validation loss = 4.5633  \n",
      "\n",
      "Fold: 3  Epoch: 152  Training loss = 2.1232  Validation loss = 4.5632  \n",
      "\n",
      "Fold: 3  Epoch: 153  Training loss = 2.1231  Validation loss = 4.5630  \n",
      "\n",
      "Fold: 3  Epoch: 154  Training loss = 2.1230  Validation loss = 4.5628  \n",
      "\n",
      "Fold: 3  Epoch: 155  Training loss = 2.1229  Validation loss = 4.5626  \n",
      "\n",
      "Fold: 3  Epoch: 156  Training loss = 2.1227  Validation loss = 4.5625  \n",
      "\n",
      "Fold: 3  Epoch: 157  Training loss = 2.1226  Validation loss = 4.5623  \n",
      "\n",
      "Fold: 3  Epoch: 158  Training loss = 2.1225  Validation loss = 4.5621  \n",
      "\n",
      "Fold: 3  Epoch: 159  Training loss = 2.1224  Validation loss = 4.5620  \n",
      "\n",
      "Fold: 3  Epoch: 160  Training loss = 2.1223  Validation loss = 4.5618  \n",
      "\n",
      "Fold: 3  Epoch: 161  Training loss = 2.1222  Validation loss = 4.5616  \n",
      "\n",
      "Fold: 3  Epoch: 162  Training loss = 2.1221  Validation loss = 4.5615  \n",
      "\n",
      "Fold: 3  Epoch: 163  Training loss = 2.1220  Validation loss = 4.5613  \n",
      "\n",
      "Fold: 3  Epoch: 164  Training loss = 2.1219  Validation loss = 4.5611  \n",
      "\n",
      "Fold: 3  Epoch: 165  Training loss = 2.1218  Validation loss = 4.5610  \n",
      "\n",
      "Fold: 3  Epoch: 166  Training loss = 2.1217  Validation loss = 4.5608  \n",
      "\n",
      "Fold: 3  Epoch: 167  Training loss = 2.1215  Validation loss = 4.5606  \n",
      "\n",
      "Fold: 3  Epoch: 168  Training loss = 2.1215  Validation loss = 4.5605  \n",
      "\n",
      "Fold: 3  Epoch: 169  Training loss = 2.1213  Validation loss = 4.5603  \n",
      "\n",
      "Fold: 3  Epoch: 170  Training loss = 2.1212  Validation loss = 4.5602  \n",
      "\n",
      "Fold: 3  Epoch: 171  Training loss = 2.1211  Validation loss = 4.5600  \n",
      "\n",
      "Fold: 3  Epoch: 172  Training loss = 2.1210  Validation loss = 4.5599  \n",
      "\n",
      "Fold: 3  Epoch: 173  Training loss = 2.1209  Validation loss = 4.5597  \n",
      "\n",
      "Fold: 3  Epoch: 174  Training loss = 2.1208  Validation loss = 4.5596  \n",
      "\n",
      "Fold: 3  Epoch: 175  Training loss = 2.1207  Validation loss = 4.5594  \n",
      "\n",
      "Fold: 3  Epoch: 176  Training loss = 2.1206  Validation loss = 4.5592  \n",
      "\n",
      "Fold: 3  Epoch: 177  Training loss = 2.1205  Validation loss = 4.5591  \n",
      "\n",
      "Fold: 3  Epoch: 178  Training loss = 2.1204  Validation loss = 4.5590  \n",
      "\n",
      "Fold: 3  Epoch: 179  Training loss = 2.1203  Validation loss = 4.5588  \n",
      "\n",
      "Fold: 3  Epoch: 180  Training loss = 2.1202  Validation loss = 4.5587  \n",
      "\n",
      "Fold: 3  Epoch: 181  Training loss = 2.1201  Validation loss = 4.5586  \n",
      "\n",
      "Fold: 3  Epoch: 182  Training loss = 2.1200  Validation loss = 4.5584  \n",
      "\n",
      "Fold: 3  Epoch: 183  Training loss = 2.1199  Validation loss = 4.5583  \n",
      "\n",
      "Fold: 3  Epoch: 184  Training loss = 2.1198  Validation loss = 4.5581  \n",
      "\n",
      "Fold: 3  Epoch: 185  Training loss = 2.1197  Validation loss = 4.5580  \n",
      "\n",
      "Fold: 3  Epoch: 186  Training loss = 2.1196  Validation loss = 4.5578  \n",
      "\n",
      "Fold: 3  Epoch: 187  Training loss = 2.1195  Validation loss = 4.5577  \n",
      "\n",
      "Fold: 3  Epoch: 188  Training loss = 2.1194  Validation loss = 4.5575  \n",
      "\n",
      "Fold: 3  Epoch: 189  Training loss = 2.1193  Validation loss = 4.5574  \n",
      "\n",
      "Fold: 3  Epoch: 190  Training loss = 2.1192  Validation loss = 4.5572  \n",
      "\n",
      "Fold: 3  Epoch: 191  Training loss = 2.1191  Validation loss = 4.5571  \n",
      "\n",
      "Fold: 3  Epoch: 192  Training loss = 2.1190  Validation loss = 4.5570  \n",
      "\n",
      "Fold: 3  Epoch: 193  Training loss = 2.1189  Validation loss = 4.5568  \n",
      "\n",
      "Fold: 3  Epoch: 194  Training loss = 2.1188  Validation loss = 4.5567  \n",
      "\n",
      "Fold: 3  Epoch: 195  Training loss = 2.1187  Validation loss = 4.5565  \n",
      "\n",
      "Fold: 3  Epoch: 196  Training loss = 2.1186  Validation loss = 4.5564  \n",
      "\n",
      "Fold: 3  Epoch: 197  Training loss = 2.1185  Validation loss = 4.5562  \n",
      "\n",
      "Fold: 3  Epoch: 198  Training loss = 2.1184  Validation loss = 4.5560  \n",
      "\n",
      "Fold: 3  Epoch: 199  Training loss = 2.1183  Validation loss = 4.5559  \n",
      "\n",
      "Fold: 3  Epoch: 200  Training loss = 2.1182  Validation loss = 4.5558  \n",
      "\n",
      "Fold: 3  Epoch: 201  Training loss = 2.1181  Validation loss = 4.5556  \n",
      "\n",
      "Fold: 3  Epoch: 202  Training loss = 2.1180  Validation loss = 4.5554  \n",
      "\n",
      "Fold: 3  Epoch: 203  Training loss = 2.1179  Validation loss = 4.5553  \n",
      "\n",
      "Fold: 3  Epoch: 204  Training loss = 2.1178  Validation loss = 4.5552  \n",
      "\n",
      "Fold: 3  Epoch: 205  Training loss = 2.1177  Validation loss = 4.5550  \n",
      "\n",
      "Fold: 3  Epoch: 206  Training loss = 2.1176  Validation loss = 4.5549  \n",
      "\n",
      "Fold: 3  Epoch: 207  Training loss = 2.1175  Validation loss = 4.5547  \n",
      "\n",
      "Fold: 3  Epoch: 208  Training loss = 2.1174  Validation loss = 4.5546  \n",
      "\n",
      "Fold: 3  Epoch: 209  Training loss = 2.1173  Validation loss = 4.5544  \n",
      "\n",
      "Fold: 3  Epoch: 210  Training loss = 2.1172  Validation loss = 4.5543  \n",
      "\n",
      "Fold: 3  Epoch: 211  Training loss = 2.1171  Validation loss = 4.5541  \n",
      "\n",
      "Fold: 3  Epoch: 212  Training loss = 2.1170  Validation loss = 4.5540  \n",
      "\n",
      "Fold: 3  Epoch: 213  Training loss = 2.1169  Validation loss = 4.5538  \n",
      "\n",
      "Fold: 3  Epoch: 214  Training loss = 2.1168  Validation loss = 4.5537  \n",
      "\n",
      "Fold: 3  Epoch: 215  Training loss = 2.1167  Validation loss = 4.5535  \n",
      "\n",
      "Fold: 3  Epoch: 216  Training loss = 2.1166  Validation loss = 4.5534  \n",
      "\n",
      "Fold: 3  Epoch: 217  Training loss = 2.1165  Validation loss = 4.5533  \n",
      "\n",
      "Fold: 3  Epoch: 218  Training loss = 2.1164  Validation loss = 4.5531  \n",
      "\n",
      "Fold: 3  Epoch: 219  Training loss = 2.1162  Validation loss = 4.5529  \n",
      "\n",
      "Fold: 3  Epoch: 220  Training loss = 2.1162  Validation loss = 4.5528  \n",
      "\n",
      "Fold: 3  Epoch: 221  Training loss = 2.1161  Validation loss = 4.5527  \n",
      "\n",
      "Fold: 3  Epoch: 222  Training loss = 2.1160  Validation loss = 4.5526  \n",
      "\n",
      "Fold: 3  Epoch: 223  Training loss = 2.1159  Validation loss = 4.5524  \n",
      "\n",
      "Fold: 3  Epoch: 224  Training loss = 2.1158  Validation loss = 4.5523  \n",
      "\n",
      "Fold: 3  Epoch: 225  Training loss = 2.1156  Validation loss = 4.5521  \n",
      "\n",
      "Fold: 3  Epoch: 226  Training loss = 2.1155  Validation loss = 4.5519  \n",
      "\n",
      "Fold: 3  Epoch: 227  Training loss = 2.1154  Validation loss = 4.5518  \n",
      "\n",
      "Fold: 3  Epoch: 228  Training loss = 2.1153  Validation loss = 4.5516  \n",
      "\n",
      "Fold: 3  Epoch: 229  Training loss = 2.1152  Validation loss = 4.5515  \n",
      "\n",
      "Fold: 3  Epoch: 230  Training loss = 2.1151  Validation loss = 4.5513  \n",
      "\n",
      "Fold: 3  Epoch: 231  Training loss = 2.1150  Validation loss = 4.5511  \n",
      "\n",
      "Fold: 3  Epoch: 232  Training loss = 2.1149  Validation loss = 4.5510  \n",
      "\n",
      "Fold: 3  Epoch: 233  Training loss = 2.1148  Validation loss = 4.5509  \n",
      "\n",
      "Fold: 3  Epoch: 234  Training loss = 2.1147  Validation loss = 4.5507  \n",
      "\n",
      "Fold: 3  Epoch: 235  Training loss = 2.1146  Validation loss = 4.5506  \n",
      "\n",
      "Fold: 3  Epoch: 236  Training loss = 2.1145  Validation loss = 4.5504  \n",
      "\n",
      "Fold: 3  Epoch: 237  Training loss = 2.1144  Validation loss = 4.5503  \n",
      "\n",
      "Fold: 3  Epoch: 238  Training loss = 2.1143  Validation loss = 4.5501  \n",
      "\n",
      "Fold: 3  Epoch: 239  Training loss = 2.1142  Validation loss = 4.5500  \n",
      "\n",
      "Fold: 3  Epoch: 240  Training loss = 2.1141  Validation loss = 4.5498  \n",
      "\n",
      "Fold: 3  Epoch: 241  Training loss = 2.1140  Validation loss = 4.5497  \n",
      "\n",
      "Fold: 3  Epoch: 242  Training loss = 2.1139  Validation loss = 4.5495  \n",
      "\n",
      "Fold: 3  Epoch: 243  Training loss = 2.1138  Validation loss = 4.5493  \n",
      "\n",
      "Fold: 3  Epoch: 244  Training loss = 2.1137  Validation loss = 4.5492  \n",
      "\n",
      "Fold: 3  Epoch: 245  Training loss = 2.1136  Validation loss = 4.5490  \n",
      "\n",
      "Fold: 3  Epoch: 246  Training loss = 2.1135  Validation loss = 4.5489  \n",
      "\n",
      "Fold: 3  Epoch: 247  Training loss = 2.1133  Validation loss = 4.5487  \n",
      "\n",
      "Fold: 3  Epoch: 248  Training loss = 2.1132  Validation loss = 4.5485  \n",
      "\n",
      "Fold: 3  Epoch: 249  Training loss = 2.1131  Validation loss = 4.5484  \n",
      "\n",
      "Fold: 3  Epoch: 250  Training loss = 2.1130  Validation loss = 4.5482  \n",
      "\n",
      "Fold: 3  Epoch: 251  Training loss = 2.1129  Validation loss = 4.5480  \n",
      "\n",
      "Fold: 3  Epoch: 252  Training loss = 2.1128  Validation loss = 4.5479  \n",
      "\n",
      "Fold: 3  Epoch: 253  Training loss = 2.1127  Validation loss = 4.5478  \n",
      "\n",
      "Fold: 3  Epoch: 254  Training loss = 2.1127  Validation loss = 4.5477  \n",
      "\n",
      "Fold: 3  Epoch: 255  Training loss = 2.1126  Validation loss = 4.5475  \n",
      "\n",
      "Fold: 3  Epoch: 256  Training loss = 2.1125  Validation loss = 4.5474  \n",
      "\n",
      "Fold: 3  Epoch: 257  Training loss = 2.1123  Validation loss = 4.5472  \n",
      "\n",
      "Fold: 3  Epoch: 258  Training loss = 2.1122  Validation loss = 4.5471  \n",
      "\n",
      "Fold: 3  Epoch: 259  Training loss = 2.1121  Validation loss = 4.5469  \n",
      "\n",
      "Fold: 3  Epoch: 260  Training loss = 2.1120  Validation loss = 4.5468  \n",
      "\n",
      "Fold: 3  Epoch: 261  Training loss = 2.1120  Validation loss = 4.5467  \n",
      "\n",
      "Fold: 3  Epoch: 262  Training loss = 2.1119  Validation loss = 4.5465  \n",
      "\n",
      "Fold: 3  Epoch: 263  Training loss = 2.1118  Validation loss = 4.5464  \n",
      "\n",
      "Fold: 3  Epoch: 264  Training loss = 2.1117  Validation loss = 4.5463  \n",
      "\n",
      "Fold: 3  Epoch: 265  Training loss = 2.1116  Validation loss = 4.5461  \n",
      "\n",
      "Fold: 3  Epoch: 266  Training loss = 2.1115  Validation loss = 4.5460  \n",
      "\n",
      "Fold: 3  Epoch: 267  Training loss = 2.1114  Validation loss = 4.5459  \n",
      "\n",
      "Fold: 3  Epoch: 268  Training loss = 2.1113  Validation loss = 4.5457  \n",
      "\n",
      "Fold: 3  Epoch: 269  Training loss = 2.1112  Validation loss = 4.5455  \n",
      "\n",
      "Fold: 3  Epoch: 270  Training loss = 2.1111  Validation loss = 4.5454  \n",
      "\n",
      "Fold: 3  Epoch: 271  Training loss = 2.1110  Validation loss = 4.5452  \n",
      "\n",
      "Fold: 3  Epoch: 272  Training loss = 2.1109  Validation loss = 4.5451  \n",
      "\n",
      "Fold: 3  Epoch: 273  Training loss = 2.1108  Validation loss = 4.5450  \n",
      "\n",
      "Fold: 3  Epoch: 274  Training loss = 2.1107  Validation loss = 4.5448  \n",
      "\n",
      "Fold: 3  Epoch: 275  Training loss = 2.1106  Validation loss = 4.5446  \n",
      "\n",
      "Fold: 3  Epoch: 276  Training loss = 2.1105  Validation loss = 4.5445  \n",
      "\n",
      "Fold: 3  Epoch: 277  Training loss = 2.1104  Validation loss = 4.5443  \n",
      "\n",
      "Fold: 3  Epoch: 278  Training loss = 2.1103  Validation loss = 4.5442  \n",
      "\n",
      "Fold: 3  Epoch: 279  Training loss = 2.1102  Validation loss = 4.5440  \n",
      "\n",
      "Fold: 3  Epoch: 280  Training loss = 2.1101  Validation loss = 4.5439  \n",
      "\n",
      "Fold: 3  Epoch: 281  Training loss = 2.1100  Validation loss = 4.5438  \n",
      "\n",
      "Fold: 3  Epoch: 282  Training loss = 2.1099  Validation loss = 4.5436  \n",
      "\n",
      "Fold: 3  Epoch: 283  Training loss = 2.1098  Validation loss = 4.5435  \n",
      "\n",
      "Fold: 3  Epoch: 284  Training loss = 2.1097  Validation loss = 4.5433  \n",
      "\n",
      "Fold: 3  Epoch: 285  Training loss = 2.1096  Validation loss = 4.5432  \n",
      "\n",
      "Fold: 3  Epoch: 286  Training loss = 2.1095  Validation loss = 4.5430  \n",
      "\n",
      "Fold: 3  Epoch: 287  Training loss = 2.1094  Validation loss = 4.5429  \n",
      "\n",
      "Fold: 3  Epoch: 288  Training loss = 2.1093  Validation loss = 4.5428  \n",
      "\n",
      "Fold: 3  Epoch: 289  Training loss = 2.1092  Validation loss = 4.5426  \n",
      "\n",
      "Fold: 3  Epoch: 290  Training loss = 2.1092  Validation loss = 4.5425  \n",
      "\n",
      "Fold: 3  Epoch: 291  Training loss = 2.1090  Validation loss = 4.5423  \n",
      "\n",
      "Fold: 3  Epoch: 292  Training loss = 2.1089  Validation loss = 4.5422  \n",
      "\n",
      "Fold: 3  Epoch: 293  Training loss = 2.1088  Validation loss = 4.5420  \n",
      "\n",
      "Fold: 3  Epoch: 294  Training loss = 2.1087  Validation loss = 4.5419  \n",
      "\n",
      "Fold: 3  Epoch: 295  Training loss = 2.1086  Validation loss = 4.5417  \n",
      "\n",
      "Fold: 3  Epoch: 296  Training loss = 2.1085  Validation loss = 4.5416  \n",
      "\n",
      "Fold: 3  Epoch: 297  Training loss = 2.1084  Validation loss = 4.5413  \n",
      "\n",
      "Fold: 3  Epoch: 298  Training loss = 2.1082  Validation loss = 4.5411  \n",
      "\n",
      "Fold: 3  Epoch: 299  Training loss = 2.1081  Validation loss = 4.5410  \n",
      "\n",
      "Fold: 3  Epoch: 300  Training loss = 2.1080  Validation loss = 4.5408  \n",
      "\n",
      "Fold: 3  Epoch: 301  Training loss = 2.1079  Validation loss = 4.5407  \n",
      "\n",
      "Fold: 3  Epoch: 302  Training loss = 2.1078  Validation loss = 4.5406  \n",
      "\n",
      "Fold: 3  Epoch: 303  Training loss = 2.1077  Validation loss = 4.5404  \n",
      "\n",
      "Fold: 3  Epoch: 304  Training loss = 2.1076  Validation loss = 4.5403  \n",
      "\n",
      "Fold: 3  Epoch: 305  Training loss = 2.1076  Validation loss = 4.5401  \n",
      "\n",
      "Fold: 3  Epoch: 306  Training loss = 2.1075  Validation loss = 4.5400  \n",
      "\n",
      "Fold: 3  Epoch: 307  Training loss = 2.1074  Validation loss = 4.5398  \n",
      "\n",
      "Fold: 3  Epoch: 308  Training loss = 2.1072  Validation loss = 4.5397  \n",
      "\n",
      "Fold: 3  Epoch: 309  Training loss = 2.1071  Validation loss = 4.5395  \n",
      "\n",
      "Fold: 3  Epoch: 310  Training loss = 2.1070  Validation loss = 4.5394  \n",
      "\n",
      "Fold: 3  Epoch: 311  Training loss = 2.1070  Validation loss = 4.5393  \n",
      "\n",
      "Fold: 3  Epoch: 312  Training loss = 2.1069  Validation loss = 4.5391  \n",
      "\n",
      "Fold: 3  Epoch: 313  Training loss = 2.1068  Validation loss = 4.5390  \n",
      "\n",
      "Fold: 3  Epoch: 314  Training loss = 2.1067  Validation loss = 4.5389  \n",
      "\n",
      "Fold: 3  Epoch: 315  Training loss = 2.1066  Validation loss = 4.5387  \n",
      "\n",
      "Fold: 3  Epoch: 316  Training loss = 2.1065  Validation loss = 4.5386  \n",
      "\n",
      "Fold: 3  Epoch: 317  Training loss = 2.1064  Validation loss = 4.5384  \n",
      "\n",
      "Fold: 3  Epoch: 318  Training loss = 2.1063  Validation loss = 4.5383  \n",
      "\n",
      "Fold: 3  Epoch: 319  Training loss = 2.1062  Validation loss = 4.5381  \n",
      "\n",
      "Fold: 3  Epoch: 320  Training loss = 2.1060  Validation loss = 4.5380  \n",
      "\n",
      "Fold: 3  Epoch: 321  Training loss = 2.1060  Validation loss = 4.5378  \n",
      "\n",
      "Fold: 3  Epoch: 322  Training loss = 2.1059  Validation loss = 4.5377  \n",
      "\n",
      "Fold: 3  Epoch: 323  Training loss = 2.1058  Validation loss = 4.5376  \n",
      "\n",
      "Fold: 3  Epoch: 324  Training loss = 2.1057  Validation loss = 4.5375  \n",
      "\n",
      "Fold: 3  Epoch: 325  Training loss = 2.1056  Validation loss = 4.5373  \n",
      "\n",
      "Fold: 3  Epoch: 326  Training loss = 2.1055  Validation loss = 4.5371  \n",
      "\n",
      "Fold: 3  Epoch: 327  Training loss = 2.1054  Validation loss = 4.5370  \n",
      "\n",
      "Fold: 3  Epoch: 328  Training loss = 2.1053  Validation loss = 4.5368  \n",
      "\n",
      "Fold: 3  Epoch: 329  Training loss = 2.1052  Validation loss = 4.5367  \n",
      "\n",
      "Fold: 3  Epoch: 330  Training loss = 2.1051  Validation loss = 4.5365  \n",
      "\n",
      "Fold: 3  Epoch: 331  Training loss = 2.1050  Validation loss = 4.5364  \n",
      "\n",
      "Fold: 3  Epoch: 332  Training loss = 2.1049  Validation loss = 4.5362  \n",
      "\n",
      "Fold: 3  Epoch: 333  Training loss = 2.1048  Validation loss = 4.5361  \n",
      "\n",
      "Fold: 3  Epoch: 334  Training loss = 2.1046  Validation loss = 4.5359  \n",
      "\n",
      "Fold: 3  Epoch: 335  Training loss = 2.1046  Validation loss = 4.5358  \n",
      "\n",
      "Fold: 3  Epoch: 336  Training loss = 2.1045  Validation loss = 4.5356  \n",
      "\n",
      "Fold: 3  Epoch: 337  Training loss = 2.1044  Validation loss = 4.5354  \n",
      "\n",
      "Fold: 3  Epoch: 338  Training loss = 2.1043  Validation loss = 4.5353  \n",
      "\n",
      "Fold: 3  Epoch: 339  Training loss = 2.1042  Validation loss = 4.5352  \n",
      "\n",
      "Fold: 3  Epoch: 340  Training loss = 2.1041  Validation loss = 4.5350  \n",
      "\n",
      "Fold: 3  Epoch: 341  Training loss = 2.1039  Validation loss = 4.5349  \n",
      "\n",
      "Fold: 3  Epoch: 342  Training loss = 2.1039  Validation loss = 4.5347  \n",
      "\n",
      "Fold: 3  Epoch: 343  Training loss = 2.1037  Validation loss = 4.5345  \n",
      "\n",
      "Fold: 3  Epoch: 344  Training loss = 2.1036  Validation loss = 4.5344  \n",
      "\n",
      "Fold: 3  Epoch: 345  Training loss = 2.1035  Validation loss = 4.5342  \n",
      "\n",
      "Fold: 3  Epoch: 346  Training loss = 2.1034  Validation loss = 4.5340  \n",
      "\n",
      "Fold: 3  Epoch: 347  Training loss = 2.1033  Validation loss = 4.5339  \n",
      "\n",
      "Fold: 3  Epoch: 348  Training loss = 2.1032  Validation loss = 4.5337  \n",
      "\n",
      "Fold: 3  Epoch: 349  Training loss = 2.1031  Validation loss = 4.5336  \n",
      "\n",
      "Fold: 3  Epoch: 350  Training loss = 2.1030  Validation loss = 4.5334  \n",
      "\n",
      "Fold: 3  Epoch: 351  Training loss = 2.1029  Validation loss = 4.5332  \n",
      "\n",
      "Fold: 3  Epoch: 352  Training loss = 2.1028  Validation loss = 4.5331  \n",
      "\n",
      "Fold: 3  Epoch: 353  Training loss = 2.1027  Validation loss = 4.5329  \n",
      "\n",
      "Fold: 3  Epoch: 354  Training loss = 2.1026  Validation loss = 4.5328  \n",
      "\n",
      "Fold: 3  Epoch: 355  Training loss = 2.1025  Validation loss = 4.5326  \n",
      "\n",
      "Fold: 3  Epoch: 356  Training loss = 2.1024  Validation loss = 4.5324  \n",
      "\n",
      "Fold: 3  Epoch: 357  Training loss = 2.1023  Validation loss = 4.5323  \n",
      "\n",
      "Fold: 3  Epoch: 358  Training loss = 2.1022  Validation loss = 4.5322  \n",
      "\n",
      "Fold: 3  Epoch: 359  Training loss = 2.1021  Validation loss = 4.5320  \n",
      "\n",
      "Fold: 3  Epoch: 360  Training loss = 2.1019  Validation loss = 4.5318  \n",
      "\n",
      "Fold: 3  Epoch: 361  Training loss = 2.1018  Validation loss = 4.5316  \n",
      "\n",
      "Fold: 3  Epoch: 362  Training loss = 2.1017  Validation loss = 4.5315  \n",
      "\n",
      "Fold: 3  Epoch: 363  Training loss = 2.1016  Validation loss = 4.5314  \n",
      "\n",
      "Fold: 3  Epoch: 364  Training loss = 2.1015  Validation loss = 4.5312  \n",
      "\n",
      "Fold: 3  Epoch: 365  Training loss = 2.1014  Validation loss = 4.5311  \n",
      "\n",
      "Fold: 3  Epoch: 366  Training loss = 2.1013  Validation loss = 4.5309  \n",
      "\n",
      "Fold: 3  Epoch: 367  Training loss = 2.1012  Validation loss = 4.5308  \n",
      "\n",
      "Fold: 3  Epoch: 368  Training loss = 2.1011  Validation loss = 4.5306  \n",
      "\n",
      "Fold: 3  Epoch: 369  Training loss = 2.1010  Validation loss = 4.5305  \n",
      "\n",
      "Fold: 3  Epoch: 370  Training loss = 2.1009  Validation loss = 4.5303  \n",
      "\n",
      "Fold: 3  Epoch: 371  Training loss = 2.1008  Validation loss = 4.5302  \n",
      "\n",
      "Fold: 3  Epoch: 372  Training loss = 2.1007  Validation loss = 4.5300  \n",
      "\n",
      "Fold: 3  Epoch: 373  Training loss = 2.1006  Validation loss = 4.5299  \n",
      "\n",
      "Fold: 3  Epoch: 374  Training loss = 2.1006  Validation loss = 4.5298  \n",
      "\n",
      "Fold: 3  Epoch: 375  Training loss = 2.1004  Validation loss = 4.5296  \n",
      "\n",
      "Fold: 3  Epoch: 376  Training loss = 2.1004  Validation loss = 4.5295  \n",
      "\n",
      "Fold: 3  Epoch: 377  Training loss = 2.1003  Validation loss = 4.5293  \n",
      "\n",
      "Fold: 3  Epoch: 378  Training loss = 2.1002  Validation loss = 4.5292  \n",
      "\n",
      "Fold: 3  Epoch: 379  Training loss = 2.1001  Validation loss = 4.5291  \n",
      "\n",
      "Fold: 3  Epoch: 380  Training loss = 2.1000  Validation loss = 4.5289  \n",
      "\n",
      "Fold: 3  Epoch: 381  Training loss = 2.0999  Validation loss = 4.5288  \n",
      "\n",
      "Fold: 3  Epoch: 382  Training loss = 2.0998  Validation loss = 4.5287  \n",
      "\n",
      "Fold: 3  Epoch: 383  Training loss = 2.0997  Validation loss = 4.5285  \n",
      "\n",
      "Fold: 3  Epoch: 384  Training loss = 2.0996  Validation loss = 4.5284  \n",
      "\n",
      "Fold: 3  Epoch: 385  Training loss = 2.0995  Validation loss = 4.5283  \n",
      "\n",
      "Fold: 3  Epoch: 386  Training loss = 2.0994  Validation loss = 4.5281  \n",
      "\n",
      "Fold: 3  Epoch: 387  Training loss = 2.0993  Validation loss = 4.5280  \n",
      "\n",
      "Fold: 3  Epoch: 388  Training loss = 2.0992  Validation loss = 4.5278  \n",
      "\n",
      "Fold: 3  Epoch: 389  Training loss = 2.0991  Validation loss = 4.5277  \n",
      "\n",
      "Fold: 3  Epoch: 390  Training loss = 2.0990  Validation loss = 4.5276  \n",
      "\n",
      "Fold: 3  Epoch: 391  Training loss = 2.0989  Validation loss = 4.5274  \n",
      "\n",
      "Fold: 3  Epoch: 392  Training loss = 2.0988  Validation loss = 4.5272  \n",
      "\n",
      "Fold: 3  Epoch: 393  Training loss = 2.0987  Validation loss = 4.5270  \n",
      "\n",
      "Fold: 3  Epoch: 394  Training loss = 2.0986  Validation loss = 4.5269  \n",
      "\n",
      "Fold: 3  Epoch: 395  Training loss = 2.0985  Validation loss = 4.5267  \n",
      "\n",
      "Fold: 3  Epoch: 396  Training loss = 2.0984  Validation loss = 4.5266  \n",
      "\n",
      "Fold: 3  Epoch: 397  Training loss = 2.0983  Validation loss = 4.5264  \n",
      "\n",
      "Fold: 3  Epoch: 398  Training loss = 2.0982  Validation loss = 4.5263  \n",
      "\n",
      "Fold: 3  Epoch: 399  Training loss = 2.0981  Validation loss = 4.5261  \n",
      "\n",
      "Fold: 3  Epoch: 400  Training loss = 2.0980  Validation loss = 4.5260  \n",
      "\n",
      "Fold: 3  Epoch: 401  Training loss = 2.0979  Validation loss = 4.5258  \n",
      "\n",
      "Fold: 3  Epoch: 402  Training loss = 2.0978  Validation loss = 4.5257  \n",
      "\n",
      "Fold: 3  Epoch: 403  Training loss = 2.0977  Validation loss = 4.5255  \n",
      "\n",
      "Fold: 3  Epoch: 404  Training loss = 2.0976  Validation loss = 4.5254  \n",
      "\n",
      "Fold: 3  Epoch: 405  Training loss = 2.0975  Validation loss = 4.5253  \n",
      "\n",
      "Fold: 3  Epoch: 406  Training loss = 2.0974  Validation loss = 4.5252  \n",
      "\n",
      "Fold: 3  Epoch: 407  Training loss = 2.0974  Validation loss = 4.5251  \n",
      "\n",
      "Fold: 3  Epoch: 408  Training loss = 2.0972  Validation loss = 4.5249  \n",
      "\n",
      "Fold: 3  Epoch: 409  Training loss = 2.0971  Validation loss = 4.5247  \n",
      "\n",
      "Fold: 3  Epoch: 410  Training loss = 2.0971  Validation loss = 4.5246  \n",
      "\n",
      "Fold: 3  Epoch: 411  Training loss = 2.0970  Validation loss = 4.5244  \n",
      "\n",
      "Fold: 3  Epoch: 412  Training loss = 2.0969  Validation loss = 4.5243  \n",
      "\n",
      "Fold: 3  Epoch: 413  Training loss = 2.0967  Validation loss = 4.5241  \n",
      "\n",
      "Fold: 3  Epoch: 414  Training loss = 2.0966  Validation loss = 4.5240  \n",
      "\n",
      "Fold: 3  Epoch: 415  Training loss = 2.0966  Validation loss = 4.5238  \n",
      "\n",
      "Fold: 3  Epoch: 416  Training loss = 2.0965  Validation loss = 4.5237  \n",
      "\n",
      "Fold: 3  Epoch: 417  Training loss = 2.0964  Validation loss = 4.5235  \n",
      "\n",
      "Fold: 3  Epoch: 418  Training loss = 2.0962  Validation loss = 4.5234  \n",
      "\n",
      "Fold: 3  Epoch: 419  Training loss = 2.0961  Validation loss = 4.5232  \n",
      "\n",
      "Fold: 3  Epoch: 420  Training loss = 2.0960  Validation loss = 4.5231  \n",
      "\n",
      "Fold: 3  Epoch: 421  Training loss = 2.0959  Validation loss = 4.5229  \n",
      "\n",
      "Fold: 3  Epoch: 422  Training loss = 2.0958  Validation loss = 4.5228  \n",
      "\n",
      "Fold: 3  Epoch: 423  Training loss = 2.0958  Validation loss = 4.5226  \n",
      "\n",
      "Fold: 3  Epoch: 424  Training loss = 2.0957  Validation loss = 4.5225  \n",
      "\n",
      "Fold: 3  Epoch: 425  Training loss = 2.0956  Validation loss = 4.5223  \n",
      "\n",
      "Fold: 3  Epoch: 426  Training loss = 2.0955  Validation loss = 4.5222  \n",
      "\n",
      "Fold: 3  Epoch: 427  Training loss = 2.0954  Validation loss = 4.5220  \n",
      "\n",
      "Fold: 3  Epoch: 428  Training loss = 2.0952  Validation loss = 4.5218  \n",
      "\n",
      "Fold: 3  Epoch: 429  Training loss = 2.0951  Validation loss = 4.5217  \n",
      "\n",
      "Fold: 3  Epoch: 430  Training loss = 2.0950  Validation loss = 4.5215  \n",
      "\n",
      "Fold: 3  Epoch: 431  Training loss = 2.0950  Validation loss = 4.5214  \n",
      "\n",
      "Fold: 3  Epoch: 432  Training loss = 2.0949  Validation loss = 4.5213  \n",
      "\n",
      "Fold: 3  Epoch: 433  Training loss = 2.0947  Validation loss = 4.5211  \n",
      "\n",
      "Fold: 3  Epoch: 434  Training loss = 2.0947  Validation loss = 4.5210  \n",
      "\n",
      "Fold: 3  Epoch: 435  Training loss = 2.0945  Validation loss = 4.5208  \n",
      "\n",
      "Fold: 3  Epoch: 436  Training loss = 2.0944  Validation loss = 4.5206  \n",
      "\n",
      "Fold: 3  Epoch: 437  Training loss = 2.0943  Validation loss = 4.5205  \n",
      "\n",
      "Fold: 3  Epoch: 438  Training loss = 2.0943  Validation loss = 4.5204  \n",
      "\n",
      "Fold: 3  Epoch: 439  Training loss = 2.0942  Validation loss = 4.5202  \n",
      "\n",
      "Fold: 3  Epoch: 440  Training loss = 2.0941  Validation loss = 4.5201  \n",
      "\n",
      "Fold: 3  Epoch: 441  Training loss = 2.0940  Validation loss = 4.5199  \n",
      "\n",
      "Fold: 3  Epoch: 442  Training loss = 2.0938  Validation loss = 4.5197  \n",
      "\n",
      "Fold: 3  Epoch: 443  Training loss = 2.0937  Validation loss = 4.5196  \n",
      "\n",
      "Fold: 3  Epoch: 444  Training loss = 2.0936  Validation loss = 4.5195  \n",
      "\n",
      "Fold: 3  Epoch: 445  Training loss = 2.0935  Validation loss = 4.5193  \n",
      "\n",
      "Fold: 3  Epoch: 446  Training loss = 2.0934  Validation loss = 4.5191  \n",
      "\n",
      "Fold: 3  Epoch: 447  Training loss = 2.0933  Validation loss = 4.5190  \n",
      "\n",
      "Fold: 3  Epoch: 448  Training loss = 2.0933  Validation loss = 4.5189  \n",
      "\n",
      "Fold: 3  Epoch: 449  Training loss = 2.0932  Validation loss = 4.5187  \n",
      "\n",
      "Fold: 3  Epoch: 450  Training loss = 2.0931  Validation loss = 4.5186  \n",
      "\n",
      "Fold: 3  Epoch: 451  Training loss = 2.0930  Validation loss = 4.5185  \n",
      "\n",
      "Fold: 3  Epoch: 452  Training loss = 2.0928  Validation loss = 4.5183  \n",
      "\n",
      "Fold: 3  Epoch: 453  Training loss = 2.0927  Validation loss = 4.5181  \n",
      "\n",
      "Fold: 3  Epoch: 454  Training loss = 2.0926  Validation loss = 4.5180  \n",
      "\n",
      "Fold: 3  Epoch: 455  Training loss = 2.0925  Validation loss = 4.5179  \n",
      "\n",
      "Fold: 3  Epoch: 456  Training loss = 2.0924  Validation loss = 4.5176  \n",
      "\n",
      "Fold: 3  Epoch: 457  Training loss = 2.0923  Validation loss = 4.5175  \n",
      "\n",
      "Fold: 3  Epoch: 458  Training loss = 2.0922  Validation loss = 4.5174  \n",
      "\n",
      "Fold: 3  Epoch: 459  Training loss = 2.0922  Validation loss = 4.5173  \n",
      "\n",
      "Fold: 3  Epoch: 460  Training loss = 2.0921  Validation loss = 4.5171  \n",
      "\n",
      "Fold: 3  Epoch: 461  Training loss = 2.0920  Validation loss = 4.5170  \n",
      "\n",
      "Fold: 3  Epoch: 462  Training loss = 2.0919  Validation loss = 4.5169  \n",
      "\n",
      "Fold: 3  Epoch: 463  Training loss = 2.0918  Validation loss = 4.5168  \n",
      "\n",
      "Fold: 3  Epoch: 464  Training loss = 2.0917  Validation loss = 4.5166  \n",
      "\n",
      "Fold: 3  Epoch: 465  Training loss = 2.0916  Validation loss = 4.5164  \n",
      "\n",
      "Fold: 3  Epoch: 466  Training loss = 2.0915  Validation loss = 4.5163  \n",
      "\n",
      "Fold: 3  Epoch: 467  Training loss = 2.0914  Validation loss = 4.5161  \n",
      "\n",
      "Fold: 3  Epoch: 468  Training loss = 2.0913  Validation loss = 4.5160  \n",
      "\n",
      "Fold: 3  Epoch: 469  Training loss = 2.0912  Validation loss = 4.5158  \n",
      "\n",
      "Fold: 3  Epoch: 470  Training loss = 2.0911  Validation loss = 4.5157  \n",
      "\n",
      "Fold: 3  Epoch: 471  Training loss = 2.0910  Validation loss = 4.5156  \n",
      "\n",
      "Fold: 3  Epoch: 472  Training loss = 2.0909  Validation loss = 4.5154  \n",
      "\n",
      "Fold: 3  Epoch: 473  Training loss = 2.0908  Validation loss = 4.5153  \n",
      "\n",
      "Fold: 3  Epoch: 474  Training loss = 2.0907  Validation loss = 4.5151  \n",
      "\n",
      "Fold: 3  Epoch: 475  Training loss = 2.0907  Validation loss = 4.5150  \n",
      "\n",
      "Fold: 3  Epoch: 476  Training loss = 2.0906  Validation loss = 4.5149  \n",
      "\n",
      "Fold: 3  Epoch: 477  Training loss = 2.0905  Validation loss = 4.5147  \n",
      "\n",
      "Fold: 3  Epoch: 478  Training loss = 2.0904  Validation loss = 4.5146  \n",
      "\n",
      "Fold: 3  Epoch: 479  Training loss = 2.0903  Validation loss = 4.5144  \n",
      "\n",
      "Fold: 3  Epoch: 480  Training loss = 2.0902  Validation loss = 4.5143  \n",
      "\n",
      "Fold: 3  Epoch: 481  Training loss = 2.0901  Validation loss = 4.5141  \n",
      "\n",
      "Fold: 3  Epoch: 482  Training loss = 2.0900  Validation loss = 4.5140  \n",
      "\n",
      "Fold: 3  Epoch: 483  Training loss = 2.0899  Validation loss = 4.5139  \n",
      "\n",
      "Fold: 3  Epoch: 484  Training loss = 2.0898  Validation loss = 4.5137  \n",
      "\n",
      "Fold: 3  Epoch: 485  Training loss = 2.0897  Validation loss = 4.5136  \n",
      "\n",
      "Fold: 3  Epoch: 486  Training loss = 2.0896  Validation loss = 4.5135  \n",
      "\n",
      "Fold: 3  Epoch: 487  Training loss = 2.0895  Validation loss = 4.5133  \n",
      "\n",
      "Fold: 3  Epoch: 488  Training loss = 2.0894  Validation loss = 4.5132  \n",
      "\n",
      "Fold: 3  Epoch: 489  Training loss = 2.0893  Validation loss = 4.5131  \n",
      "\n",
      "Fold: 3  Epoch: 490  Training loss = 2.0892  Validation loss = 4.5129  \n",
      "\n",
      "Fold: 3  Epoch: 491  Training loss = 2.0891  Validation loss = 4.5128  \n",
      "\n",
      "Fold: 3  Epoch: 492  Training loss = 2.0890  Validation loss = 4.5126  \n",
      "\n",
      "Fold: 3  Epoch: 493  Training loss = 2.0889  Validation loss = 4.5125  \n",
      "\n",
      "Fold: 3  Epoch: 494  Training loss = 2.0888  Validation loss = 4.5123  \n",
      "\n",
      "Fold: 3  Epoch: 495  Training loss = 2.0887  Validation loss = 4.5122  \n",
      "\n",
      "Fold: 3  Epoch: 496  Training loss = 2.0886  Validation loss = 4.5121  \n",
      "\n",
      "Fold: 3  Epoch: 497  Training loss = 2.0885  Validation loss = 4.5119  \n",
      "\n",
      "Fold: 3  Epoch: 498  Training loss = 2.0885  Validation loss = 4.5118  \n",
      "\n",
      "Fold: 3  Epoch: 499  Training loss = 2.0884  Validation loss = 4.5117  \n",
      "\n",
      "Fold: 3  Epoch: 500  Training loss = 2.0883  Validation loss = 4.5115  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 500  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 2.2093  Validation loss = 5.7434  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 2.2092  Validation loss = 5.7432  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 2.2091  Validation loss = 5.7431  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 2.2090  Validation loss = 5.7429  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 2.2089  Validation loss = 5.7428  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 2.2088  Validation loss = 5.7426  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 2.2087  Validation loss = 5.7424  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 2.2085  Validation loss = 5.7423  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 2.2084  Validation loss = 5.7421  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 2.2083  Validation loss = 5.7419  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 2.2082  Validation loss = 5.7417  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 2.2081  Validation loss = 5.7416  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 2.2080  Validation loss = 5.7414  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 2.2079  Validation loss = 5.7413  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 2.2078  Validation loss = 5.7411  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 2.2077  Validation loss = 5.7410  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 2.2076  Validation loss = 5.7408  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 2.2075  Validation loss = 5.7407  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 2.2074  Validation loss = 5.7405  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 2.2073  Validation loss = 5.7403  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 2.2072  Validation loss = 5.7402  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 2.2070  Validation loss = 5.7400  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 2.2069  Validation loss = 5.7398  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 2.2068  Validation loss = 5.7397  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 2.2067  Validation loss = 5.7395  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 2.2066  Validation loss = 5.7393  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 2.2065  Validation loss = 5.7392  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 2.2064  Validation loss = 5.7391  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 2.2063  Validation loss = 5.7389  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 2.2062  Validation loss = 5.7387  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 2.2061  Validation loss = 5.7386  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 2.2059  Validation loss = 5.7384  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 2.2058  Validation loss = 5.7383  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 2.2057  Validation loss = 5.7381  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 2.2056  Validation loss = 5.7380  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 2.2055  Validation loss = 5.7378  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 2.2054  Validation loss = 5.7376  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 2.2053  Validation loss = 5.7375  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 2.2052  Validation loss = 5.7373  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 2.2051  Validation loss = 5.7372  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 2.2050  Validation loss = 5.7371  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 2.2049  Validation loss = 5.7370  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 2.2048  Validation loss = 5.7368  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 2.2047  Validation loss = 5.7366  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 2.2046  Validation loss = 5.7365  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 2.2045  Validation loss = 5.7363  \n",
      "\n",
      "Fold: 4  Epoch: 47  Training loss = 2.2044  Validation loss = 5.7362  \n",
      "\n",
      "Fold: 4  Epoch: 48  Training loss = 2.2043  Validation loss = 5.7360  \n",
      "\n",
      "Fold: 4  Epoch: 49  Training loss = 2.2042  Validation loss = 5.7359  \n",
      "\n",
      "Fold: 4  Epoch: 50  Training loss = 2.2041  Validation loss = 5.7357  \n",
      "\n",
      "Fold: 4  Epoch: 51  Training loss = 2.2040  Validation loss = 5.7356  \n",
      "\n",
      "Fold: 4  Epoch: 52  Training loss = 2.2039  Validation loss = 5.7354  \n",
      "\n",
      "Fold: 4  Epoch: 53  Training loss = 2.2038  Validation loss = 5.7352  \n",
      "\n",
      "Fold: 4  Epoch: 54  Training loss = 2.2037  Validation loss = 5.7351  \n",
      "\n",
      "Fold: 4  Epoch: 55  Training loss = 2.2036  Validation loss = 5.7350  \n",
      "\n",
      "Fold: 4  Epoch: 56  Training loss = 2.2035  Validation loss = 5.7348  \n",
      "\n",
      "Fold: 4  Epoch: 57  Training loss = 2.2033  Validation loss = 5.7346  \n",
      "\n",
      "Fold: 4  Epoch: 58  Training loss = 2.2033  Validation loss = 5.7345  \n",
      "\n",
      "Fold: 4  Epoch: 59  Training loss = 2.2032  Validation loss = 5.7343  \n",
      "\n",
      "Fold: 4  Epoch: 60  Training loss = 2.2030  Validation loss = 5.7341  \n",
      "\n",
      "Fold: 4  Epoch: 61  Training loss = 2.2029  Validation loss = 5.7340  \n",
      "\n",
      "Fold: 4  Epoch: 62  Training loss = 2.2028  Validation loss = 5.7338  \n",
      "\n",
      "Fold: 4  Epoch: 63  Training loss = 2.2027  Validation loss = 5.7337  \n",
      "\n",
      "Fold: 4  Epoch: 64  Training loss = 2.2026  Validation loss = 5.7335  \n",
      "\n",
      "Fold: 4  Epoch: 65  Training loss = 2.2025  Validation loss = 5.7334  \n",
      "\n",
      "Fold: 4  Epoch: 66  Training loss = 2.2024  Validation loss = 5.7332  \n",
      "\n",
      "Fold: 4  Epoch: 67  Training loss = 2.2023  Validation loss = 5.7330  \n",
      "\n",
      "Fold: 4  Epoch: 68  Training loss = 2.2022  Validation loss = 5.7328  \n",
      "\n",
      "Fold: 4  Epoch: 69  Training loss = 2.2021  Validation loss = 5.7327  \n",
      "\n",
      "Fold: 4  Epoch: 70  Training loss = 2.2020  Validation loss = 5.7325  \n",
      "\n",
      "Fold: 4  Epoch: 71  Training loss = 2.2019  Validation loss = 5.7323  \n",
      "\n",
      "Fold: 4  Epoch: 72  Training loss = 2.2018  Validation loss = 5.7322  \n",
      "\n",
      "Fold: 4  Epoch: 73  Training loss = 2.2017  Validation loss = 5.7321  \n",
      "\n",
      "Fold: 4  Epoch: 74  Training loss = 2.2015  Validation loss = 5.7319  \n",
      "\n",
      "Fold: 4  Epoch: 75  Training loss = 2.2014  Validation loss = 5.7317  \n",
      "\n",
      "Fold: 4  Epoch: 76  Training loss = 2.2013  Validation loss = 5.7315  \n",
      "\n",
      "Fold: 4  Epoch: 77  Training loss = 2.2012  Validation loss = 5.7314  \n",
      "\n",
      "Fold: 4  Epoch: 78  Training loss = 2.2011  Validation loss = 5.7312  \n",
      "\n",
      "Fold: 4  Epoch: 79  Training loss = 2.2010  Validation loss = 5.7311  \n",
      "\n",
      "Fold: 4  Epoch: 80  Training loss = 2.2009  Validation loss = 5.7309  \n",
      "\n",
      "Fold: 4  Epoch: 81  Training loss = 2.2007  Validation loss = 5.7307  \n",
      "\n",
      "Fold: 4  Epoch: 82  Training loss = 2.2007  Validation loss = 5.7306  \n",
      "\n",
      "Fold: 4  Epoch: 83  Training loss = 2.2006  Validation loss = 5.7305  \n",
      "\n",
      "Fold: 4  Epoch: 84  Training loss = 2.2005  Validation loss = 5.7303  \n",
      "\n",
      "Fold: 4  Epoch: 85  Training loss = 2.2004  Validation loss = 5.7302  \n",
      "\n",
      "Fold: 4  Epoch: 86  Training loss = 2.2003  Validation loss = 5.7300  \n",
      "\n",
      "Fold: 4  Epoch: 87  Training loss = 2.2001  Validation loss = 5.7298  \n",
      "\n",
      "Fold: 4  Epoch: 88  Training loss = 2.2000  Validation loss = 5.7297  \n",
      "\n",
      "Fold: 4  Epoch: 89  Training loss = 2.2000  Validation loss = 5.7295  \n",
      "\n",
      "Fold: 4  Epoch: 90  Training loss = 2.1998  Validation loss = 5.7294  \n",
      "\n",
      "Fold: 4  Epoch: 91  Training loss = 2.1997  Validation loss = 5.7292  \n",
      "\n",
      "Fold: 4  Epoch: 92  Training loss = 2.1996  Validation loss = 5.7291  \n",
      "\n",
      "Fold: 4  Epoch: 93  Training loss = 2.1996  Validation loss = 5.7290  \n",
      "\n",
      "Fold: 4  Epoch: 94  Training loss = 2.1994  Validation loss = 5.7288  \n",
      "\n",
      "Fold: 4  Epoch: 95  Training loss = 2.1993  Validation loss = 5.7287  \n",
      "\n",
      "Fold: 4  Epoch: 96  Training loss = 2.1992  Validation loss = 5.7285  \n",
      "\n",
      "Fold: 4  Epoch: 97  Training loss = 2.1991  Validation loss = 5.7283  \n",
      "\n",
      "Fold: 4  Epoch: 98  Training loss = 2.1990  Validation loss = 5.7282  \n",
      "\n",
      "Fold: 4  Epoch: 99  Training loss = 2.1989  Validation loss = 5.7280  \n",
      "\n",
      "Fold: 4  Epoch: 100  Training loss = 2.1988  Validation loss = 5.7279  \n",
      "\n",
      "Fold: 4  Epoch: 101  Training loss = 2.1987  Validation loss = 5.7277  \n",
      "\n",
      "Fold: 4  Epoch: 102  Training loss = 2.1986  Validation loss = 5.7276  \n",
      "\n",
      "Fold: 4  Epoch: 103  Training loss = 2.1985  Validation loss = 5.7274  \n",
      "\n",
      "Fold: 4  Epoch: 104  Training loss = 2.1984  Validation loss = 5.7272  \n",
      "\n",
      "Fold: 4  Epoch: 105  Training loss = 2.1983  Validation loss = 5.7271  \n",
      "\n",
      "Fold: 4  Epoch: 106  Training loss = 2.1982  Validation loss = 5.7269  \n",
      "\n",
      "Fold: 4  Epoch: 107  Training loss = 2.1981  Validation loss = 5.7268  \n",
      "\n",
      "Fold: 4  Epoch: 108  Training loss = 2.1980  Validation loss = 5.7267  \n",
      "\n",
      "Fold: 4  Epoch: 109  Training loss = 2.1979  Validation loss = 5.7265  \n",
      "\n",
      "Fold: 4  Epoch: 110  Training loss = 2.1978  Validation loss = 5.7263  \n",
      "\n",
      "Fold: 4  Epoch: 111  Training loss = 2.1977  Validation loss = 5.7261  \n",
      "\n",
      "Fold: 4  Epoch: 112  Training loss = 2.1976  Validation loss = 5.7260  \n",
      "\n",
      "Fold: 4  Epoch: 113  Training loss = 2.1975  Validation loss = 5.7258  \n",
      "\n",
      "Fold: 4  Epoch: 114  Training loss = 2.1974  Validation loss = 5.7256  \n",
      "\n",
      "Fold: 4  Epoch: 115  Training loss = 2.1972  Validation loss = 5.7255  \n",
      "\n",
      "Fold: 4  Epoch: 116  Training loss = 2.1971  Validation loss = 5.7253  \n",
      "\n",
      "Fold: 4  Epoch: 117  Training loss = 2.1971  Validation loss = 5.7252  \n",
      "\n",
      "Fold: 4  Epoch: 118  Training loss = 2.1969  Validation loss = 5.7251  \n",
      "\n",
      "Fold: 4  Epoch: 119  Training loss = 2.1968  Validation loss = 5.7249  \n",
      "\n",
      "Fold: 4  Epoch: 120  Training loss = 2.1967  Validation loss = 5.7248  \n",
      "\n",
      "Fold: 4  Epoch: 121  Training loss = 2.1967  Validation loss = 5.7246  \n",
      "\n",
      "Fold: 4  Epoch: 122  Training loss = 2.1966  Validation loss = 5.7245  \n",
      "\n",
      "Fold: 4  Epoch: 123  Training loss = 2.1965  Validation loss = 5.7243  \n",
      "\n",
      "Fold: 4  Epoch: 124  Training loss = 2.1963  Validation loss = 5.7242  \n",
      "\n",
      "Fold: 4  Epoch: 125  Training loss = 2.1963  Validation loss = 5.7240  \n",
      "\n",
      "Fold: 4  Epoch: 126  Training loss = 2.1962  Validation loss = 5.7239  \n",
      "\n",
      "Fold: 4  Epoch: 127  Training loss = 2.1960  Validation loss = 5.7237  \n",
      "\n",
      "Fold: 4  Epoch: 128  Training loss = 2.1959  Validation loss = 5.7236  \n",
      "\n",
      "Fold: 4  Epoch: 129  Training loss = 2.1958  Validation loss = 5.7234  \n",
      "\n",
      "Fold: 4  Epoch: 130  Training loss = 2.1957  Validation loss = 5.7232  \n",
      "\n",
      "Fold: 4  Epoch: 131  Training loss = 2.1956  Validation loss = 5.7231  \n",
      "\n",
      "Fold: 4  Epoch: 132  Training loss = 2.1955  Validation loss = 5.7229  \n",
      "\n",
      "Fold: 4  Epoch: 133  Training loss = 2.1954  Validation loss = 5.7228  \n",
      "\n",
      "Fold: 4  Epoch: 134  Training loss = 2.1953  Validation loss = 5.7226  \n",
      "\n",
      "Fold: 4  Epoch: 135  Training loss = 2.1952  Validation loss = 5.7225  \n",
      "\n",
      "Fold: 4  Epoch: 136  Training loss = 2.1951  Validation loss = 5.7223  \n",
      "\n",
      "Fold: 4  Epoch: 137  Training loss = 2.1950  Validation loss = 5.7221  \n",
      "\n",
      "Fold: 4  Epoch: 138  Training loss = 2.1949  Validation loss = 5.7220  \n",
      "\n",
      "Fold: 4  Epoch: 139  Training loss = 2.1948  Validation loss = 5.7219  \n",
      "\n",
      "Fold: 4  Epoch: 140  Training loss = 2.1947  Validation loss = 5.7216  \n",
      "\n",
      "Fold: 4  Epoch: 141  Training loss = 2.1945  Validation loss = 5.7215  \n",
      "\n",
      "Fold: 4  Epoch: 142  Training loss = 2.1944  Validation loss = 5.7213  \n",
      "\n",
      "Fold: 4  Epoch: 143  Training loss = 2.1943  Validation loss = 5.7212  \n",
      "\n",
      "Fold: 4  Epoch: 144  Training loss = 2.1942  Validation loss = 5.7210  \n",
      "\n",
      "Fold: 4  Epoch: 145  Training loss = 2.1941  Validation loss = 5.7208  \n",
      "\n",
      "Fold: 4  Epoch: 146  Training loss = 2.1940  Validation loss = 5.7206  \n",
      "\n",
      "Fold: 4  Epoch: 147  Training loss = 2.1939  Validation loss = 5.7205  \n",
      "\n",
      "Fold: 4  Epoch: 148  Training loss = 2.1938  Validation loss = 5.7203  \n",
      "\n",
      "Fold: 4  Epoch: 149  Training loss = 2.1937  Validation loss = 5.7202  \n",
      "\n",
      "Fold: 4  Epoch: 150  Training loss = 2.1936  Validation loss = 5.7200  \n",
      "\n",
      "Fold: 4  Epoch: 151  Training loss = 2.1935  Validation loss = 5.7199  \n",
      "\n",
      "Fold: 4  Epoch: 152  Training loss = 2.1934  Validation loss = 5.7197  \n",
      "\n",
      "Fold: 4  Epoch: 153  Training loss = 2.1933  Validation loss = 5.7196  \n",
      "\n",
      "Fold: 4  Epoch: 154  Training loss = 2.1931  Validation loss = 5.7194  \n",
      "\n",
      "Fold: 4  Epoch: 155  Training loss = 2.1930  Validation loss = 5.7192  \n",
      "\n",
      "Fold: 4  Epoch: 156  Training loss = 2.1929  Validation loss = 5.7191  \n",
      "\n",
      "Fold: 4  Epoch: 157  Training loss = 2.1928  Validation loss = 5.7189  \n",
      "\n",
      "Fold: 4  Epoch: 158  Training loss = 2.1927  Validation loss = 5.7188  \n",
      "\n",
      "Fold: 4  Epoch: 159  Training loss = 2.1926  Validation loss = 5.7186  \n",
      "\n",
      "Fold: 4  Epoch: 160  Training loss = 2.1925  Validation loss = 5.7184  \n",
      "\n",
      "Fold: 4  Epoch: 161  Training loss = 2.1924  Validation loss = 5.7182  \n",
      "\n",
      "Fold: 4  Epoch: 162  Training loss = 2.1923  Validation loss = 5.7181  \n",
      "\n",
      "Fold: 4  Epoch: 163  Training loss = 2.1921  Validation loss = 5.7179  \n",
      "\n",
      "Fold: 4  Epoch: 164  Training loss = 2.1920  Validation loss = 5.7178  \n",
      "\n",
      "Fold: 4  Epoch: 165  Training loss = 2.1919  Validation loss = 5.7176  \n",
      "\n",
      "Fold: 4  Epoch: 166  Training loss = 2.1918  Validation loss = 5.7174  \n",
      "\n",
      "Fold: 4  Epoch: 167  Training loss = 2.1917  Validation loss = 5.7172  \n",
      "\n",
      "Fold: 4  Epoch: 168  Training loss = 2.1916  Validation loss = 5.7171  \n",
      "\n",
      "Fold: 4  Epoch: 169  Training loss = 2.1915  Validation loss = 5.7169  \n",
      "\n",
      "Fold: 4  Epoch: 170  Training loss = 2.1914  Validation loss = 5.7167  \n",
      "\n",
      "Fold: 4  Epoch: 171  Training loss = 2.1913  Validation loss = 5.7166  \n",
      "\n",
      "Fold: 4  Epoch: 172  Training loss = 2.1912  Validation loss = 5.7164  \n",
      "\n",
      "Fold: 4  Epoch: 173  Training loss = 2.1911  Validation loss = 5.7163  \n",
      "\n",
      "Fold: 4  Epoch: 174  Training loss = 2.1910  Validation loss = 5.7161  \n",
      "\n",
      "Fold: 4  Epoch: 175  Training loss = 2.1909  Validation loss = 5.7160  \n",
      "\n",
      "Fold: 4  Epoch: 176  Training loss = 2.1908  Validation loss = 5.7158  \n",
      "\n",
      "Fold: 4  Epoch: 177  Training loss = 2.1906  Validation loss = 5.7156  \n",
      "\n",
      "Fold: 4  Epoch: 178  Training loss = 2.1905  Validation loss = 5.7155  \n",
      "\n",
      "Fold: 4  Epoch: 179  Training loss = 2.1905  Validation loss = 5.7154  \n",
      "\n",
      "Fold: 4  Epoch: 180  Training loss = 2.1904  Validation loss = 5.7152  \n",
      "\n",
      "Fold: 4  Epoch: 181  Training loss = 2.1902  Validation loss = 5.7150  \n",
      "\n",
      "Fold: 4  Epoch: 182  Training loss = 2.1901  Validation loss = 5.7149  \n",
      "\n",
      "Fold: 4  Epoch: 183  Training loss = 2.1900  Validation loss = 5.7147  \n",
      "\n",
      "Fold: 4  Epoch: 184  Training loss = 2.1899  Validation loss = 5.7145  \n",
      "\n",
      "Fold: 4  Epoch: 185  Training loss = 2.1898  Validation loss = 5.7144  \n",
      "\n",
      "Fold: 4  Epoch: 186  Training loss = 2.1897  Validation loss = 5.7142  \n",
      "\n",
      "Fold: 4  Epoch: 187  Training loss = 2.1896  Validation loss = 5.7141  \n",
      "\n",
      "Fold: 4  Epoch: 188  Training loss = 2.1895  Validation loss = 5.7140  \n",
      "\n",
      "Fold: 4  Epoch: 189  Training loss = 2.1894  Validation loss = 5.7138  \n",
      "\n",
      "Fold: 4  Epoch: 190  Training loss = 2.1893  Validation loss = 5.7137  \n",
      "\n",
      "Fold: 4  Epoch: 191  Training loss = 2.1893  Validation loss = 5.7136  \n",
      "\n",
      "Fold: 4  Epoch: 192  Training loss = 2.1892  Validation loss = 5.7134  \n",
      "\n",
      "Fold: 4  Epoch: 193  Training loss = 2.1891  Validation loss = 5.7133  \n",
      "\n",
      "Fold: 4  Epoch: 194  Training loss = 2.1890  Validation loss = 5.7131  \n",
      "\n",
      "Fold: 4  Epoch: 195  Training loss = 2.1888  Validation loss = 5.7129  \n",
      "\n",
      "Fold: 4  Epoch: 196  Training loss = 2.1887  Validation loss = 5.7128  \n",
      "\n",
      "Fold: 4  Epoch: 197  Training loss = 2.1886  Validation loss = 5.7126  \n",
      "\n",
      "Fold: 4  Epoch: 198  Training loss = 2.1885  Validation loss = 5.7124  \n",
      "\n",
      "Fold: 4  Epoch: 199  Training loss = 2.1884  Validation loss = 5.7122  \n",
      "\n",
      "Fold: 4  Epoch: 200  Training loss = 2.1883  Validation loss = 5.7121  \n",
      "\n",
      "Fold: 4  Epoch: 201  Training loss = 2.1882  Validation loss = 5.7119  \n",
      "\n",
      "Fold: 4  Epoch: 202  Training loss = 2.1881  Validation loss = 5.7118  \n",
      "\n",
      "Fold: 4  Epoch: 203  Training loss = 2.1880  Validation loss = 5.7116  \n",
      "\n",
      "Fold: 4  Epoch: 204  Training loss = 2.1879  Validation loss = 5.7114  \n",
      "\n",
      "Fold: 4  Epoch: 205  Training loss = 2.1878  Validation loss = 5.7113  \n",
      "\n",
      "Fold: 4  Epoch: 206  Training loss = 2.1876  Validation loss = 5.7110  \n",
      "\n",
      "Fold: 4  Epoch: 207  Training loss = 2.1875  Validation loss = 5.7109  \n",
      "\n",
      "Fold: 4  Epoch: 208  Training loss = 2.1874  Validation loss = 5.7107  \n",
      "\n",
      "Fold: 4  Epoch: 209  Training loss = 2.1873  Validation loss = 5.7106  \n",
      "\n",
      "Fold: 4  Epoch: 210  Training loss = 2.1872  Validation loss = 5.7105  \n",
      "\n",
      "Fold: 4  Epoch: 211  Training loss = 2.1871  Validation loss = 5.7103  \n",
      "\n",
      "Fold: 4  Epoch: 212  Training loss = 2.1870  Validation loss = 5.7102  \n",
      "\n",
      "Fold: 4  Epoch: 213  Training loss = 2.1869  Validation loss = 5.7100  \n",
      "\n",
      "Fold: 4  Epoch: 214  Training loss = 2.1868  Validation loss = 5.7099  \n",
      "\n",
      "Fold: 4  Epoch: 215  Training loss = 2.1867  Validation loss = 5.7097  \n",
      "\n",
      "Fold: 4  Epoch: 216  Training loss = 2.1866  Validation loss = 5.7096  \n",
      "\n",
      "Fold: 4  Epoch: 217  Training loss = 2.1865  Validation loss = 5.7094  \n",
      "\n",
      "Fold: 4  Epoch: 218  Training loss = 2.1865  Validation loss = 5.7093  \n",
      "\n",
      "Fold: 4  Epoch: 219  Training loss = 2.1864  Validation loss = 5.7092  \n",
      "\n",
      "Fold: 4  Epoch: 220  Training loss = 2.1862  Validation loss = 5.7090  \n",
      "\n",
      "Fold: 4  Epoch: 221  Training loss = 2.1861  Validation loss = 5.7088  \n",
      "\n",
      "Fold: 4  Epoch: 222  Training loss = 2.1860  Validation loss = 5.7087  \n",
      "\n",
      "Fold: 4  Epoch: 223  Training loss = 2.1859  Validation loss = 5.7085  \n",
      "\n",
      "Fold: 4  Epoch: 224  Training loss = 2.1858  Validation loss = 5.7083  \n",
      "\n",
      "Fold: 4  Epoch: 225  Training loss = 2.1857  Validation loss = 5.7081  \n",
      "\n",
      "Fold: 4  Epoch: 226  Training loss = 2.1856  Validation loss = 5.7080  \n",
      "\n",
      "Fold: 4  Epoch: 227  Training loss = 2.1854  Validation loss = 5.7078  \n",
      "\n",
      "Fold: 4  Epoch: 228  Training loss = 2.1853  Validation loss = 5.7076  \n",
      "\n",
      "Fold: 4  Epoch: 229  Training loss = 2.1852  Validation loss = 5.7074  \n",
      "\n",
      "Fold: 4  Epoch: 230  Training loss = 2.1851  Validation loss = 5.7073  \n",
      "\n",
      "Fold: 4  Epoch: 231  Training loss = 2.1850  Validation loss = 5.7071  \n",
      "\n",
      "Fold: 4  Epoch: 232  Training loss = 2.1849  Validation loss = 5.7070  \n",
      "\n",
      "Fold: 4  Epoch: 233  Training loss = 2.1848  Validation loss = 5.7068  \n",
      "\n",
      "Fold: 4  Epoch: 234  Training loss = 2.1847  Validation loss = 5.7067  \n",
      "\n",
      "Fold: 4  Epoch: 235  Training loss = 2.1846  Validation loss = 5.7065  \n",
      "\n",
      "Fold: 4  Epoch: 236  Training loss = 2.1845  Validation loss = 5.7064  \n",
      "\n",
      "Fold: 4  Epoch: 237  Training loss = 2.1844  Validation loss = 5.7062  \n",
      "\n",
      "Fold: 4  Epoch: 238  Training loss = 2.1843  Validation loss = 5.7060  \n",
      "\n",
      "Fold: 4  Epoch: 239  Training loss = 2.1842  Validation loss = 5.7059  \n",
      "\n",
      "Fold: 4  Epoch: 240  Training loss = 2.1841  Validation loss = 5.7057  \n",
      "\n",
      "Fold: 4  Epoch: 241  Training loss = 2.1840  Validation loss = 5.7056  \n",
      "\n",
      "Fold: 4  Epoch: 242  Training loss = 2.1838  Validation loss = 5.7054  \n",
      "\n",
      "Fold: 4  Epoch: 243  Training loss = 2.1838  Validation loss = 5.7053  \n",
      "\n",
      "Fold: 4  Epoch: 244  Training loss = 2.1836  Validation loss = 5.7051  \n",
      "\n",
      "Fold: 4  Epoch: 245  Training loss = 2.1835  Validation loss = 5.7049  \n",
      "\n",
      "Fold: 4  Epoch: 246  Training loss = 2.1834  Validation loss = 5.7048  \n",
      "\n",
      "Fold: 4  Epoch: 247  Training loss = 2.1833  Validation loss = 5.7046  \n",
      "\n",
      "Fold: 4  Epoch: 248  Training loss = 2.1832  Validation loss = 5.7044  \n",
      "\n",
      "Fold: 4  Epoch: 249  Training loss = 2.1831  Validation loss = 5.7042  \n",
      "\n",
      "Fold: 4  Epoch: 250  Training loss = 2.1830  Validation loss = 5.7041  \n",
      "\n",
      "Fold: 4  Epoch: 251  Training loss = 2.1828  Validation loss = 5.7039  \n",
      "\n",
      "Fold: 4  Epoch: 252  Training loss = 2.1827  Validation loss = 5.7037  \n",
      "\n",
      "Fold: 4  Epoch: 253  Training loss = 2.1827  Validation loss = 5.7036  \n",
      "\n",
      "Fold: 4  Epoch: 254  Training loss = 2.1825  Validation loss = 5.7035  \n",
      "\n",
      "Fold: 4  Epoch: 255  Training loss = 2.1825  Validation loss = 5.7033  \n",
      "\n",
      "Fold: 4  Epoch: 256  Training loss = 2.1824  Validation loss = 5.7032  \n",
      "\n",
      "Fold: 4  Epoch: 257  Training loss = 2.1823  Validation loss = 5.7030  \n",
      "\n",
      "Fold: 4  Epoch: 258  Training loss = 2.1821  Validation loss = 5.7028  \n",
      "\n",
      "Fold: 4  Epoch: 259  Training loss = 2.1820  Validation loss = 5.7027  \n",
      "\n",
      "Fold: 4  Epoch: 260  Training loss = 2.1819  Validation loss = 5.7025  \n",
      "\n",
      "Fold: 4  Epoch: 261  Training loss = 2.1818  Validation loss = 5.7024  \n",
      "\n",
      "Fold: 4  Epoch: 262  Training loss = 2.1817  Validation loss = 5.7022  \n",
      "\n",
      "Fold: 4  Epoch: 263  Training loss = 2.1817  Validation loss = 5.7021  \n",
      "\n",
      "Fold: 4  Epoch: 264  Training loss = 2.1816  Validation loss = 5.7020  \n",
      "\n",
      "Fold: 4  Epoch: 265  Training loss = 2.1815  Validation loss = 5.7018  \n",
      "\n",
      "Fold: 4  Epoch: 266  Training loss = 2.1814  Validation loss = 5.7017  \n",
      "\n",
      "Fold: 4  Epoch: 267  Training loss = 2.1813  Validation loss = 5.7015  \n",
      "\n",
      "Fold: 4  Epoch: 268  Training loss = 2.1811  Validation loss = 5.7014  \n",
      "\n",
      "Fold: 4  Epoch: 269  Training loss = 2.1810  Validation loss = 5.7012  \n",
      "\n",
      "Fold: 4  Epoch: 270  Training loss = 2.1809  Validation loss = 5.7010  \n",
      "\n",
      "Fold: 4  Epoch: 271  Training loss = 2.1808  Validation loss = 5.7009  \n",
      "\n",
      "Fold: 4  Epoch: 272  Training loss = 2.1807  Validation loss = 5.7008  \n",
      "\n",
      "Fold: 4  Epoch: 273  Training loss = 2.1806  Validation loss = 5.7005  \n",
      "\n",
      "Fold: 4  Epoch: 274  Training loss = 2.1805  Validation loss = 5.7003  \n",
      "\n",
      "Fold: 4  Epoch: 275  Training loss = 2.1804  Validation loss = 5.7002  \n",
      "\n",
      "Fold: 4  Epoch: 276  Training loss = 2.1803  Validation loss = 5.7000  \n",
      "\n",
      "Fold: 4  Epoch: 277  Training loss = 2.1802  Validation loss = 5.6999  \n",
      "\n",
      "Fold: 4  Epoch: 278  Training loss = 2.1801  Validation loss = 5.6997  \n",
      "\n",
      "Fold: 4  Epoch: 279  Training loss = 2.1800  Validation loss = 5.6996  \n",
      "\n",
      "Fold: 4  Epoch: 280  Training loss = 2.1799  Validation loss = 5.6995  \n",
      "\n",
      "Fold: 4  Epoch: 281  Training loss = 2.1798  Validation loss = 5.6993  \n",
      "\n",
      "Fold: 4  Epoch: 282  Training loss = 2.1797  Validation loss = 5.6992  \n",
      "\n",
      "Fold: 4  Epoch: 283  Training loss = 2.1796  Validation loss = 5.6990  \n",
      "\n",
      "Fold: 4  Epoch: 284  Training loss = 2.1795  Validation loss = 5.6989  \n",
      "\n",
      "Fold: 4  Epoch: 285  Training loss = 2.1794  Validation loss = 5.6988  \n",
      "\n",
      "Fold: 4  Epoch: 286  Training loss = 2.1793  Validation loss = 5.6986  \n",
      "\n",
      "Fold: 4  Epoch: 287  Training loss = 2.1792  Validation loss = 5.6985  \n",
      "\n",
      "Fold: 4  Epoch: 288  Training loss = 2.1791  Validation loss = 5.6984  \n",
      "\n",
      "Fold: 4  Epoch: 289  Training loss = 2.1790  Validation loss = 5.6982  \n",
      "\n",
      "Fold: 4  Epoch: 290  Training loss = 2.1789  Validation loss = 5.6980  \n",
      "\n",
      "Fold: 4  Epoch: 291  Training loss = 2.1788  Validation loss = 5.6978  \n",
      "\n",
      "Fold: 4  Epoch: 292  Training loss = 2.1787  Validation loss = 5.6977  \n",
      "\n",
      "Fold: 4  Epoch: 293  Training loss = 2.1786  Validation loss = 5.6975  \n",
      "\n",
      "Fold: 4  Epoch: 294  Training loss = 2.1785  Validation loss = 5.6974  \n",
      "\n",
      "Fold: 4  Epoch: 295  Training loss = 2.1784  Validation loss = 5.6972  \n",
      "\n",
      "Fold: 4  Epoch: 296  Training loss = 2.1783  Validation loss = 5.6971  \n",
      "\n",
      "Fold: 4  Epoch: 297  Training loss = 2.1782  Validation loss = 5.6969  \n",
      "\n",
      "Fold: 4  Epoch: 298  Training loss = 2.1781  Validation loss = 5.6968  \n",
      "\n",
      "Fold: 4  Epoch: 299  Training loss = 2.1780  Validation loss = 5.6966  \n",
      "\n",
      "Fold: 4  Epoch: 300  Training loss = 2.1779  Validation loss = 5.6964  \n",
      "\n",
      "Fold: 4  Epoch: 301  Training loss = 2.1778  Validation loss = 5.6963  \n",
      "\n",
      "Fold: 4  Epoch: 302  Training loss = 2.1777  Validation loss = 5.6962  \n",
      "\n",
      "Fold: 4  Epoch: 303  Training loss = 2.1776  Validation loss = 5.6960  \n",
      "\n",
      "Fold: 4  Epoch: 304  Training loss = 2.1775  Validation loss = 5.6958  \n",
      "\n",
      "Fold: 4  Epoch: 305  Training loss = 2.1774  Validation loss = 5.6957  \n",
      "\n",
      "Fold: 4  Epoch: 306  Training loss = 2.1773  Validation loss = 5.6956  \n",
      "\n",
      "Fold: 4  Epoch: 307  Training loss = 2.1772  Validation loss = 5.6954  \n",
      "\n",
      "Fold: 4  Epoch: 308  Training loss = 2.1771  Validation loss = 5.6952  \n",
      "\n",
      "Fold: 4  Epoch: 309  Training loss = 2.1770  Validation loss = 5.6951  \n",
      "\n",
      "Fold: 4  Epoch: 310  Training loss = 2.1769  Validation loss = 5.6950  \n",
      "\n",
      "Fold: 4  Epoch: 311  Training loss = 2.1768  Validation loss = 5.6948  \n",
      "\n",
      "Fold: 4  Epoch: 312  Training loss = 2.1767  Validation loss = 5.6946  \n",
      "\n",
      "Fold: 4  Epoch: 313  Training loss = 2.1765  Validation loss = 5.6944  \n",
      "\n",
      "Fold: 4  Epoch: 314  Training loss = 2.1765  Validation loss = 5.6943  \n",
      "\n",
      "Fold: 4  Epoch: 315  Training loss = 2.1763  Validation loss = 5.6941  \n",
      "\n",
      "Fold: 4  Epoch: 316  Training loss = 2.1762  Validation loss = 5.6939  \n",
      "\n",
      "Fold: 4  Epoch: 317  Training loss = 2.1761  Validation loss = 5.6938  \n",
      "\n",
      "Fold: 4  Epoch: 318  Training loss = 2.1760  Validation loss = 5.6936  \n",
      "\n",
      "Fold: 4  Epoch: 319  Training loss = 2.1759  Validation loss = 5.6934  \n",
      "\n",
      "Fold: 4  Epoch: 320  Training loss = 2.1758  Validation loss = 5.6933  \n",
      "\n",
      "Fold: 4  Epoch: 321  Training loss = 2.1757  Validation loss = 5.6931  \n",
      "\n",
      "Fold: 4  Epoch: 322  Training loss = 2.1756  Validation loss = 5.6930  \n",
      "\n",
      "Fold: 4  Epoch: 323  Training loss = 2.1755  Validation loss = 5.6928  \n",
      "\n",
      "Fold: 4  Epoch: 324  Training loss = 2.1754  Validation loss = 5.6927  \n",
      "\n",
      "Fold: 4  Epoch: 325  Training loss = 2.1753  Validation loss = 5.6925  \n",
      "\n",
      "Fold: 4  Epoch: 326  Training loss = 2.1752  Validation loss = 5.6924  \n",
      "\n",
      "Fold: 4  Epoch: 327  Training loss = 2.1751  Validation loss = 5.6922  \n",
      "\n",
      "Fold: 4  Epoch: 328  Training loss = 2.1750  Validation loss = 5.6921  \n",
      "\n",
      "Fold: 4  Epoch: 329  Training loss = 2.1749  Validation loss = 5.6919  \n",
      "\n",
      "Fold: 4  Epoch: 330  Training loss = 2.1748  Validation loss = 5.6918  \n",
      "\n",
      "Fold: 4  Epoch: 331  Training loss = 2.1747  Validation loss = 5.6916  \n",
      "\n",
      "Fold: 4  Epoch: 332  Training loss = 2.1746  Validation loss = 5.6915  \n",
      "\n",
      "Fold: 4  Epoch: 333  Training loss = 2.1745  Validation loss = 5.6913  \n",
      "\n",
      "Fold: 4  Epoch: 334  Training loss = 2.1744  Validation loss = 5.6911  \n",
      "\n",
      "Fold: 4  Epoch: 335  Training loss = 2.1743  Validation loss = 5.6909  \n",
      "\n",
      "Fold: 4  Epoch: 336  Training loss = 2.1742  Validation loss = 5.6908  \n",
      "\n",
      "Fold: 4  Epoch: 337  Training loss = 2.1741  Validation loss = 5.6906  \n",
      "\n",
      "Fold: 4  Epoch: 338  Training loss = 2.1740  Validation loss = 5.6905  \n",
      "\n",
      "Fold: 4  Epoch: 339  Training loss = 2.1739  Validation loss = 5.6903  \n",
      "\n",
      "Fold: 4  Epoch: 340  Training loss = 2.1738  Validation loss = 5.6902  \n",
      "\n",
      "Fold: 4  Epoch: 341  Training loss = 2.1737  Validation loss = 5.6901  \n",
      "\n",
      "Fold: 4  Epoch: 342  Training loss = 2.1736  Validation loss = 5.6900  \n",
      "\n",
      "Fold: 4  Epoch: 343  Training loss = 2.1735  Validation loss = 5.6898  \n",
      "\n",
      "Fold: 4  Epoch: 344  Training loss = 2.1735  Validation loss = 5.6897  \n",
      "\n",
      "Fold: 4  Epoch: 345  Training loss = 2.1734  Validation loss = 5.6895  \n",
      "\n",
      "Fold: 4  Epoch: 346  Training loss = 2.1732  Validation loss = 5.6893  \n",
      "\n",
      "Fold: 4  Epoch: 347  Training loss = 2.1732  Validation loss = 5.6892  \n",
      "\n",
      "Fold: 4  Epoch: 348  Training loss = 2.1730  Validation loss = 5.6890  \n",
      "\n",
      "Fold: 4  Epoch: 349  Training loss = 2.1729  Validation loss = 5.6889  \n",
      "\n",
      "Fold: 4  Epoch: 350  Training loss = 2.1728  Validation loss = 5.6887  \n",
      "\n",
      "Fold: 4  Epoch: 351  Training loss = 2.1727  Validation loss = 5.6885  \n",
      "\n",
      "Fold: 4  Epoch: 352  Training loss = 2.1726  Validation loss = 5.6884  \n",
      "\n",
      "Fold: 4  Epoch: 353  Training loss = 2.1725  Validation loss = 5.6883  \n",
      "\n",
      "Fold: 4  Epoch: 354  Training loss = 2.1724  Validation loss = 5.6881  \n",
      "\n",
      "Fold: 4  Epoch: 355  Training loss = 2.1724  Validation loss = 5.6880  \n",
      "\n",
      "Fold: 4  Epoch: 356  Training loss = 2.1723  Validation loss = 5.6878  \n",
      "\n",
      "Fold: 4  Epoch: 357  Training loss = 2.1722  Validation loss = 5.6877  \n",
      "\n",
      "Fold: 4  Epoch: 358  Training loss = 2.1721  Validation loss = 5.6875  \n",
      "\n",
      "Fold: 4  Epoch: 359  Training loss = 2.1719  Validation loss = 5.6873  \n",
      "\n",
      "Fold: 4  Epoch: 360  Training loss = 2.1718  Validation loss = 5.6872  \n",
      "\n",
      "Fold: 4  Epoch: 361  Training loss = 2.1718  Validation loss = 5.6870  \n",
      "\n",
      "Fold: 4  Epoch: 362  Training loss = 2.1716  Validation loss = 5.6868  \n",
      "\n",
      "Fold: 4  Epoch: 363  Training loss = 2.1715  Validation loss = 5.6866  \n",
      "\n",
      "Fold: 4  Epoch: 364  Training loss = 2.1714  Validation loss = 5.6865  \n",
      "\n",
      "Fold: 4  Epoch: 365  Training loss = 2.1714  Validation loss = 5.6864  \n",
      "\n",
      "Fold: 4  Epoch: 366  Training loss = 2.1713  Validation loss = 5.6863  \n",
      "\n",
      "Fold: 4  Epoch: 367  Training loss = 2.1712  Validation loss = 5.6861  \n",
      "\n",
      "Fold: 4  Epoch: 368  Training loss = 2.1711  Validation loss = 5.6860  \n",
      "\n",
      "Fold: 4  Epoch: 369  Training loss = 2.1710  Validation loss = 5.6858  \n",
      "\n",
      "Fold: 4  Epoch: 370  Training loss = 2.1709  Validation loss = 5.6857  \n",
      "\n",
      "Fold: 4  Epoch: 371  Training loss = 2.1708  Validation loss = 5.6855  \n",
      "\n",
      "Fold: 4  Epoch: 372  Training loss = 2.1707  Validation loss = 5.6854  \n",
      "\n",
      "Fold: 4  Epoch: 373  Training loss = 2.1706  Validation loss = 5.6852  \n",
      "\n",
      "Fold: 4  Epoch: 374  Training loss = 2.1705  Validation loss = 5.6850  \n",
      "\n",
      "Fold: 4  Epoch: 375  Training loss = 2.1704  Validation loss = 5.6848  \n",
      "\n",
      "Fold: 4  Epoch: 376  Training loss = 2.1702  Validation loss = 5.6847  \n",
      "\n",
      "Fold: 4  Epoch: 377  Training loss = 2.1702  Validation loss = 5.6845  \n",
      "\n",
      "Fold: 4  Epoch: 378  Training loss = 2.1700  Validation loss = 5.6843  \n",
      "\n",
      "Fold: 4  Epoch: 379  Training loss = 2.1699  Validation loss = 5.6841  \n",
      "\n",
      "Fold: 4  Epoch: 380  Training loss = 2.1698  Validation loss = 5.6839  \n",
      "\n",
      "Fold: 4  Epoch: 381  Training loss = 2.1697  Validation loss = 5.6838  \n",
      "\n",
      "Fold: 4  Epoch: 382  Training loss = 2.1696  Validation loss = 5.6836  \n",
      "\n",
      "Fold: 4  Epoch: 383  Training loss = 2.1695  Validation loss = 5.6834  \n",
      "\n",
      "Fold: 4  Epoch: 384  Training loss = 2.1694  Validation loss = 5.6833  \n",
      "\n",
      "Fold: 4  Epoch: 385  Training loss = 2.1692  Validation loss = 5.6831  \n",
      "\n",
      "Fold: 4  Epoch: 386  Training loss = 2.1691  Validation loss = 5.6829  \n",
      "\n",
      "Fold: 4  Epoch: 387  Training loss = 2.1690  Validation loss = 5.6828  \n",
      "\n",
      "Fold: 4  Epoch: 388  Training loss = 2.1689  Validation loss = 5.6826  \n",
      "\n",
      "Fold: 4  Epoch: 389  Training loss = 2.1688  Validation loss = 5.6825  \n",
      "\n",
      "Fold: 4  Epoch: 390  Training loss = 2.1687  Validation loss = 5.6823  \n",
      "\n",
      "Fold: 4  Epoch: 391  Training loss = 2.1686  Validation loss = 5.6820  \n",
      "\n",
      "Fold: 4  Epoch: 392  Training loss = 2.1685  Validation loss = 5.6819  \n",
      "\n",
      "Fold: 4  Epoch: 393  Training loss = 2.1684  Validation loss = 5.6817  \n",
      "\n",
      "Fold: 4  Epoch: 394  Training loss = 2.1683  Validation loss = 5.6816  \n",
      "\n",
      "Fold: 4  Epoch: 395  Training loss = 2.1682  Validation loss = 5.6815  \n",
      "\n",
      "Fold: 4  Epoch: 396  Training loss = 2.1681  Validation loss = 5.6813  \n",
      "\n",
      "Fold: 4  Epoch: 397  Training loss = 2.1680  Validation loss = 5.6811  \n",
      "\n",
      "Fold: 4  Epoch: 398  Training loss = 2.1679  Validation loss = 5.6810  \n",
      "\n",
      "Fold: 4  Epoch: 399  Training loss = 2.1678  Validation loss = 5.6808  \n",
      "\n",
      "Fold: 4  Epoch: 400  Training loss = 2.1677  Validation loss = 5.6807  \n",
      "\n",
      "Fold: 4  Epoch: 401  Training loss = 2.1675  Validation loss = 5.6805  \n",
      "\n",
      "Fold: 4  Epoch: 402  Training loss = 2.1674  Validation loss = 5.6803  \n",
      "\n",
      "Fold: 4  Epoch: 403  Training loss = 2.1674  Validation loss = 5.6802  \n",
      "\n",
      "Fold: 4  Epoch: 404  Training loss = 2.1672  Validation loss = 5.6800  \n",
      "\n",
      "Fold: 4  Epoch: 405  Training loss = 2.1671  Validation loss = 5.6798  \n",
      "\n",
      "Fold: 4  Epoch: 406  Training loss = 2.1670  Validation loss = 5.6796  \n",
      "\n",
      "Fold: 4  Epoch: 407  Training loss = 2.1669  Validation loss = 5.6795  \n",
      "\n",
      "Fold: 4  Epoch: 408  Training loss = 2.1668  Validation loss = 5.6794  \n",
      "\n",
      "Fold: 4  Epoch: 409  Training loss = 2.1667  Validation loss = 5.6792  \n",
      "\n",
      "Fold: 4  Epoch: 410  Training loss = 2.1666  Validation loss = 5.6791  \n",
      "\n",
      "Fold: 4  Epoch: 411  Training loss = 2.1666  Validation loss = 5.6789  \n",
      "\n",
      "Fold: 4  Epoch: 412  Training loss = 2.1665  Validation loss = 5.6788  \n",
      "\n",
      "Fold: 4  Epoch: 413  Training loss = 2.1664  Validation loss = 5.6786  \n",
      "\n",
      "Fold: 4  Epoch: 414  Training loss = 2.1663  Validation loss = 5.6785  \n",
      "\n",
      "Fold: 4  Epoch: 415  Training loss = 2.1662  Validation loss = 5.6783  \n",
      "\n",
      "Fold: 4  Epoch: 416  Training loss = 2.1661  Validation loss = 5.6782  \n",
      "\n",
      "Fold: 4  Epoch: 417  Training loss = 2.1660  Validation loss = 5.6780  \n",
      "\n",
      "Fold: 4  Epoch: 418  Training loss = 2.1658  Validation loss = 5.6778  \n",
      "\n",
      "Fold: 4  Epoch: 419  Training loss = 2.1657  Validation loss = 5.6776  \n",
      "\n",
      "Fold: 4  Epoch: 420  Training loss = 2.1656  Validation loss = 5.6775  \n",
      "\n",
      "Fold: 4  Epoch: 421  Training loss = 2.1655  Validation loss = 5.6773  \n",
      "\n",
      "Fold: 4  Epoch: 422  Training loss = 2.1654  Validation loss = 5.6772  \n",
      "\n",
      "Fold: 4  Epoch: 423  Training loss = 2.1653  Validation loss = 5.6770  \n",
      "\n",
      "Fold: 4  Epoch: 424  Training loss = 2.1652  Validation loss = 5.6769  \n",
      "\n",
      "Fold: 4  Epoch: 425  Training loss = 2.1651  Validation loss = 5.6768  \n",
      "\n",
      "Fold: 4  Epoch: 426  Training loss = 2.1650  Validation loss = 5.6766  \n",
      "\n",
      "Fold: 4  Epoch: 427  Training loss = 2.1649  Validation loss = 5.6765  \n",
      "\n",
      "Fold: 4  Epoch: 428  Training loss = 2.1649  Validation loss = 5.6763  \n",
      "\n",
      "Fold: 4  Epoch: 429  Training loss = 2.1648  Validation loss = 5.6762  \n",
      "\n",
      "Fold: 4  Epoch: 430  Training loss = 2.1647  Validation loss = 5.6761  \n",
      "\n",
      "Fold: 4  Epoch: 431  Training loss = 2.1646  Validation loss = 5.6759  \n",
      "\n",
      "Fold: 4  Epoch: 432  Training loss = 2.1645  Validation loss = 5.6757  \n",
      "\n",
      "Fold: 4  Epoch: 433  Training loss = 2.1644  Validation loss = 5.6756  \n",
      "\n",
      "Fold: 4  Epoch: 434  Training loss = 2.1643  Validation loss = 5.6754  \n",
      "\n",
      "Fold: 4  Epoch: 435  Training loss = 2.1642  Validation loss = 5.6753  \n",
      "\n",
      "Fold: 4  Epoch: 436  Training loss = 2.1641  Validation loss = 5.6751  \n",
      "\n",
      "Fold: 4  Epoch: 437  Training loss = 2.1640  Validation loss = 5.6750  \n",
      "\n",
      "Fold: 4  Epoch: 438  Training loss = 2.1639  Validation loss = 5.6748  \n",
      "\n",
      "Fold: 4  Epoch: 439  Training loss = 2.1638  Validation loss = 5.6747  \n",
      "\n",
      "Fold: 4  Epoch: 440  Training loss = 2.1637  Validation loss = 5.6745  \n",
      "\n",
      "Fold: 4  Epoch: 441  Training loss = 2.1636  Validation loss = 5.6743  \n",
      "\n",
      "Fold: 4  Epoch: 442  Training loss = 2.1635  Validation loss = 5.6741  \n",
      "\n",
      "Fold: 4  Epoch: 443  Training loss = 2.1633  Validation loss = 5.6740  \n",
      "\n",
      "Fold: 4  Epoch: 444  Training loss = 2.1633  Validation loss = 5.6738  \n",
      "\n",
      "Fold: 4  Epoch: 445  Training loss = 2.1632  Validation loss = 5.6737  \n",
      "\n",
      "Fold: 4  Epoch: 446  Training loss = 2.1631  Validation loss = 5.6736  \n",
      "\n",
      "Fold: 4  Epoch: 447  Training loss = 2.1630  Validation loss = 5.6734  \n",
      "\n",
      "Fold: 4  Epoch: 448  Training loss = 2.1629  Validation loss = 5.6733  \n",
      "\n",
      "Fold: 4  Epoch: 449  Training loss = 2.1628  Validation loss = 5.6732  \n",
      "\n",
      "Fold: 4  Epoch: 450  Training loss = 2.1627  Validation loss = 5.6730  \n",
      "\n",
      "Fold: 4  Epoch: 451  Training loss = 2.1627  Validation loss = 5.6729  \n",
      "\n",
      "Fold: 4  Epoch: 452  Training loss = 2.1626  Validation loss = 5.6728  \n",
      "\n",
      "Fold: 4  Epoch: 453  Training loss = 2.1625  Validation loss = 5.6726  \n",
      "\n",
      "Fold: 4  Epoch: 454  Training loss = 2.1624  Validation loss = 5.6725  \n",
      "\n",
      "Fold: 4  Epoch: 455  Training loss = 2.1623  Validation loss = 5.6723  \n",
      "\n",
      "Fold: 4  Epoch: 456  Training loss = 2.1622  Validation loss = 5.6722  \n",
      "\n",
      "Fold: 4  Epoch: 457  Training loss = 2.1621  Validation loss = 5.6720  \n",
      "\n",
      "Fold: 4  Epoch: 458  Training loss = 2.1620  Validation loss = 5.6719  \n",
      "\n",
      "Fold: 4  Epoch: 459  Training loss = 2.1619  Validation loss = 5.6717  \n",
      "\n",
      "Fold: 4  Epoch: 460  Training loss = 2.1617  Validation loss = 5.6715  \n",
      "\n",
      "Fold: 4  Epoch: 461  Training loss = 2.1616  Validation loss = 5.6713  \n",
      "\n",
      "Fold: 4  Epoch: 462  Training loss = 2.1615  Validation loss = 5.6711  \n",
      "\n",
      "Fold: 4  Epoch: 463  Training loss = 2.1614  Validation loss = 5.6710  \n",
      "\n",
      "Fold: 4  Epoch: 464  Training loss = 2.1613  Validation loss = 5.6708  \n",
      "\n",
      "Fold: 4  Epoch: 465  Training loss = 2.1612  Validation loss = 5.6706  \n",
      "\n",
      "Fold: 4  Epoch: 466  Training loss = 2.1611  Validation loss = 5.6704  \n",
      "\n",
      "Fold: 4  Epoch: 467  Training loss = 2.1609  Validation loss = 5.6702  \n",
      "\n",
      "Fold: 4  Epoch: 468  Training loss = 2.1608  Validation loss = 5.6701  \n",
      "\n",
      "Fold: 4  Epoch: 469  Training loss = 2.1608  Validation loss = 5.6700  \n",
      "\n",
      "Fold: 4  Epoch: 470  Training loss = 2.1607  Validation loss = 5.6698  \n",
      "\n",
      "Fold: 4  Epoch: 471  Training loss = 2.1606  Validation loss = 5.6697  \n",
      "\n",
      "Fold: 4  Epoch: 472  Training loss = 2.1605  Validation loss = 5.6695  \n",
      "\n",
      "Fold: 4  Epoch: 473  Training loss = 2.1604  Validation loss = 5.6694  \n",
      "\n",
      "Fold: 4  Epoch: 474  Training loss = 2.1603  Validation loss = 5.6693  \n",
      "\n",
      "Fold: 4  Epoch: 475  Training loss = 2.1602  Validation loss = 5.6692  \n",
      "\n",
      "Fold: 4  Epoch: 476  Training loss = 2.1601  Validation loss = 5.6690  \n",
      "\n",
      "Fold: 4  Epoch: 477  Training loss = 2.1600  Validation loss = 5.6689  \n",
      "\n",
      "Fold: 4  Epoch: 478  Training loss = 2.1599  Validation loss = 5.6687  \n",
      "\n",
      "Fold: 4  Epoch: 479  Training loss = 2.1598  Validation loss = 5.6686  \n",
      "\n",
      "Fold: 4  Epoch: 480  Training loss = 2.1598  Validation loss = 5.6684  \n",
      "\n",
      "Fold: 4  Epoch: 481  Training loss = 2.1597  Validation loss = 5.6683  \n",
      "\n",
      "Fold: 4  Epoch: 482  Training loss = 2.1596  Validation loss = 5.6681  \n",
      "\n",
      "Fold: 4  Epoch: 483  Training loss = 2.1595  Validation loss = 5.6680  \n",
      "\n",
      "Fold: 4  Epoch: 484  Training loss = 2.1593  Validation loss = 5.6678  \n",
      "\n",
      "Fold: 4  Epoch: 485  Training loss = 2.1592  Validation loss = 5.6676  \n",
      "\n",
      "Fold: 4  Epoch: 486  Training loss = 2.1591  Validation loss = 5.6674  \n",
      "\n",
      "Fold: 4  Epoch: 487  Training loss = 2.1590  Validation loss = 5.6673  \n",
      "\n",
      "Fold: 4  Epoch: 488  Training loss = 2.1589  Validation loss = 5.6671  \n",
      "\n",
      "Fold: 4  Epoch: 489  Training loss = 2.1588  Validation loss = 5.6669  \n",
      "\n",
      "Fold: 4  Epoch: 490  Training loss = 2.1587  Validation loss = 5.6668  \n",
      "\n",
      "Fold: 4  Epoch: 491  Training loss = 2.1586  Validation loss = 5.6666  \n",
      "\n",
      "Fold: 4  Epoch: 492  Training loss = 2.1585  Validation loss = 5.6665  \n",
      "\n",
      "Fold: 4  Epoch: 493  Training loss = 2.1584  Validation loss = 5.6663  \n",
      "\n",
      "Fold: 4  Epoch: 494  Training loss = 2.1583  Validation loss = 5.6662  \n",
      "\n",
      "Fold: 4  Epoch: 495  Training loss = 2.1582  Validation loss = 5.6660  \n",
      "\n",
      "Fold: 4  Epoch: 496  Training loss = 2.1581  Validation loss = 5.6659  \n",
      "\n",
      "Fold: 4  Epoch: 497  Training loss = 2.1581  Validation loss = 5.6658  \n",
      "\n",
      "Fold: 4  Epoch: 498  Training loss = 2.1580  Validation loss = 5.6656  \n",
      "\n",
      "Fold: 4  Epoch: 499  Training loss = 2.1578  Validation loss = 5.6654  \n",
      "\n",
      "Fold: 4  Epoch: 500  Training loss = 2.1577  Validation loss = 5.6652  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 500  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 2.5471  Validation loss = 5.4418  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 2.5469  Validation loss = 5.4416  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 2.5468  Validation loss = 5.4413  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 2.5467  Validation loss = 5.4411  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 2.5466  Validation loss = 5.4409  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 2.5465  Validation loss = 5.4407  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 2.5463  Validation loss = 5.4405  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 2.5462  Validation loss = 5.4402  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 2.5461  Validation loss = 5.4399  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 2.5459  Validation loss = 5.4396  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 2.5457  Validation loss = 5.4393  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 2.5456  Validation loss = 5.4391  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 2.5455  Validation loss = 5.4388  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 2.5454  Validation loss = 5.4386  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 2.5452  Validation loss = 5.4384  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 2.5451  Validation loss = 5.4381  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 2.5449  Validation loss = 5.4379  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 2.5448  Validation loss = 5.4376  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 2.5447  Validation loss = 5.4373  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 2.5445  Validation loss = 5.4371  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 2.5444  Validation loss = 5.4368  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 2.5443  Validation loss = 5.4366  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 2.5441  Validation loss = 5.4363  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 2.5440  Validation loss = 5.4361  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 2.5439  Validation loss = 5.4358  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 2.5437  Validation loss = 5.4356  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 2.5436  Validation loss = 5.4353  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 2.5435  Validation loss = 5.4351  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 2.5433  Validation loss = 5.4348  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 2.5432  Validation loss = 5.4346  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 2.5431  Validation loss = 5.4344  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 2.5430  Validation loss = 5.4342  \n",
      "\n",
      "Fold: 5  Epoch: 33  Training loss = 2.5428  Validation loss = 5.4340  \n",
      "\n",
      "Fold: 5  Epoch: 34  Training loss = 2.5427  Validation loss = 5.4338  \n",
      "\n",
      "Fold: 5  Epoch: 35  Training loss = 2.5426  Validation loss = 5.4335  \n",
      "\n",
      "Fold: 5  Epoch: 36  Training loss = 2.5425  Validation loss = 5.4334  \n",
      "\n",
      "Fold: 5  Epoch: 37  Training loss = 2.5424  Validation loss = 5.4331  \n",
      "\n",
      "Fold: 5  Epoch: 38  Training loss = 2.5422  Validation loss = 5.4328  \n",
      "\n",
      "Fold: 5  Epoch: 39  Training loss = 2.5421  Validation loss = 5.4326  \n",
      "\n",
      "Fold: 5  Epoch: 40  Training loss = 2.5420  Validation loss = 5.4323  \n",
      "\n",
      "Fold: 5  Epoch: 41  Training loss = 2.5418  Validation loss = 5.4321  \n",
      "\n",
      "Fold: 5  Epoch: 42  Training loss = 2.5417  Validation loss = 5.4319  \n",
      "\n",
      "Fold: 5  Epoch: 43  Training loss = 2.5416  Validation loss = 5.4316  \n",
      "\n",
      "Fold: 5  Epoch: 44  Training loss = 2.5414  Validation loss = 5.4314  \n",
      "\n",
      "Fold: 5  Epoch: 45  Training loss = 2.5413  Validation loss = 5.4311  \n",
      "\n",
      "Fold: 5  Epoch: 46  Training loss = 2.5411  Validation loss = 5.4308  \n",
      "\n",
      "Fold: 5  Epoch: 47  Training loss = 2.5410  Validation loss = 5.4305  \n",
      "\n",
      "Fold: 5  Epoch: 48  Training loss = 2.5409  Validation loss = 5.4303  \n",
      "\n",
      "Fold: 5  Epoch: 49  Training loss = 2.5408  Validation loss = 5.4300  \n",
      "\n",
      "Fold: 5  Epoch: 50  Training loss = 2.5406  Validation loss = 5.4298  \n",
      "\n",
      "Fold: 5  Epoch: 51  Training loss = 2.5405  Validation loss = 5.4296  \n",
      "\n",
      "Fold: 5  Epoch: 52  Training loss = 2.5404  Validation loss = 5.4294  \n",
      "\n",
      "Fold: 5  Epoch: 53  Training loss = 2.5403  Validation loss = 5.4291  \n",
      "\n",
      "Fold: 5  Epoch: 54  Training loss = 2.5401  Validation loss = 5.4288  \n",
      "\n",
      "Fold: 5  Epoch: 55  Training loss = 2.5400  Validation loss = 5.4286  \n",
      "\n",
      "Fold: 5  Epoch: 56  Training loss = 2.5398  Validation loss = 5.4284  \n",
      "\n",
      "Fold: 5  Epoch: 57  Training loss = 2.5397  Validation loss = 5.4281  \n",
      "\n",
      "Fold: 5  Epoch: 58  Training loss = 2.5396  Validation loss = 5.4279  \n",
      "\n",
      "Fold: 5  Epoch: 59  Training loss = 2.5395  Validation loss = 5.4276  \n",
      "\n",
      "Fold: 5  Epoch: 60  Training loss = 2.5393  Validation loss = 5.4274  \n",
      "\n",
      "Fold: 5  Epoch: 61  Training loss = 2.5392  Validation loss = 5.4272  \n",
      "\n",
      "Fold: 5  Epoch: 62  Training loss = 2.5391  Validation loss = 5.4270  \n",
      "\n",
      "Fold: 5  Epoch: 63  Training loss = 2.5390  Validation loss = 5.4267  \n",
      "\n",
      "Fold: 5  Epoch: 64  Training loss = 2.5388  Validation loss = 5.4265  \n",
      "\n",
      "Fold: 5  Epoch: 65  Training loss = 2.5387  Validation loss = 5.4262  \n",
      "\n",
      "Fold: 5  Epoch: 66  Training loss = 2.5386  Validation loss = 5.4260  \n",
      "\n",
      "Fold: 5  Epoch: 67  Training loss = 2.5385  Validation loss = 5.4258  \n",
      "\n",
      "Fold: 5  Epoch: 68  Training loss = 2.5383  Validation loss = 5.4255  \n",
      "\n",
      "Fold: 5  Epoch: 69  Training loss = 2.5382  Validation loss = 5.4253  \n",
      "\n",
      "Fold: 5  Epoch: 70  Training loss = 2.5380  Validation loss = 5.4250  \n",
      "\n",
      "Fold: 5  Epoch: 71  Training loss = 2.5379  Validation loss = 5.4247  \n",
      "\n",
      "Fold: 5  Epoch: 72  Training loss = 2.5378  Validation loss = 5.4244  \n",
      "\n",
      "Fold: 5  Epoch: 73  Training loss = 2.5376  Validation loss = 5.4242  \n",
      "\n",
      "Fold: 5  Epoch: 74  Training loss = 2.5375  Validation loss = 5.4239  \n",
      "\n",
      "Fold: 5  Epoch: 75  Training loss = 2.5374  Validation loss = 5.4237  \n",
      "\n",
      "Fold: 5  Epoch: 76  Training loss = 2.5373  Validation loss = 5.4235  \n",
      "\n",
      "Fold: 5  Epoch: 77  Training loss = 2.5372  Validation loss = 5.4234  \n",
      "\n",
      "Fold: 5  Epoch: 78  Training loss = 2.5371  Validation loss = 5.4232  \n",
      "\n",
      "Fold: 5  Epoch: 79  Training loss = 2.5369  Validation loss = 5.4230  \n",
      "\n",
      "Fold: 5  Epoch: 80  Training loss = 2.5368  Validation loss = 5.4227  \n",
      "\n",
      "Fold: 5  Epoch: 81  Training loss = 2.5367  Validation loss = 5.4225  \n",
      "\n",
      "Fold: 5  Epoch: 82  Training loss = 2.5366  Validation loss = 5.4223  \n",
      "\n",
      "Fold: 5  Epoch: 83  Training loss = 2.5365  Validation loss = 5.4221  \n",
      "\n",
      "Fold: 5  Epoch: 84  Training loss = 2.5363  Validation loss = 5.4218  \n",
      "\n",
      "Fold: 5  Epoch: 85  Training loss = 2.5362  Validation loss = 5.4216  \n",
      "\n",
      "Fold: 5  Epoch: 86  Training loss = 2.5361  Validation loss = 5.4214  \n",
      "\n",
      "Fold: 5  Epoch: 87  Training loss = 2.5359  Validation loss = 5.4210  \n",
      "\n",
      "Fold: 5  Epoch: 88  Training loss = 2.5357  Validation loss = 5.4207  \n",
      "\n",
      "Fold: 5  Epoch: 89  Training loss = 2.5356  Validation loss = 5.4204  \n",
      "\n",
      "Fold: 5  Epoch: 90  Training loss = 2.5355  Validation loss = 5.4202  \n",
      "\n",
      "Fold: 5  Epoch: 91  Training loss = 2.5354  Validation loss = 5.4200  \n",
      "\n",
      "Fold: 5  Epoch: 92  Training loss = 2.5352  Validation loss = 5.4197  \n",
      "\n",
      "Fold: 5  Epoch: 93  Training loss = 2.5351  Validation loss = 5.4194  \n",
      "\n",
      "Fold: 5  Epoch: 94  Training loss = 2.5349  Validation loss = 5.4192  \n",
      "\n",
      "Fold: 5  Epoch: 95  Training loss = 2.5348  Validation loss = 5.4189  \n",
      "\n",
      "Fold: 5  Epoch: 96  Training loss = 2.5347  Validation loss = 5.4187  \n",
      "\n",
      "Fold: 5  Epoch: 97  Training loss = 2.5345  Validation loss = 5.4184  \n",
      "\n",
      "Fold: 5  Epoch: 98  Training loss = 2.5344  Validation loss = 5.4181  \n",
      "\n",
      "Fold: 5  Epoch: 99  Training loss = 2.5343  Validation loss = 5.4179  \n",
      "\n",
      "Fold: 5  Epoch: 100  Training loss = 2.5342  Validation loss = 5.4177  \n",
      "\n",
      "Fold: 5  Epoch: 101  Training loss = 2.5341  Validation loss = 5.4175  \n",
      "\n",
      "Fold: 5  Epoch: 102  Training loss = 2.5339  Validation loss = 5.4173  \n",
      "\n",
      "Fold: 5  Epoch: 103  Training loss = 2.5338  Validation loss = 5.4171  \n",
      "\n",
      "Fold: 5  Epoch: 104  Training loss = 2.5337  Validation loss = 5.4168  \n",
      "\n",
      "Fold: 5  Epoch: 105  Training loss = 2.5336  Validation loss = 5.4166  \n",
      "\n",
      "Fold: 5  Epoch: 106  Training loss = 2.5334  Validation loss = 5.4163  \n",
      "\n",
      "Fold: 5  Epoch: 107  Training loss = 2.5332  Validation loss = 5.4160  \n",
      "\n",
      "Fold: 5  Epoch: 108  Training loss = 2.5331  Validation loss = 5.4158  \n",
      "\n",
      "Fold: 5  Epoch: 109  Training loss = 2.5330  Validation loss = 5.4155  \n",
      "\n",
      "Fold: 5  Epoch: 110  Training loss = 2.5329  Validation loss = 5.4152  \n",
      "\n",
      "Fold: 5  Epoch: 111  Training loss = 2.5327  Validation loss = 5.4150  \n",
      "\n",
      "Fold: 5  Epoch: 112  Training loss = 2.5326  Validation loss = 5.4147  \n",
      "\n",
      "Fold: 5  Epoch: 113  Training loss = 2.5325  Validation loss = 5.4146  \n",
      "\n",
      "Fold: 5  Epoch: 114  Training loss = 2.5324  Validation loss = 5.4143  \n",
      "\n",
      "Fold: 5  Epoch: 115  Training loss = 2.5322  Validation loss = 5.4140  \n",
      "\n",
      "Fold: 5  Epoch: 116  Training loss = 2.5321  Validation loss = 5.4137  \n",
      "\n",
      "Fold: 5  Epoch: 117  Training loss = 2.5319  Validation loss = 5.4135  \n",
      "\n",
      "Fold: 5  Epoch: 118  Training loss = 2.5318  Validation loss = 5.4132  \n",
      "\n",
      "Fold: 5  Epoch: 119  Training loss = 2.5317  Validation loss = 5.4130  \n",
      "\n",
      "Fold: 5  Epoch: 120  Training loss = 2.5316  Validation loss = 5.4128  \n",
      "\n",
      "Fold: 5  Epoch: 121  Training loss = 2.5314  Validation loss = 5.4126  \n",
      "\n",
      "Fold: 5  Epoch: 122  Training loss = 2.5313  Validation loss = 5.4123  \n",
      "\n",
      "Fold: 5  Epoch: 123  Training loss = 2.5312  Validation loss = 5.4122  \n",
      "\n",
      "Fold: 5  Epoch: 124  Training loss = 2.5311  Validation loss = 5.4119  \n",
      "\n",
      "Fold: 5  Epoch: 125  Training loss = 2.5309  Validation loss = 5.4116  \n",
      "\n",
      "Fold: 5  Epoch: 126  Training loss = 2.5308  Validation loss = 5.4114  \n",
      "\n",
      "Fold: 5  Epoch: 127  Training loss = 2.5307  Validation loss = 5.4112  \n",
      "\n",
      "Fold: 5  Epoch: 128  Training loss = 2.5306  Validation loss = 5.4110  \n",
      "\n",
      "Fold: 5  Epoch: 129  Training loss = 2.5305  Validation loss = 5.4108  \n",
      "\n",
      "Fold: 5  Epoch: 130  Training loss = 2.5303  Validation loss = 5.4105  \n",
      "\n",
      "Fold: 5  Epoch: 131  Training loss = 2.5302  Validation loss = 5.4102  \n",
      "\n",
      "Fold: 5  Epoch: 132  Training loss = 2.5301  Validation loss = 5.4100  \n",
      "\n",
      "Fold: 5  Epoch: 133  Training loss = 2.5299  Validation loss = 5.4097  \n",
      "\n",
      "Fold: 5  Epoch: 134  Training loss = 2.5298  Validation loss = 5.4094  \n",
      "\n",
      "Fold: 5  Epoch: 135  Training loss = 2.5296  Validation loss = 5.4091  \n",
      "\n",
      "Fold: 5  Epoch: 136  Training loss = 2.5295  Validation loss = 5.4089  \n",
      "\n",
      "Fold: 5  Epoch: 137  Training loss = 2.5293  Validation loss = 5.4086  \n",
      "\n",
      "Fold: 5  Epoch: 138  Training loss = 2.5292  Validation loss = 5.4084  \n",
      "\n",
      "Fold: 5  Epoch: 139  Training loss = 2.5291  Validation loss = 5.4082  \n",
      "\n",
      "Fold: 5  Epoch: 140  Training loss = 2.5290  Validation loss = 5.4080  \n",
      "\n",
      "Fold: 5  Epoch: 141  Training loss = 2.5289  Validation loss = 5.4078  \n",
      "\n",
      "Fold: 5  Epoch: 142  Training loss = 2.5287  Validation loss = 5.4076  \n",
      "\n",
      "Fold: 5  Epoch: 143  Training loss = 2.5286  Validation loss = 5.4073  \n",
      "\n",
      "Fold: 5  Epoch: 144  Training loss = 2.5285  Validation loss = 5.4070  \n",
      "\n",
      "Fold: 5  Epoch: 145  Training loss = 2.5284  Validation loss = 5.4068  \n",
      "\n",
      "Fold: 5  Epoch: 146  Training loss = 2.5282  Validation loss = 5.4066  \n",
      "\n",
      "Fold: 5  Epoch: 147  Training loss = 2.5281  Validation loss = 5.4064  \n",
      "\n",
      "Fold: 5  Epoch: 148  Training loss = 2.5280  Validation loss = 5.4061  \n",
      "\n",
      "Fold: 5  Epoch: 149  Training loss = 2.5279  Validation loss = 5.4059  \n",
      "\n",
      "Fold: 5  Epoch: 150  Training loss = 2.5277  Validation loss = 5.4056  \n",
      "\n",
      "Fold: 5  Epoch: 151  Training loss = 2.5276  Validation loss = 5.4053  \n",
      "\n",
      "Fold: 5  Epoch: 152  Training loss = 2.5274  Validation loss = 5.4051  \n",
      "\n",
      "Fold: 5  Epoch: 153  Training loss = 2.5273  Validation loss = 5.4048  \n",
      "\n",
      "Fold: 5  Epoch: 154  Training loss = 2.5272  Validation loss = 5.4046  \n",
      "\n",
      "Fold: 5  Epoch: 155  Training loss = 2.5271  Validation loss = 5.4043  \n",
      "\n",
      "Fold: 5  Epoch: 156  Training loss = 2.5269  Validation loss = 5.4041  \n",
      "\n",
      "Fold: 5  Epoch: 157  Training loss = 2.5268  Validation loss = 5.4038  \n",
      "\n",
      "Fold: 5  Epoch: 158  Training loss = 2.5267  Validation loss = 5.4035  \n",
      "\n",
      "Fold: 5  Epoch: 159  Training loss = 2.5265  Validation loss = 5.4032  \n",
      "\n",
      "Fold: 5  Epoch: 160  Training loss = 2.5264  Validation loss = 5.4030  \n",
      "\n",
      "Fold: 5  Epoch: 161  Training loss = 2.5263  Validation loss = 5.4028  \n",
      "\n",
      "Fold: 5  Epoch: 162  Training loss = 2.5262  Validation loss = 5.4026  \n",
      "\n",
      "Fold: 5  Epoch: 163  Training loss = 2.5260  Validation loss = 5.4024  \n",
      "\n",
      "Fold: 5  Epoch: 164  Training loss = 2.5259  Validation loss = 5.4022  \n",
      "\n",
      "Fold: 5  Epoch: 165  Training loss = 2.5258  Validation loss = 5.4020  \n",
      "\n",
      "Fold: 5  Epoch: 166  Training loss = 2.5257  Validation loss = 5.4017  \n",
      "\n",
      "Fold: 5  Epoch: 167  Training loss = 2.5256  Validation loss = 5.4015  \n",
      "\n",
      "Fold: 5  Epoch: 168  Training loss = 2.5254  Validation loss = 5.4012  \n",
      "\n",
      "Fold: 5  Epoch: 169  Training loss = 2.5253  Validation loss = 5.4010  \n",
      "\n",
      "Fold: 5  Epoch: 170  Training loss = 2.5252  Validation loss = 5.4007  \n",
      "\n",
      "Fold: 5  Epoch: 171  Training loss = 2.5250  Validation loss = 5.4005  \n",
      "\n",
      "Fold: 5  Epoch: 172  Training loss = 2.5249  Validation loss = 5.4003  \n",
      "\n",
      "Fold: 5  Epoch: 173  Training loss = 2.5248  Validation loss = 5.4001  \n",
      "\n",
      "Fold: 5  Epoch: 174  Training loss = 2.5247  Validation loss = 5.3999  \n",
      "\n",
      "Fold: 5  Epoch: 175  Training loss = 2.5245  Validation loss = 5.3996  \n",
      "\n",
      "Fold: 5  Epoch: 176  Training loss = 2.5244  Validation loss = 5.3994  \n",
      "\n",
      "Fold: 5  Epoch: 177  Training loss = 2.5243  Validation loss = 5.3992  \n",
      "\n",
      "Fold: 5  Epoch: 178  Training loss = 2.5242  Validation loss = 5.3990  \n",
      "\n",
      "Fold: 5  Epoch: 179  Training loss = 2.5240  Validation loss = 5.3987  \n",
      "\n",
      "Fold: 5  Epoch: 180  Training loss = 2.5239  Validation loss = 5.3985  \n",
      "\n",
      "Fold: 5  Epoch: 181  Training loss = 2.5238  Validation loss = 5.3982  \n",
      "\n",
      "Fold: 5  Epoch: 182  Training loss = 2.5236  Validation loss = 5.3979  \n",
      "\n",
      "Fold: 5  Epoch: 183  Training loss = 2.5235  Validation loss = 5.3977  \n",
      "\n",
      "Fold: 5  Epoch: 184  Training loss = 2.5234  Validation loss = 5.3975  \n",
      "\n",
      "Fold: 5  Epoch: 185  Training loss = 2.5233  Validation loss = 5.3973  \n",
      "\n",
      "Fold: 5  Epoch: 186  Training loss = 2.5231  Validation loss = 5.3970  \n",
      "\n",
      "Fold: 5  Epoch: 187  Training loss = 2.5231  Validation loss = 5.3969  \n",
      "\n",
      "Fold: 5  Epoch: 188  Training loss = 2.5229  Validation loss = 5.3967  \n",
      "\n",
      "Fold: 5  Epoch: 189  Training loss = 2.5228  Validation loss = 5.3964  \n",
      "\n",
      "Fold: 5  Epoch: 190  Training loss = 2.5227  Validation loss = 5.3962  \n",
      "\n",
      "Fold: 5  Epoch: 191  Training loss = 2.5226  Validation loss = 5.3959  \n",
      "\n",
      "Fold: 5  Epoch: 192  Training loss = 2.5225  Validation loss = 5.3957  \n",
      "\n",
      "Fold: 5  Epoch: 193  Training loss = 2.5223  Validation loss = 5.3954  \n",
      "\n",
      "Fold: 5  Epoch: 194  Training loss = 2.5222  Validation loss = 5.3953  \n",
      "\n",
      "Fold: 5  Epoch: 195  Training loss = 2.5221  Validation loss = 5.3951  \n",
      "\n",
      "Fold: 5  Epoch: 196  Training loss = 2.5220  Validation loss = 5.3948  \n",
      "\n",
      "Fold: 5  Epoch: 197  Training loss = 2.5218  Validation loss = 5.3946  \n",
      "\n",
      "Fold: 5  Epoch: 198  Training loss = 2.5217  Validation loss = 5.3942  \n",
      "\n",
      "Fold: 5  Epoch: 199  Training loss = 2.5215  Validation loss = 5.3940  \n",
      "\n",
      "Fold: 5  Epoch: 200  Training loss = 2.5214  Validation loss = 5.3938  \n",
      "\n",
      "Fold: 5  Epoch: 201  Training loss = 2.5213  Validation loss = 5.3935  \n",
      "\n",
      "Fold: 5  Epoch: 202  Training loss = 2.5212  Validation loss = 5.3933  \n",
      "\n",
      "Fold: 5  Epoch: 203  Training loss = 2.5211  Validation loss = 5.3931  \n",
      "\n",
      "Fold: 5  Epoch: 204  Training loss = 2.5209  Validation loss = 5.3928  \n",
      "\n",
      "Fold: 5  Epoch: 205  Training loss = 2.5208  Validation loss = 5.3926  \n",
      "\n",
      "Fold: 5  Epoch: 206  Training loss = 2.5207  Validation loss = 5.3924  \n",
      "\n",
      "Fold: 5  Epoch: 207  Training loss = 2.5206  Validation loss = 5.3921  \n",
      "\n",
      "Fold: 5  Epoch: 208  Training loss = 2.5204  Validation loss = 5.3919  \n",
      "\n",
      "Fold: 5  Epoch: 209  Training loss = 2.5203  Validation loss = 5.3916  \n",
      "\n",
      "Fold: 5  Epoch: 210  Training loss = 2.5202  Validation loss = 5.3914  \n",
      "\n",
      "Fold: 5  Epoch: 211  Training loss = 2.5200  Validation loss = 5.3912  \n",
      "\n",
      "Fold: 5  Epoch: 212  Training loss = 2.5199  Validation loss = 5.3909  \n",
      "\n",
      "Fold: 5  Epoch: 213  Training loss = 2.5198  Validation loss = 5.3906  \n",
      "\n",
      "Fold: 5  Epoch: 214  Training loss = 2.5196  Validation loss = 5.3904  \n",
      "\n",
      "Fold: 5  Epoch: 215  Training loss = 2.5195  Validation loss = 5.3900  \n",
      "\n",
      "Fold: 5  Epoch: 216  Training loss = 2.5193  Validation loss = 5.3898  \n",
      "\n",
      "Fold: 5  Epoch: 217  Training loss = 2.5192  Validation loss = 5.3895  \n",
      "\n",
      "Fold: 5  Epoch: 218  Training loss = 2.5191  Validation loss = 5.3892  \n",
      "\n",
      "Fold: 5  Epoch: 219  Training loss = 2.5190  Validation loss = 5.3891  \n",
      "\n",
      "Fold: 5  Epoch: 220  Training loss = 2.5189  Validation loss = 5.3889  \n",
      "\n",
      "Fold: 5  Epoch: 221  Training loss = 2.5188  Validation loss = 5.3887  \n",
      "\n",
      "Fold: 5  Epoch: 222  Training loss = 2.5186  Validation loss = 5.3885  \n",
      "\n",
      "Fold: 5  Epoch: 223  Training loss = 2.5185  Validation loss = 5.3882  \n",
      "\n",
      "Fold: 5  Epoch: 224  Training loss = 2.5184  Validation loss = 5.3880  \n",
      "\n",
      "Fold: 5  Epoch: 225  Training loss = 2.5182  Validation loss = 5.3877  \n",
      "\n",
      "Fold: 5  Epoch: 226  Training loss = 2.5181  Validation loss = 5.3874  \n",
      "\n",
      "Fold: 5  Epoch: 227  Training loss = 2.5179  Validation loss = 5.3872  \n",
      "\n",
      "Fold: 5  Epoch: 228  Training loss = 2.5178  Validation loss = 5.3869  \n",
      "\n",
      "Fold: 5  Epoch: 229  Training loss = 2.5177  Validation loss = 5.3866  \n",
      "\n",
      "Fold: 5  Epoch: 230  Training loss = 2.5176  Validation loss = 5.3865  \n",
      "\n",
      "Fold: 5  Epoch: 231  Training loss = 2.5175  Validation loss = 5.3863  \n",
      "\n",
      "Fold: 5  Epoch: 232  Training loss = 2.5173  Validation loss = 5.3860  \n",
      "\n",
      "Fold: 5  Epoch: 233  Training loss = 2.5172  Validation loss = 5.3858  \n",
      "\n",
      "Fold: 5  Epoch: 234  Training loss = 2.5171  Validation loss = 5.3856  \n",
      "\n",
      "Fold: 5  Epoch: 235  Training loss = 2.5170  Validation loss = 5.3854  \n",
      "\n",
      "Fold: 5  Epoch: 236  Training loss = 2.5169  Validation loss = 5.3851  \n",
      "\n",
      "Fold: 5  Epoch: 237  Training loss = 2.5167  Validation loss = 5.3849  \n",
      "\n",
      "Fold: 5  Epoch: 238  Training loss = 2.5166  Validation loss = 5.3847  \n",
      "\n",
      "Fold: 5  Epoch: 239  Training loss = 2.5164  Validation loss = 5.3843  \n",
      "\n",
      "Fold: 5  Epoch: 240  Training loss = 2.5163  Validation loss = 5.3840  \n",
      "\n",
      "Fold: 5  Epoch: 241  Training loss = 2.5162  Validation loss = 5.3838  \n",
      "\n",
      "Fold: 5  Epoch: 242  Training loss = 2.5160  Validation loss = 5.3835  \n",
      "\n",
      "Fold: 5  Epoch: 243  Training loss = 2.5159  Validation loss = 5.3833  \n",
      "\n",
      "Fold: 5  Epoch: 244  Training loss = 2.5158  Validation loss = 5.3831  \n",
      "\n",
      "Fold: 5  Epoch: 245  Training loss = 2.5157  Validation loss = 5.3829  \n",
      "\n",
      "Fold: 5  Epoch: 246  Training loss = 2.5156  Validation loss = 5.3827  \n",
      "\n",
      "Fold: 5  Epoch: 247  Training loss = 2.5155  Validation loss = 5.3826  \n",
      "\n",
      "Fold: 5  Epoch: 248  Training loss = 2.5154  Validation loss = 5.3823  \n",
      "\n",
      "Fold: 5  Epoch: 249  Training loss = 2.5152  Validation loss = 5.3820  \n",
      "\n",
      "Fold: 5  Epoch: 250  Training loss = 2.5151  Validation loss = 5.3818  \n",
      "\n",
      "Fold: 5  Epoch: 251  Training loss = 2.5150  Validation loss = 5.3816  \n",
      "\n",
      "Fold: 5  Epoch: 252  Training loss = 2.5149  Validation loss = 5.3814  \n",
      "\n",
      "Fold: 5  Epoch: 253  Training loss = 2.5148  Validation loss = 5.3812  \n",
      "\n",
      "Fold: 5  Epoch: 254  Training loss = 2.5146  Validation loss = 5.3810  \n",
      "\n",
      "Fold: 5  Epoch: 255  Training loss = 2.5145  Validation loss = 5.3808  \n",
      "\n",
      "Fold: 5  Epoch: 256  Training loss = 2.5144  Validation loss = 5.3805  \n",
      "\n",
      "Fold: 5  Epoch: 257  Training loss = 2.5143  Validation loss = 5.3802  \n",
      "\n",
      "Fold: 5  Epoch: 258  Training loss = 2.5141  Validation loss = 5.3800  \n",
      "\n",
      "Fold: 5  Epoch: 259  Training loss = 2.5140  Validation loss = 5.3798  \n",
      "\n",
      "Fold: 5  Epoch: 260  Training loss = 2.5139  Validation loss = 5.3795  \n",
      "\n",
      "Fold: 5  Epoch: 261  Training loss = 2.5138  Validation loss = 5.3794  \n",
      "\n",
      "Fold: 5  Epoch: 262  Training loss = 2.5136  Validation loss = 5.3791  \n",
      "\n",
      "Fold: 5  Epoch: 263  Training loss = 2.5136  Validation loss = 5.3790  \n",
      "\n",
      "Fold: 5  Epoch: 264  Training loss = 2.5134  Validation loss = 5.3787  \n",
      "\n",
      "Fold: 5  Epoch: 265  Training loss = 2.5133  Validation loss = 5.3785  \n",
      "\n",
      "Fold: 5  Epoch: 266  Training loss = 2.5132  Validation loss = 5.3782  \n",
      "\n",
      "Fold: 5  Epoch: 267  Training loss = 2.5130  Validation loss = 5.3779  \n",
      "\n",
      "Fold: 5  Epoch: 268  Training loss = 2.5129  Validation loss = 5.3777  \n",
      "\n",
      "Fold: 5  Epoch: 269  Training loss = 2.5128  Validation loss = 5.3775  \n",
      "\n",
      "Fold: 5  Epoch: 270  Training loss = 2.5126  Validation loss = 5.3772  \n",
      "\n",
      "Fold: 5  Epoch: 271  Training loss = 2.5125  Validation loss = 5.3769  \n",
      "\n",
      "Fold: 5  Epoch: 272  Training loss = 2.5124  Validation loss = 5.3767  \n",
      "\n",
      "Fold: 5  Epoch: 273  Training loss = 2.5122  Validation loss = 5.3764  \n",
      "\n",
      "Fold: 5  Epoch: 274  Training loss = 2.5121  Validation loss = 5.3762  \n",
      "\n",
      "Fold: 5  Epoch: 275  Training loss = 2.5119  Validation loss = 5.3759  \n",
      "\n",
      "Fold: 5  Epoch: 276  Training loss = 2.5118  Validation loss = 5.3756  \n",
      "\n",
      "Fold: 5  Epoch: 277  Training loss = 2.5117  Validation loss = 5.3754  \n",
      "\n",
      "Fold: 5  Epoch: 278  Training loss = 2.5115  Validation loss = 5.3751  \n",
      "\n",
      "Fold: 5  Epoch: 279  Training loss = 2.5114  Validation loss = 5.3750  \n",
      "\n",
      "Fold: 5  Epoch: 280  Training loss = 2.5113  Validation loss = 5.3747  \n",
      "\n",
      "Fold: 5  Epoch: 281  Training loss = 2.5112  Validation loss = 5.3745  \n",
      "\n",
      "Fold: 5  Epoch: 282  Training loss = 2.5111  Validation loss = 5.3743  \n",
      "\n",
      "Fold: 5  Epoch: 283  Training loss = 2.5109  Validation loss = 5.3740  \n",
      "\n",
      "Fold: 5  Epoch: 284  Training loss = 2.5108  Validation loss = 5.3738  \n",
      "\n",
      "Fold: 5  Epoch: 285  Training loss = 2.5107  Validation loss = 5.3736  \n",
      "\n",
      "Fold: 5  Epoch: 286  Training loss = 2.5106  Validation loss = 5.3734  \n",
      "\n",
      "Fold: 5  Epoch: 287  Training loss = 2.5105  Validation loss = 5.3732  \n",
      "\n",
      "Fold: 5  Epoch: 288  Training loss = 2.5104  Validation loss = 5.3730  \n",
      "\n",
      "Fold: 5  Epoch: 289  Training loss = 2.5102  Validation loss = 5.3727  \n",
      "\n",
      "Fold: 5  Epoch: 290  Training loss = 2.5101  Validation loss = 5.3725  \n",
      "\n",
      "Fold: 5  Epoch: 291  Training loss = 2.5100  Validation loss = 5.3723  \n",
      "\n",
      "Fold: 5  Epoch: 292  Training loss = 2.5099  Validation loss = 5.3720  \n",
      "\n",
      "Fold: 5  Epoch: 293  Training loss = 2.5097  Validation loss = 5.3718  \n",
      "\n",
      "Fold: 5  Epoch: 294  Training loss = 2.5096  Validation loss = 5.3715  \n",
      "\n",
      "Fold: 5  Epoch: 295  Training loss = 2.5094  Validation loss = 5.3712  \n",
      "\n",
      "Fold: 5  Epoch: 296  Training loss = 2.5093  Validation loss = 5.3710  \n",
      "\n",
      "Fold: 5  Epoch: 297  Training loss = 2.5092  Validation loss = 5.3709  \n",
      "\n",
      "Fold: 5  Epoch: 298  Training loss = 2.5091  Validation loss = 5.3706  \n",
      "\n",
      "Fold: 5  Epoch: 299  Training loss = 2.5090  Validation loss = 5.3704  \n",
      "\n",
      "Fold: 5  Epoch: 300  Training loss = 2.5089  Validation loss = 5.3702  \n",
      "\n",
      "Fold: 5  Epoch: 301  Training loss = 2.5087  Validation loss = 5.3699  \n",
      "\n",
      "Fold: 5  Epoch: 302  Training loss = 2.5086  Validation loss = 5.3697  \n",
      "\n",
      "Fold: 5  Epoch: 303  Training loss = 2.5085  Validation loss = 5.3694  \n",
      "\n",
      "Fold: 5  Epoch: 304  Training loss = 2.5083  Validation loss = 5.3691  \n",
      "\n",
      "Fold: 5  Epoch: 305  Training loss = 2.5082  Validation loss = 5.3689  \n",
      "\n",
      "Fold: 5  Epoch: 306  Training loss = 2.5081  Validation loss = 5.3686  \n",
      "\n",
      "Fold: 5  Epoch: 307  Training loss = 2.5080  Validation loss = 5.3684  \n",
      "\n",
      "Fold: 5  Epoch: 308  Training loss = 2.5078  Validation loss = 5.3681  \n",
      "\n",
      "Fold: 5  Epoch: 309  Training loss = 2.5077  Validation loss = 5.3679  \n",
      "\n",
      "Fold: 5  Epoch: 310  Training loss = 2.5075  Validation loss = 5.3676  \n",
      "\n",
      "Fold: 5  Epoch: 311  Training loss = 2.5074  Validation loss = 5.3674  \n",
      "\n",
      "Fold: 5  Epoch: 312  Training loss = 2.5073  Validation loss = 5.3671  \n",
      "\n",
      "Fold: 5  Epoch: 313  Training loss = 2.5072  Validation loss = 5.3669  \n",
      "\n",
      "Fold: 5  Epoch: 314  Training loss = 2.5071  Validation loss = 5.3667  \n",
      "\n",
      "Fold: 5  Epoch: 315  Training loss = 2.5069  Validation loss = 5.3665  \n",
      "\n",
      "Fold: 5  Epoch: 316  Training loss = 2.5068  Validation loss = 5.3663  \n",
      "\n",
      "Fold: 5  Epoch: 317  Training loss = 2.5067  Validation loss = 5.3660  \n",
      "\n",
      "Fold: 5  Epoch: 318  Training loss = 2.5066  Validation loss = 5.3658  \n",
      "\n",
      "Fold: 5  Epoch: 319  Training loss = 2.5064  Validation loss = 5.3655  \n",
      "\n",
      "Fold: 5  Epoch: 320  Training loss = 2.5063  Validation loss = 5.3653  \n",
      "\n",
      "Fold: 5  Epoch: 321  Training loss = 2.5062  Validation loss = 5.3650  \n",
      "\n",
      "Fold: 5  Epoch: 322  Training loss = 2.5061  Validation loss = 5.3648  \n",
      "\n",
      "Fold: 5  Epoch: 323  Training loss = 2.5060  Validation loss = 5.3646  \n",
      "\n",
      "Fold: 5  Epoch: 324  Training loss = 2.5059  Validation loss = 5.3644  \n",
      "\n",
      "Fold: 5  Epoch: 325  Training loss = 2.5057  Validation loss = 5.3641  \n",
      "\n",
      "Fold: 5  Epoch: 326  Training loss = 2.5056  Validation loss = 5.3638  \n",
      "\n",
      "Fold: 5  Epoch: 327  Training loss = 2.5054  Validation loss = 5.3636  \n",
      "\n",
      "Fold: 5  Epoch: 328  Training loss = 2.5053  Validation loss = 5.3633  \n",
      "\n",
      "Fold: 5  Epoch: 329  Training loss = 2.5052  Validation loss = 5.3632  \n",
      "\n",
      "Fold: 5  Epoch: 330  Training loss = 2.5051  Validation loss = 5.3630  \n",
      "\n",
      "Fold: 5  Epoch: 331  Training loss = 2.5050  Validation loss = 5.3628  \n",
      "\n",
      "Fold: 5  Epoch: 332  Training loss = 2.5048  Validation loss = 5.3625  \n",
      "\n",
      "Fold: 5  Epoch: 333  Training loss = 2.5047  Validation loss = 5.3622  \n",
      "\n",
      "Fold: 5  Epoch: 334  Training loss = 2.5046  Validation loss = 5.3620  \n",
      "\n",
      "Fold: 5  Epoch: 335  Training loss = 2.5045  Validation loss = 5.3618  \n",
      "\n",
      "Fold: 5  Epoch: 336  Training loss = 2.5043  Validation loss = 5.3615  \n",
      "\n",
      "Fold: 5  Epoch: 337  Training loss = 2.5042  Validation loss = 5.3613  \n",
      "\n",
      "Fold: 5  Epoch: 338  Training loss = 2.5041  Validation loss = 5.3611  \n",
      "\n",
      "Fold: 5  Epoch: 339  Training loss = 2.5039  Validation loss = 5.3608  \n",
      "\n",
      "Fold: 5  Epoch: 340  Training loss = 2.5038  Validation loss = 5.3606  \n",
      "\n",
      "Fold: 5  Epoch: 341  Training loss = 2.5037  Validation loss = 5.3604  \n",
      "\n",
      "Fold: 5  Epoch: 342  Training loss = 2.5036  Validation loss = 5.3601  \n",
      "\n",
      "Fold: 5  Epoch: 343  Training loss = 2.5034  Validation loss = 5.3599  \n",
      "\n",
      "Fold: 5  Epoch: 344  Training loss = 2.5033  Validation loss = 5.3597  \n",
      "\n",
      "Fold: 5  Epoch: 345  Training loss = 2.5032  Validation loss = 5.3593  \n",
      "\n",
      "Fold: 5  Epoch: 346  Training loss = 2.5030  Validation loss = 5.3591  \n",
      "\n",
      "Fold: 5  Epoch: 347  Training loss = 2.5029  Validation loss = 5.3589  \n",
      "\n",
      "Fold: 5  Epoch: 348  Training loss = 2.5028  Validation loss = 5.3587  \n",
      "\n",
      "Fold: 5  Epoch: 349  Training loss = 2.5027  Validation loss = 5.3584  \n",
      "\n",
      "Fold: 5  Epoch: 350  Training loss = 2.5026  Validation loss = 5.3582  \n",
      "\n",
      "Fold: 5  Epoch: 351  Training loss = 2.5025  Validation loss = 5.3581  \n",
      "\n",
      "Fold: 5  Epoch: 352  Training loss = 2.5024  Validation loss = 5.3579  \n",
      "\n",
      "Fold: 5  Epoch: 353  Training loss = 2.5023  Validation loss = 5.3577  \n",
      "\n",
      "Fold: 5  Epoch: 354  Training loss = 2.5022  Validation loss = 5.3575  \n",
      "\n",
      "Fold: 5  Epoch: 355  Training loss = 2.5020  Validation loss = 5.3573  \n",
      "\n",
      "Fold: 5  Epoch: 356  Training loss = 2.5019  Validation loss = 5.3571  \n",
      "\n",
      "Fold: 5  Epoch: 357  Training loss = 2.5018  Validation loss = 5.3568  \n",
      "\n",
      "Fold: 5  Epoch: 358  Training loss = 2.5017  Validation loss = 5.3566  \n",
      "\n",
      "Fold: 5  Epoch: 359  Training loss = 2.5016  Validation loss = 5.3564  \n",
      "\n",
      "Fold: 5  Epoch: 360  Training loss = 2.5014  Validation loss = 5.3562  \n",
      "\n",
      "Fold: 5  Epoch: 361  Training loss = 2.5013  Validation loss = 5.3559  \n",
      "\n",
      "Fold: 5  Epoch: 362  Training loss = 2.5011  Validation loss = 5.3555  \n",
      "\n",
      "Fold: 5  Epoch: 363  Training loss = 2.5010  Validation loss = 5.3553  \n",
      "\n",
      "Fold: 5  Epoch: 364  Training loss = 2.5009  Validation loss = 5.3552  \n",
      "\n",
      "Fold: 5  Epoch: 365  Training loss = 2.5008  Validation loss = 5.3549  \n",
      "\n",
      "Fold: 5  Epoch: 366  Training loss = 2.5007  Validation loss = 5.3547  \n",
      "\n",
      "Fold: 5  Epoch: 367  Training loss = 2.5005  Validation loss = 5.3545  \n",
      "\n",
      "Fold: 5  Epoch: 368  Training loss = 2.5004  Validation loss = 5.3542  \n",
      "\n",
      "Fold: 5  Epoch: 369  Training loss = 2.5003  Validation loss = 5.3540  \n",
      "\n",
      "Fold: 5  Epoch: 370  Training loss = 2.5002  Validation loss = 5.3538  \n",
      "\n",
      "Fold: 5  Epoch: 371  Training loss = 2.5000  Validation loss = 5.3535  \n",
      "\n",
      "Fold: 5  Epoch: 372  Training loss = 2.4999  Validation loss = 5.3533  \n",
      "\n",
      "Fold: 5  Epoch: 373  Training loss = 2.4998  Validation loss = 5.3531  \n",
      "\n",
      "Fold: 5  Epoch: 374  Training loss = 2.4997  Validation loss = 5.3529  \n",
      "\n",
      "Fold: 5  Epoch: 375  Training loss = 2.4996  Validation loss = 5.3527  \n",
      "\n",
      "Fold: 5  Epoch: 376  Training loss = 2.4995  Validation loss = 5.3525  \n",
      "\n",
      "Fold: 5  Epoch: 377  Training loss = 2.4993  Validation loss = 5.3522  \n",
      "\n",
      "Fold: 5  Epoch: 378  Training loss = 2.4992  Validation loss = 5.3520  \n",
      "\n",
      "Fold: 5  Epoch: 379  Training loss = 2.4991  Validation loss = 5.3517  \n",
      "\n",
      "Fold: 5  Epoch: 380  Training loss = 2.4990  Validation loss = 5.3515  \n",
      "\n",
      "Fold: 5  Epoch: 381  Training loss = 2.4989  Validation loss = 5.3513  \n",
      "\n",
      "Fold: 5  Epoch: 382  Training loss = 2.4988  Validation loss = 5.3511  \n",
      "\n",
      "Fold: 5  Epoch: 383  Training loss = 2.4986  Validation loss = 5.3508  \n",
      "\n",
      "Fold: 5  Epoch: 384  Training loss = 2.4985  Validation loss = 5.3507  \n",
      "\n",
      "Fold: 5  Epoch: 385  Training loss = 2.4984  Validation loss = 5.3505  \n",
      "\n",
      "Fold: 5  Epoch: 386  Training loss = 2.4983  Validation loss = 5.3502  \n",
      "\n",
      "Fold: 5  Epoch: 387  Training loss = 2.4982  Validation loss = 5.3500  \n",
      "\n",
      "Fold: 5  Epoch: 388  Training loss = 2.4980  Validation loss = 5.3498  \n",
      "\n",
      "Fold: 5  Epoch: 389  Training loss = 2.4979  Validation loss = 5.3495  \n",
      "\n",
      "Fold: 5  Epoch: 390  Training loss = 2.4978  Validation loss = 5.3494  \n",
      "\n",
      "Fold: 5  Epoch: 391  Training loss = 2.4977  Validation loss = 5.3491  \n",
      "\n",
      "Fold: 5  Epoch: 392  Training loss = 2.4975  Validation loss = 5.3488  \n",
      "\n",
      "Fold: 5  Epoch: 393  Training loss = 2.4974  Validation loss = 5.3486  \n",
      "\n",
      "Fold: 5  Epoch: 394  Training loss = 2.4973  Validation loss = 5.3483  \n",
      "\n",
      "Fold: 5  Epoch: 395  Training loss = 2.4971  Validation loss = 5.3481  \n",
      "\n",
      "Fold: 5  Epoch: 396  Training loss = 2.4970  Validation loss = 5.3479  \n",
      "\n",
      "Fold: 5  Epoch: 397  Training loss = 2.4969  Validation loss = 5.3477  \n",
      "\n",
      "Fold: 5  Epoch: 398  Training loss = 2.4968  Validation loss = 5.3474  \n",
      "\n",
      "Fold: 5  Epoch: 399  Training loss = 2.4967  Validation loss = 5.3472  \n",
      "\n",
      "Fold: 5  Epoch: 400  Training loss = 2.4965  Validation loss = 5.3470  \n",
      "\n",
      "Fold: 5  Epoch: 401  Training loss = 2.4964  Validation loss = 5.3468  \n",
      "\n",
      "Fold: 5  Epoch: 402  Training loss = 2.4963  Validation loss = 5.3465  \n",
      "\n",
      "Fold: 5  Epoch: 403  Training loss = 2.4961  Validation loss = 5.3462  \n",
      "\n",
      "Fold: 5  Epoch: 404  Training loss = 2.4960  Validation loss = 5.3460  \n",
      "\n",
      "Fold: 5  Epoch: 405  Training loss = 2.4959  Validation loss = 5.3459  \n",
      "\n",
      "Fold: 5  Epoch: 406  Training loss = 2.4958  Validation loss = 5.3456  \n",
      "\n",
      "Fold: 5  Epoch: 407  Training loss = 2.4956  Validation loss = 5.3453  \n",
      "\n",
      "Fold: 5  Epoch: 408  Training loss = 2.4955  Validation loss = 5.3451  \n",
      "\n",
      "Fold: 5  Epoch: 409  Training loss = 2.4954  Validation loss = 5.3449  \n",
      "\n",
      "Fold: 5  Epoch: 410  Training loss = 2.4953  Validation loss = 5.3447  \n",
      "\n",
      "Fold: 5  Epoch: 411  Training loss = 2.4952  Validation loss = 5.3445  \n",
      "\n",
      "Fold: 5  Epoch: 412  Training loss = 2.4951  Validation loss = 5.3443  \n",
      "\n",
      "Fold: 5  Epoch: 413  Training loss = 2.4950  Validation loss = 5.3441  \n",
      "\n",
      "Fold: 5  Epoch: 414  Training loss = 2.4948  Validation loss = 5.3438  \n",
      "\n",
      "Fold: 5  Epoch: 415  Training loss = 2.4947  Validation loss = 5.3436  \n",
      "\n",
      "Fold: 5  Epoch: 416  Training loss = 2.4946  Validation loss = 5.3435  \n",
      "\n",
      "Fold: 5  Epoch: 417  Training loss = 2.4945  Validation loss = 5.3433  \n",
      "\n",
      "Fold: 5  Epoch: 418  Training loss = 2.4944  Validation loss = 5.3431  \n",
      "\n",
      "Fold: 5  Epoch: 419  Training loss = 2.4943  Validation loss = 5.3428  \n",
      "\n",
      "Fold: 5  Epoch: 420  Training loss = 2.4941  Validation loss = 5.3426  \n",
      "\n",
      "Fold: 5  Epoch: 421  Training loss = 2.4940  Validation loss = 5.3423  \n",
      "\n",
      "Fold: 5  Epoch: 422  Training loss = 2.4939  Validation loss = 5.3422  \n",
      "\n",
      "Fold: 5  Epoch: 423  Training loss = 2.4938  Validation loss = 5.3419  \n",
      "\n",
      "Fold: 5  Epoch: 424  Training loss = 2.4936  Validation loss = 5.3416  \n",
      "\n",
      "Fold: 5  Epoch: 425  Training loss = 2.4935  Validation loss = 5.3414  \n",
      "\n",
      "Fold: 5  Epoch: 426  Training loss = 2.4934  Validation loss = 5.3412  \n",
      "\n",
      "Fold: 5  Epoch: 427  Training loss = 2.4933  Validation loss = 5.3409  \n",
      "\n",
      "Fold: 5  Epoch: 428  Training loss = 2.4931  Validation loss = 5.3407  \n",
      "\n",
      "Fold: 5  Epoch: 429  Training loss = 2.4930  Validation loss = 5.3405  \n",
      "\n",
      "Fold: 5  Epoch: 430  Training loss = 2.4929  Validation loss = 5.3403  \n",
      "\n",
      "Fold: 5  Epoch: 431  Training loss = 2.4928  Validation loss = 5.3400  \n",
      "\n",
      "Fold: 5  Epoch: 432  Training loss = 2.4927  Validation loss = 5.3398  \n",
      "\n",
      "Fold: 5  Epoch: 433  Training loss = 2.4925  Validation loss = 5.3395  \n",
      "\n",
      "Fold: 5  Epoch: 434  Training loss = 2.4924  Validation loss = 5.3392  \n",
      "\n",
      "Fold: 5  Epoch: 435  Training loss = 2.4922  Validation loss = 5.3389  \n",
      "\n",
      "Fold: 5  Epoch: 436  Training loss = 2.4921  Validation loss = 5.3387  \n",
      "\n",
      "Fold: 5  Epoch: 437  Training loss = 2.4920  Validation loss = 5.3385  \n",
      "\n",
      "Fold: 5  Epoch: 438  Training loss = 2.4918  Validation loss = 5.3382  \n",
      "\n",
      "Fold: 5  Epoch: 439  Training loss = 2.4917  Validation loss = 5.3379  \n",
      "\n",
      "Fold: 5  Epoch: 440  Training loss = 2.4915  Validation loss = 5.3376  \n",
      "\n",
      "Fold: 5  Epoch: 441  Training loss = 2.4914  Validation loss = 5.3374  \n",
      "\n",
      "Fold: 5  Epoch: 442  Training loss = 2.4913  Validation loss = 5.3372  \n",
      "\n",
      "Fold: 5  Epoch: 443  Training loss = 2.4912  Validation loss = 5.3370  \n",
      "\n",
      "Fold: 5  Epoch: 444  Training loss = 2.4911  Validation loss = 5.3368  \n",
      "\n",
      "Fold: 5  Epoch: 445  Training loss = 2.4909  Validation loss = 5.3366  \n",
      "\n",
      "Fold: 5  Epoch: 446  Training loss = 2.4908  Validation loss = 5.3363  \n",
      "\n",
      "Fold: 5  Epoch: 447  Training loss = 2.4907  Validation loss = 5.3361  \n",
      "\n",
      "Fold: 5  Epoch: 448  Training loss = 2.4905  Validation loss = 5.3358  \n",
      "\n",
      "Fold: 5  Epoch: 449  Training loss = 2.4904  Validation loss = 5.3357  \n",
      "\n",
      "Fold: 5  Epoch: 450  Training loss = 2.4903  Validation loss = 5.3354  \n",
      "\n",
      "Fold: 5  Epoch: 451  Training loss = 2.4902  Validation loss = 5.3352  \n",
      "\n",
      "Fold: 5  Epoch: 452  Training loss = 2.4901  Validation loss = 5.3350  \n",
      "\n",
      "Fold: 5  Epoch: 453  Training loss = 2.4899  Validation loss = 5.3347  \n",
      "\n",
      "Fold: 5  Epoch: 454  Training loss = 2.4898  Validation loss = 5.3345  \n",
      "\n",
      "Fold: 5  Epoch: 455  Training loss = 2.4897  Validation loss = 5.3343  \n",
      "\n",
      "Fold: 5  Epoch: 456  Training loss = 2.4896  Validation loss = 5.3340  \n",
      "\n",
      "Fold: 5  Epoch: 457  Training loss = 2.4894  Validation loss = 5.3338  \n",
      "\n",
      "Fold: 5  Epoch: 458  Training loss = 2.4893  Validation loss = 5.3336  \n",
      "\n",
      "Fold: 5  Epoch: 459  Training loss = 2.4892  Validation loss = 5.3333  \n",
      "\n",
      "Fold: 5  Epoch: 460  Training loss = 2.4891  Validation loss = 5.3331  \n",
      "\n",
      "Fold: 5  Epoch: 461  Training loss = 2.4890  Validation loss = 5.3329  \n",
      "\n",
      "Fold: 5  Epoch: 462  Training loss = 2.4888  Validation loss = 5.3327  \n",
      "\n",
      "Fold: 5  Epoch: 463  Training loss = 2.4887  Validation loss = 5.3323  \n",
      "\n",
      "Fold: 5  Epoch: 464  Training loss = 2.4886  Validation loss = 5.3321  \n",
      "\n",
      "Fold: 5  Epoch: 465  Training loss = 2.4884  Validation loss = 5.3319  \n",
      "\n",
      "Fold: 5  Epoch: 466  Training loss = 2.4883  Validation loss = 5.3316  \n",
      "\n",
      "Fold: 5  Epoch: 467  Training loss = 2.4882  Validation loss = 5.3314  \n",
      "\n",
      "Fold: 5  Epoch: 468  Training loss = 2.4881  Validation loss = 5.3312  \n",
      "\n",
      "Fold: 5  Epoch: 469  Training loss = 2.4879  Validation loss = 5.3310  \n",
      "\n",
      "Fold: 5  Epoch: 470  Training loss = 2.4878  Validation loss = 5.3308  \n",
      "\n",
      "Fold: 5  Epoch: 471  Training loss = 2.4877  Validation loss = 5.3306  \n",
      "\n",
      "Fold: 5  Epoch: 472  Training loss = 2.4876  Validation loss = 5.3305  \n",
      "\n",
      "Fold: 5  Epoch: 473  Training loss = 2.4875  Validation loss = 5.3302  \n",
      "\n",
      "Fold: 5  Epoch: 474  Training loss = 2.4874  Validation loss = 5.3300  \n",
      "\n",
      "Fold: 5  Epoch: 475  Training loss = 2.4872  Validation loss = 5.3297  \n",
      "\n",
      "Fold: 5  Epoch: 476  Training loss = 2.4871  Validation loss = 5.3295  \n",
      "\n",
      "Fold: 5  Epoch: 477  Training loss = 2.4870  Validation loss = 5.3292  \n",
      "\n",
      "Fold: 5  Epoch: 478  Training loss = 2.4869  Validation loss = 5.3290  \n",
      "\n",
      "Fold: 5  Epoch: 479  Training loss = 2.4867  Validation loss = 5.3288  \n",
      "\n",
      "Fold: 5  Epoch: 480  Training loss = 2.4866  Validation loss = 5.3286  \n",
      "\n",
      "Fold: 5  Epoch: 481  Training loss = 2.4865  Validation loss = 5.3285  \n",
      "\n",
      "Fold: 5  Epoch: 482  Training loss = 2.4864  Validation loss = 5.3282  \n",
      "\n",
      "Fold: 5  Epoch: 483  Training loss = 2.4862  Validation loss = 5.3279  \n",
      "\n",
      "Fold: 5  Epoch: 484  Training loss = 2.4861  Validation loss = 5.3277  \n",
      "\n",
      "Fold: 5  Epoch: 485  Training loss = 2.4860  Validation loss = 5.3275  \n",
      "\n",
      "Fold: 5  Epoch: 486  Training loss = 2.4859  Validation loss = 5.3273  \n",
      "\n",
      "Fold: 5  Epoch: 487  Training loss = 2.4858  Validation loss = 5.3271  \n",
      "\n",
      "Fold: 5  Epoch: 488  Training loss = 2.4857  Validation loss = 5.3269  \n",
      "\n",
      "Fold: 5  Epoch: 489  Training loss = 2.4855  Validation loss = 5.3266  \n",
      "\n",
      "Fold: 5  Epoch: 490  Training loss = 2.4855  Validation loss = 5.3265  \n",
      "\n",
      "Fold: 5  Epoch: 491  Training loss = 2.4853  Validation loss = 5.3262  \n",
      "\n",
      "Fold: 5  Epoch: 492  Training loss = 2.4852  Validation loss = 5.3259  \n",
      "\n",
      "Fold: 5  Epoch: 493  Training loss = 2.4850  Validation loss = 5.3257  \n",
      "\n",
      "Fold: 5  Epoch: 494  Training loss = 2.4849  Validation loss = 5.3254  \n",
      "\n",
      "Fold: 5  Epoch: 495  Training loss = 2.4848  Validation loss = 5.3252  \n",
      "\n",
      "Fold: 5  Epoch: 496  Training loss = 2.4847  Validation loss = 5.3250  \n",
      "\n",
      "Fold: 5  Epoch: 497  Training loss = 2.4846  Validation loss = 5.3247  \n",
      "\n",
      "Fold: 5  Epoch: 498  Training loss = 2.4844  Validation loss = 5.3245  \n",
      "\n",
      "Fold: 5  Epoch: 499  Training loss = 2.4843  Validation loss = 5.3242  \n",
      "\n",
      "Fold: 5  Epoch: 500  Training loss = 2.4842  Validation loss = 5.3240  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 500  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 2.8085  Validation loss = 3.2352  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 2.8084  Validation loss = 3.2350  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 2.8082  Validation loss = 3.2347  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 2.8080  Validation loss = 3.2344  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 2.8078  Validation loss = 3.2341  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 2.8076  Validation loss = 3.2338  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 2.8074  Validation loss = 3.2335  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 2.8072  Validation loss = 3.2333  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 2.8071  Validation loss = 3.2330  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 2.8069  Validation loss = 3.2327  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 2.8067  Validation loss = 3.2325  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 2.8066  Validation loss = 3.2322  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 2.8064  Validation loss = 3.2319  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 2.8062  Validation loss = 3.2316  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 2.8061  Validation loss = 3.2314  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 2.8059  Validation loss = 3.2312  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 2.8058  Validation loss = 3.2310  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 2.8056  Validation loss = 3.2307  \n",
      "\n",
      "Fold: 6  Epoch: 19  Training loss = 2.8054  Validation loss = 3.2304  \n",
      "\n",
      "Fold: 6  Epoch: 20  Training loss = 2.8052  Validation loss = 3.2302  \n",
      "\n",
      "Fold: 6  Epoch: 21  Training loss = 2.8051  Validation loss = 3.2299  \n",
      "\n",
      "Fold: 6  Epoch: 22  Training loss = 2.8049  Validation loss = 3.2297  \n",
      "\n",
      "Fold: 6  Epoch: 23  Training loss = 2.8048  Validation loss = 3.2294  \n",
      "\n",
      "Fold: 6  Epoch: 24  Training loss = 2.8046  Validation loss = 3.2291  \n",
      "\n",
      "Fold: 6  Epoch: 25  Training loss = 2.8044  Validation loss = 3.2288  \n",
      "\n",
      "Fold: 6  Epoch: 26  Training loss = 2.8042  Validation loss = 3.2286  \n",
      "\n",
      "Fold: 6  Epoch: 27  Training loss = 2.8040  Validation loss = 3.2283  \n",
      "\n",
      "Fold: 6  Epoch: 28  Training loss = 2.8039  Validation loss = 3.2281  \n",
      "\n",
      "Fold: 6  Epoch: 29  Training loss = 2.8037  Validation loss = 3.2278  \n",
      "\n",
      "Fold: 6  Epoch: 30  Training loss = 2.8036  Validation loss = 3.2276  \n",
      "\n",
      "Fold: 6  Epoch: 31  Training loss = 2.8034  Validation loss = 3.2273  \n",
      "\n",
      "Fold: 6  Epoch: 32  Training loss = 2.8032  Validation loss = 3.2270  \n",
      "\n",
      "Fold: 6  Epoch: 33  Training loss = 2.8030  Validation loss = 3.2268  \n",
      "\n",
      "Fold: 6  Epoch: 34  Training loss = 2.8028  Validation loss = 3.2265  \n",
      "\n",
      "Fold: 6  Epoch: 35  Training loss = 2.8027  Validation loss = 3.2262  \n",
      "\n",
      "Fold: 6  Epoch: 36  Training loss = 2.8025  Validation loss = 3.2259  \n",
      "\n",
      "Fold: 6  Epoch: 37  Training loss = 2.8023  Validation loss = 3.2256  \n",
      "\n",
      "Fold: 6  Epoch: 38  Training loss = 2.8021  Validation loss = 3.2253  \n",
      "\n",
      "Fold: 6  Epoch: 39  Training loss = 2.8020  Validation loss = 3.2251  \n",
      "\n",
      "Fold: 6  Epoch: 40  Training loss = 2.8018  Validation loss = 3.2248  \n",
      "\n",
      "Fold: 6  Epoch: 41  Training loss = 2.8016  Validation loss = 3.2245  \n",
      "\n",
      "Fold: 6  Epoch: 42  Training loss = 2.8014  Validation loss = 3.2242  \n",
      "\n",
      "Fold: 6  Epoch: 43  Training loss = 2.8012  Validation loss = 3.2239  \n",
      "\n",
      "Fold: 6  Epoch: 44  Training loss = 2.8010  Validation loss = 3.2236  \n",
      "\n",
      "Fold: 6  Epoch: 45  Training loss = 2.8009  Validation loss = 3.2234  \n",
      "\n",
      "Fold: 6  Epoch: 46  Training loss = 2.8007  Validation loss = 3.2231  \n",
      "\n",
      "Fold: 6  Epoch: 47  Training loss = 2.8006  Validation loss = 3.2229  \n",
      "\n",
      "Fold: 6  Epoch: 48  Training loss = 2.8004  Validation loss = 3.2227  \n",
      "\n",
      "Fold: 6  Epoch: 49  Training loss = 2.8003  Validation loss = 3.2225  \n",
      "\n",
      "Fold: 6  Epoch: 50  Training loss = 2.8001  Validation loss = 3.2222  \n",
      "\n",
      "Fold: 6  Epoch: 51  Training loss = 2.7999  Validation loss = 3.2219  \n",
      "\n",
      "Fold: 6  Epoch: 52  Training loss = 2.7997  Validation loss = 3.2217  \n",
      "\n",
      "Fold: 6  Epoch: 53  Training loss = 2.7995  Validation loss = 3.2213  \n",
      "\n",
      "Fold: 6  Epoch: 54  Training loss = 2.7994  Validation loss = 3.2211  \n",
      "\n",
      "Fold: 6  Epoch: 55  Training loss = 2.7992  Validation loss = 3.2208  \n",
      "\n",
      "Fold: 6  Epoch: 56  Training loss = 2.7991  Validation loss = 3.2206  \n",
      "\n",
      "Fold: 6  Epoch: 57  Training loss = 2.7989  Validation loss = 3.2204  \n",
      "\n",
      "Fold: 6  Epoch: 58  Training loss = 2.7987  Validation loss = 3.2201  \n",
      "\n",
      "Fold: 6  Epoch: 59  Training loss = 2.7985  Validation loss = 3.2197  \n",
      "\n",
      "Fold: 6  Epoch: 60  Training loss = 2.7983  Validation loss = 3.2194  \n",
      "\n",
      "Fold: 6  Epoch: 61  Training loss = 2.7981  Validation loss = 3.2191  \n",
      "\n",
      "Fold: 6  Epoch: 62  Training loss = 2.7979  Validation loss = 3.2188  \n",
      "\n",
      "Fold: 6  Epoch: 63  Training loss = 2.7977  Validation loss = 3.2186  \n",
      "\n",
      "Fold: 6  Epoch: 64  Training loss = 2.7976  Validation loss = 3.2183  \n",
      "\n",
      "Fold: 6  Epoch: 65  Training loss = 2.7974  Validation loss = 3.2181  \n",
      "\n",
      "Fold: 6  Epoch: 66  Training loss = 2.7973  Validation loss = 3.2178  \n",
      "\n",
      "Fold: 6  Epoch: 67  Training loss = 2.7971  Validation loss = 3.2176  \n",
      "\n",
      "Fold: 6  Epoch: 68  Training loss = 2.7969  Validation loss = 3.2172  \n",
      "\n",
      "Fold: 6  Epoch: 69  Training loss = 2.7967  Validation loss = 3.2169  \n",
      "\n",
      "Fold: 6  Epoch: 70  Training loss = 2.7965  Validation loss = 3.2167  \n",
      "\n",
      "Fold: 6  Epoch: 71  Training loss = 2.7963  Validation loss = 3.2163  \n",
      "\n",
      "Fold: 6  Epoch: 72  Training loss = 2.7961  Validation loss = 3.2161  \n",
      "\n",
      "Fold: 6  Epoch: 73  Training loss = 2.7960  Validation loss = 3.2158  \n",
      "\n",
      "Fold: 6  Epoch: 74  Training loss = 2.7958  Validation loss = 3.2155  \n",
      "\n",
      "Fold: 6  Epoch: 75  Training loss = 2.7956  Validation loss = 3.2153  \n",
      "\n",
      "Fold: 6  Epoch: 76  Training loss = 2.7955  Validation loss = 3.2150  \n",
      "\n",
      "Fold: 6  Epoch: 77  Training loss = 2.7953  Validation loss = 3.2147  \n",
      "\n",
      "Fold: 6  Epoch: 78  Training loss = 2.7951  Validation loss = 3.2145  \n",
      "\n",
      "Fold: 6  Epoch: 79  Training loss = 2.7950  Validation loss = 3.2143  \n",
      "\n",
      "Fold: 6  Epoch: 80  Training loss = 2.7948  Validation loss = 3.2140  \n",
      "\n",
      "Fold: 6  Epoch: 81  Training loss = 2.7946  Validation loss = 3.2137  \n",
      "\n",
      "Fold: 6  Epoch: 82  Training loss = 2.7945  Validation loss = 3.2135  \n",
      "\n",
      "Fold: 6  Epoch: 83  Training loss = 2.7943  Validation loss = 3.2133  \n",
      "\n",
      "Fold: 6  Epoch: 84  Training loss = 2.7941  Validation loss = 3.2130  \n",
      "\n",
      "Fold: 6  Epoch: 85  Training loss = 2.7940  Validation loss = 3.2127  \n",
      "\n",
      "Fold: 6  Epoch: 86  Training loss = 2.7938  Validation loss = 3.2124  \n",
      "\n",
      "Fold: 6  Epoch: 87  Training loss = 2.7936  Validation loss = 3.2121  \n",
      "\n",
      "Fold: 6  Epoch: 88  Training loss = 2.7935  Validation loss = 3.2119  \n",
      "\n",
      "Fold: 6  Epoch: 89  Training loss = 2.7933  Validation loss = 3.2117  \n",
      "\n",
      "Fold: 6  Epoch: 90  Training loss = 2.7932  Validation loss = 3.2115  \n",
      "\n",
      "Fold: 6  Epoch: 91  Training loss = 2.7930  Validation loss = 3.2113  \n",
      "\n",
      "Fold: 6  Epoch: 92  Training loss = 2.7928  Validation loss = 3.2110  \n",
      "\n",
      "Fold: 6  Epoch: 93  Training loss = 2.7926  Validation loss = 3.2107  \n",
      "\n",
      "Fold: 6  Epoch: 94  Training loss = 2.7925  Validation loss = 3.2104  \n",
      "\n",
      "Fold: 6  Epoch: 95  Training loss = 2.7923  Validation loss = 3.2102  \n",
      "\n",
      "Fold: 6  Epoch: 96  Training loss = 2.7921  Validation loss = 3.2099  \n",
      "\n",
      "Fold: 6  Epoch: 97  Training loss = 2.7920  Validation loss = 3.2096  \n",
      "\n",
      "Fold: 6  Epoch: 98  Training loss = 2.7918  Validation loss = 3.2093  \n",
      "\n",
      "Fold: 6  Epoch: 99  Training loss = 2.7916  Validation loss = 3.2091  \n",
      "\n",
      "Fold: 6  Epoch: 100  Training loss = 2.7915  Validation loss = 3.2089  \n",
      "\n",
      "Fold: 6  Epoch: 101  Training loss = 2.7913  Validation loss = 3.2086  \n",
      "\n",
      "Fold: 6  Epoch: 102  Training loss = 2.7911  Validation loss = 3.2083  \n",
      "\n",
      "Fold: 6  Epoch: 103  Training loss = 2.7910  Validation loss = 3.2080  \n",
      "\n",
      "Fold: 6  Epoch: 104  Training loss = 2.7908  Validation loss = 3.2078  \n",
      "\n",
      "Fold: 6  Epoch: 105  Training loss = 2.7906  Validation loss = 3.2075  \n",
      "\n",
      "Fold: 6  Epoch: 106  Training loss = 2.7904  Validation loss = 3.2072  \n",
      "\n",
      "Fold: 6  Epoch: 107  Training loss = 2.7902  Validation loss = 3.2069  \n",
      "\n",
      "Fold: 6  Epoch: 108  Training loss = 2.7900  Validation loss = 3.2066  \n",
      "\n",
      "Fold: 6  Epoch: 109  Training loss = 2.7899  Validation loss = 3.2064  \n",
      "\n",
      "Fold: 6  Epoch: 110  Training loss = 2.7896  Validation loss = 3.2060  \n",
      "\n",
      "Fold: 6  Epoch: 111  Training loss = 2.7895  Validation loss = 3.2057  \n",
      "\n",
      "Fold: 6  Epoch: 112  Training loss = 2.7893  Validation loss = 3.2055  \n",
      "\n",
      "Fold: 6  Epoch: 113  Training loss = 2.7891  Validation loss = 3.2052  \n",
      "\n",
      "Fold: 6  Epoch: 114  Training loss = 2.7890  Validation loss = 3.2050  \n",
      "\n",
      "Fold: 6  Epoch: 115  Training loss = 2.7888  Validation loss = 3.2048  \n",
      "\n",
      "Fold: 6  Epoch: 116  Training loss = 2.7886  Validation loss = 3.2044  \n",
      "\n",
      "Fold: 6  Epoch: 117  Training loss = 2.7885  Validation loss = 3.2042  \n",
      "\n",
      "Fold: 6  Epoch: 118  Training loss = 2.7883  Validation loss = 3.2039  \n",
      "\n",
      "Fold: 6  Epoch: 119  Training loss = 2.7881  Validation loss = 3.2036  \n",
      "\n",
      "Fold: 6  Epoch: 120  Training loss = 2.7879  Validation loss = 3.2033  \n",
      "\n",
      "Fold: 6  Epoch: 121  Training loss = 2.7877  Validation loss = 3.2030  \n",
      "\n",
      "Fold: 6  Epoch: 122  Training loss = 2.7876  Validation loss = 3.2028  \n",
      "\n",
      "Fold: 6  Epoch: 123  Training loss = 2.7874  Validation loss = 3.2025  \n",
      "\n",
      "Fold: 6  Epoch: 124  Training loss = 2.7873  Validation loss = 3.2023  \n",
      "\n",
      "Fold: 6  Epoch: 125  Training loss = 2.7871  Validation loss = 3.2021  \n",
      "\n",
      "Fold: 6  Epoch: 126  Training loss = 2.7869  Validation loss = 3.2017  \n",
      "\n",
      "Fold: 6  Epoch: 127  Training loss = 2.7867  Validation loss = 3.2015  \n",
      "\n",
      "Fold: 6  Epoch: 128  Training loss = 2.7866  Validation loss = 3.2012  \n",
      "\n",
      "Fold: 6  Epoch: 129  Training loss = 2.7864  Validation loss = 3.2010  \n",
      "\n",
      "Fold: 6  Epoch: 130  Training loss = 2.7863  Validation loss = 3.2008  \n",
      "\n",
      "Fold: 6  Epoch: 131  Training loss = 2.7860  Validation loss = 3.2004  \n",
      "\n",
      "Fold: 6  Epoch: 132  Training loss = 2.7859  Validation loss = 3.2002  \n",
      "\n",
      "Fold: 6  Epoch: 133  Training loss = 2.7857  Validation loss = 3.1999  \n",
      "\n",
      "Fold: 6  Epoch: 134  Training loss = 2.7855  Validation loss = 3.1996  \n",
      "\n",
      "Fold: 6  Epoch: 135  Training loss = 2.7853  Validation loss = 3.1993  \n",
      "\n",
      "Fold: 6  Epoch: 136  Training loss = 2.7851  Validation loss = 3.1990  \n",
      "\n",
      "Fold: 6  Epoch: 137  Training loss = 2.7850  Validation loss = 3.1987  \n",
      "\n",
      "Fold: 6  Epoch: 138  Training loss = 2.7848  Validation loss = 3.1984  \n",
      "\n",
      "Fold: 6  Epoch: 139  Training loss = 2.7846  Validation loss = 3.1982  \n",
      "\n",
      "Fold: 6  Epoch: 140  Training loss = 2.7844  Validation loss = 3.1979  \n",
      "\n",
      "Fold: 6  Epoch: 141  Training loss = 2.7842  Validation loss = 3.1976  \n",
      "\n",
      "Fold: 6  Epoch: 142  Training loss = 2.7840  Validation loss = 3.1973  \n",
      "\n",
      "Fold: 6  Epoch: 143  Training loss = 2.7839  Validation loss = 3.1970  \n",
      "\n",
      "Fold: 6  Epoch: 144  Training loss = 2.7837  Validation loss = 3.1967  \n",
      "\n",
      "Fold: 6  Epoch: 145  Training loss = 2.7835  Validation loss = 3.1965  \n",
      "\n",
      "Fold: 6  Epoch: 146  Training loss = 2.7834  Validation loss = 3.1963  \n",
      "\n",
      "Fold: 6  Epoch: 147  Training loss = 2.7832  Validation loss = 3.1960  \n",
      "\n",
      "Fold: 6  Epoch: 148  Training loss = 2.7830  Validation loss = 3.1957  \n",
      "\n",
      "Fold: 6  Epoch: 149  Training loss = 2.7828  Validation loss = 3.1954  \n",
      "\n",
      "Fold: 6  Epoch: 150  Training loss = 2.7827  Validation loss = 3.1952  \n",
      "\n",
      "Fold: 6  Epoch: 151  Training loss = 2.7825  Validation loss = 3.1949  \n",
      "\n",
      "Fold: 6  Epoch: 152  Training loss = 2.7823  Validation loss = 3.1946  \n",
      "\n",
      "Fold: 6  Epoch: 153  Training loss = 2.7821  Validation loss = 3.1943  \n",
      "\n",
      "Fold: 6  Epoch: 154  Training loss = 2.7819  Validation loss = 3.1941  \n",
      "\n",
      "Fold: 6  Epoch: 155  Training loss = 2.7818  Validation loss = 3.1938  \n",
      "\n",
      "Fold: 6  Epoch: 156  Training loss = 2.7816  Validation loss = 3.1936  \n",
      "\n",
      "Fold: 6  Epoch: 157  Training loss = 2.7815  Validation loss = 3.1933  \n",
      "\n",
      "Fold: 6  Epoch: 158  Training loss = 2.7813  Validation loss = 3.1930  \n",
      "\n",
      "Fold: 6  Epoch: 159  Training loss = 2.7811  Validation loss = 3.1928  \n",
      "\n",
      "Fold: 6  Epoch: 160  Training loss = 2.7810  Validation loss = 3.1926  \n",
      "\n",
      "Fold: 6  Epoch: 161  Training loss = 2.7808  Validation loss = 3.1923  \n",
      "\n",
      "Fold: 6  Epoch: 162  Training loss = 2.7807  Validation loss = 3.1921  \n",
      "\n",
      "Fold: 6  Epoch: 163  Training loss = 2.7805  Validation loss = 3.1918  \n",
      "\n",
      "Fold: 6  Epoch: 164  Training loss = 2.7803  Validation loss = 3.1916  \n",
      "\n",
      "Fold: 6  Epoch: 165  Training loss = 2.7802  Validation loss = 3.1913  \n",
      "\n",
      "Fold: 6  Epoch: 166  Training loss = 2.7800  Validation loss = 3.1911  \n",
      "\n",
      "Fold: 6  Epoch: 167  Training loss = 2.7799  Validation loss = 3.1909  \n",
      "\n",
      "Fold: 6  Epoch: 168  Training loss = 2.7797  Validation loss = 3.1907  \n",
      "\n",
      "Fold: 6  Epoch: 169  Training loss = 2.7795  Validation loss = 3.1904  \n",
      "\n",
      "Fold: 6  Epoch: 170  Training loss = 2.7794  Validation loss = 3.1901  \n",
      "\n",
      "Fold: 6  Epoch: 171  Training loss = 2.7792  Validation loss = 3.1899  \n",
      "\n",
      "Fold: 6  Epoch: 172  Training loss = 2.7791  Validation loss = 3.1896  \n",
      "\n",
      "Fold: 6  Epoch: 173  Training loss = 2.7789  Validation loss = 3.1894  \n",
      "\n",
      "Fold: 6  Epoch: 174  Training loss = 2.7787  Validation loss = 3.1891  \n",
      "\n",
      "Fold: 6  Epoch: 175  Training loss = 2.7786  Validation loss = 3.1889  \n",
      "\n",
      "Fold: 6  Epoch: 176  Training loss = 2.7785  Validation loss = 3.1887  \n",
      "\n",
      "Fold: 6  Epoch: 177  Training loss = 2.7783  Validation loss = 3.1884  \n",
      "\n",
      "Fold: 6  Epoch: 178  Training loss = 2.7781  Validation loss = 3.1882  \n",
      "\n",
      "Fold: 6  Epoch: 179  Training loss = 2.7779  Validation loss = 3.1878  \n",
      "\n",
      "Fold: 6  Epoch: 180  Training loss = 2.7778  Validation loss = 3.1876  \n",
      "\n",
      "Fold: 6  Epoch: 181  Training loss = 2.7776  Validation loss = 3.1873  \n",
      "\n",
      "Fold: 6  Epoch: 182  Training loss = 2.7774  Validation loss = 3.1871  \n",
      "\n",
      "Fold: 6  Epoch: 183  Training loss = 2.7773  Validation loss = 3.1868  \n",
      "\n",
      "Fold: 6  Epoch: 184  Training loss = 2.7771  Validation loss = 3.1865  \n",
      "\n",
      "Fold: 6  Epoch: 185  Training loss = 2.7769  Validation loss = 3.1862  \n",
      "\n",
      "Fold: 6  Epoch: 186  Training loss = 2.7767  Validation loss = 3.1860  \n",
      "\n",
      "Fold: 6  Epoch: 187  Training loss = 2.7765  Validation loss = 3.1857  \n",
      "\n",
      "Fold: 6  Epoch: 188  Training loss = 2.7764  Validation loss = 3.1855  \n",
      "\n",
      "Fold: 6  Epoch: 189  Training loss = 2.7762  Validation loss = 3.1853  \n",
      "\n",
      "Fold: 6  Epoch: 190  Training loss = 2.7760  Validation loss = 3.1850  \n",
      "\n",
      "Fold: 6  Epoch: 191  Training loss = 2.7759  Validation loss = 3.1847  \n",
      "\n",
      "Fold: 6  Epoch: 192  Training loss = 2.7757  Validation loss = 3.1845  \n",
      "\n",
      "Fold: 6  Epoch: 193  Training loss = 2.7756  Validation loss = 3.1843  \n",
      "\n",
      "Fold: 6  Epoch: 194  Training loss = 2.7754  Validation loss = 3.1840  \n",
      "\n",
      "Fold: 6  Epoch: 195  Training loss = 2.7752  Validation loss = 3.1837  \n",
      "\n",
      "Fold: 6  Epoch: 196  Training loss = 2.7750  Validation loss = 3.1834  \n",
      "\n",
      "Fold: 6  Epoch: 197  Training loss = 2.7749  Validation loss = 3.1832  \n",
      "\n",
      "Fold: 6  Epoch: 198  Training loss = 2.7748  Validation loss = 3.1830  \n",
      "\n",
      "Fold: 6  Epoch: 199  Training loss = 2.7746  Validation loss = 3.1827  \n",
      "\n",
      "Fold: 6  Epoch: 200  Training loss = 2.7744  Validation loss = 3.1825  \n",
      "\n",
      "Fold: 6  Epoch: 201  Training loss = 2.7742  Validation loss = 3.1822  \n",
      "\n",
      "Fold: 6  Epoch: 202  Training loss = 2.7741  Validation loss = 3.1820  \n",
      "\n",
      "Fold: 6  Epoch: 203  Training loss = 2.7739  Validation loss = 3.1817  \n",
      "\n",
      "Fold: 6  Epoch: 204  Training loss = 2.7738  Validation loss = 3.1815  \n",
      "\n",
      "Fold: 6  Epoch: 205  Training loss = 2.7736  Validation loss = 3.1812  \n",
      "\n",
      "Fold: 6  Epoch: 206  Training loss = 2.7735  Validation loss = 3.1810  \n",
      "\n",
      "Fold: 6  Epoch: 207  Training loss = 2.7733  Validation loss = 3.1807  \n",
      "\n",
      "Fold: 6  Epoch: 208  Training loss = 2.7731  Validation loss = 3.1805  \n",
      "\n",
      "Fold: 6  Epoch: 209  Training loss = 2.7730  Validation loss = 3.1802  \n",
      "\n",
      "Fold: 6  Epoch: 210  Training loss = 2.7728  Validation loss = 3.1800  \n",
      "\n",
      "Fold: 6  Epoch: 211  Training loss = 2.7727  Validation loss = 3.1798  \n",
      "\n",
      "Fold: 6  Epoch: 212  Training loss = 2.7725  Validation loss = 3.1796  \n",
      "\n",
      "Fold: 6  Epoch: 213  Training loss = 2.7723  Validation loss = 3.1793  \n",
      "\n",
      "Fold: 6  Epoch: 214  Training loss = 2.7721  Validation loss = 3.1790  \n",
      "\n",
      "Fold: 6  Epoch: 215  Training loss = 2.7720  Validation loss = 3.1787  \n",
      "\n",
      "Fold: 6  Epoch: 216  Training loss = 2.7719  Validation loss = 3.1786  \n",
      "\n",
      "Fold: 6  Epoch: 217  Training loss = 2.7717  Validation loss = 3.1783  \n",
      "\n",
      "Fold: 6  Epoch: 218  Training loss = 2.7716  Validation loss = 3.1781  \n",
      "\n",
      "Fold: 6  Epoch: 219  Training loss = 2.7714  Validation loss = 3.1778  \n",
      "\n",
      "Fold: 6  Epoch: 220  Training loss = 2.7712  Validation loss = 3.1775  \n",
      "\n",
      "Fold: 6  Epoch: 221  Training loss = 2.7710  Validation loss = 3.1772  \n",
      "\n",
      "Fold: 6  Epoch: 222  Training loss = 2.7708  Validation loss = 3.1769  \n",
      "\n",
      "Fold: 6  Epoch: 223  Training loss = 2.7706  Validation loss = 3.1767  \n",
      "\n",
      "Fold: 6  Epoch: 224  Training loss = 2.7705  Validation loss = 3.1764  \n",
      "\n",
      "Fold: 6  Epoch: 225  Training loss = 2.7703  Validation loss = 3.1761  \n",
      "\n",
      "Fold: 6  Epoch: 226  Training loss = 2.7701  Validation loss = 3.1758  \n",
      "\n",
      "Fold: 6  Epoch: 227  Training loss = 2.7699  Validation loss = 3.1756  \n",
      "\n",
      "Fold: 6  Epoch: 228  Training loss = 2.7697  Validation loss = 3.1753  \n",
      "\n",
      "Fold: 6  Epoch: 229  Training loss = 2.7695  Validation loss = 3.1749  \n",
      "\n",
      "Fold: 6  Epoch: 230  Training loss = 2.7693  Validation loss = 3.1746  \n",
      "\n",
      "Fold: 6  Epoch: 231  Training loss = 2.7691  Validation loss = 3.1743  \n",
      "\n",
      "Fold: 6  Epoch: 232  Training loss = 2.7689  Validation loss = 3.1740  \n",
      "\n",
      "Fold: 6  Epoch: 233  Training loss = 2.7687  Validation loss = 3.1737  \n",
      "\n",
      "Fold: 6  Epoch: 234  Training loss = 2.7686  Validation loss = 3.1735  \n",
      "\n",
      "Fold: 6  Epoch: 235  Training loss = 2.7684  Validation loss = 3.1732  \n",
      "\n",
      "Fold: 6  Epoch: 236  Training loss = 2.7682  Validation loss = 3.1729  \n",
      "\n",
      "Fold: 6  Epoch: 237  Training loss = 2.7680  Validation loss = 3.1726  \n",
      "\n",
      "Fold: 6  Epoch: 238  Training loss = 2.7679  Validation loss = 3.1724  \n",
      "\n",
      "Fold: 6  Epoch: 239  Training loss = 2.7677  Validation loss = 3.1721  \n",
      "\n",
      "Fold: 6  Epoch: 240  Training loss = 2.7675  Validation loss = 3.1718  \n",
      "\n",
      "Fold: 6  Epoch: 241  Training loss = 2.7673  Validation loss = 3.1715  \n",
      "\n",
      "Fold: 6  Epoch: 242  Training loss = 2.7671  Validation loss = 3.1712  \n",
      "\n",
      "Fold: 6  Epoch: 243  Training loss = 2.7670  Validation loss = 3.1710  \n",
      "\n",
      "Fold: 6  Epoch: 244  Training loss = 2.7669  Validation loss = 3.1708  \n",
      "\n",
      "Fold: 6  Epoch: 245  Training loss = 2.7667  Validation loss = 3.1705  \n",
      "\n",
      "Fold: 6  Epoch: 246  Training loss = 2.7665  Validation loss = 3.1702  \n",
      "\n",
      "Fold: 6  Epoch: 247  Training loss = 2.7663  Validation loss = 3.1700  \n",
      "\n",
      "Fold: 6  Epoch: 248  Training loss = 2.7661  Validation loss = 3.1697  \n",
      "\n",
      "Fold: 6  Epoch: 249  Training loss = 2.7660  Validation loss = 3.1695  \n",
      "\n",
      "Fold: 6  Epoch: 250  Training loss = 2.7659  Validation loss = 3.1692  \n",
      "\n",
      "Fold: 6  Epoch: 251  Training loss = 2.7657  Validation loss = 3.1690  \n",
      "\n",
      "Fold: 6  Epoch: 252  Training loss = 2.7656  Validation loss = 3.1688  \n",
      "\n",
      "Fold: 6  Epoch: 253  Training loss = 2.7654  Validation loss = 3.1685  \n",
      "\n",
      "Fold: 6  Epoch: 254  Training loss = 2.7653  Validation loss = 3.1683  \n",
      "\n",
      "Fold: 6  Epoch: 255  Training loss = 2.7651  Validation loss = 3.1681  \n",
      "\n",
      "Fold: 6  Epoch: 256  Training loss = 2.7649  Validation loss = 3.1678  \n",
      "\n",
      "Fold: 6  Epoch: 257  Training loss = 2.7648  Validation loss = 3.1676  \n",
      "\n",
      "Fold: 6  Epoch: 258  Training loss = 2.7647  Validation loss = 3.1674  \n",
      "\n",
      "Fold: 6  Epoch: 259  Training loss = 2.7645  Validation loss = 3.1672  \n",
      "\n",
      "Fold: 6  Epoch: 260  Training loss = 2.7644  Validation loss = 3.1670  \n",
      "\n",
      "Fold: 6  Epoch: 261  Training loss = 2.7642  Validation loss = 3.1667  \n",
      "\n",
      "Fold: 6  Epoch: 262  Training loss = 2.7640  Validation loss = 3.1664  \n",
      "\n",
      "Fold: 6  Epoch: 263  Training loss = 2.7638  Validation loss = 3.1662  \n",
      "\n",
      "Fold: 6  Epoch: 264  Training loss = 2.7637  Validation loss = 3.1659  \n",
      "\n",
      "Fold: 6  Epoch: 265  Training loss = 2.7635  Validation loss = 3.1657  \n",
      "\n",
      "Fold: 6  Epoch: 266  Training loss = 2.7634  Validation loss = 3.1654  \n",
      "\n",
      "Fold: 6  Epoch: 267  Training loss = 2.7632  Validation loss = 3.1652  \n",
      "\n",
      "Fold: 6  Epoch: 268  Training loss = 2.7631  Validation loss = 3.1649  \n",
      "\n",
      "Fold: 6  Epoch: 269  Training loss = 2.7629  Validation loss = 3.1647  \n",
      "\n",
      "Fold: 6  Epoch: 270  Training loss = 2.7627  Validation loss = 3.1644  \n",
      "\n",
      "Fold: 6  Epoch: 271  Training loss = 2.7625  Validation loss = 3.1642  \n",
      "\n",
      "Fold: 6  Epoch: 272  Training loss = 2.7624  Validation loss = 3.1639  \n",
      "\n",
      "Fold: 6  Epoch: 273  Training loss = 2.7622  Validation loss = 3.1636  \n",
      "\n",
      "Fold: 6  Epoch: 274  Training loss = 2.7620  Validation loss = 3.1633  \n",
      "\n",
      "Fold: 6  Epoch: 275  Training loss = 2.7618  Validation loss = 3.1630  \n",
      "\n",
      "Fold: 6  Epoch: 276  Training loss = 2.7617  Validation loss = 3.1628  \n",
      "\n",
      "Fold: 6  Epoch: 277  Training loss = 2.7615  Validation loss = 3.1626  \n",
      "\n",
      "Fold: 6  Epoch: 278  Training loss = 2.7613  Validation loss = 3.1623  \n",
      "\n",
      "Fold: 6  Epoch: 279  Training loss = 2.7611  Validation loss = 3.1620  \n",
      "\n",
      "Fold: 6  Epoch: 280  Training loss = 2.7610  Validation loss = 3.1618  \n",
      "\n",
      "Fold: 6  Epoch: 281  Training loss = 2.7609  Validation loss = 3.1616  \n",
      "\n",
      "Fold: 6  Epoch: 282  Training loss = 2.7607  Validation loss = 3.1613  \n",
      "\n",
      "Fold: 6  Epoch: 283  Training loss = 2.7605  Validation loss = 3.1610  \n",
      "\n",
      "Fold: 6  Epoch: 284  Training loss = 2.7604  Validation loss = 3.1609  \n",
      "\n",
      "Fold: 6  Epoch: 285  Training loss = 2.7602  Validation loss = 3.1606  \n",
      "\n",
      "Fold: 6  Epoch: 286  Training loss = 2.7600  Validation loss = 3.1603  \n",
      "\n",
      "Fold: 6  Epoch: 287  Training loss = 2.7599  Validation loss = 3.1601  \n",
      "\n",
      "Fold: 6  Epoch: 288  Training loss = 2.7597  Validation loss = 3.1598  \n",
      "\n",
      "Fold: 6  Epoch: 289  Training loss = 2.7595  Validation loss = 3.1595  \n",
      "\n",
      "Fold: 6  Epoch: 290  Training loss = 2.7594  Validation loss = 3.1593  \n",
      "\n",
      "Fold: 6  Epoch: 291  Training loss = 2.7592  Validation loss = 3.1591  \n",
      "\n",
      "Fold: 6  Epoch: 292  Training loss = 2.7591  Validation loss = 3.1588  \n",
      "\n",
      "Fold: 6  Epoch: 293  Training loss = 2.7589  Validation loss = 3.1586  \n",
      "\n",
      "Fold: 6  Epoch: 294  Training loss = 2.7587  Validation loss = 3.1583  \n",
      "\n",
      "Fold: 6  Epoch: 295  Training loss = 2.7586  Validation loss = 3.1581  \n",
      "\n",
      "Fold: 6  Epoch: 296  Training loss = 2.7584  Validation loss = 3.1579  \n",
      "\n",
      "Fold: 6  Epoch: 297  Training loss = 2.7583  Validation loss = 3.1577  \n",
      "\n",
      "Fold: 6  Epoch: 298  Training loss = 2.7582  Validation loss = 3.1575  \n",
      "\n",
      "Fold: 6  Epoch: 299  Training loss = 2.7580  Validation loss = 3.1572  \n",
      "\n",
      "Fold: 6  Epoch: 300  Training loss = 2.7579  Validation loss = 3.1570  \n",
      "\n",
      "Fold: 6  Epoch: 301  Training loss = 2.7577  Validation loss = 3.1567  \n",
      "\n",
      "Fold: 6  Epoch: 302  Training loss = 2.7575  Validation loss = 3.1565  \n",
      "\n",
      "Fold: 6  Epoch: 303  Training loss = 2.7574  Validation loss = 3.1563  \n",
      "\n",
      "Fold: 6  Epoch: 304  Training loss = 2.7573  Validation loss = 3.1561  \n",
      "\n",
      "Fold: 6  Epoch: 305  Training loss = 2.7571  Validation loss = 3.1559  \n",
      "\n",
      "Fold: 6  Epoch: 306  Training loss = 2.7570  Validation loss = 3.1557  \n",
      "\n",
      "Fold: 6  Epoch: 307  Training loss = 2.7568  Validation loss = 3.1554  \n",
      "\n",
      "Fold: 6  Epoch: 308  Training loss = 2.7567  Validation loss = 3.1553  \n",
      "\n",
      "Fold: 6  Epoch: 309  Training loss = 2.7566  Validation loss = 3.1550  \n",
      "\n",
      "Fold: 6  Epoch: 310  Training loss = 2.7564  Validation loss = 3.1547  \n",
      "\n",
      "Fold: 6  Epoch: 311  Training loss = 2.7562  Validation loss = 3.1544  \n",
      "\n",
      "Fold: 6  Epoch: 312  Training loss = 2.7560  Validation loss = 3.1541  \n",
      "\n",
      "Fold: 6  Epoch: 313  Training loss = 2.7558  Validation loss = 3.1538  \n",
      "\n",
      "Fold: 6  Epoch: 314  Training loss = 2.7556  Validation loss = 3.1536  \n",
      "\n",
      "Fold: 6  Epoch: 315  Training loss = 2.7555  Validation loss = 3.1534  \n",
      "\n",
      "Fold: 6  Epoch: 316  Training loss = 2.7554  Validation loss = 3.1532  \n",
      "\n",
      "Fold: 6  Epoch: 317  Training loss = 2.7552  Validation loss = 3.1529  \n",
      "\n",
      "Fold: 6  Epoch: 318  Training loss = 2.7550  Validation loss = 3.1527  \n",
      "\n",
      "Fold: 6  Epoch: 319  Training loss = 2.7549  Validation loss = 3.1524  \n",
      "\n",
      "Fold: 6  Epoch: 320  Training loss = 2.7547  Validation loss = 3.1521  \n",
      "\n",
      "Fold: 6  Epoch: 321  Training loss = 2.7545  Validation loss = 3.1518  \n",
      "\n",
      "Fold: 6  Epoch: 322  Training loss = 2.7543  Validation loss = 3.1515  \n",
      "\n",
      "Fold: 6  Epoch: 323  Training loss = 2.7541  Validation loss = 3.1513  \n",
      "\n",
      "Fold: 6  Epoch: 324  Training loss = 2.7540  Validation loss = 3.1510  \n",
      "\n",
      "Fold: 6  Epoch: 325  Training loss = 2.7538  Validation loss = 3.1508  \n",
      "\n",
      "Fold: 6  Epoch: 326  Training loss = 2.7536  Validation loss = 3.1505  \n",
      "\n",
      "Fold: 6  Epoch: 327  Training loss = 2.7535  Validation loss = 3.1503  \n",
      "\n",
      "Fold: 6  Epoch: 328  Training loss = 2.7533  Validation loss = 3.1500  \n",
      "\n",
      "Fold: 6  Epoch: 329  Training loss = 2.7532  Validation loss = 3.1498  \n",
      "\n",
      "Fold: 6  Epoch: 330  Training loss = 2.7530  Validation loss = 3.1496  \n",
      "\n",
      "Fold: 6  Epoch: 331  Training loss = 2.7528  Validation loss = 3.1492  \n",
      "\n",
      "Fold: 6  Epoch: 332  Training loss = 2.7526  Validation loss = 3.1490  \n",
      "\n",
      "Fold: 6  Epoch: 333  Training loss = 2.7525  Validation loss = 3.1487  \n",
      "\n",
      "Fold: 6  Epoch: 334  Training loss = 2.7523  Validation loss = 3.1485  \n",
      "\n",
      "Fold: 6  Epoch: 335  Training loss = 2.7522  Validation loss = 3.1483  \n",
      "\n",
      "Fold: 6  Epoch: 336  Training loss = 2.7520  Validation loss = 3.1480  \n",
      "\n",
      "Fold: 6  Epoch: 337  Training loss = 2.7518  Validation loss = 3.1477  \n",
      "\n",
      "Fold: 6  Epoch: 338  Training loss = 2.7517  Validation loss = 3.1475  \n",
      "\n",
      "Fold: 6  Epoch: 339  Training loss = 2.7515  Validation loss = 3.1472  \n",
      "\n",
      "Fold: 6  Epoch: 340  Training loss = 2.7513  Validation loss = 3.1469  \n",
      "\n",
      "Fold: 6  Epoch: 341  Training loss = 2.7511  Validation loss = 3.1467  \n",
      "\n",
      "Fold: 6  Epoch: 342  Training loss = 2.7509  Validation loss = 3.1464  \n",
      "\n",
      "Fold: 6  Epoch: 343  Training loss = 2.7508  Validation loss = 3.1461  \n",
      "\n",
      "Fold: 6  Epoch: 344  Training loss = 2.7506  Validation loss = 3.1459  \n",
      "\n",
      "Fold: 6  Epoch: 345  Training loss = 2.7504  Validation loss = 3.1456  \n",
      "\n",
      "Fold: 6  Epoch: 346  Training loss = 2.7503  Validation loss = 3.1454  \n",
      "\n",
      "Fold: 6  Epoch: 347  Training loss = 2.7502  Validation loss = 3.1452  \n",
      "\n",
      "Fold: 6  Epoch: 348  Training loss = 2.7500  Validation loss = 3.1449  \n",
      "\n",
      "Fold: 6  Epoch: 349  Training loss = 2.7498  Validation loss = 3.1446  \n",
      "\n",
      "Fold: 6  Epoch: 350  Training loss = 2.7496  Validation loss = 3.1444  \n",
      "\n",
      "Fold: 6  Epoch: 351  Training loss = 2.7495  Validation loss = 3.1442  \n",
      "\n",
      "Fold: 6  Epoch: 352  Training loss = 2.7493  Validation loss = 3.1439  \n",
      "\n",
      "Fold: 6  Epoch: 353  Training loss = 2.7491  Validation loss = 3.1436  \n",
      "\n",
      "Fold: 6  Epoch: 354  Training loss = 2.7490  Validation loss = 3.1433  \n",
      "\n",
      "Fold: 6  Epoch: 355  Training loss = 2.7488  Validation loss = 3.1431  \n",
      "\n",
      "Fold: 6  Epoch: 356  Training loss = 2.7487  Validation loss = 3.1430  \n",
      "\n",
      "Fold: 6  Epoch: 357  Training loss = 2.7485  Validation loss = 3.1427  \n",
      "\n",
      "Fold: 6  Epoch: 358  Training loss = 2.7484  Validation loss = 3.1425  \n",
      "\n",
      "Fold: 6  Epoch: 359  Training loss = 2.7482  Validation loss = 3.1422  \n",
      "\n",
      "Fold: 6  Epoch: 360  Training loss = 2.7481  Validation loss = 3.1420  \n",
      "\n",
      "Fold: 6  Epoch: 361  Training loss = 2.7480  Validation loss = 3.1418  \n",
      "\n",
      "Fold: 6  Epoch: 362  Training loss = 2.7478  Validation loss = 3.1416  \n",
      "\n",
      "Fold: 6  Epoch: 363  Training loss = 2.7477  Validation loss = 3.1414  \n",
      "\n",
      "Fold: 6  Epoch: 364  Training loss = 2.7475  Validation loss = 3.1411  \n",
      "\n",
      "Fold: 6  Epoch: 365  Training loss = 2.7474  Validation loss = 3.1409  \n",
      "\n",
      "Fold: 6  Epoch: 366  Training loss = 2.7472  Validation loss = 3.1407  \n",
      "\n",
      "Fold: 6  Epoch: 367  Training loss = 2.7470  Validation loss = 3.1404  \n",
      "\n",
      "Fold: 6  Epoch: 368  Training loss = 2.7468  Validation loss = 3.1401  \n",
      "\n",
      "Fold: 6  Epoch: 369  Training loss = 2.7467  Validation loss = 3.1399  \n",
      "\n",
      "Fold: 6  Epoch: 370  Training loss = 2.7466  Validation loss = 3.1397  \n",
      "\n",
      "Fold: 6  Epoch: 371  Training loss = 2.7464  Validation loss = 3.1394  \n",
      "\n",
      "Fold: 6  Epoch: 372  Training loss = 2.7462  Validation loss = 3.1391  \n",
      "\n",
      "Fold: 6  Epoch: 373  Training loss = 2.7461  Validation loss = 3.1389  \n",
      "\n",
      "Fold: 6  Epoch: 374  Training loss = 2.7459  Validation loss = 3.1387  \n",
      "\n",
      "Fold: 6  Epoch: 375  Training loss = 2.7458  Validation loss = 3.1384  \n",
      "\n",
      "Fold: 6  Epoch: 376  Training loss = 2.7456  Validation loss = 3.1382  \n",
      "\n",
      "Fold: 6  Epoch: 377  Training loss = 2.7454  Validation loss = 3.1379  \n",
      "\n",
      "Fold: 6  Epoch: 378  Training loss = 2.7452  Validation loss = 3.1376  \n",
      "\n",
      "Fold: 6  Epoch: 379  Training loss = 2.7451  Validation loss = 3.1374  \n",
      "\n",
      "Fold: 6  Epoch: 380  Training loss = 2.7449  Validation loss = 3.1371  \n",
      "\n",
      "Fold: 6  Epoch: 381  Training loss = 2.7447  Validation loss = 3.1369  \n",
      "\n",
      "Fold: 6  Epoch: 382  Training loss = 2.7446  Validation loss = 3.1366  \n",
      "\n",
      "Fold: 6  Epoch: 383  Training loss = 2.7444  Validation loss = 3.1364  \n",
      "\n",
      "Fold: 6  Epoch: 384  Training loss = 2.7443  Validation loss = 3.1361  \n",
      "\n",
      "Fold: 6  Epoch: 385  Training loss = 2.7441  Validation loss = 3.1360  \n",
      "\n",
      "Fold: 6  Epoch: 386  Training loss = 2.7439  Validation loss = 3.1357  \n",
      "\n",
      "Fold: 6  Epoch: 387  Training loss = 2.7438  Validation loss = 3.1354  \n",
      "\n",
      "Fold: 6  Epoch: 388  Training loss = 2.7436  Validation loss = 3.1352  \n",
      "\n",
      "Fold: 6  Epoch: 389  Training loss = 2.7435  Validation loss = 3.1349  \n",
      "\n",
      "Fold: 6  Epoch: 390  Training loss = 2.7433  Validation loss = 3.1347  \n",
      "\n",
      "Fold: 6  Epoch: 391  Training loss = 2.7432  Validation loss = 3.1345  \n",
      "\n",
      "Fold: 6  Epoch: 392  Training loss = 2.7430  Validation loss = 3.1342  \n",
      "\n",
      "Fold: 6  Epoch: 393  Training loss = 2.7428  Validation loss = 3.1339  \n",
      "\n",
      "Fold: 6  Epoch: 394  Training loss = 2.7427  Validation loss = 3.1337  \n",
      "\n",
      "Fold: 6  Epoch: 395  Training loss = 2.7425  Validation loss = 3.1335  \n",
      "\n",
      "Fold: 6  Epoch: 396  Training loss = 2.7424  Validation loss = 3.1333  \n",
      "\n",
      "Fold: 6  Epoch: 397  Training loss = 2.7422  Validation loss = 3.1330  \n",
      "\n",
      "Fold: 6  Epoch: 398  Training loss = 2.7421  Validation loss = 3.1328  \n",
      "\n",
      "Fold: 6  Epoch: 399  Training loss = 2.7420  Validation loss = 3.1326  \n",
      "\n",
      "Fold: 6  Epoch: 400  Training loss = 2.7418  Validation loss = 3.1324  \n",
      "\n",
      "Fold: 6  Epoch: 401  Training loss = 2.7417  Validation loss = 3.1322  \n",
      "\n",
      "Fold: 6  Epoch: 402  Training loss = 2.7415  Validation loss = 3.1319  \n",
      "\n",
      "Fold: 6  Epoch: 403  Training loss = 2.7414  Validation loss = 3.1317  \n",
      "\n",
      "Fold: 6  Epoch: 404  Training loss = 2.7412  Validation loss = 3.1315  \n",
      "\n",
      "Fold: 6  Epoch: 405  Training loss = 2.7410  Validation loss = 3.1312  \n",
      "\n",
      "Fold: 6  Epoch: 406  Training loss = 2.7408  Validation loss = 3.1309  \n",
      "\n",
      "Fold: 6  Epoch: 407  Training loss = 2.7407  Validation loss = 3.1306  \n",
      "\n",
      "Fold: 6  Epoch: 408  Training loss = 2.7405  Validation loss = 3.1304  \n",
      "\n",
      "Fold: 6  Epoch: 409  Training loss = 2.7404  Validation loss = 3.1301  \n",
      "\n",
      "Fold: 6  Epoch: 410  Training loss = 2.7402  Validation loss = 3.1299  \n",
      "\n",
      "Fold: 6  Epoch: 411  Training loss = 2.7400  Validation loss = 3.1296  \n",
      "\n",
      "Fold: 6  Epoch: 412  Training loss = 2.7398  Validation loss = 3.1293  \n",
      "\n",
      "Fold: 6  Epoch: 413  Training loss = 2.7397  Validation loss = 3.1291  \n",
      "\n",
      "Fold: 6  Epoch: 414  Training loss = 2.7395  Validation loss = 3.1288  \n",
      "\n",
      "Fold: 6  Epoch: 415  Training loss = 2.7393  Validation loss = 3.1285  \n",
      "\n",
      "Fold: 6  Epoch: 416  Training loss = 2.7391  Validation loss = 3.1282  \n",
      "\n",
      "Fold: 6  Epoch: 417  Training loss = 2.7390  Validation loss = 3.1280  \n",
      "\n",
      "Fold: 6  Epoch: 418  Training loss = 2.7388  Validation loss = 3.1278  \n",
      "\n",
      "Fold: 6  Epoch: 419  Training loss = 2.7387  Validation loss = 3.1275  \n",
      "\n",
      "Fold: 6  Epoch: 420  Training loss = 2.7385  Validation loss = 3.1273  \n",
      "\n",
      "Fold: 6  Epoch: 421  Training loss = 2.7384  Validation loss = 3.1271  \n",
      "\n",
      "Fold: 6  Epoch: 422  Training loss = 2.7382  Validation loss = 3.1269  \n",
      "\n",
      "Fold: 6  Epoch: 423  Training loss = 2.7381  Validation loss = 3.1266  \n",
      "\n",
      "Fold: 6  Epoch: 424  Training loss = 2.7379  Validation loss = 3.1264  \n",
      "\n",
      "Fold: 6  Epoch: 425  Training loss = 2.7377  Validation loss = 3.1261  \n",
      "\n",
      "Fold: 6  Epoch: 426  Training loss = 2.7375  Validation loss = 3.1258  \n",
      "\n",
      "Fold: 6  Epoch: 427  Training loss = 2.7374  Validation loss = 3.1255  \n",
      "\n",
      "Fold: 6  Epoch: 428  Training loss = 2.7372  Validation loss = 3.1254  \n",
      "\n",
      "Fold: 6  Epoch: 429  Training loss = 2.7370  Validation loss = 3.1251  \n",
      "\n",
      "Fold: 6  Epoch: 430  Training loss = 2.7369  Validation loss = 3.1248  \n",
      "\n",
      "Fold: 6  Epoch: 431  Training loss = 2.7367  Validation loss = 3.1246  \n",
      "\n",
      "Fold: 6  Epoch: 432  Training loss = 2.7366  Validation loss = 3.1243  \n",
      "\n",
      "Fold: 6  Epoch: 433  Training loss = 2.7364  Validation loss = 3.1242  \n",
      "\n",
      "Fold: 6  Epoch: 434  Training loss = 2.7363  Validation loss = 3.1239  \n",
      "\n",
      "Fold: 6  Epoch: 435  Training loss = 2.7361  Validation loss = 3.1236  \n",
      "\n",
      "Fold: 6  Epoch: 436  Training loss = 2.7360  Validation loss = 3.1234  \n",
      "\n",
      "Fold: 6  Epoch: 437  Training loss = 2.7358  Validation loss = 3.1232  \n",
      "\n",
      "Fold: 6  Epoch: 438  Training loss = 2.7356  Validation loss = 3.1229  \n",
      "\n",
      "Fold: 6  Epoch: 439  Training loss = 2.7355  Validation loss = 3.1227  \n",
      "\n",
      "Fold: 6  Epoch: 440  Training loss = 2.7353  Validation loss = 3.1224  \n",
      "\n",
      "Fold: 6  Epoch: 441  Training loss = 2.7351  Validation loss = 3.1222  \n",
      "\n",
      "Fold: 6  Epoch: 442  Training loss = 2.7350  Validation loss = 3.1219  \n",
      "\n",
      "Fold: 6  Epoch: 443  Training loss = 2.7348  Validation loss = 3.1217  \n",
      "\n",
      "Fold: 6  Epoch: 444  Training loss = 2.7347  Validation loss = 3.1214  \n",
      "\n",
      "Fold: 6  Epoch: 445  Training loss = 2.7345  Validation loss = 3.1212  \n",
      "\n",
      "Fold: 6  Epoch: 446  Training loss = 2.7344  Validation loss = 3.1210  \n",
      "\n",
      "Fold: 6  Epoch: 447  Training loss = 2.7342  Validation loss = 3.1207  \n",
      "\n",
      "Fold: 6  Epoch: 448  Training loss = 2.7341  Validation loss = 3.1205  \n",
      "\n",
      "Fold: 6  Epoch: 449  Training loss = 2.7339  Validation loss = 3.1203  \n",
      "\n",
      "Fold: 6  Epoch: 450  Training loss = 2.7338  Validation loss = 3.1201  \n",
      "\n",
      "Fold: 6  Epoch: 451  Training loss = 2.7336  Validation loss = 3.1199  \n",
      "\n",
      "Fold: 6  Epoch: 452  Training loss = 2.7335  Validation loss = 3.1196  \n",
      "\n",
      "Fold: 6  Epoch: 453  Training loss = 2.7333  Validation loss = 3.1193  \n",
      "\n",
      "Fold: 6  Epoch: 454  Training loss = 2.7331  Validation loss = 3.1191  \n",
      "\n",
      "Fold: 6  Epoch: 455  Training loss = 2.7330  Validation loss = 3.1189  \n",
      "\n",
      "Fold: 6  Epoch: 456  Training loss = 2.7328  Validation loss = 3.1186  \n",
      "\n",
      "Fold: 6  Epoch: 457  Training loss = 2.7327  Validation loss = 3.1184  \n",
      "\n",
      "Fold: 6  Epoch: 458  Training loss = 2.7325  Validation loss = 3.1181  \n",
      "\n",
      "Fold: 6  Epoch: 459  Training loss = 2.7324  Validation loss = 3.1179  \n",
      "\n",
      "Fold: 6  Epoch: 460  Training loss = 2.7322  Validation loss = 3.1177  \n",
      "\n",
      "Fold: 6  Epoch: 461  Training loss = 2.7320  Validation loss = 3.1174  \n",
      "\n",
      "Fold: 6  Epoch: 462  Training loss = 2.7319  Validation loss = 3.1172  \n",
      "\n",
      "Fold: 6  Epoch: 463  Training loss = 2.7317  Validation loss = 3.1170  \n",
      "\n",
      "Fold: 6  Epoch: 464  Training loss = 2.7316  Validation loss = 3.1167  \n",
      "\n",
      "Fold: 6  Epoch: 465  Training loss = 2.7314  Validation loss = 3.1165  \n",
      "\n",
      "Fold: 6  Epoch: 466  Training loss = 2.7313  Validation loss = 3.1163  \n",
      "\n",
      "Fold: 6  Epoch: 467  Training loss = 2.7311  Validation loss = 3.1160  \n",
      "\n",
      "Fold: 6  Epoch: 468  Training loss = 2.7310  Validation loss = 3.1158  \n",
      "\n",
      "Fold: 6  Epoch: 469  Training loss = 2.7308  Validation loss = 3.1155  \n",
      "\n",
      "Fold: 6  Epoch: 470  Training loss = 2.7307  Validation loss = 3.1153  \n",
      "\n",
      "Fold: 6  Epoch: 471  Training loss = 2.7305  Validation loss = 3.1151  \n",
      "\n",
      "Fold: 6  Epoch: 472  Training loss = 2.7304  Validation loss = 3.1149  \n",
      "\n",
      "Fold: 6  Epoch: 473  Training loss = 2.7302  Validation loss = 3.1146  \n",
      "\n",
      "Fold: 6  Epoch: 474  Training loss = 2.7301  Validation loss = 3.1144  \n",
      "\n",
      "Fold: 6  Epoch: 475  Training loss = 2.7299  Validation loss = 3.1141  \n",
      "\n",
      "Fold: 6  Epoch: 476  Training loss = 2.7298  Validation loss = 3.1139  \n",
      "\n",
      "Fold: 6  Epoch: 477  Training loss = 2.7296  Validation loss = 3.1138  \n",
      "\n",
      "Fold: 6  Epoch: 478  Training loss = 2.7295  Validation loss = 3.1135  \n",
      "\n",
      "Fold: 6  Epoch: 479  Training loss = 2.7293  Validation loss = 3.1133  \n",
      "\n",
      "Fold: 6  Epoch: 480  Training loss = 2.7292  Validation loss = 3.1130  \n",
      "\n",
      "Fold: 6  Epoch: 481  Training loss = 2.7290  Validation loss = 3.1129  \n",
      "\n",
      "Fold: 6  Epoch: 482  Training loss = 2.7289  Validation loss = 3.1127  \n",
      "\n",
      "Fold: 6  Epoch: 483  Training loss = 2.7288  Validation loss = 3.1125  \n",
      "\n",
      "Fold: 6  Epoch: 484  Training loss = 2.7286  Validation loss = 3.1122  \n",
      "\n",
      "Fold: 6  Epoch: 485  Training loss = 2.7285  Validation loss = 3.1120  \n",
      "\n",
      "Fold: 6  Epoch: 486  Training loss = 2.7283  Validation loss = 3.1118  \n",
      "\n",
      "Fold: 6  Epoch: 487  Training loss = 2.7282  Validation loss = 3.1116  \n",
      "\n",
      "Fold: 6  Epoch: 488  Training loss = 2.7280  Validation loss = 3.1113  \n",
      "\n",
      "Fold: 6  Epoch: 489  Training loss = 2.7278  Validation loss = 3.1111  \n",
      "\n",
      "Fold: 6  Epoch: 490  Training loss = 2.7277  Validation loss = 3.1108  \n",
      "\n",
      "Fold: 6  Epoch: 491  Training loss = 2.7276  Validation loss = 3.1106  \n",
      "\n",
      "Fold: 6  Epoch: 492  Training loss = 2.7274  Validation loss = 3.1104  \n",
      "\n",
      "Fold: 6  Epoch: 493  Training loss = 2.7273  Validation loss = 3.1102  \n",
      "\n",
      "Fold: 6  Epoch: 494  Training loss = 2.7271  Validation loss = 3.1099  \n",
      "\n",
      "Fold: 6  Epoch: 495  Training loss = 2.7269  Validation loss = 3.1096  \n",
      "\n",
      "Fold: 6  Epoch: 496  Training loss = 2.7268  Validation loss = 3.1094  \n",
      "\n",
      "Fold: 6  Epoch: 497  Training loss = 2.7266  Validation loss = 3.1091  \n",
      "\n",
      "Fold: 6  Epoch: 498  Training loss = 2.7264  Validation loss = 3.1089  \n",
      "\n",
      "Fold: 6  Epoch: 499  Training loss = 2.7263  Validation loss = 3.1087  \n",
      "\n",
      "Fold: 6  Epoch: 500  Training loss = 2.7262  Validation loss = 3.1085  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 500  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 2.8169  Validation loss = 2.7576  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 2.8167  Validation loss = 2.7573  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 2.8165  Validation loss = 2.7571  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 2.8163  Validation loss = 2.7569  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 2.8161  Validation loss = 2.7566  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 2.8159  Validation loss = 2.7564  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 2.8157  Validation loss = 2.7562  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 2.8156  Validation loss = 2.7560  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 2.8154  Validation loss = 2.7557  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 2.8152  Validation loss = 2.7555  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 2.8150  Validation loss = 2.7552  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 2.8148  Validation loss = 2.7550  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 2.8146  Validation loss = 2.7547  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 2.8144  Validation loss = 2.7546  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 2.8142  Validation loss = 2.7543  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 2.8140  Validation loss = 2.7540  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 2.8138  Validation loss = 2.7538  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 2.8136  Validation loss = 2.7536  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 2.8134  Validation loss = 2.7533  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 2.8132  Validation loss = 2.7530  \n",
      "\n",
      "Fold: 7  Epoch: 21  Training loss = 2.8129  Validation loss = 2.7528  \n",
      "\n",
      "Fold: 7  Epoch: 22  Training loss = 2.8128  Validation loss = 2.7525  \n",
      "\n",
      "Fold: 7  Epoch: 23  Training loss = 2.8126  Validation loss = 2.7523  \n",
      "\n",
      "Fold: 7  Epoch: 24  Training loss = 2.8124  Validation loss = 2.7520  \n",
      "\n",
      "Fold: 7  Epoch: 25  Training loss = 2.8122  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 7  Epoch: 26  Training loss = 2.8120  Validation loss = 2.7516  \n",
      "\n",
      "Fold: 7  Epoch: 27  Training loss = 2.8117  Validation loss = 2.7513  \n",
      "\n",
      "Fold: 7  Epoch: 28  Training loss = 2.8115  Validation loss = 2.7510  \n",
      "\n",
      "Fold: 7  Epoch: 29  Training loss = 2.8113  Validation loss = 2.7508  \n",
      "\n",
      "Fold: 7  Epoch: 30  Training loss = 2.8112  Validation loss = 2.7506  \n",
      "\n",
      "Fold: 7  Epoch: 31  Training loss = 2.8110  Validation loss = 2.7504  \n",
      "\n",
      "Fold: 7  Epoch: 32  Training loss = 2.8109  Validation loss = 2.7503  \n",
      "\n",
      "Fold: 7  Epoch: 33  Training loss = 2.8107  Validation loss = 2.7500  \n",
      "\n",
      "Fold: 7  Epoch: 34  Training loss = 2.8105  Validation loss = 2.7498  \n",
      "\n",
      "Fold: 7  Epoch: 35  Training loss = 2.8103  Validation loss = 2.7495  \n",
      "\n",
      "Fold: 7  Epoch: 36  Training loss = 2.8101  Validation loss = 2.7492  \n",
      "\n",
      "Fold: 7  Epoch: 37  Training loss = 2.8099  Validation loss = 2.7490  \n",
      "\n",
      "Fold: 7  Epoch: 38  Training loss = 2.8097  Validation loss = 2.7488  \n",
      "\n",
      "Fold: 7  Epoch: 39  Training loss = 2.8095  Validation loss = 2.7485  \n",
      "\n",
      "Fold: 7  Epoch: 40  Training loss = 2.8093  Validation loss = 2.7483  \n",
      "\n",
      "Fold: 7  Epoch: 41  Training loss = 2.8091  Validation loss = 2.7481  \n",
      "\n",
      "Fold: 7  Epoch: 42  Training loss = 2.8089  Validation loss = 2.7478  \n",
      "\n",
      "Fold: 7  Epoch: 43  Training loss = 2.8087  Validation loss = 2.7476  \n",
      "\n",
      "Fold: 7  Epoch: 44  Training loss = 2.8085  Validation loss = 2.7474  \n",
      "\n",
      "Fold: 7  Epoch: 45  Training loss = 2.8083  Validation loss = 2.7471  \n",
      "\n",
      "Fold: 7  Epoch: 46  Training loss = 2.8081  Validation loss = 2.7469  \n",
      "\n",
      "Fold: 7  Epoch: 47  Training loss = 2.8080  Validation loss = 2.7467  \n",
      "\n",
      "Fold: 7  Epoch: 48  Training loss = 2.8078  Validation loss = 2.7465  \n",
      "\n",
      "Fold: 7  Epoch: 49  Training loss = 2.8076  Validation loss = 2.7462  \n",
      "\n",
      "Fold: 7  Epoch: 50  Training loss = 2.8074  Validation loss = 2.7460  \n",
      "\n",
      "Fold: 7  Epoch: 51  Training loss = 2.8072  Validation loss = 2.7458  \n",
      "\n",
      "Fold: 7  Epoch: 52  Training loss = 2.8071  Validation loss = 2.7456  \n",
      "\n",
      "Fold: 7  Epoch: 53  Training loss = 2.8068  Validation loss = 2.7453  \n",
      "\n",
      "Fold: 7  Epoch: 54  Training loss = 2.8066  Validation loss = 2.7451  \n",
      "\n",
      "Fold: 7  Epoch: 55  Training loss = 2.8064  Validation loss = 2.7448  \n",
      "\n",
      "Fold: 7  Epoch: 56  Training loss = 2.8062  Validation loss = 2.7446  \n",
      "\n",
      "Fold: 7  Epoch: 57  Training loss = 2.8061  Validation loss = 2.7444  \n",
      "\n",
      "Fold: 7  Epoch: 58  Training loss = 2.8059  Validation loss = 2.7441  \n",
      "\n",
      "Fold: 7  Epoch: 59  Training loss = 2.8057  Validation loss = 2.7439  \n",
      "\n",
      "Fold: 7  Epoch: 60  Training loss = 2.8055  Validation loss = 2.7437  \n",
      "\n",
      "Fold: 7  Epoch: 61  Training loss = 2.8053  Validation loss = 2.7434  \n",
      "\n",
      "Fold: 7  Epoch: 62  Training loss = 2.8051  Validation loss = 2.7432  \n",
      "\n",
      "Fold: 7  Epoch: 63  Training loss = 2.8050  Validation loss = 2.7430  \n",
      "\n",
      "Fold: 7  Epoch: 64  Training loss = 2.8048  Validation loss = 2.7428  \n",
      "\n",
      "Fold: 7  Epoch: 65  Training loss = 2.8045  Validation loss = 2.7425  \n",
      "\n",
      "Fold: 7  Epoch: 66  Training loss = 2.8043  Validation loss = 2.7422  \n",
      "\n",
      "Fold: 7  Epoch: 67  Training loss = 2.8042  Validation loss = 2.7420  \n",
      "\n",
      "Fold: 7  Epoch: 68  Training loss = 2.8040  Validation loss = 2.7418  \n",
      "\n",
      "Fold: 7  Epoch: 69  Training loss = 2.8038  Validation loss = 2.7416  \n",
      "\n",
      "Fold: 7  Epoch: 70  Training loss = 2.8036  Validation loss = 2.7413  \n",
      "\n",
      "Fold: 7  Epoch: 71  Training loss = 2.8034  Validation loss = 2.7411  \n",
      "\n",
      "Fold: 7  Epoch: 72  Training loss = 2.8033  Validation loss = 2.7409  \n",
      "\n",
      "Fold: 7  Epoch: 73  Training loss = 2.8031  Validation loss = 2.7408  \n",
      "\n",
      "Fold: 7  Epoch: 74  Training loss = 2.8030  Validation loss = 2.7405  \n",
      "\n",
      "Fold: 7  Epoch: 75  Training loss = 2.8028  Validation loss = 2.7403  \n",
      "\n",
      "Fold: 7  Epoch: 76  Training loss = 2.8026  Validation loss = 2.7401  \n",
      "\n",
      "Fold: 7  Epoch: 77  Training loss = 2.8024  Validation loss = 2.7398  \n",
      "\n",
      "Fold: 7  Epoch: 78  Training loss = 2.8022  Validation loss = 2.7396  \n",
      "\n",
      "Fold: 7  Epoch: 79  Training loss = 2.8021  Validation loss = 2.7394  \n",
      "\n",
      "Fold: 7  Epoch: 80  Training loss = 2.8019  Validation loss = 2.7392  \n",
      "\n",
      "Fold: 7  Epoch: 81  Training loss = 2.8017  Validation loss = 2.7390  \n",
      "\n",
      "Fold: 7  Epoch: 82  Training loss = 2.8015  Validation loss = 2.7388  \n",
      "\n",
      "Fold: 7  Epoch: 83  Training loss = 2.8013  Validation loss = 2.7385  \n",
      "\n",
      "Fold: 7  Epoch: 84  Training loss = 2.8011  Validation loss = 2.7383  \n",
      "\n",
      "Fold: 7  Epoch: 85  Training loss = 2.8009  Validation loss = 2.7380  \n",
      "\n",
      "Fold: 7  Epoch: 86  Training loss = 2.8007  Validation loss = 2.7378  \n",
      "\n",
      "Fold: 7  Epoch: 87  Training loss = 2.8006  Validation loss = 2.7376  \n",
      "\n",
      "Fold: 7  Epoch: 88  Training loss = 2.8003  Validation loss = 2.7373  \n",
      "\n",
      "Fold: 7  Epoch: 89  Training loss = 2.8001  Validation loss = 2.7371  \n",
      "\n",
      "Fold: 7  Epoch: 90  Training loss = 2.8000  Validation loss = 2.7369  \n",
      "\n",
      "Fold: 7  Epoch: 91  Training loss = 2.7998  Validation loss = 2.7367  \n",
      "\n",
      "Fold: 7  Epoch: 92  Training loss = 2.7996  Validation loss = 2.7364  \n",
      "\n",
      "Fold: 7  Epoch: 93  Training loss = 2.7994  Validation loss = 2.7362  \n",
      "\n",
      "Fold: 7  Epoch: 94  Training loss = 2.7992  Validation loss = 2.7360  \n",
      "\n",
      "Fold: 7  Epoch: 95  Training loss = 2.7990  Validation loss = 2.7357  \n",
      "\n",
      "Fold: 7  Epoch: 96  Training loss = 2.7989  Validation loss = 2.7355  \n",
      "\n",
      "Fold: 7  Epoch: 97  Training loss = 2.7987  Validation loss = 2.7353  \n",
      "\n",
      "Fold: 7  Epoch: 98  Training loss = 2.7985  Validation loss = 2.7350  \n",
      "\n",
      "Fold: 7  Epoch: 99  Training loss = 2.7982  Validation loss = 2.7348  \n",
      "\n",
      "Fold: 7  Epoch: 100  Training loss = 2.7981  Validation loss = 2.7345  \n",
      "\n",
      "Fold: 7  Epoch: 101  Training loss = 2.7979  Validation loss = 2.7343  \n",
      "\n",
      "Fold: 7  Epoch: 102  Training loss = 2.7977  Validation loss = 2.7341  \n",
      "\n",
      "Fold: 7  Epoch: 103  Training loss = 2.7975  Validation loss = 2.7339  \n",
      "\n",
      "Fold: 7  Epoch: 104  Training loss = 2.7974  Validation loss = 2.7337  \n",
      "\n",
      "Fold: 7  Epoch: 105  Training loss = 2.7972  Validation loss = 2.7334  \n",
      "\n",
      "Fold: 7  Epoch: 106  Training loss = 2.7970  Validation loss = 2.7332  \n",
      "\n",
      "Fold: 7  Epoch: 107  Training loss = 2.7968  Validation loss = 2.7329  \n",
      "\n",
      "Fold: 7  Epoch: 108  Training loss = 2.7966  Validation loss = 2.7327  \n",
      "\n",
      "Fold: 7  Epoch: 109  Training loss = 2.7964  Validation loss = 2.7325  \n",
      "\n",
      "Fold: 7  Epoch: 110  Training loss = 2.7962  Validation loss = 2.7322  \n",
      "\n",
      "Fold: 7  Epoch: 111  Training loss = 2.7960  Validation loss = 2.7320  \n",
      "\n",
      "Fold: 7  Epoch: 112  Training loss = 2.7958  Validation loss = 2.7318  \n",
      "\n",
      "Fold: 7  Epoch: 113  Training loss = 2.7956  Validation loss = 2.7315  \n",
      "\n",
      "Fold: 7  Epoch: 114  Training loss = 2.7954  Validation loss = 2.7313  \n",
      "\n",
      "Fold: 7  Epoch: 115  Training loss = 2.7952  Validation loss = 2.7311  \n",
      "\n",
      "Fold: 7  Epoch: 116  Training loss = 2.7950  Validation loss = 2.7309  \n",
      "\n",
      "Fold: 7  Epoch: 117  Training loss = 2.7948  Validation loss = 2.7306  \n",
      "\n",
      "Fold: 7  Epoch: 118  Training loss = 2.7946  Validation loss = 2.7303  \n",
      "\n",
      "Fold: 7  Epoch: 119  Training loss = 2.7944  Validation loss = 2.7301  \n",
      "\n",
      "Fold: 7  Epoch: 120  Training loss = 2.7942  Validation loss = 2.7298  \n",
      "\n",
      "Fold: 7  Epoch: 121  Training loss = 2.7940  Validation loss = 2.7296  \n",
      "\n",
      "Fold: 7  Epoch: 122  Training loss = 2.7938  Validation loss = 2.7294  \n",
      "\n",
      "Fold: 7  Epoch: 123  Training loss = 2.7936  Validation loss = 2.7291  \n",
      "\n",
      "Fold: 7  Epoch: 124  Training loss = 2.7935  Validation loss = 2.7289  \n",
      "\n",
      "Fold: 7  Epoch: 125  Training loss = 2.7933  Validation loss = 2.7287  \n",
      "\n",
      "Fold: 7  Epoch: 126  Training loss = 2.7931  Validation loss = 2.7286  \n",
      "\n",
      "Fold: 7  Epoch: 127  Training loss = 2.7929  Validation loss = 2.7283  \n",
      "\n",
      "Fold: 7  Epoch: 128  Training loss = 2.7927  Validation loss = 2.7280  \n",
      "\n",
      "Fold: 7  Epoch: 129  Training loss = 2.7926  Validation loss = 2.7279  \n",
      "\n",
      "Fold: 7  Epoch: 130  Training loss = 2.7923  Validation loss = 2.7276  \n",
      "\n",
      "Fold: 7  Epoch: 131  Training loss = 2.7922  Validation loss = 2.7274  \n",
      "\n",
      "Fold: 7  Epoch: 132  Training loss = 2.7919  Validation loss = 2.7271  \n",
      "\n",
      "Fold: 7  Epoch: 133  Training loss = 2.7917  Validation loss = 2.7268  \n",
      "\n",
      "Fold: 7  Epoch: 134  Training loss = 2.7915  Validation loss = 2.7266  \n",
      "\n",
      "Fold: 7  Epoch: 135  Training loss = 2.7913  Validation loss = 2.7263  \n",
      "\n",
      "Fold: 7  Epoch: 136  Training loss = 2.7911  Validation loss = 2.7261  \n",
      "\n",
      "Fold: 7  Epoch: 137  Training loss = 2.7909  Validation loss = 2.7259  \n",
      "\n",
      "Fold: 7  Epoch: 138  Training loss = 2.7907  Validation loss = 2.7256  \n",
      "\n",
      "Fold: 7  Epoch: 139  Training loss = 2.7905  Validation loss = 2.7254  \n",
      "\n",
      "Fold: 7  Epoch: 140  Training loss = 2.7903  Validation loss = 2.7251  \n",
      "\n",
      "Fold: 7  Epoch: 141  Training loss = 2.7901  Validation loss = 2.7249  \n",
      "\n",
      "Fold: 7  Epoch: 142  Training loss = 2.7899  Validation loss = 2.7247  \n",
      "\n",
      "Fold: 7  Epoch: 143  Training loss = 2.7897  Validation loss = 2.7244  \n",
      "\n",
      "Fold: 7  Epoch: 144  Training loss = 2.7895  Validation loss = 2.7242  \n",
      "\n",
      "Fold: 7  Epoch: 145  Training loss = 2.7893  Validation loss = 2.7239  \n",
      "\n",
      "Fold: 7  Epoch: 146  Training loss = 2.7892  Validation loss = 2.7237  \n",
      "\n",
      "Fold: 7  Epoch: 147  Training loss = 2.7890  Validation loss = 2.7235  \n",
      "\n",
      "Fold: 7  Epoch: 148  Training loss = 2.7888  Validation loss = 2.7233  \n",
      "\n",
      "Fold: 7  Epoch: 149  Training loss = 2.7886  Validation loss = 2.7231  \n",
      "\n",
      "Fold: 7  Epoch: 150  Training loss = 2.7884  Validation loss = 2.7228  \n",
      "\n",
      "Fold: 7  Epoch: 151  Training loss = 2.7882  Validation loss = 2.7226  \n",
      "\n",
      "Fold: 7  Epoch: 152  Training loss = 2.7880  Validation loss = 2.7223  \n",
      "\n",
      "Fold: 7  Epoch: 153  Training loss = 2.7878  Validation loss = 2.7221  \n",
      "\n",
      "Fold: 7  Epoch: 154  Training loss = 2.7876  Validation loss = 2.7219  \n",
      "\n",
      "Fold: 7  Epoch: 155  Training loss = 2.7875  Validation loss = 2.7217  \n",
      "\n",
      "Fold: 7  Epoch: 156  Training loss = 2.7873  Validation loss = 2.7215  \n",
      "\n",
      "Fold: 7  Epoch: 157  Training loss = 2.7871  Validation loss = 2.7212  \n",
      "\n",
      "Fold: 7  Epoch: 158  Training loss = 2.7869  Validation loss = 2.7210  \n",
      "\n",
      "Fold: 7  Epoch: 159  Training loss = 2.7867  Validation loss = 2.7208  \n",
      "\n",
      "Fold: 7  Epoch: 160  Training loss = 2.7866  Validation loss = 2.7206  \n",
      "\n",
      "Fold: 7  Epoch: 161  Training loss = 2.7864  Validation loss = 2.7204  \n",
      "\n",
      "Fold: 7  Epoch: 162  Training loss = 2.7862  Validation loss = 2.7202  \n",
      "\n",
      "Fold: 7  Epoch: 163  Training loss = 2.7860  Validation loss = 2.7199  \n",
      "\n",
      "Fold: 7  Epoch: 164  Training loss = 2.7858  Validation loss = 2.7197  \n",
      "\n",
      "Fold: 7  Epoch: 165  Training loss = 2.7856  Validation loss = 2.7195  \n",
      "\n",
      "Fold: 7  Epoch: 166  Training loss = 2.7855  Validation loss = 2.7192  \n",
      "\n",
      "Fold: 7  Epoch: 167  Training loss = 2.7853  Validation loss = 2.7190  \n",
      "\n",
      "Fold: 7  Epoch: 168  Training loss = 2.7851  Validation loss = 2.7188  \n",
      "\n",
      "Fold: 7  Epoch: 169  Training loss = 2.7849  Validation loss = 2.7185  \n",
      "\n",
      "Fold: 7  Epoch: 170  Training loss = 2.7847  Validation loss = 2.7183  \n",
      "\n",
      "Fold: 7  Epoch: 171  Training loss = 2.7845  Validation loss = 2.7181  \n",
      "\n",
      "Fold: 7  Epoch: 172  Training loss = 2.7843  Validation loss = 2.7178  \n",
      "\n",
      "Fold: 7  Epoch: 173  Training loss = 2.7841  Validation loss = 2.7176  \n",
      "\n",
      "Fold: 7  Epoch: 174  Training loss = 2.7839  Validation loss = 2.7173  \n",
      "\n",
      "Fold: 7  Epoch: 175  Training loss = 2.7837  Validation loss = 2.7171  \n",
      "\n",
      "Fold: 7  Epoch: 176  Training loss = 2.7835  Validation loss = 2.7169  \n",
      "\n",
      "Fold: 7  Epoch: 177  Training loss = 2.7834  Validation loss = 2.7167  \n",
      "\n",
      "Fold: 7  Epoch: 178  Training loss = 2.7832  Validation loss = 2.7164  \n",
      "\n",
      "Fold: 7  Epoch: 179  Training loss = 2.7829  Validation loss = 2.7162  \n",
      "\n",
      "Fold: 7  Epoch: 180  Training loss = 2.7828  Validation loss = 2.7160  \n",
      "\n",
      "Fold: 7  Epoch: 181  Training loss = 2.7826  Validation loss = 2.7157  \n",
      "\n",
      "Fold: 7  Epoch: 182  Training loss = 2.7824  Validation loss = 2.7155  \n",
      "\n",
      "Fold: 7  Epoch: 183  Training loss = 2.7822  Validation loss = 2.7152  \n",
      "\n",
      "Fold: 7  Epoch: 184  Training loss = 2.7820  Validation loss = 2.7150  \n",
      "\n",
      "Fold: 7  Epoch: 185  Training loss = 2.7818  Validation loss = 2.7148  \n",
      "\n",
      "Fold: 7  Epoch: 186  Training loss = 2.7817  Validation loss = 2.7146  \n",
      "\n",
      "Fold: 7  Epoch: 187  Training loss = 2.7815  Validation loss = 2.7144  \n",
      "\n",
      "Fold: 7  Epoch: 188  Training loss = 2.7813  Validation loss = 2.7141  \n",
      "\n",
      "Fold: 7  Epoch: 189  Training loss = 2.7811  Validation loss = 2.7139  \n",
      "\n",
      "Fold: 7  Epoch: 190  Training loss = 2.7809  Validation loss = 2.7137  \n",
      "\n",
      "Fold: 7  Epoch: 191  Training loss = 2.7807  Validation loss = 2.7135  \n",
      "\n",
      "Fold: 7  Epoch: 192  Training loss = 2.7806  Validation loss = 2.7133  \n",
      "\n",
      "Fold: 7  Epoch: 193  Training loss = 2.7804  Validation loss = 2.7131  \n",
      "\n",
      "Fold: 7  Epoch: 194  Training loss = 2.7802  Validation loss = 2.7128  \n",
      "\n",
      "Fold: 7  Epoch: 195  Training loss = 2.7800  Validation loss = 2.7126  \n",
      "\n",
      "Fold: 7  Epoch: 196  Training loss = 2.7798  Validation loss = 2.7124  \n",
      "\n",
      "Fold: 7  Epoch: 197  Training loss = 2.7797  Validation loss = 2.7122  \n",
      "\n",
      "Fold: 7  Epoch: 198  Training loss = 2.7795  Validation loss = 2.7120  \n",
      "\n",
      "Fold: 7  Epoch: 199  Training loss = 2.7793  Validation loss = 2.7117  \n",
      "\n",
      "Fold: 7  Epoch: 200  Training loss = 2.7791  Validation loss = 2.7115  \n",
      "\n",
      "Fold: 7  Epoch: 201  Training loss = 2.7789  Validation loss = 2.7112  \n",
      "\n",
      "Fold: 7  Epoch: 202  Training loss = 2.7787  Validation loss = 2.7110  \n",
      "\n",
      "Fold: 7  Epoch: 203  Training loss = 2.7786  Validation loss = 2.7108  \n",
      "\n",
      "Fold: 7  Epoch: 204  Training loss = 2.7784  Validation loss = 2.7106  \n",
      "\n",
      "Fold: 7  Epoch: 205  Training loss = 2.7782  Validation loss = 2.7104  \n",
      "\n",
      "Fold: 7  Epoch: 206  Training loss = 2.7779  Validation loss = 2.7101  \n",
      "\n",
      "Fold: 7  Epoch: 207  Training loss = 2.7778  Validation loss = 2.7099  \n",
      "\n",
      "Fold: 7  Epoch: 208  Training loss = 2.7775  Validation loss = 2.7096  \n",
      "\n",
      "Fold: 7  Epoch: 209  Training loss = 2.7773  Validation loss = 2.7093  \n",
      "\n",
      "Fold: 7  Epoch: 210  Training loss = 2.7771  Validation loss = 2.7091  \n",
      "\n",
      "Fold: 7  Epoch: 211  Training loss = 2.7769  Validation loss = 2.7089  \n",
      "\n",
      "Fold: 7  Epoch: 212  Training loss = 2.7768  Validation loss = 2.7087  \n",
      "\n",
      "Fold: 7  Epoch: 213  Training loss = 2.7766  Validation loss = 2.7085  \n",
      "\n",
      "Fold: 7  Epoch: 214  Training loss = 2.7764  Validation loss = 2.7083  \n",
      "\n",
      "Fold: 7  Epoch: 215  Training loss = 2.7763  Validation loss = 2.7080  \n",
      "\n",
      "Fold: 7  Epoch: 216  Training loss = 2.7761  Validation loss = 2.7078  \n",
      "\n",
      "Fold: 7  Epoch: 217  Training loss = 2.7758  Validation loss = 2.7075  \n",
      "\n",
      "Fold: 7  Epoch: 218  Training loss = 2.7757  Validation loss = 2.7074  \n",
      "\n",
      "Fold: 7  Epoch: 219  Training loss = 2.7755  Validation loss = 2.7071  \n",
      "\n",
      "Fold: 7  Epoch: 220  Training loss = 2.7753  Validation loss = 2.7069  \n",
      "\n",
      "Fold: 7  Epoch: 221  Training loss = 2.7751  Validation loss = 2.7067  \n",
      "\n",
      "Fold: 7  Epoch: 222  Training loss = 2.7750  Validation loss = 2.7065  \n",
      "\n",
      "Fold: 7  Epoch: 223  Training loss = 2.7748  Validation loss = 2.7063  \n",
      "\n",
      "Fold: 7  Epoch: 224  Training loss = 2.7746  Validation loss = 2.7060  \n",
      "\n",
      "Fold: 7  Epoch: 225  Training loss = 2.7745  Validation loss = 2.7058  \n",
      "\n",
      "Fold: 7  Epoch: 226  Training loss = 2.7743  Validation loss = 2.7056  \n",
      "\n",
      "Fold: 7  Epoch: 227  Training loss = 2.7741  Validation loss = 2.7054  \n",
      "\n",
      "Fold: 7  Epoch: 228  Training loss = 2.7739  Validation loss = 2.7052  \n",
      "\n",
      "Fold: 7  Epoch: 229  Training loss = 2.7737  Validation loss = 2.7049  \n",
      "\n",
      "Fold: 7  Epoch: 230  Training loss = 2.7735  Validation loss = 2.7047  \n",
      "\n",
      "Fold: 7  Epoch: 231  Training loss = 2.7734  Validation loss = 2.7045  \n",
      "\n",
      "Fold: 7  Epoch: 232  Training loss = 2.7732  Validation loss = 2.7043  \n",
      "\n",
      "Fold: 7  Epoch: 233  Training loss = 2.7730  Validation loss = 2.7040  \n",
      "\n",
      "Fold: 7  Epoch: 234  Training loss = 2.7728  Validation loss = 2.7038  \n",
      "\n",
      "Fold: 7  Epoch: 235  Training loss = 2.7726  Validation loss = 2.7036  \n",
      "\n",
      "Fold: 7  Epoch: 236  Training loss = 2.7724  Validation loss = 2.7033  \n",
      "\n",
      "Fold: 7  Epoch: 237  Training loss = 2.7722  Validation loss = 2.7031  \n",
      "\n",
      "Fold: 7  Epoch: 238  Training loss = 2.7721  Validation loss = 2.7029  \n",
      "\n",
      "Fold: 7  Epoch: 239  Training loss = 2.7719  Validation loss = 2.7027  \n",
      "\n",
      "Fold: 7  Epoch: 240  Training loss = 2.7717  Validation loss = 2.7025  \n",
      "\n",
      "Fold: 7  Epoch: 241  Training loss = 2.7715  Validation loss = 2.7023  \n",
      "\n",
      "Fold: 7  Epoch: 242  Training loss = 2.7714  Validation loss = 2.7021  \n",
      "\n",
      "Fold: 7  Epoch: 243  Training loss = 2.7712  Validation loss = 2.7019  \n",
      "\n",
      "Fold: 7  Epoch: 244  Training loss = 2.7710  Validation loss = 2.7017  \n",
      "\n",
      "Fold: 7  Epoch: 245  Training loss = 2.7708  Validation loss = 2.7014  \n",
      "\n",
      "Fold: 7  Epoch: 246  Training loss = 2.7706  Validation loss = 2.7012  \n",
      "\n",
      "Fold: 7  Epoch: 247  Training loss = 2.7705  Validation loss = 2.7010  \n",
      "\n",
      "Fold: 7  Epoch: 248  Training loss = 2.7703  Validation loss = 2.7007  \n",
      "\n",
      "Fold: 7  Epoch: 249  Training loss = 2.7701  Validation loss = 2.7005  \n",
      "\n",
      "Fold: 7  Epoch: 250  Training loss = 2.7699  Validation loss = 2.7003  \n",
      "\n",
      "Fold: 7  Epoch: 251  Training loss = 2.7697  Validation loss = 2.7001  \n",
      "\n",
      "Fold: 7  Epoch: 252  Training loss = 2.7696  Validation loss = 2.6999  \n",
      "\n",
      "Fold: 7  Epoch: 253  Training loss = 2.7694  Validation loss = 2.6997  \n",
      "\n",
      "Fold: 7  Epoch: 254  Training loss = 2.7692  Validation loss = 2.6994  \n",
      "\n",
      "Fold: 7  Epoch: 255  Training loss = 2.7690  Validation loss = 2.6992  \n",
      "\n",
      "Fold: 7  Epoch: 256  Training loss = 2.7688  Validation loss = 2.6989  \n",
      "\n",
      "Fold: 7  Epoch: 257  Training loss = 2.7686  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 7  Epoch: 258  Training loss = 2.7684  Validation loss = 2.6985  \n",
      "\n",
      "Fold: 7  Epoch: 259  Training loss = 2.7682  Validation loss = 2.6982  \n",
      "\n",
      "Fold: 7  Epoch: 260  Training loss = 2.7680  Validation loss = 2.6980  \n",
      "\n",
      "Fold: 7  Epoch: 261  Training loss = 2.7678  Validation loss = 2.6978  \n",
      "\n",
      "Fold: 7  Epoch: 262  Training loss = 2.7677  Validation loss = 2.6975  \n",
      "\n",
      "Fold: 7  Epoch: 263  Training loss = 2.7675  Validation loss = 2.6973  \n",
      "\n",
      "Fold: 7  Epoch: 264  Training loss = 2.7673  Validation loss = 2.6971  \n",
      "\n",
      "Fold: 7  Epoch: 265  Training loss = 2.7670  Validation loss = 2.6968  \n",
      "\n",
      "Fold: 7  Epoch: 266  Training loss = 2.7668  Validation loss = 2.6965  \n",
      "\n",
      "Fold: 7  Epoch: 267  Training loss = 2.7666  Validation loss = 2.6963  \n",
      "\n",
      "Fold: 7  Epoch: 268  Training loss = 2.7665  Validation loss = 2.6961  \n",
      "\n",
      "Fold: 7  Epoch: 269  Training loss = 2.7663  Validation loss = 2.6959  \n",
      "\n",
      "Fold: 7  Epoch: 270  Training loss = 2.7661  Validation loss = 2.6957  \n",
      "\n",
      "Fold: 7  Epoch: 271  Training loss = 2.7659  Validation loss = 2.6954  \n",
      "\n",
      "Fold: 7  Epoch: 272  Training loss = 2.7657  Validation loss = 2.6952  \n",
      "\n",
      "Fold: 7  Epoch: 273  Training loss = 2.7656  Validation loss = 2.6950  \n",
      "\n",
      "Fold: 7  Epoch: 274  Training loss = 2.7654  Validation loss = 2.6948  \n",
      "\n",
      "Fold: 7  Epoch: 275  Training loss = 2.7652  Validation loss = 2.6946  \n",
      "\n",
      "Fold: 7  Epoch: 276  Training loss = 2.7650  Validation loss = 2.6943  \n",
      "\n",
      "Fold: 7  Epoch: 277  Training loss = 2.7648  Validation loss = 2.6941  \n",
      "\n",
      "Fold: 7  Epoch: 278  Training loss = 2.7647  Validation loss = 2.6939  \n",
      "\n",
      "Fold: 7  Epoch: 279  Training loss = 2.7645  Validation loss = 2.6937  \n",
      "\n",
      "Fold: 7  Epoch: 280  Training loss = 2.7643  Validation loss = 2.6935  \n",
      "\n",
      "Fold: 7  Epoch: 281  Training loss = 2.7642  Validation loss = 2.6933  \n",
      "\n",
      "Fold: 7  Epoch: 282  Training loss = 2.7640  Validation loss = 2.6931  \n",
      "\n",
      "Fold: 7  Epoch: 283  Training loss = 2.7638  Validation loss = 2.6929  \n",
      "\n",
      "Fold: 7  Epoch: 284  Training loss = 2.7636  Validation loss = 2.6926  \n",
      "\n",
      "Fold: 7  Epoch: 285  Training loss = 2.7634  Validation loss = 2.6924  \n",
      "\n",
      "Fold: 7  Epoch: 286  Training loss = 2.7632  Validation loss = 2.6921  \n",
      "\n",
      "Fold: 7  Epoch: 287  Training loss = 2.7630  Validation loss = 2.6919  \n",
      "\n",
      "Fold: 7  Epoch: 288  Training loss = 2.7629  Validation loss = 2.6917  \n",
      "\n",
      "Fold: 7  Epoch: 289  Training loss = 2.7627  Validation loss = 2.6915  \n",
      "\n",
      "Fold: 7  Epoch: 290  Training loss = 2.7625  Validation loss = 2.6913  \n",
      "\n",
      "Fold: 7  Epoch: 291  Training loss = 2.7623  Validation loss = 2.6911  \n",
      "\n",
      "Fold: 7  Epoch: 292  Training loss = 2.7621  Validation loss = 2.6908  \n",
      "\n",
      "Fold: 7  Epoch: 293  Training loss = 2.7619  Validation loss = 2.6906  \n",
      "\n",
      "Fold: 7  Epoch: 294  Training loss = 2.7617  Validation loss = 2.6904  \n",
      "\n",
      "Fold: 7  Epoch: 295  Training loss = 2.7616  Validation loss = 2.6902  \n",
      "\n",
      "Fold: 7  Epoch: 296  Training loss = 2.7614  Validation loss = 2.6899  \n",
      "\n",
      "Fold: 7  Epoch: 297  Training loss = 2.7612  Validation loss = 2.6897  \n",
      "\n",
      "Fold: 7  Epoch: 298  Training loss = 2.7610  Validation loss = 2.6895  \n",
      "\n",
      "Fold: 7  Epoch: 299  Training loss = 2.7608  Validation loss = 2.6893  \n",
      "\n",
      "Fold: 7  Epoch: 300  Training loss = 2.7606  Validation loss = 2.6890  \n",
      "\n",
      "Fold: 7  Epoch: 301  Training loss = 2.7604  Validation loss = 2.6888  \n",
      "\n",
      "Fold: 7  Epoch: 302  Training loss = 2.7602  Validation loss = 2.6886  \n",
      "\n",
      "Fold: 7  Epoch: 303  Training loss = 2.7601  Validation loss = 2.6884  \n",
      "\n",
      "Fold: 7  Epoch: 304  Training loss = 2.7599  Validation loss = 2.6881  \n",
      "\n",
      "Fold: 7  Epoch: 305  Training loss = 2.7597  Validation loss = 2.6879  \n",
      "\n",
      "Fold: 7  Epoch: 306  Training loss = 2.7596  Validation loss = 2.6877  \n",
      "\n",
      "Fold: 7  Epoch: 307  Training loss = 2.7594  Validation loss = 2.6875  \n",
      "\n",
      "Fold: 7  Epoch: 308  Training loss = 2.7592  Validation loss = 2.6873  \n",
      "\n",
      "Fold: 7  Epoch: 309  Training loss = 2.7590  Validation loss = 2.6870  \n",
      "\n",
      "Fold: 7  Epoch: 310  Training loss = 2.7588  Validation loss = 2.6868  \n",
      "\n",
      "Fold: 7  Epoch: 311  Training loss = 2.7586  Validation loss = 2.6866  \n",
      "\n",
      "Fold: 7  Epoch: 312  Training loss = 2.7585  Validation loss = 2.6864  \n",
      "\n",
      "Fold: 7  Epoch: 313  Training loss = 2.7583  Validation loss = 2.6862  \n",
      "\n",
      "Fold: 7  Epoch: 314  Training loss = 2.7580  Validation loss = 2.6859  \n",
      "\n",
      "Fold: 7  Epoch: 315  Training loss = 2.7578  Validation loss = 2.6857  \n",
      "\n",
      "Fold: 7  Epoch: 316  Training loss = 2.7577  Validation loss = 2.6855  \n",
      "\n",
      "Fold: 7  Epoch: 317  Training loss = 2.7575  Validation loss = 2.6853  \n",
      "\n",
      "Fold: 7  Epoch: 318  Training loss = 2.7573  Validation loss = 2.6850  \n",
      "\n",
      "Fold: 7  Epoch: 319  Training loss = 2.7571  Validation loss = 2.6848  \n",
      "\n",
      "Fold: 7  Epoch: 320  Training loss = 2.7569  Validation loss = 2.6846  \n",
      "\n",
      "Fold: 7  Epoch: 321  Training loss = 2.7568  Validation loss = 2.6844  \n",
      "\n",
      "Fold: 7  Epoch: 322  Training loss = 2.7566  Validation loss = 2.6842  \n",
      "\n",
      "Fold: 7  Epoch: 323  Training loss = 2.7564  Validation loss = 2.6840  \n",
      "\n",
      "Fold: 7  Epoch: 324  Training loss = 2.7562  Validation loss = 2.6837  \n",
      "\n",
      "Fold: 7  Epoch: 325  Training loss = 2.7560  Validation loss = 2.6835  \n",
      "\n",
      "Fold: 7  Epoch: 326  Training loss = 2.7558  Validation loss = 2.6833  \n",
      "\n",
      "Fold: 7  Epoch: 327  Training loss = 2.7557  Validation loss = 2.6830  \n",
      "\n",
      "Fold: 7  Epoch: 328  Training loss = 2.7554  Validation loss = 2.6828  \n",
      "\n",
      "Fold: 7  Epoch: 329  Training loss = 2.7552  Validation loss = 2.6825  \n",
      "\n",
      "Fold: 7  Epoch: 330  Training loss = 2.7550  Validation loss = 2.6823  \n",
      "\n",
      "Fold: 7  Epoch: 331  Training loss = 2.7549  Validation loss = 2.6821  \n",
      "\n",
      "Fold: 7  Epoch: 332  Training loss = 2.7547  Validation loss = 2.6819  \n",
      "\n",
      "Fold: 7  Epoch: 333  Training loss = 2.7545  Validation loss = 2.6816  \n",
      "\n",
      "Fold: 7  Epoch: 334  Training loss = 2.7543  Validation loss = 2.6814  \n",
      "\n",
      "Fold: 7  Epoch: 335  Training loss = 2.7541  Validation loss = 2.6812  \n",
      "\n",
      "Fold: 7  Epoch: 336  Training loss = 2.7539  Validation loss = 2.6809  \n",
      "\n",
      "Fold: 7  Epoch: 337  Training loss = 2.7537  Validation loss = 2.6807  \n",
      "\n",
      "Fold: 7  Epoch: 338  Training loss = 2.7535  Validation loss = 2.6804  \n",
      "\n",
      "Fold: 7  Epoch: 339  Training loss = 2.7533  Validation loss = 2.6802  \n",
      "\n",
      "Fold: 7  Epoch: 340  Training loss = 2.7531  Validation loss = 2.6799  \n",
      "\n",
      "Fold: 7  Epoch: 341  Training loss = 2.7529  Validation loss = 2.6798  \n",
      "\n",
      "Fold: 7  Epoch: 342  Training loss = 2.7528  Validation loss = 2.6796  \n",
      "\n",
      "Fold: 7  Epoch: 343  Training loss = 2.7526  Validation loss = 2.6793  \n",
      "\n",
      "Fold: 7  Epoch: 344  Training loss = 2.7524  Validation loss = 2.6791  \n",
      "\n",
      "Fold: 7  Epoch: 345  Training loss = 2.7522  Validation loss = 2.6789  \n",
      "\n",
      "Fold: 7  Epoch: 346  Training loss = 2.7520  Validation loss = 2.6786  \n",
      "\n",
      "Fold: 7  Epoch: 347  Training loss = 2.7518  Validation loss = 2.6784  \n",
      "\n",
      "Fold: 7  Epoch: 348  Training loss = 2.7517  Validation loss = 2.6782  \n",
      "\n",
      "Fold: 7  Epoch: 349  Training loss = 2.7515  Validation loss = 2.6780  \n",
      "\n",
      "Fold: 7  Epoch: 350  Training loss = 2.7513  Validation loss = 2.6777  \n",
      "\n",
      "Fold: 7  Epoch: 351  Training loss = 2.7511  Validation loss = 2.6775  \n",
      "\n",
      "Fold: 7  Epoch: 352  Training loss = 2.7509  Validation loss = 2.6773  \n",
      "\n",
      "Fold: 7  Epoch: 353  Training loss = 2.7507  Validation loss = 2.6770  \n",
      "\n",
      "Fold: 7  Epoch: 354  Training loss = 2.7505  Validation loss = 2.6768  \n",
      "\n",
      "Fold: 7  Epoch: 355  Training loss = 2.7503  Validation loss = 2.6766  \n",
      "\n",
      "Fold: 7  Epoch: 356  Training loss = 2.7501  Validation loss = 2.6763  \n",
      "\n",
      "Fold: 7  Epoch: 357  Training loss = 2.7499  Validation loss = 2.6761  \n",
      "\n",
      "Fold: 7  Epoch: 358  Training loss = 2.7497  Validation loss = 2.6759  \n",
      "\n",
      "Fold: 7  Epoch: 359  Training loss = 2.7495  Validation loss = 2.6756  \n",
      "\n",
      "Fold: 7  Epoch: 360  Training loss = 2.7493  Validation loss = 2.6754  \n",
      "\n",
      "Fold: 7  Epoch: 361  Training loss = 2.7492  Validation loss = 2.6752  \n",
      "\n",
      "Fold: 7  Epoch: 362  Training loss = 2.7490  Validation loss = 2.6750  \n",
      "\n",
      "Fold: 7  Epoch: 363  Training loss = 2.7488  Validation loss = 2.6747  \n",
      "\n",
      "Fold: 7  Epoch: 364  Training loss = 2.7486  Validation loss = 2.6745  \n",
      "\n",
      "Fold: 7  Epoch: 365  Training loss = 2.7484  Validation loss = 2.6743  \n",
      "\n",
      "Fold: 7  Epoch: 366  Training loss = 2.7482  Validation loss = 2.6740  \n",
      "\n",
      "Fold: 7  Epoch: 367  Training loss = 2.7480  Validation loss = 2.6738  \n",
      "\n",
      "Fold: 7  Epoch: 368  Training loss = 2.7478  Validation loss = 2.6736  \n",
      "\n",
      "Fold: 7  Epoch: 369  Training loss = 2.7476  Validation loss = 2.6734  \n",
      "\n",
      "Fold: 7  Epoch: 370  Training loss = 2.7474  Validation loss = 2.6731  \n",
      "\n",
      "Fold: 7  Epoch: 371  Training loss = 2.7472  Validation loss = 2.6729  \n",
      "\n",
      "Fold: 7  Epoch: 372  Training loss = 2.7471  Validation loss = 2.6727  \n",
      "\n",
      "Fold: 7  Epoch: 373  Training loss = 2.7469  Validation loss = 2.6725  \n",
      "\n",
      "Fold: 7  Epoch: 374  Training loss = 2.7467  Validation loss = 2.6723  \n",
      "\n",
      "Fold: 7  Epoch: 375  Training loss = 2.7466  Validation loss = 2.6721  \n",
      "\n",
      "Fold: 7  Epoch: 376  Training loss = 2.7463  Validation loss = 2.6718  \n",
      "\n",
      "Fold: 7  Epoch: 377  Training loss = 2.7461  Validation loss = 2.6716  \n",
      "\n",
      "Fold: 7  Epoch: 378  Training loss = 2.7459  Validation loss = 2.6713  \n",
      "\n",
      "Fold: 7  Epoch: 379  Training loss = 2.7457  Validation loss = 2.6711  \n",
      "\n",
      "Fold: 7  Epoch: 380  Training loss = 2.7455  Validation loss = 2.6709  \n",
      "\n",
      "Fold: 7  Epoch: 381  Training loss = 2.7453  Validation loss = 2.6706  \n",
      "\n",
      "Fold: 7  Epoch: 382  Training loss = 2.7452  Validation loss = 2.6704  \n",
      "\n",
      "Fold: 7  Epoch: 383  Training loss = 2.7450  Validation loss = 2.6702  \n",
      "\n",
      "Fold: 7  Epoch: 384  Training loss = 2.7448  Validation loss = 2.6700  \n",
      "\n",
      "Fold: 7  Epoch: 385  Training loss = 2.7446  Validation loss = 2.6697  \n",
      "\n",
      "Fold: 7  Epoch: 386  Training loss = 2.7444  Validation loss = 2.6695  \n",
      "\n",
      "Fold: 7  Epoch: 387  Training loss = 2.7442  Validation loss = 2.6692  \n",
      "\n",
      "Fold: 7  Epoch: 388  Training loss = 2.7440  Validation loss = 2.6690  \n",
      "\n",
      "Fold: 7  Epoch: 389  Training loss = 2.7438  Validation loss = 2.6688  \n",
      "\n",
      "Fold: 7  Epoch: 390  Training loss = 2.7436  Validation loss = 2.6685  \n",
      "\n",
      "Fold: 7  Epoch: 391  Training loss = 2.7434  Validation loss = 2.6683  \n",
      "\n",
      "Fold: 7  Epoch: 392  Training loss = 2.7432  Validation loss = 2.6681  \n",
      "\n",
      "Fold: 7  Epoch: 393  Training loss = 2.7431  Validation loss = 2.6679  \n",
      "\n",
      "Fold: 7  Epoch: 394  Training loss = 2.7429  Validation loss = 2.6677  \n",
      "\n",
      "Fold: 7  Epoch: 395  Training loss = 2.7429  Validation loss = 2.6676  \n",
      "\n",
      "Fold: 7  Epoch: 396  Training loss = 2.7427  Validation loss = 2.6674  \n",
      "\n",
      "Fold: 7  Epoch: 397  Training loss = 2.7425  Validation loss = 2.6672  \n",
      "\n",
      "Fold: 7  Epoch: 398  Training loss = 2.7424  Validation loss = 2.6670  \n",
      "\n",
      "Fold: 7  Epoch: 399  Training loss = 2.7422  Validation loss = 2.6668  \n",
      "\n",
      "Fold: 7  Epoch: 400  Training loss = 2.7420  Validation loss = 2.6665  \n",
      "\n",
      "Fold: 7  Epoch: 401  Training loss = 2.7418  Validation loss = 2.6663  \n",
      "\n",
      "Fold: 7  Epoch: 402  Training loss = 2.7416  Validation loss = 2.6660  \n",
      "\n",
      "Fold: 7  Epoch: 403  Training loss = 2.7414  Validation loss = 2.6658  \n",
      "\n",
      "Fold: 7  Epoch: 404  Training loss = 2.7412  Validation loss = 2.6656  \n",
      "\n",
      "Fold: 7  Epoch: 405  Training loss = 2.7409  Validation loss = 2.6653  \n",
      "\n",
      "Fold: 7  Epoch: 406  Training loss = 2.7408  Validation loss = 2.6651  \n",
      "\n",
      "Fold: 7  Epoch: 407  Training loss = 2.7406  Validation loss = 2.6648  \n",
      "\n",
      "Fold: 7  Epoch: 408  Training loss = 2.7404  Validation loss = 2.6646  \n",
      "\n",
      "Fold: 7  Epoch: 409  Training loss = 2.7402  Validation loss = 2.6644  \n",
      "\n",
      "Fold: 7  Epoch: 410  Training loss = 2.7401  Validation loss = 2.6642  \n",
      "\n",
      "Fold: 7  Epoch: 411  Training loss = 2.7398  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 7  Epoch: 412  Training loss = 2.7397  Validation loss = 2.6638  \n",
      "\n",
      "Fold: 7  Epoch: 413  Training loss = 2.7395  Validation loss = 2.6636  \n",
      "\n",
      "Fold: 7  Epoch: 414  Training loss = 2.7394  Validation loss = 2.6634  \n",
      "\n",
      "Fold: 7  Epoch: 415  Training loss = 2.7391  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 7  Epoch: 416  Training loss = 2.7389  Validation loss = 2.6629  \n",
      "\n",
      "Fold: 7  Epoch: 417  Training loss = 2.7387  Validation loss = 2.6626  \n",
      "\n",
      "Fold: 7  Epoch: 418  Training loss = 2.7386  Validation loss = 2.6625  \n",
      "\n",
      "Fold: 7  Epoch: 419  Training loss = 2.7384  Validation loss = 2.6622  \n",
      "\n",
      "Fold: 7  Epoch: 420  Training loss = 2.7382  Validation loss = 2.6620  \n",
      "\n",
      "Fold: 7  Epoch: 421  Training loss = 2.7381  Validation loss = 2.6618  \n",
      "\n",
      "Fold: 7  Epoch: 422  Training loss = 2.7379  Validation loss = 2.6616  \n",
      "\n",
      "Fold: 7  Epoch: 423  Training loss = 2.7377  Validation loss = 2.6614  \n",
      "\n",
      "Fold: 7  Epoch: 424  Training loss = 2.7375  Validation loss = 2.6612  \n",
      "\n",
      "Fold: 7  Epoch: 425  Training loss = 2.7374  Validation loss = 2.6610  \n",
      "\n",
      "Fold: 7  Epoch: 426  Training loss = 2.7371  Validation loss = 2.6607  \n",
      "\n",
      "Fold: 7  Epoch: 427  Training loss = 2.7370  Validation loss = 2.6605  \n",
      "\n",
      "Fold: 7  Epoch: 428  Training loss = 2.7368  Validation loss = 2.6603  \n",
      "\n",
      "Fold: 7  Epoch: 429  Training loss = 2.7367  Validation loss = 2.6601  \n",
      "\n",
      "Fold: 7  Epoch: 430  Training loss = 2.7365  Validation loss = 2.6599  \n",
      "\n",
      "Fold: 7  Epoch: 431  Training loss = 2.7363  Validation loss = 2.6597  \n",
      "\n",
      "Fold: 7  Epoch: 432  Training loss = 2.7362  Validation loss = 2.6595  \n",
      "\n",
      "Fold: 7  Epoch: 433  Training loss = 2.7359  Validation loss = 2.6592  \n",
      "\n",
      "Fold: 7  Epoch: 434  Training loss = 2.7358  Validation loss = 2.6590  \n",
      "\n",
      "Fold: 7  Epoch: 435  Training loss = 2.7356  Validation loss = 2.6588  \n",
      "\n",
      "Fold: 7  Epoch: 436  Training loss = 2.7354  Validation loss = 2.6586  \n",
      "\n",
      "Fold: 7  Epoch: 437  Training loss = 2.7352  Validation loss = 2.6584  \n",
      "\n",
      "Fold: 7  Epoch: 438  Training loss = 2.7350  Validation loss = 2.6581  \n",
      "\n",
      "Fold: 7  Epoch: 439  Training loss = 2.7349  Validation loss = 2.6580  \n",
      "\n",
      "Fold: 7  Epoch: 440  Training loss = 2.7347  Validation loss = 2.6577  \n",
      "\n",
      "Fold: 7  Epoch: 441  Training loss = 2.7345  Validation loss = 2.6575  \n",
      "\n",
      "Fold: 7  Epoch: 442  Training loss = 2.7343  Validation loss = 2.6573  \n",
      "\n",
      "Fold: 7  Epoch: 443  Training loss = 2.7341  Validation loss = 2.6570  \n",
      "\n",
      "Fold: 7  Epoch: 444  Training loss = 2.7339  Validation loss = 2.6568  \n",
      "\n",
      "Fold: 7  Epoch: 445  Training loss = 2.7337  Validation loss = 2.6566  \n",
      "\n",
      "Fold: 7  Epoch: 446  Training loss = 2.7335  Validation loss = 2.6563  \n",
      "\n",
      "Fold: 7  Epoch: 447  Training loss = 2.7334  Validation loss = 2.6561  \n",
      "\n",
      "Fold: 7  Epoch: 448  Training loss = 2.7332  Validation loss = 2.6559  \n",
      "\n",
      "Fold: 7  Epoch: 449  Training loss = 2.7330  Validation loss = 2.6557  \n",
      "\n",
      "Fold: 7  Epoch: 450  Training loss = 2.7328  Validation loss = 2.6555  \n",
      "\n",
      "Fold: 7  Epoch: 451  Training loss = 2.7326  Validation loss = 2.6552  \n",
      "\n",
      "Fold: 7  Epoch: 452  Training loss = 2.7324  Validation loss = 2.6550  \n",
      "\n",
      "Fold: 7  Epoch: 453  Training loss = 2.7322  Validation loss = 2.6547  \n",
      "\n",
      "Fold: 7  Epoch: 454  Training loss = 2.7320  Validation loss = 2.6545  \n",
      "\n",
      "Fold: 7  Epoch: 455  Training loss = 2.7319  Validation loss = 2.6543  \n",
      "\n",
      "Fold: 7  Epoch: 456  Training loss = 2.7317  Validation loss = 2.6541  \n",
      "\n",
      "Fold: 7  Epoch: 457  Training loss = 2.7315  Validation loss = 2.6539  \n",
      "\n",
      "Fold: 7  Epoch: 458  Training loss = 2.7314  Validation loss = 2.6537  \n",
      "\n",
      "Fold: 7  Epoch: 459  Training loss = 2.7312  Validation loss = 2.6535  \n",
      "\n",
      "Fold: 7  Epoch: 460  Training loss = 2.7310  Validation loss = 2.6533  \n",
      "\n",
      "Fold: 7  Epoch: 461  Training loss = 2.7309  Validation loss = 2.6531  \n",
      "\n",
      "Fold: 7  Epoch: 462  Training loss = 2.7307  Validation loss = 2.6529  \n",
      "\n",
      "Fold: 7  Epoch: 463  Training loss = 2.7305  Validation loss = 2.6526  \n",
      "\n",
      "Fold: 7  Epoch: 464  Training loss = 2.7303  Validation loss = 2.6524  \n",
      "\n",
      "Fold: 7  Epoch: 465  Training loss = 2.7301  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 7  Epoch: 466  Training loss = 2.7299  Validation loss = 2.6519  \n",
      "\n",
      "Fold: 7  Epoch: 467  Training loss = 2.7297  Validation loss = 2.6517  \n",
      "\n",
      "Fold: 7  Epoch: 468  Training loss = 2.7295  Validation loss = 2.6515  \n",
      "\n",
      "Fold: 7  Epoch: 469  Training loss = 2.7293  Validation loss = 2.6513  \n",
      "\n",
      "Fold: 7  Epoch: 470  Training loss = 2.7291  Validation loss = 2.6510  \n",
      "\n",
      "Fold: 7  Epoch: 471  Training loss = 2.7290  Validation loss = 2.6508  \n",
      "\n",
      "Fold: 7  Epoch: 472  Training loss = 2.7288  Validation loss = 2.6506  \n",
      "\n",
      "Fold: 7  Epoch: 473  Training loss = 2.7287  Validation loss = 2.6504  \n",
      "\n",
      "Fold: 7  Epoch: 474  Training loss = 2.7285  Validation loss = 2.6502  \n",
      "\n",
      "Fold: 7  Epoch: 475  Training loss = 2.7283  Validation loss = 2.6501  \n",
      "\n",
      "Fold: 7  Epoch: 476  Training loss = 2.7282  Validation loss = 2.6499  \n",
      "\n",
      "Fold: 7  Epoch: 477  Training loss = 2.7280  Validation loss = 2.6496  \n",
      "\n",
      "Fold: 7  Epoch: 478  Training loss = 2.7278  Validation loss = 2.6495  \n",
      "\n",
      "Fold: 7  Epoch: 479  Training loss = 2.7276  Validation loss = 2.6492  \n",
      "\n",
      "Fold: 7  Epoch: 480  Training loss = 2.7275  Validation loss = 2.6490  \n",
      "\n",
      "Fold: 7  Epoch: 481  Training loss = 2.7273  Validation loss = 2.6488  \n",
      "\n",
      "Fold: 7  Epoch: 482  Training loss = 2.7271  Validation loss = 2.6486  \n",
      "\n",
      "Fold: 7  Epoch: 483  Training loss = 2.7269  Validation loss = 2.6484  \n",
      "\n",
      "Fold: 7  Epoch: 484  Training loss = 2.7267  Validation loss = 2.6482  \n",
      "\n",
      "Fold: 7  Epoch: 485  Training loss = 2.7266  Validation loss = 2.6480  \n",
      "\n",
      "Fold: 7  Epoch: 486  Training loss = 2.7264  Validation loss = 2.6477  \n",
      "\n",
      "Fold: 7  Epoch: 487  Training loss = 2.7262  Validation loss = 2.6475  \n",
      "\n",
      "Fold: 7  Epoch: 488  Training loss = 2.7260  Validation loss = 2.6472  \n",
      "\n",
      "Fold: 7  Epoch: 489  Training loss = 2.7258  Validation loss = 2.6470  \n",
      "\n",
      "Fold: 7  Epoch: 490  Training loss = 2.7256  Validation loss = 2.6468  \n",
      "\n",
      "Fold: 7  Epoch: 491  Training loss = 2.7254  Validation loss = 2.6466  \n",
      "\n",
      "Fold: 7  Epoch: 492  Training loss = 2.7252  Validation loss = 2.6463  \n",
      "\n",
      "Fold: 7  Epoch: 493  Training loss = 2.7251  Validation loss = 2.6461  \n",
      "\n",
      "Fold: 7  Epoch: 494  Training loss = 2.7249  Validation loss = 2.6459  \n",
      "\n",
      "Fold: 7  Epoch: 495  Training loss = 2.7247  Validation loss = 2.6457  \n",
      "\n",
      "Fold: 7  Epoch: 496  Training loss = 2.7245  Validation loss = 2.6455  \n",
      "\n",
      "Fold: 7  Epoch: 497  Training loss = 2.7244  Validation loss = 2.6453  \n",
      "\n",
      "Fold: 7  Epoch: 498  Training loss = 2.7242  Validation loss = 2.6451  \n",
      "\n",
      "Fold: 7  Epoch: 499  Training loss = 2.7240  Validation loss = 2.6449  \n",
      "\n",
      "Fold: 7  Epoch: 500  Training loss = 2.7238  Validation loss = 2.6446  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 500  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 2.7499  Validation loss = 7.9178  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 2.7497  Validation loss = 7.9175  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 2.7495  Validation loss = 7.9172  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 2.7493  Validation loss = 7.9169  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 2.7491  Validation loss = 7.9166  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 2.7489  Validation loss = 7.9164  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 2.7487  Validation loss = 7.9161  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 2.7485  Validation loss = 7.9158  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 2.7483  Validation loss = 7.9156  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 2.7482  Validation loss = 7.9153  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 2.7480  Validation loss = 7.9151  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 2.7478  Validation loss = 7.9148  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 2.7476  Validation loss = 7.9145  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 2.7474  Validation loss = 7.9142  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 2.7472  Validation loss = 7.9139  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 2.7470  Validation loss = 7.9136  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 2.7468  Validation loss = 7.9134  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 2.7466  Validation loss = 7.9131  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 2.7464  Validation loss = 7.9128  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 2.7462  Validation loss = 7.9125  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 2.7460  Validation loss = 7.9123  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 2.7458  Validation loss = 7.9120  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 2.7456  Validation loss = 7.9117  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 2.7454  Validation loss = 7.9115  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 2.7452  Validation loss = 7.9112  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 2.7450  Validation loss = 7.9109  \n",
      "\n",
      "Fold: 8  Epoch: 27  Training loss = 2.7448  Validation loss = 7.9106  \n",
      "\n",
      "Fold: 8  Epoch: 28  Training loss = 2.7446  Validation loss = 7.9103  \n",
      "\n",
      "Fold: 8  Epoch: 29  Training loss = 2.7444  Validation loss = 7.9100  \n",
      "\n",
      "Fold: 8  Epoch: 30  Training loss = 2.7442  Validation loss = 7.9097  \n",
      "\n",
      "Fold: 8  Epoch: 31  Training loss = 2.7440  Validation loss = 7.9095  \n",
      "\n",
      "Fold: 8  Epoch: 32  Training loss = 2.7438  Validation loss = 7.9091  \n",
      "\n",
      "Fold: 8  Epoch: 33  Training loss = 2.7436  Validation loss = 7.9089  \n",
      "\n",
      "Fold: 8  Epoch: 34  Training loss = 2.7435  Validation loss = 7.9086  \n",
      "\n",
      "Fold: 8  Epoch: 35  Training loss = 2.7432  Validation loss = 7.9083  \n",
      "\n",
      "Fold: 8  Epoch: 36  Training loss = 2.7430  Validation loss = 7.9080  \n",
      "\n",
      "Fold: 8  Epoch: 37  Training loss = 2.7428  Validation loss = 7.9078  \n",
      "\n",
      "Fold: 8  Epoch: 38  Training loss = 2.7427  Validation loss = 7.9075  \n",
      "\n",
      "Fold: 8  Epoch: 39  Training loss = 2.7425  Validation loss = 7.9073  \n",
      "\n",
      "Fold: 8  Epoch: 40  Training loss = 2.7423  Validation loss = 7.9070  \n",
      "\n",
      "Fold: 8  Epoch: 41  Training loss = 2.7421  Validation loss = 7.9068  \n",
      "\n",
      "Fold: 8  Epoch: 42  Training loss = 2.7419  Validation loss = 7.9065  \n",
      "\n",
      "Fold: 8  Epoch: 43  Training loss = 2.7417  Validation loss = 7.9062  \n",
      "\n",
      "Fold: 8  Epoch: 44  Training loss = 2.7415  Validation loss = 7.9059  \n",
      "\n",
      "Fold: 8  Epoch: 45  Training loss = 2.7413  Validation loss = 7.9057  \n",
      "\n",
      "Fold: 8  Epoch: 46  Training loss = 2.7412  Validation loss = 7.9054  \n",
      "\n",
      "Fold: 8  Epoch: 47  Training loss = 2.7410  Validation loss = 7.9052  \n",
      "\n",
      "Fold: 8  Epoch: 48  Training loss = 2.7408  Validation loss = 7.9049  \n",
      "\n",
      "Fold: 8  Epoch: 49  Training loss = 2.7406  Validation loss = 7.9047  \n",
      "\n",
      "Fold: 8  Epoch: 50  Training loss = 2.7404  Validation loss = 7.9044  \n",
      "\n",
      "Fold: 8  Epoch: 51  Training loss = 2.7402  Validation loss = 7.9041  \n",
      "\n",
      "Fold: 8  Epoch: 52  Training loss = 2.7400  Validation loss = 7.9038  \n",
      "\n",
      "Fold: 8  Epoch: 53  Training loss = 2.7399  Validation loss = 7.9036  \n",
      "\n",
      "Fold: 8  Epoch: 54  Training loss = 2.7397  Validation loss = 7.9033  \n",
      "\n",
      "Fold: 8  Epoch: 55  Training loss = 2.7394  Validation loss = 7.9030  \n",
      "\n",
      "Fold: 8  Epoch: 56  Training loss = 2.7392  Validation loss = 7.9027  \n",
      "\n",
      "Fold: 8  Epoch: 57  Training loss = 2.7390  Validation loss = 7.9024  \n",
      "\n",
      "Fold: 8  Epoch: 58  Training loss = 2.7388  Validation loss = 7.9021  \n",
      "\n",
      "Fold: 8  Epoch: 59  Training loss = 2.7386  Validation loss = 7.9018  \n",
      "\n",
      "Fold: 8  Epoch: 60  Training loss = 2.7384  Validation loss = 7.9015  \n",
      "\n",
      "Fold: 8  Epoch: 61  Training loss = 2.7382  Validation loss = 7.9012  \n",
      "\n",
      "Fold: 8  Epoch: 62  Training loss = 2.7380  Validation loss = 7.9010  \n",
      "\n",
      "Fold: 8  Epoch: 63  Training loss = 2.7379  Validation loss = 7.9008  \n",
      "\n",
      "Fold: 8  Epoch: 64  Training loss = 2.7377  Validation loss = 7.9005  \n",
      "\n",
      "Fold: 8  Epoch: 65  Training loss = 2.7375  Validation loss = 7.9003  \n",
      "\n",
      "Fold: 8  Epoch: 66  Training loss = 2.7373  Validation loss = 7.8999  \n",
      "\n",
      "Fold: 8  Epoch: 67  Training loss = 2.7371  Validation loss = 7.8997  \n",
      "\n",
      "Fold: 8  Epoch: 68  Training loss = 2.7369  Validation loss = 7.8994  \n",
      "\n",
      "Fold: 8  Epoch: 69  Training loss = 2.7367  Validation loss = 7.8992  \n",
      "\n",
      "Fold: 8  Epoch: 70  Training loss = 2.7365  Validation loss = 7.8988  \n",
      "\n",
      "Fold: 8  Epoch: 71  Training loss = 2.7363  Validation loss = 7.8986  \n",
      "\n",
      "Fold: 8  Epoch: 72  Training loss = 2.7361  Validation loss = 7.8983  \n",
      "\n",
      "Fold: 8  Epoch: 73  Training loss = 2.7359  Validation loss = 7.8980  \n",
      "\n",
      "Fold: 8  Epoch: 74  Training loss = 2.7357  Validation loss = 7.8977  \n",
      "\n",
      "Fold: 8  Epoch: 75  Training loss = 2.7355  Validation loss = 7.8973  \n",
      "\n",
      "Fold: 8  Epoch: 76  Training loss = 2.7353  Validation loss = 7.8971  \n",
      "\n",
      "Fold: 8  Epoch: 77  Training loss = 2.7351  Validation loss = 7.8969  \n",
      "\n",
      "Fold: 8  Epoch: 78  Training loss = 2.7350  Validation loss = 7.8966  \n",
      "\n",
      "Fold: 8  Epoch: 79  Training loss = 2.7348  Validation loss = 7.8964  \n",
      "\n",
      "Fold: 8  Epoch: 80  Training loss = 2.7346  Validation loss = 7.8961  \n",
      "\n",
      "Fold: 8  Epoch: 81  Training loss = 2.7344  Validation loss = 7.8959  \n",
      "\n",
      "Fold: 8  Epoch: 82  Training loss = 2.7342  Validation loss = 7.8956  \n",
      "\n",
      "Fold: 8  Epoch: 83  Training loss = 2.7340  Validation loss = 7.8953  \n",
      "\n",
      "Fold: 8  Epoch: 84  Training loss = 2.7338  Validation loss = 7.8950  \n",
      "\n",
      "Fold: 8  Epoch: 85  Training loss = 2.7337  Validation loss = 7.8948  \n",
      "\n",
      "Fold: 8  Epoch: 86  Training loss = 2.7335  Validation loss = 7.8945  \n",
      "\n",
      "Fold: 8  Epoch: 87  Training loss = 2.7333  Validation loss = 7.8943  \n",
      "\n",
      "Fold: 8  Epoch: 88  Training loss = 2.7331  Validation loss = 7.8940  \n",
      "\n",
      "Fold: 8  Epoch: 89  Training loss = 2.7330  Validation loss = 7.8938  \n",
      "\n",
      "Fold: 8  Epoch: 90  Training loss = 2.7328  Validation loss = 7.8935  \n",
      "\n",
      "Fold: 8  Epoch: 91  Training loss = 2.7326  Validation loss = 7.8932  \n",
      "\n",
      "Fold: 8  Epoch: 92  Training loss = 2.7324  Validation loss = 7.8930  \n",
      "\n",
      "Fold: 8  Epoch: 93  Training loss = 2.7322  Validation loss = 7.8927  \n",
      "\n",
      "Fold: 8  Epoch: 94  Training loss = 2.7320  Validation loss = 7.8924  \n",
      "\n",
      "Fold: 8  Epoch: 95  Training loss = 2.7318  Validation loss = 7.8922  \n",
      "\n",
      "Fold: 8  Epoch: 96  Training loss = 2.7316  Validation loss = 7.8918  \n",
      "\n",
      "Fold: 8  Epoch: 97  Training loss = 2.7314  Validation loss = 7.8916  \n",
      "\n",
      "Fold: 8  Epoch: 98  Training loss = 2.7313  Validation loss = 7.8914  \n",
      "\n",
      "Fold: 8  Epoch: 99  Training loss = 2.7311  Validation loss = 7.8911  \n",
      "\n",
      "Fold: 8  Epoch: 100  Training loss = 2.7309  Validation loss = 7.8908  \n",
      "\n",
      "Fold: 8  Epoch: 101  Training loss = 2.7307  Validation loss = 7.8906  \n",
      "\n",
      "Fold: 8  Epoch: 102  Training loss = 2.7305  Validation loss = 7.8903  \n",
      "\n",
      "Fold: 8  Epoch: 103  Training loss = 2.7303  Validation loss = 7.8901  \n",
      "\n",
      "Fold: 8  Epoch: 104  Training loss = 2.7301  Validation loss = 7.8898  \n",
      "\n",
      "Fold: 8  Epoch: 105  Training loss = 2.7299  Validation loss = 7.8895  \n",
      "\n",
      "Fold: 8  Epoch: 106  Training loss = 2.7298  Validation loss = 7.8893  \n",
      "\n",
      "Fold: 8  Epoch: 107  Training loss = 2.7296  Validation loss = 7.8890  \n",
      "\n",
      "Fold: 8  Epoch: 108  Training loss = 2.7294  Validation loss = 7.8888  \n",
      "\n",
      "Fold: 8  Epoch: 109  Training loss = 2.7292  Validation loss = 7.8885  \n",
      "\n",
      "Fold: 8  Epoch: 110  Training loss = 2.7290  Validation loss = 7.8882  \n",
      "\n",
      "Fold: 8  Epoch: 111  Training loss = 2.7288  Validation loss = 7.8880  \n",
      "\n",
      "Fold: 8  Epoch: 112  Training loss = 2.7286  Validation loss = 7.8877  \n",
      "\n",
      "Fold: 8  Epoch: 113  Training loss = 2.7284  Validation loss = 7.8874  \n",
      "\n",
      "Fold: 8  Epoch: 114  Training loss = 2.7283  Validation loss = 7.8871  \n",
      "\n",
      "Fold: 8  Epoch: 115  Training loss = 2.7280  Validation loss = 7.8868  \n",
      "\n",
      "Fold: 8  Epoch: 116  Training loss = 2.7278  Validation loss = 7.8865  \n",
      "\n",
      "Fold: 8  Epoch: 117  Training loss = 2.7276  Validation loss = 7.8862  \n",
      "\n",
      "Fold: 8  Epoch: 118  Training loss = 2.7274  Validation loss = 7.8859  \n",
      "\n",
      "Fold: 8  Epoch: 119  Training loss = 2.7272  Validation loss = 7.8856  \n",
      "\n",
      "Fold: 8  Epoch: 120  Training loss = 2.7270  Validation loss = 7.8853  \n",
      "\n",
      "Fold: 8  Epoch: 121  Training loss = 2.7268  Validation loss = 7.8850  \n",
      "\n",
      "Fold: 8  Epoch: 122  Training loss = 2.7266  Validation loss = 7.8847  \n",
      "\n",
      "Fold: 8  Epoch: 123  Training loss = 2.7264  Validation loss = 7.8844  \n",
      "\n",
      "Fold: 8  Epoch: 124  Training loss = 2.7261  Validation loss = 7.8841  \n",
      "\n",
      "Fold: 8  Epoch: 125  Training loss = 2.7259  Validation loss = 7.8838  \n",
      "\n",
      "Fold: 8  Epoch: 126  Training loss = 2.7257  Validation loss = 7.8835  \n",
      "\n",
      "Fold: 8  Epoch: 127  Training loss = 2.7255  Validation loss = 7.8833  \n",
      "\n",
      "Fold: 8  Epoch: 128  Training loss = 2.7253  Validation loss = 7.8829  \n",
      "\n",
      "Fold: 8  Epoch: 129  Training loss = 2.7251  Validation loss = 7.8827  \n",
      "\n",
      "Fold: 8  Epoch: 130  Training loss = 2.7250  Validation loss = 7.8825  \n",
      "\n",
      "Fold: 8  Epoch: 131  Training loss = 2.7248  Validation loss = 7.8822  \n",
      "\n",
      "Fold: 8  Epoch: 132  Training loss = 2.7246  Validation loss = 7.8819  \n",
      "\n",
      "Fold: 8  Epoch: 133  Training loss = 2.7244  Validation loss = 7.8816  \n",
      "\n",
      "Fold: 8  Epoch: 134  Training loss = 2.7242  Validation loss = 7.8814  \n",
      "\n",
      "Fold: 8  Epoch: 135  Training loss = 2.7241  Validation loss = 7.8811  \n",
      "\n",
      "Fold: 8  Epoch: 136  Training loss = 2.7239  Validation loss = 7.8809  \n",
      "\n",
      "Fold: 8  Epoch: 137  Training loss = 2.7237  Validation loss = 7.8806  \n",
      "\n",
      "Fold: 8  Epoch: 138  Training loss = 2.7235  Validation loss = 7.8803  \n",
      "\n",
      "Fold: 8  Epoch: 139  Training loss = 2.7232  Validation loss = 7.8800  \n",
      "\n",
      "Fold: 8  Epoch: 140  Training loss = 2.7231  Validation loss = 7.8797  \n",
      "\n",
      "Fold: 8  Epoch: 141  Training loss = 2.7228  Validation loss = 7.8794  \n",
      "\n",
      "Fold: 8  Epoch: 142  Training loss = 2.7226  Validation loss = 7.8791  \n",
      "\n",
      "Fold: 8  Epoch: 143  Training loss = 2.7225  Validation loss = 7.8789  \n",
      "\n",
      "Fold: 8  Epoch: 144  Training loss = 2.7223  Validation loss = 7.8786  \n",
      "\n",
      "Fold: 8  Epoch: 145  Training loss = 2.7221  Validation loss = 7.8784  \n",
      "\n",
      "Fold: 8  Epoch: 146  Training loss = 2.7219  Validation loss = 7.8782  \n",
      "\n",
      "Fold: 8  Epoch: 147  Training loss = 2.7218  Validation loss = 7.8779  \n",
      "\n",
      "Fold: 8  Epoch: 148  Training loss = 2.7216  Validation loss = 7.8777  \n",
      "\n",
      "Fold: 8  Epoch: 149  Training loss = 2.7214  Validation loss = 7.8774  \n",
      "\n",
      "Fold: 8  Epoch: 150  Training loss = 2.7212  Validation loss = 7.8772  \n",
      "\n",
      "Fold: 8  Epoch: 151  Training loss = 2.7211  Validation loss = 7.8770  \n",
      "\n",
      "Fold: 8  Epoch: 152  Training loss = 2.7209  Validation loss = 7.8767  \n",
      "\n",
      "Fold: 8  Epoch: 153  Training loss = 2.7207  Validation loss = 7.8764  \n",
      "\n",
      "Fold: 8  Epoch: 154  Training loss = 2.7205  Validation loss = 7.8761  \n",
      "\n",
      "Fold: 8  Epoch: 155  Training loss = 2.7203  Validation loss = 7.8759  \n",
      "\n",
      "Fold: 8  Epoch: 156  Training loss = 2.7201  Validation loss = 7.8756  \n",
      "\n",
      "Fold: 8  Epoch: 157  Training loss = 2.7199  Validation loss = 7.8753  \n",
      "\n",
      "Fold: 8  Epoch: 158  Training loss = 2.7197  Validation loss = 7.8750  \n",
      "\n",
      "Fold: 8  Epoch: 159  Training loss = 2.7195  Validation loss = 7.8747  \n",
      "\n",
      "Fold: 8  Epoch: 160  Training loss = 2.7193  Validation loss = 7.8744  \n",
      "\n",
      "Fold: 8  Epoch: 161  Training loss = 2.7191  Validation loss = 7.8742  \n",
      "\n",
      "Fold: 8  Epoch: 162  Training loss = 2.7190  Validation loss = 7.8740  \n",
      "\n",
      "Fold: 8  Epoch: 163  Training loss = 2.7187  Validation loss = 7.8737  \n",
      "\n",
      "Fold: 8  Epoch: 164  Training loss = 2.7186  Validation loss = 7.8734  \n",
      "\n",
      "Fold: 8  Epoch: 165  Training loss = 2.7184  Validation loss = 7.8732  \n",
      "\n",
      "Fold: 8  Epoch: 166  Training loss = 2.7182  Validation loss = 7.8729  \n",
      "\n",
      "Fold: 8  Epoch: 167  Training loss = 2.7180  Validation loss = 7.8727  \n",
      "\n",
      "Fold: 8  Epoch: 168  Training loss = 2.7178  Validation loss = 7.8724  \n",
      "\n",
      "Fold: 8  Epoch: 169  Training loss = 2.7177  Validation loss = 7.8722  \n",
      "\n",
      "Fold: 8  Epoch: 170  Training loss = 2.7175  Validation loss = 7.8719  \n",
      "\n",
      "Fold: 8  Epoch: 171  Training loss = 2.7173  Validation loss = 7.8716  \n",
      "\n",
      "Fold: 8  Epoch: 172  Training loss = 2.7171  Validation loss = 7.8714  \n",
      "\n",
      "Fold: 8  Epoch: 173  Training loss = 2.7170  Validation loss = 7.8711  \n",
      "\n",
      "Fold: 8  Epoch: 174  Training loss = 2.7168  Validation loss = 7.8709  \n",
      "\n",
      "Fold: 8  Epoch: 175  Training loss = 2.7166  Validation loss = 7.8706  \n",
      "\n",
      "Fold: 8  Epoch: 176  Training loss = 2.7163  Validation loss = 7.8702  \n",
      "\n",
      "Fold: 8  Epoch: 177  Training loss = 2.7161  Validation loss = 7.8700  \n",
      "\n",
      "Fold: 8  Epoch: 178  Training loss = 2.7159  Validation loss = 7.8697  \n",
      "\n",
      "Fold: 8  Epoch: 179  Training loss = 2.7157  Validation loss = 7.8694  \n",
      "\n",
      "Fold: 8  Epoch: 180  Training loss = 2.7156  Validation loss = 7.8692  \n",
      "\n",
      "Fold: 8  Epoch: 181  Training loss = 2.7154  Validation loss = 7.8690  \n",
      "\n",
      "Fold: 8  Epoch: 182  Training loss = 2.7153  Validation loss = 7.8687  \n",
      "\n",
      "Fold: 8  Epoch: 183  Training loss = 2.7150  Validation loss = 7.8684  \n",
      "\n",
      "Fold: 8  Epoch: 184  Training loss = 2.7149  Validation loss = 7.8682  \n",
      "\n",
      "Fold: 8  Epoch: 185  Training loss = 2.7147  Validation loss = 7.8679  \n",
      "\n",
      "Fold: 8  Epoch: 186  Training loss = 2.7145  Validation loss = 7.8676  \n",
      "\n",
      "Fold: 8  Epoch: 187  Training loss = 2.7143  Validation loss = 7.8673  \n",
      "\n",
      "Fold: 8  Epoch: 188  Training loss = 2.7141  Validation loss = 7.8671  \n",
      "\n",
      "Fold: 8  Epoch: 189  Training loss = 2.7139  Validation loss = 7.8667  \n",
      "\n",
      "Fold: 8  Epoch: 190  Training loss = 2.7137  Validation loss = 7.8665  \n",
      "\n",
      "Fold: 8  Epoch: 191  Training loss = 2.7135  Validation loss = 7.8662  \n",
      "\n",
      "Fold: 8  Epoch: 192  Training loss = 2.7132  Validation loss = 7.8659  \n",
      "\n",
      "Fold: 8  Epoch: 193  Training loss = 2.7130  Validation loss = 7.8656  \n",
      "\n",
      "Fold: 8  Epoch: 194  Training loss = 2.7128  Validation loss = 7.8653  \n",
      "\n",
      "Fold: 8  Epoch: 195  Training loss = 2.7127  Validation loss = 7.8651  \n",
      "\n",
      "Fold: 8  Epoch: 196  Training loss = 2.7125  Validation loss = 7.8648  \n",
      "\n",
      "Fold: 8  Epoch: 197  Training loss = 2.7123  Validation loss = 7.8646  \n",
      "\n",
      "Fold: 8  Epoch: 198  Training loss = 2.7121  Validation loss = 7.8643  \n",
      "\n",
      "Fold: 8  Epoch: 199  Training loss = 2.7119  Validation loss = 7.8640  \n",
      "\n",
      "Fold: 8  Epoch: 200  Training loss = 2.7117  Validation loss = 7.8637  \n",
      "\n",
      "Fold: 8  Epoch: 201  Training loss = 2.7115  Validation loss = 7.8634  \n",
      "\n",
      "Fold: 8  Epoch: 202  Training loss = 2.7113  Validation loss = 7.8632  \n",
      "\n",
      "Fold: 8  Epoch: 203  Training loss = 2.7111  Validation loss = 7.8629  \n",
      "\n",
      "Fold: 8  Epoch: 204  Training loss = 2.7109  Validation loss = 7.8627  \n",
      "\n",
      "Fold: 8  Epoch: 205  Training loss = 2.7107  Validation loss = 7.8624  \n",
      "\n",
      "Fold: 8  Epoch: 206  Training loss = 2.7105  Validation loss = 7.8621  \n",
      "\n",
      "Fold: 8  Epoch: 207  Training loss = 2.7103  Validation loss = 7.8618  \n",
      "\n",
      "Fold: 8  Epoch: 208  Training loss = 2.7102  Validation loss = 7.8616  \n",
      "\n",
      "Fold: 8  Epoch: 209  Training loss = 2.7100  Validation loss = 7.8613  \n",
      "\n",
      "Fold: 8  Epoch: 210  Training loss = 2.7098  Validation loss = 7.8610  \n",
      "\n",
      "Fold: 8  Epoch: 211  Training loss = 2.7096  Validation loss = 7.8608  \n",
      "\n",
      "Fold: 8  Epoch: 212  Training loss = 2.7094  Validation loss = 7.8605  \n",
      "\n",
      "Fold: 8  Epoch: 213  Training loss = 2.7092  Validation loss = 7.8602  \n",
      "\n",
      "Fold: 8  Epoch: 214  Training loss = 2.7091  Validation loss = 7.8600  \n",
      "\n",
      "Fold: 8  Epoch: 215  Training loss = 2.7089  Validation loss = 7.8597  \n",
      "\n",
      "Fold: 8  Epoch: 216  Training loss = 2.7087  Validation loss = 7.8595  \n",
      "\n",
      "Fold: 8  Epoch: 217  Training loss = 2.7085  Validation loss = 7.8591  \n",
      "\n",
      "Fold: 8  Epoch: 218  Training loss = 2.7082  Validation loss = 7.8588  \n",
      "\n",
      "Fold: 8  Epoch: 219  Training loss = 2.7081  Validation loss = 7.8586  \n",
      "\n",
      "Fold: 8  Epoch: 220  Training loss = 2.7079  Validation loss = 7.8583  \n",
      "\n",
      "Fold: 8  Epoch: 221  Training loss = 2.7077  Validation loss = 7.8580  \n",
      "\n",
      "Fold: 8  Epoch: 222  Training loss = 2.7075  Validation loss = 7.8577  \n",
      "\n",
      "Fold: 8  Epoch: 223  Training loss = 2.7073  Validation loss = 7.8575  \n",
      "\n",
      "Fold: 8  Epoch: 224  Training loss = 2.7071  Validation loss = 7.8572  \n",
      "\n",
      "Fold: 8  Epoch: 225  Training loss = 2.7069  Validation loss = 7.8569  \n",
      "\n",
      "Fold: 8  Epoch: 226  Training loss = 2.7067  Validation loss = 7.8567  \n",
      "\n",
      "Fold: 8  Epoch: 227  Training loss = 2.7066  Validation loss = 7.8565  \n",
      "\n",
      "Fold: 8  Epoch: 228  Training loss = 2.7064  Validation loss = 7.8562  \n",
      "\n",
      "Fold: 8  Epoch: 229  Training loss = 2.7062  Validation loss = 7.8559  \n",
      "\n",
      "Fold: 8  Epoch: 230  Training loss = 2.7061  Validation loss = 7.8557  \n",
      "\n",
      "Fold: 8  Epoch: 231  Training loss = 2.7059  Validation loss = 7.8554  \n",
      "\n",
      "Fold: 8  Epoch: 232  Training loss = 2.7057  Validation loss = 7.8552  \n",
      "\n",
      "Fold: 8  Epoch: 233  Training loss = 2.7055  Validation loss = 7.8549  \n",
      "\n",
      "Fold: 8  Epoch: 234  Training loss = 2.7053  Validation loss = 7.8546  \n",
      "\n",
      "Fold: 8  Epoch: 235  Training loss = 2.7052  Validation loss = 7.8544  \n",
      "\n",
      "Fold: 8  Epoch: 236  Training loss = 2.7050  Validation loss = 7.8542  \n",
      "\n",
      "Fold: 8  Epoch: 237  Training loss = 2.7048  Validation loss = 7.8539  \n",
      "\n",
      "Fold: 8  Epoch: 238  Training loss = 2.7046  Validation loss = 7.8536  \n",
      "\n",
      "Fold: 8  Epoch: 239  Training loss = 2.7044  Validation loss = 7.8533  \n",
      "\n",
      "Fold: 8  Epoch: 240  Training loss = 2.7042  Validation loss = 7.8531  \n",
      "\n",
      "Fold: 8  Epoch: 241  Training loss = 2.7040  Validation loss = 7.8528  \n",
      "\n",
      "Fold: 8  Epoch: 242  Training loss = 2.7038  Validation loss = 7.8526  \n",
      "\n",
      "Fold: 8  Epoch: 243  Training loss = 2.7037  Validation loss = 7.8523  \n",
      "\n",
      "Fold: 8  Epoch: 244  Training loss = 2.7035  Validation loss = 7.8521  \n",
      "\n",
      "Fold: 8  Epoch: 245  Training loss = 2.7033  Validation loss = 7.8518  \n",
      "\n",
      "Fold: 8  Epoch: 246  Training loss = 2.7031  Validation loss = 7.8516  \n",
      "\n",
      "Fold: 8  Epoch: 247  Training loss = 2.7030  Validation loss = 7.8513  \n",
      "\n",
      "Fold: 8  Epoch: 248  Training loss = 2.7028  Validation loss = 7.8511  \n",
      "\n",
      "Fold: 8  Epoch: 249  Training loss = 2.7026  Validation loss = 7.8508  \n",
      "\n",
      "Fold: 8  Epoch: 250  Training loss = 2.7024  Validation loss = 7.8505  \n",
      "\n",
      "Fold: 8  Epoch: 251  Training loss = 2.7021  Validation loss = 7.8501  \n",
      "\n",
      "Fold: 8  Epoch: 252  Training loss = 2.7019  Validation loss = 7.8498  \n",
      "\n",
      "Fold: 8  Epoch: 253  Training loss = 2.7017  Validation loss = 7.8495  \n",
      "\n",
      "Fold: 8  Epoch: 254  Training loss = 2.7015  Validation loss = 7.8493  \n",
      "\n",
      "Fold: 8  Epoch: 255  Training loss = 2.7014  Validation loss = 7.8490  \n",
      "\n",
      "Fold: 8  Epoch: 256  Training loss = 2.7012  Validation loss = 7.8487  \n",
      "\n",
      "Fold: 8  Epoch: 257  Training loss = 2.7010  Validation loss = 7.8485  \n",
      "\n",
      "Fold: 8  Epoch: 258  Training loss = 2.7008  Validation loss = 7.8483  \n",
      "\n",
      "Fold: 8  Epoch: 259  Training loss = 2.7006  Validation loss = 7.8480  \n",
      "\n",
      "Fold: 8  Epoch: 260  Training loss = 2.7004  Validation loss = 7.8477  \n",
      "\n",
      "Fold: 8  Epoch: 261  Training loss = 2.7002  Validation loss = 7.8474  \n",
      "\n",
      "Fold: 8  Epoch: 262  Training loss = 2.7001  Validation loss = 7.8472  \n",
      "\n",
      "Fold: 8  Epoch: 263  Training loss = 2.6999  Validation loss = 7.8470  \n",
      "\n",
      "Fold: 8  Epoch: 264  Training loss = 2.6997  Validation loss = 7.8467  \n",
      "\n",
      "Fold: 8  Epoch: 265  Training loss = 2.6996  Validation loss = 7.8464  \n",
      "\n",
      "Fold: 8  Epoch: 266  Training loss = 2.6993  Validation loss = 7.8462  \n",
      "\n",
      "Fold: 8  Epoch: 267  Training loss = 2.6992  Validation loss = 7.8459  \n",
      "\n",
      "Fold: 8  Epoch: 268  Training loss = 2.6990  Validation loss = 7.8456  \n",
      "\n",
      "Fold: 8  Epoch: 269  Training loss = 2.6987  Validation loss = 7.8453  \n",
      "\n",
      "Fold: 8  Epoch: 270  Training loss = 2.6986  Validation loss = 7.8451  \n",
      "\n",
      "Fold: 8  Epoch: 271  Training loss = 2.6984  Validation loss = 7.8448  \n",
      "\n",
      "Fold: 8  Epoch: 272  Training loss = 2.6982  Validation loss = 7.8445  \n",
      "\n",
      "Fold: 8  Epoch: 273  Training loss = 2.6980  Validation loss = 7.8443  \n",
      "\n",
      "Fold: 8  Epoch: 274  Training loss = 2.6978  Validation loss = 7.8440  \n",
      "\n",
      "Fold: 8  Epoch: 275  Training loss = 2.6976  Validation loss = 7.8437  \n",
      "\n",
      "Fold: 8  Epoch: 276  Training loss = 2.6974  Validation loss = 7.8434  \n",
      "\n",
      "Fold: 8  Epoch: 277  Training loss = 2.6972  Validation loss = 7.8432  \n",
      "\n",
      "Fold: 8  Epoch: 278  Training loss = 2.6970  Validation loss = 7.8429  \n",
      "\n",
      "Fold: 8  Epoch: 279  Training loss = 2.6968  Validation loss = 7.8426  \n",
      "\n",
      "Fold: 8  Epoch: 280  Training loss = 2.6967  Validation loss = 7.8424  \n",
      "\n",
      "Fold: 8  Epoch: 281  Training loss = 2.6965  Validation loss = 7.8421  \n",
      "\n",
      "Fold: 8  Epoch: 282  Training loss = 2.6963  Validation loss = 7.8419  \n",
      "\n",
      "Fold: 8  Epoch: 283  Training loss = 2.6961  Validation loss = 7.8416  \n",
      "\n",
      "Fold: 8  Epoch: 284  Training loss = 2.6959  Validation loss = 7.8413  \n",
      "\n",
      "Fold: 8  Epoch: 285  Training loss = 2.6957  Validation loss = 7.8411  \n",
      "\n",
      "Fold: 8  Epoch: 286  Training loss = 2.6955  Validation loss = 7.8408  \n",
      "\n",
      "Fold: 8  Epoch: 287  Training loss = 2.6953  Validation loss = 7.8405  \n",
      "\n",
      "Fold: 8  Epoch: 288  Training loss = 2.6951  Validation loss = 7.8402  \n",
      "\n",
      "Fold: 8  Epoch: 289  Training loss = 2.6950  Validation loss = 7.8400  \n",
      "\n",
      "Fold: 8  Epoch: 290  Training loss = 2.6948  Validation loss = 7.8397  \n",
      "\n",
      "Fold: 8  Epoch: 291  Training loss = 2.6946  Validation loss = 7.8394  \n",
      "\n",
      "Fold: 8  Epoch: 292  Training loss = 2.6944  Validation loss = 7.8391  \n",
      "\n",
      "Fold: 8  Epoch: 293  Training loss = 2.6942  Validation loss = 7.8389  \n",
      "\n",
      "Fold: 8  Epoch: 294  Training loss = 2.6940  Validation loss = 7.8387  \n",
      "\n",
      "Fold: 8  Epoch: 295  Training loss = 2.6938  Validation loss = 7.8383  \n",
      "\n",
      "Fold: 8  Epoch: 296  Training loss = 2.6936  Validation loss = 7.8381  \n",
      "\n",
      "Fold: 8  Epoch: 297  Training loss = 2.6934  Validation loss = 7.8378  \n",
      "\n",
      "Fold: 8  Epoch: 298  Training loss = 2.6933  Validation loss = 7.8375  \n",
      "\n",
      "Fold: 8  Epoch: 299  Training loss = 2.6930  Validation loss = 7.8372  \n",
      "\n",
      "Fold: 8  Epoch: 300  Training loss = 2.6929  Validation loss = 7.8370  \n",
      "\n",
      "Fold: 8  Epoch: 301  Training loss = 2.6927  Validation loss = 7.8367  \n",
      "\n",
      "Fold: 8  Epoch: 302  Training loss = 2.6925  Validation loss = 7.8364  \n",
      "\n",
      "Fold: 8  Epoch: 303  Training loss = 2.6923  Validation loss = 7.8362  \n",
      "\n",
      "Fold: 8  Epoch: 304  Training loss = 2.6921  Validation loss = 7.8359  \n",
      "\n",
      "Fold: 8  Epoch: 305  Training loss = 2.6919  Validation loss = 7.8356  \n",
      "\n",
      "Fold: 8  Epoch: 306  Training loss = 2.6917  Validation loss = 7.8353  \n",
      "\n",
      "Fold: 8  Epoch: 307  Training loss = 2.6915  Validation loss = 7.8350  \n",
      "\n",
      "Fold: 8  Epoch: 308  Training loss = 2.6913  Validation loss = 7.8347  \n",
      "\n",
      "Fold: 8  Epoch: 309  Training loss = 2.6911  Validation loss = 7.8345  \n",
      "\n",
      "Fold: 8  Epoch: 310  Training loss = 2.6909  Validation loss = 7.8342  \n",
      "\n",
      "Fold: 8  Epoch: 311  Training loss = 2.6907  Validation loss = 7.8339  \n",
      "\n",
      "Fold: 8  Epoch: 312  Training loss = 2.6905  Validation loss = 7.8336  \n",
      "\n",
      "Fold: 8  Epoch: 313  Training loss = 2.6903  Validation loss = 7.8333  \n",
      "\n",
      "Fold: 8  Epoch: 314  Training loss = 2.6901  Validation loss = 7.8331  \n",
      "\n",
      "Fold: 8  Epoch: 315  Training loss = 2.6899  Validation loss = 7.8327  \n",
      "\n",
      "Fold: 8  Epoch: 316  Training loss = 2.6897  Validation loss = 7.8325  \n",
      "\n",
      "Fold: 8  Epoch: 317  Training loss = 2.6895  Validation loss = 7.8322  \n",
      "\n",
      "Fold: 8  Epoch: 318  Training loss = 2.6893  Validation loss = 7.8319  \n",
      "\n",
      "Fold: 8  Epoch: 319  Training loss = 2.6891  Validation loss = 7.8316  \n",
      "\n",
      "Fold: 8  Epoch: 320  Training loss = 2.6889  Validation loss = 7.8313  \n",
      "\n",
      "Fold: 8  Epoch: 321  Training loss = 2.6887  Validation loss = 7.8310  \n",
      "\n",
      "Fold: 8  Epoch: 322  Training loss = 2.6885  Validation loss = 7.8307  \n",
      "\n",
      "Fold: 8  Epoch: 323  Training loss = 2.6883  Validation loss = 7.8305  \n",
      "\n",
      "Fold: 8  Epoch: 324  Training loss = 2.6881  Validation loss = 7.8302  \n",
      "\n",
      "Fold: 8  Epoch: 325  Training loss = 2.6879  Validation loss = 7.8300  \n",
      "\n",
      "Fold: 8  Epoch: 326  Training loss = 2.6877  Validation loss = 7.8297  \n",
      "\n",
      "Fold: 8  Epoch: 327  Training loss = 2.6876  Validation loss = 7.8294  \n",
      "\n",
      "Fold: 8  Epoch: 328  Training loss = 2.6874  Validation loss = 7.8291  \n",
      "\n",
      "Fold: 8  Epoch: 329  Training loss = 2.6872  Validation loss = 7.8289  \n",
      "\n",
      "Fold: 8  Epoch: 330  Training loss = 2.6870  Validation loss = 7.8286  \n",
      "\n",
      "Fold: 8  Epoch: 331  Training loss = 2.6868  Validation loss = 7.8283  \n",
      "\n",
      "Fold: 8  Epoch: 332  Training loss = 2.6866  Validation loss = 7.8280  \n",
      "\n",
      "Fold: 8  Epoch: 333  Training loss = 2.6864  Validation loss = 7.8277  \n",
      "\n",
      "Fold: 8  Epoch: 334  Training loss = 2.6862  Validation loss = 7.8275  \n",
      "\n",
      "Fold: 8  Epoch: 335  Training loss = 2.6860  Validation loss = 7.8273  \n",
      "\n",
      "Fold: 8  Epoch: 336  Training loss = 2.6858  Validation loss = 7.8269  \n",
      "\n",
      "Fold: 8  Epoch: 337  Training loss = 2.6856  Validation loss = 7.8266  \n",
      "\n",
      "Fold: 8  Epoch: 338  Training loss = 2.6853  Validation loss = 7.8263  \n",
      "\n",
      "Fold: 8  Epoch: 339  Training loss = 2.6851  Validation loss = 7.8260  \n",
      "\n",
      "Fold: 8  Epoch: 340  Training loss = 2.6850  Validation loss = 7.8258  \n",
      "\n",
      "Fold: 8  Epoch: 341  Training loss = 2.6848  Validation loss = 7.8255  \n",
      "\n",
      "Fold: 8  Epoch: 342  Training loss = 2.6846  Validation loss = 7.8252  \n",
      "\n",
      "Fold: 8  Epoch: 343  Training loss = 2.6844  Validation loss = 7.8250  \n",
      "\n",
      "Fold: 8  Epoch: 344  Training loss = 2.6842  Validation loss = 7.8247  \n",
      "\n",
      "Fold: 8  Epoch: 345  Training loss = 2.6840  Validation loss = 7.8244  \n",
      "\n",
      "Fold: 8  Epoch: 346  Training loss = 2.6838  Validation loss = 7.8241  \n",
      "\n",
      "Fold: 8  Epoch: 347  Training loss = 2.6836  Validation loss = 7.8238  \n",
      "\n",
      "Fold: 8  Epoch: 348  Training loss = 2.6834  Validation loss = 7.8235  \n",
      "\n",
      "Fold: 8  Epoch: 349  Training loss = 2.6832  Validation loss = 7.8232  \n",
      "\n",
      "Fold: 8  Epoch: 350  Training loss = 2.6830  Validation loss = 7.8230  \n",
      "\n",
      "Fold: 8  Epoch: 351  Training loss = 2.6828  Validation loss = 7.8226  \n",
      "\n",
      "Fold: 8  Epoch: 352  Training loss = 2.6826  Validation loss = 7.8224  \n",
      "\n",
      "Fold: 8  Epoch: 353  Training loss = 2.6824  Validation loss = 7.8221  \n",
      "\n",
      "Fold: 8  Epoch: 354  Training loss = 2.6822  Validation loss = 7.8218  \n",
      "\n",
      "Fold: 8  Epoch: 355  Training loss = 2.6820  Validation loss = 7.8215  \n",
      "\n",
      "Fold: 8  Epoch: 356  Training loss = 2.6819  Validation loss = 7.8213  \n",
      "\n",
      "Fold: 8  Epoch: 357  Training loss = 2.6816  Validation loss = 7.8210  \n",
      "\n",
      "Fold: 8  Epoch: 358  Training loss = 2.6814  Validation loss = 7.8207  \n",
      "\n",
      "Fold: 8  Epoch: 359  Training loss = 2.6812  Validation loss = 7.8204  \n",
      "\n",
      "Fold: 8  Epoch: 360  Training loss = 2.6810  Validation loss = 7.8201  \n",
      "\n",
      "Fold: 8  Epoch: 361  Training loss = 2.6808  Validation loss = 7.8198  \n",
      "\n",
      "Fold: 8  Epoch: 362  Training loss = 2.6806  Validation loss = 7.8195  \n",
      "\n",
      "Fold: 8  Epoch: 363  Training loss = 2.6804  Validation loss = 7.8192  \n",
      "\n",
      "Fold: 8  Epoch: 364  Training loss = 2.6802  Validation loss = 7.8189  \n",
      "\n",
      "Fold: 8  Epoch: 365  Training loss = 2.6800  Validation loss = 7.8187  \n",
      "\n",
      "Fold: 8  Epoch: 366  Training loss = 2.6798  Validation loss = 7.8184  \n",
      "\n",
      "Fold: 8  Epoch: 367  Training loss = 2.6796  Validation loss = 7.8182  \n",
      "\n",
      "Fold: 8  Epoch: 368  Training loss = 2.6795  Validation loss = 7.8180  \n",
      "\n",
      "Fold: 8  Epoch: 369  Training loss = 2.6793  Validation loss = 7.8177  \n",
      "\n",
      "Fold: 8  Epoch: 370  Training loss = 2.6791  Validation loss = 7.8174  \n",
      "\n",
      "Fold: 8  Epoch: 371  Training loss = 2.6789  Validation loss = 7.8172  \n",
      "\n",
      "Fold: 8  Epoch: 372  Training loss = 2.6787  Validation loss = 7.8169  \n",
      "\n",
      "Fold: 8  Epoch: 373  Training loss = 2.6785  Validation loss = 7.8166  \n",
      "\n",
      "Fold: 8  Epoch: 374  Training loss = 2.6784  Validation loss = 7.8164  \n",
      "\n",
      "Fold: 8  Epoch: 375  Training loss = 2.6781  Validation loss = 7.8161  \n",
      "\n",
      "Fold: 8  Epoch: 376  Training loss = 2.6779  Validation loss = 7.8158  \n",
      "\n",
      "Fold: 8  Epoch: 377  Training loss = 2.6777  Validation loss = 7.8155  \n",
      "\n",
      "Fold: 8  Epoch: 378  Training loss = 2.6775  Validation loss = 7.8152  \n",
      "\n",
      "Fold: 8  Epoch: 379  Training loss = 2.6774  Validation loss = 7.8150  \n",
      "\n",
      "Fold: 8  Epoch: 380  Training loss = 2.6772  Validation loss = 7.8147  \n",
      "\n",
      "Fold: 8  Epoch: 381  Training loss = 2.6770  Validation loss = 7.8145  \n",
      "\n",
      "Fold: 8  Epoch: 382  Training loss = 2.6768  Validation loss = 7.8141  \n",
      "\n",
      "Fold: 8  Epoch: 383  Training loss = 2.6766  Validation loss = 7.8139  \n",
      "\n",
      "Fold: 8  Epoch: 384  Training loss = 2.6765  Validation loss = 7.8136  \n",
      "\n",
      "Fold: 8  Epoch: 385  Training loss = 2.6763  Validation loss = 7.8134  \n",
      "\n",
      "Fold: 8  Epoch: 386  Training loss = 2.6761  Validation loss = 7.8131  \n",
      "\n",
      "Fold: 8  Epoch: 387  Training loss = 2.6760  Validation loss = 7.8129  \n",
      "\n",
      "Fold: 8  Epoch: 388  Training loss = 2.6758  Validation loss = 7.8126  \n",
      "\n",
      "Fold: 8  Epoch: 389  Training loss = 2.6756  Validation loss = 7.8124  \n",
      "\n",
      "Fold: 8  Epoch: 390  Training loss = 2.6754  Validation loss = 7.8121  \n",
      "\n",
      "Fold: 8  Epoch: 391  Training loss = 2.6752  Validation loss = 7.8118  \n",
      "\n",
      "Fold: 8  Epoch: 392  Training loss = 2.6750  Validation loss = 7.8116  \n",
      "\n",
      "Fold: 8  Epoch: 393  Training loss = 2.6748  Validation loss = 7.8113  \n",
      "\n",
      "Fold: 8  Epoch: 394  Training loss = 2.6747  Validation loss = 7.8110  \n",
      "\n",
      "Fold: 8  Epoch: 395  Training loss = 2.6745  Validation loss = 7.8108  \n",
      "\n",
      "Fold: 8  Epoch: 396  Training loss = 2.6743  Validation loss = 7.8105  \n",
      "\n",
      "Fold: 8  Epoch: 397  Training loss = 2.6741  Validation loss = 7.8103  \n",
      "\n",
      "Fold: 8  Epoch: 398  Training loss = 2.6739  Validation loss = 7.8100  \n",
      "\n",
      "Fold: 8  Epoch: 399  Training loss = 2.6738  Validation loss = 7.8098  \n",
      "\n",
      "Fold: 8  Epoch: 400  Training loss = 2.6736  Validation loss = 7.8095  \n",
      "\n",
      "Fold: 8  Epoch: 401  Training loss = 2.6734  Validation loss = 7.8093  \n",
      "\n",
      "Fold: 8  Epoch: 402  Training loss = 2.6732  Validation loss = 7.8090  \n",
      "\n",
      "Fold: 8  Epoch: 403  Training loss = 2.6730  Validation loss = 7.8087  \n",
      "\n",
      "Fold: 8  Epoch: 404  Training loss = 2.6729  Validation loss = 7.8085  \n",
      "\n",
      "Fold: 8  Epoch: 405  Training loss = 2.6727  Validation loss = 7.8082  \n",
      "\n",
      "Fold: 8  Epoch: 406  Training loss = 2.6725  Validation loss = 7.8079  \n",
      "\n",
      "Fold: 8  Epoch: 407  Training loss = 2.6722  Validation loss = 7.8076  \n",
      "\n",
      "Fold: 8  Epoch: 408  Training loss = 2.6721  Validation loss = 7.8074  \n",
      "\n",
      "Fold: 8  Epoch: 409  Training loss = 2.6719  Validation loss = 7.8071  \n",
      "\n",
      "Fold: 8  Epoch: 410  Training loss = 2.6717  Validation loss = 7.8069  \n",
      "\n",
      "Fold: 8  Epoch: 411  Training loss = 2.6715  Validation loss = 7.8066  \n",
      "\n",
      "Fold: 8  Epoch: 412  Training loss = 2.6713  Validation loss = 7.8063  \n",
      "\n",
      "Fold: 8  Epoch: 413  Training loss = 2.6711  Validation loss = 7.8060  \n",
      "\n",
      "Fold: 8  Epoch: 414  Training loss = 2.6709  Validation loss = 7.8058  \n",
      "\n",
      "Fold: 8  Epoch: 415  Training loss = 2.6708  Validation loss = 7.8055  \n",
      "\n",
      "Fold: 8  Epoch: 416  Training loss = 2.6706  Validation loss = 7.8053  \n",
      "\n",
      "Fold: 8  Epoch: 417  Training loss = 2.6704  Validation loss = 7.8050  \n",
      "\n",
      "Fold: 8  Epoch: 418  Training loss = 2.6703  Validation loss = 7.8048  \n",
      "\n",
      "Fold: 8  Epoch: 419  Training loss = 2.6701  Validation loss = 7.8046  \n",
      "\n",
      "Fold: 8  Epoch: 420  Training loss = 2.6699  Validation loss = 7.8043  \n",
      "\n",
      "Fold: 8  Epoch: 421  Training loss = 2.6697  Validation loss = 7.8040  \n",
      "\n",
      "Fold: 8  Epoch: 422  Training loss = 2.6695  Validation loss = 7.8037  \n",
      "\n",
      "Fold: 8  Epoch: 423  Training loss = 2.6693  Validation loss = 7.8034  \n",
      "\n",
      "Fold: 8  Epoch: 424  Training loss = 2.6691  Validation loss = 7.8032  \n",
      "\n",
      "Fold: 8  Epoch: 425  Training loss = 2.6689  Validation loss = 7.8029  \n",
      "\n",
      "Fold: 8  Epoch: 426  Training loss = 2.6687  Validation loss = 7.8026  \n",
      "\n",
      "Fold: 8  Epoch: 427  Training loss = 2.6686  Validation loss = 7.8024  \n",
      "\n",
      "Fold: 8  Epoch: 428  Training loss = 2.6684  Validation loss = 7.8022  \n",
      "\n",
      "Fold: 8  Epoch: 429  Training loss = 2.6682  Validation loss = 7.8019  \n",
      "\n",
      "Fold: 8  Epoch: 430  Training loss = 2.6680  Validation loss = 7.8015  \n",
      "\n",
      "Fold: 8  Epoch: 431  Training loss = 2.6678  Validation loss = 7.8013  \n",
      "\n",
      "Fold: 8  Epoch: 432  Training loss = 2.6676  Validation loss = 7.8011  \n",
      "\n",
      "Fold: 8  Epoch: 433  Training loss = 2.6674  Validation loss = 7.8008  \n",
      "\n",
      "Fold: 8  Epoch: 434  Training loss = 2.6673  Validation loss = 7.8005  \n",
      "\n",
      "Fold: 8  Epoch: 435  Training loss = 2.6671  Validation loss = 7.8003  \n",
      "\n",
      "Fold: 8  Epoch: 436  Training loss = 2.6669  Validation loss = 7.8001  \n",
      "\n",
      "Fold: 8  Epoch: 437  Training loss = 2.6667  Validation loss = 7.7998  \n",
      "\n",
      "Fold: 8  Epoch: 438  Training loss = 2.6665  Validation loss = 7.7995  \n",
      "\n",
      "Fold: 8  Epoch: 439  Training loss = 2.6663  Validation loss = 7.7992  \n",
      "\n",
      "Fold: 8  Epoch: 440  Training loss = 2.6662  Validation loss = 7.7990  \n",
      "\n",
      "Fold: 8  Epoch: 441  Training loss = 2.6660  Validation loss = 7.7988  \n",
      "\n",
      "Fold: 8  Epoch: 442  Training loss = 2.6658  Validation loss = 7.7985  \n",
      "\n",
      "Fold: 8  Epoch: 443  Training loss = 2.6656  Validation loss = 7.7982  \n",
      "\n",
      "Fold: 8  Epoch: 444  Training loss = 2.6654  Validation loss = 7.7979  \n",
      "\n",
      "Fold: 8  Epoch: 445  Training loss = 2.6652  Validation loss = 7.7977  \n",
      "\n",
      "Fold: 8  Epoch: 446  Training loss = 2.6650  Validation loss = 7.7974  \n",
      "\n",
      "Fold: 8  Epoch: 447  Training loss = 2.6649  Validation loss = 7.7971  \n",
      "\n",
      "Fold: 8  Epoch: 448  Training loss = 2.6647  Validation loss = 7.7969  \n",
      "\n",
      "Fold: 8  Epoch: 449  Training loss = 2.6646  Validation loss = 7.7967  \n",
      "\n",
      "Fold: 8  Epoch: 450  Training loss = 2.6644  Validation loss = 7.7964  \n",
      "\n",
      "Fold: 8  Epoch: 451  Training loss = 2.6642  Validation loss = 7.7961  \n",
      "\n",
      "Fold: 8  Epoch: 452  Training loss = 2.6640  Validation loss = 7.7959  \n",
      "\n",
      "Fold: 8  Epoch: 453  Training loss = 2.6638  Validation loss = 7.7956  \n",
      "\n",
      "Fold: 8  Epoch: 454  Training loss = 2.6635  Validation loss = 7.7953  \n",
      "\n",
      "Fold: 8  Epoch: 455  Training loss = 2.6634  Validation loss = 7.7950  \n",
      "\n",
      "Fold: 8  Epoch: 456  Training loss = 2.6632  Validation loss = 7.7947  \n",
      "\n",
      "Fold: 8  Epoch: 457  Training loss = 2.6630  Validation loss = 7.7944  \n",
      "\n",
      "Fold: 8  Epoch: 458  Training loss = 2.6628  Validation loss = 7.7942  \n",
      "\n",
      "Fold: 8  Epoch: 459  Training loss = 2.6626  Validation loss = 7.7939  \n",
      "\n",
      "Fold: 8  Epoch: 460  Training loss = 2.6624  Validation loss = 7.7937  \n",
      "\n",
      "Fold: 8  Epoch: 461  Training loss = 2.6622  Validation loss = 7.7934  \n",
      "\n",
      "Fold: 8  Epoch: 462  Training loss = 2.6621  Validation loss = 7.7932  \n",
      "\n",
      "Fold: 8  Epoch: 463  Training loss = 2.6619  Validation loss = 7.7929  \n",
      "\n",
      "Fold: 8  Epoch: 464  Training loss = 2.6617  Validation loss = 7.7927  \n",
      "\n",
      "Fold: 8  Epoch: 465  Training loss = 2.6615  Validation loss = 7.7924  \n",
      "\n",
      "Fold: 8  Epoch: 466  Training loss = 2.6613  Validation loss = 7.7921  \n",
      "\n",
      "Fold: 8  Epoch: 467  Training loss = 2.6612  Validation loss = 7.7919  \n",
      "\n",
      "Fold: 8  Epoch: 468  Training loss = 2.6610  Validation loss = 7.7916  \n",
      "\n",
      "Fold: 8  Epoch: 469  Training loss = 2.6608  Validation loss = 7.7914  \n",
      "\n",
      "Fold: 8  Epoch: 470  Training loss = 2.6606  Validation loss = 7.7911  \n",
      "\n",
      "Fold: 8  Epoch: 471  Training loss = 2.6604  Validation loss = 7.7908  \n",
      "\n",
      "Fold: 8  Epoch: 472  Training loss = 2.6602  Validation loss = 7.7906  \n",
      "\n",
      "Fold: 8  Epoch: 473  Training loss = 2.6601  Validation loss = 7.7904  \n",
      "\n",
      "Fold: 8  Epoch: 474  Training loss = 2.6599  Validation loss = 7.7901  \n",
      "\n",
      "Fold: 8  Epoch: 475  Training loss = 2.6597  Validation loss = 7.7899  \n",
      "\n",
      "Fold: 8  Epoch: 476  Training loss = 2.6595  Validation loss = 7.7896  \n",
      "\n",
      "Fold: 8  Epoch: 477  Training loss = 2.6594  Validation loss = 7.7893  \n",
      "\n",
      "Fold: 8  Epoch: 478  Training loss = 2.6591  Validation loss = 7.7890  \n",
      "\n",
      "Fold: 8  Epoch: 479  Training loss = 2.6589  Validation loss = 7.7887  \n",
      "\n",
      "Fold: 8  Epoch: 480  Training loss = 2.6587  Validation loss = 7.7884  \n",
      "\n",
      "Fold: 8  Epoch: 481  Training loss = 2.6586  Validation loss = 7.7882  \n",
      "\n",
      "Fold: 8  Epoch: 482  Training loss = 2.6584  Validation loss = 7.7879  \n",
      "\n",
      "Fold: 8  Epoch: 483  Training loss = 2.6582  Validation loss = 7.7876  \n",
      "\n",
      "Fold: 8  Epoch: 484  Training loss = 2.6580  Validation loss = 7.7874  \n",
      "\n",
      "Fold: 8  Epoch: 485  Training loss = 2.6578  Validation loss = 7.7872  \n",
      "\n",
      "Fold: 8  Epoch: 486  Training loss = 2.6577  Validation loss = 7.7870  \n",
      "\n",
      "Fold: 8  Epoch: 487  Training loss = 2.6575  Validation loss = 7.7867  \n",
      "\n",
      "Fold: 8  Epoch: 488  Training loss = 2.6573  Validation loss = 7.7864  \n",
      "\n",
      "Fold: 8  Epoch: 489  Training loss = 2.6571  Validation loss = 7.7861  \n",
      "\n",
      "Fold: 8  Epoch: 490  Training loss = 2.6569  Validation loss = 7.7859  \n",
      "\n",
      "Fold: 8  Epoch: 491  Training loss = 2.6568  Validation loss = 7.7857  \n",
      "\n",
      "Fold: 8  Epoch: 492  Training loss = 2.6566  Validation loss = 7.7854  \n",
      "\n",
      "Fold: 8  Epoch: 493  Training loss = 2.6564  Validation loss = 7.7851  \n",
      "\n",
      "Fold: 8  Epoch: 494  Training loss = 2.6562  Validation loss = 7.7848  \n",
      "\n",
      "Fold: 8  Epoch: 495  Training loss = 2.6560  Validation loss = 7.7846  \n",
      "\n",
      "Fold: 8  Epoch: 496  Training loss = 2.6558  Validation loss = 7.7843  \n",
      "\n",
      "Fold: 8  Epoch: 497  Training loss = 2.6556  Validation loss = 7.7841  \n",
      "\n",
      "Fold: 8  Epoch: 498  Training loss = 2.6555  Validation loss = 7.7838  \n",
      "\n",
      "Fold: 8  Epoch: 499  Training loss = 2.6553  Validation loss = 7.7836  \n",
      "\n",
      "Fold: 8  Epoch: 500  Training loss = 2.6551  Validation loss = 7.7833  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 500  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 3.2134  Validation loss = 11.3780  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 3.2131  Validation loss = 11.3776  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 3.2129  Validation loss = 11.3772  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 3.2127  Validation loss = 11.3769  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 3.2125  Validation loss = 11.3766  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 3.2122  Validation loss = 11.3763  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 3.2120  Validation loss = 11.3759  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 3.2118  Validation loss = 11.3756  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 3.2116  Validation loss = 11.3753  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 3.2114  Validation loss = 11.3750  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 3.2112  Validation loss = 11.3748  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 3.2110  Validation loss = 11.3745  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 3.2108  Validation loss = 11.3741  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 3.2106  Validation loss = 11.3739  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 3.2104  Validation loss = 11.3735  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 3.2102  Validation loss = 11.3732  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 3.2100  Validation loss = 11.3730  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 3.2098  Validation loss = 11.3727  \n",
      "\n",
      "Fold: 9  Epoch: 19  Training loss = 3.2096  Validation loss = 11.3724  \n",
      "\n",
      "Fold: 9  Epoch: 20  Training loss = 3.2094  Validation loss = 11.3722  \n",
      "\n",
      "Fold: 9  Epoch: 21  Training loss = 3.2092  Validation loss = 11.3719  \n",
      "\n",
      "Fold: 9  Epoch: 22  Training loss = 3.2090  Validation loss = 11.3716  \n",
      "\n",
      "Fold: 9  Epoch: 23  Training loss = 3.2088  Validation loss = 11.3713  \n",
      "\n",
      "Fold: 9  Epoch: 24  Training loss = 3.2086  Validation loss = 11.3710  \n",
      "\n",
      "Fold: 9  Epoch: 25  Training loss = 3.2084  Validation loss = 11.3707  \n",
      "\n",
      "Fold: 9  Epoch: 26  Training loss = 3.2082  Validation loss = 11.3704  \n",
      "\n",
      "Fold: 9  Epoch: 27  Training loss = 3.2080  Validation loss = 11.3701  \n",
      "\n",
      "Fold: 9  Epoch: 28  Training loss = 3.2078  Validation loss = 11.3698  \n",
      "\n",
      "Fold: 9  Epoch: 29  Training loss = 3.2075  Validation loss = 11.3694  \n",
      "\n",
      "Fold: 9  Epoch: 30  Training loss = 3.2072  Validation loss = 11.3690  \n",
      "\n",
      "Fold: 9  Epoch: 31  Training loss = 3.2071  Validation loss = 11.3687  \n",
      "\n",
      "Fold: 9  Epoch: 32  Training loss = 3.2069  Validation loss = 11.3685  \n",
      "\n",
      "Fold: 9  Epoch: 33  Training loss = 3.2067  Validation loss = 11.3682  \n",
      "\n",
      "Fold: 9  Epoch: 34  Training loss = 3.2065  Validation loss = 11.3679  \n",
      "\n",
      "Fold: 9  Epoch: 35  Training loss = 3.2063  Validation loss = 11.3676  \n",
      "\n",
      "Fold: 9  Epoch: 36  Training loss = 3.2061  Validation loss = 11.3674  \n",
      "\n",
      "Fold: 9  Epoch: 37  Training loss = 3.2059  Validation loss = 11.3670  \n",
      "\n",
      "Fold: 9  Epoch: 38  Training loss = 3.2057  Validation loss = 11.3668  \n",
      "\n",
      "Fold: 9  Epoch: 39  Training loss = 3.2055  Validation loss = 11.3665  \n",
      "\n",
      "Fold: 9  Epoch: 40  Training loss = 3.2053  Validation loss = 11.3662  \n",
      "\n",
      "Fold: 9  Epoch: 41  Training loss = 3.2051  Validation loss = 11.3659  \n",
      "\n",
      "Fold: 9  Epoch: 42  Training loss = 3.2049  Validation loss = 11.3656  \n",
      "\n",
      "Fold: 9  Epoch: 43  Training loss = 3.2047  Validation loss = 11.3653  \n",
      "\n",
      "Fold: 9  Epoch: 44  Training loss = 3.2045  Validation loss = 11.3650  \n",
      "\n",
      "Fold: 9  Epoch: 45  Training loss = 3.2042  Validation loss = 11.3646  \n",
      "\n",
      "Fold: 9  Epoch: 46  Training loss = 3.2040  Validation loss = 11.3643  \n",
      "\n",
      "Fold: 9  Epoch: 47  Training loss = 3.2038  Validation loss = 11.3640  \n",
      "\n",
      "Fold: 9  Epoch: 48  Training loss = 3.2036  Validation loss = 11.3637  \n",
      "\n",
      "Fold: 9  Epoch: 49  Training loss = 3.2034  Validation loss = 11.3634  \n",
      "\n",
      "Fold: 9  Epoch: 50  Training loss = 3.2031  Validation loss = 11.3630  \n",
      "\n",
      "Fold: 9  Epoch: 51  Training loss = 3.2029  Validation loss = 11.3627  \n",
      "\n",
      "Fold: 9  Epoch: 52  Training loss = 3.2027  Validation loss = 11.3623  \n",
      "\n",
      "Fold: 9  Epoch: 53  Training loss = 3.2024  Validation loss = 11.3619  \n",
      "\n",
      "Fold: 9  Epoch: 54  Training loss = 3.2021  Validation loss = 11.3615  \n",
      "\n",
      "Fold: 9  Epoch: 55  Training loss = 3.2018  Validation loss = 11.3611  \n",
      "\n",
      "Fold: 9  Epoch: 56  Training loss = 3.2016  Validation loss = 11.3608  \n",
      "\n",
      "Fold: 9  Epoch: 57  Training loss = 3.2014  Validation loss = 11.3604  \n",
      "\n",
      "Fold: 9  Epoch: 58  Training loss = 3.2012  Validation loss = 11.3601  \n",
      "\n",
      "Fold: 9  Epoch: 59  Training loss = 3.2010  Validation loss = 11.3599  \n",
      "\n",
      "Fold: 9  Epoch: 60  Training loss = 3.2007  Validation loss = 11.3595  \n",
      "\n",
      "Fold: 9  Epoch: 61  Training loss = 3.2005  Validation loss = 11.3592  \n",
      "\n",
      "Fold: 9  Epoch: 62  Training loss = 3.2003  Validation loss = 11.3588  \n",
      "\n",
      "Fold: 9  Epoch: 63  Training loss = 3.2001  Validation loss = 11.3586  \n",
      "\n",
      "Fold: 9  Epoch: 64  Training loss = 3.1999  Validation loss = 11.3583  \n",
      "\n",
      "Fold: 9  Epoch: 65  Training loss = 3.1997  Validation loss = 11.3580  \n",
      "\n",
      "Fold: 9  Epoch: 66  Training loss = 3.1995  Validation loss = 11.3576  \n",
      "\n",
      "Fold: 9  Epoch: 67  Training loss = 3.1992  Validation loss = 11.3573  \n",
      "\n",
      "Fold: 9  Epoch: 68  Training loss = 3.1990  Validation loss = 11.3569  \n",
      "\n",
      "Fold: 9  Epoch: 69  Training loss = 3.1987  Validation loss = 11.3565  \n",
      "\n",
      "Fold: 9  Epoch: 70  Training loss = 3.1985  Validation loss = 11.3562  \n",
      "\n",
      "Fold: 9  Epoch: 71  Training loss = 3.1983  Validation loss = 11.3559  \n",
      "\n",
      "Fold: 9  Epoch: 72  Training loss = 3.1980  Validation loss = 11.3556  \n",
      "\n",
      "Fold: 9  Epoch: 73  Training loss = 3.1979  Validation loss = 11.3554  \n",
      "\n",
      "Fold: 9  Epoch: 74  Training loss = 3.1977  Validation loss = 11.3550  \n",
      "\n",
      "Fold: 9  Epoch: 75  Training loss = 3.1974  Validation loss = 11.3545  \n",
      "\n",
      "Fold: 9  Epoch: 76  Training loss = 3.1971  Validation loss = 11.3541  \n",
      "\n",
      "Fold: 9  Epoch: 77  Training loss = 3.1969  Validation loss = 11.3539  \n",
      "\n",
      "Fold: 9  Epoch: 78  Training loss = 3.1968  Validation loss = 11.3536  \n",
      "\n",
      "Fold: 9  Epoch: 79  Training loss = 3.1966  Validation loss = 11.3533  \n",
      "\n",
      "Fold: 9  Epoch: 80  Training loss = 3.1964  Validation loss = 11.3530  \n",
      "\n",
      "Fold: 9  Epoch: 81  Training loss = 3.1961  Validation loss = 11.3527  \n",
      "\n",
      "Fold: 9  Epoch: 82  Training loss = 3.1959  Validation loss = 11.3524  \n",
      "\n",
      "Fold: 9  Epoch: 83  Training loss = 3.1957  Validation loss = 11.3521  \n",
      "\n",
      "Fold: 9  Epoch: 84  Training loss = 3.1955  Validation loss = 11.3518  \n",
      "\n",
      "Fold: 9  Epoch: 85  Training loss = 3.1953  Validation loss = 11.3514  \n",
      "\n",
      "Fold: 9  Epoch: 86  Training loss = 3.1951  Validation loss = 11.3511  \n",
      "\n",
      "Fold: 9  Epoch: 87  Training loss = 3.1949  Validation loss = 11.3508  \n",
      "\n",
      "Fold: 9  Epoch: 88  Training loss = 3.1947  Validation loss = 11.3505  \n",
      "\n",
      "Fold: 9  Epoch: 89  Training loss = 3.1944  Validation loss = 11.3501  \n",
      "\n",
      "Fold: 9  Epoch: 90  Training loss = 3.1942  Validation loss = 11.3498  \n",
      "\n",
      "Fold: 9  Epoch: 91  Training loss = 3.1941  Validation loss = 11.3496  \n",
      "\n",
      "Fold: 9  Epoch: 92  Training loss = 3.1938  Validation loss = 11.3492  \n",
      "\n",
      "Fold: 9  Epoch: 93  Training loss = 3.1936  Validation loss = 11.3488  \n",
      "\n",
      "Fold: 9  Epoch: 94  Training loss = 3.1934  Validation loss = 11.3485  \n",
      "\n",
      "Fold: 9  Epoch: 95  Training loss = 3.1932  Validation loss = 11.3483  \n",
      "\n",
      "Fold: 9  Epoch: 96  Training loss = 3.1930  Validation loss = 11.3479  \n",
      "\n",
      "Fold: 9  Epoch: 97  Training loss = 3.1928  Validation loss = 11.3475  \n",
      "\n",
      "Fold: 9  Epoch: 98  Training loss = 3.1926  Validation loss = 11.3473  \n",
      "\n",
      "Fold: 9  Epoch: 99  Training loss = 3.1924  Validation loss = 11.3469  \n",
      "\n",
      "Fold: 9  Epoch: 100  Training loss = 3.1922  Validation loss = 11.3466  \n",
      "\n",
      "Fold: 9  Epoch: 101  Training loss = 3.1919  Validation loss = 11.3463  \n",
      "\n",
      "Fold: 9  Epoch: 102  Training loss = 3.1917  Validation loss = 11.3459  \n",
      "\n",
      "Fold: 9  Epoch: 103  Training loss = 3.1915  Validation loss = 11.3456  \n",
      "\n",
      "Fold: 9  Epoch: 104  Training loss = 3.1914  Validation loss = 11.3453  \n",
      "\n",
      "Fold: 9  Epoch: 105  Training loss = 3.1912  Validation loss = 11.3451  \n",
      "\n",
      "Fold: 9  Epoch: 106  Training loss = 3.1909  Validation loss = 11.3447  \n",
      "\n",
      "Fold: 9  Epoch: 107  Training loss = 3.1907  Validation loss = 11.3444  \n",
      "\n",
      "Fold: 9  Epoch: 108  Training loss = 3.1905  Validation loss = 11.3440  \n",
      "\n",
      "Fold: 9  Epoch: 109  Training loss = 3.1903  Validation loss = 11.3437  \n",
      "\n",
      "Fold: 9  Epoch: 110  Training loss = 3.1901  Validation loss = 11.3433  \n",
      "\n",
      "Fold: 9  Epoch: 111  Training loss = 3.1898  Validation loss = 11.3430  \n",
      "\n",
      "Fold: 9  Epoch: 112  Training loss = 3.1896  Validation loss = 11.3426  \n",
      "\n",
      "Fold: 9  Epoch: 113  Training loss = 3.1894  Validation loss = 11.3423  \n",
      "\n",
      "Fold: 9  Epoch: 114  Training loss = 3.1892  Validation loss = 11.3419  \n",
      "\n",
      "Fold: 9  Epoch: 115  Training loss = 3.1890  Validation loss = 11.3416  \n",
      "\n",
      "Fold: 9  Epoch: 116  Training loss = 3.1888  Validation loss = 11.3413  \n",
      "\n",
      "Fold: 9  Epoch: 117  Training loss = 3.1886  Validation loss = 11.3410  \n",
      "\n",
      "Fold: 9  Epoch: 118  Training loss = 3.1884  Validation loss = 11.3407  \n",
      "\n",
      "Fold: 9  Epoch: 119  Training loss = 3.1882  Validation loss = 11.3403  \n",
      "\n",
      "Fold: 9  Epoch: 120  Training loss = 3.1880  Validation loss = 11.3401  \n",
      "\n",
      "Fold: 9  Epoch: 121  Training loss = 3.1878  Validation loss = 11.3397  \n",
      "\n",
      "Fold: 9  Epoch: 122  Training loss = 3.1877  Validation loss = 11.3395  \n",
      "\n",
      "Fold: 9  Epoch: 123  Training loss = 3.1875  Validation loss = 11.3393  \n",
      "\n",
      "Fold: 9  Epoch: 124  Training loss = 3.1873  Validation loss = 11.3389  \n",
      "\n",
      "Fold: 9  Epoch: 125  Training loss = 3.1871  Validation loss = 11.3386  \n",
      "\n",
      "Fold: 9  Epoch: 126  Training loss = 3.1868  Validation loss = 11.3381  \n",
      "\n",
      "Fold: 9  Epoch: 127  Training loss = 3.1866  Validation loss = 11.3377  \n",
      "\n",
      "Fold: 9  Epoch: 128  Training loss = 3.1864  Validation loss = 11.3374  \n",
      "\n",
      "Fold: 9  Epoch: 129  Training loss = 3.1862  Validation loss = 11.3371  \n",
      "\n",
      "Fold: 9  Epoch: 130  Training loss = 3.1860  Validation loss = 11.3368  \n",
      "\n",
      "Fold: 9  Epoch: 131  Training loss = 3.1858  Validation loss = 11.3364  \n",
      "\n",
      "Fold: 9  Epoch: 132  Training loss = 3.1855  Validation loss = 11.3360  \n",
      "\n",
      "Fold: 9  Epoch: 133  Training loss = 3.1854  Validation loss = 11.3357  \n",
      "\n",
      "Fold: 9  Epoch: 134  Training loss = 3.1852  Validation loss = 11.3354  \n",
      "\n",
      "Fold: 9  Epoch: 135  Training loss = 3.1849  Validation loss = 11.3349  \n",
      "\n",
      "Fold: 9  Epoch: 136  Training loss = 3.1848  Validation loss = 11.3346  \n",
      "\n",
      "Fold: 9  Epoch: 137  Training loss = 3.1846  Validation loss = 11.3342  \n",
      "\n",
      "Fold: 9  Epoch: 138  Training loss = 3.1843  Validation loss = 11.3337  \n",
      "\n",
      "Fold: 9  Epoch: 139  Training loss = 3.1841  Validation loss = 11.3334  \n",
      "\n",
      "Fold: 9  Epoch: 140  Training loss = 3.1839  Validation loss = 11.3330  \n",
      "\n",
      "Fold: 9  Epoch: 141  Training loss = 3.1838  Validation loss = 11.3328  \n",
      "\n",
      "Fold: 9  Epoch: 142  Training loss = 3.1836  Validation loss = 11.3323  \n",
      "\n",
      "Fold: 9  Epoch: 143  Training loss = 3.1833  Validation loss = 11.3319  \n",
      "\n",
      "Fold: 9  Epoch: 144  Training loss = 3.1832  Validation loss = 11.3316  \n",
      "\n",
      "Fold: 9  Epoch: 145  Training loss = 3.1830  Validation loss = 11.3313  \n",
      "\n",
      "Fold: 9  Epoch: 146  Training loss = 3.1828  Validation loss = 11.3309  \n",
      "\n",
      "Fold: 9  Epoch: 147  Training loss = 3.1827  Validation loss = 11.3306  \n",
      "\n",
      "Fold: 9  Epoch: 148  Training loss = 3.1824  Validation loss = 11.3302  \n",
      "\n",
      "Fold: 9  Epoch: 149  Training loss = 3.1823  Validation loss = 11.3299  \n",
      "\n",
      "Fold: 9  Epoch: 150  Training loss = 3.1820  Validation loss = 11.3293  \n",
      "\n",
      "Fold: 9  Epoch: 151  Training loss = 3.1818  Validation loss = 11.3288  \n",
      "\n",
      "Fold: 9  Epoch: 152  Training loss = 3.1816  Validation loss = 11.3284  \n",
      "\n",
      "Fold: 9  Epoch: 153  Training loss = 3.1814  Validation loss = 11.3280  \n",
      "\n",
      "Fold: 9  Epoch: 154  Training loss = 3.1812  Validation loss = 11.3275  \n",
      "\n",
      "Fold: 9  Epoch: 155  Training loss = 3.1810  Validation loss = 11.3270  \n",
      "\n",
      "Fold: 9  Epoch: 156  Training loss = 3.1808  Validation loss = 11.3266  \n",
      "\n",
      "Fold: 9  Epoch: 157  Training loss = 3.1806  Validation loss = 11.3262  \n",
      "\n",
      "Fold: 9  Epoch: 158  Training loss = 3.1803  Validation loss = 11.3256  \n",
      "\n",
      "Fold: 9  Epoch: 159  Training loss = 3.1801  Validation loss = 11.3251  \n",
      "\n",
      "Fold: 9  Epoch: 160  Training loss = 3.1799  Validation loss = 11.3246  \n",
      "\n",
      "Fold: 9  Epoch: 161  Training loss = 3.1797  Validation loss = 11.3243  \n",
      "\n",
      "Fold: 9  Epoch: 162  Training loss = 3.1795  Validation loss = 11.3238  \n",
      "\n",
      "Fold: 9  Epoch: 163  Training loss = 3.1793  Validation loss = 11.3234  \n",
      "\n",
      "Fold: 9  Epoch: 164  Training loss = 3.1791  Validation loss = 11.3230  \n",
      "\n",
      "Fold: 9  Epoch: 165  Training loss = 3.1789  Validation loss = 11.3223  \n",
      "\n",
      "Fold: 9  Epoch: 166  Training loss = 3.1787  Validation loss = 11.3219  \n",
      "\n",
      "Fold: 9  Epoch: 167  Training loss = 3.1785  Validation loss = 11.3214  \n",
      "\n",
      "Fold: 9  Epoch: 168  Training loss = 3.1783  Validation loss = 11.3209  \n",
      "\n",
      "Fold: 9  Epoch: 169  Training loss = 3.1780  Validation loss = 11.3204  \n",
      "\n",
      "Fold: 9  Epoch: 170  Training loss = 3.1778  Validation loss = 11.3198  \n",
      "\n",
      "Fold: 9  Epoch: 171  Training loss = 3.1776  Validation loss = 11.3193  \n",
      "\n",
      "Fold: 9  Epoch: 172  Training loss = 3.1775  Validation loss = 11.3188  \n",
      "\n",
      "Fold: 9  Epoch: 173  Training loss = 3.1772  Validation loss = 11.3183  \n",
      "\n",
      "Fold: 9  Epoch: 174  Training loss = 3.1770  Validation loss = 11.3179  \n",
      "\n",
      "Fold: 9  Epoch: 175  Training loss = 3.1768  Validation loss = 11.3173  \n",
      "\n",
      "Fold: 9  Epoch: 176  Training loss = 3.1766  Validation loss = 11.3168  \n",
      "\n",
      "Fold: 9  Epoch: 177  Training loss = 3.1764  Validation loss = 11.3163  \n",
      "\n",
      "Fold: 9  Epoch: 178  Training loss = 3.1762  Validation loss = 11.3158  \n",
      "\n",
      "Fold: 9  Epoch: 179  Training loss = 3.1760  Validation loss = 11.3153  \n",
      "\n",
      "Fold: 9  Epoch: 180  Training loss = 3.1758  Validation loss = 11.3149  \n",
      "\n",
      "Fold: 9  Epoch: 181  Training loss = 3.1756  Validation loss = 11.3144  \n",
      "\n",
      "Fold: 9  Epoch: 182  Training loss = 3.1754  Validation loss = 11.3139  \n",
      "\n",
      "Fold: 9  Epoch: 183  Training loss = 3.1752  Validation loss = 11.3132  \n",
      "\n",
      "Fold: 9  Epoch: 184  Training loss = 3.1749  Validation loss = 11.3126  \n",
      "\n",
      "Fold: 9  Epoch: 185  Training loss = 3.1746  Validation loss = 11.3117  \n",
      "\n",
      "Fold: 9  Epoch: 186  Training loss = 3.1745  Validation loss = 11.3114  \n",
      "\n",
      "Fold: 9  Epoch: 187  Training loss = 3.1742  Validation loss = 11.3109  \n",
      "\n",
      "Fold: 9  Epoch: 188  Training loss = 3.1741  Validation loss = 11.3105  \n",
      "\n",
      "Fold: 9  Epoch: 189  Training loss = 3.1738  Validation loss = 11.3099  \n",
      "\n",
      "Fold: 9  Epoch: 190  Training loss = 3.1736  Validation loss = 11.3094  \n",
      "\n",
      "Fold: 9  Epoch: 191  Training loss = 3.1733  Validation loss = 11.3087  \n",
      "\n",
      "Fold: 9  Epoch: 192  Training loss = 3.1731  Validation loss = 11.3081  \n",
      "\n",
      "Fold: 9  Epoch: 193  Training loss = 3.1729  Validation loss = 11.3077  \n",
      "\n",
      "Fold: 9  Epoch: 194  Training loss = 3.1727  Validation loss = 11.3072  \n",
      "\n",
      "Fold: 9  Epoch: 195  Training loss = 3.1725  Validation loss = 11.3068  \n",
      "\n",
      "Fold: 9  Epoch: 196  Training loss = 3.1723  Validation loss = 11.3063  \n",
      "\n",
      "Fold: 9  Epoch: 197  Training loss = 3.1721  Validation loss = 11.3059  \n",
      "\n",
      "Fold: 9  Epoch: 198  Training loss = 3.1719  Validation loss = 11.3054  \n",
      "\n",
      "Fold: 9  Epoch: 199  Training loss = 3.1717  Validation loss = 11.3049  \n",
      "\n",
      "Fold: 9  Epoch: 200  Training loss = 3.1715  Validation loss = 11.3045  \n",
      "\n",
      "Fold: 9  Epoch: 201  Training loss = 3.1714  Validation loss = 11.3042  \n",
      "\n",
      "Fold: 9  Epoch: 202  Training loss = 3.1712  Validation loss = 11.3038  \n",
      "\n",
      "Fold: 9  Epoch: 203  Training loss = 3.1710  Validation loss = 11.3035  \n",
      "\n",
      "Fold: 9  Epoch: 204  Training loss = 3.1707  Validation loss = 11.3030  \n",
      "\n",
      "Fold: 9  Epoch: 205  Training loss = 3.1705  Validation loss = 11.3026  \n",
      "\n",
      "Fold: 9  Epoch: 206  Training loss = 3.1704  Validation loss = 11.3022  \n",
      "\n",
      "Fold: 9  Epoch: 207  Training loss = 3.1701  Validation loss = 11.3016  \n",
      "\n",
      "Fold: 9  Epoch: 208  Training loss = 3.1699  Validation loss = 11.3012  \n",
      "\n",
      "Fold: 9  Epoch: 209  Training loss = 3.1696  Validation loss = 11.3007  \n",
      "\n",
      "Fold: 9  Epoch: 210  Training loss = 3.1694  Validation loss = 11.3002  \n",
      "\n",
      "Fold: 9  Epoch: 211  Training loss = 3.1692  Validation loss = 11.2998  \n",
      "\n",
      "Fold: 9  Epoch: 212  Training loss = 3.1690  Validation loss = 11.2994  \n",
      "\n",
      "Fold: 9  Epoch: 213  Training loss = 3.1688  Validation loss = 11.2991  \n",
      "\n",
      "Fold: 9  Epoch: 214  Training loss = 3.1686  Validation loss = 11.2987  \n",
      "\n",
      "Fold: 9  Epoch: 215  Training loss = 3.1684  Validation loss = 11.2983  \n",
      "\n",
      "Fold: 9  Epoch: 216  Training loss = 3.1682  Validation loss = 11.2980  \n",
      "\n",
      "Fold: 9  Epoch: 217  Training loss = 3.1680  Validation loss = 11.2976  \n",
      "\n",
      "Fold: 9  Epoch: 218  Training loss = 3.1678  Validation loss = 11.2971  \n",
      "\n",
      "Fold: 9  Epoch: 219  Training loss = 3.1676  Validation loss = 11.2968  \n",
      "\n",
      "Fold: 9  Epoch: 220  Training loss = 3.1674  Validation loss = 11.2965  \n",
      "\n",
      "Fold: 9  Epoch: 221  Training loss = 3.1672  Validation loss = 11.2961  \n",
      "\n",
      "Fold: 9  Epoch: 222  Training loss = 3.1670  Validation loss = 11.2958  \n",
      "\n",
      "Fold: 9  Epoch: 223  Training loss = 3.1667  Validation loss = 11.2953  \n",
      "\n",
      "Fold: 9  Epoch: 224  Training loss = 3.1665  Validation loss = 11.2949  \n",
      "\n",
      "Fold: 9  Epoch: 225  Training loss = 3.1663  Validation loss = 11.2946  \n",
      "\n",
      "Fold: 9  Epoch: 226  Training loss = 3.1661  Validation loss = 11.2942  \n",
      "\n",
      "Fold: 9  Epoch: 227  Training loss = 3.1659  Validation loss = 11.2939  \n",
      "\n",
      "Fold: 9  Epoch: 228  Training loss = 3.1657  Validation loss = 11.2936  \n",
      "\n",
      "Fold: 9  Epoch: 229  Training loss = 3.1655  Validation loss = 11.2932  \n",
      "\n",
      "Fold: 9  Epoch: 230  Training loss = 3.1653  Validation loss = 11.2929  \n",
      "\n",
      "Fold: 9  Epoch: 231  Training loss = 3.1651  Validation loss = 11.2926  \n",
      "\n",
      "Fold: 9  Epoch: 232  Training loss = 3.1649  Validation loss = 11.2923  \n",
      "\n",
      "Fold: 9  Epoch: 233  Training loss = 3.1646  Validation loss = 11.2919  \n",
      "\n",
      "Fold: 9  Epoch: 234  Training loss = 3.1644  Validation loss = 11.2915  \n",
      "\n",
      "Fold: 9  Epoch: 235  Training loss = 3.1642  Validation loss = 11.2912  \n",
      "\n",
      "Fold: 9  Epoch: 236  Training loss = 3.1639  Validation loss = 11.2908  \n",
      "\n",
      "Fold: 9  Epoch: 237  Training loss = 3.1637  Validation loss = 11.2905  \n",
      "\n",
      "Fold: 9  Epoch: 238  Training loss = 3.1635  Validation loss = 11.2902  \n",
      "\n",
      "Fold: 9  Epoch: 239  Training loss = 3.1634  Validation loss = 11.2899  \n",
      "\n",
      "Fold: 9  Epoch: 240  Training loss = 3.1631  Validation loss = 11.2896  \n",
      "\n",
      "Fold: 9  Epoch: 241  Training loss = 3.1629  Validation loss = 11.2893  \n",
      "\n",
      "Fold: 9  Epoch: 242  Training loss = 3.1628  Validation loss = 11.2890  \n",
      "\n",
      "Fold: 9  Epoch: 243  Training loss = 3.1625  Validation loss = 11.2886  \n",
      "\n",
      "Fold: 9  Epoch: 244  Training loss = 3.1623  Validation loss = 11.2884  \n",
      "\n",
      "Fold: 9  Epoch: 245  Training loss = 3.1622  Validation loss = 11.2882  \n",
      "\n",
      "Fold: 9  Epoch: 246  Training loss = 3.1620  Validation loss = 11.2879  \n",
      "\n",
      "Fold: 9  Epoch: 247  Training loss = 3.1618  Validation loss = 11.2876  \n",
      "\n",
      "Fold: 9  Epoch: 248  Training loss = 3.1615  Validation loss = 11.2872  \n",
      "\n",
      "Fold: 9  Epoch: 249  Training loss = 3.1614  Validation loss = 11.2870  \n",
      "\n",
      "Fold: 9  Epoch: 250  Training loss = 3.1612  Validation loss = 11.2866  \n",
      "\n",
      "Fold: 9  Epoch: 251  Training loss = 3.1609  Validation loss = 11.2863  \n",
      "\n",
      "Fold: 9  Epoch: 252  Training loss = 3.1607  Validation loss = 11.2860  \n",
      "\n",
      "Fold: 9  Epoch: 253  Training loss = 3.1605  Validation loss = 11.2856  \n",
      "\n",
      "Fold: 9  Epoch: 254  Training loss = 3.1603  Validation loss = 11.2853  \n",
      "\n",
      "Fold: 9  Epoch: 255  Training loss = 3.1601  Validation loss = 11.2851  \n",
      "\n",
      "Fold: 9  Epoch: 256  Training loss = 3.1599  Validation loss = 11.2848  \n",
      "\n",
      "Fold: 9  Epoch: 257  Training loss = 3.1597  Validation loss = 11.2845  \n",
      "\n",
      "Fold: 9  Epoch: 258  Training loss = 3.1595  Validation loss = 11.2841  \n",
      "\n",
      "Fold: 9  Epoch: 259  Training loss = 3.1592  Validation loss = 11.2838  \n",
      "\n",
      "Fold: 9  Epoch: 260  Training loss = 3.1590  Validation loss = 11.2835  \n",
      "\n",
      "Fold: 9  Epoch: 261  Training loss = 3.1589  Validation loss = 11.2832  \n",
      "\n",
      "Fold: 9  Epoch: 262  Training loss = 3.1586  Validation loss = 11.2829  \n",
      "\n",
      "Fold: 9  Epoch: 263  Training loss = 3.1585  Validation loss = 11.2827  \n",
      "\n",
      "Fold: 9  Epoch: 264  Training loss = 3.1583  Validation loss = 11.2824  \n",
      "\n",
      "Fold: 9  Epoch: 265  Training loss = 3.1581  Validation loss = 11.2821  \n",
      "\n",
      "Fold: 9  Epoch: 266  Training loss = 3.1579  Validation loss = 11.2818  \n",
      "\n",
      "Fold: 9  Epoch: 267  Training loss = 3.1576  Validation loss = 11.2815  \n",
      "\n",
      "Fold: 9  Epoch: 268  Training loss = 3.1574  Validation loss = 11.2812  \n",
      "\n",
      "Fold: 9  Epoch: 269  Training loss = 3.1572  Validation loss = 11.2809  \n",
      "\n",
      "Fold: 9  Epoch: 270  Training loss = 3.1571  Validation loss = 11.2806  \n",
      "\n",
      "Fold: 9  Epoch: 271  Training loss = 3.1569  Validation loss = 11.2804  \n",
      "\n",
      "Fold: 9  Epoch: 272  Training loss = 3.1567  Validation loss = 11.2801  \n",
      "\n",
      "Fold: 9  Epoch: 273  Training loss = 3.1565  Validation loss = 11.2798  \n",
      "\n",
      "Fold: 9  Epoch: 274  Training loss = 3.1563  Validation loss = 11.2795  \n",
      "\n",
      "Fold: 9  Epoch: 275  Training loss = 3.1561  Validation loss = 11.2792  \n",
      "\n",
      "Fold: 9  Epoch: 276  Training loss = 3.1559  Validation loss = 11.2790  \n",
      "\n",
      "Fold: 9  Epoch: 277  Training loss = 3.1558  Validation loss = 11.2788  \n",
      "\n",
      "Fold: 9  Epoch: 278  Training loss = 3.1556  Validation loss = 11.2785  \n",
      "\n",
      "Fold: 9  Epoch: 279  Training loss = 3.1553  Validation loss = 11.2782  \n",
      "\n",
      "Fold: 9  Epoch: 280  Training loss = 3.1551  Validation loss = 11.2778  \n",
      "\n",
      "Fold: 9  Epoch: 281  Training loss = 3.1549  Validation loss = 11.2776  \n",
      "\n",
      "Fold: 9  Epoch: 282  Training loss = 3.1547  Validation loss = 11.2772  \n",
      "\n",
      "Fold: 9  Epoch: 283  Training loss = 3.1545  Validation loss = 11.2770  \n",
      "\n",
      "Fold: 9  Epoch: 284  Training loss = 3.1543  Validation loss = 11.2766  \n",
      "\n",
      "Fold: 9  Epoch: 285  Training loss = 3.1541  Validation loss = 11.2763  \n",
      "\n",
      "Fold: 9  Epoch: 286  Training loss = 3.1539  Validation loss = 11.2760  \n",
      "\n",
      "Fold: 9  Epoch: 287  Training loss = 3.1536  Validation loss = 11.2756  \n",
      "\n",
      "Fold: 9  Epoch: 288  Training loss = 3.1534  Validation loss = 11.2753  \n",
      "\n",
      "Fold: 9  Epoch: 289  Training loss = 3.1531  Validation loss = 11.2749  \n",
      "\n",
      "Fold: 9  Epoch: 290  Training loss = 3.1529  Validation loss = 11.2746  \n",
      "\n",
      "Fold: 9  Epoch: 291  Training loss = 3.1527  Validation loss = 11.2743  \n",
      "\n",
      "Fold: 9  Epoch: 292  Training loss = 3.1525  Validation loss = 11.2740  \n",
      "\n",
      "Fold: 9  Epoch: 293  Training loss = 3.1522  Validation loss = 11.2736  \n",
      "\n",
      "Fold: 9  Epoch: 294  Training loss = 3.1520  Validation loss = 11.2733  \n",
      "\n",
      "Fold: 9  Epoch: 295  Training loss = 3.1518  Validation loss = 11.2730  \n",
      "\n",
      "Fold: 9  Epoch: 296  Training loss = 3.1516  Validation loss = 11.2726  \n",
      "\n",
      "Fold: 9  Epoch: 297  Training loss = 3.1513  Validation loss = 11.2723  \n",
      "\n",
      "Fold: 9  Epoch: 298  Training loss = 3.1511  Validation loss = 11.2720  \n",
      "\n",
      "Fold: 9  Epoch: 299  Training loss = 3.1509  Validation loss = 11.2717  \n",
      "\n",
      "Fold: 9  Epoch: 300  Training loss = 3.1507  Validation loss = 11.2714  \n",
      "\n",
      "Fold: 9  Epoch: 301  Training loss = 3.1505  Validation loss = 11.2712  \n",
      "\n",
      "Fold: 9  Epoch: 302  Training loss = 3.1504  Validation loss = 11.2709  \n",
      "\n",
      "Fold: 9  Epoch: 303  Training loss = 3.1502  Validation loss = 11.2706  \n",
      "\n",
      "Fold: 9  Epoch: 304  Training loss = 3.1499  Validation loss = 11.2703  \n",
      "\n",
      "Fold: 9  Epoch: 305  Training loss = 3.1497  Validation loss = 11.2700  \n",
      "\n",
      "Fold: 9  Epoch: 306  Training loss = 3.1495  Validation loss = 11.2696  \n",
      "\n",
      "Fold: 9  Epoch: 307  Training loss = 3.1492  Validation loss = 11.2693  \n",
      "\n",
      "Fold: 9  Epoch: 308  Training loss = 3.1490  Validation loss = 11.2690  \n",
      "\n",
      "Fold: 9  Epoch: 309  Training loss = 3.1489  Validation loss = 11.2688  \n",
      "\n",
      "Fold: 9  Epoch: 310  Training loss = 3.1487  Validation loss = 11.2685  \n",
      "\n",
      "Fold: 9  Epoch: 311  Training loss = 3.1486  Validation loss = 11.2683  \n",
      "\n",
      "Fold: 9  Epoch: 312  Training loss = 3.1483  Validation loss = 11.2679  \n",
      "\n",
      "Fold: 9  Epoch: 313  Training loss = 3.1481  Validation loss = 11.2676  \n",
      "\n",
      "Fold: 9  Epoch: 314  Training loss = 3.1479  Validation loss = 11.2673  \n",
      "\n",
      "Fold: 9  Epoch: 315  Training loss = 3.1477  Validation loss = 11.2671  \n",
      "\n",
      "Fold: 9  Epoch: 316  Training loss = 3.1475  Validation loss = 11.2668  \n",
      "\n",
      "Fold: 9  Epoch: 317  Training loss = 3.1473  Validation loss = 11.2664  \n",
      "\n",
      "Fold: 9  Epoch: 318  Training loss = 3.1471  Validation loss = 11.2661  \n",
      "\n",
      "Fold: 9  Epoch: 319  Training loss = 3.1469  Validation loss = 11.2659  \n",
      "\n",
      "Fold: 9  Epoch: 320  Training loss = 3.1467  Validation loss = 11.2656  \n",
      "\n",
      "Fold: 9  Epoch: 321  Training loss = 3.1465  Validation loss = 11.2653  \n",
      "\n",
      "Fold: 9  Epoch: 322  Training loss = 3.1463  Validation loss = 11.2650  \n",
      "\n",
      "Fold: 9  Epoch: 323  Training loss = 3.1461  Validation loss = 11.2646  \n",
      "\n",
      "Fold: 9  Epoch: 324  Training loss = 3.1459  Validation loss = 11.2644  \n",
      "\n",
      "Fold: 9  Epoch: 325  Training loss = 3.1456  Validation loss = 11.2640  \n",
      "\n",
      "Fold: 9  Epoch: 326  Training loss = 3.1454  Validation loss = 11.2636  \n",
      "\n",
      "Fold: 9  Epoch: 327  Training loss = 3.1452  Validation loss = 11.2633  \n",
      "\n",
      "Fold: 9  Epoch: 328  Training loss = 3.1450  Validation loss = 11.2630  \n",
      "\n",
      "Fold: 9  Epoch: 329  Training loss = 3.1448  Validation loss = 11.2627  \n",
      "\n",
      "Fold: 9  Epoch: 330  Training loss = 3.1445  Validation loss = 11.2624  \n",
      "\n",
      "Fold: 9  Epoch: 331  Training loss = 3.1443  Validation loss = 11.2620  \n",
      "\n",
      "Fold: 9  Epoch: 332  Training loss = 3.1440  Validation loss = 11.2617  \n",
      "\n",
      "Fold: 9  Epoch: 333  Training loss = 3.1439  Validation loss = 11.2614  \n",
      "\n",
      "Fold: 9  Epoch: 334  Training loss = 3.1437  Validation loss = 11.2612  \n",
      "\n",
      "Fold: 9  Epoch: 335  Training loss = 3.1435  Validation loss = 11.2610  \n",
      "\n",
      "Fold: 9  Epoch: 336  Training loss = 3.1433  Validation loss = 11.2607  \n",
      "\n",
      "Fold: 9  Epoch: 337  Training loss = 3.1432  Validation loss = 11.2604  \n",
      "\n",
      "Fold: 9  Epoch: 338  Training loss = 3.1430  Validation loss = 11.2602  \n",
      "\n",
      "Fold: 9  Epoch: 339  Training loss = 3.1428  Validation loss = 11.2599  \n",
      "\n",
      "Fold: 9  Epoch: 340  Training loss = 3.1426  Validation loss = 11.2596  \n",
      "\n",
      "Fold: 9  Epoch: 341  Training loss = 3.1424  Validation loss = 11.2593  \n",
      "\n",
      "Fold: 9  Epoch: 342  Training loss = 3.1422  Validation loss = 11.2590  \n",
      "\n",
      "Fold: 9  Epoch: 343  Training loss = 3.1420  Validation loss = 11.2587  \n",
      "\n",
      "Fold: 9  Epoch: 344  Training loss = 3.1419  Validation loss = 11.2585  \n",
      "\n",
      "Fold: 9  Epoch: 345  Training loss = 3.1417  Validation loss = 11.2582  \n",
      "\n",
      "Fold: 9  Epoch: 346  Training loss = 3.1414  Validation loss = 11.2578  \n",
      "\n",
      "Fold: 9  Epoch: 347  Training loss = 3.1412  Validation loss = 11.2575  \n",
      "\n",
      "Fold: 9  Epoch: 348  Training loss = 3.1410  Validation loss = 11.2571  \n",
      "\n",
      "Fold: 9  Epoch: 349  Training loss = 3.1408  Validation loss = 11.2568  \n",
      "\n",
      "Fold: 9  Epoch: 350  Training loss = 3.1406  Validation loss = 11.2565  \n",
      "\n",
      "Fold: 9  Epoch: 351  Training loss = 3.1404  Validation loss = 11.2562  \n",
      "\n",
      "Fold: 9  Epoch: 352  Training loss = 3.1402  Validation loss = 11.2559  \n",
      "\n",
      "Fold: 9  Epoch: 353  Training loss = 3.1400  Validation loss = 11.2555  \n",
      "\n",
      "Fold: 9  Epoch: 354  Training loss = 3.1398  Validation loss = 11.2552  \n",
      "\n",
      "Fold: 9  Epoch: 355  Training loss = 3.1396  Validation loss = 11.2549  \n",
      "\n",
      "Fold: 9  Epoch: 356  Training loss = 3.1394  Validation loss = 11.2546  \n",
      "\n",
      "Fold: 9  Epoch: 357  Training loss = 3.1392  Validation loss = 11.2543  \n",
      "\n",
      "Fold: 9  Epoch: 358  Training loss = 3.1390  Validation loss = 11.2540  \n",
      "\n",
      "Fold: 9  Epoch: 359  Training loss = 3.1388  Validation loss = 11.2537  \n",
      "\n",
      "Fold: 9  Epoch: 360  Training loss = 3.1387  Validation loss = 11.2535  \n",
      "\n",
      "Fold: 9  Epoch: 361  Training loss = 3.1385  Validation loss = 11.2532  \n",
      "\n",
      "Fold: 9  Epoch: 362  Training loss = 3.1383  Validation loss = 11.2529  \n",
      "\n",
      "Fold: 9  Epoch: 363  Training loss = 3.1381  Validation loss = 11.2526  \n",
      "\n",
      "Fold: 9  Epoch: 364  Training loss = 3.1379  Validation loss = 11.2523  \n",
      "\n",
      "Fold: 9  Epoch: 365  Training loss = 3.1377  Validation loss = 11.2520  \n",
      "\n",
      "Fold: 9  Epoch: 366  Training loss = 3.1375  Validation loss = 11.2516  \n",
      "\n",
      "Fold: 9  Epoch: 367  Training loss = 3.1372  Validation loss = 11.2513  \n",
      "\n",
      "Fold: 9  Epoch: 368  Training loss = 3.1370  Validation loss = 11.2509  \n",
      "\n",
      "Fold: 9  Epoch: 369  Training loss = 3.1368  Validation loss = 11.2506  \n",
      "\n",
      "Fold: 9  Epoch: 370  Training loss = 3.1366  Validation loss = 11.2503  \n",
      "\n",
      "Fold: 9  Epoch: 371  Training loss = 3.1364  Validation loss = 11.2499  \n",
      "\n",
      "Fold: 9  Epoch: 372  Training loss = 3.1362  Validation loss = 11.2496  \n",
      "\n",
      "Fold: 9  Epoch: 373  Training loss = 3.1360  Validation loss = 11.2493  \n",
      "\n",
      "Fold: 9  Epoch: 374  Training loss = 3.1358  Validation loss = 11.2490  \n",
      "\n",
      "Fold: 9  Epoch: 375  Training loss = 3.1356  Validation loss = 11.2487  \n",
      "\n",
      "Fold: 9  Epoch: 376  Training loss = 3.1354  Validation loss = 11.2483  \n",
      "\n",
      "Fold: 9  Epoch: 377  Training loss = 3.1352  Validation loss = 11.2480  \n",
      "\n",
      "Fold: 9  Epoch: 378  Training loss = 3.1350  Validation loss = 11.2477  \n",
      "\n",
      "Fold: 9  Epoch: 379  Training loss = 3.1348  Validation loss = 11.2472  \n",
      "\n",
      "Fold: 9  Epoch: 380  Training loss = 3.1346  Validation loss = 11.2469  \n",
      "\n",
      "Fold: 9  Epoch: 381  Training loss = 3.1344  Validation loss = 11.2466  \n",
      "\n",
      "Fold: 9  Epoch: 382  Training loss = 3.1342  Validation loss = 11.2463  \n",
      "\n",
      "Fold: 9  Epoch: 383  Training loss = 3.1339  Validation loss = 11.2459  \n",
      "\n",
      "Fold: 9  Epoch: 384  Training loss = 3.1337  Validation loss = 11.2456  \n",
      "\n",
      "Fold: 9  Epoch: 385  Training loss = 3.1336  Validation loss = 11.2454  \n",
      "\n",
      "Fold: 9  Epoch: 386  Training loss = 3.1334  Validation loss = 11.2450  \n",
      "\n",
      "Fold: 9  Epoch: 387  Training loss = 3.1332  Validation loss = 11.2447  \n",
      "\n",
      "Fold: 9  Epoch: 388  Training loss = 3.1330  Validation loss = 11.2444  \n",
      "\n",
      "Fold: 9  Epoch: 389  Training loss = 3.1328  Validation loss = 11.2441  \n",
      "\n",
      "Fold: 9  Epoch: 390  Training loss = 3.1326  Validation loss = 11.2438  \n",
      "\n",
      "Fold: 9  Epoch: 391  Training loss = 3.1324  Validation loss = 11.2435  \n",
      "\n",
      "Fold: 9  Epoch: 392  Training loss = 3.1321  Validation loss = 11.2431  \n",
      "\n",
      "Fold: 9  Epoch: 393  Training loss = 3.1320  Validation loss = 11.2429  \n",
      "\n",
      "Fold: 9  Epoch: 394  Training loss = 3.1318  Validation loss = 11.2425  \n",
      "\n",
      "Fold: 9  Epoch: 395  Training loss = 3.1316  Validation loss = 11.2423  \n",
      "\n",
      "Fold: 9  Epoch: 396  Training loss = 3.1314  Validation loss = 11.2421  \n",
      "\n",
      "Fold: 9  Epoch: 397  Training loss = 3.1312  Validation loss = 11.2417  \n",
      "\n",
      "Fold: 9  Epoch: 398  Training loss = 3.1310  Validation loss = 11.2414  \n",
      "\n",
      "Fold: 9  Epoch: 399  Training loss = 3.1309  Validation loss = 11.2412  \n",
      "\n",
      "Fold: 9  Epoch: 400  Training loss = 3.1307  Validation loss = 11.2409  \n",
      "\n",
      "Fold: 9  Epoch: 401  Training loss = 3.1305  Validation loss = 11.2406  \n",
      "\n",
      "Fold: 9  Epoch: 402  Training loss = 3.1303  Validation loss = 11.2403  \n",
      "\n",
      "Fold: 9  Epoch: 403  Training loss = 3.1301  Validation loss = 11.2400  \n",
      "\n",
      "Fold: 9  Epoch: 404  Training loss = 3.1299  Validation loss = 11.2397  \n",
      "\n",
      "Fold: 9  Epoch: 405  Training loss = 3.1297  Validation loss = 11.2394  \n",
      "\n",
      "Fold: 9  Epoch: 406  Training loss = 3.1295  Validation loss = 11.2391  \n",
      "\n",
      "Fold: 9  Epoch: 407  Training loss = 3.1293  Validation loss = 11.2387  \n",
      "\n",
      "Fold: 9  Epoch: 408  Training loss = 3.1291  Validation loss = 11.2384  \n",
      "\n",
      "Fold: 9  Epoch: 409  Training loss = 3.1289  Validation loss = 11.2381  \n",
      "\n",
      "Fold: 9  Epoch: 410  Training loss = 3.1287  Validation loss = 11.2378  \n",
      "\n",
      "Fold: 9  Epoch: 411  Training loss = 3.1285  Validation loss = 11.2376  \n",
      "\n",
      "Fold: 9  Epoch: 412  Training loss = 3.1283  Validation loss = 11.2373  \n",
      "\n",
      "Fold: 9  Epoch: 413  Training loss = 3.1282  Validation loss = 11.2371  \n",
      "\n",
      "Fold: 9  Epoch: 414  Training loss = 3.1280  Validation loss = 11.2368  \n",
      "\n",
      "Fold: 9  Epoch: 415  Training loss = 3.1277  Validation loss = 11.2364  \n",
      "\n",
      "Fold: 9  Epoch: 416  Training loss = 3.1275  Validation loss = 11.2360  \n",
      "\n",
      "Fold: 9  Epoch: 417  Training loss = 3.1273  Validation loss = 11.2358  \n",
      "\n",
      "Fold: 9  Epoch: 418  Training loss = 3.1272  Validation loss = 11.2355  \n",
      "\n",
      "Fold: 9  Epoch: 419  Training loss = 3.1269  Validation loss = 11.2352  \n",
      "\n",
      "Fold: 9  Epoch: 420  Training loss = 3.1267  Validation loss = 11.2348  \n",
      "\n",
      "Fold: 9  Epoch: 421  Training loss = 3.1265  Validation loss = 11.2346  \n",
      "\n",
      "Fold: 9  Epoch: 422  Training loss = 3.1262  Validation loss = 11.2342  \n",
      "\n",
      "Fold: 9  Epoch: 423  Training loss = 3.1261  Validation loss = 11.2339  \n",
      "\n",
      "Fold: 9  Epoch: 424  Training loss = 3.1258  Validation loss = 11.2336  \n",
      "\n",
      "Fold: 9  Epoch: 425  Training loss = 3.1256  Validation loss = 11.2332  \n",
      "\n",
      "Fold: 9  Epoch: 426  Training loss = 3.1254  Validation loss = 11.2329  \n",
      "\n",
      "Fold: 9  Epoch: 427  Training loss = 3.1252  Validation loss = 11.2327  \n",
      "\n",
      "Fold: 9  Epoch: 428  Training loss = 3.1250  Validation loss = 11.2324  \n",
      "\n",
      "Fold: 9  Epoch: 429  Training loss = 3.1249  Validation loss = 11.2322  \n",
      "\n",
      "Fold: 9  Epoch: 430  Training loss = 3.1246  Validation loss = 11.2318  \n",
      "\n",
      "Fold: 9  Epoch: 431  Training loss = 3.1244  Validation loss = 11.2315  \n",
      "\n",
      "Fold: 9  Epoch: 432  Training loss = 3.1243  Validation loss = 11.2313  \n",
      "\n",
      "Fold: 9  Epoch: 433  Training loss = 3.1241  Validation loss = 11.2310  \n",
      "\n",
      "Fold: 9  Epoch: 434  Training loss = 3.1239  Validation loss = 11.2308  \n",
      "\n",
      "Fold: 9  Epoch: 435  Training loss = 3.1237  Validation loss = 11.2305  \n",
      "\n",
      "Fold: 9  Epoch: 436  Training loss = 3.1235  Validation loss = 11.2303  \n",
      "\n",
      "Fold: 9  Epoch: 437  Training loss = 3.1233  Validation loss = 11.2299  \n",
      "\n",
      "Fold: 9  Epoch: 438  Training loss = 3.1231  Validation loss = 11.2296  \n",
      "\n",
      "Fold: 9  Epoch: 439  Training loss = 3.1229  Validation loss = 11.2293  \n",
      "\n",
      "Fold: 9  Epoch: 440  Training loss = 3.1227  Validation loss = 11.2290  \n",
      "\n",
      "Fold: 9  Epoch: 441  Training loss = 3.1225  Validation loss = 11.2288  \n",
      "\n",
      "Fold: 9  Epoch: 442  Training loss = 3.1223  Validation loss = 11.2285  \n",
      "\n",
      "Fold: 9  Epoch: 443  Training loss = 3.1221  Validation loss = 11.2282  \n",
      "\n",
      "Fold: 9  Epoch: 444  Training loss = 3.1219  Validation loss = 11.2279  \n",
      "\n",
      "Fold: 9  Epoch: 445  Training loss = 3.1217  Validation loss = 11.2275  \n",
      "\n",
      "Fold: 9  Epoch: 446  Training loss = 3.1215  Validation loss = 11.2273  \n",
      "\n",
      "Fold: 9  Epoch: 447  Training loss = 3.1213  Validation loss = 11.2270  \n",
      "\n",
      "Fold: 9  Epoch: 448  Training loss = 3.1211  Validation loss = 11.2267  \n",
      "\n",
      "Fold: 9  Epoch: 449  Training loss = 3.1209  Validation loss = 11.2263  \n",
      "\n",
      "Fold: 9  Epoch: 450  Training loss = 3.1207  Validation loss = 11.2261  \n",
      "\n",
      "Fold: 9  Epoch: 451  Training loss = 3.1205  Validation loss = 11.2257  \n",
      "\n",
      "Fold: 9  Epoch: 452  Training loss = 3.1202  Validation loss = 11.2254  \n",
      "\n",
      "Fold: 9  Epoch: 453  Training loss = 3.1200  Validation loss = 11.2251  \n",
      "\n",
      "Fold: 9  Epoch: 454  Training loss = 3.1199  Validation loss = 11.2248  \n",
      "\n",
      "Fold: 9  Epoch: 455  Training loss = 3.1197  Validation loss = 11.2245  \n",
      "\n",
      "Fold: 9  Epoch: 456  Training loss = 3.1195  Validation loss = 11.2243  \n",
      "\n",
      "Fold: 9  Epoch: 457  Training loss = 3.1194  Validation loss = 11.2241  \n",
      "\n",
      "Fold: 9  Epoch: 458  Training loss = 3.1191  Validation loss = 11.2237  \n",
      "\n",
      "Fold: 9  Epoch: 459  Training loss = 3.1189  Validation loss = 11.2233  \n",
      "\n",
      "Fold: 9  Epoch: 460  Training loss = 3.1187  Validation loss = 11.2231  \n",
      "\n",
      "Fold: 9  Epoch: 461  Training loss = 3.1185  Validation loss = 11.2228  \n",
      "\n",
      "Fold: 9  Epoch: 462  Training loss = 3.1183  Validation loss = 11.2225  \n",
      "\n",
      "Fold: 9  Epoch: 463  Training loss = 3.1181  Validation loss = 11.2222  \n",
      "\n",
      "Fold: 9  Epoch: 464  Training loss = 3.1179  Validation loss = 11.2218  \n",
      "\n",
      "Fold: 9  Epoch: 465  Training loss = 3.1177  Validation loss = 11.2217  \n",
      "\n",
      "Fold: 9  Epoch: 466  Training loss = 3.1175  Validation loss = 11.2214  \n",
      "\n",
      "Fold: 9  Epoch: 467  Training loss = 3.1173  Validation loss = 11.2210  \n",
      "\n",
      "Fold: 9  Epoch: 468  Training loss = 3.1171  Validation loss = 11.2208  \n",
      "\n",
      "Fold: 9  Epoch: 469  Training loss = 3.1170  Validation loss = 11.2205  \n",
      "\n",
      "Fold: 9  Epoch: 470  Training loss = 3.1168  Validation loss = 11.2203  \n",
      "\n",
      "Fold: 9  Epoch: 471  Training loss = 3.1166  Validation loss = 11.2199  \n",
      "\n",
      "Fold: 9  Epoch: 472  Training loss = 3.1163  Validation loss = 11.2196  \n",
      "\n",
      "Fold: 9  Epoch: 473  Training loss = 3.1162  Validation loss = 11.2193  \n",
      "\n",
      "Fold: 9  Epoch: 474  Training loss = 3.1160  Validation loss = 11.2191  \n",
      "\n",
      "Fold: 9  Epoch: 475  Training loss = 3.1157  Validation loss = 11.2187  \n",
      "\n",
      "Fold: 9  Epoch: 476  Training loss = 3.1155  Validation loss = 11.2184  \n",
      "\n",
      "Fold: 9  Epoch: 477  Training loss = 3.1153  Validation loss = 11.2181  \n",
      "\n",
      "Fold: 9  Epoch: 478  Training loss = 3.1152  Validation loss = 11.2179  \n",
      "\n",
      "Fold: 9  Epoch: 479  Training loss = 3.1150  Validation loss = 11.2176  \n",
      "\n",
      "Fold: 9  Epoch: 480  Training loss = 3.1148  Validation loss = 11.2174  \n",
      "\n",
      "Fold: 9  Epoch: 481  Training loss = 3.1146  Validation loss = 11.2171  \n",
      "\n",
      "Fold: 9  Epoch: 482  Training loss = 3.1144  Validation loss = 11.2168  \n",
      "\n",
      "Fold: 9  Epoch: 483  Training loss = 3.1142  Validation loss = 11.2165  \n",
      "\n",
      "Fold: 9  Epoch: 484  Training loss = 3.1140  Validation loss = 11.2162  \n",
      "\n",
      "Fold: 9  Epoch: 485  Training loss = 3.1138  Validation loss = 11.2159  \n",
      "\n",
      "Fold: 9  Epoch: 486  Training loss = 3.1136  Validation loss = 11.2156  \n",
      "\n",
      "Fold: 9  Epoch: 487  Training loss = 3.1134  Validation loss = 11.2153  \n",
      "\n",
      "Fold: 9  Epoch: 488  Training loss = 3.1133  Validation loss = 11.2150  \n",
      "\n",
      "Fold: 9  Epoch: 489  Training loss = 3.1131  Validation loss = 11.2147  \n",
      "\n",
      "Fold: 9  Epoch: 490  Training loss = 3.1129  Validation loss = 11.2144  \n",
      "\n",
      "Fold: 9  Epoch: 491  Training loss = 3.1126  Validation loss = 11.2141  \n",
      "\n",
      "Fold: 9  Epoch: 492  Training loss = 3.1124  Validation loss = 11.2138  \n",
      "\n",
      "Fold: 9  Epoch: 493  Training loss = 3.1122  Validation loss = 11.2135  \n",
      "\n",
      "Fold: 9  Epoch: 494  Training loss = 3.1120  Validation loss = 11.2132  \n",
      "\n",
      "Fold: 9  Epoch: 495  Training loss = 3.1118  Validation loss = 11.2128  \n",
      "\n",
      "Fold: 9  Epoch: 496  Training loss = 3.1115  Validation loss = 11.2125  \n",
      "\n",
      "Fold: 9  Epoch: 497  Training loss = 3.1113  Validation loss = 11.2122  \n",
      "\n",
      "Fold: 9  Epoch: 498  Training loss = 3.1111  Validation loss = 11.2118  \n",
      "\n",
      "Fold: 9  Epoch: 499  Training loss = 3.1109  Validation loss = 11.2115  \n",
      "\n",
      "Fold: 9  Epoch: 500  Training loss = 3.1107  Validation loss = 11.2113  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 500  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 4.1372  Validation loss = 6.6653  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 4.1370  Validation loss = 6.6649  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 4.1368  Validation loss = 6.6646  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 4.1365  Validation loss = 6.6641  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 4.1362  Validation loss = 6.6637  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 4.1360  Validation loss = 6.6634  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 4.1358  Validation loss = 6.6631  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 4.1355  Validation loss = 6.6626  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 4.1353  Validation loss = 6.6623  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 4.1351  Validation loss = 6.6619  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 4.1349  Validation loss = 6.6617  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 4.1347  Validation loss = 6.6613  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 4.1345  Validation loss = 6.6610  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 4.1341  Validation loss = 6.6604  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 4.1339  Validation loss = 6.6600  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 4.1336  Validation loss = 6.6596  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 4.1333  Validation loss = 6.6592  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 4.1331  Validation loss = 6.6588  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 4.1329  Validation loss = 6.6583  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 4.1326  Validation loss = 6.6579  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 4.1324  Validation loss = 6.6576  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 4.1322  Validation loss = 6.6573  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 4.1320  Validation loss = 6.6569  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 4.1317  Validation loss = 6.6564  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 4.1314  Validation loss = 6.6561  \n",
      "\n",
      "Fold: 10  Epoch: 26  Training loss = 4.1312  Validation loss = 6.6556  \n",
      "\n",
      "Fold: 10  Epoch: 27  Training loss = 4.1309  Validation loss = 6.6552  \n",
      "\n",
      "Fold: 10  Epoch: 28  Training loss = 4.1306  Validation loss = 6.6547  \n",
      "\n",
      "Fold: 10  Epoch: 29  Training loss = 4.1303  Validation loss = 6.6543  \n",
      "\n",
      "Fold: 10  Epoch: 30  Training loss = 4.1301  Validation loss = 6.6539  \n",
      "\n",
      "Fold: 10  Epoch: 31  Training loss = 4.1298  Validation loss = 6.6534  \n",
      "\n",
      "Fold: 10  Epoch: 32  Training loss = 4.1295  Validation loss = 6.6530  \n",
      "\n",
      "Fold: 10  Epoch: 33  Training loss = 4.1293  Validation loss = 6.6525  \n",
      "\n",
      "Fold: 10  Epoch: 34  Training loss = 4.1290  Validation loss = 6.6522  \n",
      "\n",
      "Fold: 10  Epoch: 35  Training loss = 4.1287  Validation loss = 6.6517  \n",
      "\n",
      "Fold: 10  Epoch: 36  Training loss = 4.1284  Validation loss = 6.6513  \n",
      "\n",
      "Fold: 10  Epoch: 37  Training loss = 4.1282  Validation loss = 6.6509  \n",
      "\n",
      "Fold: 10  Epoch: 38  Training loss = 4.1279  Validation loss = 6.6504  \n",
      "\n",
      "Fold: 10  Epoch: 39  Training loss = 4.1276  Validation loss = 6.6500  \n",
      "\n",
      "Fold: 10  Epoch: 40  Training loss = 4.1274  Validation loss = 6.6495  \n",
      "\n",
      "Fold: 10  Epoch: 41  Training loss = 4.1272  Validation loss = 6.6492  \n",
      "\n",
      "Fold: 10  Epoch: 42  Training loss = 4.1269  Validation loss = 6.6487  \n",
      "\n",
      "Fold: 10  Epoch: 43  Training loss = 4.1266  Validation loss = 6.6483  \n",
      "\n",
      "Fold: 10  Epoch: 44  Training loss = 4.1264  Validation loss = 6.6479  \n",
      "\n",
      "Fold: 10  Epoch: 45  Training loss = 4.1262  Validation loss = 6.6476  \n",
      "\n",
      "Fold: 10  Epoch: 46  Training loss = 4.1260  Validation loss = 6.6473  \n",
      "\n",
      "Fold: 10  Epoch: 47  Training loss = 4.1258  Validation loss = 6.6469  \n",
      "\n",
      "Fold: 10  Epoch: 48  Training loss = 4.1256  Validation loss = 6.6466  \n",
      "\n",
      "Fold: 10  Epoch: 49  Training loss = 4.1253  Validation loss = 6.6462  \n",
      "\n",
      "Fold: 10  Epoch: 50  Training loss = 4.1251  Validation loss = 6.6458  \n",
      "\n",
      "Fold: 10  Epoch: 51  Training loss = 4.1249  Validation loss = 6.6454  \n",
      "\n",
      "Fold: 10  Epoch: 52  Training loss = 4.1246  Validation loss = 6.6451  \n",
      "\n",
      "Fold: 10  Epoch: 53  Training loss = 4.1244  Validation loss = 6.6447  \n",
      "\n",
      "Fold: 10  Epoch: 54  Training loss = 4.1240  Validation loss = 6.6441  \n",
      "\n",
      "Fold: 10  Epoch: 55  Training loss = 4.1238  Validation loss = 6.6437  \n",
      "\n",
      "Fold: 10  Epoch: 56  Training loss = 4.1236  Validation loss = 6.6433  \n",
      "\n",
      "Fold: 10  Epoch: 57  Training loss = 4.1234  Validation loss = 6.6430  \n",
      "\n",
      "Fold: 10  Epoch: 58  Training loss = 4.1231  Validation loss = 6.6426  \n",
      "\n",
      "Fold: 10  Epoch: 59  Training loss = 4.1229  Validation loss = 6.6422  \n",
      "\n",
      "Fold: 10  Epoch: 60  Training loss = 4.1226  Validation loss = 6.6418  \n",
      "\n",
      "Fold: 10  Epoch: 61  Training loss = 4.1224  Validation loss = 6.6413  \n",
      "\n",
      "Fold: 10  Epoch: 62  Training loss = 4.1221  Validation loss = 6.6408  \n",
      "\n",
      "Fold: 10  Epoch: 63  Training loss = 4.1218  Validation loss = 6.6404  \n",
      "\n",
      "Fold: 10  Epoch: 64  Training loss = 4.1216  Validation loss = 6.6401  \n",
      "\n",
      "Fold: 10  Epoch: 65  Training loss = 4.1213  Validation loss = 6.6395  \n",
      "\n",
      "Fold: 10  Epoch: 66  Training loss = 4.1209  Validation loss = 6.6390  \n",
      "\n",
      "Fold: 10  Epoch: 67  Training loss = 4.1207  Validation loss = 6.6386  \n",
      "\n",
      "Fold: 10  Epoch: 68  Training loss = 4.1204  Validation loss = 6.6381  \n",
      "\n",
      "Fold: 10  Epoch: 69  Training loss = 4.1202  Validation loss = 6.6377  \n",
      "\n",
      "Fold: 10  Epoch: 70  Training loss = 4.1199  Validation loss = 6.6373  \n",
      "\n",
      "Fold: 10  Epoch: 71  Training loss = 4.1197  Validation loss = 6.6370  \n",
      "\n",
      "Fold: 10  Epoch: 72  Training loss = 4.1194  Validation loss = 6.6365  \n",
      "\n",
      "Fold: 10  Epoch: 73  Training loss = 4.1192  Validation loss = 6.6362  \n",
      "\n",
      "Fold: 10  Epoch: 74  Training loss = 4.1190  Validation loss = 6.6358  \n",
      "\n",
      "Fold: 10  Epoch: 75  Training loss = 4.1188  Validation loss = 6.6355  \n",
      "\n",
      "Fold: 10  Epoch: 76  Training loss = 4.1186  Validation loss = 6.6352  \n",
      "\n",
      "Fold: 10  Epoch: 77  Training loss = 4.1183  Validation loss = 6.6347  \n",
      "\n",
      "Fold: 10  Epoch: 78  Training loss = 4.1181  Validation loss = 6.6343  \n",
      "\n",
      "Fold: 10  Epoch: 79  Training loss = 4.1179  Validation loss = 6.6340  \n",
      "\n",
      "Fold: 10  Epoch: 80  Training loss = 4.1176  Validation loss = 6.6336  \n",
      "\n",
      "Fold: 10  Epoch: 81  Training loss = 4.1174  Validation loss = 6.6333  \n",
      "\n",
      "Fold: 10  Epoch: 82  Training loss = 4.1170  Validation loss = 6.6326  \n",
      "\n",
      "Fold: 10  Epoch: 83  Training loss = 4.1168  Validation loss = 6.6323  \n",
      "\n",
      "Fold: 10  Epoch: 84  Training loss = 4.1166  Validation loss = 6.6320  \n",
      "\n",
      "Fold: 10  Epoch: 85  Training loss = 4.1163  Validation loss = 6.6316  \n",
      "\n",
      "Fold: 10  Epoch: 86  Training loss = 4.1161  Validation loss = 6.6312  \n",
      "\n",
      "Fold: 10  Epoch: 87  Training loss = 4.1158  Validation loss = 6.6308  \n",
      "\n",
      "Fold: 10  Epoch: 88  Training loss = 4.1155  Validation loss = 6.6304  \n",
      "\n",
      "Fold: 10  Epoch: 89  Training loss = 4.1152  Validation loss = 6.6299  \n",
      "\n",
      "Fold: 10  Epoch: 90  Training loss = 4.1150  Validation loss = 6.6294  \n",
      "\n",
      "Fold: 10  Epoch: 91  Training loss = 4.1147  Validation loss = 6.6289  \n",
      "\n",
      "Fold: 10  Epoch: 92  Training loss = 4.1144  Validation loss = 6.6286  \n",
      "\n",
      "Fold: 10  Epoch: 93  Training loss = 4.1142  Validation loss = 6.6281  \n",
      "\n",
      "Fold: 10  Epoch: 94  Training loss = 4.1139  Validation loss = 6.6276  \n",
      "\n",
      "Fold: 10  Epoch: 95  Training loss = 4.1136  Validation loss = 6.6272  \n",
      "\n",
      "Fold: 10  Epoch: 96  Training loss = 4.1134  Validation loss = 6.6268  \n",
      "\n",
      "Fold: 10  Epoch: 97  Training loss = 4.1132  Validation loss = 6.6265  \n",
      "\n",
      "Fold: 10  Epoch: 98  Training loss = 4.1129  Validation loss = 6.6261  \n",
      "\n",
      "Fold: 10  Epoch: 99  Training loss = 4.1127  Validation loss = 6.6258  \n",
      "\n",
      "Fold: 10  Epoch: 100  Training loss = 4.1125  Validation loss = 6.6254  \n",
      "\n",
      "Fold: 10  Epoch: 101  Training loss = 4.1123  Validation loss = 6.6250  \n",
      "\n",
      "Fold: 10  Epoch: 102  Training loss = 4.1120  Validation loss = 6.6247  \n",
      "\n",
      "Fold: 10  Epoch: 103  Training loss = 4.1118  Validation loss = 6.6242  \n",
      "\n",
      "Fold: 10  Epoch: 104  Training loss = 4.1115  Validation loss = 6.6238  \n",
      "\n",
      "Fold: 10  Epoch: 105  Training loss = 4.1113  Validation loss = 6.6234  \n",
      "\n",
      "Fold: 10  Epoch: 106  Training loss = 4.1111  Validation loss = 6.6230  \n",
      "\n",
      "Fold: 10  Epoch: 107  Training loss = 4.1108  Validation loss = 6.6226  \n",
      "\n",
      "Fold: 10  Epoch: 108  Training loss = 4.1106  Validation loss = 6.6222  \n",
      "\n",
      "Fold: 10  Epoch: 109  Training loss = 4.1103  Validation loss = 6.6217  \n",
      "\n",
      "Fold: 10  Epoch: 110  Training loss = 4.1101  Validation loss = 6.6214  \n",
      "\n",
      "Fold: 10  Epoch: 111  Training loss = 4.1099  Validation loss = 6.6211  \n",
      "\n",
      "Fold: 10  Epoch: 112  Training loss = 4.1097  Validation loss = 6.6206  \n",
      "\n",
      "Fold: 10  Epoch: 113  Training loss = 4.1094  Validation loss = 6.6201  \n",
      "\n",
      "Fold: 10  Epoch: 114  Training loss = 4.1092  Validation loss = 6.6197  \n",
      "\n",
      "Fold: 10  Epoch: 115  Training loss = 4.1089  Validation loss = 6.6194  \n",
      "\n",
      "Fold: 10  Epoch: 116  Training loss = 4.1086  Validation loss = 6.6189  \n",
      "\n",
      "Fold: 10  Epoch: 117  Training loss = 4.1084  Validation loss = 6.6185  \n",
      "\n",
      "Fold: 10  Epoch: 118  Training loss = 4.1082  Validation loss = 6.6182  \n",
      "\n",
      "Fold: 10  Epoch: 119  Training loss = 4.1078  Validation loss = 6.6175  \n",
      "\n",
      "Fold: 10  Epoch: 120  Training loss = 4.1077  Validation loss = 6.6173  \n",
      "\n",
      "Fold: 10  Epoch: 121  Training loss = 4.1074  Validation loss = 6.6168  \n",
      "\n",
      "Fold: 10  Epoch: 122  Training loss = 4.1072  Validation loss = 6.6165  \n",
      "\n",
      "Fold: 10  Epoch: 123  Training loss = 4.1070  Validation loss = 6.6162  \n",
      "\n",
      "Fold: 10  Epoch: 124  Training loss = 4.1067  Validation loss = 6.6158  \n",
      "\n",
      "Fold: 10  Epoch: 125  Training loss = 4.1064  Validation loss = 6.6154  \n",
      "\n",
      "Fold: 10  Epoch: 126  Training loss = 4.1062  Validation loss = 6.6150  \n",
      "\n",
      "Fold: 10  Epoch: 127  Training loss = 4.1060  Validation loss = 6.6146  \n",
      "\n",
      "Fold: 10  Epoch: 128  Training loss = 4.1058  Validation loss = 6.6143  \n",
      "\n",
      "Fold: 10  Epoch: 129  Training loss = 4.1055  Validation loss = 6.6139  \n",
      "\n",
      "Fold: 10  Epoch: 130  Training loss = 4.1052  Validation loss = 6.6135  \n",
      "\n",
      "Fold: 10  Epoch: 131  Training loss = 4.1050  Validation loss = 6.6131  \n",
      "\n",
      "Fold: 10  Epoch: 132  Training loss = 4.1047  Validation loss = 6.6126  \n",
      "\n",
      "Fold: 10  Epoch: 133  Training loss = 4.1045  Validation loss = 6.6122  \n",
      "\n",
      "Fold: 10  Epoch: 134  Training loss = 4.1042  Validation loss = 6.6117  \n",
      "\n",
      "Fold: 10  Epoch: 135  Training loss = 4.1039  Validation loss = 6.6112  \n",
      "\n",
      "Fold: 10  Epoch: 136  Training loss = 4.1037  Validation loss = 6.6108  \n",
      "\n",
      "Fold: 10  Epoch: 137  Training loss = 4.1035  Validation loss = 6.6105  \n",
      "\n",
      "Fold: 10  Epoch: 138  Training loss = 4.1033  Validation loss = 6.6102  \n",
      "\n",
      "Fold: 10  Epoch: 139  Training loss = 4.1031  Validation loss = 6.6099  \n",
      "\n",
      "Fold: 10  Epoch: 140  Training loss = 4.1028  Validation loss = 6.6094  \n",
      "\n",
      "Fold: 10  Epoch: 141  Training loss = 4.1026  Validation loss = 6.6090  \n",
      "\n",
      "Fold: 10  Epoch: 142  Training loss = 4.1023  Validation loss = 6.6086  \n",
      "\n",
      "Fold: 10  Epoch: 143  Training loss = 4.1021  Validation loss = 6.6083  \n",
      "\n",
      "Fold: 10  Epoch: 144  Training loss = 4.1018  Validation loss = 6.6078  \n",
      "\n",
      "Fold: 10  Epoch: 145  Training loss = 4.1016  Validation loss = 6.6075  \n",
      "\n",
      "Fold: 10  Epoch: 146  Training loss = 4.1014  Validation loss = 6.6070  \n",
      "\n",
      "Fold: 10  Epoch: 147  Training loss = 4.1011  Validation loss = 6.6065  \n",
      "\n",
      "Fold: 10  Epoch: 148  Training loss = 4.1009  Validation loss = 6.6061  \n",
      "\n",
      "Fold: 10  Epoch: 149  Training loss = 4.1006  Validation loss = 6.6056  \n",
      "\n",
      "Fold: 10  Epoch: 150  Training loss = 4.1003  Validation loss = 6.6051  \n",
      "\n",
      "Fold: 10  Epoch: 151  Training loss = 4.1001  Validation loss = 6.6047  \n",
      "\n",
      "Fold: 10  Epoch: 152  Training loss = 4.0998  Validation loss = 6.6043  \n",
      "\n",
      "Fold: 10  Epoch: 153  Training loss = 4.0997  Validation loss = 6.6041  \n",
      "\n",
      "Fold: 10  Epoch: 154  Training loss = 4.0994  Validation loss = 6.6037  \n",
      "\n",
      "Fold: 10  Epoch: 155  Training loss = 4.0992  Validation loss = 6.6032  \n",
      "\n",
      "Fold: 10  Epoch: 156  Training loss = 4.0990  Validation loss = 6.6029  \n",
      "\n",
      "Fold: 10  Epoch: 157  Training loss = 4.0987  Validation loss = 6.6025  \n",
      "\n",
      "Fold: 10  Epoch: 158  Training loss = 4.0985  Validation loss = 6.6022  \n",
      "\n",
      "Fold: 10  Epoch: 159  Training loss = 4.0983  Validation loss = 6.6018  \n",
      "\n",
      "Fold: 10  Epoch: 160  Training loss = 4.0981  Validation loss = 6.6015  \n",
      "\n",
      "Fold: 10  Epoch: 161  Training loss = 4.0979  Validation loss = 6.6012  \n",
      "\n",
      "Fold: 10  Epoch: 162  Training loss = 4.0977  Validation loss = 6.6007  \n",
      "\n",
      "Fold: 10  Epoch: 163  Training loss = 4.0974  Validation loss = 6.6003  \n",
      "\n",
      "Fold: 10  Epoch: 164  Training loss = 4.0971  Validation loss = 6.5998  \n",
      "\n",
      "Fold: 10  Epoch: 165  Training loss = 4.0969  Validation loss = 6.5995  \n",
      "\n",
      "Fold: 10  Epoch: 166  Training loss = 4.0966  Validation loss = 6.5989  \n",
      "\n",
      "Fold: 10  Epoch: 167  Training loss = 4.0965  Validation loss = 6.5987  \n",
      "\n",
      "Fold: 10  Epoch: 168  Training loss = 4.0962  Validation loss = 6.5982  \n",
      "\n",
      "Fold: 10  Epoch: 169  Training loss = 4.0959  Validation loss = 6.5979  \n",
      "\n",
      "Fold: 10  Epoch: 170  Training loss = 4.0957  Validation loss = 6.5976  \n",
      "\n",
      "Fold: 10  Epoch: 171  Training loss = 4.0955  Validation loss = 6.5972  \n",
      "\n",
      "Fold: 10  Epoch: 172  Training loss = 4.0953  Validation loss = 6.5968  \n",
      "\n",
      "Fold: 10  Epoch: 173  Training loss = 4.0951  Validation loss = 6.5965  \n",
      "\n",
      "Fold: 10  Epoch: 174  Training loss = 4.0949  Validation loss = 6.5962  \n",
      "\n",
      "Fold: 10  Epoch: 175  Training loss = 4.0946  Validation loss = 6.5957  \n",
      "\n",
      "Fold: 10  Epoch: 176  Training loss = 4.0943  Validation loss = 6.5953  \n",
      "\n",
      "Fold: 10  Epoch: 177  Training loss = 4.0941  Validation loss = 6.5948  \n",
      "\n",
      "Fold: 10  Epoch: 178  Training loss = 4.0938  Validation loss = 6.5944  \n",
      "\n",
      "Fold: 10  Epoch: 179  Training loss = 4.0935  Validation loss = 6.5940  \n",
      "\n",
      "Fold: 10  Epoch: 180  Training loss = 4.0933  Validation loss = 6.5936  \n",
      "\n",
      "Fold: 10  Epoch: 181  Training loss = 4.0931  Validation loss = 6.5932  \n",
      "\n",
      "Fold: 10  Epoch: 182  Training loss = 4.0928  Validation loss = 6.5927  \n",
      "\n",
      "Fold: 10  Epoch: 183  Training loss = 4.0925  Validation loss = 6.5922  \n",
      "\n",
      "Fold: 10  Epoch: 184  Training loss = 4.0923  Validation loss = 6.5918  \n",
      "\n",
      "Fold: 10  Epoch: 185  Training loss = 4.0920  Validation loss = 6.5913  \n",
      "\n",
      "Fold: 10  Epoch: 186  Training loss = 4.0919  Validation loss = 6.5911  \n",
      "\n",
      "Fold: 10  Epoch: 187  Training loss = 4.0916  Validation loss = 6.5907  \n",
      "\n",
      "Fold: 10  Epoch: 188  Training loss = 4.0914  Validation loss = 6.5902  \n",
      "\n",
      "Fold: 10  Epoch: 189  Training loss = 4.0912  Validation loss = 6.5899  \n",
      "\n",
      "Fold: 10  Epoch: 190  Training loss = 4.0909  Validation loss = 6.5894  \n",
      "\n",
      "Fold: 10  Epoch: 191  Training loss = 4.0907  Validation loss = 6.5891  \n",
      "\n",
      "Fold: 10  Epoch: 192  Training loss = 4.0904  Validation loss = 6.5886  \n",
      "\n",
      "Fold: 10  Epoch: 193  Training loss = 4.0902  Validation loss = 6.5882  \n",
      "\n",
      "Fold: 10  Epoch: 194  Training loss = 4.0900  Validation loss = 6.5879  \n",
      "\n",
      "Fold: 10  Epoch: 195  Training loss = 4.0898  Validation loss = 6.5875  \n",
      "\n",
      "Fold: 10  Epoch: 196  Training loss = 4.0895  Validation loss = 6.5871  \n",
      "\n",
      "Fold: 10  Epoch: 197  Training loss = 4.0892  Validation loss = 6.5866  \n",
      "\n",
      "Fold: 10  Epoch: 198  Training loss = 4.0890  Validation loss = 6.5862  \n",
      "\n",
      "Fold: 10  Epoch: 199  Training loss = 4.0887  Validation loss = 6.5858  \n",
      "\n",
      "Fold: 10  Epoch: 200  Training loss = 4.0884  Validation loss = 6.5853  \n",
      "\n",
      "Fold: 10  Epoch: 201  Training loss = 4.0881  Validation loss = 6.5847  \n",
      "\n",
      "Fold: 10  Epoch: 202  Training loss = 4.0878  Validation loss = 6.5843  \n",
      "\n",
      "Fold: 10  Epoch: 203  Training loss = 4.0876  Validation loss = 6.5838  \n",
      "\n",
      "Fold: 10  Epoch: 204  Training loss = 4.0873  Validation loss = 6.5834  \n",
      "\n",
      "Fold: 10  Epoch: 205  Training loss = 4.0871  Validation loss = 6.5831  \n",
      "\n",
      "Fold: 10  Epoch: 206  Training loss = 4.0869  Validation loss = 6.5827  \n",
      "\n",
      "Fold: 10  Epoch: 207  Training loss = 4.0867  Validation loss = 6.5822  \n",
      "\n",
      "Fold: 10  Epoch: 208  Training loss = 4.0864  Validation loss = 6.5818  \n",
      "\n",
      "Fold: 10  Epoch: 209  Training loss = 4.0862  Validation loss = 6.5813  \n",
      "\n",
      "Fold: 10  Epoch: 210  Training loss = 4.0859  Validation loss = 6.5809  \n",
      "\n",
      "Fold: 10  Epoch: 211  Training loss = 4.0857  Validation loss = 6.5805  \n",
      "\n",
      "Fold: 10  Epoch: 212  Training loss = 4.0854  Validation loss = 6.5800  \n",
      "\n",
      "Fold: 10  Epoch: 213  Training loss = 4.0851  Validation loss = 6.5795  \n",
      "\n",
      "Fold: 10  Epoch: 214  Training loss = 4.0849  Validation loss = 6.5791  \n",
      "\n",
      "Fold: 10  Epoch: 215  Training loss = 4.0846  Validation loss = 6.5785  \n",
      "\n",
      "Fold: 10  Epoch: 216  Training loss = 4.0843  Validation loss = 6.5781  \n",
      "\n",
      "Fold: 10  Epoch: 217  Training loss = 4.0841  Validation loss = 6.5777  \n",
      "\n",
      "Fold: 10  Epoch: 218  Training loss = 4.0839  Validation loss = 6.5773  \n",
      "\n",
      "Fold: 10  Epoch: 219  Training loss = 4.0837  Validation loss = 6.5770  \n",
      "\n",
      "Fold: 10  Epoch: 220  Training loss = 4.0834  Validation loss = 6.5764  \n",
      "\n",
      "Fold: 10  Epoch: 221  Training loss = 4.0832  Validation loss = 6.5761  \n",
      "\n",
      "Fold: 10  Epoch: 222  Training loss = 4.0830  Validation loss = 6.5758  \n",
      "\n",
      "Fold: 10  Epoch: 223  Training loss = 4.0827  Validation loss = 6.5753  \n",
      "\n",
      "Fold: 10  Epoch: 224  Training loss = 4.0825  Validation loss = 6.5749  \n",
      "\n",
      "Fold: 10  Epoch: 225  Training loss = 4.0822  Validation loss = 6.5744  \n",
      "\n",
      "Fold: 10  Epoch: 226  Training loss = 4.0820  Validation loss = 6.5740  \n",
      "\n",
      "Fold: 10  Epoch: 227  Training loss = 4.0817  Validation loss = 6.5735  \n",
      "\n",
      "Fold: 10  Epoch: 228  Training loss = 4.0815  Validation loss = 6.5731  \n",
      "\n",
      "Fold: 10  Epoch: 229  Training loss = 4.0812  Validation loss = 6.5726  \n",
      "\n",
      "Fold: 10  Epoch: 230  Training loss = 4.0810  Validation loss = 6.5722  \n",
      "\n",
      "Fold: 10  Epoch: 231  Training loss = 4.0808  Validation loss = 6.5719  \n",
      "\n",
      "Fold: 10  Epoch: 232  Training loss = 4.0805  Validation loss = 6.5714  \n",
      "\n",
      "Fold: 10  Epoch: 233  Training loss = 4.0803  Validation loss = 6.5711  \n",
      "\n",
      "Fold: 10  Epoch: 234  Training loss = 4.0801  Validation loss = 6.5708  \n",
      "\n",
      "Fold: 10  Epoch: 235  Training loss = 4.0799  Validation loss = 6.5705  \n",
      "\n",
      "Fold: 10  Epoch: 236  Training loss = 4.0796  Validation loss = 6.5700  \n",
      "\n",
      "Fold: 10  Epoch: 237  Training loss = 4.0794  Validation loss = 6.5695  \n",
      "\n",
      "Fold: 10  Epoch: 238  Training loss = 4.0791  Validation loss = 6.5690  \n",
      "\n",
      "Fold: 10  Epoch: 239  Training loss = 4.0789  Validation loss = 6.5687  \n",
      "\n",
      "Fold: 10  Epoch: 240  Training loss = 4.0786  Validation loss = 6.5683  \n",
      "\n",
      "Fold: 10  Epoch: 241  Training loss = 4.0783  Validation loss = 6.5678  \n",
      "\n",
      "Fold: 10  Epoch: 242  Training loss = 4.0781  Validation loss = 6.5674  \n",
      "\n",
      "Fold: 10  Epoch: 243  Training loss = 4.0779  Validation loss = 6.5670  \n",
      "\n",
      "Fold: 10  Epoch: 244  Training loss = 4.0777  Validation loss = 6.5667  \n",
      "\n",
      "Fold: 10  Epoch: 245  Training loss = 4.0775  Validation loss = 6.5664  \n",
      "\n",
      "Fold: 10  Epoch: 246  Training loss = 4.0771  Validation loss = 6.5658  \n",
      "\n",
      "Fold: 10  Epoch: 247  Training loss = 4.0768  Validation loss = 6.5652  \n",
      "\n",
      "Fold: 10  Epoch: 248  Training loss = 4.0766  Validation loss = 6.5649  \n",
      "\n",
      "Fold: 10  Epoch: 249  Training loss = 4.0764  Validation loss = 6.5645  \n",
      "\n",
      "Fold: 10  Epoch: 250  Training loss = 4.0761  Validation loss = 6.5641  \n",
      "\n",
      "Fold: 10  Epoch: 251  Training loss = 4.0759  Validation loss = 6.5637  \n",
      "\n",
      "Fold: 10  Epoch: 252  Training loss = 4.0757  Validation loss = 6.5634  \n",
      "\n",
      "Fold: 10  Epoch: 253  Training loss = 4.0755  Validation loss = 6.5630  \n",
      "\n",
      "Fold: 10  Epoch: 254  Training loss = 4.0752  Validation loss = 6.5626  \n",
      "\n",
      "Fold: 10  Epoch: 255  Training loss = 4.0750  Validation loss = 6.5623  \n",
      "\n",
      "Fold: 10  Epoch: 256  Training loss = 4.0748  Validation loss = 6.5619  \n",
      "\n",
      "Fold: 10  Epoch: 257  Training loss = 4.0746  Validation loss = 6.5615  \n",
      "\n",
      "Fold: 10  Epoch: 258  Training loss = 4.0743  Validation loss = 6.5610  \n",
      "\n",
      "Fold: 10  Epoch: 259  Training loss = 4.0741  Validation loss = 6.5606  \n",
      "\n",
      "Fold: 10  Epoch: 260  Training loss = 4.0738  Validation loss = 6.5602  \n",
      "\n",
      "Fold: 10  Epoch: 261  Training loss = 4.0735  Validation loss = 6.5596  \n",
      "\n",
      "Fold: 10  Epoch: 262  Training loss = 4.0733  Validation loss = 6.5591  \n",
      "\n",
      "Fold: 10  Epoch: 263  Training loss = 4.0730  Validation loss = 6.5586  \n",
      "\n",
      "Fold: 10  Epoch: 264  Training loss = 4.0727  Validation loss = 6.5582  \n",
      "\n",
      "Fold: 10  Epoch: 265  Training loss = 4.0725  Validation loss = 6.5577  \n",
      "\n",
      "Fold: 10  Epoch: 266  Training loss = 4.0722  Validation loss = 6.5573  \n",
      "\n",
      "Fold: 10  Epoch: 267  Training loss = 4.0720  Validation loss = 6.5569  \n",
      "\n",
      "Fold: 10  Epoch: 268  Training loss = 4.0717  Validation loss = 6.5565  \n",
      "\n",
      "Fold: 10  Epoch: 269  Training loss = 4.0715  Validation loss = 6.5561  \n",
      "\n",
      "Fold: 10  Epoch: 270  Training loss = 4.0713  Validation loss = 6.5557  \n",
      "\n",
      "Fold: 10  Epoch: 271  Training loss = 4.0711  Validation loss = 6.5553  \n",
      "\n",
      "Fold: 10  Epoch: 272  Training loss = 4.0708  Validation loss = 6.5549  \n",
      "\n",
      "Fold: 10  Epoch: 273  Training loss = 4.0705  Validation loss = 6.5544  \n",
      "\n",
      "Fold: 10  Epoch: 274  Training loss = 4.0703  Validation loss = 6.5540  \n",
      "\n",
      "Fold: 10  Epoch: 275  Training loss = 4.0701  Validation loss = 6.5536  \n",
      "\n",
      "Fold: 10  Epoch: 276  Training loss = 4.0698  Validation loss = 6.5531  \n",
      "\n",
      "Fold: 10  Epoch: 277  Training loss = 4.0696  Validation loss = 6.5528  \n",
      "\n",
      "Fold: 10  Epoch: 278  Training loss = 4.0694  Validation loss = 6.5524  \n",
      "\n",
      "Fold: 10  Epoch: 279  Training loss = 4.0691  Validation loss = 6.5520  \n",
      "\n",
      "Fold: 10  Epoch: 280  Training loss = 4.0689  Validation loss = 6.5517  \n",
      "\n",
      "Fold: 10  Epoch: 281  Training loss = 4.0687  Validation loss = 6.5513  \n",
      "\n",
      "Fold: 10  Epoch: 282  Training loss = 4.0684  Validation loss = 6.5509  \n",
      "\n",
      "Fold: 10  Epoch: 283  Training loss = 4.0682  Validation loss = 6.5504  \n",
      "\n",
      "Fold: 10  Epoch: 284  Training loss = 4.0680  Validation loss = 6.5501  \n",
      "\n",
      "Fold: 10  Epoch: 285  Training loss = 4.0677  Validation loss = 6.5497  \n",
      "\n",
      "Fold: 10  Epoch: 286  Training loss = 4.0675  Validation loss = 6.5492  \n",
      "\n",
      "Fold: 10  Epoch: 287  Training loss = 4.0672  Validation loss = 6.5488  \n",
      "\n",
      "Fold: 10  Epoch: 288  Training loss = 4.0670  Validation loss = 6.5484  \n",
      "\n",
      "Fold: 10  Epoch: 289  Training loss = 4.0667  Validation loss = 6.5479  \n",
      "\n",
      "Fold: 10  Epoch: 290  Training loss = 4.0665  Validation loss = 6.5474  \n",
      "\n",
      "Fold: 10  Epoch: 291  Training loss = 4.0663  Validation loss = 6.5470  \n",
      "\n",
      "Fold: 10  Epoch: 292  Training loss = 4.0660  Validation loss = 6.5466  \n",
      "\n",
      "Fold: 10  Epoch: 293  Training loss = 4.0657  Validation loss = 6.5461  \n",
      "\n",
      "Fold: 10  Epoch: 294  Training loss = 4.0655  Validation loss = 6.5457  \n",
      "\n",
      "Fold: 10  Epoch: 295  Training loss = 4.0652  Validation loss = 6.5452  \n",
      "\n",
      "Fold: 10  Epoch: 296  Training loss = 4.0649  Validation loss = 6.5447  \n",
      "\n",
      "Fold: 10  Epoch: 297  Training loss = 4.0646  Validation loss = 6.5440  \n",
      "\n",
      "Fold: 10  Epoch: 298  Training loss = 4.0643  Validation loss = 6.5435  \n",
      "\n",
      "Fold: 10  Epoch: 299  Training loss = 4.0641  Validation loss = 6.5431  \n",
      "\n",
      "Fold: 10  Epoch: 300  Training loss = 4.0638  Validation loss = 6.5427  \n",
      "\n",
      "Fold: 10  Epoch: 301  Training loss = 4.0636  Validation loss = 6.5422  \n",
      "\n",
      "Fold: 10  Epoch: 302  Training loss = 4.0634  Validation loss = 6.5419  \n",
      "\n",
      "Fold: 10  Epoch: 303  Training loss = 4.0632  Validation loss = 6.5415  \n",
      "\n",
      "Fold: 10  Epoch: 304  Training loss = 4.0629  Validation loss = 6.5410  \n",
      "\n",
      "Fold: 10  Epoch: 305  Training loss = 4.0627  Validation loss = 6.5407  \n",
      "\n",
      "Fold: 10  Epoch: 306  Training loss = 4.0625  Validation loss = 6.5404  \n",
      "\n",
      "Fold: 10  Epoch: 307  Training loss = 4.0623  Validation loss = 6.5400  \n",
      "\n",
      "Fold: 10  Epoch: 308  Training loss = 4.0621  Validation loss = 6.5397  \n",
      "\n",
      "Fold: 10  Epoch: 309  Training loss = 4.0619  Validation loss = 6.5394  \n",
      "\n",
      "Fold: 10  Epoch: 310  Training loss = 4.0617  Validation loss = 6.5392  \n",
      "\n",
      "Fold: 10  Epoch: 311  Training loss = 4.0615  Validation loss = 6.5388  \n",
      "\n",
      "Fold: 10  Epoch: 312  Training loss = 4.0613  Validation loss = 6.5384  \n",
      "\n",
      "Fold: 10  Epoch: 313  Training loss = 4.0611  Validation loss = 6.5380  \n",
      "\n",
      "Fold: 10  Epoch: 314  Training loss = 4.0609  Validation loss = 6.5376  \n",
      "\n",
      "Fold: 10  Epoch: 315  Training loss = 4.0606  Validation loss = 6.5372  \n",
      "\n",
      "Fold: 10  Epoch: 316  Training loss = 4.0604  Validation loss = 6.5369  \n",
      "\n",
      "Fold: 10  Epoch: 317  Training loss = 4.0602  Validation loss = 6.5365  \n",
      "\n",
      "Fold: 10  Epoch: 318  Training loss = 4.0600  Validation loss = 6.5361  \n",
      "\n",
      "Fold: 10  Epoch: 319  Training loss = 4.0597  Validation loss = 6.5358  \n",
      "\n",
      "Fold: 10  Epoch: 320  Training loss = 4.0595  Validation loss = 6.5354  \n",
      "\n",
      "Fold: 10  Epoch: 321  Training loss = 4.0593  Validation loss = 6.5351  \n",
      "\n",
      "Fold: 10  Epoch: 322  Training loss = 4.0591  Validation loss = 6.5347  \n",
      "\n",
      "Fold: 10  Epoch: 323  Training loss = 4.0589  Validation loss = 6.5344  \n",
      "\n",
      "Fold: 10  Epoch: 324  Training loss = 4.0587  Validation loss = 6.5340  \n",
      "\n",
      "Fold: 10  Epoch: 325  Training loss = 4.0584  Validation loss = 6.5335  \n",
      "\n",
      "Fold: 10  Epoch: 326  Training loss = 4.0581  Validation loss = 6.5330  \n",
      "\n",
      "Fold: 10  Epoch: 327  Training loss = 4.0579  Validation loss = 6.5326  \n",
      "\n",
      "Fold: 10  Epoch: 328  Training loss = 4.0577  Validation loss = 6.5321  \n",
      "\n",
      "Fold: 10  Epoch: 329  Training loss = 4.0574  Validation loss = 6.5316  \n",
      "\n",
      "Fold: 10  Epoch: 330  Training loss = 4.0571  Validation loss = 6.5312  \n",
      "\n",
      "Fold: 10  Epoch: 331  Training loss = 4.0569  Validation loss = 6.5308  \n",
      "\n",
      "Fold: 10  Epoch: 332  Training loss = 4.0566  Validation loss = 6.5303  \n",
      "\n",
      "Fold: 10  Epoch: 333  Training loss = 4.0563  Validation loss = 6.5299  \n",
      "\n",
      "Fold: 10  Epoch: 334  Training loss = 4.0561  Validation loss = 6.5295  \n",
      "\n",
      "Fold: 10  Epoch: 335  Training loss = 4.0559  Validation loss = 6.5290  \n",
      "\n",
      "Fold: 10  Epoch: 336  Training loss = 4.0557  Validation loss = 6.5286  \n",
      "\n",
      "Fold: 10  Epoch: 337  Training loss = 4.0554  Validation loss = 6.5282  \n",
      "\n",
      "Fold: 10  Epoch: 338  Training loss = 4.0552  Validation loss = 6.5279  \n",
      "\n",
      "Fold: 10  Epoch: 339  Training loss = 4.0550  Validation loss = 6.5273  \n",
      "\n",
      "Fold: 10  Epoch: 340  Training loss = 4.0547  Validation loss = 6.5268  \n",
      "\n",
      "Fold: 10  Epoch: 341  Training loss = 4.0545  Validation loss = 6.5265  \n",
      "\n",
      "Fold: 10  Epoch: 342  Training loss = 4.0543  Validation loss = 6.5262  \n",
      "\n",
      "Fold: 10  Epoch: 343  Training loss = 4.0541  Validation loss = 6.5259  \n",
      "\n",
      "Fold: 10  Epoch: 344  Training loss = 4.0538  Validation loss = 6.5254  \n",
      "\n",
      "Fold: 10  Epoch: 345  Training loss = 4.0536  Validation loss = 6.5250  \n",
      "\n",
      "Fold: 10  Epoch: 346  Training loss = 4.0533  Validation loss = 6.5244  \n",
      "\n",
      "Fold: 10  Epoch: 347  Training loss = 4.0531  Validation loss = 6.5241  \n",
      "\n",
      "Fold: 10  Epoch: 348  Training loss = 4.0529  Validation loss = 6.5238  \n",
      "\n",
      "Fold: 10  Epoch: 349  Training loss = 4.0527  Validation loss = 6.5234  \n",
      "\n",
      "Fold: 10  Epoch: 350  Training loss = 4.0525  Validation loss = 6.5230  \n",
      "\n",
      "Fold: 10  Epoch: 351  Training loss = 4.0522  Validation loss = 6.5225  \n",
      "\n",
      "Fold: 10  Epoch: 352  Training loss = 4.0521  Validation loss = 6.5224  \n",
      "\n",
      "Fold: 10  Epoch: 353  Training loss = 4.0518  Validation loss = 6.5218  \n",
      "\n",
      "Fold: 10  Epoch: 354  Training loss = 4.0516  Validation loss = 6.5214  \n",
      "\n",
      "Fold: 10  Epoch: 355  Training loss = 4.0513  Validation loss = 6.5210  \n",
      "\n",
      "Fold: 10  Epoch: 356  Training loss = 4.0511  Validation loss = 6.5205  \n",
      "\n",
      "Fold: 10  Epoch: 357  Training loss = 4.0508  Validation loss = 6.5201  \n",
      "\n",
      "Fold: 10  Epoch: 358  Training loss = 4.0506  Validation loss = 6.5198  \n",
      "\n",
      "Fold: 10  Epoch: 359  Training loss = 4.0504  Validation loss = 6.5194  \n",
      "\n",
      "Fold: 10  Epoch: 360  Training loss = 4.0501  Validation loss = 6.5190  \n",
      "\n",
      "Fold: 10  Epoch: 361  Training loss = 4.0498  Validation loss = 6.5185  \n",
      "\n",
      "Fold: 10  Epoch: 362  Training loss = 4.0496  Validation loss = 6.5181  \n",
      "\n",
      "Fold: 10  Epoch: 363  Training loss = 4.0494  Validation loss = 6.5177  \n",
      "\n",
      "Fold: 10  Epoch: 364  Training loss = 4.0491  Validation loss = 6.5173  \n",
      "\n",
      "Fold: 10  Epoch: 365  Training loss = 4.0489  Validation loss = 6.5169  \n",
      "\n",
      "Fold: 10  Epoch: 366  Training loss = 4.0488  Validation loss = 6.5166  \n",
      "\n",
      "Fold: 10  Epoch: 367  Training loss = 4.0485  Validation loss = 6.5162  \n",
      "\n",
      "Fold: 10  Epoch: 368  Training loss = 4.0483  Validation loss = 6.5158  \n",
      "\n",
      "Fold: 10  Epoch: 369  Training loss = 4.0480  Validation loss = 6.5154  \n",
      "\n",
      "Fold: 10  Epoch: 370  Training loss = 4.0478  Validation loss = 6.5149  \n",
      "\n",
      "Fold: 10  Epoch: 371  Training loss = 4.0475  Validation loss = 6.5145  \n",
      "\n",
      "Fold: 10  Epoch: 372  Training loss = 4.0473  Validation loss = 6.5141  \n",
      "\n",
      "Fold: 10  Epoch: 373  Training loss = 4.0471  Validation loss = 6.5137  \n",
      "\n",
      "Fold: 10  Epoch: 374  Training loss = 4.0468  Validation loss = 6.5132  \n",
      "\n",
      "Fold: 10  Epoch: 375  Training loss = 4.0466  Validation loss = 6.5129  \n",
      "\n",
      "Fold: 10  Epoch: 376  Training loss = 4.0463  Validation loss = 6.5124  \n",
      "\n",
      "Fold: 10  Epoch: 377  Training loss = 4.0461  Validation loss = 6.5120  \n",
      "\n",
      "Fold: 10  Epoch: 378  Training loss = 4.0458  Validation loss = 6.5115  \n",
      "\n",
      "Fold: 10  Epoch: 379  Training loss = 4.0455  Validation loss = 6.5110  \n",
      "\n",
      "Fold: 10  Epoch: 380  Training loss = 4.0453  Validation loss = 6.5106  \n",
      "\n",
      "Fold: 10  Epoch: 381  Training loss = 4.0451  Validation loss = 6.5102  \n",
      "\n",
      "Fold: 10  Epoch: 382  Training loss = 4.0447  Validation loss = 6.5096  \n",
      "\n",
      "Fold: 10  Epoch: 383  Training loss = 4.0445  Validation loss = 6.5092  \n",
      "\n",
      "Fold: 10  Epoch: 384  Training loss = 4.0443  Validation loss = 6.5087  \n",
      "\n",
      "Fold: 10  Epoch: 385  Training loss = 4.0441  Validation loss = 6.5083  \n",
      "\n",
      "Fold: 10  Epoch: 386  Training loss = 4.0439  Validation loss = 6.5080  \n",
      "\n",
      "Fold: 10  Epoch: 387  Training loss = 4.0437  Validation loss = 6.5077  \n",
      "\n",
      "Fold: 10  Epoch: 388  Training loss = 4.0435  Validation loss = 6.5073  \n",
      "\n",
      "Fold: 10  Epoch: 389  Training loss = 4.0433  Validation loss = 6.5070  \n",
      "\n",
      "Fold: 10  Epoch: 390  Training loss = 4.0430  Validation loss = 6.5066  \n",
      "\n",
      "Fold: 10  Epoch: 391  Training loss = 4.0428  Validation loss = 6.5062  \n",
      "\n",
      "Fold: 10  Epoch: 392  Training loss = 4.0426  Validation loss = 6.5058  \n",
      "\n",
      "Fold: 10  Epoch: 393  Training loss = 4.0424  Validation loss = 6.5055  \n",
      "\n",
      "Fold: 10  Epoch: 394  Training loss = 4.0422  Validation loss = 6.5052  \n",
      "\n",
      "Fold: 10  Epoch: 395  Training loss = 4.0420  Validation loss = 6.5047  \n",
      "\n",
      "Fold: 10  Epoch: 396  Training loss = 4.0417  Validation loss = 6.5043  \n",
      "\n",
      "Fold: 10  Epoch: 397  Training loss = 4.0415  Validation loss = 6.5040  \n",
      "\n",
      "Fold: 10  Epoch: 398  Training loss = 4.0413  Validation loss = 6.5035  \n",
      "\n",
      "Fold: 10  Epoch: 399  Training loss = 4.0410  Validation loss = 6.5030  \n",
      "\n",
      "Fold: 10  Epoch: 400  Training loss = 4.0407  Validation loss = 6.5025  \n",
      "\n",
      "Fold: 10  Epoch: 401  Training loss = 4.0405  Validation loss = 6.5021  \n",
      "\n",
      "Fold: 10  Epoch: 402  Training loss = 4.0401  Validation loss = 6.5015  \n",
      "\n",
      "Fold: 10  Epoch: 403  Training loss = 4.0400  Validation loss = 6.5012  \n",
      "\n",
      "Fold: 10  Epoch: 404  Training loss = 4.0397  Validation loss = 6.5008  \n",
      "\n",
      "Fold: 10  Epoch: 405  Training loss = 4.0396  Validation loss = 6.5005  \n",
      "\n",
      "Fold: 10  Epoch: 406  Training loss = 4.0393  Validation loss = 6.5001  \n",
      "\n",
      "Fold: 10  Epoch: 407  Training loss = 4.0390  Validation loss = 6.4996  \n",
      "\n",
      "Fold: 10  Epoch: 408  Training loss = 4.0388  Validation loss = 6.4992  \n",
      "\n",
      "Fold: 10  Epoch: 409  Training loss = 4.0386  Validation loss = 6.4988  \n",
      "\n",
      "Fold: 10  Epoch: 410  Training loss = 4.0383  Validation loss = 6.4984  \n",
      "\n",
      "Fold: 10  Epoch: 411  Training loss = 4.0381  Validation loss = 6.4979  \n",
      "\n",
      "Fold: 10  Epoch: 412  Training loss = 4.0378  Validation loss = 6.4974  \n",
      "\n",
      "Fold: 10  Epoch: 413  Training loss = 4.0376  Validation loss = 6.4970  \n",
      "\n",
      "Fold: 10  Epoch: 414  Training loss = 4.0373  Validation loss = 6.4966  \n",
      "\n",
      "Fold: 10  Epoch: 415  Training loss = 4.0371  Validation loss = 6.4963  \n",
      "\n",
      "Fold: 10  Epoch: 416  Training loss = 4.0368  Validation loss = 6.4957  \n",
      "\n",
      "Fold: 10  Epoch: 417  Training loss = 4.0366  Validation loss = 6.4953  \n",
      "\n",
      "Fold: 10  Epoch: 418  Training loss = 4.0364  Validation loss = 6.4949  \n",
      "\n",
      "Fold: 10  Epoch: 419  Training loss = 4.0361  Validation loss = 6.4944  \n",
      "\n",
      "Fold: 10  Epoch: 420  Training loss = 4.0358  Validation loss = 6.4939  \n",
      "\n",
      "Fold: 10  Epoch: 421  Training loss = 4.0356  Validation loss = 6.4936  \n",
      "\n",
      "Fold: 10  Epoch: 422  Training loss = 4.0354  Validation loss = 6.4932  \n",
      "\n",
      "Fold: 10  Epoch: 423  Training loss = 4.0353  Validation loss = 6.4929  \n",
      "\n",
      "Fold: 10  Epoch: 424  Training loss = 4.0350  Validation loss = 6.4925  \n",
      "\n",
      "Fold: 10  Epoch: 425  Training loss = 4.0348  Validation loss = 6.4922  \n",
      "\n",
      "Fold: 10  Epoch: 426  Training loss = 4.0346  Validation loss = 6.4918  \n",
      "\n",
      "Fold: 10  Epoch: 427  Training loss = 4.0344  Validation loss = 6.4916  \n",
      "\n",
      "Fold: 10  Epoch: 428  Training loss = 4.0342  Validation loss = 6.4912  \n",
      "\n",
      "Fold: 10  Epoch: 429  Training loss = 4.0339  Validation loss = 6.4907  \n",
      "\n",
      "Fold: 10  Epoch: 430  Training loss = 4.0336  Validation loss = 6.4902  \n",
      "\n",
      "Fold: 10  Epoch: 431  Training loss = 4.0334  Validation loss = 6.4898  \n",
      "\n",
      "Fold: 10  Epoch: 432  Training loss = 4.0331  Validation loss = 6.4894  \n",
      "\n",
      "Fold: 10  Epoch: 433  Training loss = 4.0329  Validation loss = 6.4889  \n",
      "\n",
      "Fold: 10  Epoch: 434  Training loss = 4.0326  Validation loss = 6.4884  \n",
      "\n",
      "Fold: 10  Epoch: 435  Training loss = 4.0324  Validation loss = 6.4880  \n",
      "\n",
      "Fold: 10  Epoch: 436  Training loss = 4.0321  Validation loss = 6.4875  \n",
      "\n",
      "Fold: 10  Epoch: 437  Training loss = 4.0319  Validation loss = 6.4870  \n",
      "\n",
      "Fold: 10  Epoch: 438  Training loss = 4.0316  Validation loss = 6.4866  \n",
      "\n",
      "Fold: 10  Epoch: 439  Training loss = 4.0314  Validation loss = 6.4862  \n",
      "\n",
      "Fold: 10  Epoch: 440  Training loss = 4.0312  Validation loss = 6.4857  \n",
      "\n",
      "Fold: 10  Epoch: 441  Training loss = 4.0309  Validation loss = 6.4854  \n",
      "\n",
      "Fold: 10  Epoch: 442  Training loss = 4.0306  Validation loss = 6.4848  \n",
      "\n",
      "Fold: 10  Epoch: 443  Training loss = 4.0304  Validation loss = 6.4844  \n",
      "\n",
      "Fold: 10  Epoch: 444  Training loss = 4.0301  Validation loss = 6.4839  \n",
      "\n",
      "Fold: 10  Epoch: 445  Training loss = 4.0299  Validation loss = 6.4835  \n",
      "\n",
      "Fold: 10  Epoch: 446  Training loss = 4.0296  Validation loss = 6.4830  \n",
      "\n",
      "Fold: 10  Epoch: 447  Training loss = 4.0294  Validation loss = 6.4826  \n",
      "\n",
      "Fold: 10  Epoch: 448  Training loss = 4.0292  Validation loss = 6.4821  \n",
      "\n",
      "Fold: 10  Epoch: 449  Training loss = 4.0289  Validation loss = 6.4816  \n",
      "\n",
      "Fold: 10  Epoch: 450  Training loss = 4.0287  Validation loss = 6.4812  \n",
      "\n",
      "Fold: 10  Epoch: 451  Training loss = 4.0284  Validation loss = 6.4807  \n",
      "\n",
      "Fold: 10  Epoch: 452  Training loss = 4.0282  Validation loss = 6.4802  \n",
      "\n",
      "Fold: 10  Epoch: 453  Training loss = 4.0280  Validation loss = 6.4799  \n",
      "\n",
      "Fold: 10  Epoch: 454  Training loss = 4.0277  Validation loss = 6.4794  \n",
      "\n",
      "Fold: 10  Epoch: 455  Training loss = 4.0275  Validation loss = 6.4791  \n",
      "\n",
      "Fold: 10  Epoch: 456  Training loss = 4.0273  Validation loss = 6.4786  \n",
      "\n",
      "Fold: 10  Epoch: 457  Training loss = 4.0271  Validation loss = 6.4782  \n",
      "\n",
      "Fold: 10  Epoch: 458  Training loss = 4.0269  Validation loss = 6.4779  \n",
      "\n",
      "Fold: 10  Epoch: 459  Training loss = 4.0266  Validation loss = 6.4775  \n",
      "\n",
      "Fold: 10  Epoch: 460  Training loss = 4.0264  Validation loss = 6.4770  \n",
      "\n",
      "Fold: 10  Epoch: 461  Training loss = 4.0262  Validation loss = 6.4766  \n",
      "\n",
      "Fold: 10  Epoch: 462  Training loss = 4.0260  Validation loss = 6.4764  \n",
      "\n",
      "Fold: 10  Epoch: 463  Training loss = 4.0258  Validation loss = 6.4760  \n",
      "\n",
      "Fold: 10  Epoch: 464  Training loss = 4.0256  Validation loss = 6.4756  \n",
      "\n",
      "Fold: 10  Epoch: 465  Training loss = 4.0253  Validation loss = 6.4752  \n",
      "\n",
      "Fold: 10  Epoch: 466  Training loss = 4.0251  Validation loss = 6.4749  \n",
      "\n",
      "Fold: 10  Epoch: 467  Training loss = 4.0249  Validation loss = 6.4745  \n",
      "\n",
      "Fold: 10  Epoch: 468  Training loss = 4.0247  Validation loss = 6.4741  \n",
      "\n",
      "Fold: 10  Epoch: 469  Training loss = 4.0245  Validation loss = 6.4738  \n",
      "\n",
      "Fold: 10  Epoch: 470  Training loss = 4.0243  Validation loss = 6.4734  \n",
      "\n",
      "Fold: 10  Epoch: 471  Training loss = 4.0240  Validation loss = 6.4730  \n",
      "\n",
      "Fold: 10  Epoch: 472  Training loss = 4.0238  Validation loss = 6.4726  \n",
      "\n",
      "Fold: 10  Epoch: 473  Training loss = 4.0235  Validation loss = 6.4721  \n",
      "\n",
      "Fold: 10  Epoch: 474  Training loss = 4.0233  Validation loss = 6.4718  \n",
      "\n",
      "Fold: 10  Epoch: 475  Training loss = 4.0231  Validation loss = 6.4714  \n",
      "\n",
      "Fold: 10  Epoch: 476  Training loss = 4.0229  Validation loss = 6.4710  \n",
      "\n",
      "Fold: 10  Epoch: 477  Training loss = 4.0227  Validation loss = 6.4707  \n",
      "\n",
      "Fold: 10  Epoch: 478  Training loss = 4.0225  Validation loss = 6.4703  \n",
      "\n",
      "Fold: 10  Epoch: 479  Training loss = 4.0223  Validation loss = 6.4699  \n",
      "\n",
      "Fold: 10  Epoch: 480  Training loss = 4.0220  Validation loss = 6.4695  \n",
      "\n",
      "Fold: 10  Epoch: 481  Training loss = 4.0218  Validation loss = 6.4692  \n",
      "\n",
      "Fold: 10  Epoch: 482  Training loss = 4.0216  Validation loss = 6.4688  \n",
      "\n",
      "Fold: 10  Epoch: 483  Training loss = 4.0214  Validation loss = 6.4684  \n",
      "\n",
      "Fold: 10  Epoch: 484  Training loss = 4.0212  Validation loss = 6.4680  \n",
      "\n",
      "Fold: 10  Epoch: 485  Training loss = 4.0208  Validation loss = 6.4675  \n",
      "\n",
      "Fold: 10  Epoch: 486  Training loss = 4.0207  Validation loss = 6.4672  \n",
      "\n",
      "Fold: 10  Epoch: 487  Training loss = 4.0205  Validation loss = 6.4669  \n",
      "\n",
      "Fold: 10  Epoch: 488  Training loss = 4.0203  Validation loss = 6.4666  \n",
      "\n",
      "Fold: 10  Epoch: 489  Training loss = 4.0201  Validation loss = 6.4663  \n",
      "\n",
      "Fold: 10  Epoch: 490  Training loss = 4.0200  Validation loss = 6.4660  \n",
      "\n",
      "Fold: 10  Epoch: 491  Training loss = 4.0198  Validation loss = 6.4657  \n",
      "\n",
      "Fold: 10  Epoch: 492  Training loss = 4.0195  Validation loss = 6.4652  \n",
      "\n",
      "Fold: 10  Epoch: 493  Training loss = 4.0193  Validation loss = 6.4648  \n",
      "\n",
      "Fold: 10  Epoch: 494  Training loss = 4.0190  Validation loss = 6.4643  \n",
      "\n",
      "Fold: 10  Epoch: 495  Training loss = 4.0188  Validation loss = 6.4639  \n",
      "\n",
      "Fold: 10  Epoch: 496  Training loss = 4.0186  Validation loss = 6.4635  \n",
      "\n",
      "Fold: 10  Epoch: 497  Training loss = 4.0183  Validation loss = 6.4629  \n",
      "\n",
      "Fold: 10  Epoch: 498  Training loss = 4.0180  Validation loss = 6.4625  \n",
      "\n",
      "Fold: 10  Epoch: 499  Training loss = 4.0179  Validation loss = 6.4622  \n",
      "\n",
      "Fold: 10  Epoch: 500  Training loss = 4.0177  Validation loss = 6.4618  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 500  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 4.3170  Validation loss = 4.1567  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 4.3167  Validation loss = 4.1564  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 4.3164  Validation loss = 4.1559  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 4.3161  Validation loss = 4.1556  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 4.3158  Validation loss = 4.1551  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 4.3155  Validation loss = 4.1548  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 4.3152  Validation loss = 4.1544  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 4.3149  Validation loss = 4.1540  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 4.3145  Validation loss = 4.1535  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 4.3143  Validation loss = 4.1531  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 4.3140  Validation loss = 4.1527  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 4.3136  Validation loss = 4.1522  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 4.3133  Validation loss = 4.1519  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 4.3129  Validation loss = 4.1514  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 4.3127  Validation loss = 4.1512  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 4.3124  Validation loss = 4.1507  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 4.3122  Validation loss = 4.1504  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 4.3119  Validation loss = 4.1500  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 4.3116  Validation loss = 4.1496  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 4.3113  Validation loss = 4.1492  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 4.3110  Validation loss = 4.1488  \n",
      "\n",
      "Fold: 11  Epoch: 22  Training loss = 4.3107  Validation loss = 4.1484  \n",
      "\n",
      "Fold: 11  Epoch: 23  Training loss = 4.3103  Validation loss = 4.1481  \n",
      "\n",
      "Fold: 11  Epoch: 24  Training loss = 4.3101  Validation loss = 4.1478  \n",
      "\n",
      "Fold: 11  Epoch: 25  Training loss = 4.3098  Validation loss = 4.1474  \n",
      "\n",
      "Fold: 11  Epoch: 26  Training loss = 4.3096  Validation loss = 4.1470  \n",
      "\n",
      "Fold: 11  Epoch: 27  Training loss = 4.3092  Validation loss = 4.1466  \n",
      "\n",
      "Fold: 11  Epoch: 28  Training loss = 4.3089  Validation loss = 4.1462  \n",
      "\n",
      "Fold: 11  Epoch: 29  Training loss = 4.3086  Validation loss = 4.1458  \n",
      "\n",
      "Fold: 11  Epoch: 30  Training loss = 4.3082  Validation loss = 4.1453  \n",
      "\n",
      "Fold: 11  Epoch: 31  Training loss = 4.3079  Validation loss = 4.1449  \n",
      "\n",
      "Fold: 11  Epoch: 32  Training loss = 4.3076  Validation loss = 4.1446  \n",
      "\n",
      "Fold: 11  Epoch: 33  Training loss = 4.3073  Validation loss = 4.1442  \n",
      "\n",
      "Fold: 11  Epoch: 34  Training loss = 4.3071  Validation loss = 4.1438  \n",
      "\n",
      "Fold: 11  Epoch: 35  Training loss = 4.3067  Validation loss = 4.1434  \n",
      "\n",
      "Fold: 11  Epoch: 36  Training loss = 4.3063  Validation loss = 4.1429  \n",
      "\n",
      "Fold: 11  Epoch: 37  Training loss = 4.3060  Validation loss = 4.1425  \n",
      "\n",
      "Fold: 11  Epoch: 38  Training loss = 4.3057  Validation loss = 4.1422  \n",
      "\n",
      "Fold: 11  Epoch: 39  Training loss = 4.3054  Validation loss = 4.1418  \n",
      "\n",
      "Fold: 11  Epoch: 40  Training loss = 4.3051  Validation loss = 4.1414  \n",
      "\n",
      "Fold: 11  Epoch: 41  Training loss = 4.3048  Validation loss = 4.1410  \n",
      "\n",
      "Fold: 11  Epoch: 42  Training loss = 4.3045  Validation loss = 4.1406  \n",
      "\n",
      "Fold: 11  Epoch: 43  Training loss = 4.3042  Validation loss = 4.1402  \n",
      "\n",
      "Fold: 11  Epoch: 44  Training loss = 4.3039  Validation loss = 4.1398  \n",
      "\n",
      "Fold: 11  Epoch: 45  Training loss = 4.3036  Validation loss = 4.1394  \n",
      "\n",
      "Fold: 11  Epoch: 46  Training loss = 4.3033  Validation loss = 4.1391  \n",
      "\n",
      "Fold: 11  Epoch: 47  Training loss = 4.3030  Validation loss = 4.1387  \n",
      "\n",
      "Fold: 11  Epoch: 48  Training loss = 4.3027  Validation loss = 4.1383  \n",
      "\n",
      "Fold: 11  Epoch: 49  Training loss = 4.3024  Validation loss = 4.1379  \n",
      "\n",
      "Fold: 11  Epoch: 50  Training loss = 4.3020  Validation loss = 4.1375  \n",
      "\n",
      "Fold: 11  Epoch: 51  Training loss = 4.3017  Validation loss = 4.1371  \n",
      "\n",
      "Fold: 11  Epoch: 52  Training loss = 4.3013  Validation loss = 4.1366  \n",
      "\n",
      "Fold: 11  Epoch: 53  Training loss = 4.3011  Validation loss = 4.1363  \n",
      "\n",
      "Fold: 11  Epoch: 54  Training loss = 4.3007  Validation loss = 4.1358  \n",
      "\n",
      "Fold: 11  Epoch: 55  Training loss = 4.3005  Validation loss = 4.1356  \n",
      "\n",
      "Fold: 11  Epoch: 56  Training loss = 4.3003  Validation loss = 4.1353  \n",
      "\n",
      "Fold: 11  Epoch: 57  Training loss = 4.3001  Validation loss = 4.1350  \n",
      "\n",
      "Fold: 11  Epoch: 58  Training loss = 4.2998  Validation loss = 4.1346  \n",
      "\n",
      "Fold: 11  Epoch: 59  Training loss = 4.2995  Validation loss = 4.1342  \n",
      "\n",
      "Fold: 11  Epoch: 60  Training loss = 4.2992  Validation loss = 4.1339  \n",
      "\n",
      "Fold: 11  Epoch: 61  Training loss = 4.2990  Validation loss = 4.1335  \n",
      "\n",
      "Fold: 11  Epoch: 62  Training loss = 4.2987  Validation loss = 4.1332  \n",
      "\n",
      "Fold: 11  Epoch: 63  Training loss = 4.2984  Validation loss = 4.1328  \n",
      "\n",
      "Fold: 11  Epoch: 64  Training loss = 4.2982  Validation loss = 4.1324  \n",
      "\n",
      "Fold: 11  Epoch: 65  Training loss = 4.2979  Validation loss = 4.1320  \n",
      "\n",
      "Fold: 11  Epoch: 66  Training loss = 4.2976  Validation loss = 4.1316  \n",
      "\n",
      "Fold: 11  Epoch: 67  Training loss = 4.2973  Validation loss = 4.1313  \n",
      "\n",
      "Fold: 11  Epoch: 68  Training loss = 4.2970  Validation loss = 4.1308  \n",
      "\n",
      "Fold: 11  Epoch: 69  Training loss = 4.2967  Validation loss = 4.1305  \n",
      "\n",
      "Fold: 11  Epoch: 70  Training loss = 4.2965  Validation loss = 4.1302  \n",
      "\n",
      "Fold: 11  Epoch: 71  Training loss = 4.2962  Validation loss = 4.1298  \n",
      "\n",
      "Fold: 11  Epoch: 72  Training loss = 4.2959  Validation loss = 4.1294  \n",
      "\n",
      "Fold: 11  Epoch: 73  Training loss = 4.2956  Validation loss = 4.1290  \n",
      "\n",
      "Fold: 11  Epoch: 74  Training loss = 4.2954  Validation loss = 4.1287  \n",
      "\n",
      "Fold: 11  Epoch: 75  Training loss = 4.2950  Validation loss = 4.1283  \n",
      "\n",
      "Fold: 11  Epoch: 76  Training loss = 4.2947  Validation loss = 4.1279  \n",
      "\n",
      "Fold: 11  Epoch: 77  Training loss = 4.2944  Validation loss = 4.1275  \n",
      "\n",
      "Fold: 11  Epoch: 78  Training loss = 4.2940  Validation loss = 4.1271  \n",
      "\n",
      "Fold: 11  Epoch: 79  Training loss = 4.2937  Validation loss = 4.1267  \n",
      "\n",
      "Fold: 11  Epoch: 80  Training loss = 4.2934  Validation loss = 4.1262  \n",
      "\n",
      "Fold: 11  Epoch: 81  Training loss = 4.2931  Validation loss = 4.1258  \n",
      "\n",
      "Fold: 11  Epoch: 82  Training loss = 4.2928  Validation loss = 4.1255  \n",
      "\n",
      "Fold: 11  Epoch: 83  Training loss = 4.2926  Validation loss = 4.1252  \n",
      "\n",
      "Fold: 11  Epoch: 84  Training loss = 4.2923  Validation loss = 4.1248  \n",
      "\n",
      "Fold: 11  Epoch: 85  Training loss = 4.2920  Validation loss = 4.1244  \n",
      "\n",
      "Fold: 11  Epoch: 86  Training loss = 4.2917  Validation loss = 4.1240  \n",
      "\n",
      "Fold: 11  Epoch: 87  Training loss = 4.2914  Validation loss = 4.1237  \n",
      "\n",
      "Fold: 11  Epoch: 88  Training loss = 4.2911  Validation loss = 4.1233  \n",
      "\n",
      "Fold: 11  Epoch: 89  Training loss = 4.2909  Validation loss = 4.1229  \n",
      "\n",
      "Fold: 11  Epoch: 90  Training loss = 4.2905  Validation loss = 4.1225  \n",
      "\n",
      "Fold: 11  Epoch: 91  Training loss = 4.2902  Validation loss = 4.1222  \n",
      "\n",
      "Fold: 11  Epoch: 92  Training loss = 4.2900  Validation loss = 4.1218  \n",
      "\n",
      "Fold: 11  Epoch: 93  Training loss = 4.2896  Validation loss = 4.1213  \n",
      "\n",
      "Fold: 11  Epoch: 94  Training loss = 4.2892  Validation loss = 4.1208  \n",
      "\n",
      "Fold: 11  Epoch: 95  Training loss = 4.2889  Validation loss = 4.1205  \n",
      "\n",
      "Fold: 11  Epoch: 96  Training loss = 4.2887  Validation loss = 4.1201  \n",
      "\n",
      "Fold: 11  Epoch: 97  Training loss = 4.2884  Validation loss = 4.1198  \n",
      "\n",
      "Fold: 11  Epoch: 98  Training loss = 4.2881  Validation loss = 4.1193  \n",
      "\n",
      "Fold: 11  Epoch: 99  Training loss = 4.2878  Validation loss = 4.1190  \n",
      "\n",
      "Fold: 11  Epoch: 100  Training loss = 4.2875  Validation loss = 4.1186  \n",
      "\n",
      "Fold: 11  Epoch: 101  Training loss = 4.2873  Validation loss = 4.1182  \n",
      "\n",
      "Fold: 11  Epoch: 102  Training loss = 4.2870  Validation loss = 4.1178  \n",
      "\n",
      "Fold: 11  Epoch: 103  Training loss = 4.2867  Validation loss = 4.1175  \n",
      "\n",
      "Fold: 11  Epoch: 104  Training loss = 4.2864  Validation loss = 4.1171  \n",
      "\n",
      "Fold: 11  Epoch: 105  Training loss = 4.2861  Validation loss = 4.1167  \n",
      "\n",
      "Fold: 11  Epoch: 106  Training loss = 4.2858  Validation loss = 4.1163  \n",
      "\n",
      "Fold: 11  Epoch: 107  Training loss = 4.2855  Validation loss = 4.1159  \n",
      "\n",
      "Fold: 11  Epoch: 108  Training loss = 4.2852  Validation loss = 4.1155  \n",
      "\n",
      "Fold: 11  Epoch: 109  Training loss = 4.2850  Validation loss = 4.1152  \n",
      "\n",
      "Fold: 11  Epoch: 110  Training loss = 4.2847  Validation loss = 4.1148  \n",
      "\n",
      "Fold: 11  Epoch: 111  Training loss = 4.2843  Validation loss = 4.1143  \n",
      "\n",
      "Fold: 11  Epoch: 112  Training loss = 4.2840  Validation loss = 4.1140  \n",
      "\n",
      "Fold: 11  Epoch: 113  Training loss = 4.2838  Validation loss = 4.1136  \n",
      "\n",
      "Fold: 11  Epoch: 114  Training loss = 4.2836  Validation loss = 4.1133  \n",
      "\n",
      "Fold: 11  Epoch: 115  Training loss = 4.2833  Validation loss = 4.1129  \n",
      "\n",
      "Fold: 11  Epoch: 116  Training loss = 4.2830  Validation loss = 4.1125  \n",
      "\n",
      "Fold: 11  Epoch: 117  Training loss = 4.2827  Validation loss = 4.1121  \n",
      "\n",
      "Fold: 11  Epoch: 118  Training loss = 4.2824  Validation loss = 4.1117  \n",
      "\n",
      "Fold: 11  Epoch: 119  Training loss = 4.2820  Validation loss = 4.1113  \n",
      "\n",
      "Fold: 11  Epoch: 120  Training loss = 4.2817  Validation loss = 4.1109  \n",
      "\n",
      "Fold: 11  Epoch: 121  Training loss = 4.2815  Validation loss = 4.1106  \n",
      "\n",
      "Fold: 11  Epoch: 122  Training loss = 4.2812  Validation loss = 4.1102  \n",
      "\n",
      "Fold: 11  Epoch: 123  Training loss = 4.2808  Validation loss = 4.1097  \n",
      "\n",
      "Fold: 11  Epoch: 124  Training loss = 4.2806  Validation loss = 4.1093  \n",
      "\n",
      "Fold: 11  Epoch: 125  Training loss = 4.2803  Validation loss = 4.1090  \n",
      "\n",
      "Fold: 11  Epoch: 126  Training loss = 4.2800  Validation loss = 4.1086  \n",
      "\n",
      "Fold: 11  Epoch: 127  Training loss = 4.2797  Validation loss = 4.1082  \n",
      "\n",
      "Fold: 11  Epoch: 128  Training loss = 4.2794  Validation loss = 4.1078  \n",
      "\n",
      "Fold: 11  Epoch: 129  Training loss = 4.2791  Validation loss = 4.1074  \n",
      "\n",
      "Fold: 11  Epoch: 130  Training loss = 4.2788  Validation loss = 4.1070  \n",
      "\n",
      "Fold: 11  Epoch: 131  Training loss = 4.2785  Validation loss = 4.1066  \n",
      "\n",
      "Fold: 11  Epoch: 132  Training loss = 4.2782  Validation loss = 4.1062  \n",
      "\n",
      "Fold: 11  Epoch: 133  Training loss = 4.2779  Validation loss = 4.1058  \n",
      "\n",
      "Fold: 11  Epoch: 134  Training loss = 4.2776  Validation loss = 4.1054  \n",
      "\n",
      "Fold: 11  Epoch: 135  Training loss = 4.2773  Validation loss = 4.1050  \n",
      "\n",
      "Fold: 11  Epoch: 136  Training loss = 4.2770  Validation loss = 4.1046  \n",
      "\n",
      "Fold: 11  Epoch: 137  Training loss = 4.2767  Validation loss = 4.1043  \n",
      "\n",
      "Fold: 11  Epoch: 138  Training loss = 4.2765  Validation loss = 4.1039  \n",
      "\n",
      "Fold: 11  Epoch: 139  Training loss = 4.2763  Validation loss = 4.1037  \n",
      "\n",
      "Fold: 11  Epoch: 140  Training loss = 4.2759  Validation loss = 4.1033  \n",
      "\n",
      "Fold: 11  Epoch: 141  Training loss = 4.2756  Validation loss = 4.1028  \n",
      "\n",
      "Fold: 11  Epoch: 142  Training loss = 4.2753  Validation loss = 4.1024  \n",
      "\n",
      "Fold: 11  Epoch: 143  Training loss = 4.2750  Validation loss = 4.1020  \n",
      "\n",
      "Fold: 11  Epoch: 144  Training loss = 4.2748  Validation loss = 4.1017  \n",
      "\n",
      "Fold: 11  Epoch: 145  Training loss = 4.2745  Validation loss = 4.1013  \n",
      "\n",
      "Fold: 11  Epoch: 146  Training loss = 4.2742  Validation loss = 4.1009  \n",
      "\n",
      "Fold: 11  Epoch: 147  Training loss = 4.2739  Validation loss = 4.1005  \n",
      "\n",
      "Fold: 11  Epoch: 148  Training loss = 4.2736  Validation loss = 4.1001  \n",
      "\n",
      "Fold: 11  Epoch: 149  Training loss = 4.2733  Validation loss = 4.0998  \n",
      "\n",
      "Fold: 11  Epoch: 150  Training loss = 4.2730  Validation loss = 4.0994  \n",
      "\n",
      "Fold: 11  Epoch: 151  Training loss = 4.2727  Validation loss = 4.0990  \n",
      "\n",
      "Fold: 11  Epoch: 152  Training loss = 4.2724  Validation loss = 4.0986  \n",
      "\n",
      "Fold: 11  Epoch: 153  Training loss = 4.2721  Validation loss = 4.0982  \n",
      "\n",
      "Fold: 11  Epoch: 154  Training loss = 4.2718  Validation loss = 4.0979  \n",
      "\n",
      "Fold: 11  Epoch: 155  Training loss = 4.2715  Validation loss = 4.0975  \n",
      "\n",
      "Fold: 11  Epoch: 156  Training loss = 4.2712  Validation loss = 4.0970  \n",
      "\n",
      "Fold: 11  Epoch: 157  Training loss = 4.2710  Validation loss = 4.0967  \n",
      "\n",
      "Fold: 11  Epoch: 158  Training loss = 4.2707  Validation loss = 4.0964  \n",
      "\n",
      "Fold: 11  Epoch: 159  Training loss = 4.2704  Validation loss = 4.0960  \n",
      "\n",
      "Fold: 11  Epoch: 160  Training loss = 4.2701  Validation loss = 4.0957  \n",
      "\n",
      "Fold: 11  Epoch: 161  Training loss = 4.2699  Validation loss = 4.0953  \n",
      "\n",
      "Fold: 11  Epoch: 162  Training loss = 4.2695  Validation loss = 4.0948  \n",
      "\n",
      "Fold: 11  Epoch: 163  Training loss = 4.2692  Validation loss = 4.0945  \n",
      "\n",
      "Fold: 11  Epoch: 164  Training loss = 4.2689  Validation loss = 4.0941  \n",
      "\n",
      "Fold: 11  Epoch: 165  Training loss = 4.2686  Validation loss = 4.0937  \n",
      "\n",
      "Fold: 11  Epoch: 166  Training loss = 4.2683  Validation loss = 4.0933  \n",
      "\n",
      "Fold: 11  Epoch: 167  Training loss = 4.2680  Validation loss = 4.0929  \n",
      "\n",
      "Fold: 11  Epoch: 168  Training loss = 4.2677  Validation loss = 4.0925  \n",
      "\n",
      "Fold: 11  Epoch: 169  Training loss = 4.2674  Validation loss = 4.0921  \n",
      "\n",
      "Fold: 11  Epoch: 170  Training loss = 4.2671  Validation loss = 4.0917  \n",
      "\n",
      "Fold: 11  Epoch: 171  Training loss = 4.2668  Validation loss = 4.0913  \n",
      "\n",
      "Fold: 11  Epoch: 172  Training loss = 4.2665  Validation loss = 4.0910  \n",
      "\n",
      "Fold: 11  Epoch: 173  Training loss = 4.2662  Validation loss = 4.0905  \n",
      "\n",
      "Fold: 11  Epoch: 174  Training loss = 4.2659  Validation loss = 4.0900  \n",
      "\n",
      "Fold: 11  Epoch: 175  Training loss = 4.2656  Validation loss = 4.0897  \n",
      "\n",
      "Fold: 11  Epoch: 176  Training loss = 4.2653  Validation loss = 4.0893  \n",
      "\n",
      "Fold: 11  Epoch: 177  Training loss = 4.2650  Validation loss = 4.0889  \n",
      "\n",
      "Fold: 11  Epoch: 178  Training loss = 4.2647  Validation loss = 4.0886  \n",
      "\n",
      "Fold: 11  Epoch: 179  Training loss = 4.2645  Validation loss = 4.0883  \n",
      "\n",
      "Fold: 11  Epoch: 180  Training loss = 4.2642  Validation loss = 4.0879  \n",
      "\n",
      "Fold: 11  Epoch: 181  Training loss = 4.2638  Validation loss = 4.0874  \n",
      "\n",
      "Fold: 11  Epoch: 182  Training loss = 4.2635  Validation loss = 4.0870  \n",
      "\n",
      "Fold: 11  Epoch: 183  Training loss = 4.2632  Validation loss = 4.0867  \n",
      "\n",
      "Fold: 11  Epoch: 184  Training loss = 4.2630  Validation loss = 4.0863  \n",
      "\n",
      "Fold: 11  Epoch: 185  Training loss = 4.2627  Validation loss = 4.0860  \n",
      "\n",
      "Fold: 11  Epoch: 186  Training loss = 4.2625  Validation loss = 4.0856  \n",
      "\n",
      "Fold: 11  Epoch: 187  Training loss = 4.2622  Validation loss = 4.0853  \n",
      "\n",
      "Fold: 11  Epoch: 188  Training loss = 4.2619  Validation loss = 4.0848  \n",
      "\n",
      "Fold: 11  Epoch: 189  Training loss = 4.2615  Validation loss = 4.0844  \n",
      "\n",
      "Fold: 11  Epoch: 190  Training loss = 4.2613  Validation loss = 4.0841  \n",
      "\n",
      "Fold: 11  Epoch: 191  Training loss = 4.2610  Validation loss = 4.0837  \n",
      "\n",
      "Fold: 11  Epoch: 192  Training loss = 4.2606  Validation loss = 4.0832  \n",
      "\n",
      "Fold: 11  Epoch: 193  Training loss = 4.2603  Validation loss = 4.0828  \n",
      "\n",
      "Fold: 11  Epoch: 194  Training loss = 4.2601  Validation loss = 4.0825  \n",
      "\n",
      "Fold: 11  Epoch: 195  Training loss = 4.2597  Validation loss = 4.0821  \n",
      "\n",
      "Fold: 11  Epoch: 196  Training loss = 4.2595  Validation loss = 4.0818  \n",
      "\n",
      "Fold: 11  Epoch: 197  Training loss = 4.2592  Validation loss = 4.0814  \n",
      "\n",
      "Fold: 11  Epoch: 198  Training loss = 4.2589  Validation loss = 4.0810  \n",
      "\n",
      "Fold: 11  Epoch: 199  Training loss = 4.2586  Validation loss = 4.0806  \n",
      "\n",
      "Fold: 11  Epoch: 200  Training loss = 4.2584  Validation loss = 4.0803  \n",
      "\n",
      "Fold: 11  Epoch: 201  Training loss = 4.2580  Validation loss = 4.0798  \n",
      "\n",
      "Fold: 11  Epoch: 202  Training loss = 4.2578  Validation loss = 4.0795  \n",
      "\n",
      "Fold: 11  Epoch: 203  Training loss = 4.2576  Validation loss = 4.0792  \n",
      "\n",
      "Fold: 11  Epoch: 204  Training loss = 4.2572  Validation loss = 4.0788  \n",
      "\n",
      "Fold: 11  Epoch: 205  Training loss = 4.2569  Validation loss = 4.0784  \n",
      "\n",
      "Fold: 11  Epoch: 206  Training loss = 4.2566  Validation loss = 4.0780  \n",
      "\n",
      "Fold: 11  Epoch: 207  Training loss = 4.2564  Validation loss = 4.0776  \n",
      "\n",
      "Fold: 11  Epoch: 208  Training loss = 4.2561  Validation loss = 4.0773  \n",
      "\n",
      "Fold: 11  Epoch: 209  Training loss = 4.2558  Validation loss = 4.0769  \n",
      "\n",
      "Fold: 11  Epoch: 210  Training loss = 4.2555  Validation loss = 4.0766  \n",
      "\n",
      "Fold: 11  Epoch: 211  Training loss = 4.2552  Validation loss = 4.0761  \n",
      "\n",
      "Fold: 11  Epoch: 212  Training loss = 4.2549  Validation loss = 4.0757  \n",
      "\n",
      "Fold: 11  Epoch: 213  Training loss = 4.2547  Validation loss = 4.0753  \n",
      "\n",
      "Fold: 11  Epoch: 214  Training loss = 4.2543  Validation loss = 4.0749  \n",
      "\n",
      "Fold: 11  Epoch: 215  Training loss = 4.2540  Validation loss = 4.0745  \n",
      "\n",
      "Fold: 11  Epoch: 216  Training loss = 4.2537  Validation loss = 4.0741  \n",
      "\n",
      "Fold: 11  Epoch: 217  Training loss = 4.2534  Validation loss = 4.0738  \n",
      "\n",
      "Fold: 11  Epoch: 218  Training loss = 4.2532  Validation loss = 4.0734  \n",
      "\n",
      "Fold: 11  Epoch: 219  Training loss = 4.2529  Validation loss = 4.0731  \n",
      "\n",
      "Fold: 11  Epoch: 220  Training loss = 4.2526  Validation loss = 4.0726  \n",
      "\n",
      "Fold: 11  Epoch: 221  Training loss = 4.2523  Validation loss = 4.0722  \n",
      "\n",
      "Fold: 11  Epoch: 222  Training loss = 4.2520  Validation loss = 4.0718  \n",
      "\n",
      "Fold: 11  Epoch: 223  Training loss = 4.2517  Validation loss = 4.0714  \n",
      "\n",
      "Fold: 11  Epoch: 224  Training loss = 4.2514  Validation loss = 4.0709  \n",
      "\n",
      "Fold: 11  Epoch: 225  Training loss = 4.2511  Validation loss = 4.0706  \n",
      "\n",
      "Fold: 11  Epoch: 226  Training loss = 4.2509  Validation loss = 4.0703  \n",
      "\n",
      "Fold: 11  Epoch: 227  Training loss = 4.2507  Validation loss = 4.0700  \n",
      "\n",
      "Fold: 11  Epoch: 228  Training loss = 4.2504  Validation loss = 4.0697  \n",
      "\n",
      "Fold: 11  Epoch: 229  Training loss = 4.2501  Validation loss = 4.0693  \n",
      "\n",
      "Fold: 11  Epoch: 230  Training loss = 4.2498  Validation loss = 4.0689  \n",
      "\n",
      "Fold: 11  Epoch: 231  Training loss = 4.2495  Validation loss = 4.0685  \n",
      "\n",
      "Fold: 11  Epoch: 232  Training loss = 4.2492  Validation loss = 4.0681  \n",
      "\n",
      "Fold: 11  Epoch: 233  Training loss = 4.2488  Validation loss = 4.0677  \n",
      "\n",
      "Fold: 11  Epoch: 234  Training loss = 4.2485  Validation loss = 4.0673  \n",
      "\n",
      "Fold: 11  Epoch: 235  Training loss = 4.2482  Validation loss = 4.0669  \n",
      "\n",
      "Fold: 11  Epoch: 236  Training loss = 4.2479  Validation loss = 4.0664  \n",
      "\n",
      "Fold: 11  Epoch: 237  Training loss = 4.2476  Validation loss = 4.0660  \n",
      "\n",
      "Fold: 11  Epoch: 238  Training loss = 4.2473  Validation loss = 4.0657  \n",
      "\n",
      "Fold: 11  Epoch: 239  Training loss = 4.2470  Validation loss = 4.0653  \n",
      "\n",
      "Fold: 11  Epoch: 240  Training loss = 4.2467  Validation loss = 4.0649  \n",
      "\n",
      "Fold: 11  Epoch: 241  Training loss = 4.2464  Validation loss = 4.0645  \n",
      "\n",
      "Fold: 11  Epoch: 242  Training loss = 4.2461  Validation loss = 4.0641  \n",
      "\n",
      "Fold: 11  Epoch: 243  Training loss = 4.2457  Validation loss = 4.0636  \n",
      "\n",
      "Fold: 11  Epoch: 244  Training loss = 4.2454  Validation loss = 4.0632  \n",
      "\n",
      "Fold: 11  Epoch: 245  Training loss = 4.2451  Validation loss = 4.0629  \n",
      "\n",
      "Fold: 11  Epoch: 246  Training loss = 4.2448  Validation loss = 4.0625  \n",
      "\n",
      "Fold: 11  Epoch: 247  Training loss = 4.2445  Validation loss = 4.0620  \n",
      "\n",
      "Fold: 11  Epoch: 248  Training loss = 4.2442  Validation loss = 4.0616  \n",
      "\n",
      "Fold: 11  Epoch: 249  Training loss = 4.2439  Validation loss = 4.0612  \n",
      "\n",
      "Fold: 11  Epoch: 250  Training loss = 4.2436  Validation loss = 4.0609  \n",
      "\n",
      "Fold: 11  Epoch: 251  Training loss = 4.2434  Validation loss = 4.0606  \n",
      "\n",
      "Fold: 11  Epoch: 252  Training loss = 4.2431  Validation loss = 4.0602  \n",
      "\n",
      "Fold: 11  Epoch: 253  Training loss = 4.2428  Validation loss = 4.0599  \n",
      "\n",
      "Fold: 11  Epoch: 254  Training loss = 4.2425  Validation loss = 4.0594  \n",
      "\n",
      "Fold: 11  Epoch: 255  Training loss = 4.2423  Validation loss = 4.0591  \n",
      "\n",
      "Fold: 11  Epoch: 256  Training loss = 4.2420  Validation loss = 4.0588  \n",
      "\n",
      "Fold: 11  Epoch: 257  Training loss = 4.2417  Validation loss = 4.0584  \n",
      "\n",
      "Fold: 11  Epoch: 258  Training loss = 4.2413  Validation loss = 4.0580  \n",
      "\n",
      "Fold: 11  Epoch: 259  Training loss = 4.2410  Validation loss = 4.0576  \n",
      "\n",
      "Fold: 11  Epoch: 260  Training loss = 4.2408  Validation loss = 4.0573  \n",
      "\n",
      "Fold: 11  Epoch: 261  Training loss = 4.2405  Validation loss = 4.0569  \n",
      "\n",
      "Fold: 11  Epoch: 262  Training loss = 4.2403  Validation loss = 4.0566  \n",
      "\n",
      "Fold: 11  Epoch: 263  Training loss = 4.2400  Validation loss = 4.0562  \n",
      "\n",
      "Fold: 11  Epoch: 264  Training loss = 4.2397  Validation loss = 4.0558  \n",
      "\n",
      "Fold: 11  Epoch: 265  Training loss = 4.2394  Validation loss = 4.0554  \n",
      "\n",
      "Fold: 11  Epoch: 266  Training loss = 4.2391  Validation loss = 4.0551  \n",
      "\n",
      "Fold: 11  Epoch: 267  Training loss = 4.2388  Validation loss = 4.0547  \n",
      "\n",
      "Fold: 11  Epoch: 268  Training loss = 4.2386  Validation loss = 4.0543  \n",
      "\n",
      "Fold: 11  Epoch: 269  Training loss = 4.2383  Validation loss = 4.0540  \n",
      "\n",
      "Fold: 11  Epoch: 270  Training loss = 4.2379  Validation loss = 4.0535  \n",
      "\n",
      "Fold: 11  Epoch: 271  Training loss = 4.2377  Validation loss = 4.0532  \n",
      "\n",
      "Fold: 11  Epoch: 272  Training loss = 4.2374  Validation loss = 4.0528  \n",
      "\n",
      "Fold: 11  Epoch: 273  Training loss = 4.2371  Validation loss = 4.0525  \n",
      "\n",
      "Fold: 11  Epoch: 274  Training loss = 4.2369  Validation loss = 4.0521  \n",
      "\n",
      "Fold: 11  Epoch: 275  Training loss = 4.2366  Validation loss = 4.0518  \n",
      "\n",
      "Fold: 11  Epoch: 276  Training loss = 4.2364  Validation loss = 4.0514  \n",
      "\n",
      "Fold: 11  Epoch: 277  Training loss = 4.2362  Validation loss = 4.0512  \n",
      "\n",
      "Fold: 11  Epoch: 278  Training loss = 4.2359  Validation loss = 4.0508  \n",
      "\n",
      "Fold: 11  Epoch: 279  Training loss = 4.2356  Validation loss = 4.0504  \n",
      "\n",
      "Fold: 11  Epoch: 280  Training loss = 4.2353  Validation loss = 4.0500  \n",
      "\n",
      "Fold: 11  Epoch: 281  Training loss = 4.2350  Validation loss = 4.0496  \n",
      "\n",
      "Fold: 11  Epoch: 282  Training loss = 4.2347  Validation loss = 4.0493  \n",
      "\n",
      "Fold: 11  Epoch: 283  Training loss = 4.2345  Validation loss = 4.0489  \n",
      "\n",
      "Fold: 11  Epoch: 284  Training loss = 4.2341  Validation loss = 4.0484  \n",
      "\n",
      "Fold: 11  Epoch: 285  Training loss = 4.2338  Validation loss = 4.0480  \n",
      "\n",
      "Fold: 11  Epoch: 286  Training loss = 4.2335  Validation loss = 4.0476  \n",
      "\n",
      "Fold: 11  Epoch: 287  Training loss = 4.2333  Validation loss = 4.0473  \n",
      "\n",
      "Fold: 11  Epoch: 288  Training loss = 4.2329  Validation loss = 4.0468  \n",
      "\n",
      "Fold: 11  Epoch: 289  Training loss = 4.2326  Validation loss = 4.0464  \n",
      "\n",
      "Fold: 11  Epoch: 290  Training loss = 4.2324  Validation loss = 4.0460  \n",
      "\n",
      "Fold: 11  Epoch: 291  Training loss = 4.2321  Validation loss = 4.0456  \n",
      "\n",
      "Fold: 11  Epoch: 292  Training loss = 4.2318  Validation loss = 4.0453  \n",
      "\n",
      "Fold: 11  Epoch: 293  Training loss = 4.2316  Validation loss = 4.0449  \n",
      "\n",
      "Fold: 11  Epoch: 294  Training loss = 4.2312  Validation loss = 4.0445  \n",
      "\n",
      "Fold: 11  Epoch: 295  Training loss = 4.2309  Validation loss = 4.0441  \n",
      "\n",
      "Fold: 11  Epoch: 296  Training loss = 4.2305  Validation loss = 4.0437  \n",
      "\n",
      "Fold: 11  Epoch: 297  Training loss = 4.2302  Validation loss = 4.0433  \n",
      "\n",
      "Fold: 11  Epoch: 298  Training loss = 4.2300  Validation loss = 4.0429  \n",
      "\n",
      "Fold: 11  Epoch: 299  Training loss = 4.2298  Validation loss = 4.0426  \n",
      "\n",
      "Fold: 11  Epoch: 300  Training loss = 4.2295  Validation loss = 4.0422  \n",
      "\n",
      "Fold: 11  Epoch: 301  Training loss = 4.2292  Validation loss = 4.0418  \n",
      "\n",
      "Fold: 11  Epoch: 302  Training loss = 4.2289  Validation loss = 4.0414  \n",
      "\n",
      "Fold: 11  Epoch: 303  Training loss = 4.2286  Validation loss = 4.0411  \n",
      "\n",
      "Fold: 11  Epoch: 304  Training loss = 4.2283  Validation loss = 4.0407  \n",
      "\n",
      "Fold: 11  Epoch: 305  Training loss = 4.2279  Validation loss = 4.0402  \n",
      "\n",
      "Fold: 11  Epoch: 306  Training loss = 4.2276  Validation loss = 4.0399  \n",
      "\n",
      "Fold: 11  Epoch: 307  Training loss = 4.2274  Validation loss = 4.0395  \n",
      "\n",
      "Fold: 11  Epoch: 308  Training loss = 4.2271  Validation loss = 4.0391  \n",
      "\n",
      "Fold: 11  Epoch: 309  Training loss = 4.2268  Validation loss = 4.0388  \n",
      "\n",
      "Fold: 11  Epoch: 310  Training loss = 4.2265  Validation loss = 4.0384  \n",
      "\n",
      "Fold: 11  Epoch: 311  Training loss = 4.2263  Validation loss = 4.0381  \n",
      "\n",
      "Fold: 11  Epoch: 312  Training loss = 4.2260  Validation loss = 4.0377  \n",
      "\n",
      "Fold: 11  Epoch: 313  Training loss = 4.2257  Validation loss = 4.0374  \n",
      "\n",
      "Fold: 11  Epoch: 314  Training loss = 4.2255  Validation loss = 4.0371  \n",
      "\n",
      "Fold: 11  Epoch: 315  Training loss = 4.2252  Validation loss = 4.0366  \n",
      "\n",
      "Fold: 11  Epoch: 316  Training loss = 4.2249  Validation loss = 4.0362  \n",
      "\n",
      "Fold: 11  Epoch: 317  Training loss = 4.2246  Validation loss = 4.0358  \n",
      "\n",
      "Fold: 11  Epoch: 318  Training loss = 4.2243  Validation loss = 4.0355  \n",
      "\n",
      "Fold: 11  Epoch: 319  Training loss = 4.2240  Validation loss = 4.0350  \n",
      "\n",
      "Fold: 11  Epoch: 320  Training loss = 4.2237  Validation loss = 4.0346  \n",
      "\n",
      "Fold: 11  Epoch: 321  Training loss = 4.2234  Validation loss = 4.0343  \n",
      "\n",
      "Fold: 11  Epoch: 322  Training loss = 4.2231  Validation loss = 4.0338  \n",
      "\n",
      "Fold: 11  Epoch: 323  Training loss = 4.2229  Validation loss = 4.0335  \n",
      "\n",
      "Fold: 11  Epoch: 324  Training loss = 4.2226  Validation loss = 4.0332  \n",
      "\n",
      "Fold: 11  Epoch: 325  Training loss = 4.2223  Validation loss = 4.0328  \n",
      "\n",
      "Fold: 11  Epoch: 326  Training loss = 4.2220  Validation loss = 4.0324  \n",
      "\n",
      "Fold: 11  Epoch: 327  Training loss = 4.2218  Validation loss = 4.0321  \n",
      "\n",
      "Fold: 11  Epoch: 328  Training loss = 4.2215  Validation loss = 4.0318  \n",
      "\n",
      "Fold: 11  Epoch: 329  Training loss = 4.2212  Validation loss = 4.0313  \n",
      "\n",
      "Fold: 11  Epoch: 330  Training loss = 4.2209  Validation loss = 4.0310  \n",
      "\n",
      "Fold: 11  Epoch: 331  Training loss = 4.2206  Validation loss = 4.0306  \n",
      "\n",
      "Fold: 11  Epoch: 332  Training loss = 4.2204  Validation loss = 4.0302  \n",
      "\n",
      "Fold: 11  Epoch: 333  Training loss = 4.2201  Validation loss = 4.0299  \n",
      "\n",
      "Fold: 11  Epoch: 334  Training loss = 4.2198  Validation loss = 4.0295  \n",
      "\n",
      "Fold: 11  Epoch: 335  Training loss = 4.2195  Validation loss = 4.0292  \n",
      "\n",
      "Fold: 11  Epoch: 336  Training loss = 4.2192  Validation loss = 4.0288  \n",
      "\n",
      "Fold: 11  Epoch: 337  Training loss = 4.2190  Validation loss = 4.0284  \n",
      "\n",
      "Fold: 11  Epoch: 338  Training loss = 4.2187  Validation loss = 4.0281  \n",
      "\n",
      "Fold: 11  Epoch: 339  Training loss = 4.2184  Validation loss = 4.0277  \n",
      "\n",
      "Fold: 11  Epoch: 340  Training loss = 4.2181  Validation loss = 4.0273  \n",
      "\n",
      "Fold: 11  Epoch: 341  Training loss = 4.2178  Validation loss = 4.0269  \n",
      "\n",
      "Fold: 11  Epoch: 342  Training loss = 4.2174  Validation loss = 4.0265  \n",
      "\n",
      "Fold: 11  Epoch: 343  Training loss = 4.2172  Validation loss = 4.0261  \n",
      "\n",
      "Fold: 11  Epoch: 344  Training loss = 4.2168  Validation loss = 4.0257  \n",
      "\n",
      "Fold: 11  Epoch: 345  Training loss = 4.2166  Validation loss = 4.0254  \n",
      "\n",
      "Fold: 11  Epoch: 346  Training loss = 4.2163  Validation loss = 4.0250  \n",
      "\n",
      "Fold: 11  Epoch: 347  Training loss = 4.2160  Validation loss = 4.0246  \n",
      "\n",
      "Fold: 11  Epoch: 348  Training loss = 4.2157  Validation loss = 4.0242  \n",
      "\n",
      "Fold: 11  Epoch: 349  Training loss = 4.2155  Validation loss = 4.0239  \n",
      "\n",
      "Fold: 11  Epoch: 350  Training loss = 4.2152  Validation loss = 4.0235  \n",
      "\n",
      "Fold: 11  Epoch: 351  Training loss = 4.2149  Validation loss = 4.0232  \n",
      "\n",
      "Fold: 11  Epoch: 352  Training loss = 4.2147  Validation loss = 4.0228  \n",
      "\n",
      "Fold: 11  Epoch: 353  Training loss = 4.2143  Validation loss = 4.0223  \n",
      "\n",
      "Fold: 11  Epoch: 354  Training loss = 4.2141  Validation loss = 4.0221  \n",
      "\n",
      "Fold: 11  Epoch: 355  Training loss = 4.2138  Validation loss = 4.0217  \n",
      "\n",
      "Fold: 11  Epoch: 356  Training loss = 4.2135  Validation loss = 4.0213  \n",
      "\n",
      "Fold: 11  Epoch: 357  Training loss = 4.2133  Validation loss = 4.0210  \n",
      "\n",
      "Fold: 11  Epoch: 358  Training loss = 4.2130  Validation loss = 4.0206  \n",
      "\n",
      "Fold: 11  Epoch: 359  Training loss = 4.2128  Validation loss = 4.0203  \n",
      "\n",
      "Fold: 11  Epoch: 360  Training loss = 4.2125  Validation loss = 4.0199  \n",
      "\n",
      "Fold: 11  Epoch: 361  Training loss = 4.2122  Validation loss = 4.0195  \n",
      "\n",
      "Fold: 11  Epoch: 362  Training loss = 4.2119  Validation loss = 4.0191  \n",
      "\n",
      "Fold: 11  Epoch: 363  Training loss = 4.2116  Validation loss = 4.0186  \n",
      "\n",
      "Fold: 11  Epoch: 364  Training loss = 4.2113  Validation loss = 4.0182  \n",
      "\n",
      "Fold: 11  Epoch: 365  Training loss = 4.2110  Validation loss = 4.0178  \n",
      "\n",
      "Fold: 11  Epoch: 366  Training loss = 4.2107  Validation loss = 4.0175  \n",
      "\n",
      "Fold: 11  Epoch: 367  Training loss = 4.2104  Validation loss = 4.0172  \n",
      "\n",
      "Fold: 11  Epoch: 368  Training loss = 4.2101  Validation loss = 4.0168  \n",
      "\n",
      "Fold: 11  Epoch: 369  Training loss = 4.2099  Validation loss = 4.0164  \n",
      "\n",
      "Fold: 11  Epoch: 370  Training loss = 4.2097  Validation loss = 4.0161  \n",
      "\n",
      "Fold: 11  Epoch: 371  Training loss = 4.2093  Validation loss = 4.0156  \n",
      "\n",
      "Fold: 11  Epoch: 372  Training loss = 4.2090  Validation loss = 4.0152  \n",
      "\n",
      "Fold: 11  Epoch: 373  Training loss = 4.2088  Validation loss = 4.0149  \n",
      "\n",
      "Fold: 11  Epoch: 374  Training loss = 4.2085  Validation loss = 4.0146  \n",
      "\n",
      "Fold: 11  Epoch: 375  Training loss = 4.2082  Validation loss = 4.0142  \n",
      "\n",
      "Fold: 11  Epoch: 376  Training loss = 4.2079  Validation loss = 4.0139  \n",
      "\n",
      "Fold: 11  Epoch: 377  Training loss = 4.2077  Validation loss = 4.0136  \n",
      "\n",
      "Fold: 11  Epoch: 378  Training loss = 4.2075  Validation loss = 4.0132  \n",
      "\n",
      "Fold: 11  Epoch: 379  Training loss = 4.2073  Validation loss = 4.0129  \n",
      "\n",
      "Fold: 11  Epoch: 380  Training loss = 4.2070  Validation loss = 4.0125  \n",
      "\n",
      "Fold: 11  Epoch: 381  Training loss = 4.2068  Validation loss = 4.0122  \n",
      "\n",
      "Fold: 11  Epoch: 382  Training loss = 4.2064  Validation loss = 4.0117  \n",
      "\n",
      "Fold: 11  Epoch: 383  Training loss = 4.2061  Validation loss = 4.0113  \n",
      "\n",
      "Fold: 11  Epoch: 384  Training loss = 4.2058  Validation loss = 4.0109  \n",
      "\n",
      "Fold: 11  Epoch: 385  Training loss = 4.2056  Validation loss = 4.0106  \n",
      "\n",
      "Fold: 11  Epoch: 386  Training loss = 4.2053  Validation loss = 4.0102  \n",
      "\n",
      "Fold: 11  Epoch: 387  Training loss = 4.2051  Validation loss = 4.0100  \n",
      "\n",
      "Fold: 11  Epoch: 388  Training loss = 4.2049  Validation loss = 4.0096  \n",
      "\n",
      "Fold: 11  Epoch: 389  Training loss = 4.2045  Validation loss = 4.0092  \n",
      "\n",
      "Fold: 11  Epoch: 390  Training loss = 4.2043  Validation loss = 4.0088  \n",
      "\n",
      "Fold: 11  Epoch: 391  Training loss = 4.2039  Validation loss = 4.0083  \n",
      "\n",
      "Fold: 11  Epoch: 392  Training loss = 4.2037  Validation loss = 4.0079  \n",
      "\n",
      "Fold: 11  Epoch: 393  Training loss = 4.2034  Validation loss = 4.0075  \n",
      "\n",
      "Fold: 11  Epoch: 394  Training loss = 4.2031  Validation loss = 4.0072  \n",
      "\n",
      "Fold: 11  Epoch: 395  Training loss = 4.2028  Validation loss = 4.0068  \n",
      "\n",
      "Fold: 11  Epoch: 396  Training loss = 4.2025  Validation loss = 4.0064  \n",
      "\n",
      "Fold: 11  Epoch: 397  Training loss = 4.2022  Validation loss = 4.0060  \n",
      "\n",
      "Fold: 11  Epoch: 398  Training loss = 4.2019  Validation loss = 4.0056  \n",
      "\n",
      "Fold: 11  Epoch: 399  Training loss = 4.2016  Validation loss = 4.0052  \n",
      "\n",
      "Fold: 11  Epoch: 400  Training loss = 4.2014  Validation loss = 4.0048  \n",
      "\n",
      "Fold: 11  Epoch: 401  Training loss = 4.2011  Validation loss = 4.0044  \n",
      "\n",
      "Fold: 11  Epoch: 402  Training loss = 4.2008  Validation loss = 4.0040  \n",
      "\n",
      "Fold: 11  Epoch: 403  Training loss = 4.2004  Validation loss = 4.0036  \n",
      "\n",
      "Fold: 11  Epoch: 404  Training loss = 4.2002  Validation loss = 4.0032  \n",
      "\n",
      "Fold: 11  Epoch: 405  Training loss = 4.1999  Validation loss = 4.0028  \n",
      "\n",
      "Fold: 11  Epoch: 406  Training loss = 4.1996  Validation loss = 4.0024  \n",
      "\n",
      "Fold: 11  Epoch: 407  Training loss = 4.1992  Validation loss = 4.0020  \n",
      "\n",
      "Fold: 11  Epoch: 408  Training loss = 4.1990  Validation loss = 4.0017  \n",
      "\n",
      "Fold: 11  Epoch: 409  Training loss = 4.1987  Validation loss = 4.0012  \n",
      "\n",
      "Fold: 11  Epoch: 410  Training loss = 4.1984  Validation loss = 4.0009  \n",
      "\n",
      "Fold: 11  Epoch: 411  Training loss = 4.1982  Validation loss = 4.0005  \n",
      "\n",
      "Fold: 11  Epoch: 412  Training loss = 4.1978  Validation loss = 4.0001  \n",
      "\n",
      "Fold: 11  Epoch: 413  Training loss = 4.1976  Validation loss = 3.9997  \n",
      "\n",
      "Fold: 11  Epoch: 414  Training loss = 4.1973  Validation loss = 3.9994  \n",
      "\n",
      "Fold: 11  Epoch: 415  Training loss = 4.1970  Validation loss = 3.9990  \n",
      "\n",
      "Fold: 11  Epoch: 416  Training loss = 4.1967  Validation loss = 3.9986  \n",
      "\n",
      "Fold: 11  Epoch: 417  Training loss = 4.1963  Validation loss = 3.9981  \n",
      "\n",
      "Fold: 11  Epoch: 418  Training loss = 4.1960  Validation loss = 3.9978  \n",
      "\n",
      "Fold: 11  Epoch: 419  Training loss = 4.1958  Validation loss = 3.9975  \n",
      "\n",
      "Fold: 11  Epoch: 420  Training loss = 4.1955  Validation loss = 3.9971  \n",
      "\n",
      "Fold: 11  Epoch: 421  Training loss = 4.1953  Validation loss = 3.9968  \n",
      "\n",
      "Fold: 11  Epoch: 422  Training loss = 4.1950  Validation loss = 3.9964  \n",
      "\n",
      "Fold: 11  Epoch: 423  Training loss = 4.1946  Validation loss = 3.9959  \n",
      "\n",
      "Fold: 11  Epoch: 424  Training loss = 4.1943  Validation loss = 3.9955  \n",
      "\n",
      "Fold: 11  Epoch: 425  Training loss = 4.1941  Validation loss = 3.9952  \n",
      "\n",
      "Fold: 11  Epoch: 426  Training loss = 4.1939  Validation loss = 3.9949  \n",
      "\n",
      "Fold: 11  Epoch: 427  Training loss = 4.1936  Validation loss = 3.9945  \n",
      "\n",
      "Fold: 11  Epoch: 428  Training loss = 4.1934  Validation loss = 3.9942  \n",
      "\n",
      "Fold: 11  Epoch: 429  Training loss = 4.1931  Validation loss = 3.9939  \n",
      "\n",
      "Fold: 11  Epoch: 430  Training loss = 4.1927  Validation loss = 3.9933  \n",
      "\n",
      "Fold: 11  Epoch: 431  Training loss = 4.1925  Validation loss = 3.9930  \n",
      "\n",
      "Fold: 11  Epoch: 432  Training loss = 4.1923  Validation loss = 3.9927  \n",
      "\n",
      "Fold: 11  Epoch: 433  Training loss = 4.1920  Validation loss = 3.9923  \n",
      "\n",
      "Fold: 11  Epoch: 434  Training loss = 4.1917  Validation loss = 3.9920  \n",
      "\n",
      "Fold: 11  Epoch: 435  Training loss = 4.1915  Validation loss = 3.9916  \n",
      "\n",
      "Fold: 11  Epoch: 436  Training loss = 4.1913  Validation loss = 3.9913  \n",
      "\n",
      "Fold: 11  Epoch: 437  Training loss = 4.1910  Validation loss = 3.9910  \n",
      "\n",
      "Fold: 11  Epoch: 438  Training loss = 4.1907  Validation loss = 3.9906  \n",
      "\n",
      "Fold: 11  Epoch: 439  Training loss = 4.1904  Validation loss = 3.9902  \n",
      "\n",
      "Fold: 11  Epoch: 440  Training loss = 4.1902  Validation loss = 3.9899  \n",
      "\n",
      "Fold: 11  Epoch: 441  Training loss = 4.1900  Validation loss = 3.9897  \n",
      "\n",
      "Fold: 11  Epoch: 442  Training loss = 4.1898  Validation loss = 3.9894  \n",
      "\n",
      "Fold: 11  Epoch: 443  Training loss = 4.1896  Validation loss = 3.9891  \n",
      "\n",
      "Fold: 11  Epoch: 444  Training loss = 4.1893  Validation loss = 3.9887  \n",
      "\n",
      "Fold: 11  Epoch: 445  Training loss = 4.1891  Validation loss = 3.9885  \n",
      "\n",
      "Fold: 11  Epoch: 446  Training loss = 4.1889  Validation loss = 3.9881  \n",
      "\n",
      "Fold: 11  Epoch: 447  Training loss = 4.1886  Validation loss = 3.9878  \n",
      "\n",
      "Fold: 11  Epoch: 448  Training loss = 4.1883  Validation loss = 3.9874  \n",
      "\n",
      "Fold: 11  Epoch: 449  Training loss = 4.1880  Validation loss = 3.9870  \n",
      "\n",
      "Fold: 11  Epoch: 450  Training loss = 4.1878  Validation loss = 3.9866  \n",
      "\n",
      "Fold: 11  Epoch: 451  Training loss = 4.1874  Validation loss = 3.9862  \n",
      "\n",
      "Fold: 11  Epoch: 452  Training loss = 4.1870  Validation loss = 3.9857  \n",
      "\n",
      "Fold: 11  Epoch: 453  Training loss = 4.1868  Validation loss = 3.9854  \n",
      "\n",
      "Fold: 11  Epoch: 454  Training loss = 4.1865  Validation loss = 3.9850  \n",
      "\n",
      "Fold: 11  Epoch: 455  Training loss = 4.1862  Validation loss = 3.9846  \n",
      "\n",
      "Fold: 11  Epoch: 456  Training loss = 4.1859  Validation loss = 3.9842  \n",
      "\n",
      "Fold: 11  Epoch: 457  Training loss = 4.1857  Validation loss = 3.9838  \n",
      "\n",
      "Fold: 11  Epoch: 458  Training loss = 4.1854  Validation loss = 3.9834  \n",
      "\n",
      "Fold: 11  Epoch: 459  Training loss = 4.1851  Validation loss = 3.9832  \n",
      "\n",
      "Fold: 11  Epoch: 460  Training loss = 4.1849  Validation loss = 3.9828  \n",
      "\n",
      "Fold: 11  Epoch: 461  Training loss = 4.1845  Validation loss = 3.9824  \n",
      "\n",
      "Fold: 11  Epoch: 462  Training loss = 4.1842  Validation loss = 3.9820  \n",
      "\n",
      "Fold: 11  Epoch: 463  Training loss = 4.1839  Validation loss = 3.9815  \n",
      "\n",
      "Fold: 11  Epoch: 464  Training loss = 4.1836  Validation loss = 3.9811  \n",
      "\n",
      "Fold: 11  Epoch: 465  Training loss = 4.1832  Validation loss = 3.9806  \n",
      "\n",
      "Fold: 11  Epoch: 466  Training loss = 4.1830  Validation loss = 3.9803  \n",
      "\n",
      "Fold: 11  Epoch: 467  Training loss = 4.1828  Validation loss = 3.9799  \n",
      "\n",
      "Fold: 11  Epoch: 468  Training loss = 4.1825  Validation loss = 3.9796  \n",
      "\n",
      "Fold: 11  Epoch: 469  Training loss = 4.1822  Validation loss = 3.9791  \n",
      "\n",
      "Fold: 11  Epoch: 470  Training loss = 4.1819  Validation loss = 3.9788  \n",
      "\n",
      "Fold: 11  Epoch: 471  Training loss = 4.1817  Validation loss = 3.9784  \n",
      "\n",
      "Fold: 11  Epoch: 472  Training loss = 4.1814  Validation loss = 3.9780  \n",
      "\n",
      "Fold: 11  Epoch: 473  Training loss = 4.1811  Validation loss = 3.9777  \n",
      "\n",
      "Fold: 11  Epoch: 474  Training loss = 4.1808  Validation loss = 3.9773  \n",
      "\n",
      "Fold: 11  Epoch: 475  Training loss = 4.1806  Validation loss = 3.9769  \n",
      "\n",
      "Fold: 11  Epoch: 476  Training loss = 4.1802  Validation loss = 3.9765  \n",
      "\n",
      "Fold: 11  Epoch: 477  Training loss = 4.1799  Validation loss = 3.9761  \n",
      "\n",
      "Fold: 11  Epoch: 478  Training loss = 4.1797  Validation loss = 3.9757  \n",
      "\n",
      "Fold: 11  Epoch: 479  Training loss = 4.1794  Validation loss = 3.9754  \n",
      "\n",
      "Fold: 11  Epoch: 480  Training loss = 4.1792  Validation loss = 3.9750  \n",
      "\n",
      "Fold: 11  Epoch: 481  Training loss = 4.1789  Validation loss = 3.9746  \n",
      "\n",
      "Fold: 11  Epoch: 482  Training loss = 4.1786  Validation loss = 3.9742  \n",
      "\n",
      "Fold: 11  Epoch: 483  Training loss = 4.1783  Validation loss = 3.9738  \n",
      "\n",
      "Fold: 11  Epoch: 484  Training loss = 4.1780  Validation loss = 3.9734  \n",
      "\n",
      "Fold: 11  Epoch: 485  Training loss = 4.1777  Validation loss = 3.9730  \n",
      "\n",
      "Fold: 11  Epoch: 486  Training loss = 4.1774  Validation loss = 3.9726  \n",
      "\n",
      "Fold: 11  Epoch: 487  Training loss = 4.1771  Validation loss = 3.9722  \n",
      "\n",
      "Fold: 11  Epoch: 488  Training loss = 4.1768  Validation loss = 3.9718  \n",
      "\n",
      "Fold: 11  Epoch: 489  Training loss = 4.1765  Validation loss = 3.9714  \n",
      "\n",
      "Fold: 11  Epoch: 490  Training loss = 4.1761  Validation loss = 3.9709  \n",
      "\n",
      "Fold: 11  Epoch: 491  Training loss = 4.1758  Validation loss = 3.9704  \n",
      "\n",
      "Fold: 11  Epoch: 492  Training loss = 4.1754  Validation loss = 3.9700  \n",
      "\n",
      "Fold: 11  Epoch: 493  Training loss = 4.1752  Validation loss = 3.9696  \n",
      "\n",
      "Fold: 11  Epoch: 494  Training loss = 4.1748  Validation loss = 3.9692  \n",
      "\n",
      "Fold: 11  Epoch: 495  Training loss = 4.1745  Validation loss = 3.9687  \n",
      "\n",
      "Fold: 11  Epoch: 496  Training loss = 4.1742  Validation loss = 3.9683  \n",
      "\n",
      "Fold: 11  Epoch: 497  Training loss = 4.1739  Validation loss = 3.9679  \n",
      "\n",
      "Fold: 11  Epoch: 498  Training loss = 4.1737  Validation loss = 3.9676  \n",
      "\n",
      "Fold: 11  Epoch: 499  Training loss = 4.1733  Validation loss = 3.9672  \n",
      "\n",
      "Fold: 11  Epoch: 500  Training loss = 4.1731  Validation loss = 3.9669  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 500  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 4.2775  Validation loss = 5.4327  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 4.2772  Validation loss = 5.4321  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 4.2769  Validation loss = 5.4317  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 4.2765  Validation loss = 5.4310  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 4.2762  Validation loss = 5.4305  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 4.2759  Validation loss = 5.4300  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 4.2755  Validation loss = 5.4294  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 4.2753  Validation loss = 5.4289  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 4.2749  Validation loss = 5.4284  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 4.2746  Validation loss = 5.4278  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 4.2742  Validation loss = 5.4269  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 4.2739  Validation loss = 5.4264  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 4.2736  Validation loss = 5.4259  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 4.2733  Validation loss = 5.4255  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 4.2730  Validation loss = 5.4250  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 4.2728  Validation loss = 5.4247  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 4.2725  Validation loss = 5.4242  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 4.2721  Validation loss = 5.4235  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 4.2717  Validation loss = 5.4228  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 4.2715  Validation loss = 5.4224  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 4.2712  Validation loss = 5.4219  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 4.2709  Validation loss = 5.4215  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 4.2706  Validation loss = 5.4209  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 4.2702  Validation loss = 5.4202  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 4.2700  Validation loss = 5.4198  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 4.2696  Validation loss = 5.4192  \n",
      "\n",
      "Fold: 12  Epoch: 27  Training loss = 4.2694  Validation loss = 5.4188  \n",
      "\n",
      "Fold: 12  Epoch: 28  Training loss = 4.2690  Validation loss = 5.4183  \n",
      "\n",
      "Fold: 12  Epoch: 29  Training loss = 4.2687  Validation loss = 5.4176  \n",
      "\n",
      "Fold: 12  Epoch: 30  Training loss = 4.2683  Validation loss = 5.4169  \n",
      "\n",
      "Fold: 12  Epoch: 31  Training loss = 4.2679  Validation loss = 5.4163  \n",
      "\n",
      "Fold: 12  Epoch: 32  Training loss = 4.2676  Validation loss = 5.4158  \n",
      "\n",
      "Fold: 12  Epoch: 33  Training loss = 4.2673  Validation loss = 5.4153  \n",
      "\n",
      "Fold: 12  Epoch: 34  Training loss = 4.2671  Validation loss = 5.4149  \n",
      "\n",
      "Fold: 12  Epoch: 35  Training loss = 4.2668  Validation loss = 5.4144  \n",
      "\n",
      "Fold: 12  Epoch: 36  Training loss = 4.2664  Validation loss = 5.4138  \n",
      "\n",
      "Fold: 12  Epoch: 37  Training loss = 4.2661  Validation loss = 5.4134  \n",
      "\n",
      "Fold: 12  Epoch: 38  Training loss = 4.2658  Validation loss = 5.4129  \n",
      "\n",
      "Fold: 12  Epoch: 39  Training loss = 4.2655  Validation loss = 5.4123  \n",
      "\n",
      "Fold: 12  Epoch: 40  Training loss = 4.2652  Validation loss = 5.4118  \n",
      "\n",
      "Fold: 12  Epoch: 41  Training loss = 4.2649  Validation loss = 5.4113  \n",
      "\n",
      "Fold: 12  Epoch: 42  Training loss = 4.2646  Validation loss = 5.4108  \n",
      "\n",
      "Fold: 12  Epoch: 43  Training loss = 4.2643  Validation loss = 5.4104  \n",
      "\n",
      "Fold: 12  Epoch: 44  Training loss = 4.2640  Validation loss = 5.4100  \n",
      "\n",
      "Fold: 12  Epoch: 45  Training loss = 4.2637  Validation loss = 5.4094  \n",
      "\n",
      "Fold: 12  Epoch: 46  Training loss = 4.2634  Validation loss = 5.4090  \n",
      "\n",
      "Fold: 12  Epoch: 47  Training loss = 4.2631  Validation loss = 5.4085  \n",
      "\n",
      "Fold: 12  Epoch: 48  Training loss = 4.2627  Validation loss = 5.4078  \n",
      "\n",
      "Fold: 12  Epoch: 49  Training loss = 4.2624  Validation loss = 5.4072  \n",
      "\n",
      "Fold: 12  Epoch: 50  Training loss = 4.2621  Validation loss = 5.4069  \n",
      "\n",
      "Fold: 12  Epoch: 51  Training loss = 4.2618  Validation loss = 5.4063  \n",
      "\n",
      "Fold: 12  Epoch: 52  Training loss = 4.2614  Validation loss = 5.4056  \n",
      "\n",
      "Fold: 12  Epoch: 53  Training loss = 4.2611  Validation loss = 5.4052  \n",
      "\n",
      "Fold: 12  Epoch: 54  Training loss = 4.2607  Validation loss = 5.4045  \n",
      "\n",
      "Fold: 12  Epoch: 55  Training loss = 4.2604  Validation loss = 5.4039  \n",
      "\n",
      "Fold: 12  Epoch: 56  Training loss = 4.2600  Validation loss = 5.4034  \n",
      "\n",
      "Fold: 12  Epoch: 57  Training loss = 4.2597  Validation loss = 5.4027  \n",
      "\n",
      "Fold: 12  Epoch: 58  Training loss = 4.2594  Validation loss = 5.4022  \n",
      "\n",
      "Fold: 12  Epoch: 59  Training loss = 4.2591  Validation loss = 5.4017  \n",
      "\n",
      "Fold: 12  Epoch: 60  Training loss = 4.2587  Validation loss = 5.4012  \n",
      "\n",
      "Fold: 12  Epoch: 61  Training loss = 4.2584  Validation loss = 5.4006  \n",
      "\n",
      "Fold: 12  Epoch: 62  Training loss = 4.2580  Validation loss = 5.4001  \n",
      "\n",
      "Fold: 12  Epoch: 63  Training loss = 4.2577  Validation loss = 5.3996  \n",
      "\n",
      "Fold: 12  Epoch: 64  Training loss = 4.2574  Validation loss = 5.3991  \n",
      "\n",
      "Fold: 12  Epoch: 65  Training loss = 4.2571  Validation loss = 5.3986  \n",
      "\n",
      "Fold: 12  Epoch: 66  Training loss = 4.2569  Validation loss = 5.3983  \n",
      "\n",
      "Fold: 12  Epoch: 67  Training loss = 4.2566  Validation loss = 5.3978  \n",
      "\n",
      "Fold: 12  Epoch: 68  Training loss = 4.2562  Validation loss = 5.3972  \n",
      "\n",
      "Fold: 12  Epoch: 69  Training loss = 4.2560  Validation loss = 5.3968  \n",
      "\n",
      "Fold: 12  Epoch: 70  Training loss = 4.2557  Validation loss = 5.3964  \n",
      "\n",
      "Fold: 12  Epoch: 71  Training loss = 4.2555  Validation loss = 5.3960  \n",
      "\n",
      "Fold: 12  Epoch: 72  Training loss = 4.2551  Validation loss = 5.3953  \n",
      "\n",
      "Fold: 12  Epoch: 73  Training loss = 4.2548  Validation loss = 5.3949  \n",
      "\n",
      "Fold: 12  Epoch: 74  Training loss = 4.2545  Validation loss = 5.3945  \n",
      "\n",
      "Fold: 12  Epoch: 75  Training loss = 4.2542  Validation loss = 5.3939  \n",
      "\n",
      "Fold: 12  Epoch: 76  Training loss = 4.2540  Validation loss = 5.3935  \n",
      "\n",
      "Fold: 12  Epoch: 77  Training loss = 4.2537  Validation loss = 5.3930  \n",
      "\n",
      "Fold: 12  Epoch: 78  Training loss = 4.2532  Validation loss = 5.3921  \n",
      "\n",
      "Fold: 12  Epoch: 79  Training loss = 4.2529  Validation loss = 5.3917  \n",
      "\n",
      "Fold: 12  Epoch: 80  Training loss = 4.2526  Validation loss = 5.3913  \n",
      "\n",
      "Fold: 12  Epoch: 81  Training loss = 4.2523  Validation loss = 5.3907  \n",
      "\n",
      "Fold: 12  Epoch: 82  Training loss = 4.2519  Validation loss = 5.3902  \n",
      "\n",
      "Fold: 12  Epoch: 83  Training loss = 4.2516  Validation loss = 5.3895  \n",
      "\n",
      "Fold: 12  Epoch: 84  Training loss = 4.2513  Validation loss = 5.3891  \n",
      "\n",
      "Fold: 12  Epoch: 85  Training loss = 4.2510  Validation loss = 5.3886  \n",
      "\n",
      "Fold: 12  Epoch: 86  Training loss = 4.2508  Validation loss = 5.3883  \n",
      "\n",
      "Fold: 12  Epoch: 87  Training loss = 4.2504  Validation loss = 5.3878  \n",
      "\n",
      "Fold: 12  Epoch: 88  Training loss = 4.2501  Validation loss = 5.3872  \n",
      "\n",
      "Fold: 12  Epoch: 89  Training loss = 4.2498  Validation loss = 5.3867  \n",
      "\n",
      "Fold: 12  Epoch: 90  Training loss = 4.2494  Validation loss = 5.3861  \n",
      "\n",
      "Fold: 12  Epoch: 91  Training loss = 4.2491  Validation loss = 5.3855  \n",
      "\n",
      "Fold: 12  Epoch: 92  Training loss = 4.2488  Validation loss = 5.3849  \n",
      "\n",
      "Fold: 12  Epoch: 93  Training loss = 4.2485  Validation loss = 5.3845  \n",
      "\n",
      "Fold: 12  Epoch: 94  Training loss = 4.2481  Validation loss = 5.3838  \n",
      "\n",
      "Fold: 12  Epoch: 95  Training loss = 4.2478  Validation loss = 5.3831  \n",
      "\n",
      "Fold: 12  Epoch: 96  Training loss = 4.2475  Validation loss = 5.3826  \n",
      "\n",
      "Fold: 12  Epoch: 97  Training loss = 4.2472  Validation loss = 5.3820  \n",
      "\n",
      "Fold: 12  Epoch: 98  Training loss = 4.2469  Validation loss = 5.3815  \n",
      "\n",
      "Fold: 12  Epoch: 99  Training loss = 4.2466  Validation loss = 5.3810  \n",
      "\n",
      "Fold: 12  Epoch: 100  Training loss = 4.2463  Validation loss = 5.3806  \n",
      "\n",
      "Fold: 12  Epoch: 101  Training loss = 4.2461  Validation loss = 5.3802  \n",
      "\n",
      "Fold: 12  Epoch: 102  Training loss = 4.2458  Validation loss = 5.3798  \n",
      "\n",
      "Fold: 12  Epoch: 103  Training loss = 4.2455  Validation loss = 5.3793  \n",
      "\n",
      "Fold: 12  Epoch: 104  Training loss = 4.2453  Validation loss = 5.3789  \n",
      "\n",
      "Fold: 12  Epoch: 105  Training loss = 4.2450  Validation loss = 5.3784  \n",
      "\n",
      "Fold: 12  Epoch: 106  Training loss = 4.2447  Validation loss = 5.3778  \n",
      "\n",
      "Fold: 12  Epoch: 107  Training loss = 4.2444  Validation loss = 5.3774  \n",
      "\n",
      "Fold: 12  Epoch: 108  Training loss = 4.2441  Validation loss = 5.3769  \n",
      "\n",
      "Fold: 12  Epoch: 109  Training loss = 4.2438  Validation loss = 5.3763  \n",
      "\n",
      "Fold: 12  Epoch: 110  Training loss = 4.2434  Validation loss = 5.3756  \n",
      "\n",
      "Fold: 12  Epoch: 111  Training loss = 4.2431  Validation loss = 5.3750  \n",
      "\n",
      "Fold: 12  Epoch: 112  Training loss = 4.2428  Validation loss = 5.3745  \n",
      "\n",
      "Fold: 12  Epoch: 113  Training loss = 4.2425  Validation loss = 5.3740  \n",
      "\n",
      "Fold: 12  Epoch: 114  Training loss = 4.2422  Validation loss = 5.3735  \n",
      "\n",
      "Fold: 12  Epoch: 115  Training loss = 4.2418  Validation loss = 5.3727  \n",
      "\n",
      "Fold: 12  Epoch: 116  Training loss = 4.2415  Validation loss = 5.3723  \n",
      "\n",
      "Fold: 12  Epoch: 117  Training loss = 4.2412  Validation loss = 5.3719  \n",
      "\n",
      "Fold: 12  Epoch: 118  Training loss = 4.2408  Validation loss = 5.3711  \n",
      "\n",
      "Fold: 12  Epoch: 119  Training loss = 4.2405  Validation loss = 5.3706  \n",
      "\n",
      "Fold: 12  Epoch: 120  Training loss = 4.2403  Validation loss = 5.3702  \n",
      "\n",
      "Fold: 12  Epoch: 121  Training loss = 4.2399  Validation loss = 5.3697  \n",
      "\n",
      "Fold: 12  Epoch: 122  Training loss = 4.2395  Validation loss = 5.3688  \n",
      "\n",
      "Fold: 12  Epoch: 123  Training loss = 4.2392  Validation loss = 5.3683  \n",
      "\n",
      "Fold: 12  Epoch: 124  Training loss = 4.2388  Validation loss = 5.3679  \n",
      "\n",
      "Fold: 12  Epoch: 125  Training loss = 4.2385  Validation loss = 5.3674  \n",
      "\n",
      "Fold: 12  Epoch: 126  Training loss = 4.2382  Validation loss = 5.3668  \n",
      "\n",
      "Fold: 12  Epoch: 127  Training loss = 4.2379  Validation loss = 5.3663  \n",
      "\n",
      "Fold: 12  Epoch: 128  Training loss = 4.2376  Validation loss = 5.3657  \n",
      "\n",
      "Fold: 12  Epoch: 129  Training loss = 4.2374  Validation loss = 5.3654  \n",
      "\n",
      "Fold: 12  Epoch: 130  Training loss = 4.2371  Validation loss = 5.3649  \n",
      "\n",
      "Fold: 12  Epoch: 131  Training loss = 4.2368  Validation loss = 5.3646  \n",
      "\n",
      "Fold: 12  Epoch: 132  Training loss = 4.2365  Validation loss = 5.3641  \n",
      "\n",
      "Fold: 12  Epoch: 133  Training loss = 4.2361  Validation loss = 5.3635  \n",
      "\n",
      "Fold: 12  Epoch: 134  Training loss = 4.2358  Validation loss = 5.3629  \n",
      "\n",
      "Fold: 12  Epoch: 135  Training loss = 4.2354  Validation loss = 5.3622  \n",
      "\n",
      "Fold: 12  Epoch: 136  Training loss = 4.2350  Validation loss = 5.3615  \n",
      "\n",
      "Fold: 12  Epoch: 137  Training loss = 4.2347  Validation loss = 5.3608  \n",
      "\n",
      "Fold: 12  Epoch: 138  Training loss = 4.2343  Validation loss = 5.3603  \n",
      "\n",
      "Fold: 12  Epoch: 139  Training loss = 4.2340  Validation loss = 5.3598  \n",
      "\n",
      "Fold: 12  Epoch: 140  Training loss = 4.2337  Validation loss = 5.3593  \n",
      "\n",
      "Fold: 12  Epoch: 141  Training loss = 4.2334  Validation loss = 5.3588  \n",
      "\n",
      "Fold: 12  Epoch: 142  Training loss = 4.2331  Validation loss = 5.3583  \n",
      "\n",
      "Fold: 12  Epoch: 143  Training loss = 4.2329  Validation loss = 5.3578  \n",
      "\n",
      "Fold: 12  Epoch: 144  Training loss = 4.2326  Validation loss = 5.3574  \n",
      "\n",
      "Fold: 12  Epoch: 145  Training loss = 4.2323  Validation loss = 5.3569  \n",
      "\n",
      "Fold: 12  Epoch: 146  Training loss = 4.2320  Validation loss = 5.3564  \n",
      "\n",
      "Fold: 12  Epoch: 147  Training loss = 4.2317  Validation loss = 5.3559  \n",
      "\n",
      "Fold: 12  Epoch: 148  Training loss = 4.2313  Validation loss = 5.3554  \n",
      "\n",
      "Fold: 12  Epoch: 149  Training loss = 4.2311  Validation loss = 5.3549  \n",
      "\n",
      "Fold: 12  Epoch: 150  Training loss = 4.2307  Validation loss = 5.3542  \n",
      "\n",
      "Fold: 12  Epoch: 151  Training loss = 4.2303  Validation loss = 5.3534  \n",
      "\n",
      "Fold: 12  Epoch: 152  Training loss = 4.2299  Validation loss = 5.3527  \n",
      "\n",
      "Fold: 12  Epoch: 153  Training loss = 4.2296  Validation loss = 5.3522  \n",
      "\n",
      "Fold: 12  Epoch: 154  Training loss = 4.2293  Validation loss = 5.3517  \n",
      "\n",
      "Fold: 12  Epoch: 155  Training loss = 4.2289  Validation loss = 5.3511  \n",
      "\n",
      "Fold: 12  Epoch: 156  Training loss = 4.2286  Validation loss = 5.3505  \n",
      "\n",
      "Fold: 12  Epoch: 157  Training loss = 4.2283  Validation loss = 5.3500  \n",
      "\n",
      "Fold: 12  Epoch: 158  Training loss = 4.2279  Validation loss = 5.3494  \n",
      "\n",
      "Fold: 12  Epoch: 159  Training loss = 4.2277  Validation loss = 5.3490  \n",
      "\n",
      "Fold: 12  Epoch: 160  Training loss = 4.2274  Validation loss = 5.3486  \n",
      "\n",
      "Fold: 12  Epoch: 161  Training loss = 4.2272  Validation loss = 5.3482  \n",
      "\n",
      "Fold: 12  Epoch: 162  Training loss = 4.2268  Validation loss = 5.3476  \n",
      "\n",
      "Fold: 12  Epoch: 163  Training loss = 4.2265  Validation loss = 5.3471  \n",
      "\n",
      "Fold: 12  Epoch: 164  Training loss = 4.2262  Validation loss = 5.3464  \n",
      "\n",
      "Fold: 12  Epoch: 165  Training loss = 4.2259  Validation loss = 5.3460  \n",
      "\n",
      "Fold: 12  Epoch: 166  Training loss = 4.2256  Validation loss = 5.3454  \n",
      "\n",
      "Fold: 12  Epoch: 167  Training loss = 4.2253  Validation loss = 5.3449  \n",
      "\n",
      "Fold: 12  Epoch: 168  Training loss = 4.2252  Validation loss = 5.3447  \n",
      "\n",
      "Fold: 12  Epoch: 169  Training loss = 4.2249  Validation loss = 5.3442  \n",
      "\n",
      "Fold: 12  Epoch: 170  Training loss = 4.2245  Validation loss = 5.3435  \n",
      "\n",
      "Fold: 12  Epoch: 171  Training loss = 4.2240  Validation loss = 5.3426  \n",
      "\n",
      "Fold: 12  Epoch: 172  Training loss = 4.2237  Validation loss = 5.3422  \n",
      "\n",
      "Fold: 12  Epoch: 173  Training loss = 4.2234  Validation loss = 5.3415  \n",
      "\n",
      "Fold: 12  Epoch: 174  Training loss = 4.2231  Validation loss = 5.3411  \n",
      "\n",
      "Fold: 12  Epoch: 175  Training loss = 4.2228  Validation loss = 5.3407  \n",
      "\n",
      "Fold: 12  Epoch: 176  Training loss = 4.2225  Validation loss = 5.3401  \n",
      "\n",
      "Fold: 12  Epoch: 177  Training loss = 4.2223  Validation loss = 5.3398  \n",
      "\n",
      "Fold: 12  Epoch: 178  Training loss = 4.2219  Validation loss = 5.3390  \n",
      "\n",
      "Fold: 12  Epoch: 179  Training loss = 4.2216  Validation loss = 5.3385  \n",
      "\n",
      "Fold: 12  Epoch: 180  Training loss = 4.2213  Validation loss = 5.3380  \n",
      "\n",
      "Fold: 12  Epoch: 181  Training loss = 4.2209  Validation loss = 5.3372  \n",
      "\n",
      "Fold: 12  Epoch: 182  Training loss = 4.2206  Validation loss = 5.3367  \n",
      "\n",
      "Fold: 12  Epoch: 183  Training loss = 4.2203  Validation loss = 5.3361  \n",
      "\n",
      "Fold: 12  Epoch: 184  Training loss = 4.2200  Validation loss = 5.3358  \n",
      "\n",
      "Fold: 12  Epoch: 185  Training loss = 4.2198  Validation loss = 5.3353  \n",
      "\n",
      "Fold: 12  Epoch: 186  Training loss = 4.2195  Validation loss = 5.3349  \n",
      "\n",
      "Fold: 12  Epoch: 187  Training loss = 4.2191  Validation loss = 5.3342  \n",
      "\n",
      "Fold: 12  Epoch: 188  Training loss = 4.2188  Validation loss = 5.3338  \n",
      "\n",
      "Fold: 12  Epoch: 189  Training loss = 4.2186  Validation loss = 5.3334  \n",
      "\n",
      "Fold: 12  Epoch: 190  Training loss = 4.2183  Validation loss = 5.3329  \n",
      "\n",
      "Fold: 12  Epoch: 191  Training loss = 4.2180  Validation loss = 5.3324  \n",
      "\n",
      "Fold: 12  Epoch: 192  Training loss = 4.2177  Validation loss = 5.3320  \n",
      "\n",
      "Fold: 12  Epoch: 193  Training loss = 4.2174  Validation loss = 5.3314  \n",
      "\n",
      "Fold: 12  Epoch: 194  Training loss = 4.2170  Validation loss = 5.3308  \n",
      "\n",
      "Fold: 12  Epoch: 195  Training loss = 4.2166  Validation loss = 5.3301  \n",
      "\n",
      "Fold: 12  Epoch: 196  Training loss = 4.2163  Validation loss = 5.3296  \n",
      "\n",
      "Fold: 12  Epoch: 197  Training loss = 4.2160  Validation loss = 5.3290  \n",
      "\n",
      "Fold: 12  Epoch: 198  Training loss = 4.2156  Validation loss = 5.3284  \n",
      "\n",
      "Fold: 12  Epoch: 199  Training loss = 4.2153  Validation loss = 5.3279  \n",
      "\n",
      "Fold: 12  Epoch: 200  Training loss = 4.2150  Validation loss = 5.3274  \n",
      "\n",
      "Fold: 12  Epoch: 201  Training loss = 4.2146  Validation loss = 5.3268  \n",
      "\n",
      "Fold: 12  Epoch: 202  Training loss = 4.2144  Validation loss = 5.3264  \n",
      "\n",
      "Fold: 12  Epoch: 203  Training loss = 4.2141  Validation loss = 5.3260  \n",
      "\n",
      "Fold: 12  Epoch: 204  Training loss = 4.2138  Validation loss = 5.3254  \n",
      "\n",
      "Fold: 12  Epoch: 205  Training loss = 4.2135  Validation loss = 5.3248  \n",
      "\n",
      "Fold: 12  Epoch: 206  Training loss = 4.2131  Validation loss = 5.3242  \n",
      "\n",
      "Fold: 12  Epoch: 207  Training loss = 4.2129  Validation loss = 5.3237  \n",
      "\n",
      "Fold: 12  Epoch: 208  Training loss = 4.2125  Validation loss = 5.3229  \n",
      "\n",
      "Fold: 12  Epoch: 209  Training loss = 4.2122  Validation loss = 5.3223  \n",
      "\n",
      "Fold: 12  Epoch: 210  Training loss = 4.2119  Validation loss = 5.3216  \n",
      "\n",
      "Fold: 12  Epoch: 211  Training loss = 4.2115  Validation loss = 5.3211  \n",
      "\n",
      "Fold: 12  Epoch: 212  Training loss = 4.2112  Validation loss = 5.3204  \n",
      "\n",
      "Fold: 12  Epoch: 213  Training loss = 4.2109  Validation loss = 5.3198  \n",
      "\n",
      "Fold: 12  Epoch: 214  Training loss = 4.2105  Validation loss = 5.3191  \n",
      "\n",
      "Fold: 12  Epoch: 215  Training loss = 4.2102  Validation loss = 5.3186  \n",
      "\n",
      "Fold: 12  Epoch: 216  Training loss = 4.2099  Validation loss = 5.3181  \n",
      "\n",
      "Fold: 12  Epoch: 217  Training loss = 4.2096  Validation loss = 5.3176  \n",
      "\n",
      "Fold: 12  Epoch: 218  Training loss = 4.2092  Validation loss = 5.3169  \n",
      "\n",
      "Fold: 12  Epoch: 219  Training loss = 4.2089  Validation loss = 5.3163  \n",
      "\n",
      "Fold: 12  Epoch: 220  Training loss = 4.2086  Validation loss = 5.3157  \n",
      "\n",
      "Fold: 12  Epoch: 221  Training loss = 4.2083  Validation loss = 5.3153  \n",
      "\n",
      "Fold: 12  Epoch: 222  Training loss = 4.2080  Validation loss = 5.3146  \n",
      "\n",
      "Fold: 12  Epoch: 223  Training loss = 4.2078  Validation loss = 5.3142  \n",
      "\n",
      "Fold: 12  Epoch: 224  Training loss = 4.2075  Validation loss = 5.3137  \n",
      "\n",
      "Fold: 12  Epoch: 225  Training loss = 4.2072  Validation loss = 5.3132  \n",
      "\n",
      "Fold: 12  Epoch: 226  Training loss = 4.2069  Validation loss = 5.3127  \n",
      "\n",
      "Fold: 12  Epoch: 227  Training loss = 4.2066  Validation loss = 5.3122  \n",
      "\n",
      "Fold: 12  Epoch: 228  Training loss = 4.2063  Validation loss = 5.3117  \n",
      "\n",
      "Fold: 12  Epoch: 229  Training loss = 4.2059  Validation loss = 5.3111  \n",
      "\n",
      "Fold: 12  Epoch: 230  Training loss = 4.2056  Validation loss = 5.3105  \n",
      "\n",
      "Fold: 12  Epoch: 231  Training loss = 4.2053  Validation loss = 5.3100  \n",
      "\n",
      "Fold: 12  Epoch: 232  Training loss = 4.2050  Validation loss = 5.3094  \n",
      "\n",
      "Fold: 12  Epoch: 233  Training loss = 4.2046  Validation loss = 5.3089  \n",
      "\n",
      "Fold: 12  Epoch: 234  Training loss = 4.2043  Validation loss = 5.3084  \n",
      "\n",
      "Fold: 12  Epoch: 235  Training loss = 4.2041  Validation loss = 5.3081  \n",
      "\n",
      "Fold: 12  Epoch: 236  Training loss = 4.2038  Validation loss = 5.3075  \n",
      "\n",
      "Fold: 12  Epoch: 237  Training loss = 4.2034  Validation loss = 5.3068  \n",
      "\n",
      "Fold: 12  Epoch: 238  Training loss = 4.2031  Validation loss = 5.3063  \n",
      "\n",
      "Fold: 12  Epoch: 239  Training loss = 4.2028  Validation loss = 5.3057  \n",
      "\n",
      "Fold: 12  Epoch: 240  Training loss = 4.2025  Validation loss = 5.3051  \n",
      "\n",
      "Fold: 12  Epoch: 241  Training loss = 4.2021  Validation loss = 5.3046  \n",
      "\n",
      "Fold: 12  Epoch: 242  Training loss = 4.2019  Validation loss = 5.3041  \n",
      "\n",
      "Fold: 12  Epoch: 243  Training loss = 4.2016  Validation loss = 5.3035  \n",
      "\n",
      "Fold: 12  Epoch: 244  Training loss = 4.2012  Validation loss = 5.3028  \n",
      "\n",
      "Fold: 12  Epoch: 245  Training loss = 4.2009  Validation loss = 5.3023  \n",
      "\n",
      "Fold: 12  Epoch: 246  Training loss = 4.2006  Validation loss = 5.3017  \n",
      "\n",
      "Fold: 12  Epoch: 247  Training loss = 4.2002  Validation loss = 5.3010  \n",
      "\n",
      "Fold: 12  Epoch: 248  Training loss = 4.1999  Validation loss = 5.3005  \n",
      "\n",
      "Fold: 12  Epoch: 249  Training loss = 4.1997  Validation loss = 5.3000  \n",
      "\n",
      "Fold: 12  Epoch: 250  Training loss = 4.1994  Validation loss = 5.2995  \n",
      "\n",
      "Fold: 12  Epoch: 251  Training loss = 4.1991  Validation loss = 5.2988  \n",
      "\n",
      "Fold: 12  Epoch: 252  Training loss = 4.1987  Validation loss = 5.2982  \n",
      "\n",
      "Fold: 12  Epoch: 253  Training loss = 4.1984  Validation loss = 5.2978  \n",
      "\n",
      "Fold: 12  Epoch: 254  Training loss = 4.1981  Validation loss = 5.2974  \n",
      "\n",
      "Fold: 12  Epoch: 255  Training loss = 4.1978  Validation loss = 5.2969  \n",
      "\n",
      "Fold: 12  Epoch: 256  Training loss = 4.1976  Validation loss = 5.2965  \n",
      "\n",
      "Fold: 12  Epoch: 257  Training loss = 4.1973  Validation loss = 5.2961  \n",
      "\n",
      "Fold: 12  Epoch: 258  Training loss = 4.1971  Validation loss = 5.2956  \n",
      "\n",
      "Fold: 12  Epoch: 259  Training loss = 4.1967  Validation loss = 5.2950  \n",
      "\n",
      "Fold: 12  Epoch: 260  Training loss = 4.1965  Validation loss = 5.2946  \n",
      "\n",
      "Fold: 12  Epoch: 261  Training loss = 4.1962  Validation loss = 5.2940  \n",
      "\n",
      "Fold: 12  Epoch: 262  Training loss = 4.1959  Validation loss = 5.2934  \n",
      "\n",
      "Fold: 12  Epoch: 263  Training loss = 4.1955  Validation loss = 5.2928  \n",
      "\n",
      "Fold: 12  Epoch: 264  Training loss = 4.1952  Validation loss = 5.2921  \n",
      "\n",
      "Fold: 12  Epoch: 265  Training loss = 4.1949  Validation loss = 5.2915  \n",
      "\n",
      "Fold: 12  Epoch: 266  Training loss = 4.1946  Validation loss = 5.2910  \n",
      "\n",
      "Fold: 12  Epoch: 267  Training loss = 4.1943  Validation loss = 5.2904  \n",
      "\n",
      "Fold: 12  Epoch: 268  Training loss = 4.1940  Validation loss = 5.2898  \n",
      "\n",
      "Fold: 12  Epoch: 269  Training loss = 4.1937  Validation loss = 5.2893  \n",
      "\n",
      "Fold: 12  Epoch: 270  Training loss = 4.1933  Validation loss = 5.2887  \n",
      "\n",
      "Fold: 12  Epoch: 271  Training loss = 4.1929  Validation loss = 5.2879  \n",
      "\n",
      "Fold: 12  Epoch: 272  Training loss = 4.1926  Validation loss = 5.2871  \n",
      "\n",
      "Fold: 12  Epoch: 273  Training loss = 4.1923  Validation loss = 5.2866  \n",
      "\n",
      "Fold: 12  Epoch: 274  Training loss = 4.1920  Validation loss = 5.2861  \n",
      "\n",
      "Fold: 12  Epoch: 275  Training loss = 4.1917  Validation loss = 5.2855  \n",
      "\n",
      "Fold: 12  Epoch: 276  Training loss = 4.1914  Validation loss = 5.2850  \n",
      "\n",
      "Fold: 12  Epoch: 277  Training loss = 4.1911  Validation loss = 5.2845  \n",
      "\n",
      "Fold: 12  Epoch: 278  Training loss = 4.1907  Validation loss = 5.2839  \n",
      "\n",
      "Fold: 12  Epoch: 279  Training loss = 4.1904  Validation loss = 5.2833  \n",
      "\n",
      "Fold: 12  Epoch: 280  Training loss = 4.1902  Validation loss = 5.2830  \n",
      "\n",
      "Fold: 12  Epoch: 281  Training loss = 4.1899  Validation loss = 5.2826  \n",
      "\n",
      "Fold: 12  Epoch: 282  Training loss = 4.1896  Validation loss = 5.2820  \n",
      "\n",
      "Fold: 12  Epoch: 283  Training loss = 4.1893  Validation loss = 5.2815  \n",
      "\n",
      "Fold: 12  Epoch: 284  Training loss = 4.1889  Validation loss = 5.2808  \n",
      "\n",
      "Fold: 12  Epoch: 285  Training loss = 4.1886  Validation loss = 5.2804  \n",
      "\n",
      "Fold: 12  Epoch: 286  Training loss = 4.1883  Validation loss = 5.2799  \n",
      "\n",
      "Fold: 12  Epoch: 287  Training loss = 4.1880  Validation loss = 5.2794  \n",
      "\n",
      "Fold: 12  Epoch: 288  Training loss = 4.1877  Validation loss = 5.2789  \n",
      "\n",
      "Fold: 12  Epoch: 289  Training loss = 4.1874  Validation loss = 5.2783  \n",
      "\n",
      "Fold: 12  Epoch: 290  Training loss = 4.1870  Validation loss = 5.2776  \n",
      "\n",
      "Fold: 12  Epoch: 291  Training loss = 4.1868  Validation loss = 5.2772  \n",
      "\n",
      "Fold: 12  Epoch: 292  Training loss = 4.1865  Validation loss = 5.2768  \n",
      "\n",
      "Fold: 12  Epoch: 293  Training loss = 4.1862  Validation loss = 5.2762  \n",
      "\n",
      "Fold: 12  Epoch: 294  Training loss = 4.1859  Validation loss = 5.2759  \n",
      "\n",
      "Fold: 12  Epoch: 295  Training loss = 4.1855  Validation loss = 5.2751  \n",
      "\n",
      "Fold: 12  Epoch: 296  Training loss = 4.1853  Validation loss = 5.2748  \n",
      "\n",
      "Fold: 12  Epoch: 297  Training loss = 4.1850  Validation loss = 5.2744  \n",
      "\n",
      "Fold: 12  Epoch: 298  Training loss = 4.1847  Validation loss = 5.2739  \n",
      "\n",
      "Fold: 12  Epoch: 299  Training loss = 4.1844  Validation loss = 5.2734  \n",
      "\n",
      "Fold: 12  Epoch: 300  Training loss = 4.1840  Validation loss = 5.2727  \n",
      "\n",
      "Fold: 12  Epoch: 301  Training loss = 4.1837  Validation loss = 5.2720  \n",
      "\n",
      "Fold: 12  Epoch: 302  Training loss = 4.1835  Validation loss = 5.2716  \n",
      "\n",
      "Fold: 12  Epoch: 303  Training loss = 4.1832  Validation loss = 5.2711  \n",
      "\n",
      "Fold: 12  Epoch: 304  Training loss = 4.1829  Validation loss = 5.2704  \n",
      "\n",
      "Fold: 12  Epoch: 305  Training loss = 4.1826  Validation loss = 5.2699  \n",
      "\n",
      "Fold: 12  Epoch: 306  Training loss = 4.1822  Validation loss = 5.2693  \n",
      "\n",
      "Fold: 12  Epoch: 307  Training loss = 4.1819  Validation loss = 5.2688  \n",
      "\n",
      "Fold: 12  Epoch: 308  Training loss = 4.1816  Validation loss = 5.2681  \n",
      "\n",
      "Fold: 12  Epoch: 309  Training loss = 4.1812  Validation loss = 5.2675  \n",
      "\n",
      "Fold: 12  Epoch: 310  Training loss = 4.1809  Validation loss = 5.2670  \n",
      "\n",
      "Fold: 12  Epoch: 311  Training loss = 4.1806  Validation loss = 5.2666  \n",
      "\n",
      "Fold: 12  Epoch: 312  Training loss = 4.1804  Validation loss = 5.2661  \n",
      "\n",
      "Fold: 12  Epoch: 313  Training loss = 4.1800  Validation loss = 5.2654  \n",
      "\n",
      "Fold: 12  Epoch: 314  Training loss = 4.1797  Validation loss = 5.2648  \n",
      "\n",
      "Fold: 12  Epoch: 315  Training loss = 4.1794  Validation loss = 5.2644  \n",
      "\n",
      "Fold: 12  Epoch: 316  Training loss = 4.1791  Validation loss = 5.2638  \n",
      "\n",
      "Fold: 12  Epoch: 317  Training loss = 4.1788  Validation loss = 5.2633  \n",
      "\n",
      "Fold: 12  Epoch: 318  Training loss = 4.1785  Validation loss = 5.2628  \n",
      "\n",
      "Fold: 12  Epoch: 319  Training loss = 4.1782  Validation loss = 5.2623  \n",
      "\n",
      "Fold: 12  Epoch: 320  Training loss = 4.1779  Validation loss = 5.2617  \n",
      "\n",
      "Fold: 12  Epoch: 321  Training loss = 4.1776  Validation loss = 5.2613  \n",
      "\n",
      "Fold: 12  Epoch: 322  Training loss = 4.1773  Validation loss = 5.2607  \n",
      "\n",
      "Fold: 12  Epoch: 323  Training loss = 4.1771  Validation loss = 5.2602  \n",
      "\n",
      "Fold: 12  Epoch: 324  Training loss = 4.1768  Validation loss = 5.2597  \n",
      "\n",
      "Fold: 12  Epoch: 325  Training loss = 4.1764  Validation loss = 5.2591  \n",
      "\n",
      "Fold: 12  Epoch: 326  Training loss = 4.1761  Validation loss = 5.2584  \n",
      "\n",
      "Fold: 12  Epoch: 327  Training loss = 4.1758  Validation loss = 5.2577  \n",
      "\n",
      "Fold: 12  Epoch: 328  Training loss = 4.1755  Validation loss = 5.2572  \n",
      "\n",
      "Fold: 12  Epoch: 329  Training loss = 4.1751  Validation loss = 5.2565  \n",
      "\n",
      "Fold: 12  Epoch: 330  Training loss = 4.1748  Validation loss = 5.2558  \n",
      "\n",
      "Fold: 12  Epoch: 331  Training loss = 4.1744  Validation loss = 5.2552  \n",
      "\n",
      "Fold: 12  Epoch: 332  Training loss = 4.1741  Validation loss = 5.2546  \n",
      "\n",
      "Fold: 12  Epoch: 333  Training loss = 4.1738  Validation loss = 5.2541  \n",
      "\n",
      "Fold: 12  Epoch: 334  Training loss = 4.1736  Validation loss = 5.2537  \n",
      "\n",
      "Fold: 12  Epoch: 335  Training loss = 4.1732  Validation loss = 5.2531  \n",
      "\n",
      "Fold: 12  Epoch: 336  Training loss = 4.1729  Validation loss = 5.2525  \n",
      "\n",
      "Fold: 12  Epoch: 337  Training loss = 4.1725  Validation loss = 5.2518  \n",
      "\n",
      "Fold: 12  Epoch: 338  Training loss = 4.1723  Validation loss = 5.2514  \n",
      "\n",
      "Fold: 12  Epoch: 339  Training loss = 4.1720  Validation loss = 5.2509  \n",
      "\n",
      "Fold: 12  Epoch: 340  Training loss = 4.1717  Validation loss = 5.2503  \n",
      "\n",
      "Fold: 12  Epoch: 341  Training loss = 4.1714  Validation loss = 5.2498  \n",
      "\n",
      "Fold: 12  Epoch: 342  Training loss = 4.1710  Validation loss = 5.2491  \n",
      "\n",
      "Fold: 12  Epoch: 343  Training loss = 4.1707  Validation loss = 5.2485  \n",
      "\n",
      "Fold: 12  Epoch: 344  Training loss = 4.1705  Validation loss = 5.2481  \n",
      "\n",
      "Fold: 12  Epoch: 345  Training loss = 4.1702  Validation loss = 5.2475  \n",
      "\n",
      "Fold: 12  Epoch: 346  Training loss = 4.1699  Validation loss = 5.2470  \n",
      "\n",
      "Fold: 12  Epoch: 347  Training loss = 4.1696  Validation loss = 5.2462  \n",
      "\n",
      "Fold: 12  Epoch: 348  Training loss = 4.1693  Validation loss = 5.2458  \n",
      "\n",
      "Fold: 12  Epoch: 349  Training loss = 4.1690  Validation loss = 5.2453  \n",
      "\n",
      "Fold: 12  Epoch: 350  Training loss = 4.1688  Validation loss = 5.2448  \n",
      "\n",
      "Fold: 12  Epoch: 351  Training loss = 4.1685  Validation loss = 5.2444  \n",
      "\n",
      "Fold: 12  Epoch: 352  Training loss = 4.1682  Validation loss = 5.2438  \n",
      "\n",
      "Fold: 12  Epoch: 353  Training loss = 4.1678  Validation loss = 5.2432  \n",
      "\n",
      "Fold: 12  Epoch: 354  Training loss = 4.1675  Validation loss = 5.2427  \n",
      "\n",
      "Fold: 12  Epoch: 355  Training loss = 4.1672  Validation loss = 5.2420  \n",
      "\n",
      "Fold: 12  Epoch: 356  Training loss = 4.1669  Validation loss = 5.2414  \n",
      "\n",
      "Fold: 12  Epoch: 357  Training loss = 4.1665  Validation loss = 5.2406  \n",
      "\n",
      "Fold: 12  Epoch: 358  Training loss = 4.1661  Validation loss = 5.2399  \n",
      "\n",
      "Fold: 12  Epoch: 359  Training loss = 4.1658  Validation loss = 5.2394  \n",
      "\n",
      "Fold: 12  Epoch: 360  Training loss = 4.1655  Validation loss = 5.2387  \n",
      "\n",
      "Fold: 12  Epoch: 361  Training loss = 4.1652  Validation loss = 5.2382  \n",
      "\n",
      "Fold: 12  Epoch: 362  Training loss = 4.1649  Validation loss = 5.2377  \n",
      "\n",
      "Fold: 12  Epoch: 363  Training loss = 4.1646  Validation loss = 5.2371  \n",
      "\n",
      "Fold: 12  Epoch: 364  Training loss = 4.1642  Validation loss = 5.2365  \n",
      "\n",
      "Fold: 12  Epoch: 365  Training loss = 4.1639  Validation loss = 5.2359  \n",
      "\n",
      "Fold: 12  Epoch: 366  Training loss = 4.1636  Validation loss = 5.2355  \n",
      "\n",
      "Fold: 12  Epoch: 367  Training loss = 4.1634  Validation loss = 5.2351  \n",
      "\n",
      "Fold: 12  Epoch: 368  Training loss = 4.1631  Validation loss = 5.2345  \n",
      "\n",
      "Fold: 12  Epoch: 369  Training loss = 4.1627  Validation loss = 5.2339  \n",
      "\n",
      "Fold: 12  Epoch: 370  Training loss = 4.1624  Validation loss = 5.2334  \n",
      "\n",
      "Fold: 12  Epoch: 371  Training loss = 4.1621  Validation loss = 5.2330  \n",
      "\n",
      "Fold: 12  Epoch: 372  Training loss = 4.1619  Validation loss = 5.2325  \n",
      "\n",
      "Fold: 12  Epoch: 373  Training loss = 4.1615  Validation loss = 5.2319  \n",
      "\n",
      "Fold: 12  Epoch: 374  Training loss = 4.1612  Validation loss = 5.2314  \n",
      "\n",
      "Fold: 12  Epoch: 375  Training loss = 4.1609  Validation loss = 5.2308  \n",
      "\n",
      "Fold: 12  Epoch: 376  Training loss = 4.1606  Validation loss = 5.2303  \n",
      "\n",
      "Fold: 12  Epoch: 377  Training loss = 4.1603  Validation loss = 5.2298  \n",
      "\n",
      "Fold: 12  Epoch: 378  Training loss = 4.1600  Validation loss = 5.2293  \n",
      "\n",
      "Fold: 12  Epoch: 379  Training loss = 4.1597  Validation loss = 5.2288  \n",
      "\n",
      "Fold: 12  Epoch: 380  Training loss = 4.1594  Validation loss = 5.2283  \n",
      "\n",
      "Fold: 12  Epoch: 381  Training loss = 4.1591  Validation loss = 5.2277  \n",
      "\n",
      "Fold: 12  Epoch: 382  Training loss = 4.1588  Validation loss = 5.2273  \n",
      "\n",
      "Fold: 12  Epoch: 383  Training loss = 4.1585  Validation loss = 5.2266  \n",
      "\n",
      "Fold: 12  Epoch: 384  Training loss = 4.1581  Validation loss = 5.2259  \n",
      "\n",
      "Fold: 12  Epoch: 385  Training loss = 4.1578  Validation loss = 5.2253  \n",
      "\n",
      "Fold: 12  Epoch: 386  Training loss = 4.1575  Validation loss = 5.2248  \n",
      "\n",
      "Fold: 12  Epoch: 387  Training loss = 4.1573  Validation loss = 5.2244  \n",
      "\n",
      "Fold: 12  Epoch: 388  Training loss = 4.1570  Validation loss = 5.2238  \n",
      "\n",
      "Fold: 12  Epoch: 389  Training loss = 4.1566  Validation loss = 5.2232  \n",
      "\n",
      "Fold: 12  Epoch: 390  Training loss = 4.1563  Validation loss = 5.2226  \n",
      "\n",
      "Fold: 12  Epoch: 391  Training loss = 4.1561  Validation loss = 5.2221  \n",
      "\n",
      "Fold: 12  Epoch: 392  Training loss = 4.1557  Validation loss = 5.2214  \n",
      "\n",
      "Fold: 12  Epoch: 393  Training loss = 4.1554  Validation loss = 5.2209  \n",
      "\n",
      "Fold: 12  Epoch: 394  Training loss = 4.1552  Validation loss = 5.2206  \n",
      "\n",
      "Fold: 12  Epoch: 395  Training loss = 4.1549  Validation loss = 5.2201  \n",
      "\n",
      "Fold: 12  Epoch: 396  Training loss = 4.1546  Validation loss = 5.2197  \n",
      "\n",
      "Fold: 12  Epoch: 397  Training loss = 4.1543  Validation loss = 5.2191  \n",
      "\n",
      "Fold: 12  Epoch: 398  Training loss = 4.1540  Validation loss = 5.2186  \n",
      "\n",
      "Fold: 12  Epoch: 399  Training loss = 4.1536  Validation loss = 5.2178  \n",
      "\n",
      "Fold: 12  Epoch: 400  Training loss = 4.1534  Validation loss = 5.2174  \n",
      "\n",
      "Fold: 12  Epoch: 401  Training loss = 4.1531  Validation loss = 5.2169  \n",
      "\n",
      "Fold: 12  Epoch: 402  Training loss = 4.1528  Validation loss = 5.2163  \n",
      "\n",
      "Fold: 12  Epoch: 403  Training loss = 4.1525  Validation loss = 5.2158  \n",
      "\n",
      "Fold: 12  Epoch: 404  Training loss = 4.1522  Validation loss = 5.2152  \n",
      "\n",
      "Fold: 12  Epoch: 405  Training loss = 4.1519  Validation loss = 5.2147  \n",
      "\n",
      "Fold: 12  Epoch: 406  Training loss = 4.1516  Validation loss = 5.2140  \n",
      "\n",
      "Fold: 12  Epoch: 407  Training loss = 4.1513  Validation loss = 5.2135  \n",
      "\n",
      "Fold: 12  Epoch: 408  Training loss = 4.1509  Validation loss = 5.2130  \n",
      "\n",
      "Fold: 12  Epoch: 409  Training loss = 4.1507  Validation loss = 5.2125  \n",
      "\n",
      "Fold: 12  Epoch: 410  Training loss = 4.1503  Validation loss = 5.2119  \n",
      "\n",
      "Fold: 12  Epoch: 411  Training loss = 4.1501  Validation loss = 5.2114  \n",
      "\n",
      "Fold: 12  Epoch: 412  Training loss = 4.1498  Validation loss = 5.2109  \n",
      "\n",
      "Fold: 12  Epoch: 413  Training loss = 4.1495  Validation loss = 5.2104  \n",
      "\n",
      "Fold: 12  Epoch: 414  Training loss = 4.1492  Validation loss = 5.2100  \n",
      "\n",
      "Fold: 12  Epoch: 415  Training loss = 4.1489  Validation loss = 5.2094  \n",
      "\n",
      "Fold: 12  Epoch: 416  Training loss = 4.1485  Validation loss = 5.2086  \n",
      "\n",
      "Fold: 12  Epoch: 417  Training loss = 4.1481  Validation loss = 5.2079  \n",
      "\n",
      "Fold: 12  Epoch: 418  Training loss = 4.1478  Validation loss = 5.2074  \n",
      "\n",
      "Fold: 12  Epoch: 419  Training loss = 4.1474  Validation loss = 5.2068  \n",
      "\n",
      "Fold: 12  Epoch: 420  Training loss = 4.1470  Validation loss = 5.2061  \n",
      "\n",
      "Fold: 12  Epoch: 421  Training loss = 4.1467  Validation loss = 5.2054  \n",
      "\n",
      "Fold: 12  Epoch: 422  Training loss = 4.1463  Validation loss = 5.2048  \n",
      "\n",
      "Fold: 12  Epoch: 423  Training loss = 4.1460  Validation loss = 5.2042  \n",
      "\n",
      "Fold: 12  Epoch: 424  Training loss = 4.1457  Validation loss = 5.2038  \n",
      "\n",
      "Fold: 12  Epoch: 425  Training loss = 4.1454  Validation loss = 5.2032  \n",
      "\n",
      "Fold: 12  Epoch: 426  Training loss = 4.1451  Validation loss = 5.2027  \n",
      "\n",
      "Fold: 12  Epoch: 427  Training loss = 4.1448  Validation loss = 5.2023  \n",
      "\n",
      "Fold: 12  Epoch: 428  Training loss = 4.1445  Validation loss = 5.2017  \n",
      "\n",
      "Fold: 12  Epoch: 429  Training loss = 4.1443  Validation loss = 5.2013  \n",
      "\n",
      "Fold: 12  Epoch: 430  Training loss = 4.1439  Validation loss = 5.2007  \n",
      "\n",
      "Fold: 12  Epoch: 431  Training loss = 4.1436  Validation loss = 5.2001  \n",
      "\n",
      "Fold: 12  Epoch: 432  Training loss = 4.1433  Validation loss = 5.1997  \n",
      "\n",
      "Fold: 12  Epoch: 433  Training loss = 4.1430  Validation loss = 5.1991  \n",
      "\n",
      "Fold: 12  Epoch: 434  Training loss = 4.1427  Validation loss = 5.1983  \n",
      "\n",
      "Fold: 12  Epoch: 435  Training loss = 4.1424  Validation loss = 5.1979  \n",
      "\n",
      "Fold: 12  Epoch: 436  Training loss = 4.1421  Validation loss = 5.1973  \n",
      "\n",
      "Fold: 12  Epoch: 437  Training loss = 4.1418  Validation loss = 5.1967  \n",
      "\n",
      "Fold: 12  Epoch: 438  Training loss = 4.1415  Validation loss = 5.1962  \n",
      "\n",
      "Fold: 12  Epoch: 439  Training loss = 4.1412  Validation loss = 5.1958  \n",
      "\n",
      "Fold: 12  Epoch: 440  Training loss = 4.1409  Validation loss = 5.1951  \n",
      "\n",
      "Fold: 12  Epoch: 441  Training loss = 4.1406  Validation loss = 5.1947  \n",
      "\n",
      "Fold: 12  Epoch: 442  Training loss = 4.1403  Validation loss = 5.1941  \n",
      "\n",
      "Fold: 12  Epoch: 443  Training loss = 4.1400  Validation loss = 5.1936  \n",
      "\n",
      "Fold: 12  Epoch: 444  Training loss = 4.1397  Validation loss = 5.1932  \n",
      "\n",
      "Fold: 12  Epoch: 445  Training loss = 4.1395  Validation loss = 5.1925  \n",
      "\n",
      "Fold: 12  Epoch: 446  Training loss = 4.1391  Validation loss = 5.1919  \n",
      "\n",
      "Fold: 12  Epoch: 447  Training loss = 4.1388  Validation loss = 5.1912  \n",
      "\n",
      "Fold: 12  Epoch: 448  Training loss = 4.1385  Validation loss = 5.1908  \n",
      "\n",
      "Fold: 12  Epoch: 449  Training loss = 4.1382  Validation loss = 5.1902  \n",
      "\n",
      "Fold: 12  Epoch: 450  Training loss = 4.1379  Validation loss = 5.1897  \n",
      "\n",
      "Fold: 12  Epoch: 451  Training loss = 4.1375  Validation loss = 5.1890  \n",
      "\n",
      "Fold: 12  Epoch: 452  Training loss = 4.1372  Validation loss = 5.1884  \n",
      "\n",
      "Fold: 12  Epoch: 453  Training loss = 4.1369  Validation loss = 5.1879  \n",
      "\n",
      "Fold: 12  Epoch: 454  Training loss = 4.1366  Validation loss = 5.1873  \n",
      "\n",
      "Fold: 12  Epoch: 455  Training loss = 4.1363  Validation loss = 5.1867  \n",
      "\n",
      "Fold: 12  Epoch: 456  Training loss = 4.1361  Validation loss = 5.1864  \n",
      "\n",
      "Fold: 12  Epoch: 457  Training loss = 4.1357  Validation loss = 5.1859  \n",
      "\n",
      "Fold: 12  Epoch: 458  Training loss = 4.1354  Validation loss = 5.1851  \n",
      "\n",
      "Fold: 12  Epoch: 459  Training loss = 4.1351  Validation loss = 5.1847  \n",
      "\n",
      "Fold: 12  Epoch: 460  Training loss = 4.1348  Validation loss = 5.1842  \n",
      "\n",
      "Fold: 12  Epoch: 461  Training loss = 4.1346  Validation loss = 5.1838  \n",
      "\n",
      "Fold: 12  Epoch: 462  Training loss = 4.1343  Validation loss = 5.1832  \n",
      "\n",
      "Fold: 12  Epoch: 463  Training loss = 4.1340  Validation loss = 5.1827  \n",
      "\n",
      "Fold: 12  Epoch: 464  Training loss = 4.1336  Validation loss = 5.1820  \n",
      "\n",
      "Fold: 12  Epoch: 465  Training loss = 4.1333  Validation loss = 5.1814  \n",
      "\n",
      "Fold: 12  Epoch: 466  Training loss = 4.1330  Validation loss = 5.1808  \n",
      "\n",
      "Fold: 12  Epoch: 467  Training loss = 4.1328  Validation loss = 5.1805  \n",
      "\n",
      "Fold: 12  Epoch: 468  Training loss = 4.1325  Validation loss = 5.1800  \n",
      "\n",
      "Fold: 12  Epoch: 469  Training loss = 4.1323  Validation loss = 5.1797  \n",
      "\n",
      "Fold: 12  Epoch: 470  Training loss = 4.1320  Validation loss = 5.1791  \n",
      "\n",
      "Fold: 12  Epoch: 471  Training loss = 4.1317  Validation loss = 5.1786  \n",
      "\n",
      "Fold: 12  Epoch: 472  Training loss = 4.1314  Validation loss = 5.1782  \n",
      "\n",
      "Fold: 12  Epoch: 473  Training loss = 4.1312  Validation loss = 5.1778  \n",
      "\n",
      "Fold: 12  Epoch: 474  Training loss = 4.1309  Validation loss = 5.1774  \n",
      "\n",
      "Fold: 12  Epoch: 475  Training loss = 4.1307  Validation loss = 5.1770  \n",
      "\n",
      "Fold: 12  Epoch: 476  Training loss = 4.1304  Validation loss = 5.1765  \n",
      "\n",
      "Fold: 12  Epoch: 477  Training loss = 4.1301  Validation loss = 5.1760  \n",
      "\n",
      "Fold: 12  Epoch: 478  Training loss = 4.1298  Validation loss = 5.1756  \n",
      "\n",
      "Fold: 12  Epoch: 479  Training loss = 4.1295  Validation loss = 5.1751  \n",
      "\n",
      "Fold: 12  Epoch: 480  Training loss = 4.1292  Validation loss = 5.1746  \n",
      "\n",
      "Fold: 12  Epoch: 481  Training loss = 4.1289  Validation loss = 5.1741  \n",
      "\n",
      "Fold: 12  Epoch: 482  Training loss = 4.1287  Validation loss = 5.1736  \n",
      "\n",
      "Fold: 12  Epoch: 483  Training loss = 4.1283  Validation loss = 5.1731  \n",
      "\n",
      "Fold: 12  Epoch: 484  Training loss = 4.1280  Validation loss = 5.1726  \n",
      "\n",
      "Fold: 12  Epoch: 485  Training loss = 4.1277  Validation loss = 5.1719  \n",
      "\n",
      "Fold: 12  Epoch: 486  Training loss = 4.1275  Validation loss = 5.1715  \n",
      "\n",
      "Fold: 12  Epoch: 487  Training loss = 4.1272  Validation loss = 5.1712  \n",
      "\n",
      "Fold: 12  Epoch: 488  Training loss = 4.1269  Validation loss = 5.1706  \n",
      "\n",
      "Fold: 12  Epoch: 489  Training loss = 4.1266  Validation loss = 5.1702  \n",
      "\n",
      "Fold: 12  Epoch: 490  Training loss = 4.1263  Validation loss = 5.1697  \n",
      "\n",
      "Fold: 12  Epoch: 491  Training loss = 4.1259  Validation loss = 5.1689  \n",
      "\n",
      "Fold: 12  Epoch: 492  Training loss = 4.1257  Validation loss = 5.1685  \n",
      "\n",
      "Fold: 12  Epoch: 493  Training loss = 4.1253  Validation loss = 5.1679  \n",
      "\n",
      "Fold: 12  Epoch: 494  Training loss = 4.1250  Validation loss = 5.1673  \n",
      "\n",
      "Fold: 12  Epoch: 495  Training loss = 4.1247  Validation loss = 5.1667  \n",
      "\n",
      "Fold: 12  Epoch: 496  Training loss = 4.1244  Validation loss = 5.1662  \n",
      "\n",
      "Fold: 12  Epoch: 497  Training loss = 4.1241  Validation loss = 5.1657  \n",
      "\n",
      "Fold: 12  Epoch: 498  Training loss = 4.1237  Validation loss = 5.1652  \n",
      "\n",
      "Fold: 12  Epoch: 499  Training loss = 4.1234  Validation loss = 5.1646  \n",
      "\n",
      "Fold: 12  Epoch: 500  Training loss = 4.1231  Validation loss = 5.1640  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 500  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 4.3070  Validation loss = 7.3281  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 4.3066  Validation loss = 7.3276  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 4.3063  Validation loss = 7.3272  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 4.3059  Validation loss = 7.3265  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 4.3056  Validation loss = 7.3260  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 4.3051  Validation loss = 7.3253  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 4.3047  Validation loss = 7.3247  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 4.3044  Validation loss = 7.3242  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 4.3039  Validation loss = 7.3236  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 4.3035  Validation loss = 7.3229  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 4.3032  Validation loss = 7.3224  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 4.3028  Validation loss = 7.3219  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 4.3025  Validation loss = 7.3214  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 4.3021  Validation loss = 7.3207  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 4.3017  Validation loss = 7.3201  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 4.3013  Validation loss = 7.3196  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 4.3009  Validation loss = 7.3190  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 4.3006  Validation loss = 7.3185  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 4.3002  Validation loss = 7.3178  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 4.2998  Validation loss = 7.3173  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 4.2994  Validation loss = 7.3167  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 4.2991  Validation loss = 7.3162  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 4.2988  Validation loss = 7.3157  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 4.2984  Validation loss = 7.3152  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 4.2980  Validation loss = 7.3146  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 4.2976  Validation loss = 7.3140  \n",
      "\n",
      "Fold: 13  Epoch: 27  Training loss = 4.2972  Validation loss = 7.3133  \n",
      "\n",
      "Fold: 13  Epoch: 28  Training loss = 4.2968  Validation loss = 7.3128  \n",
      "\n",
      "Fold: 13  Epoch: 29  Training loss = 4.2964  Validation loss = 7.3121  \n",
      "\n",
      "Fold: 13  Epoch: 30  Training loss = 4.2959  Validation loss = 7.3114  \n",
      "\n",
      "Fold: 13  Epoch: 31  Training loss = 4.2956  Validation loss = 7.3109  \n",
      "\n",
      "Fold: 13  Epoch: 32  Training loss = 4.2952  Validation loss = 7.3103  \n",
      "\n",
      "Fold: 13  Epoch: 33  Training loss = 4.2948  Validation loss = 7.3098  \n",
      "\n",
      "Fold: 13  Epoch: 34  Training loss = 4.2945  Validation loss = 7.3092  \n",
      "\n",
      "Fold: 13  Epoch: 35  Training loss = 4.2941  Validation loss = 7.3087  \n",
      "\n",
      "Fold: 13  Epoch: 36  Training loss = 4.2937  Validation loss = 7.3080  \n",
      "\n",
      "Fold: 13  Epoch: 37  Training loss = 4.2934  Validation loss = 7.3075  \n",
      "\n",
      "Fold: 13  Epoch: 38  Training loss = 4.2930  Validation loss = 7.3070  \n",
      "\n",
      "Fold: 13  Epoch: 39  Training loss = 4.2927  Validation loss = 7.3065  \n",
      "\n",
      "Fold: 13  Epoch: 40  Training loss = 4.2923  Validation loss = 7.3060  \n",
      "\n",
      "Fold: 13  Epoch: 41  Training loss = 4.2920  Validation loss = 7.3054  \n",
      "\n",
      "Fold: 13  Epoch: 42  Training loss = 4.2916  Validation loss = 7.3048  \n",
      "\n",
      "Fold: 13  Epoch: 43  Training loss = 4.2912  Validation loss = 7.3043  \n",
      "\n",
      "Fold: 13  Epoch: 44  Training loss = 4.2909  Validation loss = 7.3038  \n",
      "\n",
      "Fold: 13  Epoch: 45  Training loss = 4.2905  Validation loss = 7.3032  \n",
      "\n",
      "Fold: 13  Epoch: 46  Training loss = 4.2901  Validation loss = 7.3027  \n",
      "\n",
      "Fold: 13  Epoch: 47  Training loss = 4.2897  Validation loss = 7.3020  \n",
      "\n",
      "Fold: 13  Epoch: 48  Training loss = 4.2893  Validation loss = 7.3015  \n",
      "\n",
      "Fold: 13  Epoch: 49  Training loss = 4.2890  Validation loss = 7.3010  \n",
      "\n",
      "Fold: 13  Epoch: 50  Training loss = 4.2886  Validation loss = 7.3004  \n",
      "\n",
      "Fold: 13  Epoch: 51  Training loss = 4.2881  Validation loss = 7.2997  \n",
      "\n",
      "Fold: 13  Epoch: 52  Training loss = 4.2878  Validation loss = 7.2991  \n",
      "\n",
      "Fold: 13  Epoch: 53  Training loss = 4.2873  Validation loss = 7.2984  \n",
      "\n",
      "Fold: 13  Epoch: 54  Training loss = 4.2870  Validation loss = 7.2979  \n",
      "\n",
      "Fold: 13  Epoch: 55  Training loss = 4.2865  Validation loss = 7.2972  \n",
      "\n",
      "Fold: 13  Epoch: 56  Training loss = 4.2861  Validation loss = 7.2966  \n",
      "\n",
      "Fold: 13  Epoch: 57  Training loss = 4.2857  Validation loss = 7.2960  \n",
      "\n",
      "Fold: 13  Epoch: 58  Training loss = 4.2853  Validation loss = 7.2955  \n",
      "\n",
      "Fold: 13  Epoch: 59  Training loss = 4.2849  Validation loss = 7.2947  \n",
      "\n",
      "Fold: 13  Epoch: 60  Training loss = 4.2844  Validation loss = 7.2941  \n",
      "\n",
      "Fold: 13  Epoch: 61  Training loss = 4.2841  Validation loss = 7.2936  \n",
      "\n",
      "Fold: 13  Epoch: 62  Training loss = 4.2836  Validation loss = 7.2929  \n",
      "\n",
      "Fold: 13  Epoch: 63  Training loss = 4.2833  Validation loss = 7.2924  \n",
      "\n",
      "Fold: 13  Epoch: 64  Training loss = 4.2830  Validation loss = 7.2919  \n",
      "\n",
      "Fold: 13  Epoch: 65  Training loss = 4.2826  Validation loss = 7.2913  \n",
      "\n",
      "Fold: 13  Epoch: 66  Training loss = 4.2822  Validation loss = 7.2907  \n",
      "\n",
      "Fold: 13  Epoch: 67  Training loss = 4.2819  Validation loss = 7.2902  \n",
      "\n",
      "Fold: 13  Epoch: 68  Training loss = 4.2815  Validation loss = 7.2897  \n",
      "\n",
      "Fold: 13  Epoch: 69  Training loss = 4.2811  Validation loss = 7.2891  \n",
      "\n",
      "Fold: 13  Epoch: 70  Training loss = 4.2808  Validation loss = 7.2885  \n",
      "\n",
      "Fold: 13  Epoch: 71  Training loss = 4.2803  Validation loss = 7.2879  \n",
      "\n",
      "Fold: 13  Epoch: 72  Training loss = 4.2800  Validation loss = 7.2874  \n",
      "\n",
      "Fold: 13  Epoch: 73  Training loss = 4.2796  Validation loss = 7.2867  \n",
      "\n",
      "Fold: 13  Epoch: 74  Training loss = 4.2792  Validation loss = 7.2862  \n",
      "\n",
      "Fold: 13  Epoch: 75  Training loss = 4.2788  Validation loss = 7.2856  \n",
      "\n",
      "Fold: 13  Epoch: 76  Training loss = 4.2785  Validation loss = 7.2851  \n",
      "\n",
      "Fold: 13  Epoch: 77  Training loss = 4.2781  Validation loss = 7.2845  \n",
      "\n",
      "Fold: 13  Epoch: 78  Training loss = 4.2777  Validation loss = 7.2839  \n",
      "\n",
      "Fold: 13  Epoch: 79  Training loss = 4.2773  Validation loss = 7.2833  \n",
      "\n",
      "Fold: 13  Epoch: 80  Training loss = 4.2769  Validation loss = 7.2828  \n",
      "\n",
      "Fold: 13  Epoch: 81  Training loss = 4.2765  Validation loss = 7.2821  \n",
      "\n",
      "Fold: 13  Epoch: 82  Training loss = 4.2761  Validation loss = 7.2814  \n",
      "\n",
      "Fold: 13  Epoch: 83  Training loss = 4.2757  Validation loss = 7.2808  \n",
      "\n",
      "Fold: 13  Epoch: 84  Training loss = 4.2753  Validation loss = 7.2803  \n",
      "\n",
      "Fold: 13  Epoch: 85  Training loss = 4.2750  Validation loss = 7.2797  \n",
      "\n",
      "Fold: 13  Epoch: 86  Training loss = 4.2746  Validation loss = 7.2793  \n",
      "\n",
      "Fold: 13  Epoch: 87  Training loss = 4.2743  Validation loss = 7.2787  \n",
      "\n",
      "Fold: 13  Epoch: 88  Training loss = 4.2739  Validation loss = 7.2781  \n",
      "\n",
      "Fold: 13  Epoch: 89  Training loss = 4.2735  Validation loss = 7.2776  \n",
      "\n",
      "Fold: 13  Epoch: 90  Training loss = 4.2732  Validation loss = 7.2771  \n",
      "\n",
      "Fold: 13  Epoch: 91  Training loss = 4.2728  Validation loss = 7.2765  \n",
      "\n",
      "Fold: 13  Epoch: 92  Training loss = 4.2724  Validation loss = 7.2758  \n",
      "\n",
      "Fold: 13  Epoch: 93  Training loss = 4.2720  Validation loss = 7.2752  \n",
      "\n",
      "Fold: 13  Epoch: 94  Training loss = 4.2716  Validation loss = 7.2746  \n",
      "\n",
      "Fold: 13  Epoch: 95  Training loss = 4.2713  Validation loss = 7.2741  \n",
      "\n",
      "Fold: 13  Epoch: 96  Training loss = 4.2710  Validation loss = 7.2737  \n",
      "\n",
      "Fold: 13  Epoch: 97  Training loss = 4.2705  Validation loss = 7.2731  \n",
      "\n",
      "Fold: 13  Epoch: 98  Training loss = 4.2701  Validation loss = 7.2724  \n",
      "\n",
      "Fold: 13  Epoch: 99  Training loss = 4.2698  Validation loss = 7.2719  \n",
      "\n",
      "Fold: 13  Epoch: 100  Training loss = 4.2695  Validation loss = 7.2714  \n",
      "\n",
      "Fold: 13  Epoch: 101  Training loss = 4.2692  Validation loss = 7.2710  \n",
      "\n",
      "Fold: 13  Epoch: 102  Training loss = 4.2688  Validation loss = 7.2704  \n",
      "\n",
      "Fold: 13  Epoch: 103  Training loss = 4.2685  Validation loss = 7.2699  \n",
      "\n",
      "Fold: 13  Epoch: 104  Training loss = 4.2681  Validation loss = 7.2693  \n",
      "\n",
      "Fold: 13  Epoch: 105  Training loss = 4.2676  Validation loss = 7.2687  \n",
      "\n",
      "Fold: 13  Epoch: 106  Training loss = 4.2673  Validation loss = 7.2682  \n",
      "\n",
      "Fold: 13  Epoch: 107  Training loss = 4.2668  Validation loss = 7.2674  \n",
      "\n",
      "Fold: 13  Epoch: 108  Training loss = 4.2665  Validation loss = 7.2669  \n",
      "\n",
      "Fold: 13  Epoch: 109  Training loss = 4.2661  Validation loss = 7.2663  \n",
      "\n",
      "Fold: 13  Epoch: 110  Training loss = 4.2656  Validation loss = 7.2656  \n",
      "\n",
      "Fold: 13  Epoch: 111  Training loss = 4.2653  Validation loss = 7.2651  \n",
      "\n",
      "Fold: 13  Epoch: 112  Training loss = 4.2649  Validation loss = 7.2645  \n",
      "\n",
      "Fold: 13  Epoch: 113  Training loss = 4.2645  Validation loss = 7.2639  \n",
      "\n",
      "Fold: 13  Epoch: 114  Training loss = 4.2641  Validation loss = 7.2633  \n",
      "\n",
      "Fold: 13  Epoch: 115  Training loss = 4.2637  Validation loss = 7.2628  \n",
      "\n",
      "Fold: 13  Epoch: 116  Training loss = 4.2634  Validation loss = 7.2623  \n",
      "\n",
      "Fold: 13  Epoch: 117  Training loss = 4.2630  Validation loss = 7.2616  \n",
      "\n",
      "Fold: 13  Epoch: 118  Training loss = 4.2627  Validation loss = 7.2612  \n",
      "\n",
      "Fold: 13  Epoch: 119  Training loss = 4.2624  Validation loss = 7.2607  \n",
      "\n",
      "Fold: 13  Epoch: 120  Training loss = 4.2621  Validation loss = 7.2603  \n",
      "\n",
      "Fold: 13  Epoch: 121  Training loss = 4.2618  Validation loss = 7.2598  \n",
      "\n",
      "Fold: 13  Epoch: 122  Training loss = 4.2614  Validation loss = 7.2592  \n",
      "\n",
      "Fold: 13  Epoch: 123  Training loss = 4.2609  Validation loss = 7.2586  \n",
      "\n",
      "Fold: 13  Epoch: 124  Training loss = 4.2606  Validation loss = 7.2580  \n",
      "\n",
      "Fold: 13  Epoch: 125  Training loss = 4.2602  Validation loss = 7.2574  \n",
      "\n",
      "Fold: 13  Epoch: 126  Training loss = 4.2598  Validation loss = 7.2569  \n",
      "\n",
      "Fold: 13  Epoch: 127  Training loss = 4.2594  Validation loss = 7.2563  \n",
      "\n",
      "Fold: 13  Epoch: 128  Training loss = 4.2591  Validation loss = 7.2558  \n",
      "\n",
      "Fold: 13  Epoch: 129  Training loss = 4.2588  Validation loss = 7.2553  \n",
      "\n",
      "Fold: 13  Epoch: 130  Training loss = 4.2583  Validation loss = 7.2547  \n",
      "\n",
      "Fold: 13  Epoch: 131  Training loss = 4.2580  Validation loss = 7.2541  \n",
      "\n",
      "Fold: 13  Epoch: 132  Training loss = 4.2575  Validation loss = 7.2534  \n",
      "\n",
      "Fold: 13  Epoch: 133  Training loss = 4.2571  Validation loss = 7.2528  \n",
      "\n",
      "Fold: 13  Epoch: 134  Training loss = 4.2568  Validation loss = 7.2523  \n",
      "\n",
      "Fold: 13  Epoch: 135  Training loss = 4.2563  Validation loss = 7.2516  \n",
      "\n",
      "Fold: 13  Epoch: 136  Training loss = 4.2560  Validation loss = 7.2512  \n",
      "\n",
      "Fold: 13  Epoch: 137  Training loss = 4.2556  Validation loss = 7.2505  \n",
      "\n",
      "Fold: 13  Epoch: 138  Training loss = 4.2552  Validation loss = 7.2499  \n",
      "\n",
      "Fold: 13  Epoch: 139  Training loss = 4.2548  Validation loss = 7.2494  \n",
      "\n",
      "Fold: 13  Epoch: 140  Training loss = 4.2545  Validation loss = 7.2488  \n",
      "\n",
      "Fold: 13  Epoch: 141  Training loss = 4.2540  Validation loss = 7.2481  \n",
      "\n",
      "Fold: 13  Epoch: 142  Training loss = 4.2536  Validation loss = 7.2475  \n",
      "\n",
      "Fold: 13  Epoch: 143  Training loss = 4.2532  Validation loss = 7.2469  \n",
      "\n",
      "Fold: 13  Epoch: 144  Training loss = 4.2528  Validation loss = 7.2463  \n",
      "\n",
      "Fold: 13  Epoch: 145  Training loss = 4.2525  Validation loss = 7.2459  \n",
      "\n",
      "Fold: 13  Epoch: 146  Training loss = 4.2521  Validation loss = 7.2453  \n",
      "\n",
      "Fold: 13  Epoch: 147  Training loss = 4.2518  Validation loss = 7.2448  \n",
      "\n",
      "Fold: 13  Epoch: 148  Training loss = 4.2514  Validation loss = 7.2442  \n",
      "\n",
      "Fold: 13  Epoch: 149  Training loss = 4.2510  Validation loss = 7.2436  \n",
      "\n",
      "Fold: 13  Epoch: 150  Training loss = 4.2506  Validation loss = 7.2430  \n",
      "\n",
      "Fold: 13  Epoch: 151  Training loss = 4.2503  Validation loss = 7.2425  \n",
      "\n",
      "Fold: 13  Epoch: 152  Training loss = 4.2499  Validation loss = 7.2419  \n",
      "\n",
      "Fold: 13  Epoch: 153  Training loss = 4.2495  Validation loss = 7.2413  \n",
      "\n",
      "Fold: 13  Epoch: 154  Training loss = 4.2491  Validation loss = 7.2407  \n",
      "\n",
      "Fold: 13  Epoch: 155  Training loss = 4.2488  Validation loss = 7.2403  \n",
      "\n",
      "Fold: 13  Epoch: 156  Training loss = 4.2485  Validation loss = 7.2398  \n",
      "\n",
      "Fold: 13  Epoch: 157  Training loss = 4.2480  Validation loss = 7.2391  \n",
      "\n",
      "Fold: 13  Epoch: 158  Training loss = 4.2477  Validation loss = 7.2386  \n",
      "\n",
      "Fold: 13  Epoch: 159  Training loss = 4.2473  Validation loss = 7.2381  \n",
      "\n",
      "Fold: 13  Epoch: 160  Training loss = 4.2470  Validation loss = 7.2376  \n",
      "\n",
      "Fold: 13  Epoch: 161  Training loss = 4.2466  Validation loss = 7.2370  \n",
      "\n",
      "Fold: 13  Epoch: 162  Training loss = 4.2462  Validation loss = 7.2365  \n",
      "\n",
      "Fold: 13  Epoch: 163  Training loss = 4.2458  Validation loss = 7.2359  \n",
      "\n",
      "Fold: 13  Epoch: 164  Training loss = 4.2455  Validation loss = 7.2353  \n",
      "\n",
      "Fold: 13  Epoch: 165  Training loss = 4.2451  Validation loss = 7.2347  \n",
      "\n",
      "Fold: 13  Epoch: 166  Training loss = 4.2447  Validation loss = 7.2341  \n",
      "\n",
      "Fold: 13  Epoch: 167  Training loss = 4.2444  Validation loss = 7.2337  \n",
      "\n",
      "Fold: 13  Epoch: 168  Training loss = 4.2440  Validation loss = 7.2331  \n",
      "\n",
      "Fold: 13  Epoch: 169  Training loss = 4.2436  Validation loss = 7.2325  \n",
      "\n",
      "Fold: 13  Epoch: 170  Training loss = 4.2432  Validation loss = 7.2320  \n",
      "\n",
      "Fold: 13  Epoch: 171  Training loss = 4.2429  Validation loss = 7.2315  \n",
      "\n",
      "Fold: 13  Epoch: 172  Training loss = 4.2425  Validation loss = 7.2309  \n",
      "\n",
      "Fold: 13  Epoch: 173  Training loss = 4.2422  Validation loss = 7.2304  \n",
      "\n",
      "Fold: 13  Epoch: 174  Training loss = 4.2419  Validation loss = 7.2300  \n",
      "\n",
      "Fold: 13  Epoch: 175  Training loss = 4.2416  Validation loss = 7.2295  \n",
      "\n",
      "Fold: 13  Epoch: 176  Training loss = 4.2412  Validation loss = 7.2289  \n",
      "\n",
      "Fold: 13  Epoch: 177  Training loss = 4.2408  Validation loss = 7.2282  \n",
      "\n",
      "Fold: 13  Epoch: 178  Training loss = 4.2404  Validation loss = 7.2276  \n",
      "\n",
      "Fold: 13  Epoch: 179  Training loss = 4.2401  Validation loss = 7.2271  \n",
      "\n",
      "Fold: 13  Epoch: 180  Training loss = 4.2397  Validation loss = 7.2266  \n",
      "\n",
      "Fold: 13  Epoch: 181  Training loss = 4.2394  Validation loss = 7.2261  \n",
      "\n",
      "Fold: 13  Epoch: 182  Training loss = 4.2389  Validation loss = 7.2253  \n",
      "\n",
      "Fold: 13  Epoch: 183  Training loss = 4.2385  Validation loss = 7.2248  \n",
      "\n",
      "Fold: 13  Epoch: 184  Training loss = 4.2381  Validation loss = 7.2242  \n",
      "\n",
      "Fold: 13  Epoch: 185  Training loss = 4.2378  Validation loss = 7.2237  \n",
      "\n",
      "Fold: 13  Epoch: 186  Training loss = 4.2374  Validation loss = 7.2231  \n",
      "\n",
      "Fold: 13  Epoch: 187  Training loss = 4.2369  Validation loss = 7.2224  \n",
      "\n",
      "Fold: 13  Epoch: 188  Training loss = 4.2366  Validation loss = 7.2219  \n",
      "\n",
      "Fold: 13  Epoch: 189  Training loss = 4.2362  Validation loss = 7.2214  \n",
      "\n",
      "Fold: 13  Epoch: 190  Training loss = 4.2358  Validation loss = 7.2208  \n",
      "\n",
      "Fold: 13  Epoch: 191  Training loss = 4.2354  Validation loss = 7.2201  \n",
      "\n",
      "Fold: 13  Epoch: 192  Training loss = 4.2350  Validation loss = 7.2195  \n",
      "\n",
      "Fold: 13  Epoch: 193  Training loss = 4.2346  Validation loss = 7.2190  \n",
      "\n",
      "Fold: 13  Epoch: 194  Training loss = 4.2342  Validation loss = 7.2184  \n",
      "\n",
      "Fold: 13  Epoch: 195  Training loss = 4.2339  Validation loss = 7.2178  \n",
      "\n",
      "Fold: 13  Epoch: 196  Training loss = 4.2335  Validation loss = 7.2172  \n",
      "\n",
      "Fold: 13  Epoch: 197  Training loss = 4.2331  Validation loss = 7.2166  \n",
      "\n",
      "Fold: 13  Epoch: 198  Training loss = 4.2327  Validation loss = 7.2160  \n",
      "\n",
      "Fold: 13  Epoch: 199  Training loss = 4.2324  Validation loss = 7.2156  \n",
      "\n",
      "Fold: 13  Epoch: 200  Training loss = 4.2320  Validation loss = 7.2150  \n",
      "\n",
      "Fold: 13  Epoch: 201  Training loss = 4.2316  Validation loss = 7.2144  \n",
      "\n",
      "Fold: 13  Epoch: 202  Training loss = 4.2313  Validation loss = 7.2139  \n",
      "\n",
      "Fold: 13  Epoch: 203  Training loss = 4.2309  Validation loss = 7.2133  \n",
      "\n",
      "Fold: 13  Epoch: 204  Training loss = 4.2306  Validation loss = 7.2128  \n",
      "\n",
      "Fold: 13  Epoch: 205  Training loss = 4.2302  Validation loss = 7.2123  \n",
      "\n",
      "Fold: 13  Epoch: 206  Training loss = 4.2299  Validation loss = 7.2117  \n",
      "\n",
      "Fold: 13  Epoch: 207  Training loss = 4.2295  Validation loss = 7.2112  \n",
      "\n",
      "Fold: 13  Epoch: 208  Training loss = 4.2291  Validation loss = 7.2106  \n",
      "\n",
      "Fold: 13  Epoch: 209  Training loss = 4.2286  Validation loss = 7.2099  \n",
      "\n",
      "Fold: 13  Epoch: 210  Training loss = 4.2282  Validation loss = 7.2092  \n",
      "\n",
      "Fold: 13  Epoch: 211  Training loss = 4.2278  Validation loss = 7.2086  \n",
      "\n",
      "Fold: 13  Epoch: 212  Training loss = 4.2274  Validation loss = 7.2080  \n",
      "\n",
      "Fold: 13  Epoch: 213  Training loss = 4.2271  Validation loss = 7.2075  \n",
      "\n",
      "Fold: 13  Epoch: 214  Training loss = 4.2267  Validation loss = 7.2070  \n",
      "\n",
      "Fold: 13  Epoch: 215  Training loss = 4.2262  Validation loss = 7.2063  \n",
      "\n",
      "Fold: 13  Epoch: 216  Training loss = 4.2258  Validation loss = 7.2057  \n",
      "\n",
      "Fold: 13  Epoch: 217  Training loss = 4.2255  Validation loss = 7.2052  \n",
      "\n",
      "Fold: 13  Epoch: 218  Training loss = 4.2251  Validation loss = 7.2046  \n",
      "\n",
      "Fold: 13  Epoch: 219  Training loss = 4.2248  Validation loss = 7.2041  \n",
      "\n",
      "Fold: 13  Epoch: 220  Training loss = 4.2245  Validation loss = 7.2037  \n",
      "\n",
      "Fold: 13  Epoch: 221  Training loss = 4.2241  Validation loss = 7.2030  \n",
      "\n",
      "Fold: 13  Epoch: 222  Training loss = 4.2238  Validation loss = 7.2026  \n",
      "\n",
      "Fold: 13  Epoch: 223  Training loss = 4.2234  Validation loss = 7.2020  \n",
      "\n",
      "Fold: 13  Epoch: 224  Training loss = 4.2230  Validation loss = 7.2014  \n",
      "\n",
      "Fold: 13  Epoch: 225  Training loss = 4.2227  Validation loss = 7.2009  \n",
      "\n",
      "Fold: 13  Epoch: 226  Training loss = 4.2222  Validation loss = 7.2003  \n",
      "\n",
      "Fold: 13  Epoch: 227  Training loss = 4.2219  Validation loss = 7.1998  \n",
      "\n",
      "Fold: 13  Epoch: 228  Training loss = 4.2216  Validation loss = 7.1993  \n",
      "\n",
      "Fold: 13  Epoch: 229  Training loss = 4.2213  Validation loss = 7.1988  \n",
      "\n",
      "Fold: 13  Epoch: 230  Training loss = 4.2209  Validation loss = 7.1982  \n",
      "\n",
      "Fold: 13  Epoch: 231  Training loss = 4.2206  Validation loss = 7.1977  \n",
      "\n",
      "Fold: 13  Epoch: 232  Training loss = 4.2202  Validation loss = 7.1972  \n",
      "\n",
      "Fold: 13  Epoch: 233  Training loss = 4.2198  Validation loss = 7.1966  \n",
      "\n",
      "Fold: 13  Epoch: 234  Training loss = 4.2195  Validation loss = 7.1961  \n",
      "\n",
      "Fold: 13  Epoch: 235  Training loss = 4.2190  Validation loss = 7.1954  \n",
      "\n",
      "Fold: 13  Epoch: 236  Training loss = 4.2187  Validation loss = 7.1949  \n",
      "\n",
      "Fold: 13  Epoch: 237  Training loss = 4.2183  Validation loss = 7.1943  \n",
      "\n",
      "Fold: 13  Epoch: 238  Training loss = 4.2181  Validation loss = 7.1939  \n",
      "\n",
      "Fold: 13  Epoch: 239  Training loss = 4.2177  Validation loss = 7.1934  \n",
      "\n",
      "Fold: 13  Epoch: 240  Training loss = 4.2174  Validation loss = 7.1928  \n",
      "\n",
      "Fold: 13  Epoch: 241  Training loss = 4.2171  Validation loss = 7.1924  \n",
      "\n",
      "Fold: 13  Epoch: 242  Training loss = 4.2167  Validation loss = 7.1919  \n",
      "\n",
      "Fold: 13  Epoch: 243  Training loss = 4.2163  Validation loss = 7.1913  \n",
      "\n",
      "Fold: 13  Epoch: 244  Training loss = 4.2159  Validation loss = 7.1907  \n",
      "\n",
      "Fold: 13  Epoch: 245  Training loss = 4.2155  Validation loss = 7.1901  \n",
      "\n",
      "Fold: 13  Epoch: 246  Training loss = 4.2152  Validation loss = 7.1896  \n",
      "\n",
      "Fold: 13  Epoch: 247  Training loss = 4.2148  Validation loss = 7.1890  \n",
      "\n",
      "Fold: 13  Epoch: 248  Training loss = 4.2144  Validation loss = 7.1884  \n",
      "\n",
      "Fold: 13  Epoch: 249  Training loss = 4.2140  Validation loss = 7.1878  \n",
      "\n",
      "Fold: 13  Epoch: 250  Training loss = 4.2137  Validation loss = 7.1874  \n",
      "\n",
      "Fold: 13  Epoch: 251  Training loss = 4.2133  Validation loss = 7.1868  \n",
      "\n",
      "Fold: 13  Epoch: 252  Training loss = 4.2130  Validation loss = 7.1862  \n",
      "\n",
      "Fold: 13  Epoch: 253  Training loss = 4.2127  Validation loss = 7.1858  \n",
      "\n",
      "Fold: 13  Epoch: 254  Training loss = 4.2123  Validation loss = 7.1852  \n",
      "\n",
      "Fold: 13  Epoch: 255  Training loss = 4.2119  Validation loss = 7.1846  \n",
      "\n",
      "Fold: 13  Epoch: 256  Training loss = 4.2115  Validation loss = 7.1840  \n",
      "\n",
      "Fold: 13  Epoch: 257  Training loss = 4.2111  Validation loss = 7.1834  \n",
      "\n",
      "Fold: 13  Epoch: 258  Training loss = 4.2107  Validation loss = 7.1829  \n",
      "\n",
      "Fold: 13  Epoch: 259  Training loss = 4.2103  Validation loss = 7.1822  \n",
      "\n",
      "Fold: 13  Epoch: 260  Training loss = 4.2099  Validation loss = 7.1817  \n",
      "\n",
      "Fold: 13  Epoch: 261  Training loss = 4.2095  Validation loss = 7.1811  \n",
      "\n",
      "Fold: 13  Epoch: 262  Training loss = 4.2092  Validation loss = 7.1805  \n",
      "\n",
      "Fold: 13  Epoch: 263  Training loss = 4.2089  Validation loss = 7.1800  \n",
      "\n",
      "Fold: 13  Epoch: 264  Training loss = 4.2084  Validation loss = 7.1794  \n",
      "\n",
      "Fold: 13  Epoch: 265  Training loss = 4.2081  Validation loss = 7.1789  \n",
      "\n",
      "Fold: 13  Epoch: 266  Training loss = 4.2077  Validation loss = 7.1783  \n",
      "\n",
      "Fold: 13  Epoch: 267  Training loss = 4.2074  Validation loss = 7.1778  \n",
      "\n",
      "Fold: 13  Epoch: 268  Training loss = 4.2071  Validation loss = 7.1774  \n",
      "\n",
      "Fold: 13  Epoch: 269  Training loss = 4.2067  Validation loss = 7.1767  \n",
      "\n",
      "Fold: 13  Epoch: 270  Training loss = 4.2062  Validation loss = 7.1760  \n",
      "\n",
      "Fold: 13  Epoch: 271  Training loss = 4.2059  Validation loss = 7.1755  \n",
      "\n",
      "Fold: 13  Epoch: 272  Training loss = 4.2056  Validation loss = 7.1750  \n",
      "\n",
      "Fold: 13  Epoch: 273  Training loss = 4.2052  Validation loss = 7.1745  \n",
      "\n",
      "Fold: 13  Epoch: 274  Training loss = 4.2048  Validation loss = 7.1739  \n",
      "\n",
      "Fold: 13  Epoch: 275  Training loss = 4.2044  Validation loss = 7.1733  \n",
      "\n",
      "Fold: 13  Epoch: 276  Training loss = 4.2040  Validation loss = 7.1727  \n",
      "\n",
      "Fold: 13  Epoch: 277  Training loss = 4.2037  Validation loss = 7.1722  \n",
      "\n",
      "Fold: 13  Epoch: 278  Training loss = 4.2033  Validation loss = 7.1716  \n",
      "\n",
      "Fold: 13  Epoch: 279  Training loss = 4.2030  Validation loss = 7.1712  \n",
      "\n",
      "Fold: 13  Epoch: 280  Training loss = 4.2027  Validation loss = 7.1708  \n",
      "\n",
      "Fold: 13  Epoch: 281  Training loss = 4.2024  Validation loss = 7.1703  \n",
      "\n",
      "Fold: 13  Epoch: 282  Training loss = 4.2021  Validation loss = 7.1698  \n",
      "\n",
      "Fold: 13  Epoch: 283  Training loss = 4.2017  Validation loss = 7.1692  \n",
      "\n",
      "Fold: 13  Epoch: 284  Training loss = 4.2014  Validation loss = 7.1687  \n",
      "\n",
      "Fold: 13  Epoch: 285  Training loss = 4.2009  Validation loss = 7.1680  \n",
      "\n",
      "Fold: 13  Epoch: 286  Training loss = 4.2005  Validation loss = 7.1674  \n",
      "\n",
      "Fold: 13  Epoch: 287  Training loss = 4.2001  Validation loss = 7.1668  \n",
      "\n",
      "Fold: 13  Epoch: 288  Training loss = 4.1997  Validation loss = 7.1662  \n",
      "\n",
      "Fold: 13  Epoch: 289  Training loss = 4.1994  Validation loss = 7.1657  \n",
      "\n",
      "Fold: 13  Epoch: 290  Training loss = 4.1991  Validation loss = 7.1652  \n",
      "\n",
      "Fold: 13  Epoch: 291  Training loss = 4.1987  Validation loss = 7.1646  \n",
      "\n",
      "Fold: 13  Epoch: 292  Training loss = 4.1983  Validation loss = 7.1640  \n",
      "\n",
      "Fold: 13  Epoch: 293  Training loss = 4.1980  Validation loss = 7.1635  \n",
      "\n",
      "Fold: 13  Epoch: 294  Training loss = 4.1976  Validation loss = 7.1629  \n",
      "\n",
      "Fold: 13  Epoch: 295  Training loss = 4.1971  Validation loss = 7.1622  \n",
      "\n",
      "Fold: 13  Epoch: 296  Training loss = 4.1968  Validation loss = 7.1617  \n",
      "\n",
      "Fold: 13  Epoch: 297  Training loss = 4.1964  Validation loss = 7.1611  \n",
      "\n",
      "Fold: 13  Epoch: 298  Training loss = 4.1961  Validation loss = 7.1606  \n",
      "\n",
      "Fold: 13  Epoch: 299  Training loss = 4.1957  Validation loss = 7.1601  \n",
      "\n",
      "Fold: 13  Epoch: 300  Training loss = 4.1952  Validation loss = 7.1594  \n",
      "\n",
      "Fold: 13  Epoch: 301  Training loss = 4.1948  Validation loss = 7.1587  \n",
      "\n",
      "Fold: 13  Epoch: 302  Training loss = 4.1944  Validation loss = 7.1581  \n",
      "\n",
      "Fold: 13  Epoch: 303  Training loss = 4.1941  Validation loss = 7.1576  \n",
      "\n",
      "Fold: 13  Epoch: 304  Training loss = 4.1939  Validation loss = 7.1572  \n",
      "\n",
      "Fold: 13  Epoch: 305  Training loss = 4.1934  Validation loss = 7.1565  \n",
      "\n",
      "Fold: 13  Epoch: 306  Training loss = 4.1930  Validation loss = 7.1560  \n",
      "\n",
      "Fold: 13  Epoch: 307  Training loss = 4.1926  Validation loss = 7.1554  \n",
      "\n",
      "Fold: 13  Epoch: 308  Training loss = 4.1923  Validation loss = 7.1549  \n",
      "\n",
      "Fold: 13  Epoch: 309  Training loss = 4.1919  Validation loss = 7.1543  \n",
      "\n",
      "Fold: 13  Epoch: 310  Training loss = 4.1916  Validation loss = 7.1538  \n",
      "\n",
      "Fold: 13  Epoch: 311  Training loss = 4.1912  Validation loss = 7.1533  \n",
      "\n",
      "Fold: 13  Epoch: 312  Training loss = 4.1908  Validation loss = 7.1526  \n",
      "\n",
      "Fold: 13  Epoch: 313  Training loss = 4.1905  Validation loss = 7.1521  \n",
      "\n",
      "Fold: 13  Epoch: 314  Training loss = 4.1901  Validation loss = 7.1515  \n",
      "\n",
      "Fold: 13  Epoch: 315  Training loss = 4.1897  Validation loss = 7.1510  \n",
      "\n",
      "Fold: 13  Epoch: 316  Training loss = 4.1893  Validation loss = 7.1504  \n",
      "\n",
      "Fold: 13  Epoch: 317  Training loss = 4.1889  Validation loss = 7.1498  \n",
      "\n",
      "Fold: 13  Epoch: 318  Training loss = 4.1885  Validation loss = 7.1491  \n",
      "\n",
      "Fold: 13  Epoch: 319  Training loss = 4.1881  Validation loss = 7.1486  \n",
      "\n",
      "Fold: 13  Epoch: 320  Training loss = 4.1879  Validation loss = 7.1482  \n",
      "\n",
      "Fold: 13  Epoch: 321  Training loss = 4.1875  Validation loss = 7.1477  \n",
      "\n",
      "Fold: 13  Epoch: 322  Training loss = 4.1871  Validation loss = 7.1471  \n",
      "\n",
      "Fold: 13  Epoch: 323  Training loss = 4.1868  Validation loss = 7.1465  \n",
      "\n",
      "Fold: 13  Epoch: 324  Training loss = 4.1864  Validation loss = 7.1459  \n",
      "\n",
      "Fold: 13  Epoch: 325  Training loss = 4.1860  Validation loss = 7.1453  \n",
      "\n",
      "Fold: 13  Epoch: 326  Training loss = 4.1856  Validation loss = 7.1448  \n",
      "\n",
      "Fold: 13  Epoch: 327  Training loss = 4.1854  Validation loss = 7.1443  \n",
      "\n",
      "Fold: 13  Epoch: 328  Training loss = 4.1849  Validation loss = 7.1437  \n",
      "\n",
      "Fold: 13  Epoch: 329  Training loss = 4.1846  Validation loss = 7.1432  \n",
      "\n",
      "Fold: 13  Epoch: 330  Training loss = 4.1842  Validation loss = 7.1426  \n",
      "\n",
      "Fold: 13  Epoch: 331  Training loss = 4.1839  Validation loss = 7.1421  \n",
      "\n",
      "Fold: 13  Epoch: 332  Training loss = 4.1835  Validation loss = 7.1415  \n",
      "\n",
      "Fold: 13  Epoch: 333  Training loss = 4.1832  Validation loss = 7.1410  \n",
      "\n",
      "Fold: 13  Epoch: 334  Training loss = 4.1827  Validation loss = 7.1403  \n",
      "\n",
      "Fold: 13  Epoch: 335  Training loss = 4.1824  Validation loss = 7.1398  \n",
      "\n",
      "Fold: 13  Epoch: 336  Training loss = 4.1820  Validation loss = 7.1393  \n",
      "\n",
      "Fold: 13  Epoch: 337  Training loss = 4.1816  Validation loss = 7.1387  \n",
      "\n",
      "Fold: 13  Epoch: 338  Training loss = 4.1812  Validation loss = 7.1381  \n",
      "\n",
      "Fold: 13  Epoch: 339  Training loss = 4.1808  Validation loss = 7.1376  \n",
      "\n",
      "Fold: 13  Epoch: 340  Training loss = 4.1805  Validation loss = 7.1371  \n",
      "\n",
      "Fold: 13  Epoch: 341  Training loss = 4.1802  Validation loss = 7.1365  \n",
      "\n",
      "Fold: 13  Epoch: 342  Training loss = 4.1799  Validation loss = 7.1360  \n",
      "\n",
      "Fold: 13  Epoch: 343  Training loss = 4.1795  Validation loss = 7.1355  \n",
      "\n",
      "Fold: 13  Epoch: 344  Training loss = 4.1791  Validation loss = 7.1350  \n",
      "\n",
      "Fold: 13  Epoch: 345  Training loss = 4.1788  Validation loss = 7.1345  \n",
      "\n",
      "Fold: 13  Epoch: 346  Training loss = 4.1785  Validation loss = 7.1340  \n",
      "\n",
      "Fold: 13  Epoch: 347  Training loss = 4.1782  Validation loss = 7.1335  \n",
      "\n",
      "Fold: 13  Epoch: 348  Training loss = 4.1778  Validation loss = 7.1330  \n",
      "\n",
      "Fold: 13  Epoch: 349  Training loss = 4.1775  Validation loss = 7.1325  \n",
      "\n",
      "Fold: 13  Epoch: 350  Training loss = 4.1771  Validation loss = 7.1319  \n",
      "\n",
      "Fold: 13  Epoch: 351  Training loss = 4.1768  Validation loss = 7.1314  \n",
      "\n",
      "Fold: 13  Epoch: 352  Training loss = 4.1764  Validation loss = 7.1308  \n",
      "\n",
      "Fold: 13  Epoch: 353  Training loss = 4.1760  Validation loss = 7.1302  \n",
      "\n",
      "Fold: 13  Epoch: 354  Training loss = 4.1756  Validation loss = 7.1296  \n",
      "\n",
      "Fold: 13  Epoch: 355  Training loss = 4.1752  Validation loss = 7.1290  \n",
      "\n",
      "Fold: 13  Epoch: 356  Training loss = 4.1748  Validation loss = 7.1284  \n",
      "\n",
      "Fold: 13  Epoch: 357  Training loss = 4.1745  Validation loss = 7.1279  \n",
      "\n",
      "Fold: 13  Epoch: 358  Training loss = 4.1741  Validation loss = 7.1273  \n",
      "\n",
      "Fold: 13  Epoch: 359  Training loss = 4.1737  Validation loss = 7.1267  \n",
      "\n",
      "Fold: 13  Epoch: 360  Training loss = 4.1734  Validation loss = 7.1262  \n",
      "\n",
      "Fold: 13  Epoch: 361  Training loss = 4.1731  Validation loss = 7.1258  \n",
      "\n",
      "Fold: 13  Epoch: 362  Training loss = 4.1728  Validation loss = 7.1253  \n",
      "\n",
      "Fold: 13  Epoch: 363  Training loss = 4.1725  Validation loss = 7.1248  \n",
      "\n",
      "Fold: 13  Epoch: 364  Training loss = 4.1720  Validation loss = 7.1242  \n",
      "\n",
      "Fold: 13  Epoch: 365  Training loss = 4.1716  Validation loss = 7.1236  \n",
      "\n",
      "Fold: 13  Epoch: 366  Training loss = 4.1713  Validation loss = 7.1230  \n",
      "\n",
      "Fold: 13  Epoch: 367  Training loss = 4.1709  Validation loss = 7.1224  \n",
      "\n",
      "Fold: 13  Epoch: 368  Training loss = 4.1706  Validation loss = 7.1220  \n",
      "\n",
      "Fold: 13  Epoch: 369  Training loss = 4.1701  Validation loss = 7.1213  \n",
      "\n",
      "Fold: 13  Epoch: 370  Training loss = 4.1698  Validation loss = 7.1208  \n",
      "\n",
      "Fold: 13  Epoch: 371  Training loss = 4.1695  Validation loss = 7.1203  \n",
      "\n",
      "Fold: 13  Epoch: 372  Training loss = 4.1692  Validation loss = 7.1198  \n",
      "\n",
      "Fold: 13  Epoch: 373  Training loss = 4.1689  Validation loss = 7.1193  \n",
      "\n",
      "Fold: 13  Epoch: 374  Training loss = 4.1685  Validation loss = 7.1188  \n",
      "\n",
      "Fold: 13  Epoch: 375  Training loss = 4.1682  Validation loss = 7.1183  \n",
      "\n",
      "Fold: 13  Epoch: 376  Training loss = 4.1679  Validation loss = 7.1178  \n",
      "\n",
      "Fold: 13  Epoch: 377  Training loss = 4.1676  Validation loss = 7.1173  \n",
      "\n",
      "Fold: 13  Epoch: 378  Training loss = 4.1673  Validation loss = 7.1169  \n",
      "\n",
      "Fold: 13  Epoch: 379  Training loss = 4.1670  Validation loss = 7.1164  \n",
      "\n",
      "Fold: 13  Epoch: 380  Training loss = 4.1665  Validation loss = 7.1158  \n",
      "\n",
      "Fold: 13  Epoch: 381  Training loss = 4.1662  Validation loss = 7.1152  \n",
      "\n",
      "Fold: 13  Epoch: 382  Training loss = 4.1659  Validation loss = 7.1148  \n",
      "\n",
      "Fold: 13  Epoch: 383  Training loss = 4.1656  Validation loss = 7.1143  \n",
      "\n",
      "Fold: 13  Epoch: 384  Training loss = 4.1653  Validation loss = 7.1139  \n",
      "\n",
      "Fold: 13  Epoch: 385  Training loss = 4.1649  Validation loss = 7.1133  \n",
      "\n",
      "Fold: 13  Epoch: 386  Training loss = 4.1646  Validation loss = 7.1128  \n",
      "\n",
      "Fold: 13  Epoch: 387  Training loss = 4.1642  Validation loss = 7.1123  \n",
      "\n",
      "Fold: 13  Epoch: 388  Training loss = 4.1639  Validation loss = 7.1117  \n",
      "\n",
      "Fold: 13  Epoch: 389  Training loss = 4.1636  Validation loss = 7.1112  \n",
      "\n",
      "Fold: 13  Epoch: 390  Training loss = 4.1631  Validation loss = 7.1106  \n",
      "\n",
      "Fold: 13  Epoch: 391  Training loss = 4.1628  Validation loss = 7.1100  \n",
      "\n",
      "Fold: 13  Epoch: 392  Training loss = 4.1624  Validation loss = 7.1094  \n",
      "\n",
      "Fold: 13  Epoch: 393  Training loss = 4.1621  Validation loss = 7.1089  \n",
      "\n",
      "Fold: 13  Epoch: 394  Training loss = 4.1617  Validation loss = 7.1083  \n",
      "\n",
      "Fold: 13  Epoch: 395  Training loss = 4.1614  Validation loss = 7.1079  \n",
      "\n",
      "Fold: 13  Epoch: 396  Training loss = 4.1610  Validation loss = 7.1073  \n",
      "\n",
      "Fold: 13  Epoch: 397  Training loss = 4.1606  Validation loss = 7.1068  \n",
      "\n",
      "Fold: 13  Epoch: 398  Training loss = 4.1603  Validation loss = 7.1063  \n",
      "\n",
      "Fold: 13  Epoch: 399  Training loss = 4.1599  Validation loss = 7.1056  \n",
      "\n",
      "Fold: 13  Epoch: 400  Training loss = 4.1595  Validation loss = 7.1051  \n",
      "\n",
      "Fold: 13  Epoch: 401  Training loss = 4.1592  Validation loss = 7.1045  \n",
      "\n",
      "Fold: 13  Epoch: 402  Training loss = 4.1588  Validation loss = 7.1040  \n",
      "\n",
      "Fold: 13  Epoch: 403  Training loss = 4.1585  Validation loss = 7.1034  \n",
      "\n",
      "Fold: 13  Epoch: 404  Training loss = 4.1581  Validation loss = 7.1029  \n",
      "\n",
      "Fold: 13  Epoch: 405  Training loss = 4.1579  Validation loss = 7.1025  \n",
      "\n",
      "Fold: 13  Epoch: 406  Training loss = 4.1576  Validation loss = 7.1021  \n",
      "\n",
      "Fold: 13  Epoch: 407  Training loss = 4.1572  Validation loss = 7.1015  \n",
      "\n",
      "Fold: 13  Epoch: 408  Training loss = 4.1568  Validation loss = 7.1009  \n",
      "\n",
      "Fold: 13  Epoch: 409  Training loss = 4.1564  Validation loss = 7.1003  \n",
      "\n",
      "Fold: 13  Epoch: 410  Training loss = 4.1560  Validation loss = 7.0997  \n",
      "\n",
      "Fold: 13  Epoch: 411  Training loss = 4.1557  Validation loss = 7.0992  \n",
      "\n",
      "Fold: 13  Epoch: 412  Training loss = 4.1553  Validation loss = 7.0986  \n",
      "\n",
      "Fold: 13  Epoch: 413  Training loss = 4.1549  Validation loss = 7.0980  \n",
      "\n",
      "Fold: 13  Epoch: 414  Training loss = 4.1544  Validation loss = 7.0973  \n",
      "\n",
      "Fold: 13  Epoch: 415  Training loss = 4.1541  Validation loss = 7.0967  \n",
      "\n",
      "Fold: 13  Epoch: 416  Training loss = 4.1537  Validation loss = 7.0962  \n",
      "\n",
      "Fold: 13  Epoch: 417  Training loss = 4.1533  Validation loss = 7.0955  \n",
      "\n",
      "Fold: 13  Epoch: 418  Training loss = 4.1530  Validation loss = 7.0950  \n",
      "\n",
      "Fold: 13  Epoch: 419  Training loss = 4.1526  Validation loss = 7.0944  \n",
      "\n",
      "Fold: 13  Epoch: 420  Training loss = 4.1522  Validation loss = 7.0938  \n",
      "\n",
      "Fold: 13  Epoch: 421  Training loss = 4.1518  Validation loss = 7.0932  \n",
      "\n",
      "Fold: 13  Epoch: 422  Training loss = 4.1515  Validation loss = 7.0928  \n",
      "\n",
      "Fold: 13  Epoch: 423  Training loss = 4.1510  Validation loss = 7.0921  \n",
      "\n",
      "Fold: 13  Epoch: 424  Training loss = 4.1507  Validation loss = 7.0915  \n",
      "\n",
      "Fold: 13  Epoch: 425  Training loss = 4.1504  Validation loss = 7.0911  \n",
      "\n",
      "Fold: 13  Epoch: 426  Training loss = 4.1500  Validation loss = 7.0905  \n",
      "\n",
      "Fold: 13  Epoch: 427  Training loss = 4.1497  Validation loss = 7.0900  \n",
      "\n",
      "Fold: 13  Epoch: 428  Training loss = 4.1493  Validation loss = 7.0894  \n",
      "\n",
      "Fold: 13  Epoch: 429  Training loss = 4.1489  Validation loss = 7.0889  \n",
      "\n",
      "Fold: 13  Epoch: 430  Training loss = 4.1486  Validation loss = 7.0884  \n",
      "\n",
      "Fold: 13  Epoch: 431  Training loss = 4.1483  Validation loss = 7.0880  \n",
      "\n",
      "Fold: 13  Epoch: 432  Training loss = 4.1480  Validation loss = 7.0875  \n",
      "\n",
      "Fold: 13  Epoch: 433  Training loss = 4.1476  Validation loss = 7.0869  \n",
      "\n",
      "Fold: 13  Epoch: 434  Training loss = 4.1472  Validation loss = 7.0864  \n",
      "\n",
      "Fold: 13  Epoch: 435  Training loss = 4.1469  Validation loss = 7.0859  \n",
      "\n",
      "Fold: 13  Epoch: 436  Training loss = 4.1466  Validation loss = 7.0854  \n",
      "\n",
      "Fold: 13  Epoch: 437  Training loss = 4.1462  Validation loss = 7.0848  \n",
      "\n",
      "Fold: 13  Epoch: 438  Training loss = 4.1458  Validation loss = 7.0842  \n",
      "\n",
      "Fold: 13  Epoch: 439  Training loss = 4.1455  Validation loss = 7.0836  \n",
      "\n",
      "Fold: 13  Epoch: 440  Training loss = 4.1451  Validation loss = 7.0831  \n",
      "\n",
      "Fold: 13  Epoch: 441  Training loss = 4.1448  Validation loss = 7.0827  \n",
      "\n",
      "Fold: 13  Epoch: 442  Training loss = 4.1445  Validation loss = 7.0822  \n",
      "\n",
      "Fold: 13  Epoch: 443  Training loss = 4.1440  Validation loss = 7.0815  \n",
      "\n",
      "Fold: 13  Epoch: 444  Training loss = 4.1436  Validation loss = 7.0808  \n",
      "\n",
      "Fold: 13  Epoch: 445  Training loss = 4.1432  Validation loss = 7.0802  \n",
      "\n",
      "Fold: 13  Epoch: 446  Training loss = 4.1428  Validation loss = 7.0796  \n",
      "\n",
      "Fold: 13  Epoch: 447  Training loss = 4.1425  Validation loss = 7.0792  \n",
      "\n",
      "Fold: 13  Epoch: 448  Training loss = 4.1421  Validation loss = 7.0786  \n",
      "\n",
      "Fold: 13  Epoch: 449  Training loss = 4.1418  Validation loss = 7.0781  \n",
      "\n",
      "Fold: 13  Epoch: 450  Training loss = 4.1414  Validation loss = 7.0775  \n",
      "\n",
      "Fold: 13  Epoch: 451  Training loss = 4.1411  Validation loss = 7.0770  \n",
      "\n",
      "Fold: 13  Epoch: 452  Training loss = 4.1407  Validation loss = 7.0764  \n",
      "\n",
      "Fold: 13  Epoch: 453  Training loss = 4.1404  Validation loss = 7.0759  \n",
      "\n",
      "Fold: 13  Epoch: 454  Training loss = 4.1400  Validation loss = 7.0753  \n",
      "\n",
      "Fold: 13  Epoch: 455  Training loss = 4.1397  Validation loss = 7.0748  \n",
      "\n",
      "Fold: 13  Epoch: 456  Training loss = 4.1394  Validation loss = 7.0743  \n",
      "\n",
      "Fold: 13  Epoch: 457  Training loss = 4.1390  Validation loss = 7.0737  \n",
      "\n",
      "Fold: 13  Epoch: 458  Training loss = 4.1386  Validation loss = 7.0732  \n",
      "\n",
      "Fold: 13  Epoch: 459  Training loss = 4.1382  Validation loss = 7.0726  \n",
      "\n",
      "Fold: 13  Epoch: 460  Training loss = 4.1378  Validation loss = 7.0720  \n",
      "\n",
      "Fold: 13  Epoch: 461  Training loss = 4.1375  Validation loss = 7.0715  \n",
      "\n",
      "Fold: 13  Epoch: 462  Training loss = 4.1371  Validation loss = 7.0708  \n",
      "\n",
      "Fold: 13  Epoch: 463  Training loss = 4.1367  Validation loss = 7.0702  \n",
      "\n",
      "Fold: 13  Epoch: 464  Training loss = 4.1362  Validation loss = 7.0696  \n",
      "\n",
      "Fold: 13  Epoch: 465  Training loss = 4.1360  Validation loss = 7.0691  \n",
      "\n",
      "Fold: 13  Epoch: 466  Training loss = 4.1357  Validation loss = 7.0686  \n",
      "\n",
      "Fold: 13  Epoch: 467  Training loss = 4.1353  Validation loss = 7.0682  \n",
      "\n",
      "Fold: 13  Epoch: 468  Training loss = 4.1350  Validation loss = 7.0676  \n",
      "\n",
      "Fold: 13  Epoch: 469  Training loss = 4.1346  Validation loss = 7.0670  \n",
      "\n",
      "Fold: 13  Epoch: 470  Training loss = 4.1343  Validation loss = 7.0665  \n",
      "\n",
      "Fold: 13  Epoch: 471  Training loss = 4.1339  Validation loss = 7.0660  \n",
      "\n",
      "Fold: 13  Epoch: 472  Training loss = 4.1336  Validation loss = 7.0654  \n",
      "\n",
      "Fold: 13  Epoch: 473  Training loss = 4.1333  Validation loss = 7.0650  \n",
      "\n",
      "Fold: 13  Epoch: 474  Training loss = 4.1330  Validation loss = 7.0646  \n",
      "\n",
      "Fold: 13  Epoch: 475  Training loss = 4.1327  Validation loss = 7.0641  \n",
      "\n",
      "Fold: 13  Epoch: 476  Training loss = 4.1323  Validation loss = 7.0634  \n",
      "\n",
      "Fold: 13  Epoch: 477  Training loss = 4.1319  Validation loss = 7.0628  \n",
      "\n",
      "Fold: 13  Epoch: 478  Training loss = 4.1316  Validation loss = 7.0623  \n",
      "\n",
      "Fold: 13  Epoch: 479  Training loss = 4.1313  Validation loss = 7.0618  \n",
      "\n",
      "Fold: 13  Epoch: 480  Training loss = 4.1309  Validation loss = 7.0612  \n",
      "\n",
      "Fold: 13  Epoch: 481  Training loss = 4.1305  Validation loss = 7.0606  \n",
      "\n",
      "Fold: 13  Epoch: 482  Training loss = 4.1301  Validation loss = 7.0600  \n",
      "\n",
      "Fold: 13  Epoch: 483  Training loss = 4.1297  Validation loss = 7.0594  \n",
      "\n",
      "Fold: 13  Epoch: 484  Training loss = 4.1294  Validation loss = 7.0589  \n",
      "\n",
      "Fold: 13  Epoch: 485  Training loss = 4.1290  Validation loss = 7.0583  \n",
      "\n",
      "Fold: 13  Epoch: 486  Training loss = 4.1286  Validation loss = 7.0577  \n",
      "\n",
      "Fold: 13  Epoch: 487  Training loss = 4.1283  Validation loss = 7.0573  \n",
      "\n",
      "Fold: 13  Epoch: 488  Training loss = 4.1280  Validation loss = 7.0567  \n",
      "\n",
      "Fold: 13  Epoch: 489  Training loss = 4.1276  Validation loss = 7.0562  \n",
      "\n",
      "Fold: 13  Epoch: 490  Training loss = 4.1272  Validation loss = 7.0555  \n",
      "\n",
      "Fold: 13  Epoch: 491  Training loss = 4.1268  Validation loss = 7.0549  \n",
      "\n",
      "Fold: 13  Epoch: 492  Training loss = 4.1265  Validation loss = 7.0544  \n",
      "\n",
      "Fold: 13  Epoch: 493  Training loss = 4.1260  Validation loss = 7.0537  \n",
      "\n",
      "Fold: 13  Epoch: 494  Training loss = 4.1257  Validation loss = 7.0532  \n",
      "\n",
      "Fold: 13  Epoch: 495  Training loss = 4.1253  Validation loss = 7.0526  \n",
      "\n",
      "Fold: 13  Epoch: 496  Training loss = 4.1250  Validation loss = 7.0522  \n",
      "\n",
      "Fold: 13  Epoch: 497  Training loss = 4.1246  Validation loss = 7.0516  \n",
      "\n",
      "Fold: 13  Epoch: 498  Training loss = 4.1244  Validation loss = 7.0512  \n",
      "\n",
      "Fold: 13  Epoch: 499  Training loss = 4.1240  Validation loss = 7.0506  \n",
      "\n",
      "Fold: 13  Epoch: 500  Training loss = 4.1237  Validation loss = 7.0502  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 500  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 4.4777  Validation loss = 10.9013  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 4.4772  Validation loss = 10.9007  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 4.4768  Validation loss = 10.9001  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 4.4763  Validation loss = 10.8996  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 4.4759  Validation loss = 10.8989  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 4.4755  Validation loss = 10.8983  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 4.4751  Validation loss = 10.8978  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 4.4747  Validation loss = 10.8973  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 4.4742  Validation loss = 10.8967  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 4.4738  Validation loss = 10.8960  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 4.4733  Validation loss = 10.8954  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 4.4728  Validation loss = 10.8949  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 4.4724  Validation loss = 10.8943  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 4.4720  Validation loss = 10.8938  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 4.4716  Validation loss = 10.8933  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 4.4712  Validation loss = 10.8928  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 4.4707  Validation loss = 10.8921  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 4.4703  Validation loss = 10.8916  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 4.4699  Validation loss = 10.8911  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 4.4694  Validation loss = 10.8904  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 4.4691  Validation loss = 10.8900  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 4.4686  Validation loss = 10.8893  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 4.4681  Validation loss = 10.8887  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 4.4677  Validation loss = 10.8881  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 4.4673  Validation loss = 10.8876  \n",
      "\n",
      "Fold: 14  Epoch: 26  Training loss = 4.4668  Validation loss = 10.8870  \n",
      "\n",
      "Fold: 14  Epoch: 27  Training loss = 4.4664  Validation loss = 10.8865  \n",
      "\n",
      "Fold: 14  Epoch: 28  Training loss = 4.4660  Validation loss = 10.8859  \n",
      "\n",
      "Fold: 14  Epoch: 29  Training loss = 4.4655  Validation loss = 10.8853  \n",
      "\n",
      "Fold: 14  Epoch: 30  Training loss = 4.4651  Validation loss = 10.8848  \n",
      "\n",
      "Fold: 14  Epoch: 31  Training loss = 4.4646  Validation loss = 10.8842  \n",
      "\n",
      "Fold: 14  Epoch: 32  Training loss = 4.4640  Validation loss = 10.8835  \n",
      "\n",
      "Fold: 14  Epoch: 33  Training loss = 4.4636  Validation loss = 10.8830  \n",
      "\n",
      "Fold: 14  Epoch: 34  Training loss = 4.4632  Validation loss = 10.8824  \n",
      "\n",
      "Fold: 14  Epoch: 35  Training loss = 4.4627  Validation loss = 10.8818  \n",
      "\n",
      "Fold: 14  Epoch: 36  Training loss = 4.4623  Validation loss = 10.8812  \n",
      "\n",
      "Fold: 14  Epoch: 37  Training loss = 4.4618  Validation loss = 10.8806  \n",
      "\n",
      "Fold: 14  Epoch: 38  Training loss = 4.4614  Validation loss = 10.8800  \n",
      "\n",
      "Fold: 14  Epoch: 39  Training loss = 4.4610  Validation loss = 10.8795  \n",
      "\n",
      "Fold: 14  Epoch: 40  Training loss = 4.4606  Validation loss = 10.8789  \n",
      "\n",
      "Fold: 14  Epoch: 41  Training loss = 4.4601  Validation loss = 10.8783  \n",
      "\n",
      "Fold: 14  Epoch: 42  Training loss = 4.4597  Validation loss = 10.8778  \n",
      "\n",
      "Fold: 14  Epoch: 43  Training loss = 4.4593  Validation loss = 10.8772  \n",
      "\n",
      "Fold: 14  Epoch: 44  Training loss = 4.4588  Validation loss = 10.8766  \n",
      "\n",
      "Fold: 14  Epoch: 45  Training loss = 4.4584  Validation loss = 10.8760  \n",
      "\n",
      "Fold: 14  Epoch: 46  Training loss = 4.4580  Validation loss = 10.8755  \n",
      "\n",
      "Fold: 14  Epoch: 47  Training loss = 4.4576  Validation loss = 10.8750  \n",
      "\n",
      "Fold: 14  Epoch: 48  Training loss = 4.4572  Validation loss = 10.8744  \n",
      "\n",
      "Fold: 14  Epoch: 49  Training loss = 4.4567  Validation loss = 10.8738  \n",
      "\n",
      "Fold: 14  Epoch: 50  Training loss = 4.4564  Validation loss = 10.8733  \n",
      "\n",
      "Fold: 14  Epoch: 51  Training loss = 4.4559  Validation loss = 10.8727  \n",
      "\n",
      "Fold: 14  Epoch: 52  Training loss = 4.4555  Validation loss = 10.8721  \n",
      "\n",
      "Fold: 14  Epoch: 53  Training loss = 4.4550  Validation loss = 10.8715  \n",
      "\n",
      "Fold: 14  Epoch: 54  Training loss = 4.4546  Validation loss = 10.8709  \n",
      "\n",
      "Fold: 14  Epoch: 55  Training loss = 4.4542  Validation loss = 10.8704  \n",
      "\n",
      "Fold: 14  Epoch: 56  Training loss = 4.4538  Validation loss = 10.8698  \n",
      "\n",
      "Fold: 14  Epoch: 57  Training loss = 4.4533  Validation loss = 10.8693  \n",
      "\n",
      "Fold: 14  Epoch: 58  Training loss = 4.4530  Validation loss = 10.8688  \n",
      "\n",
      "Fold: 14  Epoch: 59  Training loss = 4.4525  Validation loss = 10.8682  \n",
      "\n",
      "Fold: 14  Epoch: 60  Training loss = 4.4521  Validation loss = 10.8677  \n",
      "\n",
      "Fold: 14  Epoch: 61  Training loss = 4.4517  Validation loss = 10.8671  \n",
      "\n",
      "Fold: 14  Epoch: 62  Training loss = 4.4512  Validation loss = 10.8665  \n",
      "\n",
      "Fold: 14  Epoch: 63  Training loss = 4.4507  Validation loss = 10.8659  \n",
      "\n",
      "Fold: 14  Epoch: 64  Training loss = 4.4503  Validation loss = 10.8653  \n",
      "\n",
      "Fold: 14  Epoch: 65  Training loss = 4.4499  Validation loss = 10.8648  \n",
      "\n",
      "Fold: 14  Epoch: 66  Training loss = 4.4495  Validation loss = 10.8642  \n",
      "\n",
      "Fold: 14  Epoch: 67  Training loss = 4.4490  Validation loss = 10.8636  \n",
      "\n",
      "Fold: 14  Epoch: 68  Training loss = 4.4486  Validation loss = 10.8630  \n",
      "\n",
      "Fold: 14  Epoch: 69  Training loss = 4.4482  Validation loss = 10.8625  \n",
      "\n",
      "Fold: 14  Epoch: 70  Training loss = 4.4478  Validation loss = 10.8619  \n",
      "\n",
      "Fold: 14  Epoch: 71  Training loss = 4.4474  Validation loss = 10.8613  \n",
      "\n",
      "Fold: 14  Epoch: 72  Training loss = 4.4470  Validation loss = 10.8607  \n",
      "\n",
      "Fold: 14  Epoch: 73  Training loss = 4.4466  Validation loss = 10.8602  \n",
      "\n",
      "Fold: 14  Epoch: 74  Training loss = 4.4461  Validation loss = 10.8596  \n",
      "\n",
      "Fold: 14  Epoch: 75  Training loss = 4.4457  Validation loss = 10.8590  \n",
      "\n",
      "Fold: 14  Epoch: 76  Training loss = 4.4452  Validation loss = 10.8584  \n",
      "\n",
      "Fold: 14  Epoch: 77  Training loss = 4.4448  Validation loss = 10.8579  \n",
      "\n",
      "Fold: 14  Epoch: 78  Training loss = 4.4444  Validation loss = 10.8573  \n",
      "\n",
      "Fold: 14  Epoch: 79  Training loss = 4.4440  Validation loss = 10.8567  \n",
      "\n",
      "Fold: 14  Epoch: 80  Training loss = 4.4436  Validation loss = 10.8563  \n",
      "\n",
      "Fold: 14  Epoch: 81  Training loss = 4.4431  Validation loss = 10.8557  \n",
      "\n",
      "Fold: 14  Epoch: 82  Training loss = 4.4427  Validation loss = 10.8552  \n",
      "\n",
      "Fold: 14  Epoch: 83  Training loss = 4.4424  Validation loss = 10.8547  \n",
      "\n",
      "Fold: 14  Epoch: 84  Training loss = 4.4420  Validation loss = 10.8542  \n",
      "\n",
      "Fold: 14  Epoch: 85  Training loss = 4.4416  Validation loss = 10.8536  \n",
      "\n",
      "Fold: 14  Epoch: 86  Training loss = 4.4412  Validation loss = 10.8531  \n",
      "\n",
      "Fold: 14  Epoch: 87  Training loss = 4.4408  Validation loss = 10.8525  \n",
      "\n",
      "Fold: 14  Epoch: 88  Training loss = 4.4403  Validation loss = 10.8519  \n",
      "\n",
      "Fold: 14  Epoch: 89  Training loss = 4.4398  Validation loss = 10.8513  \n",
      "\n",
      "Fold: 14  Epoch: 90  Training loss = 4.4394  Validation loss = 10.8507  \n",
      "\n",
      "Fold: 14  Epoch: 91  Training loss = 4.4390  Validation loss = 10.8501  \n",
      "\n",
      "Fold: 14  Epoch: 92  Training loss = 4.4385  Validation loss = 10.8495  \n",
      "\n",
      "Fold: 14  Epoch: 93  Training loss = 4.4381  Validation loss = 10.8490  \n",
      "\n",
      "Fold: 14  Epoch: 94  Training loss = 4.4376  Validation loss = 10.8483  \n",
      "\n",
      "Fold: 14  Epoch: 95  Training loss = 4.4371  Validation loss = 10.8477  \n",
      "\n",
      "Fold: 14  Epoch: 96  Training loss = 4.4367  Validation loss = 10.8471  \n",
      "\n",
      "Fold: 14  Epoch: 97  Training loss = 4.4363  Validation loss = 10.8466  \n",
      "\n",
      "Fold: 14  Epoch: 98  Training loss = 4.4359  Validation loss = 10.8460  \n",
      "\n",
      "Fold: 14  Epoch: 99  Training loss = 4.4355  Validation loss = 10.8455  \n",
      "\n",
      "Fold: 14  Epoch: 100  Training loss = 4.4352  Validation loss = 10.8450  \n",
      "\n",
      "Fold: 14  Epoch: 101  Training loss = 4.4347  Validation loss = 10.8444  \n",
      "\n",
      "Fold: 14  Epoch: 102  Training loss = 4.4343  Validation loss = 10.8439  \n",
      "\n",
      "Fold: 14  Epoch: 103  Training loss = 4.4339  Validation loss = 10.8433  \n",
      "\n",
      "Fold: 14  Epoch: 104  Training loss = 4.4335  Validation loss = 10.8427  \n",
      "\n",
      "Fold: 14  Epoch: 105  Training loss = 4.4331  Validation loss = 10.8422  \n",
      "\n",
      "Fold: 14  Epoch: 106  Training loss = 4.4327  Validation loss = 10.8417  \n",
      "\n",
      "Fold: 14  Epoch: 107  Training loss = 4.4322  Validation loss = 10.8411  \n",
      "\n",
      "Fold: 14  Epoch: 108  Training loss = 4.4318  Validation loss = 10.8406  \n",
      "\n",
      "Fold: 14  Epoch: 109  Training loss = 4.4315  Validation loss = 10.8401  \n",
      "\n",
      "Fold: 14  Epoch: 110  Training loss = 4.4310  Validation loss = 10.8395  \n",
      "\n",
      "Fold: 14  Epoch: 111  Training loss = 4.4306  Validation loss = 10.8389  \n",
      "\n",
      "Fold: 14  Epoch: 112  Training loss = 4.4301  Validation loss = 10.8382  \n",
      "\n",
      "Fold: 14  Epoch: 113  Training loss = 4.4297  Validation loss = 10.8378  \n",
      "\n",
      "Fold: 14  Epoch: 114  Training loss = 4.4293  Validation loss = 10.8371  \n",
      "\n",
      "Fold: 14  Epoch: 115  Training loss = 4.4289  Validation loss = 10.8366  \n",
      "\n",
      "Fold: 14  Epoch: 116  Training loss = 4.4285  Validation loss = 10.8361  \n",
      "\n",
      "Fold: 14  Epoch: 117  Training loss = 4.4280  Validation loss = 10.8354  \n",
      "\n",
      "Fold: 14  Epoch: 118  Training loss = 4.4276  Validation loss = 10.8349  \n",
      "\n",
      "Fold: 14  Epoch: 119  Training loss = 4.4272  Validation loss = 10.8343  \n",
      "\n",
      "Fold: 14  Epoch: 120  Training loss = 4.4268  Validation loss = 10.8338  \n",
      "\n",
      "Fold: 14  Epoch: 121  Training loss = 4.4264  Validation loss = 10.8333  \n",
      "\n",
      "Fold: 14  Epoch: 122  Training loss = 4.4260  Validation loss = 10.8327  \n",
      "\n",
      "Fold: 14  Epoch: 123  Training loss = 4.4255  Validation loss = 10.8321  \n",
      "\n",
      "Fold: 14  Epoch: 124  Training loss = 4.4251  Validation loss = 10.8315  \n",
      "\n",
      "Fold: 14  Epoch: 125  Training loss = 4.4247  Validation loss = 10.8310  \n",
      "\n",
      "Fold: 14  Epoch: 126  Training loss = 4.4243  Validation loss = 10.8304  \n",
      "\n",
      "Fold: 14  Epoch: 127  Training loss = 4.4239  Validation loss = 10.8299  \n",
      "\n",
      "Fold: 14  Epoch: 128  Training loss = 4.4235  Validation loss = 10.8293  \n",
      "\n",
      "Fold: 14  Epoch: 129  Training loss = 4.4231  Validation loss = 10.8288  \n",
      "\n",
      "Fold: 14  Epoch: 130  Training loss = 4.4226  Validation loss = 10.8281  \n",
      "\n",
      "Fold: 14  Epoch: 131  Training loss = 4.4220  Validation loss = 10.8274  \n",
      "\n",
      "Fold: 14  Epoch: 132  Training loss = 4.4216  Validation loss = 10.8268  \n",
      "\n",
      "Fold: 14  Epoch: 133  Training loss = 4.4211  Validation loss = 10.8262  \n",
      "\n",
      "Fold: 14  Epoch: 134  Training loss = 4.4206  Validation loss = 10.8256  \n",
      "\n",
      "Fold: 14  Epoch: 135  Training loss = 4.4202  Validation loss = 10.8250  \n",
      "\n",
      "Fold: 14  Epoch: 136  Training loss = 4.4197  Validation loss = 10.8244  \n",
      "\n",
      "Fold: 14  Epoch: 137  Training loss = 4.4193  Validation loss = 10.8238  \n",
      "\n",
      "Fold: 14  Epoch: 138  Training loss = 4.4189  Validation loss = 10.8232  \n",
      "\n",
      "Fold: 14  Epoch: 139  Training loss = 4.4184  Validation loss = 10.8226  \n",
      "\n",
      "Fold: 14  Epoch: 140  Training loss = 4.4180  Validation loss = 10.8220  \n",
      "\n",
      "Fold: 14  Epoch: 141  Training loss = 4.4176  Validation loss = 10.8215  \n",
      "\n",
      "Fold: 14  Epoch: 142  Training loss = 4.4171  Validation loss = 10.8209  \n",
      "\n",
      "Fold: 14  Epoch: 143  Training loss = 4.4167  Validation loss = 10.8203  \n",
      "\n",
      "Fold: 14  Epoch: 144  Training loss = 4.4163  Validation loss = 10.8197  \n",
      "\n",
      "Fold: 14  Epoch: 145  Training loss = 4.4158  Validation loss = 10.8190  \n",
      "\n",
      "Fold: 14  Epoch: 146  Training loss = 4.4154  Validation loss = 10.8184  \n",
      "\n",
      "Fold: 14  Epoch: 147  Training loss = 4.4149  Validation loss = 10.8179  \n",
      "\n",
      "Fold: 14  Epoch: 148  Training loss = 4.4145  Validation loss = 10.8173  \n",
      "\n",
      "Fold: 14  Epoch: 149  Training loss = 4.4142  Validation loss = 10.8168  \n",
      "\n",
      "Fold: 14  Epoch: 150  Training loss = 4.4137  Validation loss = 10.8162  \n",
      "\n",
      "Fold: 14  Epoch: 151  Training loss = 4.4133  Validation loss = 10.8157  \n",
      "\n",
      "Fold: 14  Epoch: 152  Training loss = 4.4128  Validation loss = 10.8151  \n",
      "\n",
      "Fold: 14  Epoch: 153  Training loss = 4.4125  Validation loss = 10.8146  \n",
      "\n",
      "Fold: 14  Epoch: 154  Training loss = 4.4121  Validation loss = 10.8141  \n",
      "\n",
      "Fold: 14  Epoch: 155  Training loss = 4.4117  Validation loss = 10.8136  \n",
      "\n",
      "Fold: 14  Epoch: 156  Training loss = 4.4114  Validation loss = 10.8131  \n",
      "\n",
      "Fold: 14  Epoch: 157  Training loss = 4.4110  Validation loss = 10.8126  \n",
      "\n",
      "Fold: 14  Epoch: 158  Training loss = 4.4106  Validation loss = 10.8120  \n",
      "\n",
      "Fold: 14  Epoch: 159  Training loss = 4.4101  Validation loss = 10.8115  \n",
      "\n",
      "Fold: 14  Epoch: 160  Training loss = 4.4097  Validation loss = 10.8109  \n",
      "\n",
      "Fold: 14  Epoch: 161  Training loss = 4.4094  Validation loss = 10.8104  \n",
      "\n",
      "Fold: 14  Epoch: 162  Training loss = 4.4090  Validation loss = 10.8099  \n",
      "\n",
      "Fold: 14  Epoch: 163  Training loss = 4.4086  Validation loss = 10.8094  \n",
      "\n",
      "Fold: 14  Epoch: 164  Training loss = 4.4081  Validation loss = 10.8088  \n",
      "\n",
      "Fold: 14  Epoch: 165  Training loss = 4.4076  Validation loss = 10.8081  \n",
      "\n",
      "Fold: 14  Epoch: 166  Training loss = 4.4072  Validation loss = 10.8076  \n",
      "\n",
      "Fold: 14  Epoch: 167  Training loss = 4.4068  Validation loss = 10.8070  \n",
      "\n",
      "Fold: 14  Epoch: 168  Training loss = 4.4063  Validation loss = 10.8064  \n",
      "\n",
      "Fold: 14  Epoch: 169  Training loss = 4.4059  Validation loss = 10.8058  \n",
      "\n",
      "Fold: 14  Epoch: 170  Training loss = 4.4056  Validation loss = 10.8053  \n",
      "\n",
      "Fold: 14  Epoch: 171  Training loss = 4.4051  Validation loss = 10.8046  \n",
      "\n",
      "Fold: 14  Epoch: 172  Training loss = 4.4047  Validation loss = 10.8041  \n",
      "\n",
      "Fold: 14  Epoch: 173  Training loss = 4.4043  Validation loss = 10.8036  \n",
      "\n",
      "Fold: 14  Epoch: 174  Training loss = 4.4038  Validation loss = 10.8030  \n",
      "\n",
      "Fold: 14  Epoch: 175  Training loss = 4.4034  Validation loss = 10.8025  \n",
      "\n",
      "Fold: 14  Epoch: 176  Training loss = 4.4030  Validation loss = 10.8019  \n",
      "\n",
      "Fold: 14  Epoch: 177  Training loss = 4.4027  Validation loss = 10.8014  \n",
      "\n",
      "Fold: 14  Epoch: 178  Training loss = 4.4023  Validation loss = 10.8010  \n",
      "\n",
      "Fold: 14  Epoch: 179  Training loss = 4.4019  Validation loss = 10.8004  \n",
      "\n",
      "Fold: 14  Epoch: 180  Training loss = 4.4014  Validation loss = 10.7997  \n",
      "\n",
      "Fold: 14  Epoch: 181  Training loss = 4.4010  Validation loss = 10.7992  \n",
      "\n",
      "Fold: 14  Epoch: 182  Training loss = 4.4006  Validation loss = 10.7986  \n",
      "\n",
      "Fold: 14  Epoch: 183  Training loss = 4.4002  Validation loss = 10.7981  \n",
      "\n",
      "Fold: 14  Epoch: 184  Training loss = 4.3998  Validation loss = 10.7976  \n",
      "\n",
      "Fold: 14  Epoch: 185  Training loss = 4.3994  Validation loss = 10.7970  \n",
      "\n",
      "Fold: 14  Epoch: 186  Training loss = 4.3990  Validation loss = 10.7965  \n",
      "\n",
      "Fold: 14  Epoch: 187  Training loss = 4.3984  Validation loss = 10.7958  \n",
      "\n",
      "Fold: 14  Epoch: 188  Training loss = 4.3980  Validation loss = 10.7952  \n",
      "\n",
      "Fold: 14  Epoch: 189  Training loss = 4.3976  Validation loss = 10.7947  \n",
      "\n",
      "Fold: 14  Epoch: 190  Training loss = 4.3972  Validation loss = 10.7941  \n",
      "\n",
      "Fold: 14  Epoch: 191  Training loss = 4.3968  Validation loss = 10.7936  \n",
      "\n",
      "Fold: 14  Epoch: 192  Training loss = 4.3964  Validation loss = 10.7931  \n",
      "\n",
      "Fold: 14  Epoch: 193  Training loss = 4.3961  Validation loss = 10.7926  \n",
      "\n",
      "Fold: 14  Epoch: 194  Training loss = 4.3957  Validation loss = 10.7921  \n",
      "\n",
      "Fold: 14  Epoch: 195  Training loss = 4.3952  Validation loss = 10.7914  \n",
      "\n",
      "Fold: 14  Epoch: 196  Training loss = 4.3947  Validation loss = 10.7908  \n",
      "\n",
      "Fold: 14  Epoch: 197  Training loss = 4.3944  Validation loss = 10.7903  \n",
      "\n",
      "Fold: 14  Epoch: 198  Training loss = 4.3940  Validation loss = 10.7898  \n",
      "\n",
      "Fold: 14  Epoch: 199  Training loss = 4.3935  Validation loss = 10.7892  \n",
      "\n",
      "Fold: 14  Epoch: 200  Training loss = 4.3931  Validation loss = 10.7886  \n",
      "\n",
      "Fold: 14  Epoch: 201  Training loss = 4.3927  Validation loss = 10.7880  \n",
      "\n",
      "Fold: 14  Epoch: 202  Training loss = 4.3923  Validation loss = 10.7876  \n",
      "\n",
      "Fold: 14  Epoch: 203  Training loss = 4.3920  Validation loss = 10.7871  \n",
      "\n",
      "Fold: 14  Epoch: 204  Training loss = 4.3915  Validation loss = 10.7865  \n",
      "\n",
      "Fold: 14  Epoch: 205  Training loss = 4.3911  Validation loss = 10.7860  \n",
      "\n",
      "Fold: 14  Epoch: 206  Training loss = 4.3907  Validation loss = 10.7854  \n",
      "\n",
      "Fold: 14  Epoch: 207  Training loss = 4.3903  Validation loss = 10.7848  \n",
      "\n",
      "Fold: 14  Epoch: 208  Training loss = 4.3899  Validation loss = 10.7844  \n",
      "\n",
      "Fold: 14  Epoch: 209  Training loss = 4.3895  Validation loss = 10.7838  \n",
      "\n",
      "Fold: 14  Epoch: 210  Training loss = 4.3891  Validation loss = 10.7832  \n",
      "\n",
      "Fold: 14  Epoch: 211  Training loss = 4.3887  Validation loss = 10.7827  \n",
      "\n",
      "Fold: 14  Epoch: 212  Training loss = 4.3883  Validation loss = 10.7822  \n",
      "\n",
      "Fold: 14  Epoch: 213  Training loss = 4.3879  Validation loss = 10.7816  \n",
      "\n",
      "Fold: 14  Epoch: 214  Training loss = 4.3875  Validation loss = 10.7811  \n",
      "\n",
      "Fold: 14  Epoch: 215  Training loss = 4.3872  Validation loss = 10.7806  \n",
      "\n",
      "Fold: 14  Epoch: 216  Training loss = 4.3867  Validation loss = 10.7799  \n",
      "\n",
      "Fold: 14  Epoch: 217  Training loss = 4.3863  Validation loss = 10.7793  \n",
      "\n",
      "Fold: 14  Epoch: 218  Training loss = 4.3858  Validation loss = 10.7787  \n",
      "\n",
      "Fold: 14  Epoch: 219  Training loss = 4.3854  Validation loss = 10.7782  \n",
      "\n",
      "Fold: 14  Epoch: 220  Training loss = 4.3849  Validation loss = 10.7775  \n",
      "\n",
      "Fold: 14  Epoch: 221  Training loss = 4.3844  Validation loss = 10.7769  \n",
      "\n",
      "Fold: 14  Epoch: 222  Training loss = 4.3840  Validation loss = 10.7763  \n",
      "\n",
      "Fold: 14  Epoch: 223  Training loss = 4.3836  Validation loss = 10.7757  \n",
      "\n",
      "Fold: 14  Epoch: 224  Training loss = 4.3832  Validation loss = 10.7751  \n",
      "\n",
      "Fold: 14  Epoch: 225  Training loss = 4.3828  Validation loss = 10.7746  \n",
      "\n",
      "Fold: 14  Epoch: 226  Training loss = 4.3824  Validation loss = 10.7741  \n",
      "\n",
      "Fold: 14  Epoch: 227  Training loss = 4.3820  Validation loss = 10.7735  \n",
      "\n",
      "Fold: 14  Epoch: 228  Training loss = 4.3816  Validation loss = 10.7730  \n",
      "\n",
      "Fold: 14  Epoch: 229  Training loss = 4.3812  Validation loss = 10.7724  \n",
      "\n",
      "Fold: 14  Epoch: 230  Training loss = 4.3807  Validation loss = 10.7717  \n",
      "\n",
      "Fold: 14  Epoch: 231  Training loss = 4.3804  Validation loss = 10.7712  \n",
      "\n",
      "Fold: 14  Epoch: 232  Training loss = 4.3800  Validation loss = 10.7707  \n",
      "\n",
      "Fold: 14  Epoch: 233  Training loss = 4.3796  Validation loss = 10.7701  \n",
      "\n",
      "Fold: 14  Epoch: 234  Training loss = 4.3792  Validation loss = 10.7696  \n",
      "\n",
      "Fold: 14  Epoch: 235  Training loss = 4.3787  Validation loss = 10.7689  \n",
      "\n",
      "Fold: 14  Epoch: 236  Training loss = 4.3783  Validation loss = 10.7683  \n",
      "\n",
      "Fold: 14  Epoch: 237  Training loss = 4.3778  Validation loss = 10.7677  \n",
      "\n",
      "Fold: 14  Epoch: 238  Training loss = 4.3773  Validation loss = 10.7671  \n",
      "\n",
      "Fold: 14  Epoch: 239  Training loss = 4.3769  Validation loss = 10.7665  \n",
      "\n",
      "Fold: 14  Epoch: 240  Training loss = 4.3764  Validation loss = 10.7658  \n",
      "\n",
      "Fold: 14  Epoch: 241  Training loss = 4.3759  Validation loss = 10.7651  \n",
      "\n",
      "Fold: 14  Epoch: 242  Training loss = 4.3755  Validation loss = 10.7645  \n",
      "\n",
      "Fold: 14  Epoch: 243  Training loss = 4.3751  Validation loss = 10.7640  \n",
      "\n",
      "Fold: 14  Epoch: 244  Training loss = 4.3747  Validation loss = 10.7635  \n",
      "\n",
      "Fold: 14  Epoch: 245  Training loss = 4.3743  Validation loss = 10.7630  \n",
      "\n",
      "Fold: 14  Epoch: 246  Training loss = 4.3739  Validation loss = 10.7624  \n",
      "\n",
      "Fold: 14  Epoch: 247  Training loss = 4.3735  Validation loss = 10.7618  \n",
      "\n",
      "Fold: 14  Epoch: 248  Training loss = 4.3730  Validation loss = 10.7612  \n",
      "\n",
      "Fold: 14  Epoch: 249  Training loss = 4.3726  Validation loss = 10.7606  \n",
      "\n",
      "Fold: 14  Epoch: 250  Training loss = 4.3722  Validation loss = 10.7600  \n",
      "\n",
      "Fold: 14  Epoch: 251  Training loss = 4.3718  Validation loss = 10.7594  \n",
      "\n",
      "Fold: 14  Epoch: 252  Training loss = 4.3713  Validation loss = 10.7588  \n",
      "\n",
      "Fold: 14  Epoch: 253  Training loss = 4.3709  Validation loss = 10.7582  \n",
      "\n",
      "Fold: 14  Epoch: 254  Training loss = 4.3705  Validation loss = 10.7577  \n",
      "\n",
      "Fold: 14  Epoch: 255  Training loss = 4.3700  Validation loss = 10.7571  \n",
      "\n",
      "Fold: 14  Epoch: 256  Training loss = 4.3695  Validation loss = 10.7564  \n",
      "\n",
      "Fold: 14  Epoch: 257  Training loss = 4.3692  Validation loss = 10.7559  \n",
      "\n",
      "Fold: 14  Epoch: 258  Training loss = 4.3687  Validation loss = 10.7553  \n",
      "\n",
      "Fold: 14  Epoch: 259  Training loss = 4.3683  Validation loss = 10.7547  \n",
      "\n",
      "Fold: 14  Epoch: 260  Training loss = 4.3679  Validation loss = 10.7542  \n",
      "\n",
      "Fold: 14  Epoch: 261  Training loss = 4.3675  Validation loss = 10.7536  \n",
      "\n",
      "Fold: 14  Epoch: 262  Training loss = 4.3671  Validation loss = 10.7530  \n",
      "\n",
      "Fold: 14  Epoch: 263  Training loss = 4.3667  Validation loss = 10.7525  \n",
      "\n",
      "Fold: 14  Epoch: 264  Training loss = 4.3664  Validation loss = 10.7520  \n",
      "\n",
      "Fold: 14  Epoch: 265  Training loss = 4.3660  Validation loss = 10.7515  \n",
      "\n",
      "Fold: 14  Epoch: 266  Training loss = 4.3656  Validation loss = 10.7509  \n",
      "\n",
      "Fold: 14  Epoch: 267  Training loss = 4.3653  Validation loss = 10.7505  \n",
      "\n",
      "Fold: 14  Epoch: 268  Training loss = 4.3648  Validation loss = 10.7499  \n",
      "\n",
      "Fold: 14  Epoch: 269  Training loss = 4.3644  Validation loss = 10.7493  \n",
      "\n",
      "Fold: 14  Epoch: 270  Training loss = 4.3640  Validation loss = 10.7487  \n",
      "\n",
      "Fold: 14  Epoch: 271  Training loss = 4.3636  Validation loss = 10.7482  \n",
      "\n",
      "Fold: 14  Epoch: 272  Training loss = 4.3631  Validation loss = 10.7475  \n",
      "\n",
      "Fold: 14  Epoch: 273  Training loss = 4.3627  Validation loss = 10.7469  \n",
      "\n",
      "Fold: 14  Epoch: 274  Training loss = 4.3623  Validation loss = 10.7464  \n",
      "\n",
      "Fold: 14  Epoch: 275  Training loss = 4.3619  Validation loss = 10.7459  \n",
      "\n",
      "Fold: 14  Epoch: 276  Training loss = 4.3615  Validation loss = 10.7453  \n",
      "\n",
      "Fold: 14  Epoch: 277  Training loss = 4.3612  Validation loss = 10.7448  \n",
      "\n",
      "Fold: 14  Epoch: 278  Training loss = 4.3607  Validation loss = 10.7442  \n",
      "\n",
      "Fold: 14  Epoch: 279  Training loss = 4.3603  Validation loss = 10.7436  \n",
      "\n",
      "Fold: 14  Epoch: 280  Training loss = 4.3598  Validation loss = 10.7429  \n",
      "\n",
      "Fold: 14  Epoch: 281  Training loss = 4.3594  Validation loss = 10.7424  \n",
      "\n",
      "Fold: 14  Epoch: 282  Training loss = 4.3590  Validation loss = 10.7418  \n",
      "\n",
      "Fold: 14  Epoch: 283  Training loss = 4.3586  Validation loss = 10.7414  \n",
      "\n",
      "Fold: 14  Epoch: 284  Training loss = 4.3583  Validation loss = 10.7409  \n",
      "\n",
      "Fold: 14  Epoch: 285  Training loss = 4.3578  Validation loss = 10.7403  \n",
      "\n",
      "Fold: 14  Epoch: 286  Training loss = 4.3574  Validation loss = 10.7397  \n",
      "\n",
      "Fold: 14  Epoch: 287  Training loss = 4.3571  Validation loss = 10.7392  \n",
      "\n",
      "Fold: 14  Epoch: 288  Training loss = 4.3567  Validation loss = 10.7387  \n",
      "\n",
      "Fold: 14  Epoch: 289  Training loss = 4.3562  Validation loss = 10.7380  \n",
      "\n",
      "Fold: 14  Epoch: 290  Training loss = 4.3558  Validation loss = 10.7374  \n",
      "\n",
      "Fold: 14  Epoch: 291  Training loss = 4.3555  Validation loss = 10.7370  \n",
      "\n",
      "Fold: 14  Epoch: 292  Training loss = 4.3551  Validation loss = 10.7364  \n",
      "\n",
      "Fold: 14  Epoch: 293  Training loss = 4.3547  Validation loss = 10.7359  \n",
      "\n",
      "Fold: 14  Epoch: 294  Training loss = 4.3543  Validation loss = 10.7354  \n",
      "\n",
      "Fold: 14  Epoch: 295  Training loss = 4.3539  Validation loss = 10.7347  \n",
      "\n",
      "Fold: 14  Epoch: 296  Training loss = 4.3535  Validation loss = 10.7341  \n",
      "\n",
      "Fold: 14  Epoch: 297  Training loss = 4.3530  Validation loss = 10.7335  \n",
      "\n",
      "Fold: 14  Epoch: 298  Training loss = 4.3526  Validation loss = 10.7329  \n",
      "\n",
      "Fold: 14  Epoch: 299  Training loss = 4.3521  Validation loss = 10.7322  \n",
      "\n",
      "Fold: 14  Epoch: 300  Training loss = 4.3517  Validation loss = 10.7317  \n",
      "\n",
      "Fold: 14  Epoch: 301  Training loss = 4.3513  Validation loss = 10.7312  \n",
      "\n",
      "Fold: 14  Epoch: 302  Training loss = 4.3508  Validation loss = 10.7305  \n",
      "\n",
      "Fold: 14  Epoch: 303  Training loss = 4.3504  Validation loss = 10.7300  \n",
      "\n",
      "Fold: 14  Epoch: 304  Training loss = 4.3500  Validation loss = 10.7294  \n",
      "\n",
      "Fold: 14  Epoch: 305  Training loss = 4.3496  Validation loss = 10.7289  \n",
      "\n",
      "Fold: 14  Epoch: 306  Training loss = 4.3492  Validation loss = 10.7283  \n",
      "\n",
      "Fold: 14  Epoch: 307  Training loss = 4.3488  Validation loss = 10.7277  \n",
      "\n",
      "Fold: 14  Epoch: 308  Training loss = 4.3484  Validation loss = 10.7271  \n",
      "\n",
      "Fold: 14  Epoch: 309  Training loss = 4.3480  Validation loss = 10.7266  \n",
      "\n",
      "Fold: 14  Epoch: 310  Training loss = 4.3475  Validation loss = 10.7259  \n",
      "\n",
      "Fold: 14  Epoch: 311  Training loss = 4.3471  Validation loss = 10.7253  \n",
      "\n",
      "Fold: 14  Epoch: 312  Training loss = 4.3466  Validation loss = 10.7247  \n",
      "\n",
      "Fold: 14  Epoch: 313  Training loss = 4.3462  Validation loss = 10.7241  \n",
      "\n",
      "Fold: 14  Epoch: 314  Training loss = 4.3457  Validation loss = 10.7234  \n",
      "\n",
      "Fold: 14  Epoch: 315  Training loss = 4.3453  Validation loss = 10.7229  \n",
      "\n",
      "Fold: 14  Epoch: 316  Training loss = 4.3448  Validation loss = 10.7222  \n",
      "\n",
      "Fold: 14  Epoch: 317  Training loss = 4.3443  Validation loss = 10.7215  \n",
      "\n",
      "Fold: 14  Epoch: 318  Training loss = 4.3439  Validation loss = 10.7209  \n",
      "\n",
      "Fold: 14  Epoch: 319  Training loss = 4.3435  Validation loss = 10.7204  \n",
      "\n",
      "Fold: 14  Epoch: 320  Training loss = 4.3432  Validation loss = 10.7200  \n",
      "\n",
      "Fold: 14  Epoch: 321  Training loss = 4.3427  Validation loss = 10.7194  \n",
      "\n",
      "Fold: 14  Epoch: 322  Training loss = 4.3423  Validation loss = 10.7188  \n",
      "\n",
      "Fold: 14  Epoch: 323  Training loss = 4.3418  Validation loss = 10.7181  \n",
      "\n",
      "Fold: 14  Epoch: 324  Training loss = 4.3415  Validation loss = 10.7176  \n",
      "\n",
      "Fold: 14  Epoch: 325  Training loss = 4.3410  Validation loss = 10.7170  \n",
      "\n",
      "Fold: 14  Epoch: 326  Training loss = 4.3406  Validation loss = 10.7164  \n",
      "\n",
      "Fold: 14  Epoch: 327  Training loss = 4.3402  Validation loss = 10.7159  \n",
      "\n",
      "Fold: 14  Epoch: 328  Training loss = 4.3398  Validation loss = 10.7152  \n",
      "\n",
      "Fold: 14  Epoch: 329  Training loss = 4.3394  Validation loss = 10.7147  \n",
      "\n",
      "Fold: 14  Epoch: 330  Training loss = 4.3389  Validation loss = 10.7141  \n",
      "\n",
      "Fold: 14  Epoch: 331  Training loss = 4.3385  Validation loss = 10.7136  \n",
      "\n",
      "Fold: 14  Epoch: 332  Training loss = 4.3381  Validation loss = 10.7129  \n",
      "\n",
      "Fold: 14  Epoch: 333  Training loss = 4.3377  Validation loss = 10.7124  \n",
      "\n",
      "Fold: 14  Epoch: 334  Training loss = 4.3373  Validation loss = 10.7118  \n",
      "\n",
      "Fold: 14  Epoch: 335  Training loss = 4.3368  Validation loss = 10.7112  \n",
      "\n",
      "Fold: 14  Epoch: 336  Training loss = 4.3364  Validation loss = 10.7106  \n",
      "\n",
      "Fold: 14  Epoch: 337  Training loss = 4.3361  Validation loss = 10.7102  \n",
      "\n",
      "Fold: 14  Epoch: 338  Training loss = 4.3357  Validation loss = 10.7097  \n",
      "\n",
      "Fold: 14  Epoch: 339  Training loss = 4.3354  Validation loss = 10.7091  \n",
      "\n",
      "Fold: 14  Epoch: 340  Training loss = 4.3349  Validation loss = 10.7085  \n",
      "\n",
      "Fold: 14  Epoch: 341  Training loss = 4.3344  Validation loss = 10.7078  \n",
      "\n",
      "Fold: 14  Epoch: 342  Training loss = 4.3340  Validation loss = 10.7073  \n",
      "\n",
      "Fold: 14  Epoch: 343  Training loss = 4.3336  Validation loss = 10.7067  \n",
      "\n",
      "Fold: 14  Epoch: 344  Training loss = 4.3332  Validation loss = 10.7062  \n",
      "\n",
      "Fold: 14  Epoch: 345  Training loss = 4.3328  Validation loss = 10.7057  \n",
      "\n",
      "Fold: 14  Epoch: 346  Training loss = 4.3324  Validation loss = 10.7051  \n",
      "\n",
      "Fold: 14  Epoch: 347  Training loss = 4.3319  Validation loss = 10.7044  \n",
      "\n",
      "Fold: 14  Epoch: 348  Training loss = 4.3315  Validation loss = 10.7038  \n",
      "\n",
      "Fold: 14  Epoch: 349  Training loss = 4.3310  Validation loss = 10.7032  \n",
      "\n",
      "Fold: 14  Epoch: 350  Training loss = 4.3306  Validation loss = 10.7027  \n",
      "\n",
      "Fold: 14  Epoch: 351  Training loss = 4.3303  Validation loss = 10.7022  \n",
      "\n",
      "Fold: 14  Epoch: 352  Training loss = 4.3298  Validation loss = 10.7016  \n",
      "\n",
      "Fold: 14  Epoch: 353  Training loss = 4.3294  Validation loss = 10.7010  \n",
      "\n",
      "Fold: 14  Epoch: 354  Training loss = 4.3290  Validation loss = 10.7004  \n",
      "\n",
      "Fold: 14  Epoch: 355  Training loss = 4.3286  Validation loss = 10.6998  \n",
      "\n",
      "Fold: 14  Epoch: 356  Training loss = 4.3281  Validation loss = 10.6992  \n",
      "\n",
      "Fold: 14  Epoch: 357  Training loss = 4.3278  Validation loss = 10.6987  \n",
      "\n",
      "Fold: 14  Epoch: 358  Training loss = 4.3275  Validation loss = 10.6983  \n",
      "\n",
      "Fold: 14  Epoch: 359  Training loss = 4.3271  Validation loss = 10.6978  \n",
      "\n",
      "Fold: 14  Epoch: 360  Training loss = 4.3266  Validation loss = 10.6971  \n",
      "\n",
      "Fold: 14  Epoch: 361  Training loss = 4.3263  Validation loss = 10.6968  \n",
      "\n",
      "Fold: 14  Epoch: 362  Training loss = 4.3259  Validation loss = 10.6962  \n",
      "\n",
      "Fold: 14  Epoch: 363  Training loss = 4.3255  Validation loss = 10.6955  \n",
      "\n",
      "Fold: 14  Epoch: 364  Training loss = 4.3251  Validation loss = 10.6950  \n",
      "\n",
      "Fold: 14  Epoch: 365  Training loss = 4.3247  Validation loss = 10.6945  \n",
      "\n",
      "Fold: 14  Epoch: 366  Training loss = 4.3243  Validation loss = 10.6939  \n",
      "\n",
      "Fold: 14  Epoch: 367  Training loss = 4.3239  Validation loss = 10.6933  \n",
      "\n",
      "Fold: 14  Epoch: 368  Training loss = 4.3235  Validation loss = 10.6927  \n",
      "\n",
      "Fold: 14  Epoch: 369  Training loss = 4.3230  Validation loss = 10.6922  \n",
      "\n",
      "Fold: 14  Epoch: 370  Training loss = 4.3226  Validation loss = 10.6916  \n",
      "\n",
      "Fold: 14  Epoch: 371  Training loss = 4.3222  Validation loss = 10.6910  \n",
      "\n",
      "Fold: 14  Epoch: 372  Training loss = 4.3217  Validation loss = 10.6903  \n",
      "\n",
      "Fold: 14  Epoch: 373  Training loss = 4.3213  Validation loss = 10.6897  \n",
      "\n",
      "Fold: 14  Epoch: 374  Training loss = 4.3209  Validation loss = 10.6892  \n",
      "\n",
      "Fold: 14  Epoch: 375  Training loss = 4.3205  Validation loss = 10.6886  \n",
      "\n",
      "Fold: 14  Epoch: 376  Training loss = 4.3202  Validation loss = 10.6882  \n",
      "\n",
      "Fold: 14  Epoch: 377  Training loss = 4.3197  Validation loss = 10.6875  \n",
      "\n",
      "Fold: 14  Epoch: 378  Training loss = 4.3193  Validation loss = 10.6870  \n",
      "\n",
      "Fold: 14  Epoch: 379  Training loss = 4.3190  Validation loss = 10.6865  \n",
      "\n",
      "Fold: 14  Epoch: 380  Training loss = 4.3187  Validation loss = 10.6860  \n",
      "\n",
      "Fold: 14  Epoch: 381  Training loss = 4.3183  Validation loss = 10.6855  \n",
      "\n",
      "Fold: 14  Epoch: 382  Training loss = 4.3179  Validation loss = 10.6849  \n",
      "\n",
      "Fold: 14  Epoch: 383  Training loss = 4.3175  Validation loss = 10.6843  \n",
      "\n",
      "Fold: 14  Epoch: 384  Training loss = 4.3171  Validation loss = 10.6839  \n",
      "\n",
      "Fold: 14  Epoch: 385  Training loss = 4.3167  Validation loss = 10.6832  \n",
      "\n",
      "Fold: 14  Epoch: 386  Training loss = 4.3163  Validation loss = 10.6827  \n",
      "\n",
      "Fold: 14  Epoch: 387  Training loss = 4.3159  Validation loss = 10.6822  \n",
      "\n",
      "Fold: 14  Epoch: 388  Training loss = 4.3155  Validation loss = 10.6816  \n",
      "\n",
      "Fold: 14  Epoch: 389  Training loss = 4.3150  Validation loss = 10.6809  \n",
      "\n",
      "Fold: 14  Epoch: 390  Training loss = 4.3146  Validation loss = 10.6803  \n",
      "\n",
      "Fold: 14  Epoch: 391  Training loss = 4.3142  Validation loss = 10.6797  \n",
      "\n",
      "Fold: 14  Epoch: 392  Training loss = 4.3138  Validation loss = 10.6792  \n",
      "\n",
      "Fold: 14  Epoch: 393  Training loss = 4.3134  Validation loss = 10.6787  \n",
      "\n",
      "Fold: 14  Epoch: 394  Training loss = 4.3130  Validation loss = 10.6781  \n",
      "\n",
      "Fold: 14  Epoch: 395  Training loss = 4.3127  Validation loss = 10.6777  \n",
      "\n",
      "Fold: 14  Epoch: 396  Training loss = 4.3123  Validation loss = 10.6771  \n",
      "\n",
      "Fold: 14  Epoch: 397  Training loss = 4.3119  Validation loss = 10.6766  \n",
      "\n",
      "Fold: 14  Epoch: 398  Training loss = 4.3114  Validation loss = 10.6760  \n",
      "\n",
      "Fold: 14  Epoch: 399  Training loss = 4.3110  Validation loss = 10.6753  \n",
      "\n",
      "Fold: 14  Epoch: 400  Training loss = 4.3106  Validation loss = 10.6748  \n",
      "\n",
      "Fold: 14  Epoch: 401  Training loss = 4.3103  Validation loss = 10.6743  \n",
      "\n",
      "Fold: 14  Epoch: 402  Training loss = 4.3099  Validation loss = 10.6737  \n",
      "\n",
      "Fold: 14  Epoch: 403  Training loss = 4.3095  Validation loss = 10.6732  \n",
      "\n",
      "Fold: 14  Epoch: 404  Training loss = 4.3091  Validation loss = 10.6726  \n",
      "\n",
      "Fold: 14  Epoch: 405  Training loss = 4.3086  Validation loss = 10.6720  \n",
      "\n",
      "Fold: 14  Epoch: 406  Training loss = 4.3082  Validation loss = 10.6714  \n",
      "\n",
      "Fold: 14  Epoch: 407  Training loss = 4.3079  Validation loss = 10.6709  \n",
      "\n",
      "Fold: 14  Epoch: 408  Training loss = 4.3075  Validation loss = 10.6704  \n",
      "\n",
      "Fold: 14  Epoch: 409  Training loss = 4.3072  Validation loss = 10.6699  \n",
      "\n",
      "Fold: 14  Epoch: 410  Training loss = 4.3068  Validation loss = 10.6694  \n",
      "\n",
      "Fold: 14  Epoch: 411  Training loss = 4.3064  Validation loss = 10.6689  \n",
      "\n",
      "Fold: 14  Epoch: 412  Training loss = 4.3060  Validation loss = 10.6683  \n",
      "\n",
      "Fold: 14  Epoch: 413  Training loss = 4.3056  Validation loss = 10.6677  \n",
      "\n",
      "Fold: 14  Epoch: 414  Training loss = 4.3052  Validation loss = 10.6673  \n",
      "\n",
      "Fold: 14  Epoch: 415  Training loss = 4.3049  Validation loss = 10.6668  \n",
      "\n",
      "Fold: 14  Epoch: 416  Training loss = 4.3045  Validation loss = 10.6663  \n",
      "\n",
      "Fold: 14  Epoch: 417  Training loss = 4.3040  Validation loss = 10.6656  \n",
      "\n",
      "Fold: 14  Epoch: 418  Training loss = 4.3037  Validation loss = 10.6651  \n",
      "\n",
      "Fold: 14  Epoch: 419  Training loss = 4.3032  Validation loss = 10.6645  \n",
      "\n",
      "Fold: 14  Epoch: 420  Training loss = 4.3028  Validation loss = 10.6639  \n",
      "\n",
      "Fold: 14  Epoch: 421  Training loss = 4.3024  Validation loss = 10.6634  \n",
      "\n",
      "Fold: 14  Epoch: 422  Training loss = 4.3021  Validation loss = 10.6628  \n",
      "\n",
      "Fold: 14  Epoch: 423  Training loss = 4.3016  Validation loss = 10.6622  \n",
      "\n",
      "Fold: 14  Epoch: 424  Training loss = 4.3012  Validation loss = 10.6617  \n",
      "\n",
      "Fold: 14  Epoch: 425  Training loss = 4.3008  Validation loss = 10.6611  \n",
      "\n",
      "Fold: 14  Epoch: 426  Training loss = 4.3004  Validation loss = 10.6607  \n",
      "\n",
      "Fold: 14  Epoch: 427  Training loss = 4.3000  Validation loss = 10.6601  \n",
      "\n",
      "Fold: 14  Epoch: 428  Training loss = 4.2995  Validation loss = 10.6595  \n",
      "\n",
      "Fold: 14  Epoch: 429  Training loss = 4.2988  Validation loss = 10.6590  \n",
      "\n",
      "Fold: 14  Epoch: 430  Training loss = 4.2943  Validation loss = 10.6584  \n",
      "\n",
      "Fold: 14  Epoch: 431  Training loss = 4.2874  Validation loss = 10.6579  \n",
      "\n",
      "Fold: 14  Epoch: 432  Training loss = 4.2862  Validation loss = 10.6574  \n",
      "\n",
      "Fold: 14  Epoch: 433  Training loss = 4.2857  Validation loss = 10.6568  \n",
      "\n",
      "Fold: 14  Epoch: 434  Training loss = 4.2852  Validation loss = 10.6562  \n",
      "\n",
      "Fold: 14  Epoch: 435  Training loss = 4.2847  Validation loss = 10.6556  \n",
      "\n",
      "Fold: 14  Epoch: 436  Training loss = 4.2844  Validation loss = 10.6551  \n",
      "\n",
      "Fold: 14  Epoch: 437  Training loss = 4.2840  Validation loss = 10.6546  \n",
      "\n",
      "Fold: 14  Epoch: 438  Training loss = 4.2834  Validation loss = 10.6539  \n",
      "\n",
      "Fold: 14  Epoch: 439  Training loss = 4.2830  Validation loss = 10.6533  \n",
      "\n",
      "Fold: 14  Epoch: 440  Training loss = 4.2826  Validation loss = 10.6527  \n",
      "\n",
      "Fold: 14  Epoch: 441  Training loss = 4.2822  Validation loss = 10.6521  \n",
      "\n",
      "Fold: 14  Epoch: 442  Training loss = 4.2818  Validation loss = 10.6516  \n",
      "\n",
      "Fold: 14  Epoch: 443  Training loss = 4.2813  Validation loss = 10.6509  \n",
      "\n",
      "Fold: 14  Epoch: 444  Training loss = 4.2808  Validation loss = 10.6503  \n",
      "\n",
      "Fold: 14  Epoch: 445  Training loss = 4.2803  Validation loss = 10.6496  \n",
      "\n",
      "Fold: 14  Epoch: 446  Training loss = 4.2799  Validation loss = 10.6490  \n",
      "\n",
      "Fold: 14  Epoch: 447  Training loss = 4.2795  Validation loss = 10.6485  \n",
      "\n",
      "Fold: 14  Epoch: 448  Training loss = 4.2792  Validation loss = 10.6480  \n",
      "\n",
      "Fold: 14  Epoch: 449  Training loss = 4.2788  Validation loss = 10.6475  \n",
      "\n",
      "Fold: 14  Epoch: 450  Training loss = 4.2785  Validation loss = 10.6470  \n",
      "\n",
      "Fold: 14  Epoch: 451  Training loss = 4.2780  Validation loss = 10.6464  \n",
      "\n",
      "Fold: 14  Epoch: 452  Training loss = 4.2776  Validation loss = 10.6457  \n",
      "\n",
      "Fold: 14  Epoch: 453  Training loss = 4.2772  Validation loss = 10.6452  \n",
      "\n",
      "Fold: 14  Epoch: 454  Training loss = 4.2767  Validation loss = 10.6446  \n",
      "\n",
      "Fold: 14  Epoch: 455  Training loss = 4.2763  Validation loss = 10.6439  \n",
      "\n",
      "Fold: 14  Epoch: 456  Training loss = 4.2759  Validation loss = 10.6434  \n",
      "\n",
      "Fold: 14  Epoch: 457  Training loss = 4.2755  Validation loss = 10.6429  \n",
      "\n",
      "Fold: 14  Epoch: 458  Training loss = 4.2751  Validation loss = 10.6423  \n",
      "\n",
      "Fold: 14  Epoch: 459  Training loss = 4.2747  Validation loss = 10.6417  \n",
      "\n",
      "Fold: 14  Epoch: 460  Training loss = 4.2742  Validation loss = 10.6411  \n",
      "\n",
      "Fold: 14  Epoch: 461  Training loss = 4.2739  Validation loss = 10.6406  \n",
      "\n",
      "Fold: 14  Epoch: 462  Training loss = 4.2735  Validation loss = 10.6400  \n",
      "\n",
      "Fold: 14  Epoch: 463  Training loss = 4.2731  Validation loss = 10.6395  \n",
      "\n",
      "Fold: 14  Epoch: 464  Training loss = 4.2727  Validation loss = 10.6389  \n",
      "\n",
      "Fold: 14  Epoch: 465  Training loss = 4.2722  Validation loss = 10.6383  \n",
      "\n",
      "Fold: 14  Epoch: 466  Training loss = 4.2719  Validation loss = 10.6378  \n",
      "\n",
      "Fold: 14  Epoch: 467  Training loss = 4.2716  Validation loss = 10.6374  \n",
      "\n",
      "Fold: 14  Epoch: 468  Training loss = 4.2711  Validation loss = 10.6367  \n",
      "\n",
      "Fold: 14  Epoch: 469  Training loss = 4.2707  Validation loss = 10.6362  \n",
      "\n",
      "Fold: 14  Epoch: 470  Training loss = 4.2704  Validation loss = 10.6358  \n",
      "\n",
      "Fold: 14  Epoch: 471  Training loss = 4.2699  Validation loss = 10.6351  \n",
      "\n",
      "Fold: 14  Epoch: 472  Training loss = 4.2696  Validation loss = 10.6345  \n",
      "\n",
      "Fold: 14  Epoch: 473  Training loss = 4.2691  Validation loss = 10.6340  \n",
      "\n",
      "Fold: 14  Epoch: 474  Training loss = 4.2688  Validation loss = 10.6335  \n",
      "\n",
      "Fold: 14  Epoch: 475  Training loss = 4.2684  Validation loss = 10.6329  \n",
      "\n",
      "Fold: 14  Epoch: 476  Training loss = 4.2680  Validation loss = 10.6324  \n",
      "\n",
      "Fold: 14  Epoch: 477  Training loss = 4.2676  Validation loss = 10.6319  \n",
      "\n",
      "Fold: 14  Epoch: 478  Training loss = 4.2672  Validation loss = 10.6313  \n",
      "\n",
      "Fold: 14  Epoch: 479  Training loss = 4.2668  Validation loss = 10.6307  \n",
      "\n",
      "Fold: 14  Epoch: 480  Training loss = 4.2664  Validation loss = 10.6301  \n",
      "\n",
      "Fold: 14  Epoch: 481  Training loss = 4.2660  Validation loss = 10.6296  \n",
      "\n",
      "Fold: 14  Epoch: 482  Training loss = 4.2657  Validation loss = 10.6291  \n",
      "\n",
      "Fold: 14  Epoch: 483  Training loss = 4.2652  Validation loss = 10.6284  \n",
      "\n",
      "Fold: 14  Epoch: 484  Training loss = 4.2648  Validation loss = 10.6279  \n",
      "\n",
      "Fold: 14  Epoch: 485  Training loss = 4.2645  Validation loss = 10.6275  \n",
      "\n",
      "Fold: 14  Epoch: 486  Training loss = 4.2641  Validation loss = 10.6269  \n",
      "\n",
      "Fold: 14  Epoch: 487  Training loss = 4.2637  Validation loss = 10.6264  \n",
      "\n",
      "Fold: 14  Epoch: 488  Training loss = 4.2633  Validation loss = 10.6257  \n",
      "\n",
      "Fold: 14  Epoch: 489  Training loss = 4.2629  Validation loss = 10.6252  \n",
      "\n",
      "Fold: 14  Epoch: 490  Training loss = 4.2624  Validation loss = 10.6245  \n",
      "\n",
      "Fold: 14  Epoch: 491  Training loss = 4.2620  Validation loss = 10.6240  \n",
      "\n",
      "Fold: 14  Epoch: 492  Training loss = 4.2616  Validation loss = 10.6234  \n",
      "\n",
      "Fold: 14  Epoch: 493  Training loss = 4.2613  Validation loss = 10.6229  \n",
      "\n",
      "Fold: 14  Epoch: 494  Training loss = 4.2609  Validation loss = 10.6225  \n",
      "\n",
      "Fold: 14  Epoch: 495  Training loss = 4.2605  Validation loss = 10.6219  \n",
      "\n",
      "Fold: 14  Epoch: 496  Training loss = 4.2601  Validation loss = 10.6213  \n",
      "\n",
      "Fold: 14  Epoch: 497  Training loss = 4.2597  Validation loss = 10.6207  \n",
      "\n",
      "Fold: 14  Epoch: 498  Training loss = 4.2594  Validation loss = 10.6203  \n",
      "\n",
      "Fold: 14  Epoch: 499  Training loss = 4.2590  Validation loss = 10.6197  \n",
      "\n",
      "Fold: 14  Epoch: 500  Training loss = 4.2586  Validation loss = 10.6192  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 500  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 5.0032  Validation loss = 11.3065  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 5.0027  Validation loss = 11.3059  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 5.0021  Validation loss = 11.3053  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 5.0016  Validation loss = 11.3046  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 5.0011  Validation loss = 11.3039  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 5.0005  Validation loss = 11.3032  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 5.0000  Validation loss = 11.3027  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 4.9994  Validation loss = 11.3019  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 4.9990  Validation loss = 11.3014  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 4.9984  Validation loss = 11.3008  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 4.9980  Validation loss = 11.3002  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 4.9974  Validation loss = 11.2995  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 4.9969  Validation loss = 11.2989  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 4.9964  Validation loss = 11.2984  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 4.9959  Validation loss = 11.2978  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 4.9955  Validation loss = 11.2973  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 4.9949  Validation loss = 11.2967  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 4.9944  Validation loss = 11.2960  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 4.9939  Validation loss = 11.2955  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 4.9935  Validation loss = 11.2950  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 4.9930  Validation loss = 11.2945  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 4.9925  Validation loss = 11.2939  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 4.9919  Validation loss = 11.2933  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 4.9913  Validation loss = 11.2925  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 4.9908  Validation loss = 11.2919  \n",
      "\n",
      "Fold: 15  Epoch: 26  Training loss = 4.9903  Validation loss = 11.2913  \n",
      "\n",
      "Fold: 15  Epoch: 27  Training loss = 4.9897  Validation loss = 11.2907  \n",
      "\n",
      "Fold: 15  Epoch: 28  Training loss = 4.9892  Validation loss = 11.2900  \n",
      "\n",
      "Fold: 15  Epoch: 29  Training loss = 4.9886  Validation loss = 11.2893  \n",
      "\n",
      "Fold: 15  Epoch: 30  Training loss = 4.9880  Validation loss = 11.2885  \n",
      "\n",
      "Fold: 15  Epoch: 31  Training loss = 4.9875  Validation loss = 11.2880  \n",
      "\n",
      "Fold: 15  Epoch: 32  Training loss = 4.9870  Validation loss = 11.2873  \n",
      "\n",
      "Fold: 15  Epoch: 33  Training loss = 4.9867  Validation loss = 11.2870  \n",
      "\n",
      "Fold: 15  Epoch: 34  Training loss = 4.9862  Validation loss = 11.2864  \n",
      "\n",
      "Fold: 15  Epoch: 35  Training loss = 4.9858  Validation loss = 11.2860  \n",
      "\n",
      "Fold: 15  Epoch: 36  Training loss = 4.9853  Validation loss = 11.2854  \n",
      "\n",
      "Fold: 15  Epoch: 37  Training loss = 4.9848  Validation loss = 11.2848  \n",
      "\n",
      "Fold: 15  Epoch: 38  Training loss = 4.9844  Validation loss = 11.2842  \n",
      "\n",
      "Fold: 15  Epoch: 39  Training loss = 4.9839  Validation loss = 11.2836  \n",
      "\n",
      "Fold: 15  Epoch: 40  Training loss = 4.9834  Validation loss = 11.2831  \n",
      "\n",
      "Fold: 15  Epoch: 41  Training loss = 4.9828  Validation loss = 11.2823  \n",
      "\n",
      "Fold: 15  Epoch: 42  Training loss = 4.9822  Validation loss = 11.2816  \n",
      "\n",
      "Fold: 15  Epoch: 43  Training loss = 4.9818  Validation loss = 11.2811  \n",
      "\n",
      "Fold: 15  Epoch: 44  Training loss = 4.9814  Validation loss = 11.2806  \n",
      "\n",
      "Fold: 15  Epoch: 45  Training loss = 4.9809  Validation loss = 11.2800  \n",
      "\n",
      "Fold: 15  Epoch: 46  Training loss = 4.9804  Validation loss = 11.2793  \n",
      "\n",
      "Fold: 15  Epoch: 47  Training loss = 4.9798  Validation loss = 11.2787  \n",
      "\n",
      "Fold: 15  Epoch: 48  Training loss = 4.9793  Validation loss = 11.2780  \n",
      "\n",
      "Fold: 15  Epoch: 49  Training loss = 4.9787  Validation loss = 11.2773  \n",
      "\n",
      "Fold: 15  Epoch: 50  Training loss = 4.9781  Validation loss = 11.2767  \n",
      "\n",
      "Fold: 15  Epoch: 51  Training loss = 4.9777  Validation loss = 11.2761  \n",
      "\n",
      "Fold: 15  Epoch: 52  Training loss = 4.9772  Validation loss = 11.2756  \n",
      "\n",
      "Fold: 15  Epoch: 53  Training loss = 4.9768  Validation loss = 11.2750  \n",
      "\n",
      "Fold: 15  Epoch: 54  Training loss = 4.9762  Validation loss = 11.2744  \n",
      "\n",
      "Fold: 15  Epoch: 55  Training loss = 4.9756  Validation loss = 11.2736  \n",
      "\n",
      "Fold: 15  Epoch: 56  Training loss = 4.9751  Validation loss = 11.2729  \n",
      "\n",
      "Fold: 15  Epoch: 57  Training loss = 4.9746  Validation loss = 11.2723  \n",
      "\n",
      "Fold: 15  Epoch: 58  Training loss = 4.9741  Validation loss = 11.2718  \n",
      "\n",
      "Fold: 15  Epoch: 59  Training loss = 4.9736  Validation loss = 11.2712  \n",
      "\n",
      "Fold: 15  Epoch: 60  Training loss = 4.9731  Validation loss = 11.2706  \n",
      "\n",
      "Fold: 15  Epoch: 61  Training loss = 4.9726  Validation loss = 11.2700  \n",
      "\n",
      "Fold: 15  Epoch: 62  Training loss = 4.9721  Validation loss = 11.2695  \n",
      "\n",
      "Fold: 15  Epoch: 63  Training loss = 4.9717  Validation loss = 11.2689  \n",
      "\n",
      "Fold: 15  Epoch: 64  Training loss = 4.9713  Validation loss = 11.2685  \n",
      "\n",
      "Fold: 15  Epoch: 65  Training loss = 4.9707  Validation loss = 11.2678  \n",
      "\n",
      "Fold: 15  Epoch: 66  Training loss = 4.9702  Validation loss = 11.2672  \n",
      "\n",
      "Fold: 15  Epoch: 67  Training loss = 4.9697  Validation loss = 11.2667  \n",
      "\n",
      "Fold: 15  Epoch: 68  Training loss = 4.9692  Validation loss = 11.2660  \n",
      "\n",
      "Fold: 15  Epoch: 69  Training loss = 4.9687  Validation loss = 11.2654  \n",
      "\n",
      "Fold: 15  Epoch: 70  Training loss = 4.9682  Validation loss = 11.2648  \n",
      "\n",
      "Fold: 15  Epoch: 71  Training loss = 4.9677  Validation loss = 11.2642  \n",
      "\n",
      "Fold: 15  Epoch: 72  Training loss = 4.9671  Validation loss = 11.2635  \n",
      "\n",
      "Fold: 15  Epoch: 73  Training loss = 4.9667  Validation loss = 11.2629  \n",
      "\n",
      "Fold: 15  Epoch: 74  Training loss = 4.9661  Validation loss = 11.2621  \n",
      "\n",
      "Fold: 15  Epoch: 75  Training loss = 4.9657  Validation loss = 11.2617  \n",
      "\n",
      "Fold: 15  Epoch: 76  Training loss = 4.9651  Validation loss = 11.2610  \n",
      "\n",
      "Fold: 15  Epoch: 77  Training loss = 4.9646  Validation loss = 11.2603  \n",
      "\n",
      "Fold: 15  Epoch: 78  Training loss = 4.9641  Validation loss = 11.2597  \n",
      "\n",
      "Fold: 15  Epoch: 79  Training loss = 4.9637  Validation loss = 11.2592  \n",
      "\n",
      "Fold: 15  Epoch: 80  Training loss = 4.9632  Validation loss = 11.2587  \n",
      "\n",
      "Fold: 15  Epoch: 81  Training loss = 4.9626  Validation loss = 11.2579  \n",
      "\n",
      "Fold: 15  Epoch: 82  Training loss = 4.9621  Validation loss = 11.2573  \n",
      "\n",
      "Fold: 15  Epoch: 83  Training loss = 4.9616  Validation loss = 11.2567  \n",
      "\n",
      "Fold: 15  Epoch: 84  Training loss = 4.9611  Validation loss = 11.2561  \n",
      "\n",
      "Fold: 15  Epoch: 85  Training loss = 4.9606  Validation loss = 11.2556  \n",
      "\n",
      "Fold: 15  Epoch: 86  Training loss = 4.9601  Validation loss = 11.2550  \n",
      "\n",
      "Fold: 15  Epoch: 87  Training loss = 4.9596  Validation loss = 11.2542  \n",
      "\n",
      "Fold: 15  Epoch: 88  Training loss = 4.9591  Validation loss = 11.2537  \n",
      "\n",
      "Fold: 15  Epoch: 89  Training loss = 4.9586  Validation loss = 11.2530  \n",
      "\n",
      "Fold: 15  Epoch: 90  Training loss = 4.9581  Validation loss = 11.2524  \n",
      "\n",
      "Fold: 15  Epoch: 91  Training loss = 4.9575  Validation loss = 11.2517  \n",
      "\n",
      "Fold: 15  Epoch: 92  Training loss = 4.9571  Validation loss = 11.2512  \n",
      "\n",
      "Fold: 15  Epoch: 93  Training loss = 4.9566  Validation loss = 11.2506  \n",
      "\n",
      "Fold: 15  Epoch: 94  Training loss = 4.9561  Validation loss = 11.2499  \n",
      "\n",
      "Fold: 15  Epoch: 95  Training loss = 4.9556  Validation loss = 11.2493  \n",
      "\n",
      "Fold: 15  Epoch: 96  Training loss = 4.9551  Validation loss = 11.2486  \n",
      "\n",
      "Fold: 15  Epoch: 97  Training loss = 4.9546  Validation loss = 11.2480  \n",
      "\n",
      "Fold: 15  Epoch: 98  Training loss = 4.9541  Validation loss = 11.2474  \n",
      "\n",
      "Fold: 15  Epoch: 99  Training loss = 4.9535  Validation loss = 11.2468  \n",
      "\n",
      "Fold: 15  Epoch: 100  Training loss = 4.9532  Validation loss = 11.2463  \n",
      "\n",
      "Fold: 15  Epoch: 101  Training loss = 4.9527  Validation loss = 11.2457  \n",
      "\n",
      "Fold: 15  Epoch: 102  Training loss = 4.9522  Validation loss = 11.2451  \n",
      "\n",
      "Fold: 15  Epoch: 103  Training loss = 4.9518  Validation loss = 11.2445  \n",
      "\n",
      "Fold: 15  Epoch: 104  Training loss = 4.9513  Validation loss = 11.2440  \n",
      "\n",
      "Fold: 15  Epoch: 105  Training loss = 4.9508  Validation loss = 11.2434  \n",
      "\n",
      "Fold: 15  Epoch: 106  Training loss = 4.9504  Validation loss = 11.2429  \n",
      "\n",
      "Fold: 15  Epoch: 107  Training loss = 4.9499  Validation loss = 11.2423  \n",
      "\n",
      "Fold: 15  Epoch: 108  Training loss = 4.9494  Validation loss = 11.2417  \n",
      "\n",
      "Fold: 15  Epoch: 109  Training loss = 4.9489  Validation loss = 11.2410  \n",
      "\n",
      "Fold: 15  Epoch: 110  Training loss = 4.9483  Validation loss = 11.2402  \n",
      "\n",
      "Fold: 15  Epoch: 111  Training loss = 4.9478  Validation loss = 11.2395  \n",
      "\n",
      "Fold: 15  Epoch: 112  Training loss = 4.9472  Validation loss = 11.2387  \n",
      "\n",
      "Fold: 15  Epoch: 113  Training loss = 4.9466  Validation loss = 11.2379  \n",
      "\n",
      "Fold: 15  Epoch: 114  Training loss = 4.9460  Validation loss = 11.2371  \n",
      "\n",
      "Fold: 15  Epoch: 115  Training loss = 4.9455  Validation loss = 11.2366  \n",
      "\n",
      "Fold: 15  Epoch: 116  Training loss = 4.9449  Validation loss = 11.2359  \n",
      "\n",
      "Fold: 15  Epoch: 117  Training loss = 4.9445  Validation loss = 11.2353  \n",
      "\n",
      "Fold: 15  Epoch: 118  Training loss = 4.9440  Validation loss = 11.2348  \n",
      "\n",
      "Fold: 15  Epoch: 119  Training loss = 4.9435  Validation loss = 11.2341  \n",
      "\n",
      "Fold: 15  Epoch: 120  Training loss = 4.9431  Validation loss = 11.2336  \n",
      "\n",
      "Fold: 15  Epoch: 121  Training loss = 4.9426  Validation loss = 11.2330  \n",
      "\n",
      "Fold: 15  Epoch: 122  Training loss = 4.9421  Validation loss = 11.2323  \n",
      "\n",
      "Fold: 15  Epoch: 123  Training loss = 4.9415  Validation loss = 11.2316  \n",
      "\n",
      "Fold: 15  Epoch: 124  Training loss = 4.9410  Validation loss = 11.2310  \n",
      "\n",
      "Fold: 15  Epoch: 125  Training loss = 4.9405  Validation loss = 11.2303  \n",
      "\n",
      "Fold: 15  Epoch: 126  Training loss = 4.9400  Validation loss = 11.2297  \n",
      "\n",
      "Fold: 15  Epoch: 127  Training loss = 4.9395  Validation loss = 11.2290  \n",
      "\n",
      "Fold: 15  Epoch: 128  Training loss = 4.9390  Validation loss = 11.2284  \n",
      "\n",
      "Fold: 15  Epoch: 129  Training loss = 4.9386  Validation loss = 11.2279  \n",
      "\n",
      "Fold: 15  Epoch: 130  Training loss = 4.9382  Validation loss = 11.2274  \n",
      "\n",
      "Fold: 15  Epoch: 131  Training loss = 4.9376  Validation loss = 11.2267  \n",
      "\n",
      "Fold: 15  Epoch: 132  Training loss = 4.9372  Validation loss = 11.2262  \n",
      "\n",
      "Fold: 15  Epoch: 133  Training loss = 4.9367  Validation loss = 11.2256  \n",
      "\n",
      "Fold: 15  Epoch: 134  Training loss = 4.9362  Validation loss = 11.2249  \n",
      "\n",
      "Fold: 15  Epoch: 135  Training loss = 4.9357  Validation loss = 11.2243  \n",
      "\n",
      "Fold: 15  Epoch: 136  Training loss = 4.9351  Validation loss = 11.2235  \n",
      "\n",
      "Fold: 15  Epoch: 137  Training loss = 4.9347  Validation loss = 11.2230  \n",
      "\n",
      "Fold: 15  Epoch: 138  Training loss = 4.9342  Validation loss = 11.2224  \n",
      "\n",
      "Fold: 15  Epoch: 139  Training loss = 4.9337  Validation loss = 11.2218  \n",
      "\n",
      "Fold: 15  Epoch: 140  Training loss = 4.9332  Validation loss = 11.2211  \n",
      "\n",
      "Fold: 15  Epoch: 141  Training loss = 4.9327  Validation loss = 11.2205  \n",
      "\n",
      "Fold: 15  Epoch: 142  Training loss = 4.9321  Validation loss = 11.2198  \n",
      "\n",
      "Fold: 15  Epoch: 143  Training loss = 4.9316  Validation loss = 11.2192  \n",
      "\n",
      "Fold: 15  Epoch: 144  Training loss = 4.9311  Validation loss = 11.2185  \n",
      "\n",
      "Fold: 15  Epoch: 145  Training loss = 4.9307  Validation loss = 11.2179  \n",
      "\n",
      "Fold: 15  Epoch: 146  Training loss = 4.9302  Validation loss = 11.2172  \n",
      "\n",
      "Fold: 15  Epoch: 147  Training loss = 4.9297  Validation loss = 11.2166  \n",
      "\n",
      "Fold: 15  Epoch: 148  Training loss = 4.9292  Validation loss = 11.2158  \n",
      "\n",
      "Fold: 15  Epoch: 149  Training loss = 4.9286  Validation loss = 11.2150  \n",
      "\n",
      "Fold: 15  Epoch: 150  Training loss = 4.9282  Validation loss = 11.2145  \n",
      "\n",
      "Fold: 15  Epoch: 151  Training loss = 4.9277  Validation loss = 11.2139  \n",
      "\n",
      "Fold: 15  Epoch: 152  Training loss = 4.9272  Validation loss = 11.2133  \n",
      "\n",
      "Fold: 15  Epoch: 153  Training loss = 4.9267  Validation loss = 11.2126  \n",
      "\n",
      "Fold: 15  Epoch: 154  Training loss = 4.9262  Validation loss = 11.2118  \n",
      "\n",
      "Fold: 15  Epoch: 155  Training loss = 4.9257  Validation loss = 11.2111  \n",
      "\n",
      "Fold: 15  Epoch: 156  Training loss = 4.9251  Validation loss = 11.2103  \n",
      "\n",
      "Fold: 15  Epoch: 157  Training loss = 4.9246  Validation loss = 11.2096  \n",
      "\n",
      "Fold: 15  Epoch: 158  Training loss = 4.9241  Validation loss = 11.2089  \n",
      "\n",
      "Fold: 15  Epoch: 159  Training loss = 4.9235  Validation loss = 11.2082  \n",
      "\n",
      "Fold: 15  Epoch: 160  Training loss = 4.9230  Validation loss = 11.2075  \n",
      "\n",
      "Fold: 15  Epoch: 161  Training loss = 4.9225  Validation loss = 11.2068  \n",
      "\n",
      "Fold: 15  Epoch: 162  Training loss = 4.9220  Validation loss = 11.2060  \n",
      "\n",
      "Fold: 15  Epoch: 163  Training loss = 4.9214  Validation loss = 11.2052  \n",
      "\n",
      "Fold: 15  Epoch: 164  Training loss = 4.9209  Validation loss = 11.2045  \n",
      "\n",
      "Fold: 15  Epoch: 165  Training loss = 4.9204  Validation loss = 11.2039  \n",
      "\n",
      "Fold: 15  Epoch: 166  Training loss = 4.9198  Validation loss = 11.2031  \n",
      "\n",
      "Fold: 15  Epoch: 167  Training loss = 4.9194  Validation loss = 11.2025  \n",
      "\n",
      "Fold: 15  Epoch: 168  Training loss = 4.9188  Validation loss = 11.2017  \n",
      "\n",
      "Fold: 15  Epoch: 169  Training loss = 4.9183  Validation loss = 11.2011  \n",
      "\n",
      "Fold: 15  Epoch: 170  Training loss = 4.9178  Validation loss = 11.2006  \n",
      "\n",
      "Fold: 15  Epoch: 171  Training loss = 4.9174  Validation loss = 11.2000  \n",
      "\n",
      "Fold: 15  Epoch: 172  Training loss = 4.9169  Validation loss = 11.1994  \n",
      "\n",
      "Fold: 15  Epoch: 173  Training loss = 4.9164  Validation loss = 11.1987  \n",
      "\n",
      "Fold: 15  Epoch: 174  Training loss = 4.9160  Validation loss = 11.1981  \n",
      "\n",
      "Fold: 15  Epoch: 175  Training loss = 4.9155  Validation loss = 11.1975  \n",
      "\n",
      "Fold: 15  Epoch: 176  Training loss = 4.9151  Validation loss = 11.1969  \n",
      "\n",
      "Fold: 15  Epoch: 177  Training loss = 4.9145  Validation loss = 11.1963  \n",
      "\n",
      "Fold: 15  Epoch: 178  Training loss = 4.9141  Validation loss = 11.1957  \n",
      "\n",
      "Fold: 15  Epoch: 179  Training loss = 4.9136  Validation loss = 11.1951  \n",
      "\n",
      "Fold: 15  Epoch: 180  Training loss = 4.9130  Validation loss = 11.1943  \n",
      "\n",
      "Fold: 15  Epoch: 181  Training loss = 4.9126  Validation loss = 11.1937  \n",
      "\n",
      "Fold: 15  Epoch: 182  Training loss = 4.9122  Validation loss = 11.1931  \n",
      "\n",
      "Fold: 15  Epoch: 183  Training loss = 4.9116  Validation loss = 11.1925  \n",
      "\n",
      "Fold: 15  Epoch: 184  Training loss = 4.9111  Validation loss = 11.1917  \n",
      "\n",
      "Fold: 15  Epoch: 185  Training loss = 4.9106  Validation loss = 11.1910  \n",
      "\n",
      "Fold: 15  Epoch: 186  Training loss = 4.9101  Validation loss = 11.1904  \n",
      "\n",
      "Fold: 15  Epoch: 187  Training loss = 4.9095  Validation loss = 11.1896  \n",
      "\n",
      "Fold: 15  Epoch: 188  Training loss = 4.9089  Validation loss = 11.1888  \n",
      "\n",
      "Fold: 15  Epoch: 189  Training loss = 4.9084  Validation loss = 11.1882  \n",
      "\n",
      "Fold: 15  Epoch: 190  Training loss = 4.9079  Validation loss = 11.1875  \n",
      "\n",
      "Fold: 15  Epoch: 191  Training loss = 4.9074  Validation loss = 11.1869  \n",
      "\n",
      "Fold: 15  Epoch: 192  Training loss = 4.9068  Validation loss = 11.1861  \n",
      "\n",
      "Fold: 15  Epoch: 193  Training loss = 4.9064  Validation loss = 11.1855  \n",
      "\n",
      "Fold: 15  Epoch: 194  Training loss = 4.9060  Validation loss = 11.1849  \n",
      "\n",
      "Fold: 15  Epoch: 195  Training loss = 4.9055  Validation loss = 11.1843  \n",
      "\n",
      "Fold: 15  Epoch: 196  Training loss = 4.9049  Validation loss = 11.1836  \n",
      "\n",
      "Fold: 15  Epoch: 197  Training loss = 4.9044  Validation loss = 11.1829  \n",
      "\n",
      "Fold: 15  Epoch: 198  Training loss = 4.9039  Validation loss = 11.1822  \n",
      "\n",
      "Fold: 15  Epoch: 199  Training loss = 4.9034  Validation loss = 11.1816  \n",
      "\n",
      "Fold: 15  Epoch: 200  Training loss = 4.9029  Validation loss = 11.1810  \n",
      "\n",
      "Fold: 15  Epoch: 201  Training loss = 4.9025  Validation loss = 11.1805  \n",
      "\n",
      "Fold: 15  Epoch: 202  Training loss = 4.9020  Validation loss = 11.1798  \n",
      "\n",
      "Fold: 15  Epoch: 203  Training loss = 4.9015  Validation loss = 11.1793  \n",
      "\n",
      "Fold: 15  Epoch: 204  Training loss = 4.9010  Validation loss = 11.1786  \n",
      "\n",
      "Fold: 15  Epoch: 205  Training loss = 4.9005  Validation loss = 11.1779  \n",
      "\n",
      "Fold: 15  Epoch: 206  Training loss = 4.9001  Validation loss = 11.1774  \n",
      "\n",
      "Fold: 15  Epoch: 207  Training loss = 4.8995  Validation loss = 11.1766  \n",
      "\n",
      "Fold: 15  Epoch: 208  Training loss = 4.8990  Validation loss = 11.1760  \n",
      "\n",
      "Fold: 15  Epoch: 209  Training loss = 4.8986  Validation loss = 11.1753  \n",
      "\n",
      "Fold: 15  Epoch: 210  Training loss = 4.8981  Validation loss = 11.1748  \n",
      "\n",
      "Fold: 15  Epoch: 211  Training loss = 4.8976  Validation loss = 11.1740  \n",
      "\n",
      "Fold: 15  Epoch: 212  Training loss = 4.8970  Validation loss = 11.1732  \n",
      "\n",
      "Fold: 15  Epoch: 213  Training loss = 4.8965  Validation loss = 11.1725  \n",
      "\n",
      "Fold: 15  Epoch: 214  Training loss = 4.8960  Validation loss = 11.1719  \n",
      "\n",
      "Fold: 15  Epoch: 215  Training loss = 4.8956  Validation loss = 11.1714  \n",
      "\n",
      "Fold: 15  Epoch: 216  Training loss = 4.8952  Validation loss = 11.1709  \n",
      "\n",
      "Fold: 15  Epoch: 217  Training loss = 4.8947  Validation loss = 11.1702  \n",
      "\n",
      "Fold: 15  Epoch: 218  Training loss = 4.8942  Validation loss = 11.1695  \n",
      "\n",
      "Fold: 15  Epoch: 219  Training loss = 4.8937  Validation loss = 11.1688  \n",
      "\n",
      "Fold: 15  Epoch: 220  Training loss = 4.8932  Validation loss = 11.1681  \n",
      "\n",
      "Fold: 15  Epoch: 221  Training loss = 4.8926  Validation loss = 11.1674  \n",
      "\n",
      "Fold: 15  Epoch: 222  Training loss = 4.8921  Validation loss = 11.1666  \n",
      "\n",
      "Fold: 15  Epoch: 223  Training loss = 4.8915  Validation loss = 11.1659  \n",
      "\n",
      "Fold: 15  Epoch: 224  Training loss = 4.8910  Validation loss = 11.1652  \n",
      "\n",
      "Fold: 15  Epoch: 225  Training loss = 4.8904  Validation loss = 11.1643  \n",
      "\n",
      "Fold: 15  Epoch: 226  Training loss = 4.8897  Validation loss = 11.1633  \n",
      "\n",
      "Fold: 15  Epoch: 227  Training loss = 4.8893  Validation loss = 11.1627  \n",
      "\n",
      "Fold: 15  Epoch: 228  Training loss = 4.8887  Validation loss = 11.1619  \n",
      "\n",
      "Fold: 15  Epoch: 229  Training loss = 4.8882  Validation loss = 11.1613  \n",
      "\n",
      "Fold: 15  Epoch: 230  Training loss = 4.8877  Validation loss = 11.1605  \n",
      "\n",
      "Fold: 15  Epoch: 231  Training loss = 4.8871  Validation loss = 11.1597  \n",
      "\n",
      "Fold: 15  Epoch: 232  Training loss = 4.8866  Validation loss = 11.1588  \n",
      "\n",
      "Fold: 15  Epoch: 233  Training loss = 4.8860  Validation loss = 11.1581  \n",
      "\n",
      "Fold: 15  Epoch: 234  Training loss = 4.8854  Validation loss = 11.1573  \n",
      "\n",
      "Fold: 15  Epoch: 235  Training loss = 4.8849  Validation loss = 11.1566  \n",
      "\n",
      "Fold: 15  Epoch: 236  Training loss = 4.8844  Validation loss = 11.1559  \n",
      "\n",
      "Fold: 15  Epoch: 237  Training loss = 4.8839  Validation loss = 11.1552  \n",
      "\n",
      "Fold: 15  Epoch: 238  Training loss = 4.8834  Validation loss = 11.1547  \n",
      "\n",
      "Fold: 15  Epoch: 239  Training loss = 4.8830  Validation loss = 11.1541  \n",
      "\n",
      "Fold: 15  Epoch: 240  Training loss = 4.8824  Validation loss = 11.1533  \n",
      "\n",
      "Fold: 15  Epoch: 241  Training loss = 4.8819  Validation loss = 11.1527  \n",
      "\n",
      "Fold: 15  Epoch: 242  Training loss = 4.8814  Validation loss = 11.1519  \n",
      "\n",
      "Fold: 15  Epoch: 243  Training loss = 4.8808  Validation loss = 11.1512  \n",
      "\n",
      "Fold: 15  Epoch: 244  Training loss = 4.8803  Validation loss = 11.1504  \n",
      "\n",
      "Fold: 15  Epoch: 245  Training loss = 4.8798  Validation loss = 11.1498  \n",
      "\n",
      "Fold: 15  Epoch: 246  Training loss = 4.8793  Validation loss = 11.1491  \n",
      "\n",
      "Fold: 15  Epoch: 247  Training loss = 4.8788  Validation loss = 11.1485  \n",
      "\n",
      "Fold: 15  Epoch: 248  Training loss = 4.8783  Validation loss = 11.1478  \n",
      "\n",
      "Fold: 15  Epoch: 249  Training loss = 4.8777  Validation loss = 11.1468  \n",
      "\n",
      "Fold: 15  Epoch: 250  Training loss = 4.8774  Validation loss = 11.1463  \n",
      "\n",
      "Fold: 15  Epoch: 251  Training loss = 4.8769  Validation loss = 11.1456  \n",
      "\n",
      "Fold: 15  Epoch: 252  Training loss = 4.8765  Validation loss = 11.1450  \n",
      "\n",
      "Fold: 15  Epoch: 253  Training loss = 4.8759  Validation loss = 11.1443  \n",
      "\n",
      "Fold: 15  Epoch: 254  Training loss = 4.8754  Validation loss = 11.1436  \n",
      "\n",
      "Fold: 15  Epoch: 255  Training loss = 4.8750  Validation loss = 11.1430  \n",
      "\n",
      "Fold: 15  Epoch: 256  Training loss = 4.8745  Validation loss = 11.1423  \n",
      "\n",
      "Fold: 15  Epoch: 257  Training loss = 4.8739  Validation loss = 11.1414  \n",
      "\n",
      "Fold: 15  Epoch: 258  Training loss = 4.8734  Validation loss = 11.1408  \n",
      "\n",
      "Fold: 15  Epoch: 259  Training loss = 4.8730  Validation loss = 11.1401  \n",
      "\n",
      "Fold: 15  Epoch: 260  Training loss = 4.8725  Validation loss = 11.1393  \n",
      "\n",
      "Fold: 15  Epoch: 261  Training loss = 4.8720  Validation loss = 11.1386  \n",
      "\n",
      "Fold: 15  Epoch: 262  Training loss = 4.8715  Validation loss = 11.1379  \n",
      "\n",
      "Fold: 15  Epoch: 263  Training loss = 4.8710  Validation loss = 11.1372  \n",
      "\n",
      "Fold: 15  Epoch: 264  Training loss = 4.8705  Validation loss = 11.1365  \n",
      "\n",
      "Fold: 15  Epoch: 265  Training loss = 4.8699  Validation loss = 11.1356  \n",
      "\n",
      "Fold: 15  Epoch: 266  Training loss = 4.8694  Validation loss = 11.1349  \n",
      "\n",
      "Fold: 15  Epoch: 267  Training loss = 4.8689  Validation loss = 11.1340  \n",
      "\n",
      "Fold: 15  Epoch: 268  Training loss = 4.8684  Validation loss = 11.1334  \n",
      "\n",
      "Fold: 15  Epoch: 269  Training loss = 4.8679  Validation loss = 11.1327  \n",
      "\n",
      "Fold: 15  Epoch: 270  Training loss = 4.8674  Validation loss = 11.1320  \n",
      "\n",
      "Fold: 15  Epoch: 271  Training loss = 4.8668  Validation loss = 11.1311  \n",
      "\n",
      "Fold: 15  Epoch: 272  Training loss = 4.8663  Validation loss = 11.1304  \n",
      "\n",
      "Fold: 15  Epoch: 273  Training loss = 4.8657  Validation loss = 11.1295  \n",
      "\n",
      "Fold: 15  Epoch: 274  Training loss = 4.8653  Validation loss = 11.1288  \n",
      "\n",
      "Fold: 15  Epoch: 275  Training loss = 4.8648  Validation loss = 11.1282  \n",
      "\n",
      "Fold: 15  Epoch: 276  Training loss = 4.8643  Validation loss = 11.1273  \n",
      "\n",
      "Fold: 15  Epoch: 277  Training loss = 4.8638  Validation loss = 11.1268  \n",
      "\n",
      "Fold: 15  Epoch: 278  Training loss = 4.8633  Validation loss = 11.1260  \n",
      "\n",
      "Fold: 15  Epoch: 279  Training loss = 4.8627  Validation loss = 11.1252  \n",
      "\n",
      "Fold: 15  Epoch: 280  Training loss = 4.8623  Validation loss = 11.1245  \n",
      "\n",
      "Fold: 15  Epoch: 281  Training loss = 4.8618  Validation loss = 11.1238  \n",
      "\n",
      "Fold: 15  Epoch: 282  Training loss = 4.8611  Validation loss = 11.1229  \n",
      "\n",
      "Fold: 15  Epoch: 283  Training loss = 4.8606  Validation loss = 11.1223  \n",
      "\n",
      "Fold: 15  Epoch: 284  Training loss = 4.8601  Validation loss = 11.1217  \n",
      "\n",
      "Fold: 15  Epoch: 285  Training loss = 4.8595  Validation loss = 11.1208  \n",
      "\n",
      "Fold: 15  Epoch: 286  Training loss = 4.8591  Validation loss = 11.1202  \n",
      "\n",
      "Fold: 15  Epoch: 287  Training loss = 4.8587  Validation loss = 11.1196  \n",
      "\n",
      "Fold: 15  Epoch: 288  Training loss = 4.8582  Validation loss = 11.1189  \n",
      "\n",
      "Fold: 15  Epoch: 289  Training loss = 4.8577  Validation loss = 11.1182  \n",
      "\n",
      "Fold: 15  Epoch: 290  Training loss = 4.8572  Validation loss = 11.1175  \n",
      "\n",
      "Fold: 15  Epoch: 291  Training loss = 4.8568  Validation loss = 11.1169  \n",
      "\n",
      "Fold: 15  Epoch: 292  Training loss = 4.8563  Validation loss = 11.1162  \n",
      "\n",
      "Fold: 15  Epoch: 293  Training loss = 4.8558  Validation loss = 11.1153  \n",
      "\n",
      "Fold: 15  Epoch: 294  Training loss = 4.8553  Validation loss = 11.1146  \n",
      "\n",
      "Fold: 15  Epoch: 295  Training loss = 4.8549  Validation loss = 11.1139  \n",
      "\n",
      "Fold: 15  Epoch: 296  Training loss = 4.8542  Validation loss = 11.1130  \n",
      "\n",
      "Fold: 15  Epoch: 297  Training loss = 4.8537  Validation loss = 11.1122  \n",
      "\n",
      "Fold: 15  Epoch: 298  Training loss = 4.8532  Validation loss = 11.1116  \n",
      "\n",
      "Fold: 15  Epoch: 299  Training loss = 4.8528  Validation loss = 11.1109  \n",
      "\n",
      "Fold: 15  Epoch: 300  Training loss = 4.8522  Validation loss = 11.1102  \n",
      "\n",
      "Fold: 15  Epoch: 301  Training loss = 4.8518  Validation loss = 11.1096  \n",
      "\n",
      "Fold: 15  Epoch: 302  Training loss = 4.8512  Validation loss = 11.1087  \n",
      "\n",
      "Fold: 15  Epoch: 303  Training loss = 4.8507  Validation loss = 11.1079  \n",
      "\n",
      "Fold: 15  Epoch: 304  Training loss = 4.8501  Validation loss = 11.1069  \n",
      "\n",
      "Fold: 15  Epoch: 305  Training loss = 4.8495  Validation loss = 11.1061  \n",
      "\n",
      "Fold: 15  Epoch: 306  Training loss = 4.8490  Validation loss = 11.1054  \n",
      "\n",
      "Fold: 15  Epoch: 307  Training loss = 4.8486  Validation loss = 11.1049  \n",
      "\n",
      "Fold: 15  Epoch: 308  Training loss = 4.8481  Validation loss = 11.1040  \n",
      "\n",
      "Fold: 15  Epoch: 309  Training loss = 4.8476  Validation loss = 11.1034  \n",
      "\n",
      "Fold: 15  Epoch: 310  Training loss = 4.8470  Validation loss = 11.1025  \n",
      "\n",
      "Fold: 15  Epoch: 311  Training loss = 4.8467  Validation loss = 11.1019  \n",
      "\n",
      "Fold: 15  Epoch: 312  Training loss = 4.8462  Validation loss = 11.1012  \n",
      "\n",
      "Fold: 15  Epoch: 313  Training loss = 4.8456  Validation loss = 11.1003  \n",
      "\n",
      "Fold: 15  Epoch: 314  Training loss = 4.8451  Validation loss = 11.0995  \n",
      "\n",
      "Fold: 15  Epoch: 315  Training loss = 4.8447  Validation loss = 11.0987  \n",
      "\n",
      "Fold: 15  Epoch: 316  Training loss = 4.8442  Validation loss = 11.0980  \n",
      "\n",
      "Fold: 15  Epoch: 317  Training loss = 4.8436  Validation loss = 11.0972  \n",
      "\n",
      "Fold: 15  Epoch: 318  Training loss = 4.8432  Validation loss = 11.0965  \n",
      "\n",
      "Fold: 15  Epoch: 319  Training loss = 4.8426  Validation loss = 11.0956  \n",
      "\n",
      "Fold: 15  Epoch: 320  Training loss = 4.8421  Validation loss = 11.0950  \n",
      "\n",
      "Fold: 15  Epoch: 321  Training loss = 4.8416  Validation loss = 11.0942  \n",
      "\n",
      "Fold: 15  Epoch: 322  Training loss = 4.8411  Validation loss = 11.0933  \n",
      "\n",
      "Fold: 15  Epoch: 323  Training loss = 4.8405  Validation loss = 11.0925  \n",
      "\n",
      "Fold: 15  Epoch: 324  Training loss = 4.8400  Validation loss = 11.0918  \n",
      "\n",
      "Fold: 15  Epoch: 325  Training loss = 4.8395  Validation loss = 11.0909  \n",
      "\n",
      "Fold: 15  Epoch: 326  Training loss = 4.8390  Validation loss = 11.0902  \n",
      "\n",
      "Fold: 15  Epoch: 327  Training loss = 4.8387  Validation loss = 11.0897  \n",
      "\n",
      "Fold: 15  Epoch: 328  Training loss = 4.8381  Validation loss = 11.0890  \n",
      "\n",
      "Fold: 15  Epoch: 329  Training loss = 4.8378  Validation loss = 11.0884  \n",
      "\n",
      "Fold: 15  Epoch: 330  Training loss = 4.8372  Validation loss = 11.0876  \n",
      "\n",
      "Fold: 15  Epoch: 331  Training loss = 4.8367  Validation loss = 11.0867  \n",
      "\n",
      "Fold: 15  Epoch: 332  Training loss = 4.8362  Validation loss = 11.0859  \n",
      "\n",
      "Fold: 15  Epoch: 333  Training loss = 4.8357  Validation loss = 11.0853  \n",
      "\n",
      "Fold: 15  Epoch: 334  Training loss = 4.8354  Validation loss = 11.0846  \n",
      "\n",
      "Fold: 15  Epoch: 335  Training loss = 4.8348  Validation loss = 11.0837  \n",
      "\n",
      "Fold: 15  Epoch: 336  Training loss = 4.8343  Validation loss = 11.0830  \n",
      "\n",
      "Fold: 15  Epoch: 337  Training loss = 4.8337  Validation loss = 11.0821  \n",
      "\n",
      "Fold: 15  Epoch: 338  Training loss = 4.8332  Validation loss = 11.0812  \n",
      "\n",
      "Fold: 15  Epoch: 339  Training loss = 4.8327  Validation loss = 11.0804  \n",
      "\n",
      "Fold: 15  Epoch: 340  Training loss = 4.8322  Validation loss = 11.0795  \n",
      "\n",
      "Fold: 15  Epoch: 341  Training loss = 4.8316  Validation loss = 11.0786  \n",
      "\n",
      "Fold: 15  Epoch: 342  Training loss = 4.8310  Validation loss = 11.0776  \n",
      "\n",
      "Fold: 15  Epoch: 343  Training loss = 4.8305  Validation loss = 11.0767  \n",
      "\n",
      "Fold: 15  Epoch: 344  Training loss = 4.8300  Validation loss = 11.0760  \n",
      "\n",
      "Fold: 15  Epoch: 345  Training loss = 4.8295  Validation loss = 11.0753  \n",
      "\n",
      "Fold: 15  Epoch: 346  Training loss = 4.8290  Validation loss = 11.0745  \n",
      "\n",
      "Fold: 15  Epoch: 347  Training loss = 4.8284  Validation loss = 11.0736  \n",
      "\n",
      "Fold: 15  Epoch: 348  Training loss = 4.8279  Validation loss = 11.0729  \n",
      "\n",
      "Fold: 15  Epoch: 349  Training loss = 4.8274  Validation loss = 11.0721  \n",
      "\n",
      "Fold: 15  Epoch: 350  Training loss = 4.8270  Validation loss = 11.0714  \n",
      "\n",
      "Fold: 15  Epoch: 351  Training loss = 4.8264  Validation loss = 11.0706  \n",
      "\n",
      "Fold: 15  Epoch: 352  Training loss = 4.8259  Validation loss = 11.0696  \n",
      "\n",
      "Fold: 15  Epoch: 353  Training loss = 4.8254  Validation loss = 11.0688  \n",
      "\n",
      "Fold: 15  Epoch: 354  Training loss = 4.8249  Validation loss = 11.0680  \n",
      "\n",
      "Fold: 15  Epoch: 355  Training loss = 4.8244  Validation loss = 11.0671  \n",
      "\n",
      "Fold: 15  Epoch: 356  Training loss = 4.8238  Validation loss = 11.0662  \n",
      "\n",
      "Fold: 15  Epoch: 357  Training loss = 4.8232  Validation loss = 11.0654  \n",
      "\n",
      "Fold: 15  Epoch: 358  Training loss = 4.8227  Validation loss = 11.0645  \n",
      "\n",
      "Fold: 15  Epoch: 359  Training loss = 4.8223  Validation loss = 11.0639  \n",
      "\n",
      "Fold: 15  Epoch: 360  Training loss = 4.8217  Validation loss = 11.0630  \n",
      "\n",
      "Fold: 15  Epoch: 361  Training loss = 4.8213  Validation loss = 11.0624  \n",
      "\n",
      "Fold: 15  Epoch: 362  Training loss = 4.8208  Validation loss = 11.0616  \n",
      "\n",
      "Fold: 15  Epoch: 363  Training loss = 4.8203  Validation loss = 11.0606  \n",
      "\n",
      "Fold: 15  Epoch: 364  Training loss = 4.8197  Validation loss = 11.0598  \n",
      "\n",
      "Fold: 15  Epoch: 365  Training loss = 4.8191  Validation loss = 11.0588  \n",
      "\n",
      "Fold: 15  Epoch: 366  Training loss = 4.8185  Validation loss = 11.0580  \n",
      "\n",
      "Fold: 15  Epoch: 367  Training loss = 4.8181  Validation loss = 11.0574  \n",
      "\n",
      "Fold: 15  Epoch: 368  Training loss = 4.8176  Validation loss = 11.0565  \n",
      "\n",
      "Fold: 15  Epoch: 369  Training loss = 4.8171  Validation loss = 11.0555  \n",
      "\n",
      "Fold: 15  Epoch: 370  Training loss = 4.8166  Validation loss = 11.0545  \n",
      "\n",
      "Fold: 15  Epoch: 371  Training loss = 4.8160  Validation loss = 11.0536  \n",
      "\n",
      "Fold: 15  Epoch: 372  Training loss = 4.8155  Validation loss = 11.0528  \n",
      "\n",
      "Fold: 15  Epoch: 373  Training loss = 4.8149  Validation loss = 11.0520  \n",
      "\n",
      "Fold: 15  Epoch: 374  Training loss = 4.8144  Validation loss = 11.0512  \n",
      "\n",
      "Fold: 15  Epoch: 375  Training loss = 4.8139  Validation loss = 11.0504  \n",
      "\n",
      "Fold: 15  Epoch: 376  Training loss = 4.8134  Validation loss = 11.0495  \n",
      "\n",
      "Fold: 15  Epoch: 377  Training loss = 4.8128  Validation loss = 11.0484  \n",
      "\n",
      "Fold: 15  Epoch: 378  Training loss = 4.8121  Validation loss = 11.0473  \n",
      "\n",
      "Fold: 15  Epoch: 379  Training loss = 4.8116  Validation loss = 11.0465  \n",
      "\n",
      "Fold: 15  Epoch: 380  Training loss = 4.8110  Validation loss = 11.0455  \n",
      "\n",
      "Fold: 15  Epoch: 381  Training loss = 4.8105  Validation loss = 11.0448  \n",
      "\n",
      "Fold: 15  Epoch: 382  Training loss = 4.8101  Validation loss = 11.0440  \n",
      "\n",
      "Fold: 15  Epoch: 383  Training loss = 4.8096  Validation loss = 11.0429  \n",
      "\n",
      "Fold: 15  Epoch: 384  Training loss = 4.8091  Validation loss = 11.0422  \n",
      "\n",
      "Fold: 15  Epoch: 385  Training loss = 4.8086  Validation loss = 11.0415  \n",
      "\n",
      "Fold: 15  Epoch: 386  Training loss = 4.8081  Validation loss = 11.0407  \n",
      "\n",
      "Fold: 15  Epoch: 387  Training loss = 4.8077  Validation loss = 11.0400  \n",
      "\n",
      "Fold: 15  Epoch: 388  Training loss = 4.8073  Validation loss = 11.0394  \n",
      "\n",
      "Fold: 15  Epoch: 389  Training loss = 4.8069  Validation loss = 11.0388  \n",
      "\n",
      "Fold: 15  Epoch: 390  Training loss = 4.8065  Validation loss = 11.0382  \n",
      "\n",
      "Fold: 15  Epoch: 391  Training loss = 4.8059  Validation loss = 11.0374  \n",
      "\n",
      "Fold: 15  Epoch: 392  Training loss = 4.8054  Validation loss = 11.0365  \n",
      "\n",
      "Fold: 15  Epoch: 393  Training loss = 4.8050  Validation loss = 11.0358  \n",
      "\n",
      "Fold: 15  Epoch: 394  Training loss = 4.8046  Validation loss = 11.0351  \n",
      "\n",
      "Fold: 15  Epoch: 395  Training loss = 4.8041  Validation loss = 11.0343  \n",
      "\n",
      "Fold: 15  Epoch: 396  Training loss = 4.8035  Validation loss = 11.0333  \n",
      "\n",
      "Fold: 15  Epoch: 397  Training loss = 4.8031  Validation loss = 11.0326  \n",
      "\n",
      "Fold: 15  Epoch: 398  Training loss = 4.8026  Validation loss = 11.0316  \n",
      "\n",
      "Fold: 15  Epoch: 399  Training loss = 4.8022  Validation loss = 11.0309  \n",
      "\n",
      "Fold: 15  Epoch: 400  Training loss = 4.8017  Validation loss = 11.0300  \n",
      "\n",
      "Fold: 15  Epoch: 401  Training loss = 4.8012  Validation loss = 11.0291  \n",
      "\n",
      "Fold: 15  Epoch: 402  Training loss = 4.8008  Validation loss = 11.0285  \n",
      "\n",
      "Fold: 15  Epoch: 403  Training loss = 4.8003  Validation loss = 11.0275  \n",
      "\n",
      "Fold: 15  Epoch: 404  Training loss = 4.7997  Validation loss = 11.0265  \n",
      "\n",
      "Fold: 15  Epoch: 405  Training loss = 4.7993  Validation loss = 11.0259  \n",
      "\n",
      "Fold: 15  Epoch: 406  Training loss = 4.7989  Validation loss = 11.0252  \n",
      "\n",
      "Fold: 15  Epoch: 407  Training loss = 4.7984  Validation loss = 11.0244  \n",
      "\n",
      "Fold: 15  Epoch: 408  Training loss = 4.7979  Validation loss = 11.0237  \n",
      "\n",
      "Fold: 15  Epoch: 409  Training loss = 4.7973  Validation loss = 11.0228  \n",
      "\n",
      "Fold: 15  Epoch: 410  Training loss = 4.7968  Validation loss = 11.0219  \n",
      "\n",
      "Fold: 15  Epoch: 411  Training loss = 4.7963  Validation loss = 11.0210  \n",
      "\n",
      "Fold: 15  Epoch: 412  Training loss = 4.7958  Validation loss = 11.0201  \n",
      "\n",
      "Fold: 15  Epoch: 413  Training loss = 4.7954  Validation loss = 11.0193  \n",
      "\n",
      "Fold: 15  Epoch: 414  Training loss = 4.7949  Validation loss = 11.0186  \n",
      "\n",
      "Fold: 15  Epoch: 415  Training loss = 4.7942  Validation loss = 11.0174  \n",
      "\n",
      "Fold: 15  Epoch: 416  Training loss = 4.7938  Validation loss = 11.0166  \n",
      "\n",
      "Fold: 15  Epoch: 417  Training loss = 4.7933  Validation loss = 11.0157  \n",
      "\n",
      "Fold: 15  Epoch: 418  Training loss = 4.7928  Validation loss = 11.0150  \n",
      "\n",
      "Fold: 15  Epoch: 419  Training loss = 4.7923  Validation loss = 11.0141  \n",
      "\n",
      "Fold: 15  Epoch: 420  Training loss = 4.7919  Validation loss = 11.0134  \n",
      "\n",
      "Fold: 15  Epoch: 421  Training loss = 4.7915  Validation loss = 11.0128  \n",
      "\n",
      "Fold: 15  Epoch: 422  Training loss = 4.7909  Validation loss = 11.0117  \n",
      "\n",
      "Fold: 15  Epoch: 423  Training loss = 4.7904  Validation loss = 11.0108  \n",
      "\n",
      "Fold: 15  Epoch: 424  Training loss = 4.7899  Validation loss = 11.0101  \n",
      "\n",
      "Fold: 15  Epoch: 425  Training loss = 4.7894  Validation loss = 11.0091  \n",
      "\n",
      "Fold: 15  Epoch: 426  Training loss = 4.7888  Validation loss = 11.0082  \n",
      "\n",
      "Fold: 15  Epoch: 427  Training loss = 4.7884  Validation loss = 11.0075  \n",
      "\n",
      "Fold: 15  Epoch: 428  Training loss = 4.7880  Validation loss = 11.0068  \n",
      "\n",
      "Fold: 15  Epoch: 429  Training loss = 4.7875  Validation loss = 11.0060  \n",
      "\n",
      "Fold: 15  Epoch: 430  Training loss = 4.7871  Validation loss = 11.0054  \n",
      "\n",
      "Fold: 15  Epoch: 431  Training loss = 4.7866  Validation loss = 11.0045  \n",
      "\n",
      "Fold: 15  Epoch: 432  Training loss = 4.7861  Validation loss = 11.0037  \n",
      "\n",
      "Fold: 15  Epoch: 433  Training loss = 4.7856  Validation loss = 11.0027  \n",
      "\n",
      "Fold: 15  Epoch: 434  Training loss = 4.7851  Validation loss = 11.0019  \n",
      "\n",
      "Fold: 15  Epoch: 435  Training loss = 4.7847  Validation loss = 11.0011  \n",
      "\n",
      "Fold: 15  Epoch: 436  Training loss = 4.7843  Validation loss = 11.0005  \n",
      "\n",
      "Fold: 15  Epoch: 437  Training loss = 4.7839  Validation loss = 10.9997  \n",
      "\n",
      "Fold: 15  Epoch: 438  Training loss = 4.7834  Validation loss = 10.9990  \n",
      "\n",
      "Fold: 15  Epoch: 439  Training loss = 4.7830  Validation loss = 10.9982  \n",
      "\n",
      "Fold: 15  Epoch: 440  Training loss = 4.7826  Validation loss = 10.9975  \n",
      "\n",
      "Fold: 15  Epoch: 441  Training loss = 4.7821  Validation loss = 10.9965  \n",
      "\n",
      "Fold: 15  Epoch: 442  Training loss = 4.7816  Validation loss = 10.9958  \n",
      "\n",
      "Fold: 15  Epoch: 443  Training loss = 4.7812  Validation loss = 10.9951  \n",
      "\n",
      "Fold: 15  Epoch: 444  Training loss = 4.7807  Validation loss = 10.9942  \n",
      "\n",
      "Fold: 15  Epoch: 445  Training loss = 4.7801  Validation loss = 10.9933  \n",
      "\n",
      "Fold: 15  Epoch: 446  Training loss = 4.7798  Validation loss = 10.9926  \n",
      "\n",
      "Fold: 15  Epoch: 447  Training loss = 4.7792  Validation loss = 10.9915  \n",
      "\n",
      "Fold: 15  Epoch: 448  Training loss = 4.7788  Validation loss = 10.9907  \n",
      "\n",
      "Fold: 15  Epoch: 449  Training loss = 4.7782  Validation loss = 10.9897  \n",
      "\n",
      "Fold: 15  Epoch: 450  Training loss = 4.7778  Validation loss = 10.9888  \n",
      "\n",
      "Fold: 15  Epoch: 451  Training loss = 4.7774  Validation loss = 10.9881  \n",
      "\n",
      "Fold: 15  Epoch: 452  Training loss = 4.7768  Validation loss = 10.9873  \n",
      "\n",
      "Fold: 15  Epoch: 453  Training loss = 4.7764  Validation loss = 10.9865  \n",
      "\n",
      "Fold: 15  Epoch: 454  Training loss = 4.7759  Validation loss = 10.9857  \n",
      "\n",
      "Fold: 15  Epoch: 455  Training loss = 4.7753  Validation loss = 10.9845  \n",
      "\n",
      "Fold: 15  Epoch: 456  Training loss = 4.7748  Validation loss = 10.9836  \n",
      "\n",
      "Fold: 15  Epoch: 457  Training loss = 4.7743  Validation loss = 10.9827  \n",
      "\n",
      "Fold: 15  Epoch: 458  Training loss = 4.7738  Validation loss = 10.9817  \n",
      "\n",
      "Fold: 15  Epoch: 459  Training loss = 4.7733  Validation loss = 10.9809  \n",
      "\n",
      "Fold: 15  Epoch: 460  Training loss = 4.7729  Validation loss = 10.9802  \n",
      "\n",
      "Fold: 15  Epoch: 461  Training loss = 4.7724  Validation loss = 10.9792  \n",
      "\n",
      "Fold: 15  Epoch: 462  Training loss = 4.7720  Validation loss = 10.9786  \n",
      "\n",
      "Fold: 15  Epoch: 463  Training loss = 4.7715  Validation loss = 10.9778  \n",
      "\n",
      "Fold: 15  Epoch: 464  Training loss = 4.7710  Validation loss = 10.9770  \n",
      "\n",
      "Fold: 15  Epoch: 465  Training loss = 4.7704  Validation loss = 10.9759  \n",
      "\n",
      "Fold: 15  Epoch: 466  Training loss = 4.7700  Validation loss = 10.9750  \n",
      "\n",
      "Fold: 15  Epoch: 467  Training loss = 4.7695  Validation loss = 10.9742  \n",
      "\n",
      "Fold: 15  Epoch: 468  Training loss = 4.7691  Validation loss = 10.9735  \n",
      "\n",
      "Fold: 15  Epoch: 469  Training loss = 4.7686  Validation loss = 10.9728  \n",
      "\n",
      "Fold: 15  Epoch: 470  Training loss = 4.7680  Validation loss = 10.9719  \n",
      "\n",
      "Fold: 15  Epoch: 471  Training loss = 4.7675  Validation loss = 10.9710  \n",
      "\n",
      "Fold: 15  Epoch: 472  Training loss = 4.7670  Validation loss = 10.9700  \n",
      "\n",
      "Fold: 15  Epoch: 473  Training loss = 4.7665  Validation loss = 10.9692  \n",
      "\n",
      "Fold: 15  Epoch: 474  Training loss = 4.7661  Validation loss = 10.9686  \n",
      "\n",
      "Fold: 15  Epoch: 475  Training loss = 4.7657  Validation loss = 10.9677  \n",
      "\n",
      "Fold: 15  Epoch: 476  Training loss = 4.7651  Validation loss = 10.9666  \n",
      "\n",
      "Fold: 15  Epoch: 477  Training loss = 4.7647  Validation loss = 10.9658  \n",
      "\n",
      "Fold: 15  Epoch: 478  Training loss = 4.7642  Validation loss = 10.9650  \n",
      "\n",
      "Fold: 15  Epoch: 479  Training loss = 4.7638  Validation loss = 10.9641  \n",
      "\n",
      "Fold: 15  Epoch: 480  Training loss = 4.7632  Validation loss = 10.9631  \n",
      "\n",
      "Fold: 15  Epoch: 481  Training loss = 4.7627  Validation loss = 10.9621  \n",
      "\n",
      "Fold: 15  Epoch: 482  Training loss = 4.7622  Validation loss = 10.9612  \n",
      "\n",
      "Fold: 15  Epoch: 483  Training loss = 4.7618  Validation loss = 10.9605  \n",
      "\n",
      "Fold: 15  Epoch: 484  Training loss = 4.7613  Validation loss = 10.9595  \n",
      "\n",
      "Fold: 15  Epoch: 485  Training loss = 4.7610  Validation loss = 10.9590  \n",
      "\n",
      "Fold: 15  Epoch: 486  Training loss = 4.7606  Validation loss = 10.9580  \n",
      "\n",
      "Fold: 15  Epoch: 487  Training loss = 4.7601  Validation loss = 10.9574  \n",
      "\n",
      "Fold: 15  Epoch: 488  Training loss = 4.7597  Validation loss = 10.9565  \n",
      "\n",
      "Fold: 15  Epoch: 489  Training loss = 4.7592  Validation loss = 10.9558  \n",
      "\n",
      "Fold: 15  Epoch: 490  Training loss = 4.7587  Validation loss = 10.9549  \n",
      "\n",
      "Fold: 15  Epoch: 491  Training loss = 4.7582  Validation loss = 10.9541  \n",
      "\n",
      "Fold: 15  Epoch: 492  Training loss = 4.7578  Validation loss = 10.9534  \n",
      "\n",
      "Fold: 15  Epoch: 493  Training loss = 4.7573  Validation loss = 10.9526  \n",
      "\n",
      "Fold: 15  Epoch: 494  Training loss = 4.7568  Validation loss = 10.9517  \n",
      "\n",
      "Fold: 15  Epoch: 495  Training loss = 4.7563  Validation loss = 10.9508  \n",
      "\n",
      "Fold: 15  Epoch: 496  Training loss = 4.7558  Validation loss = 10.9500  \n",
      "\n",
      "Fold: 15  Epoch: 497  Training loss = 4.7553  Validation loss = 10.9489  \n",
      "\n",
      "Fold: 15  Epoch: 498  Training loss = 4.7549  Validation loss = 10.9481  \n",
      "\n",
      "Fold: 15  Epoch: 499  Training loss = 4.7543  Validation loss = 10.9472  \n",
      "\n",
      "Fold: 15  Epoch: 500  Training loss = 4.7537  Validation loss = 10.9461  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 500  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 5.4692  Validation loss = 7.9024  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 5.4682  Validation loss = 7.9009  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 5.4674  Validation loss = 7.8997  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 5.4665  Validation loss = 7.8981  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 5.4658  Validation loss = 7.8971  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 5.4651  Validation loss = 7.8962  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 5.4641  Validation loss = 7.8946  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 5.4632  Validation loss = 7.8933  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 5.4624  Validation loss = 7.8919  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 5.4616  Validation loss = 7.8908  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 5.4609  Validation loss = 7.8898  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 5.4600  Validation loss = 7.8885  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 5.4591  Validation loss = 7.8872  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 5.4584  Validation loss = 7.8861  \n",
      "\n",
      "Fold: 16  Epoch: 15  Training loss = 5.4577  Validation loss = 7.8851  \n",
      "\n",
      "Fold: 16  Epoch: 16  Training loss = 5.4566  Validation loss = 7.8833  \n",
      "\n",
      "Fold: 16  Epoch: 17  Training loss = 5.4558  Validation loss = 7.8821  \n",
      "\n",
      "Fold: 16  Epoch: 18  Training loss = 5.4547  Validation loss = 7.8802  \n",
      "\n",
      "Fold: 16  Epoch: 19  Training loss = 5.4539  Validation loss = 7.8790  \n",
      "\n",
      "Fold: 16  Epoch: 20  Training loss = 5.4530  Validation loss = 7.8774  \n",
      "\n",
      "Fold: 16  Epoch: 21  Training loss = 5.4522  Validation loss = 7.8762  \n",
      "\n",
      "Fold: 16  Epoch: 22  Training loss = 5.4516  Validation loss = 7.8753  \n",
      "\n",
      "Fold: 16  Epoch: 23  Training loss = 5.4507  Validation loss = 7.8738  \n",
      "\n",
      "Fold: 16  Epoch: 24  Training loss = 5.4498  Validation loss = 7.8723  \n",
      "\n",
      "Fold: 16  Epoch: 25  Training loss = 5.4490  Validation loss = 7.8711  \n",
      "\n",
      "Fold: 16  Epoch: 26  Training loss = 5.4481  Validation loss = 7.8697  \n",
      "\n",
      "Fold: 16  Epoch: 27  Training loss = 5.4471  Validation loss = 7.8679  \n",
      "\n",
      "Fold: 16  Epoch: 28  Training loss = 5.4464  Validation loss = 7.8670  \n",
      "\n",
      "Fold: 16  Epoch: 29  Training loss = 5.4456  Validation loss = 7.8657  \n",
      "\n",
      "Fold: 16  Epoch: 30  Training loss = 5.4448  Validation loss = 7.8646  \n",
      "\n",
      "Fold: 16  Epoch: 31  Training loss = 5.4440  Validation loss = 7.8634  \n",
      "\n",
      "Fold: 16  Epoch: 32  Training loss = 5.4430  Validation loss = 7.8618  \n",
      "\n",
      "Fold: 16  Epoch: 33  Training loss = 5.4419  Validation loss = 7.8598  \n",
      "\n",
      "Fold: 16  Epoch: 34  Training loss = 5.4409  Validation loss = 7.8581  \n",
      "\n",
      "Fold: 16  Epoch: 35  Training loss = 5.4403  Validation loss = 7.8573  \n",
      "\n",
      "Fold: 16  Epoch: 36  Training loss = 5.4393  Validation loss = 7.8556  \n",
      "\n",
      "Fold: 16  Epoch: 37  Training loss = 5.4385  Validation loss = 7.8545  \n",
      "\n",
      "Fold: 16  Epoch: 38  Training loss = 5.4376  Validation loss = 7.8531  \n",
      "\n",
      "Fold: 16  Epoch: 39  Training loss = 5.4368  Validation loss = 7.8520  \n",
      "\n",
      "Fold: 16  Epoch: 40  Training loss = 5.4360  Validation loss = 7.8507  \n",
      "\n",
      "Fold: 16  Epoch: 41  Training loss = 5.4350  Validation loss = 7.8492  \n",
      "\n",
      "Fold: 16  Epoch: 42  Training loss = 5.4340  Validation loss = 7.8476  \n",
      "\n",
      "Fold: 16  Epoch: 43  Training loss = 5.4333  Validation loss = 7.8465  \n",
      "\n",
      "Fold: 16  Epoch: 44  Training loss = 5.4325  Validation loss = 7.8453  \n",
      "\n",
      "Fold: 16  Epoch: 45  Training loss = 5.4316  Validation loss = 7.8440  \n",
      "\n",
      "Fold: 16  Epoch: 46  Training loss = 5.4308  Validation loss = 7.8428  \n",
      "\n",
      "Fold: 16  Epoch: 47  Training loss = 5.4298  Validation loss = 7.8411  \n",
      "\n",
      "Fold: 16  Epoch: 48  Training loss = 5.4289  Validation loss = 7.8396  \n",
      "\n",
      "Fold: 16  Epoch: 49  Training loss = 5.4281  Validation loss = 7.8384  \n",
      "\n",
      "Fold: 16  Epoch: 50  Training loss = 5.4272  Validation loss = 7.8371  \n",
      "\n",
      "Fold: 16  Epoch: 51  Training loss = 5.4264  Validation loss = 7.8358  \n",
      "\n",
      "Fold: 16  Epoch: 52  Training loss = 5.4258  Validation loss = 7.8349  \n",
      "\n",
      "Fold: 16  Epoch: 53  Training loss = 5.4249  Validation loss = 7.8334  \n",
      "\n",
      "Fold: 16  Epoch: 54  Training loss = 5.4242  Validation loss = 7.8325  \n",
      "\n",
      "Fold: 16  Epoch: 55  Training loss = 5.4233  Validation loss = 7.8311  \n",
      "\n",
      "Fold: 16  Epoch: 56  Training loss = 5.4225  Validation loss = 7.8297  \n",
      "\n",
      "Fold: 16  Epoch: 57  Training loss = 5.4217  Validation loss = 7.8284  \n",
      "\n",
      "Fold: 16  Epoch: 58  Training loss = 5.4207  Validation loss = 7.8269  \n",
      "\n",
      "Fold: 16  Epoch: 59  Training loss = 5.4200  Validation loss = 7.8259  \n",
      "\n",
      "Fold: 16  Epoch: 60  Training loss = 5.4191  Validation loss = 7.8241  \n",
      "\n",
      "Fold: 16  Epoch: 61  Training loss = 5.4183  Validation loss = 7.8228  \n",
      "\n",
      "Fold: 16  Epoch: 62  Training loss = 5.4173  Validation loss = 7.8210  \n",
      "\n",
      "Fold: 16  Epoch: 63  Training loss = 5.4166  Validation loss = 7.8199  \n",
      "\n",
      "Fold: 16  Epoch: 64  Training loss = 5.4157  Validation loss = 7.8187  \n",
      "\n",
      "Fold: 16  Epoch: 65  Training loss = 5.4149  Validation loss = 7.8175  \n",
      "\n",
      "Fold: 16  Epoch: 66  Training loss = 5.4140  Validation loss = 7.8160  \n",
      "\n",
      "Fold: 16  Epoch: 67  Training loss = 5.4131  Validation loss = 7.8146  \n",
      "\n",
      "Fold: 16  Epoch: 68  Training loss = 5.4123  Validation loss = 7.8134  \n",
      "\n",
      "Fold: 16  Epoch: 69  Training loss = 5.4116  Validation loss = 7.8126  \n",
      "\n",
      "Fold: 16  Epoch: 70  Training loss = 5.4109  Validation loss = 7.8115  \n",
      "\n",
      "Fold: 16  Epoch: 71  Training loss = 5.4101  Validation loss = 7.8105  \n",
      "\n",
      "Fold: 16  Epoch: 72  Training loss = 5.4093  Validation loss = 7.8092  \n",
      "\n",
      "Fold: 16  Epoch: 73  Training loss = 5.4084  Validation loss = 7.8079  \n",
      "\n",
      "Fold: 16  Epoch: 74  Training loss = 5.4077  Validation loss = 7.8068  \n",
      "\n",
      "Fold: 16  Epoch: 75  Training loss = 5.4070  Validation loss = 7.8057  \n",
      "\n",
      "Fold: 16  Epoch: 76  Training loss = 5.4064  Validation loss = 7.8050  \n",
      "\n",
      "Fold: 16  Epoch: 77  Training loss = 5.4056  Validation loss = 7.8039  \n",
      "\n",
      "Fold: 16  Epoch: 78  Training loss = 5.4047  Validation loss = 7.8026  \n",
      "\n",
      "Fold: 16  Epoch: 79  Training loss = 5.4038  Validation loss = 7.8013  \n",
      "\n",
      "Fold: 16  Epoch: 80  Training loss = 5.4032  Validation loss = 7.8003  \n",
      "\n",
      "Fold: 16  Epoch: 81  Training loss = 5.4026  Validation loss = 7.7995  \n",
      "\n",
      "Fold: 16  Epoch: 82  Training loss = 5.4019  Validation loss = 7.7984  \n",
      "\n",
      "Fold: 16  Epoch: 83  Training loss = 5.4010  Validation loss = 7.7969  \n",
      "\n",
      "Fold: 16  Epoch: 84  Training loss = 5.4002  Validation loss = 7.7957  \n",
      "\n",
      "Fold: 16  Epoch: 85  Training loss = 5.3996  Validation loss = 7.7947  \n",
      "\n",
      "Fold: 16  Epoch: 86  Training loss = 5.3989  Validation loss = 7.7939  \n",
      "\n",
      "Fold: 16  Epoch: 87  Training loss = 5.3982  Validation loss = 7.7929  \n",
      "\n",
      "Fold: 16  Epoch: 88  Training loss = 5.3975  Validation loss = 7.7918  \n",
      "\n",
      "Fold: 16  Epoch: 89  Training loss = 5.3968  Validation loss = 7.7908  \n",
      "\n",
      "Fold: 16  Epoch: 90  Training loss = 5.3959  Validation loss = 7.7894  \n",
      "\n",
      "Fold: 16  Epoch: 91  Training loss = 5.3953  Validation loss = 7.7886  \n",
      "\n",
      "Fold: 16  Epoch: 92  Training loss = 5.3946  Validation loss = 7.7878  \n",
      "\n",
      "Fold: 16  Epoch: 93  Training loss = 5.3939  Validation loss = 7.7867  \n",
      "\n",
      "Fold: 16  Epoch: 94  Training loss = 5.3933  Validation loss = 7.7859  \n",
      "\n",
      "Fold: 16  Epoch: 95  Training loss = 5.3925  Validation loss = 7.7848  \n",
      "\n",
      "Fold: 16  Epoch: 96  Training loss = 5.3918  Validation loss = 7.7836  \n",
      "\n",
      "Fold: 16  Epoch: 97  Training loss = 5.3911  Validation loss = 7.7828  \n",
      "\n",
      "Fold: 16  Epoch: 98  Training loss = 5.3905  Validation loss = 7.7820  \n",
      "\n",
      "Fold: 16  Epoch: 99  Training loss = 5.3897  Validation loss = 7.7809  \n",
      "\n",
      "Fold: 16  Epoch: 100  Training loss = 5.3891  Validation loss = 7.7799  \n",
      "\n",
      "Fold: 16  Epoch: 101  Training loss = 5.3883  Validation loss = 7.7788  \n",
      "\n",
      "Fold: 16  Epoch: 102  Training loss = 5.3875  Validation loss = 7.7776  \n",
      "\n",
      "Fold: 16  Epoch: 103  Training loss = 5.3870  Validation loss = 7.7768  \n",
      "\n",
      "Fold: 16  Epoch: 104  Training loss = 5.3864  Validation loss = 7.7762  \n",
      "\n",
      "Fold: 16  Epoch: 105  Training loss = 5.3857  Validation loss = 7.7752  \n",
      "\n",
      "Fold: 16  Epoch: 106  Training loss = 5.3851  Validation loss = 7.7743  \n",
      "\n",
      "Fold: 16  Epoch: 107  Training loss = 5.3845  Validation loss = 7.7736  \n",
      "\n",
      "Fold: 16  Epoch: 108  Training loss = 5.3839  Validation loss = 7.7729  \n",
      "\n",
      "Fold: 16  Epoch: 109  Training loss = 5.3831  Validation loss = 7.7717  \n",
      "\n",
      "Fold: 16  Epoch: 110  Training loss = 5.3824  Validation loss = 7.7708  \n",
      "\n",
      "Fold: 16  Epoch: 111  Training loss = 5.3817  Validation loss = 7.7699  \n",
      "\n",
      "Fold: 16  Epoch: 112  Training loss = 5.3811  Validation loss = 7.7689  \n",
      "\n",
      "Fold: 16  Epoch: 113  Training loss = 5.3804  Validation loss = 7.7681  \n",
      "\n",
      "Fold: 16  Epoch: 114  Training loss = 5.3799  Validation loss = 7.7674  \n",
      "\n",
      "Fold: 16  Epoch: 115  Training loss = 5.3791  Validation loss = 7.7663  \n",
      "\n",
      "Fold: 16  Epoch: 116  Training loss = 5.3783  Validation loss = 7.7651  \n",
      "\n",
      "Fold: 16  Epoch: 117  Training loss = 5.3777  Validation loss = 7.7643  \n",
      "\n",
      "Fold: 16  Epoch: 118  Training loss = 5.3770  Validation loss = 7.7633  \n",
      "\n",
      "Fold: 16  Epoch: 119  Training loss = 5.3763  Validation loss = 7.7625  \n",
      "\n",
      "Fold: 16  Epoch: 120  Training loss = 5.3757  Validation loss = 7.7616  \n",
      "\n",
      "Fold: 16  Epoch: 121  Training loss = 5.3751  Validation loss = 7.7609  \n",
      "\n",
      "Fold: 16  Epoch: 122  Training loss = 5.3745  Validation loss = 7.7601  \n",
      "\n",
      "Fold: 16  Epoch: 123  Training loss = 5.3739  Validation loss = 7.7593  \n",
      "\n",
      "Fold: 16  Epoch: 124  Training loss = 5.3732  Validation loss = 7.7585  \n",
      "\n",
      "Fold: 16  Epoch: 125  Training loss = 5.3725  Validation loss = 7.7575  \n",
      "\n",
      "Fold: 16  Epoch: 126  Training loss = 5.3719  Validation loss = 7.7566  \n",
      "\n",
      "Fold: 16  Epoch: 127  Training loss = 5.3713  Validation loss = 7.7559  \n",
      "\n",
      "Fold: 16  Epoch: 128  Training loss = 5.3706  Validation loss = 7.7550  \n",
      "\n",
      "Fold: 16  Epoch: 129  Training loss = 5.3700  Validation loss = 7.7543  \n",
      "\n",
      "Fold: 16  Epoch: 130  Training loss = 5.3694  Validation loss = 7.7536  \n",
      "\n",
      "Fold: 16  Epoch: 131  Training loss = 5.3687  Validation loss = 7.7525  \n",
      "\n",
      "Fold: 16  Epoch: 132  Training loss = 5.3680  Validation loss = 7.7518  \n",
      "\n",
      "Fold: 16  Epoch: 133  Training loss = 5.3675  Validation loss = 7.7511  \n",
      "\n",
      "Fold: 16  Epoch: 134  Training loss = 5.3670  Validation loss = 7.7504  \n",
      "\n",
      "Fold: 16  Epoch: 135  Training loss = 5.3663  Validation loss = 7.7495  \n",
      "\n",
      "Fold: 16  Epoch: 136  Training loss = 5.3656  Validation loss = 7.7485  \n",
      "\n",
      "Fold: 16  Epoch: 137  Training loss = 5.3651  Validation loss = 7.7480  \n",
      "\n",
      "Fold: 16  Epoch: 138  Training loss = 5.3645  Validation loss = 7.7472  \n",
      "\n",
      "Fold: 16  Epoch: 139  Training loss = 5.3639  Validation loss = 7.7465  \n",
      "\n",
      "Fold: 16  Epoch: 140  Training loss = 5.3633  Validation loss = 7.7456  \n",
      "\n",
      "Fold: 16  Epoch: 141  Training loss = 5.3626  Validation loss = 7.7447  \n",
      "\n",
      "Fold: 16  Epoch: 142  Training loss = 5.3621  Validation loss = 7.7440  \n",
      "\n",
      "Fold: 16  Epoch: 143  Training loss = 5.3616  Validation loss = 7.7434  \n",
      "\n",
      "Fold: 16  Epoch: 144  Training loss = 5.3610  Validation loss = 7.7428  \n",
      "\n",
      "Fold: 16  Epoch: 145  Training loss = 5.3604  Validation loss = 7.7420  \n",
      "\n",
      "Fold: 16  Epoch: 146  Training loss = 5.3599  Validation loss = 7.7414  \n",
      "\n",
      "Fold: 16  Epoch: 147  Training loss = 5.3594  Validation loss = 7.7408  \n",
      "\n",
      "Fold: 16  Epoch: 148  Training loss = 5.3587  Validation loss = 7.7400  \n",
      "\n",
      "Fold: 16  Epoch: 149  Training loss = 5.3581  Validation loss = 7.7391  \n",
      "\n",
      "Fold: 16  Epoch: 150  Training loss = 5.3576  Validation loss = 7.7386  \n",
      "\n",
      "Fold: 16  Epoch: 151  Training loss = 5.3570  Validation loss = 7.7379  \n",
      "\n",
      "Fold: 16  Epoch: 152  Training loss = 5.3565  Validation loss = 7.7372  \n",
      "\n",
      "Fold: 16  Epoch: 153  Training loss = 5.3559  Validation loss = 7.7364  \n",
      "\n",
      "Fold: 16  Epoch: 154  Training loss = 5.3552  Validation loss = 7.7356  \n",
      "\n",
      "Fold: 16  Epoch: 155  Training loss = 5.3546  Validation loss = 7.7347  \n",
      "\n",
      "Fold: 16  Epoch: 156  Training loss = 5.3540  Validation loss = 7.7339  \n",
      "\n",
      "Fold: 16  Epoch: 157  Training loss = 5.3532  Validation loss = 7.7329  \n",
      "\n",
      "Fold: 16  Epoch: 158  Training loss = 5.3525  Validation loss = 7.7321  \n",
      "\n",
      "Fold: 16  Epoch: 159  Training loss = 5.3520  Validation loss = 7.7314  \n",
      "\n",
      "Fold: 16  Epoch: 160  Training loss = 5.3514  Validation loss = 7.7306  \n",
      "\n",
      "Fold: 16  Epoch: 161  Training loss = 5.3507  Validation loss = 7.7298  \n",
      "\n",
      "Fold: 16  Epoch: 162  Training loss = 5.3501  Validation loss = 7.7291  \n",
      "\n",
      "Fold: 16  Epoch: 163  Training loss = 5.3496  Validation loss = 7.7286  \n",
      "\n",
      "Fold: 16  Epoch: 164  Training loss = 5.3490  Validation loss = 7.7278  \n",
      "\n",
      "Fold: 16  Epoch: 165  Training loss = 5.3486  Validation loss = 7.7274  \n",
      "\n",
      "Fold: 16  Epoch: 166  Training loss = 5.3480  Validation loss = 7.7266  \n",
      "\n",
      "Fold: 16  Epoch: 167  Training loss = 5.3474  Validation loss = 7.7259  \n",
      "\n",
      "Fold: 16  Epoch: 168  Training loss = 5.3468  Validation loss = 7.7252  \n",
      "\n",
      "Fold: 16  Epoch: 169  Training loss = 5.3462  Validation loss = 7.7245  \n",
      "\n",
      "Fold: 16  Epoch: 170  Training loss = 5.3457  Validation loss = 7.7238  \n",
      "\n",
      "Fold: 16  Epoch: 171  Training loss = 5.3451  Validation loss = 7.7232  \n",
      "\n",
      "Fold: 16  Epoch: 172  Training loss = 5.3445  Validation loss = 7.7225  \n",
      "\n",
      "Fold: 16  Epoch: 173  Training loss = 5.3438  Validation loss = 7.7216  \n",
      "\n",
      "Fold: 16  Epoch: 174  Training loss = 5.3433  Validation loss = 7.7210  \n",
      "\n",
      "Fold: 16  Epoch: 175  Training loss = 5.3428  Validation loss = 7.7205  \n",
      "\n",
      "Fold: 16  Epoch: 176  Training loss = 5.3422  Validation loss = 7.7198  \n",
      "\n",
      "Fold: 16  Epoch: 177  Training loss = 5.3417  Validation loss = 7.7192  \n",
      "\n",
      "Fold: 16  Epoch: 178  Training loss = 5.3411  Validation loss = 7.7185  \n",
      "\n",
      "Fold: 16  Epoch: 179  Training loss = 5.3405  Validation loss = 7.7178  \n",
      "\n",
      "Fold: 16  Epoch: 180  Training loss = 5.3400  Validation loss = 7.7172  \n",
      "\n",
      "Fold: 16  Epoch: 181  Training loss = 5.3394  Validation loss = 7.7164  \n",
      "\n",
      "Fold: 16  Epoch: 182  Training loss = 5.3389  Validation loss = 7.7159  \n",
      "\n",
      "Fold: 16  Epoch: 183  Training loss = 5.3383  Validation loss = 7.7152  \n",
      "\n",
      "Fold: 16  Epoch: 184  Training loss = 5.3377  Validation loss = 7.7146  \n",
      "\n",
      "Fold: 16  Epoch: 185  Training loss = 5.3372  Validation loss = 7.7140  \n",
      "\n",
      "Fold: 16  Epoch: 186  Training loss = 5.3367  Validation loss = 7.7134  \n",
      "\n",
      "Fold: 16  Epoch: 187  Training loss = 5.3361  Validation loss = 7.7127  \n",
      "\n",
      "Fold: 16  Epoch: 188  Training loss = 5.3356  Validation loss = 7.7121  \n",
      "\n",
      "Fold: 16  Epoch: 189  Training loss = 5.3350  Validation loss = 7.7114  \n",
      "\n",
      "Fold: 16  Epoch: 190  Training loss = 5.3343  Validation loss = 7.7106  \n",
      "\n",
      "Fold: 16  Epoch: 191  Training loss = 5.3337  Validation loss = 7.7098  \n",
      "\n",
      "Fold: 16  Epoch: 192  Training loss = 5.3332  Validation loss = 7.7093  \n",
      "\n",
      "Fold: 16  Epoch: 193  Training loss = 5.3328  Validation loss = 7.7088  \n",
      "\n",
      "Fold: 16  Epoch: 194  Training loss = 5.3323  Validation loss = 7.7082  \n",
      "\n",
      "Fold: 16  Epoch: 195  Training loss = 5.3318  Validation loss = 7.7077  \n",
      "\n",
      "Fold: 16  Epoch: 196  Training loss = 5.3312  Validation loss = 7.7069  \n",
      "\n",
      "Fold: 16  Epoch: 197  Training loss = 5.3305  Validation loss = 7.7061  \n",
      "\n",
      "Fold: 16  Epoch: 198  Training loss = 5.3299  Validation loss = 7.7054  \n",
      "\n",
      "Fold: 16  Epoch: 199  Training loss = 5.3293  Validation loss = 7.7046  \n",
      "\n",
      "Fold: 16  Epoch: 200  Training loss = 5.3287  Validation loss = 7.7040  \n",
      "\n",
      "Fold: 16  Epoch: 201  Training loss = 5.3280  Validation loss = 7.7032  \n",
      "\n",
      "Fold: 16  Epoch: 202  Training loss = 5.3275  Validation loss = 7.7026  \n",
      "\n",
      "Fold: 16  Epoch: 203  Training loss = 5.3269  Validation loss = 7.7019  \n",
      "\n",
      "Fold: 16  Epoch: 204  Training loss = 5.3263  Validation loss = 7.7012  \n",
      "\n",
      "Fold: 16  Epoch: 205  Training loss = 5.3257  Validation loss = 7.7005  \n",
      "\n",
      "Fold: 16  Epoch: 206  Training loss = 5.3252  Validation loss = 7.6999  \n",
      "\n",
      "Fold: 16  Epoch: 207  Training loss = 5.3245  Validation loss = 7.6991  \n",
      "\n",
      "Fold: 16  Epoch: 208  Training loss = 5.3240  Validation loss = 7.6985  \n",
      "\n",
      "Fold: 16  Epoch: 209  Training loss = 5.3235  Validation loss = 7.6980  \n",
      "\n",
      "Fold: 16  Epoch: 210  Training loss = 5.3230  Validation loss = 7.6974  \n",
      "\n",
      "Fold: 16  Epoch: 211  Training loss = 5.3225  Validation loss = 7.6968  \n",
      "\n",
      "Fold: 16  Epoch: 212  Training loss = 5.3220  Validation loss = 7.6962  \n",
      "\n",
      "Fold: 16  Epoch: 213  Training loss = 5.3213  Validation loss = 7.6955  \n",
      "\n",
      "Fold: 16  Epoch: 214  Training loss = 5.3207  Validation loss = 7.6947  \n",
      "\n",
      "Fold: 16  Epoch: 215  Training loss = 5.3201  Validation loss = 7.6941  \n",
      "\n",
      "Fold: 16  Epoch: 216  Training loss = 5.3195  Validation loss = 7.6933  \n",
      "\n",
      "Fold: 16  Epoch: 217  Training loss = 5.3189  Validation loss = 7.6926  \n",
      "\n",
      "Fold: 16  Epoch: 218  Training loss = 5.3183  Validation loss = 7.6919  \n",
      "\n",
      "Fold: 16  Epoch: 219  Training loss = 5.3177  Validation loss = 7.6912  \n",
      "\n",
      "Fold: 16  Epoch: 220  Training loss = 5.3170  Validation loss = 7.6903  \n",
      "\n",
      "Fold: 16  Epoch: 221  Training loss = 5.3164  Validation loss = 7.6896  \n",
      "\n",
      "Fold: 16  Epoch: 222  Training loss = 5.3157  Validation loss = 7.6888  \n",
      "\n",
      "Fold: 16  Epoch: 223  Training loss = 5.3150  Validation loss = 7.6880  \n",
      "\n",
      "Fold: 16  Epoch: 224  Training loss = 5.3142  Validation loss = 7.6872  \n",
      "\n",
      "Fold: 16  Epoch: 225  Training loss = 5.3133  Validation loss = 7.6863  \n",
      "\n",
      "Fold: 16  Epoch: 226  Training loss = 5.3125  Validation loss = 7.6855  \n",
      "\n",
      "Fold: 16  Epoch: 227  Training loss = 5.3117  Validation loss = 7.6847  \n",
      "\n",
      "Fold: 16  Epoch: 228  Training loss = 5.3108  Validation loss = 7.6837  \n",
      "\n",
      "Fold: 16  Epoch: 229  Training loss = 5.3102  Validation loss = 7.6830  \n",
      "\n",
      "Fold: 16  Epoch: 230  Training loss = 5.3096  Validation loss = 7.6823  \n",
      "\n",
      "Fold: 16  Epoch: 231  Training loss = 5.3090  Validation loss = 7.6816  \n",
      "\n",
      "Fold: 16  Epoch: 232  Training loss = 5.3084  Validation loss = 7.6809  \n",
      "\n",
      "Fold: 16  Epoch: 233  Training loss = 5.3078  Validation loss = 7.6802  \n",
      "\n",
      "Fold: 16  Epoch: 234  Training loss = 5.3073  Validation loss = 7.6797  \n",
      "\n",
      "Fold: 16  Epoch: 235  Training loss = 5.3067  Validation loss = 7.6789  \n",
      "\n",
      "Fold: 16  Epoch: 236  Training loss = 5.3061  Validation loss = 7.6783  \n",
      "\n",
      "Fold: 16  Epoch: 237  Training loss = 5.3055  Validation loss = 7.6776  \n",
      "\n",
      "Fold: 16  Epoch: 238  Training loss = 5.3050  Validation loss = 7.6771  \n",
      "\n",
      "Fold: 16  Epoch: 239  Training loss = 5.3044  Validation loss = 7.6764  \n",
      "\n",
      "Fold: 16  Epoch: 240  Training loss = 5.3038  Validation loss = 7.6757  \n",
      "\n",
      "Fold: 16  Epoch: 241  Training loss = 5.3032  Validation loss = 7.6750  \n",
      "\n",
      "Fold: 16  Epoch: 242  Training loss = 5.3026  Validation loss = 7.6744  \n",
      "\n",
      "Fold: 16  Epoch: 243  Training loss = 5.3020  Validation loss = 7.6738  \n",
      "\n",
      "Fold: 16  Epoch: 244  Training loss = 5.3015  Validation loss = 7.6732  \n",
      "\n",
      "Fold: 16  Epoch: 245  Training loss = 5.3009  Validation loss = 7.6726  \n",
      "\n",
      "Fold: 16  Epoch: 246  Training loss = 5.3003  Validation loss = 7.6719  \n",
      "\n",
      "Fold: 16  Epoch: 247  Training loss = 5.2998  Validation loss = 7.6713  \n",
      "\n",
      "Fold: 16  Epoch: 248  Training loss = 5.2992  Validation loss = 7.6707  \n",
      "\n",
      "Fold: 16  Epoch: 249  Training loss = 5.2986  Validation loss = 7.6700  \n",
      "\n",
      "Fold: 16  Epoch: 250  Training loss = 5.2981  Validation loss = 7.6694  \n",
      "\n",
      "Fold: 16  Epoch: 251  Training loss = 5.2975  Validation loss = 7.6688  \n",
      "\n",
      "Fold: 16  Epoch: 252  Training loss = 5.2969  Validation loss = 7.6682  \n",
      "\n",
      "Fold: 16  Epoch: 253  Training loss = 5.2964  Validation loss = 7.6676  \n",
      "\n",
      "Fold: 16  Epoch: 254  Training loss = 5.2958  Validation loss = 7.6669  \n",
      "\n",
      "Fold: 16  Epoch: 255  Training loss = 5.2953  Validation loss = 7.6664  \n",
      "\n",
      "Fold: 16  Epoch: 256  Training loss = 5.2947  Validation loss = 7.6657  \n",
      "\n",
      "Fold: 16  Epoch: 257  Training loss = 5.2941  Validation loss = 7.6651  \n",
      "\n",
      "Fold: 16  Epoch: 258  Training loss = 5.2936  Validation loss = 7.6645  \n",
      "\n",
      "Fold: 16  Epoch: 259  Training loss = 5.2930  Validation loss = 7.6639  \n",
      "\n",
      "Fold: 16  Epoch: 260  Training loss = 5.2925  Validation loss = 7.6634  \n",
      "\n",
      "Fold: 16  Epoch: 261  Training loss = 5.2919  Validation loss = 7.6628  \n",
      "\n",
      "Fold: 16  Epoch: 262  Training loss = 5.2915  Validation loss = 7.6623  \n",
      "\n",
      "Fold: 16  Epoch: 263  Training loss = 5.2909  Validation loss = 7.6616  \n",
      "\n",
      "Fold: 16  Epoch: 264  Training loss = 5.2903  Validation loss = 7.6610  \n",
      "\n",
      "Fold: 16  Epoch: 265  Training loss = 5.2897  Validation loss = 7.6604  \n",
      "\n",
      "Fold: 16  Epoch: 266  Training loss = 5.2891  Validation loss = 7.6597  \n",
      "\n",
      "Fold: 16  Epoch: 267  Training loss = 5.2885  Validation loss = 7.6591  \n",
      "\n",
      "Fold: 16  Epoch: 268  Training loss = 5.2880  Validation loss = 7.6584  \n",
      "\n",
      "Fold: 16  Epoch: 269  Training loss = 5.2875  Validation loss = 7.6580  \n",
      "\n",
      "Fold: 16  Epoch: 270  Training loss = 5.2870  Validation loss = 7.6574  \n",
      "\n",
      "Fold: 16  Epoch: 271  Training loss = 5.2864  Validation loss = 7.6567  \n",
      "\n",
      "Fold: 16  Epoch: 272  Training loss = 5.2858  Validation loss = 7.6561  \n",
      "\n",
      "Fold: 16  Epoch: 273  Training loss = 5.2853  Validation loss = 7.6555  \n",
      "\n",
      "Fold: 16  Epoch: 274  Training loss = 5.2846  Validation loss = 7.6548  \n",
      "\n",
      "Fold: 16  Epoch: 275  Training loss = 5.2841  Validation loss = 7.6542  \n",
      "\n",
      "Fold: 16  Epoch: 276  Training loss = 5.2836  Validation loss = 7.6536  \n",
      "\n",
      "Fold: 16  Epoch: 277  Training loss = 5.2831  Validation loss = 7.6531  \n",
      "\n",
      "Fold: 16  Epoch: 278  Training loss = 5.2825  Validation loss = 7.6525  \n",
      "\n",
      "Fold: 16  Epoch: 279  Training loss = 5.2820  Validation loss = 7.6519  \n",
      "\n",
      "Fold: 16  Epoch: 280  Training loss = 5.2815  Validation loss = 7.6514  \n",
      "\n",
      "Fold: 16  Epoch: 281  Training loss = 5.2809  Validation loss = 7.6507  \n",
      "\n",
      "Fold: 16  Epoch: 282  Training loss = 5.2804  Validation loss = 7.6502  \n",
      "\n",
      "Fold: 16  Epoch: 283  Training loss = 5.2799  Validation loss = 7.6496  \n",
      "\n",
      "Fold: 16  Epoch: 284  Training loss = 5.2794  Validation loss = 7.6491  \n",
      "\n",
      "Fold: 16  Epoch: 285  Training loss = 5.2788  Validation loss = 7.6485  \n",
      "\n",
      "Fold: 16  Epoch: 286  Training loss = 5.2783  Validation loss = 7.6479  \n",
      "\n",
      "Fold: 16  Epoch: 287  Training loss = 5.2778  Validation loss = 7.6474  \n",
      "\n",
      "Fold: 16  Epoch: 288  Training loss = 5.2774  Validation loss = 7.6470  \n",
      "\n",
      "Fold: 16  Epoch: 289  Training loss = 5.2768  Validation loss = 7.6463  \n",
      "\n",
      "Fold: 16  Epoch: 290  Training loss = 5.2762  Validation loss = 7.6456  \n",
      "\n",
      "Fold: 16  Epoch: 291  Training loss = 5.2756  Validation loss = 7.6450  \n",
      "\n",
      "Fold: 16  Epoch: 292  Training loss = 5.2750  Validation loss = 7.6444  \n",
      "\n",
      "Fold: 16  Epoch: 293  Training loss = 5.2744  Validation loss = 7.6438  \n",
      "\n",
      "Fold: 16  Epoch: 294  Training loss = 5.2738  Validation loss = 7.6431  \n",
      "\n",
      "Fold: 16  Epoch: 295  Training loss = 5.2733  Validation loss = 7.6426  \n",
      "\n",
      "Fold: 16  Epoch: 296  Training loss = 5.2728  Validation loss = 7.6420  \n",
      "\n",
      "Fold: 16  Epoch: 297  Training loss = 5.2722  Validation loss = 7.6413  \n",
      "\n",
      "Fold: 16  Epoch: 298  Training loss = 5.2716  Validation loss = 7.6407  \n",
      "\n",
      "Fold: 16  Epoch: 299  Training loss = 5.2711  Validation loss = 7.6401  \n",
      "\n",
      "Fold: 16  Epoch: 300  Training loss = 5.2706  Validation loss = 7.6396  \n",
      "\n",
      "Fold: 16  Epoch: 301  Training loss = 5.2701  Validation loss = 7.6390  \n",
      "\n",
      "Fold: 16  Epoch: 302  Training loss = 5.2695  Validation loss = 7.6384  \n",
      "\n",
      "Fold: 16  Epoch: 303  Training loss = 5.2690  Validation loss = 7.6379  \n",
      "\n",
      "Fold: 16  Epoch: 304  Training loss = 5.2683  Validation loss = 7.6372  \n",
      "\n",
      "Fold: 16  Epoch: 305  Training loss = 5.2677  Validation loss = 7.6366  \n",
      "\n",
      "Fold: 16  Epoch: 306  Training loss = 5.2672  Validation loss = 7.6360  \n",
      "\n",
      "Fold: 16  Epoch: 307  Training loss = 5.2666  Validation loss = 7.6354  \n",
      "\n",
      "Fold: 16  Epoch: 308  Training loss = 5.2661  Validation loss = 7.6348  \n",
      "\n",
      "Fold: 16  Epoch: 309  Training loss = 5.2654  Validation loss = 7.6341  \n",
      "\n",
      "Fold: 16  Epoch: 310  Training loss = 5.2648  Validation loss = 7.6334  \n",
      "\n",
      "Fold: 16  Epoch: 311  Training loss = 5.2644  Validation loss = 7.6329  \n",
      "\n",
      "Fold: 16  Epoch: 312  Training loss = 5.2638  Validation loss = 7.6323  \n",
      "\n",
      "Fold: 16  Epoch: 313  Training loss = 5.2632  Validation loss = 7.6316  \n",
      "\n",
      "Fold: 16  Epoch: 314  Training loss = 5.2627  Validation loss = 7.6311  \n",
      "\n",
      "Fold: 16  Epoch: 315  Training loss = 5.2622  Validation loss = 7.6305  \n",
      "\n",
      "Fold: 16  Epoch: 316  Training loss = 5.2617  Validation loss = 7.6300  \n",
      "\n",
      "Fold: 16  Epoch: 317  Training loss = 5.2611  Validation loss = 7.6294  \n",
      "\n",
      "Fold: 16  Epoch: 318  Training loss = 5.2606  Validation loss = 7.6288  \n",
      "\n",
      "Fold: 16  Epoch: 319  Training loss = 5.2600  Validation loss = 7.6282  \n",
      "\n",
      "Fold: 16  Epoch: 320  Training loss = 5.2594  Validation loss = 7.6276  \n",
      "\n",
      "Fold: 16  Epoch: 321  Training loss = 5.2589  Validation loss = 7.6270  \n",
      "\n",
      "Fold: 16  Epoch: 322  Training loss = 5.2583  Validation loss = 7.6263  \n",
      "\n",
      "Fold: 16  Epoch: 323  Training loss = 5.2577  Validation loss = 7.6257  \n",
      "\n",
      "Fold: 16  Epoch: 324  Training loss = 5.2571  Validation loss = 7.6251  \n",
      "\n",
      "Fold: 16  Epoch: 325  Training loss = 5.2565  Validation loss = 7.6245  \n",
      "\n",
      "Fold: 16  Epoch: 326  Training loss = 5.2560  Validation loss = 7.6239  \n",
      "\n",
      "Fold: 16  Epoch: 327  Training loss = 5.2554  Validation loss = 7.6233  \n",
      "\n",
      "Fold: 16  Epoch: 328  Training loss = 5.2549  Validation loss = 7.6228  \n",
      "\n",
      "Fold: 16  Epoch: 329  Training loss = 5.2545  Validation loss = 7.6223  \n",
      "\n",
      "Fold: 16  Epoch: 330  Training loss = 5.2538  Validation loss = 7.6216  \n",
      "\n",
      "Fold: 16  Epoch: 331  Training loss = 5.2532  Validation loss = 7.6209  \n",
      "\n",
      "Fold: 16  Epoch: 332  Training loss = 5.2528  Validation loss = 7.6204  \n",
      "\n",
      "Fold: 16  Epoch: 333  Training loss = 5.2523  Validation loss = 7.6199  \n",
      "\n",
      "Fold: 16  Epoch: 334  Training loss = 5.2518  Validation loss = 7.6194  \n",
      "\n",
      "Fold: 16  Epoch: 335  Training loss = 5.2513  Validation loss = 7.6188  \n",
      "\n",
      "Fold: 16  Epoch: 336  Training loss = 5.2508  Validation loss = 7.6182  \n",
      "\n",
      "Fold: 16  Epoch: 337  Training loss = 5.2502  Validation loss = 7.6176  \n",
      "\n",
      "Fold: 16  Epoch: 338  Training loss = 5.2496  Validation loss = 7.6169  \n",
      "\n",
      "Fold: 16  Epoch: 339  Training loss = 5.2490  Validation loss = 7.6164  \n",
      "\n",
      "Fold: 16  Epoch: 340  Training loss = 5.2485  Validation loss = 7.6158  \n",
      "\n",
      "Fold: 16  Epoch: 341  Training loss = 5.2479  Validation loss = 7.6151  \n",
      "\n",
      "Fold: 16  Epoch: 342  Training loss = 5.2473  Validation loss = 7.6145  \n",
      "\n",
      "Fold: 16  Epoch: 343  Training loss = 5.2468  Validation loss = 7.6139  \n",
      "\n",
      "Fold: 16  Epoch: 344  Training loss = 5.2463  Validation loss = 7.6134  \n",
      "\n",
      "Fold: 16  Epoch: 345  Training loss = 5.2458  Validation loss = 7.6128  \n",
      "\n",
      "Fold: 16  Epoch: 346  Training loss = 5.2452  Validation loss = 7.6122  \n",
      "\n",
      "Fold: 16  Epoch: 347  Training loss = 5.2448  Validation loss = 7.6118  \n",
      "\n",
      "Fold: 16  Epoch: 348  Training loss = 5.2443  Validation loss = 7.6112  \n",
      "\n",
      "Fold: 16  Epoch: 349  Training loss = 5.2437  Validation loss = 7.6105  \n",
      "\n",
      "Fold: 16  Epoch: 350  Training loss = 5.2431  Validation loss = 7.6100  \n",
      "\n",
      "Fold: 16  Epoch: 351  Training loss = 5.2425  Validation loss = 7.6093  \n",
      "\n",
      "Fold: 16  Epoch: 352  Training loss = 5.2420  Validation loss = 7.6087  \n",
      "\n",
      "Fold: 16  Epoch: 353  Training loss = 5.2414  Validation loss = 7.6081  \n",
      "\n",
      "Fold: 16  Epoch: 354  Training loss = 5.2410  Validation loss = 7.6076  \n",
      "\n",
      "Fold: 16  Epoch: 355  Training loss = 5.2404  Validation loss = 7.6070  \n",
      "\n",
      "Fold: 16  Epoch: 356  Training loss = 5.2399  Validation loss = 7.6064  \n",
      "\n",
      "Fold: 16  Epoch: 357  Training loss = 5.2392  Validation loss = 7.6058  \n",
      "\n",
      "Fold: 16  Epoch: 358  Training loss = 5.2388  Validation loss = 7.6053  \n",
      "\n",
      "Fold: 16  Epoch: 359  Training loss = 5.2384  Validation loss = 7.6048  \n",
      "\n",
      "Fold: 16  Epoch: 360  Training loss = 5.2379  Validation loss = 7.6043  \n",
      "\n",
      "Fold: 16  Epoch: 361  Training loss = 5.2373  Validation loss = 7.6037  \n",
      "\n",
      "Fold: 16  Epoch: 362  Training loss = 5.2367  Validation loss = 7.6030  \n",
      "\n",
      "Fold: 16  Epoch: 363  Training loss = 5.2361  Validation loss = 7.6024  \n",
      "\n",
      "Fold: 16  Epoch: 364  Training loss = 5.2355  Validation loss = 7.6017  \n",
      "\n",
      "Fold: 16  Epoch: 365  Training loss = 5.2349  Validation loss = 7.6011  \n",
      "\n",
      "Fold: 16  Epoch: 366  Training loss = 5.2343  Validation loss = 7.6005  \n",
      "\n",
      "Fold: 16  Epoch: 367  Training loss = 5.2338  Validation loss = 7.5999  \n",
      "\n",
      "Fold: 16  Epoch: 368  Training loss = 5.2332  Validation loss = 7.5993  \n",
      "\n",
      "Fold: 16  Epoch: 369  Training loss = 5.2327  Validation loss = 7.5987  \n",
      "\n",
      "Fold: 16  Epoch: 370  Training loss = 5.2321  Validation loss = 7.5981  \n",
      "\n",
      "Fold: 16  Epoch: 371  Training loss = 5.2317  Validation loss = 7.5976  \n",
      "\n",
      "Fold: 16  Epoch: 372  Training loss = 5.2311  Validation loss = 7.5971  \n",
      "\n",
      "Fold: 16  Epoch: 373  Training loss = 5.2305  Validation loss = 7.5964  \n",
      "\n",
      "Fold: 16  Epoch: 374  Training loss = 5.2299  Validation loss = 7.5957  \n",
      "\n",
      "Fold: 16  Epoch: 375  Training loss = 5.2295  Validation loss = 7.5952  \n",
      "\n",
      "Fold: 16  Epoch: 376  Training loss = 5.2288  Validation loss = 7.5945  \n",
      "\n",
      "Fold: 16  Epoch: 377  Training loss = 5.2283  Validation loss = 7.5940  \n",
      "\n",
      "Fold: 16  Epoch: 378  Training loss = 5.2278  Validation loss = 7.5934  \n",
      "\n",
      "Fold: 16  Epoch: 379  Training loss = 5.2273  Validation loss = 7.5929  \n",
      "\n",
      "Fold: 16  Epoch: 380  Training loss = 5.2268  Validation loss = 7.5923  \n",
      "\n",
      "Fold: 16  Epoch: 381  Training loss = 5.2263  Validation loss = 7.5918  \n",
      "\n",
      "Fold: 16  Epoch: 382  Training loss = 5.2258  Validation loss = 7.5912  \n",
      "\n",
      "Fold: 16  Epoch: 383  Training loss = 5.2252  Validation loss = 7.5906  \n",
      "\n",
      "Fold: 16  Epoch: 384  Training loss = 5.2247  Validation loss = 7.5901  \n",
      "\n",
      "Fold: 16  Epoch: 385  Training loss = 5.2241  Validation loss = 7.5894  \n",
      "\n",
      "Fold: 16  Epoch: 386  Training loss = 5.2235  Validation loss = 7.5888  \n",
      "\n",
      "Fold: 16  Epoch: 387  Training loss = 5.2229  Validation loss = 7.5882  \n",
      "\n",
      "Fold: 16  Epoch: 388  Training loss = 5.2223  Validation loss = 7.5875  \n",
      "\n",
      "Fold: 16  Epoch: 389  Training loss = 5.2218  Validation loss = 7.5869  \n",
      "\n",
      "Fold: 16  Epoch: 390  Training loss = 5.2211  Validation loss = 7.5862  \n",
      "\n",
      "Fold: 16  Epoch: 391  Training loss = 5.2205  Validation loss = 7.5855  \n",
      "\n",
      "Fold: 16  Epoch: 392  Training loss = 5.2199  Validation loss = 7.5849  \n",
      "\n",
      "Fold: 16  Epoch: 393  Training loss = 5.2194  Validation loss = 7.5843  \n",
      "\n",
      "Fold: 16  Epoch: 394  Training loss = 5.2188  Validation loss = 7.5837  \n",
      "\n",
      "Fold: 16  Epoch: 395  Training loss = 5.2183  Validation loss = 7.5831  \n",
      "\n",
      "Fold: 16  Epoch: 396  Training loss = 5.2178  Validation loss = 7.5826  \n",
      "\n",
      "Fold: 16  Epoch: 397  Training loss = 5.2173  Validation loss = 7.5821  \n",
      "\n",
      "Fold: 16  Epoch: 398  Training loss = 5.2167  Validation loss = 7.5814  \n",
      "\n",
      "Fold: 16  Epoch: 399  Training loss = 5.2162  Validation loss = 7.5809  \n",
      "\n",
      "Fold: 16  Epoch: 400  Training loss = 5.2156  Validation loss = 7.5803  \n",
      "\n",
      "Fold: 16  Epoch: 401  Training loss = 5.2151  Validation loss = 7.5798  \n",
      "\n",
      "Fold: 16  Epoch: 402  Training loss = 5.2146  Validation loss = 7.5792  \n",
      "\n",
      "Fold: 16  Epoch: 403  Training loss = 5.2141  Validation loss = 7.5787  \n",
      "\n",
      "Fold: 16  Epoch: 404  Training loss = 5.2135  Validation loss = 7.5780  \n",
      "\n",
      "Fold: 16  Epoch: 405  Training loss = 5.2129  Validation loss = 7.5775  \n",
      "\n",
      "Fold: 16  Epoch: 406  Training loss = 5.2123  Validation loss = 7.5768  \n",
      "\n",
      "Fold: 16  Epoch: 407  Training loss = 5.2118  Validation loss = 7.5763  \n",
      "\n",
      "Fold: 16  Epoch: 408  Training loss = 5.2113  Validation loss = 7.5757  \n",
      "\n",
      "Fold: 16  Epoch: 409  Training loss = 5.2108  Validation loss = 7.5752  \n",
      "\n",
      "Fold: 16  Epoch: 410  Training loss = 5.2103  Validation loss = 7.5746  \n",
      "\n",
      "Fold: 16  Epoch: 411  Training loss = 5.2096  Validation loss = 7.5739  \n",
      "\n",
      "Fold: 16  Epoch: 412  Training loss = 5.2091  Validation loss = 7.5733  \n",
      "\n",
      "Fold: 16  Epoch: 413  Training loss = 5.2084  Validation loss = 7.5727  \n",
      "\n",
      "Fold: 16  Epoch: 414  Training loss = 5.2079  Validation loss = 7.5721  \n",
      "\n",
      "Fold: 16  Epoch: 415  Training loss = 5.2073  Validation loss = 7.5715  \n",
      "\n",
      "Fold: 16  Epoch: 416  Training loss = 5.2068  Validation loss = 7.5710  \n",
      "\n",
      "Fold: 16  Epoch: 417  Training loss = 5.2063  Validation loss = 7.5704  \n",
      "\n",
      "Fold: 16  Epoch: 418  Training loss = 5.2057  Validation loss = 7.5698  \n",
      "\n",
      "Fold: 16  Epoch: 419  Training loss = 5.2052  Validation loss = 7.5692  \n",
      "\n",
      "Fold: 16  Epoch: 420  Training loss = 5.2047  Validation loss = 7.5687  \n",
      "\n",
      "Fold: 16  Epoch: 421  Training loss = 5.2042  Validation loss = 7.5681  \n",
      "\n",
      "Fold: 16  Epoch: 422  Training loss = 5.2037  Validation loss = 7.5676  \n",
      "\n",
      "Fold: 16  Epoch: 423  Training loss = 5.2032  Validation loss = 7.5671  \n",
      "\n",
      "Fold: 16  Epoch: 424  Training loss = 5.2026  Validation loss = 7.5665  \n",
      "\n",
      "Fold: 16  Epoch: 425  Training loss = 5.2021  Validation loss = 7.5659  \n",
      "\n",
      "Fold: 16  Epoch: 426  Training loss = 5.2014  Validation loss = 7.5652  \n",
      "\n",
      "Fold: 16  Epoch: 427  Training loss = 5.2010  Validation loss = 7.5648  \n",
      "\n",
      "Fold: 16  Epoch: 428  Training loss = 5.2005  Validation loss = 7.5642  \n",
      "\n",
      "Fold: 16  Epoch: 429  Training loss = 5.2000  Validation loss = 7.5637  \n",
      "\n",
      "Fold: 16  Epoch: 430  Training loss = 5.1996  Validation loss = 7.5632  \n",
      "\n",
      "Fold: 16  Epoch: 431  Training loss = 5.1991  Validation loss = 7.5627  \n",
      "\n",
      "Fold: 16  Epoch: 432  Training loss = 5.1986  Validation loss = 7.5621  \n",
      "\n",
      "Fold: 16  Epoch: 433  Training loss = 5.1981  Validation loss = 7.5616  \n",
      "\n",
      "Fold: 16  Epoch: 434  Training loss = 5.1975  Validation loss = 7.5610  \n",
      "\n",
      "Fold: 16  Epoch: 435  Training loss = 5.1970  Validation loss = 7.5605  \n",
      "\n",
      "Fold: 16  Epoch: 436  Training loss = 5.1965  Validation loss = 7.5599  \n",
      "\n",
      "Fold: 16  Epoch: 437  Training loss = 5.1960  Validation loss = 7.5593  \n",
      "\n",
      "Fold: 16  Epoch: 438  Training loss = 5.1953  Validation loss = 7.5587  \n",
      "\n",
      "Fold: 16  Epoch: 439  Training loss = 5.1948  Validation loss = 7.5581  \n",
      "\n",
      "Fold: 16  Epoch: 440  Training loss = 5.1943  Validation loss = 7.5576  \n",
      "\n",
      "Fold: 16  Epoch: 441  Training loss = 5.1939  Validation loss = 7.5571  \n",
      "\n",
      "Fold: 16  Epoch: 442  Training loss = 5.1934  Validation loss = 7.5566  \n",
      "\n",
      "Fold: 16  Epoch: 443  Training loss = 5.1928  Validation loss = 7.5560  \n",
      "\n",
      "Fold: 16  Epoch: 444  Training loss = 5.1923  Validation loss = 7.5554  \n",
      "\n",
      "Fold: 16  Epoch: 445  Training loss = 5.1918  Validation loss = 7.5548  \n",
      "\n",
      "Fold: 16  Epoch: 446  Training loss = 5.1912  Validation loss = 7.5542  \n",
      "\n",
      "Fold: 16  Epoch: 447  Training loss = 5.1906  Validation loss = 7.5536  \n",
      "\n",
      "Fold: 16  Epoch: 448  Training loss = 5.1902  Validation loss = 7.5531  \n",
      "\n",
      "Fold: 16  Epoch: 449  Training loss = 5.1895  Validation loss = 7.5525  \n",
      "\n",
      "Fold: 16  Epoch: 450  Training loss = 5.1889  Validation loss = 7.5518  \n",
      "\n",
      "Fold: 16  Epoch: 451  Training loss = 5.1885  Validation loss = 7.5513  \n",
      "\n",
      "Fold: 16  Epoch: 452  Training loss = 5.1879  Validation loss = 7.5507  \n",
      "\n",
      "Fold: 16  Epoch: 453  Training loss = 5.1874  Validation loss = 7.5501  \n",
      "\n",
      "Fold: 16  Epoch: 454  Training loss = 5.1868  Validation loss = 7.5495  \n",
      "\n",
      "Fold: 16  Epoch: 455  Training loss = 5.1863  Validation loss = 7.5490  \n",
      "\n",
      "Fold: 16  Epoch: 456  Training loss = 5.1858  Validation loss = 7.5484  \n",
      "\n",
      "Fold: 16  Epoch: 457  Training loss = 5.1853  Validation loss = 7.5479  \n",
      "\n",
      "Fold: 16  Epoch: 458  Training loss = 5.1849  Validation loss = 7.5474  \n",
      "\n",
      "Fold: 16  Epoch: 459  Training loss = 5.1843  Validation loss = 7.5468  \n",
      "\n",
      "Fold: 16  Epoch: 460  Training loss = 5.1836  Validation loss = 7.5461  \n",
      "\n",
      "Fold: 16  Epoch: 461  Training loss = 5.1830  Validation loss = 7.5454  \n",
      "\n",
      "Fold: 16  Epoch: 462  Training loss = 5.1824  Validation loss = 7.5448  \n",
      "\n",
      "Fold: 16  Epoch: 463  Training loss = 5.1818  Validation loss = 7.5442  \n",
      "\n",
      "Fold: 16  Epoch: 464  Training loss = 5.1812  Validation loss = 7.5435  \n",
      "\n",
      "Fold: 16  Epoch: 465  Training loss = 5.1808  Validation loss = 7.5430  \n",
      "\n",
      "Fold: 16  Epoch: 466  Training loss = 5.1803  Validation loss = 7.5426  \n",
      "\n",
      "Fold: 16  Epoch: 467  Training loss = 5.1798  Validation loss = 7.5420  \n",
      "\n",
      "Fold: 16  Epoch: 468  Training loss = 5.1793  Validation loss = 7.5414  \n",
      "\n",
      "Fold: 16  Epoch: 469  Training loss = 5.1788  Validation loss = 7.5409  \n",
      "\n",
      "Fold: 16  Epoch: 470  Training loss = 5.1782  Validation loss = 7.5402  \n",
      "\n",
      "Fold: 16  Epoch: 471  Training loss = 5.1777  Validation loss = 7.5398  \n",
      "\n",
      "Fold: 16  Epoch: 472  Training loss = 5.1772  Validation loss = 7.5392  \n",
      "\n",
      "Fold: 16  Epoch: 473  Training loss = 5.1767  Validation loss = 7.5387  \n",
      "\n",
      "Fold: 16  Epoch: 474  Training loss = 5.1761  Validation loss = 7.5380  \n",
      "\n",
      "Fold: 16  Epoch: 475  Training loss = 5.1755  Validation loss = 7.5373  \n",
      "\n",
      "Fold: 16  Epoch: 476  Training loss = 5.1750  Validation loss = 7.5368  \n",
      "\n",
      "Fold: 16  Epoch: 477  Training loss = 5.1744  Validation loss = 7.5362  \n",
      "\n",
      "Fold: 16  Epoch: 478  Training loss = 5.1738  Validation loss = 7.5355  \n",
      "\n",
      "Fold: 16  Epoch: 479  Training loss = 5.1733  Validation loss = 7.5351  \n",
      "\n",
      "Fold: 16  Epoch: 480  Training loss = 5.1728  Validation loss = 7.5344  \n",
      "\n",
      "Fold: 16  Epoch: 481  Training loss = 5.1722  Validation loss = 7.5338  \n",
      "\n",
      "Fold: 16  Epoch: 482  Training loss = 5.1717  Validation loss = 7.5333  \n",
      "\n",
      "Fold: 16  Epoch: 483  Training loss = 5.1712  Validation loss = 7.5328  \n",
      "\n",
      "Fold: 16  Epoch: 484  Training loss = 5.1707  Validation loss = 7.5322  \n",
      "\n",
      "Fold: 16  Epoch: 485  Training loss = 5.1702  Validation loss = 7.5317  \n",
      "\n",
      "Fold: 16  Epoch: 486  Training loss = 5.1697  Validation loss = 7.5311  \n",
      "\n",
      "Fold: 16  Epoch: 487  Training loss = 5.1691  Validation loss = 7.5305  \n",
      "\n",
      "Fold: 16  Epoch: 488  Training loss = 5.1686  Validation loss = 7.5299  \n",
      "\n",
      "Fold: 16  Epoch: 489  Training loss = 5.1680  Validation loss = 7.5293  \n",
      "\n",
      "Fold: 16  Epoch: 490  Training loss = 5.1675  Validation loss = 7.5288  \n",
      "\n",
      "Fold: 16  Epoch: 491  Training loss = 5.1670  Validation loss = 7.5283  \n",
      "\n",
      "Fold: 16  Epoch: 492  Training loss = 5.1664  Validation loss = 7.5276  \n",
      "\n",
      "Fold: 16  Epoch: 493  Training loss = 5.1660  Validation loss = 7.5271  \n",
      "\n",
      "Fold: 16  Epoch: 494  Training loss = 5.1654  Validation loss = 7.5265  \n",
      "\n",
      "Fold: 16  Epoch: 495  Training loss = 5.1648  Validation loss = 7.5259  \n",
      "\n",
      "Fold: 16  Epoch: 496  Training loss = 5.1643  Validation loss = 7.5253  \n",
      "\n",
      "Fold: 16  Epoch: 497  Training loss = 5.1637  Validation loss = 7.5247  \n",
      "\n",
      "Fold: 16  Epoch: 498  Training loss = 5.1632  Validation loss = 7.5242  \n",
      "\n",
      "Fold: 16  Epoch: 499  Training loss = 5.1626  Validation loss = 7.5235  \n",
      "\n",
      "Fold: 16  Epoch: 500  Training loss = 5.1621  Validation loss = 7.5229  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 500  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 5.4870  Validation loss = 3.4506  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 5.4863  Validation loss = 3.4501  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 5.4856  Validation loss = 3.4496  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 5.4850  Validation loss = 3.4492  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 5.4845  Validation loss = 3.4488  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 5.4838  Validation loss = 3.4483  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 5.4833  Validation loss = 3.4480  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 5.4827  Validation loss = 3.4476  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 5.4821  Validation loss = 3.4471  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 5.4815  Validation loss = 3.4467  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 5.4810  Validation loss = 3.4463  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 5.4803  Validation loss = 3.4458  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 5.4796  Validation loss = 3.4453  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 5.4791  Validation loss = 3.4450  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 5.4785  Validation loss = 3.4445  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 5.4780  Validation loss = 3.4442  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 5.4775  Validation loss = 3.4437  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 5.4768  Validation loss = 3.4433  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 5.4762  Validation loss = 3.4429  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 5.4756  Validation loss = 3.4425  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 5.4749  Validation loss = 3.4420  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 5.4743  Validation loss = 3.4415  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 5.4737  Validation loss = 3.4410  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 5.4729  Validation loss = 3.4404  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 5.4722  Validation loss = 3.4400  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 5.4717  Validation loss = 3.4396  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 5.4710  Validation loss = 3.4392  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 5.4704  Validation loss = 3.4387  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 5.4697  Validation loss = 3.4382  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 5.4690  Validation loss = 3.4377  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 5.4683  Validation loss = 3.4373  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 5.4677  Validation loss = 3.4369  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 5.4671  Validation loss = 3.4365  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 5.4666  Validation loss = 3.4361  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 5.4659  Validation loss = 3.4356  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 5.4654  Validation loss = 3.4352  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 5.4647  Validation loss = 3.4346  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 5.4641  Validation loss = 3.4343  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 5.4635  Validation loss = 3.4339  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 5.4630  Validation loss = 3.4334  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 5.4624  Validation loss = 3.4329  \n",
      "\n",
      "Fold: 17  Epoch: 42  Training loss = 5.4617  Validation loss = 3.4325  \n",
      "\n",
      "Fold: 17  Epoch: 43  Training loss = 5.4611  Validation loss = 3.4321  \n",
      "\n",
      "Fold: 17  Epoch: 44  Training loss = 5.4605  Validation loss = 3.4317  \n",
      "\n",
      "Fold: 17  Epoch: 45  Training loss = 5.4600  Validation loss = 3.4313  \n",
      "\n",
      "Fold: 17  Epoch: 46  Training loss = 5.4594  Validation loss = 3.4310  \n",
      "\n",
      "Fold: 17  Epoch: 47  Training loss = 5.4587  Validation loss = 3.4304  \n",
      "\n",
      "Fold: 17  Epoch: 48  Training loss = 5.4581  Validation loss = 3.4300  \n",
      "\n",
      "Fold: 17  Epoch: 49  Training loss = 5.4576  Validation loss = 3.4296  \n",
      "\n",
      "Fold: 17  Epoch: 50  Training loss = 5.4570  Validation loss = 3.4291  \n",
      "\n",
      "Fold: 17  Epoch: 51  Training loss = 5.4564  Validation loss = 3.4287  \n",
      "\n",
      "Fold: 17  Epoch: 52  Training loss = 5.4558  Validation loss = 3.4282  \n",
      "\n",
      "Fold: 17  Epoch: 53  Training loss = 5.4552  Validation loss = 3.4278  \n",
      "\n",
      "Fold: 17  Epoch: 54  Training loss = 5.4546  Validation loss = 3.4274  \n",
      "\n",
      "Fold: 17  Epoch: 55  Training loss = 5.4540  Validation loss = 3.4269  \n",
      "\n",
      "Fold: 17  Epoch: 56  Training loss = 5.4534  Validation loss = 3.4265  \n",
      "\n",
      "Fold: 17  Epoch: 57  Training loss = 5.4528  Validation loss = 3.4260  \n",
      "\n",
      "Fold: 17  Epoch: 58  Training loss = 5.4521  Validation loss = 3.4255  \n",
      "\n",
      "Fold: 17  Epoch: 59  Training loss = 5.4514  Validation loss = 3.4250  \n",
      "\n",
      "Fold: 17  Epoch: 60  Training loss = 5.4508  Validation loss = 3.4247  \n",
      "\n",
      "Fold: 17  Epoch: 61  Training loss = 5.4502  Validation loss = 3.4242  \n",
      "\n",
      "Fold: 17  Epoch: 62  Training loss = 5.4496  Validation loss = 3.4238  \n",
      "\n",
      "Fold: 17  Epoch: 63  Training loss = 5.4489  Validation loss = 3.4234  \n",
      "\n",
      "Fold: 17  Epoch: 64  Training loss = 5.4483  Validation loss = 3.4230  \n",
      "\n",
      "Fold: 17  Epoch: 65  Training loss = 5.4477  Validation loss = 3.4226  \n",
      "\n",
      "Fold: 17  Epoch: 66  Training loss = 5.4470  Validation loss = 3.4221  \n",
      "\n",
      "Fold: 17  Epoch: 67  Training loss = 5.4465  Validation loss = 3.4217  \n",
      "\n",
      "Fold: 17  Epoch: 68  Training loss = 5.4459  Validation loss = 3.4211  \n",
      "\n",
      "Fold: 17  Epoch: 69  Training loss = 5.4453  Validation loss = 3.4207  \n",
      "\n",
      "Fold: 17  Epoch: 70  Training loss = 5.4446  Validation loss = 3.4202  \n",
      "\n",
      "Fold: 17  Epoch: 71  Training loss = 5.4440  Validation loss = 3.4198  \n",
      "\n",
      "Fold: 17  Epoch: 72  Training loss = 5.4434  Validation loss = 3.4194  \n",
      "\n",
      "Fold: 17  Epoch: 73  Training loss = 5.4429  Validation loss = 3.4190  \n",
      "\n",
      "Fold: 17  Epoch: 74  Training loss = 5.4424  Validation loss = 3.4187  \n",
      "\n",
      "Fold: 17  Epoch: 75  Training loss = 5.4418  Validation loss = 3.4183  \n",
      "\n",
      "Fold: 17  Epoch: 76  Training loss = 5.4412  Validation loss = 3.4180  \n",
      "\n",
      "Fold: 17  Epoch: 77  Training loss = 5.4406  Validation loss = 3.4176  \n",
      "\n",
      "Fold: 17  Epoch: 78  Training loss = 5.4400  Validation loss = 3.4171  \n",
      "\n",
      "Fold: 17  Epoch: 79  Training loss = 5.4394  Validation loss = 3.4165  \n",
      "\n",
      "Fold: 17  Epoch: 80  Training loss = 5.4388  Validation loss = 3.4161  \n",
      "\n",
      "Fold: 17  Epoch: 81  Training loss = 5.4381  Validation loss = 3.4156  \n",
      "\n",
      "Fold: 17  Epoch: 82  Training loss = 5.4375  Validation loss = 3.4152  \n",
      "\n",
      "Fold: 17  Epoch: 83  Training loss = 5.4369  Validation loss = 3.4148  \n",
      "\n",
      "Fold: 17  Epoch: 84  Training loss = 5.4363  Validation loss = 3.4143  \n",
      "\n",
      "Fold: 17  Epoch: 85  Training loss = 5.4358  Validation loss = 3.4140  \n",
      "\n",
      "Fold: 17  Epoch: 86  Training loss = 5.4351  Validation loss = 3.4136  \n",
      "\n",
      "Fold: 17  Epoch: 87  Training loss = 5.4345  Validation loss = 3.4132  \n",
      "\n",
      "Fold: 17  Epoch: 88  Training loss = 5.4339  Validation loss = 3.4128  \n",
      "\n",
      "Fold: 17  Epoch: 89  Training loss = 5.4332  Validation loss = 3.4123  \n",
      "\n",
      "Fold: 17  Epoch: 90  Training loss = 5.4326  Validation loss = 3.4119  \n",
      "\n",
      "Fold: 17  Epoch: 91  Training loss = 5.4320  Validation loss = 3.4115  \n",
      "\n",
      "Fold: 17  Epoch: 92  Training loss = 5.4314  Validation loss = 3.4110  \n",
      "\n",
      "Fold: 17  Epoch: 93  Training loss = 5.4307  Validation loss = 3.4105  \n",
      "\n",
      "Fold: 17  Epoch: 94  Training loss = 5.4301  Validation loss = 3.4101  \n",
      "\n",
      "Fold: 17  Epoch: 95  Training loss = 5.4295  Validation loss = 3.4096  \n",
      "\n",
      "Fold: 17  Epoch: 96  Training loss = 5.4289  Validation loss = 3.4093  \n",
      "\n",
      "Fold: 17  Epoch: 97  Training loss = 5.4283  Validation loss = 3.4089  \n",
      "\n",
      "Fold: 17  Epoch: 98  Training loss = 5.4276  Validation loss = 3.4084  \n",
      "\n",
      "Fold: 17  Epoch: 99  Training loss = 5.4271  Validation loss = 3.4080  \n",
      "\n",
      "Fold: 17  Epoch: 100  Training loss = 5.4264  Validation loss = 3.4075  \n",
      "\n",
      "Fold: 17  Epoch: 101  Training loss = 5.4258  Validation loss = 3.4070  \n",
      "\n",
      "Fold: 17  Epoch: 102  Training loss = 5.4252  Validation loss = 3.4066  \n",
      "\n",
      "Fold: 17  Epoch: 103  Training loss = 5.4245  Validation loss = 3.4060  \n",
      "\n",
      "Fold: 17  Epoch: 104  Training loss = 5.4239  Validation loss = 3.4055  \n",
      "\n",
      "Fold: 17  Epoch: 105  Training loss = 5.4234  Validation loss = 3.4051  \n",
      "\n",
      "Fold: 17  Epoch: 106  Training loss = 5.4227  Validation loss = 3.4046  \n",
      "\n",
      "Fold: 17  Epoch: 107  Training loss = 5.4221  Validation loss = 3.4042  \n",
      "\n",
      "Fold: 17  Epoch: 108  Training loss = 5.4216  Validation loss = 3.4039  \n",
      "\n",
      "Fold: 17  Epoch: 109  Training loss = 5.4209  Validation loss = 3.4034  \n",
      "\n",
      "Fold: 17  Epoch: 110  Training loss = 5.4203  Validation loss = 3.4030  \n",
      "\n",
      "Fold: 17  Epoch: 111  Training loss = 5.4197  Validation loss = 3.4027  \n",
      "\n",
      "Fold: 17  Epoch: 112  Training loss = 5.4191  Validation loss = 3.4023  \n",
      "\n",
      "Fold: 17  Epoch: 113  Training loss = 5.4185  Validation loss = 3.4019  \n",
      "\n",
      "Fold: 17  Epoch: 114  Training loss = 5.4179  Validation loss = 3.4015  \n",
      "\n",
      "Fold: 17  Epoch: 115  Training loss = 5.4173  Validation loss = 3.4010  \n",
      "\n",
      "Fold: 17  Epoch: 116  Training loss = 5.4166  Validation loss = 3.4006  \n",
      "\n",
      "Fold: 17  Epoch: 117  Training loss = 5.4160  Validation loss = 3.4001  \n",
      "\n",
      "Fold: 17  Epoch: 118  Training loss = 5.4153  Validation loss = 3.3997  \n",
      "\n",
      "Fold: 17  Epoch: 119  Training loss = 5.4147  Validation loss = 3.3993  \n",
      "\n",
      "Fold: 17  Epoch: 120  Training loss = 5.4141  Validation loss = 3.3990  \n",
      "\n",
      "Fold: 17  Epoch: 121  Training loss = 5.4134  Validation loss = 3.3985  \n",
      "\n",
      "Fold: 17  Epoch: 122  Training loss = 5.4128  Validation loss = 3.3981  \n",
      "\n",
      "Fold: 17  Epoch: 123  Training loss = 5.4123  Validation loss = 3.3977  \n",
      "\n",
      "Fold: 17  Epoch: 124  Training loss = 5.4117  Validation loss = 3.3973  \n",
      "\n",
      "Fold: 17  Epoch: 125  Training loss = 5.4111  Validation loss = 3.3968  \n",
      "\n",
      "Fold: 17  Epoch: 126  Training loss = 5.4104  Validation loss = 3.3963  \n",
      "\n",
      "Fold: 17  Epoch: 127  Training loss = 5.4099  Validation loss = 3.3960  \n",
      "\n",
      "Fold: 17  Epoch: 128  Training loss = 5.4093  Validation loss = 3.3956  \n",
      "\n",
      "Fold: 17  Epoch: 129  Training loss = 5.4087  Validation loss = 3.3952  \n",
      "\n",
      "Fold: 17  Epoch: 130  Training loss = 5.4081  Validation loss = 3.3948  \n",
      "\n",
      "Fold: 17  Epoch: 131  Training loss = 5.4074  Validation loss = 3.3942  \n",
      "\n",
      "Fold: 17  Epoch: 132  Training loss = 5.4067  Validation loss = 3.3938  \n",
      "\n",
      "Fold: 17  Epoch: 133  Training loss = 5.4062  Validation loss = 3.3934  \n",
      "\n",
      "Fold: 17  Epoch: 134  Training loss = 5.4055  Validation loss = 3.3929  \n",
      "\n",
      "Fold: 17  Epoch: 135  Training loss = 5.4049  Validation loss = 3.3925  \n",
      "\n",
      "Fold: 17  Epoch: 136  Training loss = 5.4043  Validation loss = 3.3921  \n",
      "\n",
      "Fold: 17  Epoch: 137  Training loss = 5.4038  Validation loss = 3.3918  \n",
      "\n",
      "Fold: 17  Epoch: 138  Training loss = 5.4032  Validation loss = 3.3914  \n",
      "\n",
      "Fold: 17  Epoch: 139  Training loss = 5.4026  Validation loss = 3.3909  \n",
      "\n",
      "Fold: 17  Epoch: 140  Training loss = 5.4020  Validation loss = 3.3906  \n",
      "\n",
      "Fold: 17  Epoch: 141  Training loss = 5.4014  Validation loss = 3.3901  \n",
      "\n",
      "Fold: 17  Epoch: 142  Training loss = 5.4008  Validation loss = 3.3896  \n",
      "\n",
      "Fold: 17  Epoch: 143  Training loss = 5.4002  Validation loss = 3.3892  \n",
      "\n",
      "Fold: 17  Epoch: 144  Training loss = 5.3995  Validation loss = 3.3886  \n",
      "\n",
      "Fold: 17  Epoch: 145  Training loss = 5.3989  Validation loss = 3.3883  \n",
      "\n",
      "Fold: 17  Epoch: 146  Training loss = 5.3984  Validation loss = 3.3879  \n",
      "\n",
      "Fold: 17  Epoch: 147  Training loss = 5.3978  Validation loss = 3.3875  \n",
      "\n",
      "Fold: 17  Epoch: 148  Training loss = 5.3973  Validation loss = 3.3871  \n",
      "\n",
      "Fold: 17  Epoch: 149  Training loss = 5.3965  Validation loss = 3.3866  \n",
      "\n",
      "Fold: 17  Epoch: 150  Training loss = 5.3959  Validation loss = 3.3862  \n",
      "\n",
      "Fold: 17  Epoch: 151  Training loss = 5.3954  Validation loss = 3.3857  \n",
      "\n",
      "Fold: 17  Epoch: 152  Training loss = 5.3947  Validation loss = 3.3853  \n",
      "\n",
      "Fold: 17  Epoch: 153  Training loss = 5.3941  Validation loss = 3.3850  \n",
      "\n",
      "Fold: 17  Epoch: 154  Training loss = 5.3935  Validation loss = 3.3844  \n",
      "\n",
      "Fold: 17  Epoch: 155  Training loss = 5.3929  Validation loss = 3.3840  \n",
      "\n",
      "Fold: 17  Epoch: 156  Training loss = 5.3922  Validation loss = 3.3835  \n",
      "\n",
      "Fold: 17  Epoch: 157  Training loss = 5.3916  Validation loss = 3.3831  \n",
      "\n",
      "Fold: 17  Epoch: 158  Training loss = 5.3910  Validation loss = 3.3827  \n",
      "\n",
      "Fold: 17  Epoch: 159  Training loss = 5.3904  Validation loss = 3.3823  \n",
      "\n",
      "Fold: 17  Epoch: 160  Training loss = 5.3899  Validation loss = 3.3819  \n",
      "\n",
      "Fold: 17  Epoch: 161  Training loss = 5.3894  Validation loss = 3.3815  \n",
      "\n",
      "Fold: 17  Epoch: 162  Training loss = 5.3888  Validation loss = 3.3811  \n",
      "\n",
      "Fold: 17  Epoch: 163  Training loss = 5.3881  Validation loss = 3.3806  \n",
      "\n",
      "Fold: 17  Epoch: 164  Training loss = 5.3874  Validation loss = 3.3802  \n",
      "\n",
      "Fold: 17  Epoch: 165  Training loss = 5.3870  Validation loss = 3.3798  \n",
      "\n",
      "Fold: 17  Epoch: 166  Training loss = 5.3863  Validation loss = 3.3793  \n",
      "\n",
      "Fold: 17  Epoch: 167  Training loss = 5.3857  Validation loss = 3.3790  \n",
      "\n",
      "Fold: 17  Epoch: 168  Training loss = 5.3850  Validation loss = 3.3784  \n",
      "\n",
      "Fold: 17  Epoch: 169  Training loss = 5.3844  Validation loss = 3.3781  \n",
      "\n",
      "Fold: 17  Epoch: 170  Training loss = 5.3837  Validation loss = 3.3776  \n",
      "\n",
      "Fold: 17  Epoch: 171  Training loss = 5.3831  Validation loss = 3.3772  \n",
      "\n",
      "Fold: 17  Epoch: 172  Training loss = 5.3826  Validation loss = 3.3767  \n",
      "\n",
      "Fold: 17  Epoch: 173  Training loss = 5.3820  Validation loss = 3.3762  \n",
      "\n",
      "Fold: 17  Epoch: 174  Training loss = 5.3814  Validation loss = 3.3758  \n",
      "\n",
      "Fold: 17  Epoch: 175  Training loss = 5.3808  Validation loss = 3.3754  \n",
      "\n",
      "Fold: 17  Epoch: 176  Training loss = 5.3803  Validation loss = 3.3751  \n",
      "\n",
      "Fold: 17  Epoch: 177  Training loss = 5.3797  Validation loss = 3.3747  \n",
      "\n",
      "Fold: 17  Epoch: 178  Training loss = 5.3791  Validation loss = 3.3743  \n",
      "\n",
      "Fold: 17  Epoch: 179  Training loss = 5.3785  Validation loss = 3.3739  \n",
      "\n",
      "Fold: 17  Epoch: 180  Training loss = 5.3779  Validation loss = 3.3735  \n",
      "\n",
      "Fold: 17  Epoch: 181  Training loss = 5.3773  Validation loss = 3.3731  \n",
      "\n",
      "Fold: 17  Epoch: 182  Training loss = 5.3767  Validation loss = 3.3728  \n",
      "\n",
      "Fold: 17  Epoch: 183  Training loss = 5.3761  Validation loss = 3.3724  \n",
      "\n",
      "Fold: 17  Epoch: 184  Training loss = 5.3754  Validation loss = 3.3720  \n",
      "\n",
      "Fold: 17  Epoch: 185  Training loss = 5.3748  Validation loss = 3.3717  \n",
      "\n",
      "Fold: 17  Epoch: 186  Training loss = 5.3743  Validation loss = 3.3713  \n",
      "\n",
      "Fold: 17  Epoch: 187  Training loss = 5.3737  Validation loss = 3.3709  \n",
      "\n",
      "Fold: 17  Epoch: 188  Training loss = 5.3731  Validation loss = 3.3704  \n",
      "\n",
      "Fold: 17  Epoch: 189  Training loss = 5.3724  Validation loss = 3.3699  \n",
      "\n",
      "Fold: 17  Epoch: 190  Training loss = 5.3719  Validation loss = 3.3695  \n",
      "\n",
      "Fold: 17  Epoch: 191  Training loss = 5.3713  Validation loss = 3.3691  \n",
      "\n",
      "Fold: 17  Epoch: 192  Training loss = 5.3705  Validation loss = 3.3685  \n",
      "\n",
      "Fold: 17  Epoch: 193  Training loss = 5.3700  Validation loss = 3.3682  \n",
      "\n",
      "Fold: 17  Epoch: 194  Training loss = 5.3694  Validation loss = 3.3678  \n",
      "\n",
      "Fold: 17  Epoch: 195  Training loss = 5.3688  Validation loss = 3.3674  \n",
      "\n",
      "Fold: 17  Epoch: 196  Training loss = 5.3682  Validation loss = 3.3670  \n",
      "\n",
      "Fold: 17  Epoch: 197  Training loss = 5.3677  Validation loss = 3.3667  \n",
      "\n",
      "Fold: 17  Epoch: 198  Training loss = 5.3672  Validation loss = 3.3662  \n",
      "\n",
      "Fold: 17  Epoch: 199  Training loss = 5.3666  Validation loss = 3.3659  \n",
      "\n",
      "Fold: 17  Epoch: 200  Training loss = 5.3661  Validation loss = 3.3655  \n",
      "\n",
      "Fold: 17  Epoch: 201  Training loss = 5.3655  Validation loss = 3.3651  \n",
      "\n",
      "Fold: 17  Epoch: 202  Training loss = 5.3648  Validation loss = 3.3647  \n",
      "\n",
      "Fold: 17  Epoch: 203  Training loss = 5.3642  Validation loss = 3.3643  \n",
      "\n",
      "Fold: 17  Epoch: 204  Training loss = 5.3637  Validation loss = 3.3639  \n",
      "\n",
      "Fold: 17  Epoch: 205  Training loss = 5.3631  Validation loss = 3.3634  \n",
      "\n",
      "Fold: 17  Epoch: 206  Training loss = 5.3626  Validation loss = 3.3631  \n",
      "\n",
      "Fold: 17  Epoch: 207  Training loss = 5.3620  Validation loss = 3.3627  \n",
      "\n",
      "Fold: 17  Epoch: 208  Training loss = 5.3614  Validation loss = 3.3622  \n",
      "\n",
      "Fold: 17  Epoch: 209  Training loss = 5.3607  Validation loss = 3.3618  \n",
      "\n",
      "Fold: 17  Epoch: 210  Training loss = 5.3601  Validation loss = 3.3613  \n",
      "\n",
      "Fold: 17  Epoch: 211  Training loss = 5.3593  Validation loss = 3.3608  \n",
      "\n",
      "Fold: 17  Epoch: 212  Training loss = 5.3587  Validation loss = 3.3604  \n",
      "\n",
      "Fold: 17  Epoch: 213  Training loss = 5.3581  Validation loss = 3.3600  \n",
      "\n",
      "Fold: 17  Epoch: 214  Training loss = 5.3576  Validation loss = 3.3596  \n",
      "\n",
      "Fold: 17  Epoch: 215  Training loss = 5.3571  Validation loss = 3.3593  \n",
      "\n",
      "Fold: 17  Epoch: 216  Training loss = 5.3565  Validation loss = 3.3588  \n",
      "\n",
      "Fold: 17  Epoch: 217  Training loss = 5.3559  Validation loss = 3.3585  \n",
      "\n",
      "Fold: 17  Epoch: 218  Training loss = 5.3553  Validation loss = 3.3581  \n",
      "\n",
      "Fold: 17  Epoch: 219  Training loss = 5.3548  Validation loss = 3.3577  \n",
      "\n",
      "Fold: 17  Epoch: 220  Training loss = 5.3543  Validation loss = 3.3574  \n",
      "\n",
      "Fold: 17  Epoch: 221  Training loss = 5.3538  Validation loss = 3.3571  \n",
      "\n",
      "Fold: 17  Epoch: 222  Training loss = 5.3533  Validation loss = 3.3567  \n",
      "\n",
      "Fold: 17  Epoch: 223  Training loss = 5.3526  Validation loss = 3.3563  \n",
      "\n",
      "Fold: 17  Epoch: 224  Training loss = 5.3519  Validation loss = 3.3558  \n",
      "\n",
      "Fold: 17  Epoch: 225  Training loss = 5.3513  Validation loss = 3.3554  \n",
      "\n",
      "Fold: 17  Epoch: 226  Training loss = 5.3506  Validation loss = 3.3549  \n",
      "\n",
      "Fold: 17  Epoch: 227  Training loss = 5.3500  Validation loss = 3.3543  \n",
      "\n",
      "Fold: 17  Epoch: 228  Training loss = 5.3494  Validation loss = 3.3539  \n",
      "\n",
      "Fold: 17  Epoch: 229  Training loss = 5.3489  Validation loss = 3.3535  \n",
      "\n",
      "Fold: 17  Epoch: 230  Training loss = 5.3483  Validation loss = 3.3532  \n",
      "\n",
      "Fold: 17  Epoch: 231  Training loss = 5.3477  Validation loss = 3.3527  \n",
      "\n",
      "Fold: 17  Epoch: 232  Training loss = 5.3471  Validation loss = 3.3523  \n",
      "\n",
      "Fold: 17  Epoch: 233  Training loss = 5.3465  Validation loss = 3.3519  \n",
      "\n",
      "Fold: 17  Epoch: 234  Training loss = 5.3458  Validation loss = 3.3514  \n",
      "\n",
      "Fold: 17  Epoch: 235  Training loss = 5.3452  Validation loss = 3.3511  \n",
      "\n",
      "Fold: 17  Epoch: 236  Training loss = 5.3445  Validation loss = 3.3505  \n",
      "\n",
      "Fold: 17  Epoch: 237  Training loss = 5.3438  Validation loss = 3.3499  \n",
      "\n",
      "Fold: 17  Epoch: 238  Training loss = 5.3431  Validation loss = 3.3494  \n",
      "\n",
      "Fold: 17  Epoch: 239  Training loss = 5.3425  Validation loss = 3.3489  \n",
      "\n",
      "Fold: 17  Epoch: 240  Training loss = 5.3419  Validation loss = 3.3485  \n",
      "\n",
      "Fold: 17  Epoch: 241  Training loss = 5.3414  Validation loss = 3.3481  \n",
      "\n",
      "Fold: 17  Epoch: 242  Training loss = 5.3407  Validation loss = 3.3476  \n",
      "\n",
      "Fold: 17  Epoch: 243  Training loss = 5.3402  Validation loss = 3.3473  \n",
      "\n",
      "Fold: 17  Epoch: 244  Training loss = 5.3396  Validation loss = 3.3468  \n",
      "\n",
      "Fold: 17  Epoch: 245  Training loss = 5.3391  Validation loss = 3.3464  \n",
      "\n",
      "Fold: 17  Epoch: 246  Training loss = 5.3385  Validation loss = 3.3460  \n",
      "\n",
      "Fold: 17  Epoch: 247  Training loss = 5.3379  Validation loss = 3.3457  \n",
      "\n",
      "Fold: 17  Epoch: 248  Training loss = 5.3372  Validation loss = 3.3453  \n",
      "\n",
      "Fold: 17  Epoch: 249  Training loss = 5.3366  Validation loss = 3.3448  \n",
      "\n",
      "Fold: 17  Epoch: 250  Training loss = 5.3360  Validation loss = 3.3444  \n",
      "\n",
      "Fold: 17  Epoch: 251  Training loss = 5.3353  Validation loss = 3.3439  \n",
      "\n",
      "Fold: 17  Epoch: 252  Training loss = 5.3348  Validation loss = 3.3435  \n",
      "\n",
      "Fold: 17  Epoch: 253  Training loss = 5.3342  Validation loss = 3.3431  \n",
      "\n",
      "Fold: 17  Epoch: 254  Training loss = 5.3335  Validation loss = 3.3427  \n",
      "\n",
      "Fold: 17  Epoch: 255  Training loss = 5.3329  Validation loss = 3.3422  \n",
      "\n",
      "Fold: 17  Epoch: 256  Training loss = 5.3324  Validation loss = 3.3419  \n",
      "\n",
      "Fold: 17  Epoch: 257  Training loss = 5.3318  Validation loss = 3.3416  \n",
      "\n",
      "Fold: 17  Epoch: 258  Training loss = 5.3311  Validation loss = 3.3411  \n",
      "\n",
      "Fold: 17  Epoch: 259  Training loss = 5.3305  Validation loss = 3.3406  \n",
      "\n",
      "Fold: 17  Epoch: 260  Training loss = 5.3299  Validation loss = 3.3403  \n",
      "\n",
      "Fold: 17  Epoch: 261  Training loss = 5.3293  Validation loss = 3.3398  \n",
      "\n",
      "Fold: 17  Epoch: 262  Training loss = 5.3287  Validation loss = 3.3395  \n",
      "\n",
      "Fold: 17  Epoch: 263  Training loss = 5.3281  Validation loss = 3.3390  \n",
      "\n",
      "Fold: 17  Epoch: 264  Training loss = 5.3275  Validation loss = 3.3386  \n",
      "\n",
      "Fold: 17  Epoch: 265  Training loss = 5.3268  Validation loss = 3.3382  \n",
      "\n",
      "Fold: 17  Epoch: 266  Training loss = 5.3263  Validation loss = 3.3377  \n",
      "\n",
      "Fold: 17  Epoch: 267  Training loss = 5.3257  Validation loss = 3.3374  \n",
      "\n",
      "Fold: 17  Epoch: 268  Training loss = 5.3251  Validation loss = 3.3370  \n",
      "\n",
      "Fold: 17  Epoch: 269  Training loss = 5.3244  Validation loss = 3.3366  \n",
      "\n",
      "Fold: 17  Epoch: 270  Training loss = 5.3239  Validation loss = 3.3363  \n",
      "\n",
      "Fold: 17  Epoch: 271  Training loss = 5.3233  Validation loss = 3.3359  \n",
      "\n",
      "Fold: 17  Epoch: 272  Training loss = 5.3227  Validation loss = 3.3356  \n",
      "\n",
      "Fold: 17  Epoch: 273  Training loss = 5.3221  Validation loss = 3.3351  \n",
      "\n",
      "Fold: 17  Epoch: 274  Training loss = 5.3215  Validation loss = 3.3347  \n",
      "\n",
      "Fold: 17  Epoch: 275  Training loss = 5.3209  Validation loss = 3.3343  \n",
      "\n",
      "Fold: 17  Epoch: 276  Training loss = 5.3203  Validation loss = 3.3339  \n",
      "\n",
      "Fold: 17  Epoch: 277  Training loss = 5.3197  Validation loss = 3.3335  \n",
      "\n",
      "Fold: 17  Epoch: 278  Training loss = 5.3193  Validation loss = 3.3332  \n",
      "\n",
      "Fold: 17  Epoch: 279  Training loss = 5.3187  Validation loss = 3.3328  \n",
      "\n",
      "Fold: 17  Epoch: 280  Training loss = 5.3182  Validation loss = 3.3324  \n",
      "\n",
      "Fold: 17  Epoch: 281  Training loss = 5.3175  Validation loss = 3.3320  \n",
      "\n",
      "Fold: 17  Epoch: 282  Training loss = 5.3171  Validation loss = 3.3317  \n",
      "\n",
      "Fold: 17  Epoch: 283  Training loss = 5.3165  Validation loss = 3.3314  \n",
      "\n",
      "Fold: 17  Epoch: 284  Training loss = 5.3159  Validation loss = 3.3309  \n",
      "\n",
      "Fold: 17  Epoch: 285  Training loss = 5.3153  Validation loss = 3.3305  \n",
      "\n",
      "Fold: 17  Epoch: 286  Training loss = 5.3147  Validation loss = 3.3302  \n",
      "\n",
      "Fold: 17  Epoch: 287  Training loss = 5.3141  Validation loss = 3.3298  \n",
      "\n",
      "Fold: 17  Epoch: 288  Training loss = 5.3136  Validation loss = 3.3294  \n",
      "\n",
      "Fold: 17  Epoch: 289  Training loss = 5.3130  Validation loss = 3.3291  \n",
      "\n",
      "Fold: 17  Epoch: 290  Training loss = 5.3125  Validation loss = 3.3286  \n",
      "\n",
      "Fold: 17  Epoch: 291  Training loss = 5.3117  Validation loss = 3.3282  \n",
      "\n",
      "Fold: 17  Epoch: 292  Training loss = 5.3112  Validation loss = 3.3278  \n",
      "\n",
      "Fold: 17  Epoch: 293  Training loss = 5.3106  Validation loss = 3.3274  \n",
      "\n",
      "Fold: 17  Epoch: 294  Training loss = 5.3100  Validation loss = 3.3269  \n",
      "\n",
      "Fold: 17  Epoch: 295  Training loss = 5.3094  Validation loss = 3.3265  \n",
      "\n",
      "Fold: 17  Epoch: 296  Training loss = 5.3089  Validation loss = 3.3261  \n",
      "\n",
      "Fold: 17  Epoch: 297  Training loss = 5.3082  Validation loss = 3.3257  \n",
      "\n",
      "Fold: 17  Epoch: 298  Training loss = 5.3076  Validation loss = 3.3253  \n",
      "\n",
      "Fold: 17  Epoch: 299  Training loss = 5.3071  Validation loss = 3.3249  \n",
      "\n",
      "Fold: 17  Epoch: 300  Training loss = 5.3066  Validation loss = 3.3245  \n",
      "\n",
      "Fold: 17  Epoch: 301  Training loss = 5.3057  Validation loss = 3.3240  \n",
      "\n",
      "Fold: 17  Epoch: 302  Training loss = 5.3052  Validation loss = 3.3236  \n",
      "\n",
      "Fold: 17  Epoch: 303  Training loss = 5.3047  Validation loss = 3.3233  \n",
      "\n",
      "Fold: 17  Epoch: 304  Training loss = 5.3041  Validation loss = 3.3229  \n",
      "\n",
      "Fold: 17  Epoch: 305  Training loss = 5.3035  Validation loss = 3.3226  \n",
      "\n",
      "Fold: 17  Epoch: 306  Training loss = 5.3029  Validation loss = 3.3222  \n",
      "\n",
      "Fold: 17  Epoch: 307  Training loss = 5.3024  Validation loss = 3.3217  \n",
      "\n",
      "Fold: 17  Epoch: 308  Training loss = 5.3018  Validation loss = 3.3214  \n",
      "\n",
      "Fold: 17  Epoch: 309  Training loss = 5.3011  Validation loss = 3.3209  \n",
      "\n",
      "Fold: 17  Epoch: 310  Training loss = 5.3005  Validation loss = 3.3205  \n",
      "\n",
      "Fold: 17  Epoch: 311  Training loss = 5.2998  Validation loss = 3.3201  \n",
      "\n",
      "Fold: 17  Epoch: 312  Training loss = 5.2993  Validation loss = 3.3197  \n",
      "\n",
      "Fold: 17  Epoch: 313  Training loss = 5.2988  Validation loss = 3.3194  \n",
      "\n",
      "Fold: 17  Epoch: 314  Training loss = 5.2982  Validation loss = 3.3190  \n",
      "\n",
      "Fold: 17  Epoch: 315  Training loss = 5.2977  Validation loss = 3.3186  \n",
      "\n",
      "Fold: 17  Epoch: 316  Training loss = 5.2970  Validation loss = 3.3182  \n",
      "\n",
      "Fold: 17  Epoch: 317  Training loss = 5.2964  Validation loss = 3.3177  \n",
      "\n",
      "Fold: 17  Epoch: 318  Training loss = 5.2958  Validation loss = 3.3173  \n",
      "\n",
      "Fold: 17  Epoch: 319  Training loss = 5.2951  Validation loss = 3.3168  \n",
      "\n",
      "Fold: 17  Epoch: 320  Training loss = 5.2945  Validation loss = 3.3163  \n",
      "\n",
      "Fold: 17  Epoch: 321  Training loss = 5.2940  Validation loss = 3.3159  \n",
      "\n",
      "Fold: 17  Epoch: 322  Training loss = 5.2933  Validation loss = 3.3155  \n",
      "\n",
      "Fold: 17  Epoch: 323  Training loss = 5.2928  Validation loss = 3.3151  \n",
      "\n",
      "Fold: 17  Epoch: 324  Training loss = 5.2922  Validation loss = 3.3147  \n",
      "\n",
      "Fold: 17  Epoch: 325  Training loss = 5.2916  Validation loss = 3.3143  \n",
      "\n",
      "Fold: 17  Epoch: 326  Training loss = 5.2911  Validation loss = 3.3139  \n",
      "\n",
      "Fold: 17  Epoch: 327  Training loss = 5.2904  Validation loss = 3.3135  \n",
      "\n",
      "Fold: 17  Epoch: 328  Training loss = 5.2900  Validation loss = 3.3132  \n",
      "\n",
      "Fold: 17  Epoch: 329  Training loss = 5.2894  Validation loss = 3.3128  \n",
      "\n",
      "Fold: 17  Epoch: 330  Training loss = 5.2888  Validation loss = 3.3124  \n",
      "\n",
      "Fold: 17  Epoch: 331  Training loss = 5.2882  Validation loss = 3.3120  \n",
      "\n",
      "Fold: 17  Epoch: 332  Training loss = 5.2875  Validation loss = 3.3116  \n",
      "\n",
      "Fold: 17  Epoch: 333  Training loss = 5.2870  Validation loss = 3.3112  \n",
      "\n",
      "Fold: 17  Epoch: 334  Training loss = 5.2864  Validation loss = 3.3108  \n",
      "\n",
      "Fold: 17  Epoch: 335  Training loss = 5.2857  Validation loss = 3.3103  \n",
      "\n",
      "Fold: 17  Epoch: 336  Training loss = 5.2852  Validation loss = 3.3099  \n",
      "\n",
      "Fold: 17  Epoch: 337  Training loss = 5.2846  Validation loss = 3.3094  \n",
      "\n",
      "Fold: 17  Epoch: 338  Training loss = 5.2840  Validation loss = 3.3090  \n",
      "\n",
      "Fold: 17  Epoch: 339  Training loss = 5.2834  Validation loss = 3.3087  \n",
      "\n",
      "Fold: 17  Epoch: 340  Training loss = 5.2829  Validation loss = 3.3084  \n",
      "\n",
      "Fold: 17  Epoch: 341  Training loss = 5.2822  Validation loss = 3.3080  \n",
      "\n",
      "Fold: 17  Epoch: 342  Training loss = 5.2816  Validation loss = 3.3076  \n",
      "\n",
      "Fold: 17  Epoch: 343  Training loss = 5.2811  Validation loss = 3.3072  \n",
      "\n",
      "Fold: 17  Epoch: 344  Training loss = 5.2806  Validation loss = 3.3069  \n",
      "\n",
      "Fold: 17  Epoch: 345  Training loss = 5.2801  Validation loss = 3.3066  \n",
      "\n",
      "Fold: 17  Epoch: 346  Training loss = 5.2796  Validation loss = 3.3063  \n",
      "\n",
      "Fold: 17  Epoch: 347  Training loss = 5.2790  Validation loss = 3.3058  \n",
      "\n",
      "Fold: 17  Epoch: 348  Training loss = 5.2785  Validation loss = 3.3055  \n",
      "\n",
      "Fold: 17  Epoch: 349  Training loss = 5.2780  Validation loss = 3.3051  \n",
      "\n",
      "Fold: 17  Epoch: 350  Training loss = 5.2774  Validation loss = 3.3047  \n",
      "\n",
      "Fold: 17  Epoch: 351  Training loss = 5.2768  Validation loss = 3.3043  \n",
      "\n",
      "Fold: 17  Epoch: 352  Training loss = 5.2762  Validation loss = 3.3039  \n",
      "\n",
      "Fold: 17  Epoch: 353  Training loss = 5.2755  Validation loss = 3.3034  \n",
      "\n",
      "Fold: 17  Epoch: 354  Training loss = 5.2749  Validation loss = 3.3030  \n",
      "\n",
      "Fold: 17  Epoch: 355  Training loss = 5.2743  Validation loss = 3.3026  \n",
      "\n",
      "Fold: 17  Epoch: 356  Training loss = 5.2737  Validation loss = 3.3021  \n",
      "\n",
      "Fold: 17  Epoch: 357  Training loss = 5.2732  Validation loss = 3.3018  \n",
      "\n",
      "Fold: 17  Epoch: 358  Training loss = 5.2726  Validation loss = 3.3014  \n",
      "\n",
      "Fold: 17  Epoch: 359  Training loss = 5.2721  Validation loss = 3.3010  \n",
      "\n",
      "Fold: 17  Epoch: 360  Training loss = 5.2714  Validation loss = 3.3006  \n",
      "\n",
      "Fold: 17  Epoch: 361  Training loss = 5.2708  Validation loss = 3.3002  \n",
      "\n",
      "Fold: 17  Epoch: 362  Training loss = 5.2703  Validation loss = 3.2999  \n",
      "\n",
      "Fold: 17  Epoch: 363  Training loss = 5.2697  Validation loss = 3.2995  \n",
      "\n",
      "Fold: 17  Epoch: 364  Training loss = 5.2690  Validation loss = 3.2990  \n",
      "\n",
      "Fold: 17  Epoch: 365  Training loss = 5.2685  Validation loss = 3.2987  \n",
      "\n",
      "Fold: 17  Epoch: 366  Training loss = 5.2679  Validation loss = 3.2982  \n",
      "\n",
      "Fold: 17  Epoch: 367  Training loss = 5.2673  Validation loss = 3.2978  \n",
      "\n",
      "Fold: 17  Epoch: 368  Training loss = 5.2668  Validation loss = 3.2975  \n",
      "\n",
      "Fold: 17  Epoch: 369  Training loss = 5.2663  Validation loss = 3.2972  \n",
      "\n",
      "Fold: 17  Epoch: 370  Training loss = 5.2658  Validation loss = 3.2969  \n",
      "\n",
      "Fold: 17  Epoch: 371  Training loss = 5.2651  Validation loss = 3.2964  \n",
      "\n",
      "Fold: 17  Epoch: 372  Training loss = 5.2645  Validation loss = 3.2960  \n",
      "\n",
      "Fold: 17  Epoch: 373  Training loss = 5.2640  Validation loss = 3.2956  \n",
      "\n",
      "Fold: 17  Epoch: 374  Training loss = 5.2633  Validation loss = 3.2952  \n",
      "\n",
      "Fold: 17  Epoch: 375  Training loss = 5.2628  Validation loss = 3.2949  \n",
      "\n",
      "Fold: 17  Epoch: 376  Training loss = 5.2622  Validation loss = 3.2944  \n",
      "\n",
      "Fold: 17  Epoch: 377  Training loss = 5.2616  Validation loss = 3.2941  \n",
      "\n",
      "Fold: 17  Epoch: 378  Training loss = 5.2610  Validation loss = 3.2937  \n",
      "\n",
      "Fold: 17  Epoch: 379  Training loss = 5.2604  Validation loss = 3.2933  \n",
      "\n",
      "Fold: 17  Epoch: 380  Training loss = 5.2599  Validation loss = 3.2930  \n",
      "\n",
      "Fold: 17  Epoch: 381  Training loss = 5.2593  Validation loss = 3.2926  \n",
      "\n",
      "Fold: 17  Epoch: 382  Training loss = 5.2587  Validation loss = 3.2922  \n",
      "\n",
      "Fold: 17  Epoch: 383  Training loss = 5.2582  Validation loss = 3.2919  \n",
      "\n",
      "Fold: 17  Epoch: 384  Training loss = 5.2575  Validation loss = 3.2914  \n",
      "\n",
      "Fold: 17  Epoch: 385  Training loss = 5.2569  Validation loss = 3.2910  \n",
      "\n",
      "Fold: 17  Epoch: 386  Training loss = 5.2564  Validation loss = 3.2906  \n",
      "\n",
      "Fold: 17  Epoch: 387  Training loss = 5.2558  Validation loss = 3.2902  \n",
      "\n",
      "Fold: 17  Epoch: 388  Training loss = 5.2552  Validation loss = 3.2898  \n",
      "\n",
      "Fold: 17  Epoch: 389  Training loss = 5.2545  Validation loss = 3.2894  \n",
      "\n",
      "Fold: 17  Epoch: 390  Training loss = 5.2540  Validation loss = 3.2891  \n",
      "\n",
      "Fold: 17  Epoch: 391  Training loss = 5.2534  Validation loss = 3.2887  \n",
      "\n",
      "Fold: 17  Epoch: 392  Training loss = 5.2528  Validation loss = 3.2883  \n",
      "\n",
      "Fold: 17  Epoch: 393  Training loss = 5.2521  Validation loss = 3.2878  \n",
      "\n",
      "Fold: 17  Epoch: 394  Training loss = 5.2515  Validation loss = 3.2874  \n",
      "\n",
      "Fold: 17  Epoch: 395  Training loss = 5.2510  Validation loss = 3.2870  \n",
      "\n",
      "Fold: 17  Epoch: 396  Training loss = 5.2504  Validation loss = 3.2866  \n",
      "\n",
      "Fold: 17  Epoch: 397  Training loss = 5.2498  Validation loss = 3.2862  \n",
      "\n",
      "Fold: 17  Epoch: 398  Training loss = 5.2493  Validation loss = 3.2859  \n",
      "\n",
      "Fold: 17  Epoch: 399  Training loss = 5.2488  Validation loss = 3.2855  \n",
      "\n",
      "Fold: 17  Epoch: 400  Training loss = 5.2483  Validation loss = 3.2851  \n",
      "\n",
      "Fold: 17  Epoch: 401  Training loss = 5.2478  Validation loss = 3.2847  \n",
      "\n",
      "Fold: 17  Epoch: 402  Training loss = 5.2471  Validation loss = 3.2844  \n",
      "\n",
      "Fold: 17  Epoch: 403  Training loss = 5.2466  Validation loss = 3.2840  \n",
      "\n",
      "Fold: 17  Epoch: 404  Training loss = 5.2460  Validation loss = 3.2836  \n",
      "\n",
      "Fold: 17  Epoch: 405  Training loss = 5.2454  Validation loss = 3.2831  \n",
      "\n",
      "Fold: 17  Epoch: 406  Training loss = 5.2449  Validation loss = 3.2828  \n",
      "\n",
      "Fold: 17  Epoch: 407  Training loss = 5.2443  Validation loss = 3.2824  \n",
      "\n",
      "Fold: 17  Epoch: 408  Training loss = 5.2437  Validation loss = 3.2820  \n",
      "\n",
      "Fold: 17  Epoch: 409  Training loss = 5.2431  Validation loss = 3.2816  \n",
      "\n",
      "Fold: 17  Epoch: 410  Training loss = 5.2425  Validation loss = 3.2813  \n",
      "\n",
      "Fold: 17  Epoch: 411  Training loss = 5.2418  Validation loss = 3.2809  \n",
      "\n",
      "Fold: 17  Epoch: 412  Training loss = 5.2413  Validation loss = 3.2805  \n",
      "\n",
      "Fold: 17  Epoch: 413  Training loss = 5.2406  Validation loss = 3.2801  \n",
      "\n",
      "Fold: 17  Epoch: 414  Training loss = 5.2400  Validation loss = 3.2796  \n",
      "\n",
      "Fold: 17  Epoch: 415  Training loss = 5.2394  Validation loss = 3.2792  \n",
      "\n",
      "Fold: 17  Epoch: 416  Training loss = 5.2389  Validation loss = 3.2788  \n",
      "\n",
      "Fold: 17  Epoch: 417  Training loss = 5.2383  Validation loss = 3.2784  \n",
      "\n",
      "Fold: 17  Epoch: 418  Training loss = 5.2378  Validation loss = 3.2781  \n",
      "\n",
      "Fold: 17  Epoch: 419  Training loss = 5.2373  Validation loss = 3.2776  \n",
      "\n",
      "Fold: 17  Epoch: 420  Training loss = 5.2366  Validation loss = 3.2771  \n",
      "\n",
      "Fold: 17  Epoch: 421  Training loss = 5.2361  Validation loss = 3.2767  \n",
      "\n",
      "Fold: 17  Epoch: 422  Training loss = 5.2356  Validation loss = 3.2764  \n",
      "\n",
      "Fold: 17  Epoch: 423  Training loss = 5.2349  Validation loss = 3.2760  \n",
      "\n",
      "Fold: 17  Epoch: 424  Training loss = 5.2344  Validation loss = 3.2756  \n",
      "\n",
      "Fold: 17  Epoch: 425  Training loss = 5.2338  Validation loss = 3.2752  \n",
      "\n",
      "Fold: 17  Epoch: 426  Training loss = 5.2331  Validation loss = 3.2748  \n",
      "\n",
      "Fold: 17  Epoch: 427  Training loss = 5.2326  Validation loss = 3.2745  \n",
      "\n",
      "Fold: 17  Epoch: 428  Training loss = 5.2321  Validation loss = 3.2742  \n",
      "\n",
      "Fold: 17  Epoch: 429  Training loss = 5.2316  Validation loss = 3.2738  \n",
      "\n",
      "Fold: 17  Epoch: 430  Training loss = 5.2309  Validation loss = 3.2733  \n",
      "\n",
      "Fold: 17  Epoch: 431  Training loss = 5.2303  Validation loss = 3.2729  \n",
      "\n",
      "Fold: 17  Epoch: 432  Training loss = 5.2297  Validation loss = 3.2726  \n",
      "\n",
      "Fold: 17  Epoch: 433  Training loss = 5.2290  Validation loss = 3.2721  \n",
      "\n",
      "Fold: 17  Epoch: 434  Training loss = 5.2285  Validation loss = 3.2718  \n",
      "\n",
      "Fold: 17  Epoch: 435  Training loss = 5.2279  Validation loss = 3.2715  \n",
      "\n",
      "Fold: 17  Epoch: 436  Training loss = 5.2273  Validation loss = 3.2711  \n",
      "\n",
      "Fold: 17  Epoch: 437  Training loss = 5.2267  Validation loss = 3.2707  \n",
      "\n",
      "Fold: 17  Epoch: 438  Training loss = 5.2262  Validation loss = 3.2703  \n",
      "\n",
      "Fold: 17  Epoch: 439  Training loss = 5.2255  Validation loss = 3.2698  \n",
      "\n",
      "Fold: 17  Epoch: 440  Training loss = 5.2249  Validation loss = 3.2694  \n",
      "\n",
      "Fold: 17  Epoch: 441  Training loss = 5.2243  Validation loss = 3.2690  \n",
      "\n",
      "Fold: 17  Epoch: 442  Training loss = 5.2236  Validation loss = 3.2686  \n",
      "\n",
      "Fold: 17  Epoch: 443  Training loss = 5.2231  Validation loss = 3.2682  \n",
      "\n",
      "Fold: 17  Epoch: 444  Training loss = 5.2225  Validation loss = 3.2679  \n",
      "\n",
      "Fold: 17  Epoch: 445  Training loss = 5.2219  Validation loss = 3.2675  \n",
      "\n",
      "Fold: 17  Epoch: 446  Training loss = 5.2213  Validation loss = 3.2671  \n",
      "\n",
      "Fold: 17  Epoch: 447  Training loss = 5.2207  Validation loss = 3.2667  \n",
      "\n",
      "Fold: 17  Epoch: 448  Training loss = 5.2201  Validation loss = 3.2663  \n",
      "\n",
      "Fold: 17  Epoch: 449  Training loss = 5.2195  Validation loss = 3.2659  \n",
      "\n",
      "Fold: 17  Epoch: 450  Training loss = 5.2189  Validation loss = 3.2654  \n",
      "\n",
      "Fold: 17  Epoch: 451  Training loss = 5.2184  Validation loss = 3.2650  \n",
      "\n",
      "Fold: 17  Epoch: 452  Training loss = 5.2179  Validation loss = 3.2646  \n",
      "\n",
      "Fold: 17  Epoch: 453  Training loss = 5.2173  Validation loss = 3.2642  \n",
      "\n",
      "Fold: 17  Epoch: 454  Training loss = 5.2167  Validation loss = 3.2638  \n",
      "\n",
      "Fold: 17  Epoch: 455  Training loss = 5.2161  Validation loss = 3.2635  \n",
      "\n",
      "Fold: 17  Epoch: 456  Training loss = 5.2155  Validation loss = 3.2630  \n",
      "\n",
      "Fold: 17  Epoch: 457  Training loss = 5.2149  Validation loss = 3.2627  \n",
      "\n",
      "Fold: 17  Epoch: 458  Training loss = 5.2143  Validation loss = 3.2622  \n",
      "\n",
      "Fold: 17  Epoch: 459  Training loss = 5.2138  Validation loss = 3.2619  \n",
      "\n",
      "Fold: 17  Epoch: 460  Training loss = 5.2132  Validation loss = 3.2614  \n",
      "\n",
      "Fold: 17  Epoch: 461  Training loss = 5.2125  Validation loss = 3.2610  \n",
      "\n",
      "Fold: 17  Epoch: 462  Training loss = 5.2119  Validation loss = 3.2605  \n",
      "\n",
      "Fold: 17  Epoch: 463  Training loss = 5.2113  Validation loss = 3.2601  \n",
      "\n",
      "Fold: 17  Epoch: 464  Training loss = 5.2107  Validation loss = 3.2598  \n",
      "\n",
      "Fold: 17  Epoch: 465  Training loss = 5.2102  Validation loss = 3.2594  \n",
      "\n",
      "Fold: 17  Epoch: 466  Training loss = 5.2096  Validation loss = 3.2589  \n",
      "\n",
      "Fold: 17  Epoch: 467  Training loss = 5.2091  Validation loss = 3.2586  \n",
      "\n",
      "Fold: 17  Epoch: 468  Training loss = 5.2087  Validation loss = 3.2583  \n",
      "\n",
      "Fold: 17  Epoch: 469  Training loss = 5.2080  Validation loss = 3.2579  \n",
      "\n",
      "Fold: 17  Epoch: 470  Training loss = 5.2075  Validation loss = 3.2575  \n",
      "\n",
      "Fold: 17  Epoch: 471  Training loss = 5.2068  Validation loss = 3.2571  \n",
      "\n",
      "Fold: 17  Epoch: 472  Training loss = 5.2062  Validation loss = 3.2567  \n",
      "\n",
      "Fold: 17  Epoch: 473  Training loss = 5.2057  Validation loss = 3.2564  \n",
      "\n",
      "Fold: 17  Epoch: 474  Training loss = 5.2050  Validation loss = 3.2559  \n",
      "\n",
      "Fold: 17  Epoch: 475  Training loss = 5.2044  Validation loss = 3.2556  \n",
      "\n",
      "Fold: 17  Epoch: 476  Training loss = 5.2039  Validation loss = 3.2552  \n",
      "\n",
      "Fold: 17  Epoch: 477  Training loss = 5.2033  Validation loss = 3.2548  \n",
      "\n",
      "Fold: 17  Epoch: 478  Training loss = 5.2027  Validation loss = 3.2544  \n",
      "\n",
      "Fold: 17  Epoch: 479  Training loss = 5.2021  Validation loss = 3.2540  \n",
      "\n",
      "Fold: 17  Epoch: 480  Training loss = 5.2016  Validation loss = 3.2536  \n",
      "\n",
      "Fold: 17  Epoch: 481  Training loss = 5.2010  Validation loss = 3.2532  \n",
      "\n",
      "Fold: 17  Epoch: 482  Training loss = 5.2003  Validation loss = 3.2527  \n",
      "\n",
      "Fold: 17  Epoch: 483  Training loss = 5.1997  Validation loss = 3.2523  \n",
      "\n",
      "Fold: 17  Epoch: 484  Training loss = 5.1992  Validation loss = 3.2520  \n",
      "\n",
      "Fold: 17  Epoch: 485  Training loss = 5.1985  Validation loss = 3.2515  \n",
      "\n",
      "Fold: 17  Epoch: 486  Training loss = 5.1980  Validation loss = 3.2512  \n",
      "\n",
      "Fold: 17  Epoch: 487  Training loss = 5.1974  Validation loss = 3.2508  \n",
      "\n",
      "Fold: 17  Epoch: 488  Training loss = 5.1968  Validation loss = 3.2503  \n",
      "\n",
      "Fold: 17  Epoch: 489  Training loss = 5.1962  Validation loss = 3.2500  \n",
      "\n",
      "Fold: 17  Epoch: 490  Training loss = 5.1956  Validation loss = 3.2496  \n",
      "\n",
      "Fold: 17  Epoch: 491  Training loss = 5.1950  Validation loss = 3.2491  \n",
      "\n",
      "Fold: 17  Epoch: 492  Training loss = 5.1944  Validation loss = 3.2487  \n",
      "\n",
      "Fold: 17  Epoch: 493  Training loss = 5.1937  Validation loss = 3.2484  \n",
      "\n",
      "Fold: 17  Epoch: 494  Training loss = 5.1933  Validation loss = 3.2481  \n",
      "\n",
      "Fold: 17  Epoch: 495  Training loss = 5.1927  Validation loss = 3.2477  \n",
      "\n",
      "Fold: 17  Epoch: 496  Training loss = 5.1920  Validation loss = 3.2472  \n",
      "\n",
      "Fold: 17  Epoch: 497  Training loss = 5.1914  Validation loss = 3.2468  \n",
      "\n",
      "Fold: 17  Epoch: 498  Training loss = 5.1909  Validation loss = 3.2465  \n",
      "\n",
      "Fold: 17  Epoch: 499  Training loss = 5.1903  Validation loss = 3.2462  \n",
      "\n",
      "Fold: 17  Epoch: 500  Training loss = 5.1897  Validation loss = 3.2458  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 500  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 5.2452  Validation loss = 1.6072  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 5.2445  Validation loss = 1.6067  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 5.2439  Validation loss = 1.6062  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 5.2433  Validation loss = 1.6058  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 5.2427  Validation loss = 1.6053  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 5.2421  Validation loss = 1.6049  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 5.2415  Validation loss = 1.6045  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 5.2409  Validation loss = 1.6041  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 5.2404  Validation loss = 1.6037  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 5.2397  Validation loss = 1.6033  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 5.2392  Validation loss = 1.6029  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 5.2386  Validation loss = 1.6025  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 5.2380  Validation loss = 1.6020  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 5.2374  Validation loss = 1.6016  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 5.2367  Validation loss = 1.6011  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 5.2361  Validation loss = 1.6007  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 5.2355  Validation loss = 1.6003  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 5.2349  Validation loss = 1.5998  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 5.2343  Validation loss = 1.5994  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 5.2337  Validation loss = 1.5989  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 5.2331  Validation loss = 1.5985  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 5.2325  Validation loss = 1.5981  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 5.2320  Validation loss = 1.5977  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 5.2314  Validation loss = 1.5973  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 5.2308  Validation loss = 1.5969  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 5.2302  Validation loss = 1.5964  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 5.2295  Validation loss = 1.5960  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 5.2288  Validation loss = 1.5955  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 5.2282  Validation loss = 1.5950  \n",
      "\n",
      "Fold: 18  Epoch: 30  Training loss = 5.2277  Validation loss = 1.5947  \n",
      "\n",
      "Fold: 18  Epoch: 31  Training loss = 5.2271  Validation loss = 1.5942  \n",
      "\n",
      "Fold: 18  Epoch: 32  Training loss = 5.2265  Validation loss = 1.5938  \n",
      "\n",
      "Fold: 18  Epoch: 33  Training loss = 5.2261  Validation loss = 1.5934  \n",
      "\n",
      "Fold: 18  Epoch: 34  Training loss = 5.2255  Validation loss = 1.5930  \n",
      "\n",
      "Fold: 18  Epoch: 35  Training loss = 5.2250  Validation loss = 1.5927  \n",
      "\n",
      "Fold: 18  Epoch: 36  Training loss = 5.2243  Validation loss = 1.5922  \n",
      "\n",
      "Fold: 18  Epoch: 37  Training loss = 5.2238  Validation loss = 1.5918  \n",
      "\n",
      "Fold: 18  Epoch: 38  Training loss = 5.2232  Validation loss = 1.5914  \n",
      "\n",
      "Fold: 18  Epoch: 39  Training loss = 5.2226  Validation loss = 1.5909  \n",
      "\n",
      "Fold: 18  Epoch: 40  Training loss = 5.2220  Validation loss = 1.5905  \n",
      "\n",
      "Fold: 18  Epoch: 41  Training loss = 5.2214  Validation loss = 1.5901  \n",
      "\n",
      "Fold: 18  Epoch: 42  Training loss = 5.2208  Validation loss = 1.5896  \n",
      "\n",
      "Fold: 18  Epoch: 43  Training loss = 5.2201  Validation loss = 1.5892  \n",
      "\n",
      "Fold: 18  Epoch: 44  Training loss = 5.2195  Validation loss = 1.5887  \n",
      "\n",
      "Fold: 18  Epoch: 45  Training loss = 5.2190  Validation loss = 1.5883  \n",
      "\n",
      "Fold: 18  Epoch: 46  Training loss = 5.2184  Validation loss = 1.5880  \n",
      "\n",
      "Fold: 18  Epoch: 47  Training loss = 5.2179  Validation loss = 1.5876  \n",
      "\n",
      "Fold: 18  Epoch: 48  Training loss = 5.2173  Validation loss = 1.5871  \n",
      "\n",
      "Fold: 18  Epoch: 49  Training loss = 5.2166  Validation loss = 1.5867  \n",
      "\n",
      "Fold: 18  Epoch: 50  Training loss = 5.2161  Validation loss = 1.5863  \n",
      "\n",
      "Fold: 18  Epoch: 51  Training loss = 5.2156  Validation loss = 1.5859  \n",
      "\n",
      "Fold: 18  Epoch: 52  Training loss = 5.2150  Validation loss = 1.5855  \n",
      "\n",
      "Fold: 18  Epoch: 53  Training loss = 5.2144  Validation loss = 1.5851  \n",
      "\n",
      "Fold: 18  Epoch: 54  Training loss = 5.2139  Validation loss = 1.5847  \n",
      "\n",
      "Fold: 18  Epoch: 55  Training loss = 5.2132  Validation loss = 1.5843  \n",
      "\n",
      "Fold: 18  Epoch: 56  Training loss = 5.2127  Validation loss = 1.5839  \n",
      "\n",
      "Fold: 18  Epoch: 57  Training loss = 5.2120  Validation loss = 1.5834  \n",
      "\n",
      "Fold: 18  Epoch: 58  Training loss = 5.2113  Validation loss = 1.5829  \n",
      "\n",
      "Fold: 18  Epoch: 59  Training loss = 5.2107  Validation loss = 1.5825  \n",
      "\n",
      "Fold: 18  Epoch: 60  Training loss = 5.2100  Validation loss = 1.5820  \n",
      "\n",
      "Fold: 18  Epoch: 61  Training loss = 5.2094  Validation loss = 1.5816  \n",
      "\n",
      "Fold: 18  Epoch: 62  Training loss = 5.2088  Validation loss = 1.5812  \n",
      "\n",
      "Fold: 18  Epoch: 63  Training loss = 5.2082  Validation loss = 1.5807  \n",
      "\n",
      "Fold: 18  Epoch: 64  Training loss = 5.2075  Validation loss = 1.5802  \n",
      "\n",
      "Fold: 18  Epoch: 65  Training loss = 5.2070  Validation loss = 1.5799  \n",
      "\n",
      "Fold: 18  Epoch: 66  Training loss = 5.2065  Validation loss = 1.5795  \n",
      "\n",
      "Fold: 18  Epoch: 67  Training loss = 5.2059  Validation loss = 1.5791  \n",
      "\n",
      "Fold: 18  Epoch: 68  Training loss = 5.2053  Validation loss = 1.5786  \n",
      "\n",
      "Fold: 18  Epoch: 69  Training loss = 5.2047  Validation loss = 1.5782  \n",
      "\n",
      "Fold: 18  Epoch: 70  Training loss = 5.2042  Validation loss = 1.5778  \n",
      "\n",
      "Fold: 18  Epoch: 71  Training loss = 5.2035  Validation loss = 1.5773  \n",
      "\n",
      "Fold: 18  Epoch: 72  Training loss = 5.2029  Validation loss = 1.5769  \n",
      "\n",
      "Fold: 18  Epoch: 73  Training loss = 5.2023  Validation loss = 1.5765  \n",
      "\n",
      "Fold: 18  Epoch: 74  Training loss = 5.2017  Validation loss = 1.5761  \n",
      "\n",
      "Fold: 18  Epoch: 75  Training loss = 5.2012  Validation loss = 1.5757  \n",
      "\n",
      "Fold: 18  Epoch: 76  Training loss = 5.2005  Validation loss = 1.5753  \n",
      "\n",
      "Fold: 18  Epoch: 77  Training loss = 5.1999  Validation loss = 1.5748  \n",
      "\n",
      "Fold: 18  Epoch: 78  Training loss = 5.1993  Validation loss = 1.5744  \n",
      "\n",
      "Fold: 18  Epoch: 79  Training loss = 5.1987  Validation loss = 1.5740  \n",
      "\n",
      "Fold: 18  Epoch: 80  Training loss = 5.1981  Validation loss = 1.5736  \n",
      "\n",
      "Fold: 18  Epoch: 81  Training loss = 5.1974  Validation loss = 1.5732  \n",
      "\n",
      "Fold: 18  Epoch: 82  Training loss = 5.1969  Validation loss = 1.5728  \n",
      "\n",
      "Fold: 18  Epoch: 83  Training loss = 5.1961  Validation loss = 1.5723  \n",
      "\n",
      "Fold: 18  Epoch: 84  Training loss = 5.1956  Validation loss = 1.5719  \n",
      "\n",
      "Fold: 18  Epoch: 85  Training loss = 5.1952  Validation loss = 1.5716  \n",
      "\n",
      "Fold: 18  Epoch: 86  Training loss = 5.1946  Validation loss = 1.5712  \n",
      "\n",
      "Fold: 18  Epoch: 87  Training loss = 5.1941  Validation loss = 1.5708  \n",
      "\n",
      "Fold: 18  Epoch: 88  Training loss = 5.1935  Validation loss = 1.5704  \n",
      "\n",
      "Fold: 18  Epoch: 89  Training loss = 5.1929  Validation loss = 1.5700  \n",
      "\n",
      "Fold: 18  Epoch: 90  Training loss = 5.1922  Validation loss = 1.5695  \n",
      "\n",
      "Fold: 18  Epoch: 91  Training loss = 5.1916  Validation loss = 1.5691  \n",
      "\n",
      "Fold: 18  Epoch: 92  Training loss = 5.1911  Validation loss = 1.5687  \n",
      "\n",
      "Fold: 18  Epoch: 93  Training loss = 5.1905  Validation loss = 1.5683  \n",
      "\n",
      "Fold: 18  Epoch: 94  Training loss = 5.1899  Validation loss = 1.5678  \n",
      "\n",
      "Fold: 18  Epoch: 95  Training loss = 5.1893  Validation loss = 1.5674  \n",
      "\n",
      "Fold: 18  Epoch: 96  Training loss = 5.1887  Validation loss = 1.5670  \n",
      "\n",
      "Fold: 18  Epoch: 97  Training loss = 5.1882  Validation loss = 1.5666  \n",
      "\n",
      "Fold: 18  Epoch: 98  Training loss = 5.1877  Validation loss = 1.5663  \n",
      "\n",
      "Fold: 18  Epoch: 99  Training loss = 5.1871  Validation loss = 1.5659  \n",
      "\n",
      "Fold: 18  Epoch: 100  Training loss = 5.1864  Validation loss = 1.5654  \n",
      "\n",
      "Fold: 18  Epoch: 101  Training loss = 5.1859  Validation loss = 1.5650  \n",
      "\n",
      "Fold: 18  Epoch: 102  Training loss = 5.1853  Validation loss = 1.5645  \n",
      "\n",
      "Fold: 18  Epoch: 103  Training loss = 5.1846  Validation loss = 1.5641  \n",
      "\n",
      "Fold: 18  Epoch: 104  Training loss = 5.1841  Validation loss = 1.5637  \n",
      "\n",
      "Fold: 18  Epoch: 105  Training loss = 5.1835  Validation loss = 1.5633  \n",
      "\n",
      "Fold: 18  Epoch: 106  Training loss = 5.1828  Validation loss = 1.5628  \n",
      "\n",
      "Fold: 18  Epoch: 107  Training loss = 5.1823  Validation loss = 1.5625  \n",
      "\n",
      "Fold: 18  Epoch: 108  Training loss = 5.1817  Validation loss = 1.5621  \n",
      "\n",
      "Fold: 18  Epoch: 109  Training loss = 5.1811  Validation loss = 1.5617  \n",
      "\n",
      "Fold: 18  Epoch: 110  Training loss = 5.1806  Validation loss = 1.5613  \n",
      "\n",
      "Fold: 18  Epoch: 111  Training loss = 5.1801  Validation loss = 1.5609  \n",
      "\n",
      "Fold: 18  Epoch: 112  Training loss = 5.1795  Validation loss = 1.5605  \n",
      "\n",
      "Fold: 18  Epoch: 113  Training loss = 5.1789  Validation loss = 1.5601  \n",
      "\n",
      "Fold: 18  Epoch: 114  Training loss = 5.1782  Validation loss = 1.5596  \n",
      "\n",
      "Fold: 18  Epoch: 115  Training loss = 5.1776  Validation loss = 1.5592  \n",
      "\n",
      "Fold: 18  Epoch: 116  Training loss = 5.1770  Validation loss = 1.5588  \n",
      "\n",
      "Fold: 18  Epoch: 117  Training loss = 5.1763  Validation loss = 1.5583  \n",
      "\n",
      "Fold: 18  Epoch: 118  Training loss = 5.1756  Validation loss = 1.5578  \n",
      "\n",
      "Fold: 18  Epoch: 119  Training loss = 5.1751  Validation loss = 1.5575  \n",
      "\n",
      "Fold: 18  Epoch: 120  Training loss = 5.1745  Validation loss = 1.5571  \n",
      "\n",
      "Fold: 18  Epoch: 121  Training loss = 5.1739  Validation loss = 1.5567  \n",
      "\n",
      "Fold: 18  Epoch: 122  Training loss = 5.1734  Validation loss = 1.5563  \n",
      "\n",
      "Fold: 18  Epoch: 123  Training loss = 5.1728  Validation loss = 1.5559  \n",
      "\n",
      "Fold: 18  Epoch: 124  Training loss = 5.1722  Validation loss = 1.5555  \n",
      "\n",
      "Fold: 18  Epoch: 125  Training loss = 5.1717  Validation loss = 1.5551  \n",
      "\n",
      "Fold: 18  Epoch: 126  Training loss = 5.1710  Validation loss = 1.5547  \n",
      "\n",
      "Fold: 18  Epoch: 127  Training loss = 5.1704  Validation loss = 1.5542  \n",
      "\n",
      "Fold: 18  Epoch: 128  Training loss = 5.1698  Validation loss = 1.5538  \n",
      "\n",
      "Fold: 18  Epoch: 129  Training loss = 5.1692  Validation loss = 1.5534  \n",
      "\n",
      "Fold: 18  Epoch: 130  Training loss = 5.1686  Validation loss = 1.5530  \n",
      "\n",
      "Fold: 18  Epoch: 131  Training loss = 5.1681  Validation loss = 1.5526  \n",
      "\n",
      "Fold: 18  Epoch: 132  Training loss = 5.1674  Validation loss = 1.5521  \n",
      "\n",
      "Fold: 18  Epoch: 133  Training loss = 5.1668  Validation loss = 1.5517  \n",
      "\n",
      "Fold: 18  Epoch: 134  Training loss = 5.1662  Validation loss = 1.5513  \n",
      "\n",
      "Fold: 18  Epoch: 135  Training loss = 5.1656  Validation loss = 1.5508  \n",
      "\n",
      "Fold: 18  Epoch: 136  Training loss = 5.1651  Validation loss = 1.5504  \n",
      "\n",
      "Fold: 18  Epoch: 137  Training loss = 5.1646  Validation loss = 1.5501  \n",
      "\n",
      "Fold: 18  Epoch: 138  Training loss = 5.1640  Validation loss = 1.5496  \n",
      "\n",
      "Fold: 18  Epoch: 139  Training loss = 5.1635  Validation loss = 1.5493  \n",
      "\n",
      "Fold: 18  Epoch: 140  Training loss = 5.1629  Validation loss = 1.5489  \n",
      "\n",
      "Fold: 18  Epoch: 141  Training loss = 5.1623  Validation loss = 1.5485  \n",
      "\n",
      "Fold: 18  Epoch: 142  Training loss = 5.1618  Validation loss = 1.5481  \n",
      "\n",
      "Fold: 18  Epoch: 143  Training loss = 5.1613  Validation loss = 1.5477  \n",
      "\n",
      "Fold: 18  Epoch: 144  Training loss = 5.1607  Validation loss = 1.5473  \n",
      "\n",
      "Fold: 18  Epoch: 145  Training loss = 5.1601  Validation loss = 1.5469  \n",
      "\n",
      "Fold: 18  Epoch: 146  Training loss = 5.1595  Validation loss = 1.5464  \n",
      "\n",
      "Fold: 18  Epoch: 147  Training loss = 5.1589  Validation loss = 1.5460  \n",
      "\n",
      "Fold: 18  Epoch: 148  Training loss = 5.1583  Validation loss = 1.5456  \n",
      "\n",
      "Fold: 18  Epoch: 149  Training loss = 5.1577  Validation loss = 1.5452  \n",
      "\n",
      "Fold: 18  Epoch: 150  Training loss = 5.1570  Validation loss = 1.5447  \n",
      "\n",
      "Fold: 18  Epoch: 151  Training loss = 5.1564  Validation loss = 1.5443  \n",
      "\n",
      "Fold: 18  Epoch: 152  Training loss = 5.1557  Validation loss = 1.5438  \n",
      "\n",
      "Fold: 18  Epoch: 153  Training loss = 5.1550  Validation loss = 1.5433  \n",
      "\n",
      "Fold: 18  Epoch: 154  Training loss = 5.1545  Validation loss = 1.5429  \n",
      "\n",
      "Fold: 18  Epoch: 155  Training loss = 5.1539  Validation loss = 1.5425  \n",
      "\n",
      "Fold: 18  Epoch: 156  Training loss = 5.1533  Validation loss = 1.5421  \n",
      "\n",
      "Fold: 18  Epoch: 157  Training loss = 5.1526  Validation loss = 1.5417  \n",
      "\n",
      "Fold: 18  Epoch: 158  Training loss = 5.1521  Validation loss = 1.5413  \n",
      "\n",
      "Fold: 18  Epoch: 159  Training loss = 5.1516  Validation loss = 1.5409  \n",
      "\n",
      "Fold: 18  Epoch: 160  Training loss = 5.1510  Validation loss = 1.5405  \n",
      "\n",
      "Fold: 18  Epoch: 161  Training loss = 5.1504  Validation loss = 1.5401  \n",
      "\n",
      "Fold: 18  Epoch: 162  Training loss = 5.1498  Validation loss = 1.5397  \n",
      "\n",
      "Fold: 18  Epoch: 163  Training loss = 5.1492  Validation loss = 1.5393  \n",
      "\n",
      "Fold: 18  Epoch: 164  Training loss = 5.1486  Validation loss = 1.5388  \n",
      "\n",
      "Fold: 18  Epoch: 165  Training loss = 5.1480  Validation loss = 1.5384  \n",
      "\n",
      "Fold: 18  Epoch: 166  Training loss = 5.1475  Validation loss = 1.5381  \n",
      "\n",
      "Fold: 18  Epoch: 167  Training loss = 5.1470  Validation loss = 1.5377  \n",
      "\n",
      "Fold: 18  Epoch: 168  Training loss = 5.1463  Validation loss = 1.5373  \n",
      "\n",
      "Fold: 18  Epoch: 169  Training loss = 5.1458  Validation loss = 1.5369  \n",
      "\n",
      "Fold: 18  Epoch: 170  Training loss = 5.1453  Validation loss = 1.5366  \n",
      "\n",
      "Fold: 18  Epoch: 171  Training loss = 5.1447  Validation loss = 1.5362  \n",
      "\n",
      "Fold: 18  Epoch: 172  Training loss = 5.1442  Validation loss = 1.5358  \n",
      "\n",
      "Fold: 18  Epoch: 173  Training loss = 5.1436  Validation loss = 1.5354  \n",
      "\n",
      "Fold: 18  Epoch: 174  Training loss = 5.1429  Validation loss = 1.5349  \n",
      "\n",
      "Fold: 18  Epoch: 175  Training loss = 5.1424  Validation loss = 1.5345  \n",
      "\n",
      "Fold: 18  Epoch: 176  Training loss = 5.1417  Validation loss = 1.5340  \n",
      "\n",
      "Fold: 18  Epoch: 177  Training loss = 5.1410  Validation loss = 1.5335  \n",
      "\n",
      "Fold: 18  Epoch: 178  Training loss = 5.1403  Validation loss = 1.5330  \n",
      "\n",
      "Fold: 18  Epoch: 179  Training loss = 5.1397  Validation loss = 1.5326  \n",
      "\n",
      "Fold: 18  Epoch: 180  Training loss = 5.1390  Validation loss = 1.5321  \n",
      "\n",
      "Fold: 18  Epoch: 181  Training loss = 5.1385  Validation loss = 1.5317  \n",
      "\n",
      "Fold: 18  Epoch: 182  Training loss = 5.1379  Validation loss = 1.5313  \n",
      "\n",
      "Fold: 18  Epoch: 183  Training loss = 5.1373  Validation loss = 1.5309  \n",
      "\n",
      "Fold: 18  Epoch: 184  Training loss = 5.1366  Validation loss = 1.5304  \n",
      "\n",
      "Fold: 18  Epoch: 185  Training loss = 5.1360  Validation loss = 1.5300  \n",
      "\n",
      "Fold: 18  Epoch: 186  Training loss = 5.1354  Validation loss = 1.5296  \n",
      "\n",
      "Fold: 18  Epoch: 187  Training loss = 5.1348  Validation loss = 1.5292  \n",
      "\n",
      "Fold: 18  Epoch: 188  Training loss = 5.1341  Validation loss = 1.5288  \n",
      "\n",
      "Fold: 18  Epoch: 189  Training loss = 5.1335  Validation loss = 1.5284  \n",
      "\n",
      "Fold: 18  Epoch: 190  Training loss = 5.1330  Validation loss = 1.5280  \n",
      "\n",
      "Fold: 18  Epoch: 191  Training loss = 5.1324  Validation loss = 1.5276  \n",
      "\n",
      "Fold: 18  Epoch: 192  Training loss = 5.1317  Validation loss = 1.5271  \n",
      "\n",
      "Fold: 18  Epoch: 193  Training loss = 5.1313  Validation loss = 1.5268  \n",
      "\n",
      "Fold: 18  Epoch: 194  Training loss = 5.1306  Validation loss = 1.5264  \n",
      "\n",
      "Fold: 18  Epoch: 195  Training loss = 5.1302  Validation loss = 1.5261  \n",
      "\n",
      "Fold: 18  Epoch: 196  Training loss = 5.1295  Validation loss = 1.5256  \n",
      "\n",
      "Fold: 18  Epoch: 197  Training loss = 5.1290  Validation loss = 1.5252  \n",
      "\n",
      "Fold: 18  Epoch: 198  Training loss = 5.1283  Validation loss = 1.5248  \n",
      "\n",
      "Fold: 18  Epoch: 199  Training loss = 5.1277  Validation loss = 1.5243  \n",
      "\n",
      "Fold: 18  Epoch: 200  Training loss = 5.1272  Validation loss = 1.5240  \n",
      "\n",
      "Fold: 18  Epoch: 201  Training loss = 5.1265  Validation loss = 1.5235  \n",
      "\n",
      "Fold: 18  Epoch: 202  Training loss = 5.1259  Validation loss = 1.5231  \n",
      "\n",
      "Fold: 18  Epoch: 203  Training loss = 5.1254  Validation loss = 1.5227  \n",
      "\n",
      "Fold: 18  Epoch: 204  Training loss = 5.1248  Validation loss = 1.5223  \n",
      "\n",
      "Fold: 18  Epoch: 205  Training loss = 5.1243  Validation loss = 1.5220  \n",
      "\n",
      "Fold: 18  Epoch: 206  Training loss = 5.1238  Validation loss = 1.5216  \n",
      "\n",
      "Fold: 18  Epoch: 207  Training loss = 5.1232  Validation loss = 1.5212  \n",
      "\n",
      "Fold: 18  Epoch: 208  Training loss = 5.1226  Validation loss = 1.5208  \n",
      "\n",
      "Fold: 18  Epoch: 209  Training loss = 5.1220  Validation loss = 1.5204  \n",
      "\n",
      "Fold: 18  Epoch: 210  Training loss = 5.1214  Validation loss = 1.5199  \n",
      "\n",
      "Fold: 18  Epoch: 211  Training loss = 5.1208  Validation loss = 1.5195  \n",
      "\n",
      "Fold: 18  Epoch: 212  Training loss = 5.1201  Validation loss = 1.5191  \n",
      "\n",
      "Fold: 18  Epoch: 213  Training loss = 5.1195  Validation loss = 1.5187  \n",
      "\n",
      "Fold: 18  Epoch: 214  Training loss = 5.1189  Validation loss = 1.5183  \n",
      "\n",
      "Fold: 18  Epoch: 215  Training loss = 5.1182  Validation loss = 1.5178  \n",
      "\n",
      "Fold: 18  Epoch: 216  Training loss = 5.1176  Validation loss = 1.5174  \n",
      "\n",
      "Fold: 18  Epoch: 217  Training loss = 5.1170  Validation loss = 1.5170  \n",
      "\n",
      "Fold: 18  Epoch: 218  Training loss = 5.1163  Validation loss = 1.5165  \n",
      "\n",
      "Fold: 18  Epoch: 219  Training loss = 5.1158  Validation loss = 1.5161  \n",
      "\n",
      "Fold: 18  Epoch: 220  Training loss = 5.1151  Validation loss = 1.5157  \n",
      "\n",
      "Fold: 18  Epoch: 221  Training loss = 5.1146  Validation loss = 1.5153  \n",
      "\n",
      "Fold: 18  Epoch: 222  Training loss = 5.1140  Validation loss = 1.5149  \n",
      "\n",
      "Fold: 18  Epoch: 223  Training loss = 5.1134  Validation loss = 1.5145  \n",
      "\n",
      "Fold: 18  Epoch: 224  Training loss = 5.1128  Validation loss = 1.5140  \n",
      "\n",
      "Fold: 18  Epoch: 225  Training loss = 5.1122  Validation loss = 1.5136  \n",
      "\n",
      "Fold: 18  Epoch: 226  Training loss = 5.1116  Validation loss = 1.5132  \n",
      "\n",
      "Fold: 18  Epoch: 227  Training loss = 5.1111  Validation loss = 1.5128  \n",
      "\n",
      "Fold: 18  Epoch: 228  Training loss = 5.1106  Validation loss = 1.5124  \n",
      "\n",
      "Fold: 18  Epoch: 229  Training loss = 5.1099  Validation loss = 1.5120  \n",
      "\n",
      "Fold: 18  Epoch: 230  Training loss = 5.1094  Validation loss = 1.5116  \n",
      "\n",
      "Fold: 18  Epoch: 231  Training loss = 5.1088  Validation loss = 1.5112  \n",
      "\n",
      "Fold: 18  Epoch: 232  Training loss = 5.1081  Validation loss = 1.5107  \n",
      "\n",
      "Fold: 18  Epoch: 233  Training loss = 5.1076  Validation loss = 1.5103  \n",
      "\n",
      "Fold: 18  Epoch: 234  Training loss = 5.1071  Validation loss = 1.5100  \n",
      "\n",
      "Fold: 18  Epoch: 235  Training loss = 5.1065  Validation loss = 1.5095  \n",
      "\n",
      "Fold: 18  Epoch: 236  Training loss = 5.1059  Validation loss = 1.5092  \n",
      "\n",
      "Fold: 18  Epoch: 237  Training loss = 5.1053  Validation loss = 1.5088  \n",
      "\n",
      "Fold: 18  Epoch: 238  Training loss = 5.1047  Validation loss = 1.5084  \n",
      "\n",
      "Fold: 18  Epoch: 239  Training loss = 5.1041  Validation loss = 1.5079  \n",
      "\n",
      "Fold: 18  Epoch: 240  Training loss = 5.1036  Validation loss = 1.5076  \n",
      "\n",
      "Fold: 18  Epoch: 241  Training loss = 5.1030  Validation loss = 1.5072  \n",
      "\n",
      "Fold: 18  Epoch: 242  Training loss = 5.1023  Validation loss = 1.5068  \n",
      "\n",
      "Fold: 18  Epoch: 243  Training loss = 5.1017  Validation loss = 1.5063  \n",
      "\n",
      "Fold: 18  Epoch: 244  Training loss = 5.1011  Validation loss = 1.5058  \n",
      "\n",
      "Fold: 18  Epoch: 245  Training loss = 5.1005  Validation loss = 1.5054  \n",
      "\n",
      "Fold: 18  Epoch: 246  Training loss = 5.1000  Validation loss = 1.5051  \n",
      "\n",
      "Fold: 18  Epoch: 247  Training loss = 5.0993  Validation loss = 1.5046  \n",
      "\n",
      "Fold: 18  Epoch: 248  Training loss = 5.0987  Validation loss = 1.5042  \n",
      "\n",
      "Fold: 18  Epoch: 249  Training loss = 5.0981  Validation loss = 1.5038  \n",
      "\n",
      "Fold: 18  Epoch: 250  Training loss = 5.0975  Validation loss = 1.5034  \n",
      "\n",
      "Fold: 18  Epoch: 251  Training loss = 5.0969  Validation loss = 1.5030  \n",
      "\n",
      "Fold: 18  Epoch: 252  Training loss = 5.0964  Validation loss = 1.5026  \n",
      "\n",
      "Fold: 18  Epoch: 253  Training loss = 5.0959  Validation loss = 1.5023  \n",
      "\n",
      "Fold: 18  Epoch: 254  Training loss = 5.0952  Validation loss = 1.5018  \n",
      "\n",
      "Fold: 18  Epoch: 255  Training loss = 5.0947  Validation loss = 1.5015  \n",
      "\n",
      "Fold: 18  Epoch: 256  Training loss = 5.0941  Validation loss = 1.5010  \n",
      "\n",
      "Fold: 18  Epoch: 257  Training loss = 5.0936  Validation loss = 1.5007  \n",
      "\n",
      "Fold: 18  Epoch: 258  Training loss = 5.0930  Validation loss = 1.5003  \n",
      "\n",
      "Fold: 18  Epoch: 259  Training loss = 5.0926  Validation loss = 1.5000  \n",
      "\n",
      "Fold: 18  Epoch: 260  Training loss = 5.0921  Validation loss = 1.4996  \n",
      "\n",
      "Fold: 18  Epoch: 261  Training loss = 5.0915  Validation loss = 1.4993  \n",
      "\n",
      "Fold: 18  Epoch: 262  Training loss = 5.0909  Validation loss = 1.4988  \n",
      "\n",
      "Fold: 18  Epoch: 263  Training loss = 5.0903  Validation loss = 1.4984  \n",
      "\n",
      "Fold: 18  Epoch: 264  Training loss = 5.0899  Validation loss = 1.4981  \n",
      "\n",
      "Fold: 18  Epoch: 265  Training loss = 5.0893  Validation loss = 1.4977  \n",
      "\n",
      "Fold: 18  Epoch: 266  Training loss = 5.0888  Validation loss = 1.4973  \n",
      "\n",
      "Fold: 18  Epoch: 267  Training loss = 5.0881  Validation loss = 1.4969  \n",
      "\n",
      "Fold: 18  Epoch: 268  Training loss = 5.0876  Validation loss = 1.4965  \n",
      "\n",
      "Fold: 18  Epoch: 269  Training loss = 5.0870  Validation loss = 1.4961  \n",
      "\n",
      "Fold: 18  Epoch: 270  Training loss = 5.0865  Validation loss = 1.4957  \n",
      "\n",
      "Fold: 18  Epoch: 271  Training loss = 5.0858  Validation loss = 1.4953  \n",
      "\n",
      "Fold: 18  Epoch: 272  Training loss = 5.0852  Validation loss = 1.4948  \n",
      "\n",
      "Fold: 18  Epoch: 273  Training loss = 5.0847  Validation loss = 1.4945  \n",
      "\n",
      "Fold: 18  Epoch: 274  Training loss = 5.0841  Validation loss = 1.4941  \n",
      "\n",
      "Fold: 18  Epoch: 275  Training loss = 5.0835  Validation loss = 1.4937  \n",
      "\n",
      "Fold: 18  Epoch: 276  Training loss = 5.0829  Validation loss = 1.4933  \n",
      "\n",
      "Fold: 18  Epoch: 277  Training loss = 5.0823  Validation loss = 1.4929  \n",
      "\n",
      "Fold: 18  Epoch: 278  Training loss = 5.0816  Validation loss = 1.4924  \n",
      "\n",
      "Fold: 18  Epoch: 279  Training loss = 5.0810  Validation loss = 1.4920  \n",
      "\n",
      "Fold: 18  Epoch: 280  Training loss = 5.0803  Validation loss = 1.4915  \n",
      "\n",
      "Fold: 18  Epoch: 281  Training loss = 5.0799  Validation loss = 1.4912  \n",
      "\n",
      "Fold: 18  Epoch: 282  Training loss = 5.0793  Validation loss = 1.4908  \n",
      "\n",
      "Fold: 18  Epoch: 283  Training loss = 5.0786  Validation loss = 1.4903  \n",
      "\n",
      "Fold: 18  Epoch: 284  Training loss = 5.0781  Validation loss = 1.4900  \n",
      "\n",
      "Fold: 18  Epoch: 285  Training loss = 5.0775  Validation loss = 1.4896  \n",
      "\n",
      "Fold: 18  Epoch: 286  Training loss = 5.0769  Validation loss = 1.4892  \n",
      "\n",
      "Fold: 18  Epoch: 287  Training loss = 5.0763  Validation loss = 1.4888  \n",
      "\n",
      "Fold: 18  Epoch: 288  Training loss = 5.0757  Validation loss = 1.4883  \n",
      "\n",
      "Fold: 18  Epoch: 289  Training loss = 5.0750  Validation loss = 1.4878  \n",
      "\n",
      "Fold: 18  Epoch: 290  Training loss = 5.0742  Validation loss = 1.4873  \n",
      "\n",
      "Fold: 18  Epoch: 291  Training loss = 5.0736  Validation loss = 1.4869  \n",
      "\n",
      "Fold: 18  Epoch: 292  Training loss = 5.0730  Validation loss = 1.4865  \n",
      "\n",
      "Fold: 18  Epoch: 293  Training loss = 5.0723  Validation loss = 1.4860  \n",
      "\n",
      "Fold: 18  Epoch: 294  Training loss = 5.0718  Validation loss = 1.4856  \n",
      "\n",
      "Fold: 18  Epoch: 295  Training loss = 5.0711  Validation loss = 1.4851  \n",
      "\n",
      "Fold: 18  Epoch: 296  Training loss = 5.0705  Validation loss = 1.4847  \n",
      "\n",
      "Fold: 18  Epoch: 297  Training loss = 5.0699  Validation loss = 1.4844  \n",
      "\n",
      "Fold: 18  Epoch: 298  Training loss = 5.0694  Validation loss = 1.4839  \n",
      "\n",
      "Fold: 18  Epoch: 299  Training loss = 5.0688  Validation loss = 1.4836  \n",
      "\n",
      "Fold: 18  Epoch: 300  Training loss = 5.0681  Validation loss = 1.4831  \n",
      "\n",
      "Fold: 18  Epoch: 301  Training loss = 5.0675  Validation loss = 1.4827  \n",
      "\n",
      "Fold: 18  Epoch: 302  Training loss = 5.0670  Validation loss = 1.4823  \n",
      "\n",
      "Fold: 18  Epoch: 303  Training loss = 5.0664  Validation loss = 1.4819  \n",
      "\n",
      "Fold: 18  Epoch: 304  Training loss = 5.0660  Validation loss = 1.4816  \n",
      "\n",
      "Fold: 18  Epoch: 305  Training loss = 5.0654  Validation loss = 1.4812  \n",
      "\n",
      "Fold: 18  Epoch: 306  Training loss = 5.0647  Validation loss = 1.4808  \n",
      "\n",
      "Fold: 18  Epoch: 307  Training loss = 5.0642  Validation loss = 1.4804  \n",
      "\n",
      "Fold: 18  Epoch: 308  Training loss = 5.0637  Validation loss = 1.4801  \n",
      "\n",
      "Fold: 18  Epoch: 309  Training loss = 5.0633  Validation loss = 1.4798  \n",
      "\n",
      "Fold: 18  Epoch: 310  Training loss = 5.0628  Validation loss = 1.4794  \n",
      "\n",
      "Fold: 18  Epoch: 311  Training loss = 5.0621  Validation loss = 1.4790  \n",
      "\n",
      "Fold: 18  Epoch: 312  Training loss = 5.0615  Validation loss = 1.4786  \n",
      "\n",
      "Fold: 18  Epoch: 313  Training loss = 5.0610  Validation loss = 1.4782  \n",
      "\n",
      "Fold: 18  Epoch: 314  Training loss = 5.0604  Validation loss = 1.4778  \n",
      "\n",
      "Fold: 18  Epoch: 315  Training loss = 5.0598  Validation loss = 1.4774  \n",
      "\n",
      "Fold: 18  Epoch: 316  Training loss = 5.0591  Validation loss = 1.4769  \n",
      "\n",
      "Fold: 18  Epoch: 317  Training loss = 5.0585  Validation loss = 1.4765  \n",
      "\n",
      "Fold: 18  Epoch: 318  Training loss = 5.0580  Validation loss = 1.4761  \n",
      "\n",
      "Fold: 18  Epoch: 319  Training loss = 5.0575  Validation loss = 1.4758  \n",
      "\n",
      "Fold: 18  Epoch: 320  Training loss = 5.0569  Validation loss = 1.4754  \n",
      "\n",
      "Fold: 18  Epoch: 321  Training loss = 5.0563  Validation loss = 1.4750  \n",
      "\n",
      "Fold: 18  Epoch: 322  Training loss = 5.0556  Validation loss = 1.4745  \n",
      "\n",
      "Fold: 18  Epoch: 323  Training loss = 5.0549  Validation loss = 1.4741  \n",
      "\n",
      "Fold: 18  Epoch: 324  Training loss = 5.0543  Validation loss = 1.4736  \n",
      "\n",
      "Fold: 18  Epoch: 325  Training loss = 5.0538  Validation loss = 1.4733  \n",
      "\n",
      "Fold: 18  Epoch: 326  Training loss = 5.0532  Validation loss = 1.4729  \n",
      "\n",
      "Fold: 18  Epoch: 327  Training loss = 5.0528  Validation loss = 1.4726  \n",
      "\n",
      "Fold: 18  Epoch: 328  Training loss = 5.0521  Validation loss = 1.4721  \n",
      "\n",
      "Fold: 18  Epoch: 329  Training loss = 5.0515  Validation loss = 1.4716  \n",
      "\n",
      "Fold: 18  Epoch: 330  Training loss = 5.0508  Validation loss = 1.4712  \n",
      "\n",
      "Fold: 18  Epoch: 331  Training loss = 5.0503  Validation loss = 1.4708  \n",
      "\n",
      "Fold: 18  Epoch: 332  Training loss = 5.0496  Validation loss = 1.4704  \n",
      "\n",
      "Fold: 18  Epoch: 333  Training loss = 5.0490  Validation loss = 1.4699  \n",
      "\n",
      "Fold: 18  Epoch: 334  Training loss = 5.0484  Validation loss = 1.4695  \n",
      "\n",
      "Fold: 18  Epoch: 335  Training loss = 5.0480  Validation loss = 1.4692  \n",
      "\n",
      "Fold: 18  Epoch: 336  Training loss = 5.0474  Validation loss = 1.4688  \n",
      "\n",
      "Fold: 18  Epoch: 337  Training loss = 5.0468  Validation loss = 1.4684  \n",
      "\n",
      "Fold: 18  Epoch: 338  Training loss = 5.0463  Validation loss = 1.4680  \n",
      "\n",
      "Fold: 18  Epoch: 339  Training loss = 5.0456  Validation loss = 1.4676  \n",
      "\n",
      "Fold: 18  Epoch: 340  Training loss = 5.0452  Validation loss = 1.4673  \n",
      "\n",
      "Fold: 18  Epoch: 341  Training loss = 5.0446  Validation loss = 1.4669  \n",
      "\n",
      "Fold: 18  Epoch: 342  Training loss = 5.0440  Validation loss = 1.4665  \n",
      "\n",
      "Fold: 18  Epoch: 343  Training loss = 5.0434  Validation loss = 1.4661  \n",
      "\n",
      "Fold: 18  Epoch: 344  Training loss = 5.0429  Validation loss = 1.4657  \n",
      "\n",
      "Fold: 18  Epoch: 345  Training loss = 5.0423  Validation loss = 1.4654  \n",
      "\n",
      "Fold: 18  Epoch: 346  Training loss = 5.0417  Validation loss = 1.4650  \n",
      "\n",
      "Fold: 18  Epoch: 347  Training loss = 5.0411  Validation loss = 1.4646  \n",
      "\n",
      "Fold: 18  Epoch: 348  Training loss = 5.0405  Validation loss = 1.4642  \n",
      "\n",
      "Fold: 18  Epoch: 349  Training loss = 5.0400  Validation loss = 1.4638  \n",
      "\n",
      "Fold: 18  Epoch: 350  Training loss = 5.0394  Validation loss = 1.4634  \n",
      "\n",
      "Fold: 18  Epoch: 351  Training loss = 5.0389  Validation loss = 1.4631  \n",
      "\n",
      "Fold: 18  Epoch: 352  Training loss = 5.0383  Validation loss = 1.4626  \n",
      "\n",
      "Fold: 18  Epoch: 353  Training loss = 5.0377  Validation loss = 1.4622  \n",
      "\n",
      "Fold: 18  Epoch: 354  Training loss = 5.0372  Validation loss = 1.4619  \n",
      "\n",
      "Fold: 18  Epoch: 355  Training loss = 5.0366  Validation loss = 1.4615  \n",
      "\n",
      "Fold: 18  Epoch: 356  Training loss = 5.0360  Validation loss = 1.4611  \n",
      "\n",
      "Fold: 18  Epoch: 357  Training loss = 5.0354  Validation loss = 1.4607  \n",
      "\n",
      "Fold: 18  Epoch: 358  Training loss = 5.0348  Validation loss = 1.4603  \n",
      "\n",
      "Fold: 18  Epoch: 359  Training loss = 5.0341  Validation loss = 1.4598  \n",
      "\n",
      "Fold: 18  Epoch: 360  Training loss = 5.0337  Validation loss = 1.4595  \n",
      "\n",
      "Fold: 18  Epoch: 361  Training loss = 5.0330  Validation loss = 1.4591  \n",
      "\n",
      "Fold: 18  Epoch: 362  Training loss = 5.0324  Validation loss = 1.4586  \n",
      "\n",
      "Fold: 18  Epoch: 363  Training loss = 5.0318  Validation loss = 1.4582  \n",
      "\n",
      "Fold: 18  Epoch: 364  Training loss = 5.0312  Validation loss = 1.4578  \n",
      "\n",
      "Fold: 18  Epoch: 365  Training loss = 5.0306  Validation loss = 1.4574  \n",
      "\n",
      "Fold: 18  Epoch: 366  Training loss = 5.0300  Validation loss = 1.4570  \n",
      "\n",
      "Fold: 18  Epoch: 367  Training loss = 5.0294  Validation loss = 1.4566  \n",
      "\n",
      "Fold: 18  Epoch: 368  Training loss = 5.0288  Validation loss = 1.4562  \n",
      "\n",
      "Fold: 18  Epoch: 369  Training loss = 5.0282  Validation loss = 1.4558  \n",
      "\n",
      "Fold: 18  Epoch: 370  Training loss = 5.0275  Validation loss = 1.4553  \n",
      "\n",
      "Fold: 18  Epoch: 371  Training loss = 5.0270  Validation loss = 1.4549  \n",
      "\n",
      "Fold: 18  Epoch: 372  Training loss = 5.0263  Validation loss = 1.4545  \n",
      "\n",
      "Fold: 18  Epoch: 373  Training loss = 5.0256  Validation loss = 1.4541  \n",
      "\n",
      "Fold: 18  Epoch: 374  Training loss = 5.0252  Validation loss = 1.4538  \n",
      "\n",
      "Fold: 18  Epoch: 375  Training loss = 5.0246  Validation loss = 1.4533  \n",
      "\n",
      "Fold: 18  Epoch: 376  Training loss = 5.0240  Validation loss = 1.4530  \n",
      "\n",
      "Fold: 18  Epoch: 377  Training loss = 5.0234  Validation loss = 1.4525  \n",
      "\n",
      "Fold: 18  Epoch: 378  Training loss = 5.0228  Validation loss = 1.4521  \n",
      "\n",
      "Fold: 18  Epoch: 379  Training loss = 5.0222  Validation loss = 1.4517  \n",
      "\n",
      "Fold: 18  Epoch: 380  Training loss = 5.0216  Validation loss = 1.4513  \n",
      "\n",
      "Fold: 18  Epoch: 381  Training loss = 5.0211  Validation loss = 1.4510  \n",
      "\n",
      "Fold: 18  Epoch: 382  Training loss = 5.0205  Validation loss = 1.4506  \n",
      "\n",
      "Fold: 18  Epoch: 383  Training loss = 5.0199  Validation loss = 1.4502  \n",
      "\n",
      "Fold: 18  Epoch: 384  Training loss = 5.0193  Validation loss = 1.4498  \n",
      "\n",
      "Fold: 18  Epoch: 385  Training loss = 5.0188  Validation loss = 1.4494  \n",
      "\n",
      "Fold: 18  Epoch: 386  Training loss = 5.0182  Validation loss = 1.4490  \n",
      "\n",
      "Fold: 18  Epoch: 387  Training loss = 5.0176  Validation loss = 1.4486  \n",
      "\n",
      "Fold: 18  Epoch: 388  Training loss = 5.0171  Validation loss = 1.4482  \n",
      "\n",
      "Fold: 18  Epoch: 389  Training loss = 5.0165  Validation loss = 1.4478  \n",
      "\n",
      "Fold: 18  Epoch: 390  Training loss = 5.0159  Validation loss = 1.4474  \n",
      "\n",
      "Fold: 18  Epoch: 391  Training loss = 5.0153  Validation loss = 1.4470  \n",
      "\n",
      "Fold: 18  Epoch: 392  Training loss = 5.0147  Validation loss = 1.4466  \n",
      "\n",
      "Fold: 18  Epoch: 393  Training loss = 5.0141  Validation loss = 1.4462  \n",
      "\n",
      "Fold: 18  Epoch: 394  Training loss = 5.0135  Validation loss = 1.4458  \n",
      "\n",
      "Fold: 18  Epoch: 395  Training loss = 5.0129  Validation loss = 1.4454  \n",
      "\n",
      "Fold: 18  Epoch: 396  Training loss = 5.0123  Validation loss = 1.4449  \n",
      "\n",
      "Fold: 18  Epoch: 397  Training loss = 5.0118  Validation loss = 1.4446  \n",
      "\n",
      "Fold: 18  Epoch: 398  Training loss = 5.0112  Validation loss = 1.4442  \n",
      "\n",
      "Fold: 18  Epoch: 399  Training loss = 5.0106  Validation loss = 1.4438  \n",
      "\n",
      "Fold: 18  Epoch: 400  Training loss = 5.0100  Validation loss = 1.4434  \n",
      "\n",
      "Fold: 18  Epoch: 401  Training loss = 5.0094  Validation loss = 1.4430  \n",
      "\n",
      "Fold: 18  Epoch: 402  Training loss = 5.0087  Validation loss = 1.4425  \n",
      "\n",
      "Fold: 18  Epoch: 403  Training loss = 5.0082  Validation loss = 1.4422  \n",
      "\n",
      "Fold: 18  Epoch: 404  Training loss = 5.0076  Validation loss = 1.4417  \n",
      "\n",
      "Fold: 18  Epoch: 405  Training loss = 5.0070  Validation loss = 1.4413  \n",
      "\n",
      "Fold: 18  Epoch: 406  Training loss = 5.0066  Validation loss = 1.4411  \n",
      "\n",
      "Fold: 18  Epoch: 407  Training loss = 5.0059  Validation loss = 1.4406  \n",
      "\n",
      "Fold: 18  Epoch: 408  Training loss = 5.0054  Validation loss = 1.4402  \n",
      "\n",
      "Fold: 18  Epoch: 409  Training loss = 5.0048  Validation loss = 1.4399  \n",
      "\n",
      "Fold: 18  Epoch: 410  Training loss = 5.0043  Validation loss = 1.4395  \n",
      "\n",
      "Fold: 18  Epoch: 411  Training loss = 5.0036  Validation loss = 1.4390  \n",
      "\n",
      "Fold: 18  Epoch: 412  Training loss = 5.0031  Validation loss = 1.4387  \n",
      "\n",
      "Fold: 18  Epoch: 413  Training loss = 5.0025  Validation loss = 1.4383  \n",
      "\n",
      "Fold: 18  Epoch: 414  Training loss = 5.0020  Validation loss = 1.4379  \n",
      "\n",
      "Fold: 18  Epoch: 415  Training loss = 5.0014  Validation loss = 1.4375  \n",
      "\n",
      "Fold: 18  Epoch: 416  Training loss = 5.0009  Validation loss = 1.4371  \n",
      "\n",
      "Fold: 18  Epoch: 417  Training loss = 5.0003  Validation loss = 1.4368  \n",
      "\n",
      "Fold: 18  Epoch: 418  Training loss = 4.9998  Validation loss = 1.4364  \n",
      "\n",
      "Fold: 18  Epoch: 419  Training loss = 4.9992  Validation loss = 1.4360  \n",
      "\n",
      "Fold: 18  Epoch: 420  Training loss = 4.9986  Validation loss = 1.4356  \n",
      "\n",
      "Fold: 18  Epoch: 421  Training loss = 4.9981  Validation loss = 1.4352  \n",
      "\n",
      "Fold: 18  Epoch: 422  Training loss = 4.9976  Validation loss = 1.4349  \n",
      "\n",
      "Fold: 18  Epoch: 423  Training loss = 4.9969  Validation loss = 1.4345  \n",
      "\n",
      "Fold: 18  Epoch: 424  Training loss = 4.9963  Validation loss = 1.4341  \n",
      "\n",
      "Fold: 18  Epoch: 425  Training loss = 4.9958  Validation loss = 1.4337  \n",
      "\n",
      "Fold: 18  Epoch: 426  Training loss = 4.9952  Validation loss = 1.4333  \n",
      "\n",
      "Fold: 18  Epoch: 427  Training loss = 4.9945  Validation loss = 1.4328  \n",
      "\n",
      "Fold: 18  Epoch: 428  Training loss = 4.9939  Validation loss = 1.4324  \n",
      "\n",
      "Fold: 18  Epoch: 429  Training loss = 4.9933  Validation loss = 1.4320  \n",
      "\n",
      "Fold: 18  Epoch: 430  Training loss = 4.9927  Validation loss = 1.4316  \n",
      "\n",
      "Fold: 18  Epoch: 431  Training loss = 4.9921  Validation loss = 1.4313  \n",
      "\n",
      "Fold: 18  Epoch: 432  Training loss = 4.9916  Validation loss = 1.4309  \n",
      "\n",
      "Fold: 18  Epoch: 433  Training loss = 4.9910  Validation loss = 1.4306  \n",
      "\n",
      "Fold: 18  Epoch: 434  Training loss = 4.9905  Validation loss = 1.4302  \n",
      "\n",
      "Fold: 18  Epoch: 435  Training loss = 4.9900  Validation loss = 1.4298  \n",
      "\n",
      "Fold: 18  Epoch: 436  Training loss = 4.9894  Validation loss = 1.4294  \n",
      "\n",
      "Fold: 18  Epoch: 437  Training loss = 4.9889  Validation loss = 1.4290  \n",
      "\n",
      "Fold: 18  Epoch: 438  Training loss = 4.9882  Validation loss = 1.4286  \n",
      "\n",
      "Fold: 18  Epoch: 439  Training loss = 4.9875  Validation loss = 1.4281  \n",
      "\n",
      "Fold: 18  Epoch: 440  Training loss = 4.9869  Validation loss = 1.4277  \n",
      "\n",
      "Fold: 18  Epoch: 441  Training loss = 4.9863  Validation loss = 1.4273  \n",
      "\n",
      "Fold: 18  Epoch: 442  Training loss = 4.9858  Validation loss = 1.4270  \n",
      "\n",
      "Fold: 18  Epoch: 443  Training loss = 4.9853  Validation loss = 1.4266  \n",
      "\n",
      "Fold: 18  Epoch: 444  Training loss = 4.9846  Validation loss = 1.4261  \n",
      "\n",
      "Fold: 18  Epoch: 445  Training loss = 4.9841  Validation loss = 1.4258  \n",
      "\n",
      "Fold: 18  Epoch: 446  Training loss = 4.9836  Validation loss = 1.4254  \n",
      "\n",
      "Fold: 18  Epoch: 447  Training loss = 4.9831  Validation loss = 1.4251  \n",
      "\n",
      "Fold: 18  Epoch: 448  Training loss = 4.9825  Validation loss = 1.4247  \n",
      "\n",
      "Fold: 18  Epoch: 449  Training loss = 4.9819  Validation loss = 1.4243  \n",
      "\n",
      "Fold: 18  Epoch: 450  Training loss = 4.9815  Validation loss = 1.4240  \n",
      "\n",
      "Fold: 18  Epoch: 451  Training loss = 4.9809  Validation loss = 1.4236  \n",
      "\n",
      "Fold: 18  Epoch: 452  Training loss = 4.9804  Validation loss = 1.4232  \n",
      "\n",
      "Fold: 18  Epoch: 453  Training loss = 4.9798  Validation loss = 1.4228  \n",
      "\n",
      "Fold: 18  Epoch: 454  Training loss = 4.9792  Validation loss = 1.4224  \n",
      "\n",
      "Fold: 18  Epoch: 455  Training loss = 4.9787  Validation loss = 1.4220  \n",
      "\n",
      "Fold: 18  Epoch: 456  Training loss = 4.9779  Validation loss = 1.4216  \n",
      "\n",
      "Fold: 18  Epoch: 457  Training loss = 4.9775  Validation loss = 1.4212  \n",
      "\n",
      "Fold: 18  Epoch: 458  Training loss = 4.9768  Validation loss = 1.4209  \n",
      "\n",
      "Fold: 18  Epoch: 459  Training loss = 4.9762  Validation loss = 1.4205  \n",
      "\n",
      "Fold: 18  Epoch: 460  Training loss = 4.9756  Validation loss = 1.4200  \n",
      "\n",
      "Fold: 18  Epoch: 461  Training loss = 4.9751  Validation loss = 1.4197  \n",
      "\n",
      "Fold: 18  Epoch: 462  Training loss = 4.9745  Validation loss = 1.4193  \n",
      "\n",
      "Fold: 18  Epoch: 463  Training loss = 4.9739  Validation loss = 1.4188  \n",
      "\n",
      "Fold: 18  Epoch: 464  Training loss = 4.9733  Validation loss = 1.4184  \n",
      "\n",
      "Fold: 18  Epoch: 465  Training loss = 4.9728  Validation loss = 1.4180  \n",
      "\n",
      "Fold: 18  Epoch: 466  Training loss = 4.9723  Validation loss = 1.4177  \n",
      "\n",
      "Fold: 18  Epoch: 467  Training loss = 4.9718  Validation loss = 1.4173  \n",
      "\n",
      "Fold: 18  Epoch: 468  Training loss = 4.9711  Validation loss = 1.4169  \n",
      "\n",
      "Fold: 18  Epoch: 469  Training loss = 4.9706  Validation loss = 1.4166  \n",
      "\n",
      "Fold: 18  Epoch: 470  Training loss = 4.9700  Validation loss = 1.4162  \n",
      "\n",
      "Fold: 18  Epoch: 471  Training loss = 4.9694  Validation loss = 1.4158  \n",
      "\n",
      "Fold: 18  Epoch: 472  Training loss = 4.9689  Validation loss = 1.4155  \n",
      "\n",
      "Fold: 18  Epoch: 473  Training loss = 4.9684  Validation loss = 1.4151  \n",
      "\n",
      "Fold: 18  Epoch: 474  Training loss = 4.9678  Validation loss = 1.4147  \n",
      "\n",
      "Fold: 18  Epoch: 475  Training loss = 4.9672  Validation loss = 1.4143  \n",
      "\n",
      "Fold: 18  Epoch: 476  Training loss = 4.9667  Validation loss = 1.4140  \n",
      "\n",
      "Fold: 18  Epoch: 477  Training loss = 4.9662  Validation loss = 1.4136  \n",
      "\n",
      "Fold: 18  Epoch: 478  Training loss = 4.9657  Validation loss = 1.4133  \n",
      "\n",
      "Fold: 18  Epoch: 479  Training loss = 4.9651  Validation loss = 1.4129  \n",
      "\n",
      "Fold: 18  Epoch: 480  Training loss = 4.9646  Validation loss = 1.4126  \n",
      "\n",
      "Fold: 18  Epoch: 481  Training loss = 4.9641  Validation loss = 1.4123  \n",
      "\n",
      "Fold: 18  Epoch: 482  Training loss = 4.9635  Validation loss = 1.4119  \n",
      "\n",
      "Fold: 18  Epoch: 483  Training loss = 4.9629  Validation loss = 1.4115  \n",
      "\n",
      "Fold: 18  Epoch: 484  Training loss = 4.9624  Validation loss = 1.4111  \n",
      "\n",
      "Fold: 18  Epoch: 485  Training loss = 4.9619  Validation loss = 1.4108  \n",
      "\n",
      "Fold: 18  Epoch: 486  Training loss = 4.9613  Validation loss = 1.4103  \n",
      "\n",
      "Fold: 18  Epoch: 487  Training loss = 4.9607  Validation loss = 1.4099  \n",
      "\n",
      "Fold: 18  Epoch: 488  Training loss = 4.9601  Validation loss = 1.4095  \n",
      "\n",
      "Fold: 18  Epoch: 489  Training loss = 4.9595  Validation loss = 1.4091  \n",
      "\n",
      "Fold: 18  Epoch: 490  Training loss = 4.9589  Validation loss = 1.4087  \n",
      "\n",
      "Fold: 18  Epoch: 491  Training loss = 4.9584  Validation loss = 1.4084  \n",
      "\n",
      "Fold: 18  Epoch: 492  Training loss = 4.9579  Validation loss = 1.4080  \n",
      "\n",
      "Fold: 18  Epoch: 493  Training loss = 4.9574  Validation loss = 1.4077  \n",
      "\n",
      "Fold: 18  Epoch: 494  Training loss = 4.9569  Validation loss = 1.4073  \n",
      "\n",
      "Fold: 18  Epoch: 495  Training loss = 4.9563  Validation loss = 1.4070  \n",
      "\n",
      "Fold: 18  Epoch: 496  Training loss = 4.9558  Validation loss = 1.4066  \n",
      "\n",
      "Fold: 18  Epoch: 497  Training loss = 4.9552  Validation loss = 1.4062  \n",
      "\n",
      "Fold: 18  Epoch: 498  Training loss = 4.9547  Validation loss = 1.4059  \n",
      "\n",
      "Fold: 18  Epoch: 499  Training loss = 4.9542  Validation loss = 1.4055  \n",
      "\n",
      "Fold: 18  Epoch: 500  Training loss = 4.9537  Validation loss = 1.4052  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 500  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 4.9549  Validation loss = 2.2666  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 4.9542  Validation loss = 2.2665  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 4.9536  Validation loss = 2.2663  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 4.9531  Validation loss = 2.2662  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 4.9525  Validation loss = 2.2662  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 4.9519  Validation loss = 2.2661  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 4.9514  Validation loss = 2.2659  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 4.9508  Validation loss = 2.2658  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 4.9503  Validation loss = 2.2657  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 4.9497  Validation loss = 2.2656  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 4.9490  Validation loss = 2.2655  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 4.9484  Validation loss = 2.2654  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 4.9478  Validation loss = 2.2653  \n",
      "\n",
      "Fold: 19  Epoch: 14  Training loss = 4.9473  Validation loss = 2.2651  \n",
      "\n",
      "Fold: 19  Epoch: 15  Training loss = 4.9468  Validation loss = 2.2650  \n",
      "\n",
      "Fold: 19  Epoch: 16  Training loss = 4.9461  Validation loss = 2.2649  \n",
      "\n",
      "Fold: 19  Epoch: 17  Training loss = 4.9456  Validation loss = 2.2648  \n",
      "\n",
      "Fold: 19  Epoch: 18  Training loss = 4.9449  Validation loss = 2.2646  \n",
      "\n",
      "Fold: 19  Epoch: 19  Training loss = 4.9444  Validation loss = 2.2645  \n",
      "\n",
      "Fold: 19  Epoch: 20  Training loss = 4.9437  Validation loss = 2.2644  \n",
      "\n",
      "Fold: 19  Epoch: 21  Training loss = 4.9431  Validation loss = 2.2642  \n",
      "\n",
      "Fold: 19  Epoch: 22  Training loss = 4.9425  Validation loss = 2.2641  \n",
      "\n",
      "Fold: 19  Epoch: 23  Training loss = 4.9419  Validation loss = 2.2640  \n",
      "\n",
      "Fold: 19  Epoch: 24  Training loss = 4.9413  Validation loss = 2.2639  \n",
      "\n",
      "Fold: 19  Epoch: 25  Training loss = 4.9407  Validation loss = 2.2638  \n",
      "\n",
      "Fold: 19  Epoch: 26  Training loss = 4.9403  Validation loss = 2.2637  \n",
      "\n",
      "Fold: 19  Epoch: 27  Training loss = 4.9396  Validation loss = 2.2635  \n",
      "\n",
      "Fold: 19  Epoch: 28  Training loss = 4.9391  Validation loss = 2.2634  \n",
      "\n",
      "Fold: 19  Epoch: 29  Training loss = 4.9385  Validation loss = 2.2633  \n",
      "\n",
      "Fold: 19  Epoch: 30  Training loss = 4.9379  Validation loss = 2.2632  \n",
      "\n",
      "Fold: 19  Epoch: 31  Training loss = 4.9372  Validation loss = 2.2630  \n",
      "\n",
      "Fold: 19  Epoch: 32  Training loss = 4.9366  Validation loss = 2.2629  \n",
      "\n",
      "Fold: 19  Epoch: 33  Training loss = 4.9360  Validation loss = 2.2628  \n",
      "\n",
      "Fold: 19  Epoch: 34  Training loss = 4.9354  Validation loss = 2.2626  \n",
      "\n",
      "Fold: 19  Epoch: 35  Training loss = 4.9348  Validation loss = 2.2625  \n",
      "\n",
      "Fold: 19  Epoch: 36  Training loss = 4.9341  Validation loss = 2.2623  \n",
      "\n",
      "Fold: 19  Epoch: 37  Training loss = 4.9336  Validation loss = 2.2623  \n",
      "\n",
      "Fold: 19  Epoch: 38  Training loss = 4.9330  Validation loss = 2.2622  \n",
      "\n",
      "Fold: 19  Epoch: 39  Training loss = 4.9325  Validation loss = 2.2621  \n",
      "\n",
      "Fold: 19  Epoch: 40  Training loss = 4.9319  Validation loss = 2.2619  \n",
      "\n",
      "Fold: 19  Epoch: 41  Training loss = 4.9313  Validation loss = 2.2618  \n",
      "\n",
      "Fold: 19  Epoch: 42  Training loss = 4.9307  Validation loss = 2.2616  \n",
      "\n",
      "Fold: 19  Epoch: 43  Training loss = 4.9300  Validation loss = 2.2615  \n",
      "\n",
      "Fold: 19  Epoch: 44  Training loss = 4.9294  Validation loss = 2.2614  \n",
      "\n",
      "Fold: 19  Epoch: 45  Training loss = 4.9289  Validation loss = 2.2613  \n",
      "\n",
      "Fold: 19  Epoch: 46  Training loss = 4.9283  Validation loss = 2.2612  \n",
      "\n",
      "Fold: 19  Epoch: 47  Training loss = 4.9277  Validation loss = 2.2611  \n",
      "\n",
      "Fold: 19  Epoch: 48  Training loss = 4.9270  Validation loss = 2.2610  \n",
      "\n",
      "Fold: 19  Epoch: 49  Training loss = 4.9265  Validation loss = 2.2609  \n",
      "\n",
      "Fold: 19  Epoch: 50  Training loss = 4.9258  Validation loss = 2.2608  \n",
      "\n",
      "Fold: 19  Epoch: 51  Training loss = 4.9252  Validation loss = 2.2607  \n",
      "\n",
      "Fold: 19  Epoch: 52  Training loss = 4.9247  Validation loss = 2.2606  \n",
      "\n",
      "Fold: 19  Epoch: 53  Training loss = 4.9241  Validation loss = 2.2605  \n",
      "\n",
      "Fold: 19  Epoch: 54  Training loss = 4.9236  Validation loss = 2.2604  \n",
      "\n",
      "Fold: 19  Epoch: 55  Training loss = 4.9230  Validation loss = 2.2603  \n",
      "\n",
      "Fold: 19  Epoch: 56  Training loss = 4.9223  Validation loss = 2.2601  \n",
      "\n",
      "Fold: 19  Epoch: 57  Training loss = 4.9218  Validation loss = 2.2600  \n",
      "\n",
      "Fold: 19  Epoch: 58  Training loss = 4.9214  Validation loss = 2.2599  \n",
      "\n",
      "Fold: 19  Epoch: 59  Training loss = 4.9209  Validation loss = 2.2599  \n",
      "\n",
      "Fold: 19  Epoch: 60  Training loss = 4.9203  Validation loss = 2.2597  \n",
      "\n",
      "Fold: 19  Epoch: 61  Training loss = 4.9198  Validation loss = 2.2596  \n",
      "\n",
      "Fold: 19  Epoch: 62  Training loss = 4.9192  Validation loss = 2.2596  \n",
      "\n",
      "Fold: 19  Epoch: 63  Training loss = 4.9186  Validation loss = 2.2594  \n",
      "\n",
      "Fold: 19  Epoch: 64  Training loss = 4.9180  Validation loss = 2.2594  \n",
      "\n",
      "Fold: 19  Epoch: 65  Training loss = 4.9174  Validation loss = 2.2593  \n",
      "\n",
      "Fold: 19  Epoch: 66  Training loss = 4.9169  Validation loss = 2.2592  \n",
      "\n",
      "Fold: 19  Epoch: 67  Training loss = 4.9163  Validation loss = 2.2591  \n",
      "\n",
      "Fold: 19  Epoch: 68  Training loss = 4.9157  Validation loss = 2.2591  \n",
      "\n",
      "Fold: 19  Epoch: 69  Training loss = 4.9152  Validation loss = 2.2589  \n",
      "\n",
      "Fold: 19  Epoch: 70  Training loss = 4.9145  Validation loss = 2.2588  \n",
      "\n",
      "Fold: 19  Epoch: 71  Training loss = 4.9140  Validation loss = 2.2587  \n",
      "\n",
      "Fold: 19  Epoch: 72  Training loss = 4.9134  Validation loss = 2.2585  \n",
      "\n",
      "Fold: 19  Epoch: 73  Training loss = 4.9127  Validation loss = 2.2584  \n",
      "\n",
      "Fold: 19  Epoch: 74  Training loss = 4.9123  Validation loss = 2.2583  \n",
      "\n",
      "Fold: 19  Epoch: 75  Training loss = 4.9117  Validation loss = 2.2582  \n",
      "\n",
      "Fold: 19  Epoch: 76  Training loss = 4.9111  Validation loss = 2.2581  \n",
      "\n",
      "Fold: 19  Epoch: 77  Training loss = 4.9105  Validation loss = 2.2579  \n",
      "\n",
      "Fold: 19  Epoch: 78  Training loss = 4.9099  Validation loss = 2.2578  \n",
      "\n",
      "Fold: 19  Epoch: 79  Training loss = 4.9093  Validation loss = 2.2577  \n",
      "\n",
      "Fold: 19  Epoch: 80  Training loss = 4.9086  Validation loss = 2.2575  \n",
      "\n",
      "Fold: 19  Epoch: 81  Training loss = 4.9080  Validation loss = 2.2573  \n",
      "\n",
      "Fold: 19  Epoch: 82  Training loss = 4.9074  Validation loss = 2.2572  \n",
      "\n",
      "Fold: 19  Epoch: 83  Training loss = 4.9067  Validation loss = 2.2570  \n",
      "\n",
      "Fold: 19  Epoch: 84  Training loss = 4.9062  Validation loss = 2.2569  \n",
      "\n",
      "Fold: 19  Epoch: 85  Training loss = 4.9056  Validation loss = 2.2568  \n",
      "\n",
      "Fold: 19  Epoch: 86  Training loss = 4.9050  Validation loss = 2.2567  \n",
      "\n",
      "Fold: 19  Epoch: 87  Training loss = 4.9044  Validation loss = 2.2566  \n",
      "\n",
      "Fold: 19  Epoch: 88  Training loss = 4.9038  Validation loss = 2.2565  \n",
      "\n",
      "Fold: 19  Epoch: 89  Training loss = 4.9032  Validation loss = 2.2564  \n",
      "\n",
      "Fold: 19  Epoch: 90  Training loss = 4.9026  Validation loss = 2.2563  \n",
      "\n",
      "Fold: 19  Epoch: 91  Training loss = 4.9021  Validation loss = 2.2562  \n",
      "\n",
      "Fold: 19  Epoch: 92  Training loss = 4.9015  Validation loss = 2.2561  \n",
      "\n",
      "Fold: 19  Epoch: 93  Training loss = 4.9009  Validation loss = 2.2559  \n",
      "\n",
      "Fold: 19  Epoch: 94  Training loss = 4.9003  Validation loss = 2.2558  \n",
      "\n",
      "Fold: 19  Epoch: 95  Training loss = 4.8999  Validation loss = 2.2558  \n",
      "\n",
      "Fold: 19  Epoch: 96  Training loss = 4.8994  Validation loss = 2.2557  \n",
      "\n",
      "Fold: 19  Epoch: 97  Training loss = 4.8988  Validation loss = 2.2556  \n",
      "\n",
      "Fold: 19  Epoch: 98  Training loss = 4.8983  Validation loss = 2.2555  \n",
      "\n",
      "Fold: 19  Epoch: 99  Training loss = 4.8977  Validation loss = 2.2554  \n",
      "\n",
      "Fold: 19  Epoch: 100  Training loss = 4.8971  Validation loss = 2.2553  \n",
      "\n",
      "Fold: 19  Epoch: 101  Training loss = 4.8966  Validation loss = 2.2551  \n",
      "\n",
      "Fold: 19  Epoch: 102  Training loss = 4.8961  Validation loss = 2.2550  \n",
      "\n",
      "Fold: 19  Epoch: 103  Training loss = 4.8956  Validation loss = 2.2549  \n",
      "\n",
      "Fold: 19  Epoch: 104  Training loss = 4.8950  Validation loss = 2.2548  \n",
      "\n",
      "Fold: 19  Epoch: 105  Training loss = 4.8944  Validation loss = 2.2547  \n",
      "\n",
      "Fold: 19  Epoch: 106  Training loss = 4.8939  Validation loss = 2.2546  \n",
      "\n",
      "Fold: 19  Epoch: 107  Training loss = 4.8934  Validation loss = 2.2545  \n",
      "\n",
      "Fold: 19  Epoch: 108  Training loss = 4.8928  Validation loss = 2.2544  \n",
      "\n",
      "Fold: 19  Epoch: 109  Training loss = 4.8923  Validation loss = 2.2543  \n",
      "\n",
      "Fold: 19  Epoch: 110  Training loss = 4.8917  Validation loss = 2.2542  \n",
      "\n",
      "Fold: 19  Epoch: 111  Training loss = 4.8910  Validation loss = 2.2541  \n",
      "\n",
      "Fold: 19  Epoch: 112  Training loss = 4.8905  Validation loss = 2.2540  \n",
      "\n",
      "Fold: 19  Epoch: 113  Training loss = 4.8899  Validation loss = 2.2539  \n",
      "\n",
      "Fold: 19  Epoch: 114  Training loss = 4.8893  Validation loss = 2.2538  \n",
      "\n",
      "Fold: 19  Epoch: 115  Training loss = 4.8888  Validation loss = 2.2537  \n",
      "\n",
      "Fold: 19  Epoch: 116  Training loss = 4.8881  Validation loss = 2.2535  \n",
      "\n",
      "Fold: 19  Epoch: 117  Training loss = 4.8875  Validation loss = 2.2535  \n",
      "\n",
      "Fold: 19  Epoch: 118  Training loss = 4.8870  Validation loss = 2.2534  \n",
      "\n",
      "Fold: 19  Epoch: 119  Training loss = 4.8864  Validation loss = 2.2533  \n",
      "\n",
      "Fold: 19  Epoch: 120  Training loss = 4.8858  Validation loss = 2.2533  \n",
      "\n",
      "Fold: 19  Epoch: 121  Training loss = 4.8853  Validation loss = 2.2531  \n",
      "\n",
      "Fold: 19  Epoch: 122  Training loss = 4.8847  Validation loss = 2.2531  \n",
      "\n",
      "Fold: 19  Epoch: 123  Training loss = 4.8841  Validation loss = 2.2530  \n",
      "\n",
      "Fold: 19  Epoch: 124  Training loss = 4.8835  Validation loss = 2.2529  \n",
      "\n",
      "Fold: 19  Epoch: 125  Training loss = 4.8830  Validation loss = 2.2528  \n",
      "\n",
      "Fold: 19  Epoch: 126  Training loss = 4.8825  Validation loss = 2.2526  \n",
      "\n",
      "Fold: 19  Epoch: 127  Training loss = 4.8819  Validation loss = 2.2525  \n",
      "\n",
      "Fold: 19  Epoch: 128  Training loss = 4.8813  Validation loss = 2.2524  \n",
      "\n",
      "Fold: 19  Epoch: 129  Training loss = 4.8807  Validation loss = 2.2523  \n",
      "\n",
      "Fold: 19  Epoch: 130  Training loss = 4.8800  Validation loss = 2.2522  \n",
      "\n",
      "Fold: 19  Epoch: 131  Training loss = 4.8794  Validation loss = 2.2521  \n",
      "\n",
      "Fold: 19  Epoch: 132  Training loss = 4.8788  Validation loss = 2.2520  \n",
      "\n",
      "Fold: 19  Epoch: 133  Training loss = 4.8782  Validation loss = 2.2520  \n",
      "\n",
      "Fold: 19  Epoch: 134  Training loss = 4.8777  Validation loss = 2.2519  \n",
      "\n",
      "Fold: 19  Epoch: 135  Training loss = 4.8772  Validation loss = 2.2519  \n",
      "\n",
      "Fold: 19  Epoch: 136  Training loss = 4.8767  Validation loss = 2.2518  \n",
      "\n",
      "Fold: 19  Epoch: 137  Training loss = 4.8761  Validation loss = 2.2518  \n",
      "\n",
      "Fold: 19  Epoch: 138  Training loss = 4.8756  Validation loss = 2.2517  \n",
      "\n",
      "Fold: 19  Epoch: 139  Training loss = 4.8751  Validation loss = 2.2516  \n",
      "\n",
      "Fold: 19  Epoch: 140  Training loss = 4.8746  Validation loss = 2.2516  \n",
      "\n",
      "Fold: 19  Epoch: 141  Training loss = 4.8739  Validation loss = 2.2515  \n",
      "\n",
      "Fold: 19  Epoch: 142  Training loss = 4.8732  Validation loss = 2.2514  \n",
      "\n",
      "Fold: 19  Epoch: 143  Training loss = 4.8725  Validation loss = 2.2513  \n",
      "\n",
      "Fold: 19  Epoch: 144  Training loss = 4.8719  Validation loss = 2.2511  \n",
      "\n",
      "Fold: 19  Epoch: 145  Training loss = 4.8714  Validation loss = 2.2510  \n",
      "\n",
      "Fold: 19  Epoch: 146  Training loss = 4.8709  Validation loss = 2.2509  \n",
      "\n",
      "Fold: 19  Epoch: 147  Training loss = 4.8704  Validation loss = 2.2508  \n",
      "\n",
      "Fold: 19  Epoch: 148  Training loss = 4.8697  Validation loss = 2.2506  \n",
      "\n",
      "Fold: 19  Epoch: 149  Training loss = 4.8692  Validation loss = 2.2505  \n",
      "\n",
      "Fold: 19  Epoch: 150  Training loss = 4.8686  Validation loss = 2.2504  \n",
      "\n",
      "Fold: 19  Epoch: 151  Training loss = 4.8680  Validation loss = 2.2503  \n",
      "\n",
      "Fold: 19  Epoch: 152  Training loss = 4.8675  Validation loss = 2.2501  \n",
      "\n",
      "Fold: 19  Epoch: 153  Training loss = 4.8669  Validation loss = 2.2500  \n",
      "\n",
      "Fold: 19  Epoch: 154  Training loss = 4.8662  Validation loss = 2.2499  \n",
      "\n",
      "Fold: 19  Epoch: 155  Training loss = 4.8657  Validation loss = 2.2498  \n",
      "\n",
      "Fold: 19  Epoch: 156  Training loss = 4.8652  Validation loss = 2.2497  \n",
      "\n",
      "Fold: 19  Epoch: 157  Training loss = 4.8646  Validation loss = 2.2496  \n",
      "\n",
      "Fold: 19  Epoch: 158  Training loss = 4.8641  Validation loss = 2.2496  \n",
      "\n",
      "Fold: 19  Epoch: 159  Training loss = 4.8636  Validation loss = 2.2495  \n",
      "\n",
      "Fold: 19  Epoch: 160  Training loss = 4.8629  Validation loss = 2.2494  \n",
      "\n",
      "Fold: 19  Epoch: 161  Training loss = 4.8624  Validation loss = 2.2493  \n",
      "\n",
      "Fold: 19  Epoch: 162  Training loss = 4.8619  Validation loss = 2.2492  \n",
      "\n",
      "Fold: 19  Epoch: 163  Training loss = 4.8613  Validation loss = 2.2491  \n",
      "\n",
      "Fold: 19  Epoch: 164  Training loss = 4.8608  Validation loss = 2.2491  \n",
      "\n",
      "Fold: 19  Epoch: 165  Training loss = 4.8603  Validation loss = 2.2491  \n",
      "\n",
      "Fold: 19  Epoch: 166  Training loss = 4.8597  Validation loss = 2.2490  \n",
      "\n",
      "Fold: 19  Epoch: 167  Training loss = 4.8590  Validation loss = 2.2488  \n",
      "\n",
      "Fold: 19  Epoch: 168  Training loss = 4.8584  Validation loss = 2.2488  \n",
      "\n",
      "Fold: 19  Epoch: 169  Training loss = 4.8580  Validation loss = 2.2487  \n",
      "\n",
      "Fold: 19  Epoch: 170  Training loss = 4.8573  Validation loss = 2.2486  \n",
      "\n",
      "Fold: 19  Epoch: 171  Training loss = 4.8568  Validation loss = 2.2486  \n",
      "\n",
      "Fold: 19  Epoch: 172  Training loss = 4.8563  Validation loss = 2.2485  \n",
      "\n",
      "Fold: 19  Epoch: 173  Training loss = 4.8558  Validation loss = 2.2484  \n",
      "\n",
      "Fold: 19  Epoch: 174  Training loss = 4.8553  Validation loss = 2.2483  \n",
      "\n",
      "Fold: 19  Epoch: 175  Training loss = 4.8546  Validation loss = 2.2482  \n",
      "\n",
      "Fold: 19  Epoch: 176  Training loss = 4.8540  Validation loss = 2.2481  \n",
      "\n",
      "Fold: 19  Epoch: 177  Training loss = 4.8535  Validation loss = 2.2480  \n",
      "\n",
      "Fold: 19  Epoch: 178  Training loss = 4.8530  Validation loss = 2.2479  \n",
      "\n",
      "Fold: 19  Epoch: 179  Training loss = 4.8524  Validation loss = 2.2478  \n",
      "\n",
      "Fold: 19  Epoch: 180  Training loss = 4.8520  Validation loss = 2.2477  \n",
      "\n",
      "Fold: 19  Epoch: 181  Training loss = 4.8513  Validation loss = 2.2476  \n",
      "\n",
      "Fold: 19  Epoch: 182  Training loss = 4.8507  Validation loss = 2.2475  \n",
      "\n",
      "Fold: 19  Epoch: 183  Training loss = 4.8502  Validation loss = 2.2474  \n",
      "\n",
      "Fold: 19  Epoch: 184  Training loss = 4.8497  Validation loss = 2.2473  \n",
      "\n",
      "Fold: 19  Epoch: 185  Training loss = 4.8492  Validation loss = 2.2472  \n",
      "\n",
      "Fold: 19  Epoch: 186  Training loss = 4.8487  Validation loss = 2.2471  \n",
      "\n",
      "Fold: 19  Epoch: 187  Training loss = 4.8481  Validation loss = 2.2470  \n",
      "\n",
      "Fold: 19  Epoch: 188  Training loss = 4.8475  Validation loss = 2.2469  \n",
      "\n",
      "Fold: 19  Epoch: 189  Training loss = 4.8469  Validation loss = 2.2468  \n",
      "\n",
      "Fold: 19  Epoch: 190  Training loss = 4.8463  Validation loss = 2.2467  \n",
      "\n",
      "Fold: 19  Epoch: 191  Training loss = 4.8457  Validation loss = 2.2465  \n",
      "\n",
      "Fold: 19  Epoch: 192  Training loss = 4.8450  Validation loss = 2.2464  \n",
      "\n",
      "Fold: 19  Epoch: 193  Training loss = 4.8444  Validation loss = 2.2464  \n",
      "\n",
      "Fold: 19  Epoch: 194  Training loss = 4.8439  Validation loss = 2.2463  \n",
      "\n",
      "Fold: 19  Epoch: 195  Training loss = 4.8434  Validation loss = 2.2463  \n",
      "\n",
      "Fold: 19  Epoch: 196  Training loss = 4.8428  Validation loss = 2.2462  \n",
      "\n",
      "Fold: 19  Epoch: 197  Training loss = 4.8422  Validation loss = 2.2462  \n",
      "\n",
      "Fold: 19  Epoch: 198  Training loss = 4.8416  Validation loss = 2.2461  \n",
      "\n",
      "Fold: 19  Epoch: 199  Training loss = 4.8411  Validation loss = 2.2459  \n",
      "\n",
      "Fold: 19  Epoch: 200  Training loss = 4.8405  Validation loss = 2.2458  \n",
      "\n",
      "Fold: 19  Epoch: 201  Training loss = 4.8400  Validation loss = 2.2458  \n",
      "\n",
      "Fold: 19  Epoch: 202  Training loss = 4.8394  Validation loss = 2.2457  \n",
      "\n",
      "Fold: 19  Epoch: 203  Training loss = 4.8390  Validation loss = 2.2456  \n",
      "\n",
      "Fold: 19  Epoch: 204  Training loss = 4.8384  Validation loss = 2.2456  \n",
      "\n",
      "Fold: 19  Epoch: 205  Training loss = 4.8377  Validation loss = 2.2455  \n",
      "\n",
      "Fold: 19  Epoch: 206  Training loss = 4.8372  Validation loss = 2.2455  \n",
      "\n",
      "Fold: 19  Epoch: 207  Training loss = 4.8365  Validation loss = 2.2454  \n",
      "\n",
      "Fold: 19  Epoch: 208  Training loss = 4.8359  Validation loss = 2.2453  \n",
      "\n",
      "Fold: 19  Epoch: 209  Training loss = 4.8354  Validation loss = 2.2452  \n",
      "\n",
      "Fold: 19  Epoch: 210  Training loss = 4.8350  Validation loss = 2.2452  \n",
      "\n",
      "Fold: 19  Epoch: 211  Training loss = 4.8342  Validation loss = 2.2451  \n",
      "\n",
      "Fold: 19  Epoch: 212  Training loss = 4.8338  Validation loss = 2.2450  \n",
      "\n",
      "Fold: 19  Epoch: 213  Training loss = 4.8332  Validation loss = 2.2450  \n",
      "\n",
      "Fold: 19  Epoch: 214  Training loss = 4.8326  Validation loss = 2.2448  \n",
      "\n",
      "Fold: 19  Epoch: 215  Training loss = 4.8320  Validation loss = 2.2448  \n",
      "\n",
      "Fold: 19  Epoch: 216  Training loss = 4.8314  Validation loss = 2.2446  \n",
      "\n",
      "Fold: 19  Epoch: 217  Training loss = 4.8308  Validation loss = 2.2446  \n",
      "\n",
      "Fold: 19  Epoch: 218  Training loss = 4.8303  Validation loss = 2.2445  \n",
      "\n",
      "Fold: 19  Epoch: 219  Training loss = 4.8298  Validation loss = 2.2444  \n",
      "\n",
      "Fold: 19  Epoch: 220  Training loss = 4.8292  Validation loss = 2.2443  \n",
      "\n",
      "Fold: 19  Epoch: 221  Training loss = 4.8287  Validation loss = 2.2443  \n",
      "\n",
      "Fold: 19  Epoch: 222  Training loss = 4.8281  Validation loss = 2.2443  \n",
      "\n",
      "Fold: 19  Epoch: 223  Training loss = 4.8275  Validation loss = 2.2442  \n",
      "\n",
      "Fold: 19  Epoch: 224  Training loss = 4.8269  Validation loss = 2.2441  \n",
      "\n",
      "Fold: 19  Epoch: 225  Training loss = 4.8264  Validation loss = 2.2440  \n",
      "\n",
      "Fold: 19  Epoch: 226  Training loss = 4.8258  Validation loss = 2.2439  \n",
      "\n",
      "Fold: 19  Epoch: 227  Training loss = 4.8252  Validation loss = 2.2439  \n",
      "\n",
      "Fold: 19  Epoch: 228  Training loss = 4.8246  Validation loss = 2.2438  \n",
      "\n",
      "Fold: 19  Epoch: 229  Training loss = 4.8240  Validation loss = 2.2437  \n",
      "\n",
      "Fold: 19  Epoch: 230  Training loss = 4.8234  Validation loss = 2.2436  \n",
      "\n",
      "Fold: 19  Epoch: 231  Training loss = 4.8228  Validation loss = 2.2436  \n",
      "\n",
      "Fold: 19  Epoch: 232  Training loss = 4.8223  Validation loss = 2.2435  \n",
      "\n",
      "Fold: 19  Epoch: 233  Training loss = 4.8218  Validation loss = 2.2434  \n",
      "\n",
      "Fold: 19  Epoch: 234  Training loss = 4.8212  Validation loss = 2.2433  \n",
      "\n",
      "Fold: 19  Epoch: 235  Training loss = 4.8207  Validation loss = 2.2433  \n",
      "\n",
      "Fold: 19  Epoch: 236  Training loss = 4.8201  Validation loss = 2.2432  \n",
      "\n",
      "Fold: 19  Epoch: 237  Training loss = 4.8196  Validation loss = 2.2431  \n",
      "\n",
      "Fold: 19  Epoch: 238  Training loss = 4.8192  Validation loss = 2.2431  \n",
      "\n",
      "Fold: 19  Epoch: 239  Training loss = 4.8187  Validation loss = 2.2430  \n",
      "\n",
      "Fold: 19  Epoch: 240  Training loss = 4.8182  Validation loss = 2.2430  \n",
      "\n",
      "Fold: 19  Epoch: 241  Training loss = 4.8176  Validation loss = 2.2429  \n",
      "\n",
      "Fold: 19  Epoch: 242  Training loss = 4.8171  Validation loss = 2.2428  \n",
      "\n",
      "Fold: 19  Epoch: 243  Training loss = 4.8164  Validation loss = 2.2428  \n",
      "\n",
      "Fold: 19  Epoch: 244  Training loss = 4.8160  Validation loss = 2.2427  \n",
      "\n",
      "Fold: 19  Epoch: 245  Training loss = 4.8155  Validation loss = 2.2427  \n",
      "\n",
      "Fold: 19  Epoch: 246  Training loss = 4.8150  Validation loss = 2.2426  \n",
      "\n",
      "Fold: 19  Epoch: 247  Training loss = 4.8144  Validation loss = 2.2425  \n",
      "\n",
      "Fold: 19  Epoch: 248  Training loss = 4.8139  Validation loss = 2.2424  \n",
      "\n",
      "Fold: 19  Epoch: 249  Training loss = 4.8134  Validation loss = 2.2424  \n",
      "\n",
      "Fold: 19  Epoch: 250  Training loss = 4.8129  Validation loss = 2.2422  \n",
      "\n",
      "Fold: 19  Epoch: 251  Training loss = 4.8122  Validation loss = 2.2422  \n",
      "\n",
      "Fold: 19  Epoch: 252  Training loss = 4.8118  Validation loss = 2.2421  \n",
      "\n",
      "Fold: 19  Epoch: 253  Training loss = 4.8113  Validation loss = 2.2420  \n",
      "\n",
      "Fold: 19  Epoch: 254  Training loss = 4.8109  Validation loss = 2.2419  \n",
      "\n",
      "Fold: 19  Epoch: 255  Training loss = 4.8103  Validation loss = 2.2418  \n",
      "\n",
      "Fold: 19  Epoch: 256  Training loss = 4.8098  Validation loss = 2.2418  \n",
      "\n",
      "Fold: 19  Epoch: 257  Training loss = 4.8093  Validation loss = 2.2417  \n",
      "\n",
      "Fold: 19  Epoch: 258  Training loss = 4.8088  Validation loss = 2.2416  \n",
      "\n",
      "Fold: 19  Epoch: 259  Training loss = 4.8083  Validation loss = 2.2416  \n",
      "\n",
      "Fold: 19  Epoch: 260  Training loss = 4.8078  Validation loss = 2.2415  \n",
      "\n",
      "Fold: 19  Epoch: 261  Training loss = 4.8071  Validation loss = 2.2415  \n",
      "\n",
      "Fold: 19  Epoch: 262  Training loss = 4.8066  Validation loss = 2.2414  \n",
      "\n",
      "Fold: 19  Epoch: 263  Training loss = 4.8061  Validation loss = 2.2413  \n",
      "\n",
      "Fold: 19  Epoch: 264  Training loss = 4.8056  Validation loss = 2.2413  \n",
      "\n",
      "Fold: 19  Epoch: 265  Training loss = 4.8051  Validation loss = 2.2412  \n",
      "\n",
      "Fold: 19  Epoch: 266  Training loss = 4.8046  Validation loss = 2.2411  \n",
      "\n",
      "Fold: 19  Epoch: 267  Training loss = 4.8040  Validation loss = 2.2410  \n",
      "\n",
      "Fold: 19  Epoch: 268  Training loss = 4.8034  Validation loss = 2.2409  \n",
      "\n",
      "Fold: 19  Epoch: 269  Training loss = 4.8029  Validation loss = 2.2409  \n",
      "\n",
      "Fold: 19  Epoch: 270  Training loss = 4.8024  Validation loss = 2.2408  \n",
      "\n",
      "Fold: 19  Epoch: 271  Training loss = 4.8017  Validation loss = 2.2407  \n",
      "\n",
      "Fold: 19  Epoch: 272  Training loss = 4.8012  Validation loss = 2.2407  \n",
      "\n",
      "Fold: 19  Epoch: 273  Training loss = 4.8005  Validation loss = 2.2406  \n",
      "\n",
      "Fold: 19  Epoch: 274  Training loss = 4.8000  Validation loss = 2.2405  \n",
      "\n",
      "Fold: 19  Epoch: 275  Training loss = 4.7994  Validation loss = 2.2404  \n",
      "\n",
      "Fold: 19  Epoch: 276  Training loss = 4.7988  Validation loss = 2.2403  \n",
      "\n",
      "Fold: 19  Epoch: 277  Training loss = 4.7983  Validation loss = 2.2402  \n",
      "\n",
      "Fold: 19  Epoch: 278  Training loss = 4.7978  Validation loss = 2.2401  \n",
      "\n",
      "Fold: 19  Epoch: 279  Training loss = 4.7973  Validation loss = 2.2401  \n",
      "\n",
      "Fold: 19  Epoch: 280  Training loss = 4.7968  Validation loss = 2.2400  \n",
      "\n",
      "Fold: 19  Epoch: 281  Training loss = 4.7962  Validation loss = 2.2399  \n",
      "\n",
      "Fold: 19  Epoch: 282  Training loss = 4.7957  Validation loss = 2.2398  \n",
      "\n",
      "Fold: 19  Epoch: 283  Training loss = 4.7950  Validation loss = 2.2397  \n",
      "\n",
      "Fold: 19  Epoch: 284  Training loss = 4.7944  Validation loss = 2.2396  \n",
      "\n",
      "Fold: 19  Epoch: 285  Training loss = 4.7939  Validation loss = 2.2396  \n",
      "\n",
      "Fold: 19  Epoch: 286  Training loss = 4.7932  Validation loss = 2.2395  \n",
      "\n",
      "Fold: 19  Epoch: 287  Training loss = 4.7927  Validation loss = 2.2394  \n",
      "\n",
      "Fold: 19  Epoch: 288  Training loss = 4.7919  Validation loss = 2.2393  \n",
      "\n",
      "Fold: 19  Epoch: 289  Training loss = 4.7913  Validation loss = 2.2392  \n",
      "\n",
      "Fold: 19  Epoch: 290  Training loss = 4.7908  Validation loss = 2.2391  \n",
      "\n",
      "Fold: 19  Epoch: 291  Training loss = 4.7902  Validation loss = 2.2390  \n",
      "\n",
      "Fold: 19  Epoch: 292  Training loss = 4.7896  Validation loss = 2.2389  \n",
      "\n",
      "Fold: 19  Epoch: 293  Training loss = 4.7890  Validation loss = 2.2389  \n",
      "\n",
      "Fold: 19  Epoch: 294  Training loss = 4.7884  Validation loss = 2.2388  \n",
      "\n",
      "Fold: 19  Epoch: 295  Training loss = 4.7879  Validation loss = 2.2387  \n",
      "\n",
      "Fold: 19  Epoch: 296  Training loss = 4.7872  Validation loss = 2.2386  \n",
      "\n",
      "Fold: 19  Epoch: 297  Training loss = 4.7867  Validation loss = 2.2385  \n",
      "\n",
      "Fold: 19  Epoch: 298  Training loss = 4.7861  Validation loss = 2.2384  \n",
      "\n",
      "Fold: 19  Epoch: 299  Training loss = 4.7856  Validation loss = 2.2383  \n",
      "\n",
      "Fold: 19  Epoch: 300  Training loss = 4.7850  Validation loss = 2.2383  \n",
      "\n",
      "Fold: 19  Epoch: 301  Training loss = 4.7845  Validation loss = 2.2382  \n",
      "\n",
      "Fold: 19  Epoch: 302  Training loss = 4.7840  Validation loss = 2.2382  \n",
      "\n",
      "Fold: 19  Epoch: 303  Training loss = 4.7834  Validation loss = 2.2382  \n",
      "\n",
      "Fold: 19  Epoch: 304  Training loss = 4.7827  Validation loss = 2.2381  \n",
      "\n",
      "Fold: 19  Epoch: 305  Training loss = 4.7822  Validation loss = 2.2380  \n",
      "\n",
      "Fold: 19  Epoch: 306  Training loss = 4.7817  Validation loss = 2.2379  \n",
      "\n",
      "Fold: 19  Epoch: 307  Training loss = 4.7812  Validation loss = 2.2378  \n",
      "\n",
      "Fold: 19  Epoch: 308  Training loss = 4.7806  Validation loss = 2.2378  \n",
      "\n",
      "Fold: 19  Epoch: 309  Training loss = 4.7799  Validation loss = 2.2377  \n",
      "\n",
      "Fold: 19  Epoch: 310  Training loss = 4.7794  Validation loss = 2.2376  \n",
      "\n",
      "Fold: 19  Epoch: 311  Training loss = 4.7789  Validation loss = 2.2376  \n",
      "\n",
      "Fold: 19  Epoch: 312  Training loss = 4.7785  Validation loss = 2.2376  \n",
      "\n",
      "Fold: 19  Epoch: 313  Training loss = 4.7779  Validation loss = 2.2374  \n",
      "\n",
      "Fold: 19  Epoch: 314  Training loss = 4.7773  Validation loss = 2.2374  \n",
      "\n",
      "Fold: 19  Epoch: 315  Training loss = 4.7767  Validation loss = 2.2373  \n",
      "\n",
      "Fold: 19  Epoch: 316  Training loss = 4.7760  Validation loss = 2.2372  \n",
      "\n",
      "Fold: 19  Epoch: 317  Training loss = 4.7755  Validation loss = 2.2371  \n",
      "\n",
      "Fold: 19  Epoch: 318  Training loss = 4.7750  Validation loss = 2.2370  \n",
      "\n",
      "Fold: 19  Epoch: 319  Training loss = 4.7744  Validation loss = 2.2370  \n",
      "\n",
      "Fold: 19  Epoch: 320  Training loss = 4.7739  Validation loss = 2.2370  \n",
      "\n",
      "Fold: 19  Epoch: 321  Training loss = 4.7732  Validation loss = 2.2369  \n",
      "\n",
      "Fold: 19  Epoch: 322  Training loss = 4.7727  Validation loss = 2.2368  \n",
      "\n",
      "Fold: 19  Epoch: 323  Training loss = 4.7721  Validation loss = 2.2367  \n",
      "\n",
      "Fold: 19  Epoch: 324  Training loss = 4.7717  Validation loss = 2.2367  \n",
      "\n",
      "Fold: 19  Epoch: 325  Training loss = 4.7711  Validation loss = 2.2367  \n",
      "\n",
      "Fold: 19  Epoch: 326  Training loss = 4.7706  Validation loss = 2.2366  \n",
      "\n",
      "Fold: 19  Epoch: 327  Training loss = 4.7701  Validation loss = 2.2365  \n",
      "\n",
      "Fold: 19  Epoch: 328  Training loss = 4.7696  Validation loss = 2.2365  \n",
      "\n",
      "Fold: 19  Epoch: 329  Training loss = 4.7690  Validation loss = 2.2365  \n",
      "\n",
      "Fold: 19  Epoch: 330  Training loss = 4.7685  Validation loss = 2.2365  \n",
      "\n",
      "Fold: 19  Epoch: 331  Training loss = 4.7680  Validation loss = 2.2364  \n",
      "\n",
      "Fold: 19  Epoch: 332  Training loss = 4.7674  Validation loss = 2.2363  \n",
      "\n",
      "Fold: 19  Epoch: 333  Training loss = 4.7668  Validation loss = 2.2363  \n",
      "\n",
      "Fold: 19  Epoch: 334  Training loss = 4.7662  Validation loss = 2.2362  \n",
      "\n",
      "Fold: 19  Epoch: 335  Training loss = 4.7657  Validation loss = 2.2361  \n",
      "\n",
      "Fold: 19  Epoch: 336  Training loss = 4.7652  Validation loss = 2.2361  \n",
      "\n",
      "Fold: 19  Epoch: 337  Training loss = 4.7647  Validation loss = 2.2360  \n",
      "\n",
      "Fold: 19  Epoch: 338  Training loss = 4.7642  Validation loss = 2.2360  \n",
      "\n",
      "Fold: 19  Epoch: 339  Training loss = 4.7637  Validation loss = 2.2359  \n",
      "\n",
      "Fold: 19  Epoch: 340  Training loss = 4.7632  Validation loss = 2.2359  \n",
      "\n",
      "Fold: 19  Epoch: 341  Training loss = 4.7627  Validation loss = 2.2358  \n",
      "\n",
      "Fold: 19  Epoch: 342  Training loss = 4.7622  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 19  Epoch: 343  Training loss = 4.7616  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 19  Epoch: 344  Training loss = 4.7612  Validation loss = 2.2357  \n",
      "\n",
      "Fold: 19  Epoch: 345  Training loss = 4.7607  Validation loss = 2.2356  \n",
      "\n",
      "Fold: 19  Epoch: 346  Training loss = 4.7602  Validation loss = 2.2356  \n",
      "\n",
      "Fold: 19  Epoch: 347  Training loss = 4.7597  Validation loss = 2.2356  \n",
      "\n",
      "Fold: 19  Epoch: 348  Training loss = 4.7591  Validation loss = 2.2354  \n",
      "\n",
      "Fold: 19  Epoch: 349  Training loss = 4.7585  Validation loss = 2.2354  \n",
      "\n",
      "Fold: 19  Epoch: 350  Training loss = 4.7580  Validation loss = 2.2353  \n",
      "\n",
      "Fold: 19  Epoch: 351  Training loss = 4.7575  Validation loss = 2.2352  \n",
      "\n",
      "Fold: 19  Epoch: 352  Training loss = 4.7570  Validation loss = 2.2352  \n",
      "\n",
      "Fold: 19  Epoch: 353  Training loss = 4.7563  Validation loss = 2.2351  \n",
      "\n",
      "Fold: 19  Epoch: 354  Training loss = 4.7558  Validation loss = 2.2350  \n",
      "\n",
      "Fold: 19  Epoch: 355  Training loss = 4.7553  Validation loss = 2.2350  \n",
      "\n",
      "Fold: 19  Epoch: 356  Training loss = 4.7548  Validation loss = 2.2349  \n",
      "\n",
      "Fold: 19  Epoch: 357  Training loss = 4.7543  Validation loss = 2.2349  \n",
      "\n",
      "Fold: 19  Epoch: 358  Training loss = 4.7536  Validation loss = 2.2348  \n",
      "\n",
      "Fold: 19  Epoch: 359  Training loss = 4.7532  Validation loss = 2.2347  \n",
      "\n",
      "Fold: 19  Epoch: 360  Training loss = 4.7527  Validation loss = 2.2347  \n",
      "\n",
      "Fold: 19  Epoch: 361  Training loss = 4.7521  Validation loss = 2.2346  \n",
      "\n",
      "Fold: 19  Epoch: 362  Training loss = 4.7517  Validation loss = 2.2346  \n",
      "\n",
      "Fold: 19  Epoch: 363  Training loss = 4.7511  Validation loss = 2.2346  \n",
      "\n",
      "Fold: 19  Epoch: 364  Training loss = 4.7505  Validation loss = 2.2345  \n",
      "\n",
      "Fold: 19  Epoch: 365  Training loss = 4.7500  Validation loss = 2.2345  \n",
      "\n",
      "Fold: 19  Epoch: 366  Training loss = 4.7495  Validation loss = 2.2344  \n",
      "\n",
      "Fold: 19  Epoch: 367  Training loss = 4.7489  Validation loss = 2.2344  \n",
      "\n",
      "Fold: 19  Epoch: 368  Training loss = 4.7484  Validation loss = 2.2344  \n",
      "\n",
      "Fold: 19  Epoch: 369  Training loss = 4.7479  Validation loss = 2.2343  \n",
      "\n",
      "Fold: 19  Epoch: 370  Training loss = 4.7474  Validation loss = 2.2343  \n",
      "\n",
      "Fold: 19  Epoch: 371  Training loss = 4.7469  Validation loss = 2.2342  \n",
      "\n",
      "Fold: 19  Epoch: 372  Training loss = 4.7463  Validation loss = 2.2341  \n",
      "\n",
      "Fold: 19  Epoch: 373  Training loss = 4.7457  Validation loss = 2.2341  \n",
      "\n",
      "Fold: 19  Epoch: 374  Training loss = 4.7451  Validation loss = 2.2341  \n",
      "\n",
      "Fold: 19  Epoch: 375  Training loss = 4.7445  Validation loss = 2.2340  \n",
      "\n",
      "Fold: 19  Epoch: 376  Training loss = 4.7439  Validation loss = 2.2339  \n",
      "\n",
      "Fold: 19  Epoch: 377  Training loss = 4.7434  Validation loss = 2.2339  \n",
      "\n",
      "Fold: 19  Epoch: 378  Training loss = 4.7430  Validation loss = 2.2337  \n",
      "\n",
      "Fold: 19  Epoch: 379  Training loss = 4.7424  Validation loss = 2.2336  \n",
      "\n",
      "Fold: 19  Epoch: 380  Training loss = 4.7419  Validation loss = 2.2336  \n",
      "\n",
      "Fold: 19  Epoch: 381  Training loss = 4.7414  Validation loss = 2.2335  \n",
      "\n",
      "Fold: 19  Epoch: 382  Training loss = 4.7410  Validation loss = 2.2336  \n",
      "\n",
      "Fold: 19  Epoch: 383  Training loss = 4.7404  Validation loss = 2.2335  \n",
      "\n",
      "Fold: 19  Epoch: 384  Training loss = 4.7399  Validation loss = 2.2334  \n",
      "\n",
      "Fold: 19  Epoch: 385  Training loss = 4.7393  Validation loss = 2.2333  \n",
      "\n",
      "Fold: 19  Epoch: 386  Training loss = 4.7388  Validation loss = 2.2332  \n",
      "\n",
      "Fold: 19  Epoch: 387  Training loss = 4.7383  Validation loss = 2.2332  \n",
      "\n",
      "Fold: 19  Epoch: 388  Training loss = 4.7378  Validation loss = 2.2331  \n",
      "\n",
      "Fold: 19  Epoch: 389  Training loss = 4.7374  Validation loss = 2.2331  \n",
      "\n",
      "Fold: 19  Epoch: 390  Training loss = 4.7368  Validation loss = 2.2331  \n",
      "\n",
      "Fold: 19  Epoch: 391  Training loss = 4.7364  Validation loss = 2.2331  \n",
      "\n",
      "Fold: 19  Epoch: 392  Training loss = 4.7360  Validation loss = 2.2330  \n",
      "\n",
      "Fold: 19  Epoch: 393  Training loss = 4.7354  Validation loss = 2.2329  \n",
      "\n",
      "Fold: 19  Epoch: 394  Training loss = 4.7349  Validation loss = 2.2329  \n",
      "\n",
      "Fold: 19  Epoch: 395  Training loss = 4.7345  Validation loss = 2.2328  \n",
      "\n",
      "Fold: 19  Epoch: 396  Training loss = 4.7339  Validation loss = 2.2327  \n",
      "\n",
      "Fold: 19  Epoch: 397  Training loss = 4.7335  Validation loss = 2.2327  \n",
      "\n",
      "Fold: 19  Epoch: 398  Training loss = 4.7329  Validation loss = 2.2327  \n",
      "\n",
      "Fold: 19  Epoch: 399  Training loss = 4.7323  Validation loss = 2.2326  \n",
      "\n",
      "Fold: 19  Epoch: 400  Training loss = 4.7317  Validation loss = 2.2325  \n",
      "\n",
      "Fold: 19  Epoch: 401  Training loss = 4.7312  Validation loss = 2.2324  \n",
      "\n",
      "Fold: 19  Epoch: 402  Training loss = 4.7308  Validation loss = 2.2324  \n",
      "\n",
      "Fold: 19  Epoch: 403  Training loss = 4.7303  Validation loss = 2.2324  \n",
      "\n",
      "Fold: 19  Epoch: 404  Training loss = 4.7298  Validation loss = 2.2323  \n",
      "\n",
      "Fold: 19  Epoch: 405  Training loss = 4.7293  Validation loss = 2.2322  \n",
      "\n",
      "Fold: 19  Epoch: 406  Training loss = 4.7289  Validation loss = 2.2322  \n",
      "\n",
      "Fold: 19  Epoch: 407  Training loss = 4.7285  Validation loss = 2.2322  \n",
      "\n",
      "Fold: 19  Epoch: 408  Training loss = 4.7281  Validation loss = 2.2322  \n",
      "\n",
      "Fold: 19  Epoch: 409  Training loss = 4.7276  Validation loss = 2.2322  \n",
      "\n",
      "Fold: 19  Epoch: 410  Training loss = 4.7271  Validation loss = 2.2321  \n",
      "\n",
      "Fold: 19  Epoch: 411  Training loss = 4.7266  Validation loss = 2.2321  \n",
      "\n",
      "Fold: 19  Epoch: 412  Training loss = 4.7261  Validation loss = 2.2321  \n",
      "\n",
      "Fold: 19  Epoch: 413  Training loss = 4.7255  Validation loss = 2.2320  \n",
      "\n",
      "Fold: 19  Epoch: 414  Training loss = 4.7249  Validation loss = 2.2319  \n",
      "\n",
      "Fold: 19  Epoch: 415  Training loss = 4.7243  Validation loss = 2.2319  \n",
      "\n",
      "Fold: 19  Epoch: 416  Training loss = 4.7238  Validation loss = 2.2318  \n",
      "\n",
      "Fold: 19  Epoch: 417  Training loss = 4.7234  Validation loss = 2.2318  \n",
      "\n",
      "Fold: 19  Epoch: 418  Training loss = 4.7229  Validation loss = 2.2317  \n",
      "\n",
      "Fold: 19  Epoch: 419  Training loss = 4.7223  Validation loss = 2.2316  \n",
      "\n",
      "Fold: 19  Epoch: 420  Training loss = 4.7219  Validation loss = 2.2316  \n",
      "\n",
      "Fold: 19  Epoch: 421  Training loss = 4.7213  Validation loss = 2.2316  \n",
      "\n",
      "Fold: 19  Epoch: 422  Training loss = 4.7208  Validation loss = 2.2315  \n",
      "\n",
      "Fold: 19  Epoch: 423  Training loss = 4.7201  Validation loss = 2.2314  \n",
      "\n",
      "Fold: 19  Epoch: 424  Training loss = 4.7195  Validation loss = 2.2314  \n",
      "\n",
      "Fold: 19  Epoch: 425  Training loss = 4.7190  Validation loss = 2.2314  \n",
      "\n",
      "Fold: 19  Epoch: 426  Training loss = 4.7186  Validation loss = 2.2313  \n",
      "\n",
      "Fold: 19  Epoch: 427  Training loss = 4.7180  Validation loss = 2.2313  \n",
      "\n",
      "Fold: 19  Epoch: 428  Training loss = 4.7175  Validation loss = 2.2312  \n",
      "\n",
      "Fold: 19  Epoch: 429  Training loss = 4.7170  Validation loss = 2.2312  \n",
      "\n",
      "Fold: 19  Epoch: 430  Training loss = 4.7165  Validation loss = 2.2311  \n",
      "\n",
      "Fold: 19  Epoch: 431  Training loss = 4.7160  Validation loss = 2.2311  \n",
      "\n",
      "Fold: 19  Epoch: 432  Training loss = 4.7155  Validation loss = 2.2311  \n",
      "\n",
      "Fold: 19  Epoch: 433  Training loss = 4.7149  Validation loss = 2.2310  \n",
      "\n",
      "Fold: 19  Epoch: 434  Training loss = 4.7144  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 19  Epoch: 435  Training loss = 4.7139  Validation loss = 2.2310  \n",
      "\n",
      "Fold: 19  Epoch: 436  Training loss = 4.7134  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 19  Epoch: 437  Training loss = 4.7129  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 19  Epoch: 438  Training loss = 4.7125  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 19  Epoch: 439  Training loss = 4.7119  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 19  Epoch: 440  Training loss = 4.7115  Validation loss = 2.2309  \n",
      "\n",
      "Fold: 19  Epoch: 441  Training loss = 4.7110  Validation loss = 2.2308  \n",
      "\n",
      "Fold: 19  Epoch: 442  Training loss = 4.7105  Validation loss = 2.2308  \n",
      "\n",
      "Fold: 19  Epoch: 443  Training loss = 4.7100  Validation loss = 2.2307  \n",
      "\n",
      "Fold: 19  Epoch: 444  Training loss = 4.7095  Validation loss = 2.2307  \n",
      "\n",
      "Fold: 19  Epoch: 445  Training loss = 4.7090  Validation loss = 2.2307  \n",
      "\n",
      "Fold: 19  Epoch: 446  Training loss = 4.7085  Validation loss = 2.2306  \n",
      "\n",
      "Fold: 19  Epoch: 447  Training loss = 4.7078  Validation loss = 2.2305  \n",
      "\n",
      "Fold: 19  Epoch: 448  Training loss = 4.7072  Validation loss = 2.2305  \n",
      "\n",
      "Fold: 19  Epoch: 449  Training loss = 4.7065  Validation loss = 2.2304  \n",
      "\n",
      "Fold: 19  Epoch: 450  Training loss = 4.7062  Validation loss = 2.2303  \n",
      "\n",
      "Fold: 19  Epoch: 451  Training loss = 4.7056  Validation loss = 2.2303  \n",
      "\n",
      "Fold: 19  Epoch: 452  Training loss = 4.7052  Validation loss = 2.2303  \n",
      "\n",
      "Fold: 19  Epoch: 453  Training loss = 4.7046  Validation loss = 2.2302  \n",
      "\n",
      "Fold: 19  Epoch: 454  Training loss = 4.7041  Validation loss = 2.2301  \n",
      "\n",
      "Fold: 19  Epoch: 455  Training loss = 4.7034  Validation loss = 2.2301  \n",
      "\n",
      "Fold: 19  Epoch: 456  Training loss = 4.7028  Validation loss = 2.2301  \n",
      "\n",
      "Fold: 19  Epoch: 457  Training loss = 4.7024  Validation loss = 2.2301  \n",
      "\n",
      "Fold: 19  Epoch: 458  Training loss = 4.7020  Validation loss = 2.2300  \n",
      "\n",
      "Fold: 19  Epoch: 459  Training loss = 4.7013  Validation loss = 2.2300  \n",
      "\n",
      "Fold: 19  Epoch: 460  Training loss = 4.7009  Validation loss = 2.2299  \n",
      "\n",
      "Fold: 19  Epoch: 461  Training loss = 4.7004  Validation loss = 2.2299  \n",
      "\n",
      "Fold: 19  Epoch: 462  Training loss = 4.6999  Validation loss = 2.2299  \n",
      "\n",
      "Fold: 19  Epoch: 463  Training loss = 4.6995  Validation loss = 2.2298  \n",
      "\n",
      "Fold: 19  Epoch: 464  Training loss = 4.6988  Validation loss = 2.2298  \n",
      "\n",
      "Fold: 19  Epoch: 465  Training loss = 4.6983  Validation loss = 2.2298  \n",
      "\n",
      "Fold: 19  Epoch: 466  Training loss = 4.6978  Validation loss = 2.2298  \n",
      "\n",
      "Fold: 19  Epoch: 467  Training loss = 4.6972  Validation loss = 2.2297  \n",
      "\n",
      "Fold: 19  Epoch: 468  Training loss = 4.6967  Validation loss = 2.2297  \n",
      "\n",
      "Fold: 19  Epoch: 469  Training loss = 4.6962  Validation loss = 2.2297  \n",
      "\n",
      "Fold: 19  Epoch: 470  Training loss = 4.6956  Validation loss = 2.2296  \n",
      "\n",
      "Fold: 19  Epoch: 471  Training loss = 4.6951  Validation loss = 2.2296  \n",
      "\n",
      "Fold: 19  Epoch: 472  Training loss = 4.6945  Validation loss = 2.2295  \n",
      "\n",
      "Fold: 19  Epoch: 473  Training loss = 4.6939  Validation loss = 2.2295  \n",
      "\n",
      "Fold: 19  Epoch: 474  Training loss = 4.6934  Validation loss = 2.2294  \n",
      "\n",
      "Fold: 19  Epoch: 475  Training loss = 4.6928  Validation loss = 2.2294  \n",
      "\n",
      "Fold: 19  Epoch: 476  Training loss = 4.6922  Validation loss = 2.2294  \n",
      "\n",
      "Fold: 19  Epoch: 477  Training loss = 4.6917  Validation loss = 2.2293  \n",
      "\n",
      "Fold: 19  Epoch: 478  Training loss = 4.6913  Validation loss = 2.2293  \n",
      "\n",
      "Fold: 19  Epoch: 479  Training loss = 4.6908  Validation loss = 2.2292  \n",
      "\n",
      "Fold: 19  Epoch: 480  Training loss = 4.6902  Validation loss = 2.2292  \n",
      "\n",
      "Fold: 19  Epoch: 481  Training loss = 4.6897  Validation loss = 2.2292  \n",
      "\n",
      "Fold: 19  Epoch: 482  Training loss = 4.6892  Validation loss = 2.2291  \n",
      "\n",
      "Fold: 19  Epoch: 483  Training loss = 4.6888  Validation loss = 2.2291  \n",
      "\n",
      "Fold: 19  Epoch: 484  Training loss = 4.6882  Validation loss = 2.2290  \n",
      "\n",
      "Fold: 19  Epoch: 485  Training loss = 4.6877  Validation loss = 2.2290  \n",
      "\n",
      "Fold: 19  Epoch: 486  Training loss = 4.6872  Validation loss = 2.2290  \n",
      "\n",
      "Fold: 19  Epoch: 487  Training loss = 4.6865  Validation loss = 2.2289  \n",
      "\n",
      "Fold: 19  Epoch: 488  Training loss = 4.6860  Validation loss = 2.2289  \n",
      "\n",
      "Fold: 19  Epoch: 489  Training loss = 4.6856  Validation loss = 2.2289  \n",
      "\n",
      "Fold: 19  Epoch: 490  Training loss = 4.6850  Validation loss = 2.2289  \n",
      "\n",
      "Fold: 19  Epoch: 491  Training loss = 4.6846  Validation loss = 2.2288  \n",
      "\n",
      "Fold: 19  Epoch: 492  Training loss = 4.6840  Validation loss = 2.2288  \n",
      "\n",
      "Fold: 19  Epoch: 493  Training loss = 4.6835  Validation loss = 2.2288  \n",
      "\n",
      "Fold: 19  Epoch: 494  Training loss = 4.6828  Validation loss = 2.2287  \n",
      "\n",
      "Fold: 19  Epoch: 495  Training loss = 4.6823  Validation loss = 2.2288  \n",
      "\n",
      "Fold: 19  Epoch: 496  Training loss = 4.6817  Validation loss = 2.2287  \n",
      "\n",
      "Fold: 19  Epoch: 497  Training loss = 4.6812  Validation loss = 2.2287  \n",
      "\n",
      "Fold: 19  Epoch: 498  Training loss = 4.6807  Validation loss = 2.2287  \n",
      "\n",
      "Fold: 19  Epoch: 499  Training loss = 4.6802  Validation loss = 2.2286  \n",
      "\n",
      "Fold: 19  Epoch: 500  Training loss = 4.6798  Validation loss = 2.2286  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 499  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 4.7070  Validation loss = 1.1651  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 4.7066  Validation loss = 1.1648  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 4.7062  Validation loss = 1.1647  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 4.7057  Validation loss = 1.1644  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 4.7052  Validation loss = 1.1641  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 4.7046  Validation loss = 1.1638  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 4.7041  Validation loss = 1.1635  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 4.7034  Validation loss = 1.1630  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 4.7028  Validation loss = 1.1627  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 4.7023  Validation loss = 1.1623  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 4.7017  Validation loss = 1.1620  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 4.7011  Validation loss = 1.1617  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 4.7005  Validation loss = 1.1613  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 4.7001  Validation loss = 1.1610  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 4.6996  Validation loss = 1.1607  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 4.6990  Validation loss = 1.1604  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 4.6985  Validation loss = 1.1601  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 4.6980  Validation loss = 1.1597  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 4.6976  Validation loss = 1.1596  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 4.6970  Validation loss = 1.1592  \n",
      "\n",
      "Fold: 20  Epoch: 21  Training loss = 4.6964  Validation loss = 1.1589  \n",
      "\n",
      "Fold: 20  Epoch: 22  Training loss = 4.6958  Validation loss = 1.1586  \n",
      "\n",
      "Fold: 20  Epoch: 23  Training loss = 4.6954  Validation loss = 1.1584  \n",
      "\n",
      "Fold: 20  Epoch: 24  Training loss = 4.6950  Validation loss = 1.1582  \n",
      "\n",
      "Fold: 20  Epoch: 25  Training loss = 4.6944  Validation loss = 1.1579  \n",
      "\n",
      "Fold: 20  Epoch: 26  Training loss = 4.6939  Validation loss = 1.1577  \n",
      "\n",
      "Fold: 20  Epoch: 27  Training loss = 4.6933  Validation loss = 1.1573  \n",
      "\n",
      "Fold: 20  Epoch: 28  Training loss = 4.6927  Validation loss = 1.1570  \n",
      "\n",
      "Fold: 20  Epoch: 29  Training loss = 4.6923  Validation loss = 1.1567  \n",
      "\n",
      "Fold: 20  Epoch: 30  Training loss = 4.6918  Validation loss = 1.1565  \n",
      "\n",
      "Fold: 20  Epoch: 31  Training loss = 4.6913  Validation loss = 1.1562  \n",
      "\n",
      "Fold: 20  Epoch: 32  Training loss = 4.6907  Validation loss = 1.1559  \n",
      "\n",
      "Fold: 20  Epoch: 33  Training loss = 4.6902  Validation loss = 1.1556  \n",
      "\n",
      "Fold: 20  Epoch: 34  Training loss = 4.6897  Validation loss = 1.1554  \n",
      "\n",
      "Fold: 20  Epoch: 35  Training loss = 4.6892  Validation loss = 1.1551  \n",
      "\n",
      "Fold: 20  Epoch: 36  Training loss = 4.6887  Validation loss = 1.1549  \n",
      "\n",
      "Fold: 20  Epoch: 37  Training loss = 4.6881  Validation loss = 1.1547  \n",
      "\n",
      "Fold: 20  Epoch: 38  Training loss = 4.6875  Validation loss = 1.1544  \n",
      "\n",
      "Fold: 20  Epoch: 39  Training loss = 4.6871  Validation loss = 1.1543  \n",
      "\n",
      "Fold: 20  Epoch: 40  Training loss = 4.6866  Validation loss = 1.1540  \n",
      "\n",
      "Fold: 20  Epoch: 41  Training loss = 4.6860  Validation loss = 1.1537  \n",
      "\n",
      "Fold: 20  Epoch: 42  Training loss = 4.6855  Validation loss = 1.1534  \n",
      "\n",
      "Fold: 20  Epoch: 43  Training loss = 4.6849  Validation loss = 1.1532  \n",
      "\n",
      "Fold: 20  Epoch: 44  Training loss = 4.6844  Validation loss = 1.1529  \n",
      "\n",
      "Fold: 20  Epoch: 45  Training loss = 4.6839  Validation loss = 1.1526  \n",
      "\n",
      "Fold: 20  Epoch: 46  Training loss = 4.6834  Validation loss = 1.1522  \n",
      "\n",
      "Fold: 20  Epoch: 47  Training loss = 4.6828  Validation loss = 1.1519  \n",
      "\n",
      "Fold: 20  Epoch: 48  Training loss = 4.6823  Validation loss = 1.1516  \n",
      "\n",
      "Fold: 20  Epoch: 49  Training loss = 4.6818  Validation loss = 1.1513  \n",
      "\n",
      "Fold: 20  Epoch: 50  Training loss = 4.6813  Validation loss = 1.1511  \n",
      "\n",
      "Fold: 20  Epoch: 51  Training loss = 4.6808  Validation loss = 1.1507  \n",
      "\n",
      "Fold: 20  Epoch: 52  Training loss = 4.6803  Validation loss = 1.1504  \n",
      "\n",
      "Fold: 20  Epoch: 53  Training loss = 4.6798  Validation loss = 1.1502  \n",
      "\n",
      "Fold: 20  Epoch: 54  Training loss = 4.6793  Validation loss = 1.1499  \n",
      "\n",
      "Fold: 20  Epoch: 55  Training loss = 4.6788  Validation loss = 1.1497  \n",
      "\n",
      "Fold: 20  Epoch: 56  Training loss = 4.6784  Validation loss = 1.1495  \n",
      "\n",
      "Fold: 20  Epoch: 57  Training loss = 4.6781  Validation loss = 1.1492  \n",
      "\n",
      "Fold: 20  Epoch: 58  Training loss = 4.6775  Validation loss = 1.1489  \n",
      "\n",
      "Fold: 20  Epoch: 59  Training loss = 4.6770  Validation loss = 1.1485  \n",
      "\n",
      "Fold: 20  Epoch: 60  Training loss = 4.6766  Validation loss = 1.1484  \n",
      "\n",
      "Fold: 20  Epoch: 61  Training loss = 4.6761  Validation loss = 1.1481  \n",
      "\n",
      "Fold: 20  Epoch: 62  Training loss = 4.6756  Validation loss = 1.1478  \n",
      "\n",
      "Fold: 20  Epoch: 63  Training loss = 4.6751  Validation loss = 1.1475  \n",
      "\n",
      "Fold: 20  Epoch: 64  Training loss = 4.6746  Validation loss = 1.1473  \n",
      "\n",
      "Fold: 20  Epoch: 65  Training loss = 4.6741  Validation loss = 1.1470  \n",
      "\n",
      "Fold: 20  Epoch: 66  Training loss = 4.6737  Validation loss = 1.1467  \n",
      "\n",
      "Fold: 20  Epoch: 67  Training loss = 4.6732  Validation loss = 1.1464  \n",
      "\n",
      "Fold: 20  Epoch: 68  Training loss = 4.6727  Validation loss = 1.1461  \n",
      "\n",
      "Fold: 20  Epoch: 69  Training loss = 4.6722  Validation loss = 1.1458  \n",
      "\n",
      "Fold: 20  Epoch: 70  Training loss = 4.6717  Validation loss = 1.1456  \n",
      "\n",
      "Fold: 20  Epoch: 71  Training loss = 4.6712  Validation loss = 1.1453  \n",
      "\n",
      "Fold: 20  Epoch: 72  Training loss = 4.6707  Validation loss = 1.1450  \n",
      "\n",
      "Fold: 20  Epoch: 73  Training loss = 4.6700  Validation loss = 1.1447  \n",
      "\n",
      "Fold: 20  Epoch: 74  Training loss = 4.6694  Validation loss = 1.1443  \n",
      "\n",
      "Fold: 20  Epoch: 75  Training loss = 4.6687  Validation loss = 1.1441  \n",
      "\n",
      "Fold: 20  Epoch: 76  Training loss = 4.6682  Validation loss = 1.1438  \n",
      "\n",
      "Fold: 20  Epoch: 77  Training loss = 4.6677  Validation loss = 1.1434  \n",
      "\n",
      "Fold: 20  Epoch: 78  Training loss = 4.6672  Validation loss = 1.1432  \n",
      "\n",
      "Fold: 20  Epoch: 79  Training loss = 4.6668  Validation loss = 1.1429  \n",
      "\n",
      "Fold: 20  Epoch: 80  Training loss = 4.6663  Validation loss = 1.1427  \n",
      "\n",
      "Fold: 20  Epoch: 81  Training loss = 4.6659  Validation loss = 1.1424  \n",
      "\n",
      "Fold: 20  Epoch: 82  Training loss = 4.6654  Validation loss = 1.1422  \n",
      "\n",
      "Fold: 20  Epoch: 83  Training loss = 4.6649  Validation loss = 1.1419  \n",
      "\n",
      "Fold: 20  Epoch: 84  Training loss = 4.6644  Validation loss = 1.1416  \n",
      "\n",
      "Fold: 20  Epoch: 85  Training loss = 4.6639  Validation loss = 1.1414  \n",
      "\n",
      "Fold: 20  Epoch: 86  Training loss = 4.6634  Validation loss = 1.1411  \n",
      "\n",
      "Fold: 20  Epoch: 87  Training loss = 4.6629  Validation loss = 1.1408  \n",
      "\n",
      "Fold: 20  Epoch: 88  Training loss = 4.6625  Validation loss = 1.1406  \n",
      "\n",
      "Fold: 20  Epoch: 89  Training loss = 4.6619  Validation loss = 1.1403  \n",
      "\n",
      "Fold: 20  Epoch: 90  Training loss = 4.6614  Validation loss = 1.1399  \n",
      "\n",
      "Fold: 20  Epoch: 91  Training loss = 4.6608  Validation loss = 1.1396  \n",
      "\n",
      "Fold: 20  Epoch: 92  Training loss = 4.6604  Validation loss = 1.1393  \n",
      "\n",
      "Fold: 20  Epoch: 93  Training loss = 4.6599  Validation loss = 1.1391  \n",
      "\n",
      "Fold: 20  Epoch: 94  Training loss = 4.6593  Validation loss = 1.1387  \n",
      "\n",
      "Fold: 20  Epoch: 95  Training loss = 4.6589  Validation loss = 1.1385  \n",
      "\n",
      "Fold: 20  Epoch: 96  Training loss = 4.6584  Validation loss = 1.1382  \n",
      "\n",
      "Fold: 20  Epoch: 97  Training loss = 4.6579  Validation loss = 1.1379  \n",
      "\n",
      "Fold: 20  Epoch: 98  Training loss = 4.6573  Validation loss = 1.1376  \n",
      "\n",
      "Fold: 20  Epoch: 99  Training loss = 4.6568  Validation loss = 1.1373  \n",
      "\n",
      "Fold: 20  Epoch: 100  Training loss = 4.6563  Validation loss = 1.1370  \n",
      "\n",
      "Fold: 20  Epoch: 101  Training loss = 4.6558  Validation loss = 1.1368  \n",
      "\n",
      "Fold: 20  Epoch: 102  Training loss = 4.6552  Validation loss = 1.1365  \n",
      "\n",
      "Fold: 20  Epoch: 103  Training loss = 4.6546  Validation loss = 1.1363  \n",
      "\n",
      "Fold: 20  Epoch: 104  Training loss = 4.6541  Validation loss = 1.1361  \n",
      "\n",
      "Fold: 20  Epoch: 105  Training loss = 4.6536  Validation loss = 1.1358  \n",
      "\n",
      "Fold: 20  Epoch: 106  Training loss = 4.6531  Validation loss = 1.1354  \n",
      "\n",
      "Fold: 20  Epoch: 107  Training loss = 4.6526  Validation loss = 1.1351  \n",
      "\n",
      "Fold: 20  Epoch: 108  Training loss = 4.6520  Validation loss = 1.1348  \n",
      "\n",
      "Fold: 20  Epoch: 109  Training loss = 4.6515  Validation loss = 1.1344  \n",
      "\n",
      "Fold: 20  Epoch: 110  Training loss = 4.6509  Validation loss = 1.1342  \n",
      "\n",
      "Fold: 20  Epoch: 111  Training loss = 4.6504  Validation loss = 1.1339  \n",
      "\n",
      "Fold: 20  Epoch: 112  Training loss = 4.6499  Validation loss = 1.1336  \n",
      "\n",
      "Fold: 20  Epoch: 113  Training loss = 4.6493  Validation loss = 1.1333  \n",
      "\n",
      "Fold: 20  Epoch: 114  Training loss = 4.6488  Validation loss = 1.1331  \n",
      "\n",
      "Fold: 20  Epoch: 115  Training loss = 4.6482  Validation loss = 1.1328  \n",
      "\n",
      "Fold: 20  Epoch: 116  Training loss = 4.6478  Validation loss = 1.1326  \n",
      "\n",
      "Fold: 20  Epoch: 117  Training loss = 4.6473  Validation loss = 1.1323  \n",
      "\n",
      "Fold: 20  Epoch: 118  Training loss = 4.6468  Validation loss = 1.1320  \n",
      "\n",
      "Fold: 20  Epoch: 119  Training loss = 4.6463  Validation loss = 1.1318  \n",
      "\n",
      "Fold: 20  Epoch: 120  Training loss = 4.6459  Validation loss = 1.1315  \n",
      "\n",
      "Fold: 20  Epoch: 121  Training loss = 4.6454  Validation loss = 1.1312  \n",
      "\n",
      "Fold: 20  Epoch: 122  Training loss = 4.6450  Validation loss = 1.1309  \n",
      "\n",
      "Fold: 20  Epoch: 123  Training loss = 4.6445  Validation loss = 1.1306  \n",
      "\n",
      "Fold: 20  Epoch: 124  Training loss = 4.6440  Validation loss = 1.1303  \n",
      "\n",
      "Fold: 20  Epoch: 125  Training loss = 4.6436  Validation loss = 1.1300  \n",
      "\n",
      "Fold: 20  Epoch: 126  Training loss = 4.6432  Validation loss = 1.1297  \n",
      "\n",
      "Fold: 20  Epoch: 127  Training loss = 4.6427  Validation loss = 1.1294  \n",
      "\n",
      "Fold: 20  Epoch: 128  Training loss = 4.6422  Validation loss = 1.1292  \n",
      "\n",
      "Fold: 20  Epoch: 129  Training loss = 4.6417  Validation loss = 1.1288  \n",
      "\n",
      "Fold: 20  Epoch: 130  Training loss = 4.6411  Validation loss = 1.1285  \n",
      "\n",
      "Fold: 20  Epoch: 131  Training loss = 4.6406  Validation loss = 1.1283  \n",
      "\n",
      "Fold: 20  Epoch: 132  Training loss = 4.6400  Validation loss = 1.1280  \n",
      "\n",
      "Fold: 20  Epoch: 133  Training loss = 4.6395  Validation loss = 1.1278  \n",
      "\n",
      "Fold: 20  Epoch: 134  Training loss = 4.6389  Validation loss = 1.1275  \n",
      "\n",
      "Fold: 20  Epoch: 135  Training loss = 4.6384  Validation loss = 1.1272  \n",
      "\n",
      "Fold: 20  Epoch: 136  Training loss = 4.6378  Validation loss = 1.1269  \n",
      "\n",
      "Fold: 20  Epoch: 137  Training loss = 4.6373  Validation loss = 1.1266  \n",
      "\n",
      "Fold: 20  Epoch: 138  Training loss = 4.6369  Validation loss = 1.1263  \n",
      "\n",
      "Fold: 20  Epoch: 139  Training loss = 4.6364  Validation loss = 1.1261  \n",
      "\n",
      "Fold: 20  Epoch: 140  Training loss = 4.6359  Validation loss = 1.1258  \n",
      "\n",
      "Fold: 20  Epoch: 141  Training loss = 4.6355  Validation loss = 1.1255  \n",
      "\n",
      "Fold: 20  Epoch: 142  Training loss = 4.6349  Validation loss = 1.1252  \n",
      "\n",
      "Fold: 20  Epoch: 143  Training loss = 4.6344  Validation loss = 1.1250  \n",
      "\n",
      "Fold: 20  Epoch: 144  Training loss = 4.6338  Validation loss = 1.1247  \n",
      "\n",
      "Fold: 20  Epoch: 145  Training loss = 4.6333  Validation loss = 1.1243  \n",
      "\n",
      "Fold: 20  Epoch: 146  Training loss = 4.6329  Validation loss = 1.1241  \n",
      "\n",
      "Fold: 20  Epoch: 147  Training loss = 4.6324  Validation loss = 1.1239  \n",
      "\n",
      "Fold: 20  Epoch: 148  Training loss = 4.6318  Validation loss = 1.1236  \n",
      "\n",
      "Fold: 20  Epoch: 149  Training loss = 4.6313  Validation loss = 1.1234  \n",
      "\n",
      "Fold: 20  Epoch: 150  Training loss = 4.6309  Validation loss = 1.1232  \n",
      "\n",
      "Fold: 20  Epoch: 151  Training loss = 4.6304  Validation loss = 1.1229  \n",
      "\n",
      "Fold: 20  Epoch: 152  Training loss = 4.6299  Validation loss = 1.1225  \n",
      "\n",
      "Fold: 20  Epoch: 153  Training loss = 4.6295  Validation loss = 1.1223  \n",
      "\n",
      "Fold: 20  Epoch: 154  Training loss = 4.6291  Validation loss = 1.1220  \n",
      "\n",
      "Fold: 20  Epoch: 155  Training loss = 4.6285  Validation loss = 1.1216  \n",
      "\n",
      "Fold: 20  Epoch: 156  Training loss = 4.6280  Validation loss = 1.1214  \n",
      "\n",
      "Fold: 20  Epoch: 157  Training loss = 4.6274  Validation loss = 1.1210  \n",
      "\n",
      "Fold: 20  Epoch: 158  Training loss = 4.6269  Validation loss = 1.1207  \n",
      "\n",
      "Fold: 20  Epoch: 159  Training loss = 4.6264  Validation loss = 1.1204  \n",
      "\n",
      "Fold: 20  Epoch: 160  Training loss = 4.6260  Validation loss = 1.1202  \n",
      "\n",
      "Fold: 20  Epoch: 161  Training loss = 4.6253  Validation loss = 1.1199  \n",
      "\n",
      "Fold: 20  Epoch: 162  Training loss = 4.6247  Validation loss = 1.1196  \n",
      "\n",
      "Fold: 20  Epoch: 163  Training loss = 4.6242  Validation loss = 1.1192  \n",
      "\n",
      "Fold: 20  Epoch: 164  Training loss = 4.6237  Validation loss = 1.1190  \n",
      "\n",
      "Fold: 20  Epoch: 165  Training loss = 4.6232  Validation loss = 1.1188  \n",
      "\n",
      "Fold: 20  Epoch: 166  Training loss = 4.6227  Validation loss = 1.1185  \n",
      "\n",
      "Fold: 20  Epoch: 167  Training loss = 4.6220  Validation loss = 1.1182  \n",
      "\n",
      "Fold: 20  Epoch: 168  Training loss = 4.6216  Validation loss = 1.1179  \n",
      "\n",
      "Fold: 20  Epoch: 169  Training loss = 4.6211  Validation loss = 1.1176  \n",
      "\n",
      "Fold: 20  Epoch: 170  Training loss = 4.6205  Validation loss = 1.1174  \n",
      "\n",
      "Fold: 20  Epoch: 171  Training loss = 4.6200  Validation loss = 1.1171  \n",
      "\n",
      "Fold: 20  Epoch: 172  Training loss = 4.6196  Validation loss = 1.1169  \n",
      "\n",
      "Fold: 20  Epoch: 173  Training loss = 4.6192  Validation loss = 1.1167  \n",
      "\n",
      "Fold: 20  Epoch: 174  Training loss = 4.6187  Validation loss = 1.1163  \n",
      "\n",
      "Fold: 20  Epoch: 175  Training loss = 4.6182  Validation loss = 1.1161  \n",
      "\n",
      "Fold: 20  Epoch: 176  Training loss = 4.6178  Validation loss = 1.1158  \n",
      "\n",
      "Fold: 20  Epoch: 177  Training loss = 4.6172  Validation loss = 1.1156  \n",
      "\n",
      "Fold: 20  Epoch: 178  Training loss = 4.6168  Validation loss = 1.1154  \n",
      "\n",
      "Fold: 20  Epoch: 179  Training loss = 4.6163  Validation loss = 1.1151  \n",
      "\n",
      "Fold: 20  Epoch: 180  Training loss = 4.6157  Validation loss = 1.1148  \n",
      "\n",
      "Fold: 20  Epoch: 181  Training loss = 4.6152  Validation loss = 1.1145  \n",
      "\n",
      "Fold: 20  Epoch: 182  Training loss = 4.6147  Validation loss = 1.1143  \n",
      "\n",
      "Fold: 20  Epoch: 183  Training loss = 4.6144  Validation loss = 1.1141  \n",
      "\n",
      "Fold: 20  Epoch: 184  Training loss = 4.6140  Validation loss = 1.1139  \n",
      "\n",
      "Fold: 20  Epoch: 185  Training loss = 4.6135  Validation loss = 1.1136  \n",
      "\n",
      "Fold: 20  Epoch: 186  Training loss = 4.6130  Validation loss = 1.1134  \n",
      "\n",
      "Fold: 20  Epoch: 187  Training loss = 4.6125  Validation loss = 1.1131  \n",
      "\n",
      "Fold: 20  Epoch: 188  Training loss = 4.6121  Validation loss = 1.1130  \n",
      "\n",
      "Fold: 20  Epoch: 189  Training loss = 4.6115  Validation loss = 1.1126  \n",
      "\n",
      "Fold: 20  Epoch: 190  Training loss = 4.6112  Validation loss = 1.1123  \n",
      "\n",
      "Fold: 20  Epoch: 191  Training loss = 4.6106  Validation loss = 1.1121  \n",
      "\n",
      "Fold: 20  Epoch: 192  Training loss = 4.6101  Validation loss = 1.1119  \n",
      "\n",
      "Fold: 20  Epoch: 193  Training loss = 4.6096  Validation loss = 1.1115  \n",
      "\n",
      "Fold: 20  Epoch: 194  Training loss = 4.6091  Validation loss = 1.1111  \n",
      "\n",
      "Fold: 20  Epoch: 195  Training loss = 4.6086  Validation loss = 1.1108  \n",
      "\n",
      "Fold: 20  Epoch: 196  Training loss = 4.6081  Validation loss = 1.1104  \n",
      "\n",
      "Fold: 20  Epoch: 197  Training loss = 4.6075  Validation loss = 1.1102  \n",
      "\n",
      "Fold: 20  Epoch: 198  Training loss = 4.6071  Validation loss = 1.1099  \n",
      "\n",
      "Fold: 20  Epoch: 199  Training loss = 4.6067  Validation loss = 1.1097  \n",
      "\n",
      "Fold: 20  Epoch: 200  Training loss = 4.6062  Validation loss = 1.1094  \n",
      "\n",
      "Fold: 20  Epoch: 201  Training loss = 4.6056  Validation loss = 1.1091  \n",
      "\n",
      "Fold: 20  Epoch: 202  Training loss = 4.6052  Validation loss = 1.1088  \n",
      "\n",
      "Fold: 20  Epoch: 203  Training loss = 4.6047  Validation loss = 1.1086  \n",
      "\n",
      "Fold: 20  Epoch: 204  Training loss = 4.6041  Validation loss = 1.1083  \n",
      "\n",
      "Fold: 20  Epoch: 205  Training loss = 4.6036  Validation loss = 1.1080  \n",
      "\n",
      "Fold: 20  Epoch: 206  Training loss = 4.6033  Validation loss = 1.1077  \n",
      "\n",
      "Fold: 20  Epoch: 207  Training loss = 4.6028  Validation loss = 1.1075  \n",
      "\n",
      "Fold: 20  Epoch: 208  Training loss = 4.6022  Validation loss = 1.1072  \n",
      "\n",
      "Fold: 20  Epoch: 209  Training loss = 4.6017  Validation loss = 1.1069  \n",
      "\n",
      "Fold: 20  Epoch: 210  Training loss = 4.6012  Validation loss = 1.1067  \n",
      "\n",
      "Fold: 20  Epoch: 211  Training loss = 4.6006  Validation loss = 1.1063  \n",
      "\n",
      "Fold: 20  Epoch: 212  Training loss = 4.6002  Validation loss = 1.1060  \n",
      "\n",
      "Fold: 20  Epoch: 213  Training loss = 4.5997  Validation loss = 1.1057  \n",
      "\n",
      "Fold: 20  Epoch: 214  Training loss = 4.5992  Validation loss = 1.1055  \n",
      "\n",
      "Fold: 20  Epoch: 215  Training loss = 4.5989  Validation loss = 1.1053  \n",
      "\n",
      "Fold: 20  Epoch: 216  Training loss = 4.5984  Validation loss = 1.1050  \n",
      "\n",
      "Fold: 20  Epoch: 217  Training loss = 4.5979  Validation loss = 1.1047  \n",
      "\n",
      "Fold: 20  Epoch: 218  Training loss = 4.5976  Validation loss = 1.1045  \n",
      "\n",
      "Fold: 20  Epoch: 219  Training loss = 4.5969  Validation loss = 1.1042  \n",
      "\n",
      "Fold: 20  Epoch: 220  Training loss = 4.5965  Validation loss = 1.1040  \n",
      "\n",
      "Fold: 20  Epoch: 221  Training loss = 4.5960  Validation loss = 1.1038  \n",
      "\n",
      "Fold: 20  Epoch: 222  Training loss = 4.5955  Validation loss = 1.1036  \n",
      "\n",
      "Fold: 20  Epoch: 223  Training loss = 4.5950  Validation loss = 1.1033  \n",
      "\n",
      "Fold: 20  Epoch: 224  Training loss = 4.5946  Validation loss = 1.1030  \n",
      "\n",
      "Fold: 20  Epoch: 225  Training loss = 4.5941  Validation loss = 1.1027  \n",
      "\n",
      "Fold: 20  Epoch: 226  Training loss = 4.5935  Validation loss = 1.1024  \n",
      "\n",
      "Fold: 20  Epoch: 227  Training loss = 4.5929  Validation loss = 1.1021  \n",
      "\n",
      "Fold: 20  Epoch: 228  Training loss = 4.5925  Validation loss = 1.1018  \n",
      "\n",
      "Fold: 20  Epoch: 229  Training loss = 4.5921  Validation loss = 1.1016  \n",
      "\n",
      "Fold: 20  Epoch: 230  Training loss = 4.5915  Validation loss = 1.1013  \n",
      "\n",
      "Fold: 20  Epoch: 231  Training loss = 4.5909  Validation loss = 1.1011  \n",
      "\n",
      "Fold: 20  Epoch: 232  Training loss = 4.5905  Validation loss = 1.1008  \n",
      "\n",
      "Fold: 20  Epoch: 233  Training loss = 4.5899  Validation loss = 1.1005  \n",
      "\n",
      "Fold: 20  Epoch: 234  Training loss = 4.5894  Validation loss = 1.1003  \n",
      "\n",
      "Fold: 20  Epoch: 235  Training loss = 4.5889  Validation loss = 1.1000  \n",
      "\n",
      "Fold: 20  Epoch: 236  Training loss = 4.5883  Validation loss = 1.0998  \n",
      "\n",
      "Fold: 20  Epoch: 237  Training loss = 4.5878  Validation loss = 1.0996  \n",
      "\n",
      "Fold: 20  Epoch: 238  Training loss = 4.5871  Validation loss = 1.0995  \n",
      "\n",
      "Fold: 20  Epoch: 239  Training loss = 4.5860  Validation loss = 1.0995  \n",
      "\n",
      "Fold: 20  Epoch: 240  Training loss = 4.5848  Validation loss = 1.0996  \n",
      "\n",
      "Fold: 20  Epoch: 241  Training loss = 4.5843  Validation loss = 1.0993  \n",
      "\n",
      "Fold: 20  Epoch: 242  Training loss = 4.5835  Validation loss = 1.0991  \n",
      "\n",
      "Fold: 20  Epoch: 243  Training loss = 4.5828  Validation loss = 1.0991  \n",
      "\n",
      "Fold: 20  Epoch: 244  Training loss = 4.5823  Validation loss = 1.0987  \n",
      "\n",
      "Fold: 20  Epoch: 245  Training loss = 4.5819  Validation loss = 1.0985  \n",
      "\n",
      "Fold: 20  Epoch: 246  Training loss = 4.5814  Validation loss = 1.0983  \n",
      "\n",
      "Fold: 20  Epoch: 247  Training loss = 4.5808  Validation loss = 1.0981  \n",
      "\n",
      "Fold: 20  Epoch: 248  Training loss = 4.5802  Validation loss = 1.0978  \n",
      "\n",
      "Fold: 20  Epoch: 249  Training loss = 4.5797  Validation loss = 1.0976  \n",
      "\n",
      "Fold: 20  Epoch: 250  Training loss = 4.5792  Validation loss = 1.0974  \n",
      "\n",
      "Fold: 20  Epoch: 251  Training loss = 4.5786  Validation loss = 1.0972  \n",
      "\n",
      "Fold: 20  Epoch: 252  Training loss = 4.5782  Validation loss = 1.0968  \n",
      "\n",
      "Fold: 20  Epoch: 253  Training loss = 4.5777  Validation loss = 1.0966  \n",
      "\n",
      "Fold: 20  Epoch: 254  Training loss = 4.5773  Validation loss = 1.0963  \n",
      "\n",
      "Fold: 20  Epoch: 255  Training loss = 4.5767  Validation loss = 1.0961  \n",
      "\n",
      "Fold: 20  Epoch: 256  Training loss = 4.5763  Validation loss = 1.0958  \n",
      "\n",
      "Fold: 20  Epoch: 257  Training loss = 4.5759  Validation loss = 1.0956  \n",
      "\n",
      "Fold: 20  Epoch: 258  Training loss = 4.5753  Validation loss = 1.0953  \n",
      "\n",
      "Fold: 20  Epoch: 259  Training loss = 4.5749  Validation loss = 1.0950  \n",
      "\n",
      "Fold: 20  Epoch: 260  Training loss = 4.5744  Validation loss = 1.0947  \n",
      "\n",
      "Fold: 20  Epoch: 261  Training loss = 4.5738  Validation loss = 1.0944  \n",
      "\n",
      "Fold: 20  Epoch: 262  Training loss = 4.5734  Validation loss = 1.0941  \n",
      "\n",
      "Fold: 20  Epoch: 263  Training loss = 4.5729  Validation loss = 1.0939  \n",
      "\n",
      "Fold: 20  Epoch: 264  Training loss = 4.5723  Validation loss = 1.0936  \n",
      "\n",
      "Fold: 20  Epoch: 265  Training loss = 4.5718  Validation loss = 1.0934  \n",
      "\n",
      "Fold: 20  Epoch: 266  Training loss = 4.5714  Validation loss = 1.0931  \n",
      "\n",
      "Fold: 20  Epoch: 267  Training loss = 4.5709  Validation loss = 1.0929  \n",
      "\n",
      "Fold: 20  Epoch: 268  Training loss = 4.5703  Validation loss = 1.0926  \n",
      "\n",
      "Fold: 20  Epoch: 269  Training loss = 4.5697  Validation loss = 1.0923  \n",
      "\n",
      "Fold: 20  Epoch: 270  Training loss = 4.5692  Validation loss = 1.0920  \n",
      "\n",
      "Fold: 20  Epoch: 271  Training loss = 4.5687  Validation loss = 1.0917  \n",
      "\n",
      "Fold: 20  Epoch: 272  Training loss = 4.5681  Validation loss = 1.0915  \n",
      "\n",
      "Fold: 20  Epoch: 273  Training loss = 4.5675  Validation loss = 1.0912  \n",
      "\n",
      "Fold: 20  Epoch: 274  Training loss = 4.5671  Validation loss = 1.0909  \n",
      "\n",
      "Fold: 20  Epoch: 275  Training loss = 4.5665  Validation loss = 1.0906  \n",
      "\n",
      "Fold: 20  Epoch: 276  Training loss = 4.5660  Validation loss = 1.0904  \n",
      "\n",
      "Fold: 20  Epoch: 277  Training loss = 4.5655  Validation loss = 1.0900  \n",
      "\n",
      "Fold: 20  Epoch: 278  Training loss = 4.5651  Validation loss = 1.0897  \n",
      "\n",
      "Fold: 20  Epoch: 279  Training loss = 4.5647  Validation loss = 1.0895  \n",
      "\n",
      "Fold: 20  Epoch: 280  Training loss = 4.5642  Validation loss = 1.0891  \n",
      "\n",
      "Fold: 20  Epoch: 281  Training loss = 4.5639  Validation loss = 1.0889  \n",
      "\n",
      "Fold: 20  Epoch: 282  Training loss = 4.5634  Validation loss = 1.0886  \n",
      "\n",
      "Fold: 20  Epoch: 283  Training loss = 4.5630  Validation loss = 1.0884  \n",
      "\n",
      "Fold: 20  Epoch: 284  Training loss = 4.5624  Validation loss = 1.0880  \n",
      "\n",
      "Fold: 20  Epoch: 285  Training loss = 4.5619  Validation loss = 1.0877  \n",
      "\n",
      "Fold: 20  Epoch: 286  Training loss = 4.5614  Validation loss = 1.0874  \n",
      "\n",
      "Fold: 20  Epoch: 287  Training loss = 4.5610  Validation loss = 1.0872  \n",
      "\n",
      "Fold: 20  Epoch: 288  Training loss = 4.5605  Validation loss = 1.0869  \n",
      "\n",
      "Fold: 20  Epoch: 289  Training loss = 4.5600  Validation loss = 1.0866  \n",
      "\n",
      "Fold: 20  Epoch: 290  Training loss = 4.5595  Validation loss = 1.0864  \n",
      "\n",
      "Fold: 20  Epoch: 291  Training loss = 4.5591  Validation loss = 1.0861  \n",
      "\n",
      "Fold: 20  Epoch: 292  Training loss = 4.5587  Validation loss = 1.0859  \n",
      "\n",
      "Fold: 20  Epoch: 293  Training loss = 4.5582  Validation loss = 1.0857  \n",
      "\n",
      "Fold: 20  Epoch: 294  Training loss = 4.5576  Validation loss = 1.0853  \n",
      "\n",
      "Fold: 20  Epoch: 295  Training loss = 4.5571  Validation loss = 1.0851  \n",
      "\n",
      "Fold: 20  Epoch: 296  Training loss = 4.5565  Validation loss = 1.0848  \n",
      "\n",
      "Fold: 20  Epoch: 297  Training loss = 4.5560  Validation loss = 1.0846  \n",
      "\n",
      "Fold: 20  Epoch: 298  Training loss = 4.5554  Validation loss = 1.0843  \n",
      "\n",
      "Fold: 20  Epoch: 299  Training loss = 4.5549  Validation loss = 1.0841  \n",
      "\n",
      "Fold: 20  Epoch: 300  Training loss = 4.5544  Validation loss = 1.0838  \n",
      "\n",
      "Fold: 20  Epoch: 301  Training loss = 4.5538  Validation loss = 1.0835  \n",
      "\n",
      "Fold: 20  Epoch: 302  Training loss = 4.5533  Validation loss = 1.0831  \n",
      "\n",
      "Fold: 20  Epoch: 303  Training loss = 4.5529  Validation loss = 1.0829  \n",
      "\n",
      "Fold: 20  Epoch: 304  Training loss = 4.5525  Validation loss = 1.0827  \n",
      "\n",
      "Fold: 20  Epoch: 305  Training loss = 4.5520  Validation loss = 1.0825  \n",
      "\n",
      "Fold: 20  Epoch: 306  Training loss = 4.5515  Validation loss = 1.0823  \n",
      "\n",
      "Fold: 20  Epoch: 307  Training loss = 4.5510  Validation loss = 1.0820  \n",
      "\n",
      "Fold: 20  Epoch: 308  Training loss = 4.5506  Validation loss = 1.0818  \n",
      "\n",
      "Fold: 20  Epoch: 309  Training loss = 4.5502  Validation loss = 1.0816  \n",
      "\n",
      "Fold: 20  Epoch: 310  Training loss = 4.5497  Validation loss = 1.0814  \n",
      "\n",
      "Fold: 20  Epoch: 311  Training loss = 4.5493  Validation loss = 1.0812  \n",
      "\n",
      "Fold: 20  Epoch: 312  Training loss = 4.5489  Validation loss = 1.0810  \n",
      "\n",
      "Fold: 20  Epoch: 313  Training loss = 4.5484  Validation loss = 1.0807  \n",
      "\n",
      "Fold: 20  Epoch: 314  Training loss = 4.5479  Validation loss = 1.0805  \n",
      "\n",
      "Fold: 20  Epoch: 315  Training loss = 4.5476  Validation loss = 1.0803  \n",
      "\n",
      "Fold: 20  Epoch: 316  Training loss = 4.5470  Validation loss = 1.0800  \n",
      "\n",
      "Fold: 20  Epoch: 317  Training loss = 4.5464  Validation loss = 1.0797  \n",
      "\n",
      "Fold: 20  Epoch: 318  Training loss = 4.5460  Validation loss = 1.0795  \n",
      "\n",
      "Fold: 20  Epoch: 319  Training loss = 4.5455  Validation loss = 1.0793  \n",
      "\n",
      "Fold: 20  Epoch: 320  Training loss = 4.5451  Validation loss = 1.0791  \n",
      "\n",
      "Fold: 20  Epoch: 321  Training loss = 4.5446  Validation loss = 1.0789  \n",
      "\n",
      "Fold: 20  Epoch: 322  Training loss = 4.5441  Validation loss = 1.0786  \n",
      "\n",
      "Fold: 20  Epoch: 323  Training loss = 4.5435  Validation loss = 1.0783  \n",
      "\n",
      "Fold: 20  Epoch: 324  Training loss = 4.5429  Validation loss = 1.0779  \n",
      "\n",
      "Fold: 20  Epoch: 325  Training loss = 4.5424  Validation loss = 1.0776  \n",
      "\n",
      "Fold: 20  Epoch: 326  Training loss = 4.5418  Validation loss = 1.0774  \n",
      "\n",
      "Fold: 20  Epoch: 327  Training loss = 4.5413  Validation loss = 1.0771  \n",
      "\n",
      "Fold: 20  Epoch: 328  Training loss = 4.5408  Validation loss = 1.0769  \n",
      "\n",
      "Fold: 20  Epoch: 329  Training loss = 4.5403  Validation loss = 1.0766  \n",
      "\n",
      "Fold: 20  Epoch: 330  Training loss = 4.5398  Validation loss = 1.0763  \n",
      "\n",
      "Fold: 20  Epoch: 331  Training loss = 4.5393  Validation loss = 1.0761  \n",
      "\n",
      "Fold: 20  Epoch: 332  Training loss = 4.5388  Validation loss = 1.0759  \n",
      "\n",
      "Fold: 20  Epoch: 333  Training loss = 4.5384  Validation loss = 1.0757  \n",
      "\n",
      "Fold: 20  Epoch: 334  Training loss = 4.5378  Validation loss = 1.0755  \n",
      "\n",
      "Fold: 20  Epoch: 335  Training loss = 4.5373  Validation loss = 1.0753  \n",
      "\n",
      "Fold: 20  Epoch: 336  Training loss = 4.5369  Validation loss = 1.0751  \n",
      "\n",
      "Fold: 20  Epoch: 337  Training loss = 4.5364  Validation loss = 1.0748  \n",
      "\n",
      "Fold: 20  Epoch: 338  Training loss = 4.5358  Validation loss = 1.0745  \n",
      "\n",
      "Fold: 20  Epoch: 339  Training loss = 4.5352  Validation loss = 1.0742  \n",
      "\n",
      "Fold: 20  Epoch: 340  Training loss = 4.5347  Validation loss = 1.0739  \n",
      "\n",
      "Fold: 20  Epoch: 341  Training loss = 4.5341  Validation loss = 1.0737  \n",
      "\n",
      "Fold: 20  Epoch: 342  Training loss = 4.5337  Validation loss = 1.0734  \n",
      "\n",
      "Fold: 20  Epoch: 343  Training loss = 4.5332  Validation loss = 1.0732  \n",
      "\n",
      "Fold: 20  Epoch: 344  Training loss = 4.5328  Validation loss = 1.0730  \n",
      "\n",
      "Fold: 20  Epoch: 345  Training loss = 4.5324  Validation loss = 1.0728  \n",
      "\n",
      "Fold: 20  Epoch: 346  Training loss = 4.5318  Validation loss = 1.0725  \n",
      "\n",
      "Fold: 20  Epoch: 347  Training loss = 4.5313  Validation loss = 1.0722  \n",
      "\n",
      "Fold: 20  Epoch: 348  Training loss = 4.5309  Validation loss = 1.0720  \n",
      "\n",
      "Fold: 20  Epoch: 349  Training loss = 4.5304  Validation loss = 1.0717  \n",
      "\n",
      "Fold: 20  Epoch: 350  Training loss = 4.5300  Validation loss = 1.0715  \n",
      "\n",
      "Fold: 20  Epoch: 351  Training loss = 4.5295  Validation loss = 1.0713  \n",
      "\n",
      "Fold: 20  Epoch: 352  Training loss = 4.5290  Validation loss = 1.0711  \n",
      "\n",
      "Fold: 20  Epoch: 353  Training loss = 4.5285  Validation loss = 1.0708  \n",
      "\n",
      "Fold: 20  Epoch: 354  Training loss = 4.5280  Validation loss = 1.0705  \n",
      "\n",
      "Fold: 20  Epoch: 355  Training loss = 4.5275  Validation loss = 1.0702  \n",
      "\n",
      "Fold: 20  Epoch: 356  Training loss = 4.5272  Validation loss = 1.0701  \n",
      "\n",
      "Fold: 20  Epoch: 357  Training loss = 4.5268  Validation loss = 1.0699  \n",
      "\n",
      "Fold: 20  Epoch: 358  Training loss = 4.5263  Validation loss = 1.0697  \n",
      "\n",
      "Fold: 20  Epoch: 359  Training loss = 4.5259  Validation loss = 1.0695  \n",
      "\n",
      "Fold: 20  Epoch: 360  Training loss = 4.5253  Validation loss = 1.0692  \n",
      "\n",
      "Fold: 20  Epoch: 361  Training loss = 4.5249  Validation loss = 1.0690  \n",
      "\n",
      "Fold: 20  Epoch: 362  Training loss = 4.5243  Validation loss = 1.0687  \n",
      "\n",
      "Fold: 20  Epoch: 363  Training loss = 4.5238  Validation loss = 1.0683  \n",
      "\n",
      "Fold: 20  Epoch: 364  Training loss = 4.5234  Validation loss = 1.0681  \n",
      "\n",
      "Fold: 20  Epoch: 365  Training loss = 4.5228  Validation loss = 1.0677  \n",
      "\n",
      "Fold: 20  Epoch: 366  Training loss = 4.5224  Validation loss = 1.0675  \n",
      "\n",
      "Fold: 20  Epoch: 367  Training loss = 4.5218  Validation loss = 1.0673  \n",
      "\n",
      "Fold: 20  Epoch: 368  Training loss = 4.5212  Validation loss = 1.0670  \n",
      "\n",
      "Fold: 20  Epoch: 369  Training loss = 4.5208  Validation loss = 1.0668  \n",
      "\n",
      "Fold: 20  Epoch: 370  Training loss = 4.5203  Validation loss = 1.0666  \n",
      "\n",
      "Fold: 20  Epoch: 371  Training loss = 4.5198  Validation loss = 1.0665  \n",
      "\n",
      "Fold: 20  Epoch: 372  Training loss = 4.5194  Validation loss = 1.0662  \n",
      "\n",
      "Fold: 20  Epoch: 373  Training loss = 4.5189  Validation loss = 1.0659  \n",
      "\n",
      "Fold: 20  Epoch: 374  Training loss = 4.5183  Validation loss = 1.0657  \n",
      "\n",
      "Fold: 20  Epoch: 375  Training loss = 4.5178  Validation loss = 1.0655  \n",
      "\n",
      "Fold: 20  Epoch: 376  Training loss = 4.5173  Validation loss = 1.0652  \n",
      "\n",
      "Fold: 20  Epoch: 377  Training loss = 4.5168  Validation loss = 1.0650  \n",
      "\n",
      "Fold: 20  Epoch: 378  Training loss = 4.5162  Validation loss = 1.0647  \n",
      "\n",
      "Fold: 20  Epoch: 379  Training loss = 4.5157  Validation loss = 1.0645  \n",
      "\n",
      "Fold: 20  Epoch: 380  Training loss = 4.5153  Validation loss = 1.0643  \n",
      "\n",
      "Fold: 20  Epoch: 381  Training loss = 4.5147  Validation loss = 1.0640  \n",
      "\n",
      "Fold: 20  Epoch: 382  Training loss = 4.5142  Validation loss = 1.0637  \n",
      "\n",
      "Fold: 20  Epoch: 383  Training loss = 4.5136  Validation loss = 1.0635  \n",
      "\n",
      "Fold: 20  Epoch: 384  Training loss = 4.5130  Validation loss = 1.0633  \n",
      "\n",
      "Fold: 20  Epoch: 385  Training loss = 4.5125  Validation loss = 1.0630  \n",
      "\n",
      "Fold: 20  Epoch: 386  Training loss = 4.5120  Validation loss = 1.0628  \n",
      "\n",
      "Fold: 20  Epoch: 387  Training loss = 4.5115  Validation loss = 1.0626  \n",
      "\n",
      "Fold: 20  Epoch: 388  Training loss = 4.5110  Validation loss = 1.0624  \n",
      "\n",
      "Fold: 20  Epoch: 389  Training loss = 4.5104  Validation loss = 1.0622  \n",
      "\n",
      "Fold: 20  Epoch: 390  Training loss = 4.5099  Validation loss = 1.0619  \n",
      "\n",
      "Fold: 20  Epoch: 391  Training loss = 4.5095  Validation loss = 1.0617  \n",
      "\n",
      "Fold: 20  Epoch: 392  Training loss = 4.5091  Validation loss = 1.0615  \n",
      "\n",
      "Fold: 20  Epoch: 393  Training loss = 4.5086  Validation loss = 1.0613  \n",
      "\n",
      "Fold: 20  Epoch: 394  Training loss = 4.5081  Validation loss = 1.0610  \n",
      "\n",
      "Fold: 20  Epoch: 395  Training loss = 4.5076  Validation loss = 1.0608  \n",
      "\n",
      "Fold: 20  Epoch: 396  Training loss = 4.5071  Validation loss = 1.0606  \n",
      "\n",
      "Fold: 20  Epoch: 397  Training loss = 4.5067  Validation loss = 1.0604  \n",
      "\n",
      "Fold: 20  Epoch: 398  Training loss = 4.5062  Validation loss = 1.0602  \n",
      "\n",
      "Fold: 20  Epoch: 399  Training loss = 4.5058  Validation loss = 1.0599  \n",
      "\n",
      "Fold: 20  Epoch: 400  Training loss = 4.5052  Validation loss = 1.0597  \n",
      "\n",
      "Fold: 20  Epoch: 401  Training loss = 4.5048  Validation loss = 1.0594  \n",
      "\n",
      "Fold: 20  Epoch: 402  Training loss = 4.5043  Validation loss = 1.0592  \n",
      "\n",
      "Fold: 20  Epoch: 403  Training loss = 4.5039  Validation loss = 1.0590  \n",
      "\n",
      "Fold: 20  Epoch: 404  Training loss = 4.5035  Validation loss = 1.0589  \n",
      "\n",
      "Fold: 20  Epoch: 405  Training loss = 4.5030  Validation loss = 1.0587  \n",
      "\n",
      "Fold: 20  Epoch: 406  Training loss = 4.5026  Validation loss = 1.0585  \n",
      "\n",
      "Fold: 20  Epoch: 407  Training loss = 4.5023  Validation loss = 1.0583  \n",
      "\n",
      "Fold: 20  Epoch: 408  Training loss = 4.5018  Validation loss = 1.0581  \n",
      "\n",
      "Fold: 20  Epoch: 409  Training loss = 4.5013  Validation loss = 1.0578  \n",
      "\n",
      "Fold: 20  Epoch: 410  Training loss = 4.5009  Validation loss = 1.0576  \n",
      "\n",
      "Fold: 20  Epoch: 411  Training loss = 4.5005  Validation loss = 1.0574  \n",
      "\n",
      "Fold: 20  Epoch: 412  Training loss = 4.5001  Validation loss = 1.0572  \n",
      "\n",
      "Fold: 20  Epoch: 413  Training loss = 4.4997  Validation loss = 1.0570  \n",
      "\n",
      "Fold: 20  Epoch: 414  Training loss = 4.4992  Validation loss = 1.0567  \n",
      "\n",
      "Fold: 20  Epoch: 415  Training loss = 4.4987  Validation loss = 1.0565  \n",
      "\n",
      "Fold: 20  Epoch: 416  Training loss = 4.4983  Validation loss = 1.0562  \n",
      "\n",
      "Fold: 20  Epoch: 417  Training loss = 4.4978  Validation loss = 1.0560  \n",
      "\n",
      "Fold: 20  Epoch: 418  Training loss = 4.4973  Validation loss = 1.0558  \n",
      "\n",
      "Fold: 20  Epoch: 419  Training loss = 4.4968  Validation loss = 1.0555  \n",
      "\n",
      "Fold: 20  Epoch: 420  Training loss = 4.4964  Validation loss = 1.0552  \n",
      "\n",
      "Fold: 20  Epoch: 421  Training loss = 4.4959  Validation loss = 1.0550  \n",
      "\n",
      "Fold: 20  Epoch: 422  Training loss = 4.4952  Validation loss = 1.0546  \n",
      "\n",
      "Fold: 20  Epoch: 423  Training loss = 4.4948  Validation loss = 1.0544  \n",
      "\n",
      "Fold: 20  Epoch: 424  Training loss = 4.4944  Validation loss = 1.0542  \n",
      "\n",
      "Fold: 20  Epoch: 425  Training loss = 4.4938  Validation loss = 1.0538  \n",
      "\n",
      "Fold: 20  Epoch: 426  Training loss = 4.4934  Validation loss = 1.0536  \n",
      "\n",
      "Fold: 20  Epoch: 427  Training loss = 4.4928  Validation loss = 1.0533  \n",
      "\n",
      "Fold: 20  Epoch: 428  Training loss = 4.4923  Validation loss = 1.0530  \n",
      "\n",
      "Fold: 20  Epoch: 429  Training loss = 4.4918  Validation loss = 1.0528  \n",
      "\n",
      "Fold: 20  Epoch: 430  Training loss = 4.4914  Validation loss = 1.0527  \n",
      "\n",
      "Fold: 20  Epoch: 431  Training loss = 4.4908  Validation loss = 1.0525  \n",
      "\n",
      "Fold: 20  Epoch: 432  Training loss = 4.4904  Validation loss = 1.0523  \n",
      "\n",
      "Fold: 20  Epoch: 433  Training loss = 4.4899  Validation loss = 1.0521  \n",
      "\n",
      "Fold: 20  Epoch: 434  Training loss = 4.4894  Validation loss = 1.0518  \n",
      "\n",
      "Fold: 20  Epoch: 435  Training loss = 4.4889  Validation loss = 1.0516  \n",
      "\n",
      "Fold: 20  Epoch: 436  Training loss = 4.4884  Validation loss = 1.0513  \n",
      "\n",
      "Fold: 20  Epoch: 437  Training loss = 4.4878  Validation loss = 1.0511  \n",
      "\n",
      "Fold: 20  Epoch: 438  Training loss = 4.4873  Validation loss = 1.0508  \n",
      "\n",
      "Fold: 20  Epoch: 439  Training loss = 4.4869  Validation loss = 1.0506  \n",
      "\n",
      "Fold: 20  Epoch: 440  Training loss = 4.4864  Validation loss = 1.0503  \n",
      "\n",
      "Fold: 20  Epoch: 441  Training loss = 4.4860  Validation loss = 1.0501  \n",
      "\n",
      "Fold: 20  Epoch: 442  Training loss = 4.4857  Validation loss = 1.0500  \n",
      "\n",
      "Fold: 20  Epoch: 443  Training loss = 4.4852  Validation loss = 1.0497  \n",
      "\n",
      "Fold: 20  Epoch: 444  Training loss = 4.4847  Validation loss = 1.0494  \n",
      "\n",
      "Fold: 20  Epoch: 445  Training loss = 4.4842  Validation loss = 1.0492  \n",
      "\n",
      "Fold: 20  Epoch: 446  Training loss = 4.4838  Validation loss = 1.0489  \n",
      "\n",
      "Fold: 20  Epoch: 447  Training loss = 4.4833  Validation loss = 1.0487  \n",
      "\n",
      "Fold: 20  Epoch: 448  Training loss = 4.4828  Validation loss = 1.0485  \n",
      "\n",
      "Fold: 20  Epoch: 449  Training loss = 4.4823  Validation loss = 1.0483  \n",
      "\n",
      "Fold: 20  Epoch: 450  Training loss = 4.4818  Validation loss = 1.0481  \n",
      "\n",
      "Fold: 20  Epoch: 451  Training loss = 4.4814  Validation loss = 1.0479  \n",
      "\n",
      "Fold: 20  Epoch: 452  Training loss = 4.4811  Validation loss = 1.0477  \n",
      "\n",
      "Fold: 20  Epoch: 453  Training loss = 4.4804  Validation loss = 1.0475  \n",
      "\n",
      "Fold: 20  Epoch: 454  Training loss = 4.4800  Validation loss = 1.0473  \n",
      "\n",
      "Fold: 20  Epoch: 455  Training loss = 4.4795  Validation loss = 1.0471  \n",
      "\n",
      "Fold: 20  Epoch: 456  Training loss = 4.4791  Validation loss = 1.0469  \n",
      "\n",
      "Fold: 20  Epoch: 457  Training loss = 4.4784  Validation loss = 1.0466  \n",
      "\n",
      "Fold: 20  Epoch: 458  Training loss = 4.4780  Validation loss = 1.0464  \n",
      "\n",
      "Fold: 20  Epoch: 459  Training loss = 4.4775  Validation loss = 1.0461  \n",
      "\n",
      "Fold: 20  Epoch: 460  Training loss = 4.4770  Validation loss = 1.0458  \n",
      "\n",
      "Fold: 20  Epoch: 461  Training loss = 4.4765  Validation loss = 1.0456  \n",
      "\n",
      "Fold: 20  Epoch: 462  Training loss = 4.4759  Validation loss = 1.0453  \n",
      "\n",
      "Fold: 20  Epoch: 463  Training loss = 4.4754  Validation loss = 1.0450  \n",
      "\n",
      "Fold: 20  Epoch: 464  Training loss = 4.4749  Validation loss = 1.0448  \n",
      "\n",
      "Fold: 20  Epoch: 465  Training loss = 4.4743  Validation loss = 1.0446  \n",
      "\n",
      "Fold: 20  Epoch: 466  Training loss = 4.4738  Validation loss = 1.0444  \n",
      "\n",
      "Fold: 20  Epoch: 467  Training loss = 4.4734  Validation loss = 1.0442  \n",
      "\n",
      "Fold: 20  Epoch: 468  Training loss = 4.4730  Validation loss = 1.0440  \n",
      "\n",
      "Fold: 20  Epoch: 469  Training loss = 4.4725  Validation loss = 1.0437  \n",
      "\n",
      "Fold: 20  Epoch: 470  Training loss = 4.4721  Validation loss = 1.0435  \n",
      "\n",
      "Fold: 20  Epoch: 471  Training loss = 4.4717  Validation loss = 1.0434  \n",
      "\n",
      "Fold: 20  Epoch: 472  Training loss = 4.4711  Validation loss = 1.0431  \n",
      "\n",
      "Fold: 20  Epoch: 473  Training loss = 4.4708  Validation loss = 1.0429  \n",
      "\n",
      "Fold: 20  Epoch: 474  Training loss = 4.4704  Validation loss = 1.0426  \n",
      "\n",
      "Fold: 20  Epoch: 475  Training loss = 4.4698  Validation loss = 1.0422  \n",
      "\n",
      "Fold: 20  Epoch: 476  Training loss = 4.4692  Validation loss = 1.0420  \n",
      "\n",
      "Fold: 20  Epoch: 477  Training loss = 4.4688  Validation loss = 1.0418  \n",
      "\n",
      "Fold: 20  Epoch: 478  Training loss = 4.4683  Validation loss = 1.0416  \n",
      "\n",
      "Fold: 20  Epoch: 479  Training loss = 4.4678  Validation loss = 1.0414  \n",
      "\n",
      "Fold: 20  Epoch: 480  Training loss = 4.4672  Validation loss = 1.0413  \n",
      "\n",
      "Fold: 20  Epoch: 481  Training loss = 4.4669  Validation loss = 1.0411  \n",
      "\n",
      "Fold: 20  Epoch: 482  Training loss = 4.4664  Validation loss = 1.0409  \n",
      "\n",
      "Fold: 20  Epoch: 483  Training loss = 4.4660  Validation loss = 1.0407  \n",
      "\n",
      "Fold: 20  Epoch: 484  Training loss = 4.4655  Validation loss = 1.0406  \n",
      "\n",
      "Fold: 20  Epoch: 485  Training loss = 4.4651  Validation loss = 1.0404  \n",
      "\n",
      "Fold: 20  Epoch: 486  Training loss = 4.4647  Validation loss = 1.0402  \n",
      "\n",
      "Fold: 20  Epoch: 487  Training loss = 4.4642  Validation loss = 1.0401  \n",
      "\n",
      "Fold: 20  Epoch: 488  Training loss = 4.4637  Validation loss = 1.0399  \n",
      "\n",
      "Fold: 20  Epoch: 489  Training loss = 4.4632  Validation loss = 1.0397  \n",
      "\n",
      "Fold: 20  Epoch: 490  Training loss = 4.4628  Validation loss = 1.0395  \n",
      "\n",
      "Fold: 20  Epoch: 491  Training loss = 4.4623  Validation loss = 1.0392  \n",
      "\n",
      "Fold: 20  Epoch: 492  Training loss = 4.4618  Validation loss = 1.0391  \n",
      "\n",
      "Fold: 20  Epoch: 493  Training loss = 4.4613  Validation loss = 1.0389  \n",
      "\n",
      "Fold: 20  Epoch: 494  Training loss = 4.4609  Validation loss = 1.0387  \n",
      "\n",
      "Fold: 20  Epoch: 495  Training loss = 4.4604  Validation loss = 1.0385  \n",
      "\n",
      "Fold: 20  Epoch: 496  Training loss = 4.4599  Validation loss = 1.0382  \n",
      "\n",
      "Fold: 20  Epoch: 497  Training loss = 4.4594  Validation loss = 1.0380  \n",
      "\n",
      "Fold: 20  Epoch: 498  Training loss = 4.4590  Validation loss = 1.0378  \n",
      "\n",
      "Fold: 20  Epoch: 499  Training loss = 4.4585  Validation loss = 1.0377  \n",
      "\n",
      "Fold: 20  Epoch: 500  Training loss = 4.4582  Validation loss = 1.0374  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 500  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 4.4475  Validation loss = 3.4203  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 4.4471  Validation loss = 3.4207  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 4.4468  Validation loss = 3.4210  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 4.4464  Validation loss = 3.4214  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 4.4459  Validation loss = 3.4218  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 4.4455  Validation loss = 3.4223  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 4.4449  Validation loss = 3.4228  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 4.4445  Validation loss = 3.4232  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 4.4441  Validation loss = 3.4236  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 4.4435  Validation loss = 3.4242  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 4.4430  Validation loss = 3.4246  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 4.5068  Validation loss = 2.3519  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 4.5064  Validation loss = 2.3517  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 4.5060  Validation loss = 2.3513  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 4.5056  Validation loss = 2.3510  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 4.5052  Validation loss = 2.3508  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 4.5048  Validation loss = 2.3507  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 4.5044  Validation loss = 2.3505  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 4.5039  Validation loss = 2.3501  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 4.5036  Validation loss = 2.3497  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 4.5031  Validation loss = 2.3494  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 4.5027  Validation loss = 2.3492  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 4.5023  Validation loss = 2.3489  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 4.5019  Validation loss = 2.3486  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 4.5015  Validation loss = 2.3481  \n",
      "\n",
      "Fold: 22  Epoch: 15  Training loss = 4.5011  Validation loss = 2.3480  \n",
      "\n",
      "Fold: 22  Epoch: 16  Training loss = 4.5007  Validation loss = 2.3477  \n",
      "\n",
      "Fold: 22  Epoch: 17  Training loss = 4.5002  Validation loss = 2.3475  \n",
      "\n",
      "Fold: 22  Epoch: 18  Training loss = 4.4998  Validation loss = 2.3472  \n",
      "\n",
      "Fold: 22  Epoch: 19  Training loss = 4.4995  Validation loss = 2.3471  \n",
      "\n",
      "Fold: 22  Epoch: 20  Training loss = 4.4992  Validation loss = 2.3469  \n",
      "\n",
      "Fold: 22  Epoch: 21  Training loss = 4.4989  Validation loss = 2.3466  \n",
      "\n",
      "Fold: 22  Epoch: 22  Training loss = 4.4984  Validation loss = 2.3463  \n",
      "\n",
      "Fold: 22  Epoch: 23  Training loss = 4.4980  Validation loss = 2.3461  \n",
      "\n",
      "Fold: 22  Epoch: 24  Training loss = 4.4977  Validation loss = 2.3458  \n",
      "\n",
      "Fold: 22  Epoch: 25  Training loss = 4.4974  Validation loss = 2.3458  \n",
      "\n",
      "Fold: 22  Epoch: 26  Training loss = 4.4969  Validation loss = 2.3455  \n",
      "\n",
      "Fold: 22  Epoch: 27  Training loss = 4.4966  Validation loss = 2.3451  \n",
      "\n",
      "Fold: 22  Epoch: 28  Training loss = 4.4963  Validation loss = 2.3449  \n",
      "\n",
      "Fold: 22  Epoch: 29  Training loss = 4.4960  Validation loss = 2.3447  \n",
      "\n",
      "Fold: 22  Epoch: 30  Training loss = 4.4956  Validation loss = 2.3446  \n",
      "\n",
      "Fold: 22  Epoch: 31  Training loss = 4.4952  Validation loss = 2.3443  \n",
      "\n",
      "Fold: 22  Epoch: 32  Training loss = 4.4948  Validation loss = 2.3440  \n",
      "\n",
      "Fold: 22  Epoch: 33  Training loss = 4.4943  Validation loss = 2.3436  \n",
      "\n",
      "Fold: 22  Epoch: 34  Training loss = 4.4939  Validation loss = 2.3434  \n",
      "\n",
      "Fold: 22  Epoch: 35  Training loss = 4.4934  Validation loss = 2.3431  \n",
      "\n",
      "Fold: 22  Epoch: 36  Training loss = 4.4930  Validation loss = 2.3428  \n",
      "\n",
      "Fold: 22  Epoch: 37  Training loss = 4.4926  Validation loss = 2.3425  \n",
      "\n",
      "Fold: 22  Epoch: 38  Training loss = 4.4924  Validation loss = 2.3423  \n",
      "\n",
      "Fold: 22  Epoch: 39  Training loss = 4.4919  Validation loss = 2.3420  \n",
      "\n",
      "Fold: 22  Epoch: 40  Training loss = 4.4916  Validation loss = 2.3416  \n",
      "\n",
      "Fold: 22  Epoch: 41  Training loss = 4.4912  Validation loss = 2.3414  \n",
      "\n",
      "Fold: 22  Epoch: 42  Training loss = 4.4909  Validation loss = 2.3412  \n",
      "\n",
      "Fold: 22  Epoch: 43  Training loss = 4.4905  Validation loss = 2.3409  \n",
      "\n",
      "Fold: 22  Epoch: 44  Training loss = 4.4901  Validation loss = 2.3406  \n",
      "\n",
      "Fold: 22  Epoch: 45  Training loss = 4.4897  Validation loss = 2.3404  \n",
      "\n",
      "Fold: 22  Epoch: 46  Training loss = 4.4894  Validation loss = 2.3402  \n",
      "\n",
      "Fold: 22  Epoch: 47  Training loss = 4.4891  Validation loss = 2.3397  \n",
      "\n",
      "Fold: 22  Epoch: 48  Training loss = 4.4888  Validation loss = 2.3395  \n",
      "\n",
      "Fold: 22  Epoch: 49  Training loss = 4.4884  Validation loss = 2.3393  \n",
      "\n",
      "Fold: 22  Epoch: 50  Training loss = 4.4880  Validation loss = 2.3390  \n",
      "\n",
      "Fold: 22  Epoch: 51  Training loss = 4.4875  Validation loss = 2.3388  \n",
      "\n",
      "Fold: 22  Epoch: 52  Training loss = 4.4873  Validation loss = 2.3387  \n",
      "\n",
      "Fold: 22  Epoch: 53  Training loss = 4.4871  Validation loss = 2.3384  \n",
      "\n",
      "Fold: 22  Epoch: 54  Training loss = 4.4866  Validation loss = 2.3382  \n",
      "\n",
      "Fold: 22  Epoch: 55  Training loss = 4.4862  Validation loss = 2.3379  \n",
      "\n",
      "Fold: 22  Epoch: 56  Training loss = 4.4858  Validation loss = 2.3377  \n",
      "\n",
      "Fold: 22  Epoch: 57  Training loss = 4.4854  Validation loss = 2.3376  \n",
      "\n",
      "Fold: 22  Epoch: 58  Training loss = 4.4851  Validation loss = 2.3374  \n",
      "\n",
      "Fold: 22  Epoch: 59  Training loss = 4.4847  Validation loss = 2.3371  \n",
      "\n",
      "Fold: 22  Epoch: 60  Training loss = 4.4844  Validation loss = 2.3370  \n",
      "\n",
      "Fold: 22  Epoch: 61  Training loss = 4.4840  Validation loss = 2.3368  \n",
      "\n",
      "Fold: 22  Epoch: 62  Training loss = 4.4837  Validation loss = 2.3366  \n",
      "\n",
      "Fold: 22  Epoch: 63  Training loss = 4.4835  Validation loss = 2.3363  \n",
      "\n",
      "Fold: 22  Epoch: 64  Training loss = 4.4831  Validation loss = 2.3361  \n",
      "\n",
      "Fold: 22  Epoch: 65  Training loss = 4.4827  Validation loss = 2.3359  \n",
      "\n",
      "Fold: 22  Epoch: 66  Training loss = 4.4823  Validation loss = 2.3357  \n",
      "\n",
      "Fold: 22  Epoch: 67  Training loss = 4.4819  Validation loss = 2.3354  \n",
      "\n",
      "Fold: 22  Epoch: 68  Training loss = 4.4815  Validation loss = 2.3351  \n",
      "\n",
      "Fold: 22  Epoch: 69  Training loss = 4.4811  Validation loss = 2.3348  \n",
      "\n",
      "Fold: 22  Epoch: 70  Training loss = 4.4807  Validation loss = 2.3345  \n",
      "\n",
      "Fold: 22  Epoch: 71  Training loss = 4.4803  Validation loss = 2.3343  \n",
      "\n",
      "Fold: 22  Epoch: 72  Training loss = 4.4800  Validation loss = 2.3341  \n",
      "\n",
      "Fold: 22  Epoch: 73  Training loss = 4.4797  Validation loss = 2.3339  \n",
      "\n",
      "Fold: 22  Epoch: 74  Training loss = 4.4794  Validation loss = 2.3335  \n",
      "\n",
      "Fold: 22  Epoch: 75  Training loss = 4.4790  Validation loss = 2.3334  \n",
      "\n",
      "Fold: 22  Epoch: 76  Training loss = 4.4787  Validation loss = 2.3332  \n",
      "\n",
      "Fold: 22  Epoch: 77  Training loss = 4.4783  Validation loss = 2.3329  \n",
      "\n",
      "Fold: 22  Epoch: 78  Training loss = 4.4780  Validation loss = 2.3325  \n",
      "\n",
      "Fold: 22  Epoch: 79  Training loss = 4.4776  Validation loss = 2.3324  \n",
      "\n",
      "Fold: 22  Epoch: 80  Training loss = 4.4771  Validation loss = 2.3321  \n",
      "\n",
      "Fold: 22  Epoch: 81  Training loss = 4.4769  Validation loss = 2.3319  \n",
      "\n",
      "Fold: 22  Epoch: 82  Training loss = 4.4765  Validation loss = 2.3317  \n",
      "\n",
      "Fold: 22  Epoch: 83  Training loss = 4.4761  Validation loss = 2.3316  \n",
      "\n",
      "Fold: 22  Epoch: 84  Training loss = 4.4757  Validation loss = 2.3314  \n",
      "\n",
      "Fold: 22  Epoch: 85  Training loss = 4.4754  Validation loss = 2.3311  \n",
      "\n",
      "Fold: 22  Epoch: 86  Training loss = 4.4751  Validation loss = 2.3309  \n",
      "\n",
      "Fold: 22  Epoch: 87  Training loss = 4.4747  Validation loss = 2.3306  \n",
      "\n",
      "Fold: 22  Epoch: 88  Training loss = 4.4742  Validation loss = 2.3303  \n",
      "\n",
      "Fold: 22  Epoch: 89  Training loss = 4.4738  Validation loss = 2.3300  \n",
      "\n",
      "Fold: 22  Epoch: 90  Training loss = 4.4735  Validation loss = 2.3298  \n",
      "\n",
      "Fold: 22  Epoch: 91  Training loss = 4.4731  Validation loss = 2.3295  \n",
      "\n",
      "Fold: 22  Epoch: 92  Training loss = 4.4728  Validation loss = 2.3294  \n",
      "\n",
      "Fold: 22  Epoch: 93  Training loss = 4.4725  Validation loss = 2.3291  \n",
      "\n",
      "Fold: 22  Epoch: 94  Training loss = 4.4721  Validation loss = 2.3289  \n",
      "\n",
      "Fold: 22  Epoch: 95  Training loss = 4.4717  Validation loss = 2.3287  \n",
      "\n",
      "Fold: 22  Epoch: 96  Training loss = 4.4714  Validation loss = 2.3285  \n",
      "\n",
      "Fold: 22  Epoch: 97  Training loss = 4.4711  Validation loss = 2.3282  \n",
      "\n",
      "Fold: 22  Epoch: 98  Training loss = 4.4707  Validation loss = 2.3281  \n",
      "\n",
      "Fold: 22  Epoch: 99  Training loss = 4.4702  Validation loss = 2.3279  \n",
      "\n",
      "Fold: 22  Epoch: 100  Training loss = 4.4699  Validation loss = 2.3275  \n",
      "\n",
      "Fold: 22  Epoch: 101  Training loss = 4.4695  Validation loss = 2.3273  \n",
      "\n",
      "Fold: 22  Epoch: 102  Training loss = 4.4691  Validation loss = 2.3270  \n",
      "\n",
      "Fold: 22  Epoch: 103  Training loss = 4.4688  Validation loss = 2.3269  \n",
      "\n",
      "Fold: 22  Epoch: 104  Training loss = 4.4685  Validation loss = 2.3267  \n",
      "\n",
      "Fold: 22  Epoch: 105  Training loss = 4.4681  Validation loss = 2.3265  \n",
      "\n",
      "Fold: 22  Epoch: 106  Training loss = 4.4677  Validation loss = 2.3263  \n",
      "\n",
      "Fold: 22  Epoch: 107  Training loss = 4.4673  Validation loss = 2.3261  \n",
      "\n",
      "Fold: 22  Epoch: 108  Training loss = 4.4669  Validation loss = 2.3258  \n",
      "\n",
      "Fold: 22  Epoch: 109  Training loss = 4.4666  Validation loss = 2.3255  \n",
      "\n",
      "Fold: 22  Epoch: 110  Training loss = 4.4662  Validation loss = 2.3252  \n",
      "\n",
      "Fold: 22  Epoch: 111  Training loss = 4.4657  Validation loss = 2.3249  \n",
      "\n",
      "Fold: 22  Epoch: 112  Training loss = 4.4653  Validation loss = 2.3247  \n",
      "\n",
      "Fold: 22  Epoch: 113  Training loss = 4.4650  Validation loss = 2.3244  \n",
      "\n",
      "Fold: 22  Epoch: 114  Training loss = 4.4645  Validation loss = 2.3241  \n",
      "\n",
      "Fold: 22  Epoch: 115  Training loss = 4.4641  Validation loss = 2.3239  \n",
      "\n",
      "Fold: 22  Epoch: 116  Training loss = 4.4637  Validation loss = 2.3238  \n",
      "\n",
      "Fold: 22  Epoch: 117  Training loss = 4.4634  Validation loss = 2.3235  \n",
      "\n",
      "Fold: 22  Epoch: 118  Training loss = 4.4629  Validation loss = 2.3234  \n",
      "\n",
      "Fold: 22  Epoch: 119  Training loss = 4.4625  Validation loss = 2.3233  \n",
      "\n",
      "Fold: 22  Epoch: 120  Training loss = 4.4622  Validation loss = 2.3230  \n",
      "\n",
      "Fold: 22  Epoch: 121  Training loss = 4.4619  Validation loss = 2.3228  \n",
      "\n",
      "Fold: 22  Epoch: 122  Training loss = 4.4616  Validation loss = 2.3225  \n",
      "\n",
      "Fold: 22  Epoch: 123  Training loss = 4.4612  Validation loss = 2.3221  \n",
      "\n",
      "Fold: 22  Epoch: 124  Training loss = 4.4609  Validation loss = 2.3219  \n",
      "\n",
      "Fold: 22  Epoch: 125  Training loss = 4.4606  Validation loss = 2.3216  \n",
      "\n",
      "Fold: 22  Epoch: 126  Training loss = 4.4603  Validation loss = 2.3213  \n",
      "\n",
      "Fold: 22  Epoch: 127  Training loss = 4.4599  Validation loss = 2.3212  \n",
      "\n",
      "Fold: 22  Epoch: 128  Training loss = 4.4596  Validation loss = 2.3211  \n",
      "\n",
      "Fold: 22  Epoch: 129  Training loss = 4.4591  Validation loss = 2.3207  \n",
      "\n",
      "Fold: 22  Epoch: 130  Training loss = 4.4587  Validation loss = 2.3205  \n",
      "\n",
      "Fold: 22  Epoch: 131  Training loss = 4.4582  Validation loss = 2.3203  \n",
      "\n",
      "Fold: 22  Epoch: 132  Training loss = 4.4579  Validation loss = 2.3202  \n",
      "\n",
      "Fold: 22  Epoch: 133  Training loss = 4.4575  Validation loss = 2.3197  \n",
      "\n",
      "Fold: 22  Epoch: 134  Training loss = 4.4572  Validation loss = 2.3196  \n",
      "\n",
      "Fold: 22  Epoch: 135  Training loss = 4.4568  Validation loss = 2.3194  \n",
      "\n",
      "Fold: 22  Epoch: 136  Training loss = 4.4564  Validation loss = 2.3192  \n",
      "\n",
      "Fold: 22  Epoch: 137  Training loss = 4.4560  Validation loss = 2.3190  \n",
      "\n",
      "Fold: 22  Epoch: 138  Training loss = 4.4555  Validation loss = 2.3187  \n",
      "\n",
      "Fold: 22  Epoch: 139  Training loss = 4.4552  Validation loss = 2.3185  \n",
      "\n",
      "Fold: 22  Epoch: 140  Training loss = 4.4549  Validation loss = 2.3182  \n",
      "\n",
      "Fold: 22  Epoch: 141  Training loss = 4.4545  Validation loss = 2.3180  \n",
      "\n",
      "Fold: 22  Epoch: 142  Training loss = 4.4541  Validation loss = 2.3175  \n",
      "\n",
      "Fold: 22  Epoch: 143  Training loss = 4.4537  Validation loss = 2.3173  \n",
      "\n",
      "Fold: 22  Epoch: 144  Training loss = 4.4532  Validation loss = 2.3171  \n",
      "\n",
      "Fold: 22  Epoch: 145  Training loss = 4.4528  Validation loss = 2.3169  \n",
      "\n",
      "Fold: 22  Epoch: 146  Training loss = 4.4526  Validation loss = 2.3166  \n",
      "\n",
      "Fold: 22  Epoch: 147  Training loss = 4.4522  Validation loss = 2.3163  \n",
      "\n",
      "Fold: 22  Epoch: 148  Training loss = 4.4520  Validation loss = 2.3163  \n",
      "\n",
      "Fold: 22  Epoch: 149  Training loss = 4.4516  Validation loss = 2.3161  \n",
      "\n",
      "Fold: 22  Epoch: 150  Training loss = 4.4512  Validation loss = 2.3158  \n",
      "\n",
      "Fold: 22  Epoch: 151  Training loss = 4.4509  Validation loss = 2.3155  \n",
      "\n",
      "Fold: 22  Epoch: 152  Training loss = 4.4506  Validation loss = 2.3154  \n",
      "\n",
      "Fold: 22  Epoch: 153  Training loss = 4.4502  Validation loss = 2.3153  \n",
      "\n",
      "Fold: 22  Epoch: 154  Training loss = 4.4499  Validation loss = 2.3150  \n",
      "\n",
      "Fold: 22  Epoch: 155  Training loss = 4.4495  Validation loss = 2.3147  \n",
      "\n",
      "Fold: 22  Epoch: 156  Training loss = 4.4492  Validation loss = 2.3145  \n",
      "\n",
      "Fold: 22  Epoch: 157  Training loss = 4.4488  Validation loss = 2.3142  \n",
      "\n",
      "Fold: 22  Epoch: 158  Training loss = 4.4484  Validation loss = 2.3140  \n",
      "\n",
      "Fold: 22  Epoch: 159  Training loss = 4.4480  Validation loss = 2.3137  \n",
      "\n",
      "Fold: 22  Epoch: 160  Training loss = 4.4476  Validation loss = 2.3136  \n",
      "\n",
      "Fold: 22  Epoch: 161  Training loss = 4.4472  Validation loss = 2.3133  \n",
      "\n",
      "Fold: 22  Epoch: 162  Training loss = 4.4468  Validation loss = 2.3132  \n",
      "\n",
      "Fold: 22  Epoch: 163  Training loss = 4.4464  Validation loss = 2.3129  \n",
      "\n",
      "Fold: 22  Epoch: 164  Training loss = 4.4461  Validation loss = 2.3126  \n",
      "\n",
      "Fold: 22  Epoch: 165  Training loss = 4.4457  Validation loss = 2.3125  \n",
      "\n",
      "Fold: 22  Epoch: 166  Training loss = 4.4453  Validation loss = 2.3123  \n",
      "\n",
      "Fold: 22  Epoch: 167  Training loss = 4.4450  Validation loss = 2.3121  \n",
      "\n",
      "Fold: 22  Epoch: 168  Training loss = 4.4445  Validation loss = 2.3118  \n",
      "\n",
      "Fold: 22  Epoch: 169  Training loss = 4.4442  Validation loss = 2.3117  \n",
      "\n",
      "Fold: 22  Epoch: 170  Training loss = 4.4437  Validation loss = 2.3116  \n",
      "\n",
      "Fold: 22  Epoch: 171  Training loss = 4.4433  Validation loss = 2.3114  \n",
      "\n",
      "Fold: 22  Epoch: 172  Training loss = 4.4430  Validation loss = 2.3111  \n",
      "\n",
      "Fold: 22  Epoch: 173  Training loss = 4.4428  Validation loss = 2.3110  \n",
      "\n",
      "Fold: 22  Epoch: 174  Training loss = 4.4425  Validation loss = 2.3108  \n",
      "\n",
      "Fold: 22  Epoch: 175  Training loss = 4.4422  Validation loss = 2.3106  \n",
      "\n",
      "Fold: 22  Epoch: 176  Training loss = 4.4418  Validation loss = 2.3105  \n",
      "\n",
      "Fold: 22  Epoch: 177  Training loss = 4.4415  Validation loss = 2.3102  \n",
      "\n",
      "Fold: 22  Epoch: 178  Training loss = 4.4412  Validation loss = 2.3102  \n",
      "\n",
      "Fold: 22  Epoch: 179  Training loss = 4.4408  Validation loss = 2.3099  \n",
      "\n",
      "Fold: 22  Epoch: 180  Training loss = 4.4403  Validation loss = 2.3096  \n",
      "\n",
      "Fold: 22  Epoch: 181  Training loss = 4.4399  Validation loss = 2.3094  \n",
      "\n",
      "Fold: 22  Epoch: 182  Training loss = 4.4396  Validation loss = 2.3092  \n",
      "\n",
      "Fold: 22  Epoch: 183  Training loss = 4.4392  Validation loss = 2.3091  \n",
      "\n",
      "Fold: 22  Epoch: 184  Training loss = 4.4388  Validation loss = 2.3089  \n",
      "\n",
      "Fold: 22  Epoch: 185  Training loss = 4.4385  Validation loss = 2.3087  \n",
      "\n",
      "Fold: 22  Epoch: 186  Training loss = 4.4382  Validation loss = 2.3086  \n",
      "\n",
      "Fold: 22  Epoch: 187  Training loss = 4.4378  Validation loss = 2.3084  \n",
      "\n",
      "Fold: 22  Epoch: 188  Training loss = 4.4374  Validation loss = 2.3083  \n",
      "\n",
      "Fold: 22  Epoch: 189  Training loss = 4.4371  Validation loss = 2.3081  \n",
      "\n",
      "Fold: 22  Epoch: 190  Training loss = 4.4366  Validation loss = 2.3079  \n",
      "\n",
      "Fold: 22  Epoch: 191  Training loss = 4.4362  Validation loss = 2.3077  \n",
      "\n",
      "Fold: 22  Epoch: 192  Training loss = 4.4358  Validation loss = 2.3075  \n",
      "\n",
      "Fold: 22  Epoch: 193  Training loss = 4.4354  Validation loss = 2.3074  \n",
      "\n",
      "Fold: 22  Epoch: 194  Training loss = 4.4350  Validation loss = 2.3073  \n",
      "\n",
      "Fold: 22  Epoch: 195  Training loss = 4.4347  Validation loss = 2.3071  \n",
      "\n",
      "Fold: 22  Epoch: 196  Training loss = 4.4345  Validation loss = 2.3071  \n",
      "\n",
      "Fold: 22  Epoch: 197  Training loss = 4.4341  Validation loss = 2.3070  \n",
      "\n",
      "Fold: 22  Epoch: 198  Training loss = 4.4337  Validation loss = 2.3069  \n",
      "\n",
      "Fold: 22  Epoch: 199  Training loss = 4.4334  Validation loss = 2.3068  \n",
      "\n",
      "Fold: 22  Epoch: 200  Training loss = 4.4330  Validation loss = 2.3066  \n",
      "\n",
      "Fold: 22  Epoch: 201  Training loss = 4.4327  Validation loss = 2.3064  \n",
      "\n",
      "Fold: 22  Epoch: 202  Training loss = 4.4324  Validation loss = 2.3062  \n",
      "\n",
      "Fold: 22  Epoch: 203  Training loss = 4.4321  Validation loss = 2.3058  \n",
      "\n",
      "Fold: 22  Epoch: 204  Training loss = 4.4317  Validation loss = 2.3056  \n",
      "\n",
      "Fold: 22  Epoch: 205  Training loss = 4.4313  Validation loss = 2.3054  \n",
      "\n",
      "Fold: 22  Epoch: 206  Training loss = 4.4310  Validation loss = 2.3053  \n",
      "\n",
      "Fold: 22  Epoch: 207  Training loss = 4.4306  Validation loss = 2.3050  \n",
      "\n",
      "Fold: 22  Epoch: 208  Training loss = 4.4301  Validation loss = 2.3049  \n",
      "\n",
      "Fold: 22  Epoch: 209  Training loss = 4.4297  Validation loss = 2.3048  \n",
      "\n",
      "Fold: 22  Epoch: 210  Training loss = 4.4293  Validation loss = 2.3047  \n",
      "\n",
      "Fold: 22  Epoch: 211  Training loss = 4.4289  Validation loss = 2.3046  \n",
      "\n",
      "Fold: 22  Epoch: 212  Training loss = 4.4285  Validation loss = 2.3045  \n",
      "\n",
      "Fold: 22  Epoch: 213  Training loss = 4.4281  Validation loss = 2.3042  \n",
      "\n",
      "Fold: 22  Epoch: 214  Training loss = 4.4277  Validation loss = 2.3042  \n",
      "\n",
      "Fold: 22  Epoch: 215  Training loss = 4.4272  Validation loss = 2.3041  \n",
      "\n",
      "Fold: 22  Epoch: 216  Training loss = 4.4269  Validation loss = 2.3040  \n",
      "\n",
      "Fold: 22  Epoch: 217  Training loss = 4.4264  Validation loss = 2.3037  \n",
      "\n",
      "Fold: 22  Epoch: 218  Training loss = 4.4259  Validation loss = 2.3036  \n",
      "\n",
      "Fold: 22  Epoch: 219  Training loss = 4.4254  Validation loss = 2.3034  \n",
      "\n",
      "Fold: 22  Epoch: 220  Training loss = 4.4250  Validation loss = 2.3034  \n",
      "\n",
      "Fold: 22  Epoch: 221  Training loss = 4.4246  Validation loss = 2.3033  \n",
      "\n",
      "Fold: 22  Epoch: 222  Training loss = 4.4242  Validation loss = 2.3032  \n",
      "\n",
      "Fold: 22  Epoch: 223  Training loss = 4.4237  Validation loss = 2.3030  \n",
      "\n",
      "Fold: 22  Epoch: 224  Training loss = 4.4234  Validation loss = 2.3027  \n",
      "\n",
      "Fold: 22  Epoch: 225  Training loss = 4.4229  Validation loss = 2.3025  \n",
      "\n",
      "Fold: 22  Epoch: 226  Training loss = 4.4226  Validation loss = 2.3023  \n",
      "\n",
      "Fold: 22  Epoch: 227  Training loss = 4.4222  Validation loss = 2.3022  \n",
      "\n",
      "Fold: 22  Epoch: 228  Training loss = 4.4216  Validation loss = 2.3018  \n",
      "\n",
      "Fold: 22  Epoch: 229  Training loss = 4.4212  Validation loss = 2.3017  \n",
      "\n",
      "Fold: 22  Epoch: 230  Training loss = 4.4208  Validation loss = 2.3012  \n",
      "\n",
      "Fold: 22  Epoch: 231  Training loss = 4.4204  Validation loss = 2.3010  \n",
      "\n",
      "Fold: 22  Epoch: 232  Training loss = 4.4200  Validation loss = 2.3009  \n",
      "\n",
      "Fold: 22  Epoch: 233  Training loss = 4.4194  Validation loss = 2.3006  \n",
      "\n",
      "Fold: 22  Epoch: 234  Training loss = 4.4190  Validation loss = 2.3004  \n",
      "\n",
      "Fold: 22  Epoch: 235  Training loss = 4.4186  Validation loss = 2.3001  \n",
      "\n",
      "Fold: 22  Epoch: 236  Training loss = 4.4183  Validation loss = 2.2998  \n",
      "\n",
      "Fold: 22  Epoch: 237  Training loss = 4.4180  Validation loss = 2.2998  \n",
      "\n",
      "Fold: 22  Epoch: 238  Training loss = 4.4176  Validation loss = 2.2996  \n",
      "\n",
      "Fold: 22  Epoch: 239  Training loss = 4.4171  Validation loss = 2.2994  \n",
      "\n",
      "Fold: 22  Epoch: 240  Training loss = 4.4168  Validation loss = 2.2991  \n",
      "\n",
      "Fold: 22  Epoch: 241  Training loss = 4.4162  Validation loss = 2.2990  \n",
      "\n",
      "Fold: 22  Epoch: 242  Training loss = 4.4157  Validation loss = 2.2989  \n",
      "\n",
      "Fold: 22  Epoch: 243  Training loss = 4.4154  Validation loss = 2.2988  \n",
      "\n",
      "Fold: 22  Epoch: 244  Training loss = 4.4149  Validation loss = 2.2987  \n",
      "\n",
      "Fold: 22  Epoch: 245  Training loss = 4.4144  Validation loss = 2.2986  \n",
      "\n",
      "Fold: 22  Epoch: 246  Training loss = 4.4141  Validation loss = 2.2985  \n",
      "\n",
      "Fold: 22  Epoch: 247  Training loss = 4.4136  Validation loss = 2.2984  \n",
      "\n",
      "Fold: 22  Epoch: 248  Training loss = 4.4133  Validation loss = 2.2982  \n",
      "\n",
      "Fold: 22  Epoch: 249  Training loss = 4.4130  Validation loss = 2.2981  \n",
      "\n",
      "Fold: 22  Epoch: 250  Training loss = 4.4124  Validation loss = 2.2979  \n",
      "\n",
      "Fold: 22  Epoch: 251  Training loss = 4.4120  Validation loss = 2.2978  \n",
      "\n",
      "Fold: 22  Epoch: 252  Training loss = 4.4115  Validation loss = 2.2977  \n",
      "\n",
      "Fold: 22  Epoch: 253  Training loss = 4.4110  Validation loss = 2.2975  \n",
      "\n",
      "Fold: 22  Epoch: 254  Training loss = 4.4106  Validation loss = 2.2973  \n",
      "\n",
      "Fold: 22  Epoch: 255  Training loss = 4.4102  Validation loss = 2.2971  \n",
      "\n",
      "Fold: 22  Epoch: 256  Training loss = 4.4099  Validation loss = 2.2971  \n",
      "\n",
      "Fold: 22  Epoch: 257  Training loss = 4.4096  Validation loss = 2.2968  \n",
      "\n",
      "Fold: 22  Epoch: 258  Training loss = 4.4093  Validation loss = 2.2967  \n",
      "\n",
      "Fold: 22  Epoch: 259  Training loss = 4.4089  Validation loss = 2.2967  \n",
      "\n",
      "Fold: 22  Epoch: 260  Training loss = 4.4084  Validation loss = 2.2964  \n",
      "\n",
      "Fold: 22  Epoch: 261  Training loss = 4.4080  Validation loss = 2.2960  \n",
      "\n",
      "Fold: 22  Epoch: 262  Training loss = 4.4076  Validation loss = 2.2957  \n",
      "\n",
      "Fold: 22  Epoch: 263  Training loss = 4.4070  Validation loss = 2.2954  \n",
      "\n",
      "Fold: 22  Epoch: 264  Training loss = 4.4066  Validation loss = 2.2952  \n",
      "\n",
      "Fold: 22  Epoch: 265  Training loss = 4.4062  Validation loss = 2.2951  \n",
      "\n",
      "Fold: 22  Epoch: 266  Training loss = 4.4057  Validation loss = 2.2950  \n",
      "\n",
      "Fold: 22  Epoch: 267  Training loss = 4.4053  Validation loss = 2.2948  \n",
      "\n",
      "Fold: 22  Epoch: 268  Training loss = 4.4049  Validation loss = 2.2947  \n",
      "\n",
      "Fold: 22  Epoch: 269  Training loss = 4.4043  Validation loss = 2.2946  \n",
      "\n",
      "Fold: 22  Epoch: 270  Training loss = 4.4038  Validation loss = 2.2945  \n",
      "\n",
      "Fold: 22  Epoch: 271  Training loss = 4.4031  Validation loss = 2.2943  \n",
      "\n",
      "Fold: 22  Epoch: 272  Training loss = 4.4027  Validation loss = 2.2941  \n",
      "\n",
      "Fold: 22  Epoch: 273  Training loss = 4.4022  Validation loss = 2.2939  \n",
      "\n",
      "Fold: 22  Epoch: 274  Training loss = 4.4018  Validation loss = 2.2939  \n",
      "\n",
      "Fold: 22  Epoch: 275  Training loss = 4.4012  Validation loss = 2.2938  \n",
      "\n",
      "Fold: 22  Epoch: 276  Training loss = 4.4008  Validation loss = 2.2936  \n",
      "\n",
      "Fold: 22  Epoch: 277  Training loss = 4.3999  Validation loss = 2.2935  \n",
      "\n",
      "Fold: 22  Epoch: 278  Training loss = 4.3991  Validation loss = 2.2934  \n",
      "\n",
      "Fold: 22  Epoch: 279  Training loss = 4.3987  Validation loss = 2.2932  \n",
      "\n",
      "Fold: 22  Epoch: 280  Training loss = 4.3980  Validation loss = 2.2930  \n",
      "\n",
      "Fold: 22  Epoch: 281  Training loss = 4.3975  Validation loss = 2.2930  \n",
      "\n",
      "Fold: 22  Epoch: 282  Training loss = 4.3970  Validation loss = 2.2928  \n",
      "\n",
      "Fold: 22  Epoch: 283  Training loss = 4.3961  Validation loss = 2.2925  \n",
      "\n",
      "Fold: 22  Epoch: 284  Training loss = 4.3955  Validation loss = 2.2923  \n",
      "\n",
      "Fold: 22  Epoch: 285  Training loss = 4.3949  Validation loss = 2.2922  \n",
      "\n",
      "Fold: 22  Epoch: 286  Training loss = 4.3946  Validation loss = 2.2921  \n",
      "\n",
      "Fold: 22  Epoch: 287  Training loss = 4.3941  Validation loss = 2.2920  \n",
      "\n",
      "Fold: 22  Epoch: 288  Training loss = 4.3936  Validation loss = 2.2919  \n",
      "\n",
      "Fold: 22  Epoch: 289  Training loss = 4.3928  Validation loss = 2.2919  \n",
      "\n",
      "Fold: 22  Epoch: 290  Training loss = 4.3921  Validation loss = 2.2918  \n",
      "\n",
      "Fold: 22  Epoch: 291  Training loss = 4.3915  Validation loss = 2.2917  \n",
      "\n",
      "Fold: 22  Epoch: 292  Training loss = 4.3908  Validation loss = 2.2917  \n",
      "\n",
      "Fold: 22  Epoch: 293  Training loss = 4.3902  Validation loss = 2.2916  \n",
      "\n",
      "Fold: 22  Epoch: 294  Training loss = 4.3895  Validation loss = 2.2916  \n",
      "\n",
      "Fold: 22  Epoch: 295  Training loss = 4.3885  Validation loss = 2.2915  \n",
      "\n",
      "Fold: 22  Epoch: 296  Training loss = 4.3879  Validation loss = 2.2913  \n",
      "\n",
      "Fold: 22  Epoch: 297  Training loss = 4.3874  Validation loss = 2.2911  \n",
      "\n",
      "Fold: 22  Epoch: 298  Training loss = 4.3867  Validation loss = 2.2911  \n",
      "\n",
      "Fold: 22  Epoch: 299  Training loss = 4.3858  Validation loss = 2.2910  \n",
      "\n",
      "Fold: 22  Epoch: 300  Training loss = 4.3852  Validation loss = 2.2909  \n",
      "\n",
      "Fold: 22  Epoch: 301  Training loss = 4.3843  Validation loss = 2.2908  \n",
      "\n",
      "Fold: 22  Epoch: 302  Training loss = 4.3835  Validation loss = 2.2906  \n",
      "\n",
      "Fold: 22  Epoch: 303  Training loss = 4.3829  Validation loss = 2.2904  \n",
      "\n",
      "Fold: 22  Epoch: 304  Training loss = 4.3822  Validation loss = 2.2904  \n",
      "\n",
      "Fold: 22  Epoch: 305  Training loss = 4.3818  Validation loss = 2.2902  \n",
      "\n",
      "Fold: 22  Epoch: 306  Training loss = 4.3810  Validation loss = 2.2900  \n",
      "\n",
      "Fold: 22  Epoch: 307  Training loss = 4.3805  Validation loss = 2.2898  \n",
      "\n",
      "Fold: 22  Epoch: 308  Training loss = 4.3795  Validation loss = 2.2896  \n",
      "\n",
      "Fold: 22  Epoch: 309  Training loss = 4.3788  Validation loss = 2.2894  \n",
      "\n",
      "Fold: 22  Epoch: 310  Training loss = 4.3782  Validation loss = 2.2893  \n",
      "\n",
      "Fold: 22  Epoch: 311  Training loss = 4.3776  Validation loss = 2.2891  \n",
      "\n",
      "Fold: 22  Epoch: 312  Training loss = 4.3765  Validation loss = 2.2889  \n",
      "\n",
      "Fold: 22  Epoch: 313  Training loss = 4.3759  Validation loss = 2.2888  \n",
      "\n",
      "Fold: 22  Epoch: 314  Training loss = 4.3752  Validation loss = 2.2887  \n",
      "\n",
      "Fold: 22  Epoch: 315  Training loss = 4.3745  Validation loss = 2.2886  \n",
      "\n",
      "Fold: 22  Epoch: 316  Training loss = 4.3735  Validation loss = 2.2884  \n",
      "\n",
      "Fold: 22  Epoch: 317  Training loss = 4.3726  Validation loss = 2.2884  \n",
      "\n",
      "Fold: 22  Epoch: 318  Training loss = 4.3719  Validation loss = 2.2881  \n",
      "\n",
      "Fold: 22  Epoch: 319  Training loss = 4.3714  Validation loss = 2.2879  \n",
      "\n",
      "Fold: 22  Epoch: 320  Training loss = 4.3708  Validation loss = 2.2877  \n",
      "\n",
      "Fold: 22  Epoch: 321  Training loss = 4.3701  Validation loss = 2.2875  \n",
      "\n",
      "Fold: 22  Epoch: 322  Training loss = 4.3693  Validation loss = 2.2875  \n",
      "\n",
      "Fold: 22  Epoch: 323  Training loss = 4.3685  Validation loss = 2.2873  \n",
      "\n",
      "Fold: 22  Epoch: 324  Training loss = 4.3678  Validation loss = 2.2872  \n",
      "\n",
      "Fold: 22  Epoch: 325  Training loss = 4.3671  Validation loss = 2.2869  \n",
      "\n",
      "Fold: 22  Epoch: 326  Training loss = 4.3664  Validation loss = 2.2868  \n",
      "\n",
      "Fold: 22  Epoch: 327  Training loss = 4.3657  Validation loss = 2.2866  \n",
      "\n",
      "Fold: 22  Epoch: 328  Training loss = 4.3649  Validation loss = 2.2865  \n",
      "\n",
      "Fold: 22  Epoch: 329  Training loss = 4.3641  Validation loss = 2.2863  \n",
      "\n",
      "Fold: 22  Epoch: 330  Training loss = 4.3635  Validation loss = 2.2861  \n",
      "\n",
      "Fold: 22  Epoch: 331  Training loss = 4.3627  Validation loss = 2.2858  \n",
      "\n",
      "Fold: 22  Epoch: 332  Training loss = 4.3619  Validation loss = 2.2857  \n",
      "\n",
      "Fold: 22  Epoch: 333  Training loss = 4.3614  Validation loss = 2.2854  \n",
      "\n",
      "Fold: 22  Epoch: 334  Training loss = 4.3609  Validation loss = 2.2854  \n",
      "\n",
      "Fold: 22  Epoch: 335  Training loss = 4.3601  Validation loss = 2.2851  \n",
      "\n",
      "Fold: 22  Epoch: 336  Training loss = 4.3598  Validation loss = 2.2851  \n",
      "\n",
      "Fold: 22  Epoch: 337  Training loss = 4.3593  Validation loss = 2.2849  \n",
      "\n",
      "Fold: 22  Epoch: 338  Training loss = 4.3588  Validation loss = 2.2848  \n",
      "\n",
      "Fold: 22  Epoch: 339  Training loss = 4.3582  Validation loss = 2.2846  \n",
      "\n",
      "Fold: 22  Epoch: 340  Training loss = 4.3577  Validation loss = 2.2843  \n",
      "\n",
      "Fold: 22  Epoch: 341  Training loss = 4.3571  Validation loss = 2.2842  \n",
      "\n",
      "Fold: 22  Epoch: 342  Training loss = 4.3565  Validation loss = 2.2840  \n",
      "\n",
      "Fold: 22  Epoch: 343  Training loss = 4.3558  Validation loss = 2.2838  \n",
      "\n",
      "Fold: 22  Epoch: 344  Training loss = 4.3553  Validation loss = 2.2837  \n",
      "\n",
      "Fold: 22  Epoch: 345  Training loss = 4.3547  Validation loss = 2.2835  \n",
      "\n",
      "Fold: 22  Epoch: 346  Training loss = 4.3540  Validation loss = 2.2835  \n",
      "\n",
      "Fold: 22  Epoch: 347  Training loss = 4.3532  Validation loss = 2.2834  \n",
      "\n",
      "Fold: 22  Epoch: 348  Training loss = 4.3525  Validation loss = 2.2831  \n",
      "\n",
      "Fold: 22  Epoch: 349  Training loss = 4.3521  Validation loss = 2.2832  \n",
      "\n",
      "Fold: 22  Epoch: 350  Training loss = 4.3514  Validation loss = 2.2830  \n",
      "\n",
      "Fold: 22  Epoch: 351  Training loss = 4.3506  Validation loss = 2.2828  \n",
      "\n",
      "Fold: 22  Epoch: 352  Training loss = 4.3503  Validation loss = 2.2826  \n",
      "\n",
      "Fold: 22  Epoch: 353  Training loss = 4.3499  Validation loss = 2.2826  \n",
      "\n",
      "Fold: 22  Epoch: 354  Training loss = 4.3492  Validation loss = 2.2823  \n",
      "\n",
      "Fold: 22  Epoch: 355  Training loss = 4.3489  Validation loss = 2.2822  \n",
      "\n",
      "Fold: 22  Epoch: 356  Training loss = 4.3484  Validation loss = 2.2820  \n",
      "\n",
      "Fold: 22  Epoch: 357  Training loss = 4.3478  Validation loss = 2.2818  \n",
      "\n",
      "Fold: 22  Epoch: 358  Training loss = 4.3471  Validation loss = 2.2816  \n",
      "\n",
      "Fold: 22  Epoch: 359  Training loss = 4.3466  Validation loss = 2.2814  \n",
      "\n",
      "Fold: 22  Epoch: 360  Training loss = 4.3458  Validation loss = 2.2813  \n",
      "\n",
      "Fold: 22  Epoch: 361  Training loss = 4.3455  Validation loss = 2.2812  \n",
      "\n",
      "Fold: 22  Epoch: 362  Training loss = 4.3450  Validation loss = 2.2809  \n",
      "\n",
      "Fold: 22  Epoch: 363  Training loss = 4.3442  Validation loss = 2.2806  \n",
      "\n",
      "Fold: 22  Epoch: 364  Training loss = 4.3437  Validation loss = 2.2806  \n",
      "\n",
      "Fold: 22  Epoch: 365  Training loss = 4.3433  Validation loss = 2.2804  \n",
      "\n",
      "Fold: 22  Epoch: 366  Training loss = 4.3427  Validation loss = 2.2802  \n",
      "\n",
      "Fold: 22  Epoch: 367  Training loss = 4.3423  Validation loss = 2.2799  \n",
      "\n",
      "Fold: 22  Epoch: 368  Training loss = 4.3418  Validation loss = 2.2798  \n",
      "\n",
      "Fold: 22  Epoch: 369  Training loss = 4.3413  Validation loss = 2.2796  \n",
      "\n",
      "Fold: 22  Epoch: 370  Training loss = 4.3409  Validation loss = 2.2796  \n",
      "\n",
      "Fold: 22  Epoch: 371  Training loss = 4.3406  Validation loss = 2.2796  \n",
      "\n",
      "Fold: 22  Epoch: 372  Training loss = 4.3403  Validation loss = 2.2793  \n",
      "\n",
      "Fold: 22  Epoch: 373  Training loss = 4.3397  Validation loss = 2.2791  \n",
      "\n",
      "Fold: 22  Epoch: 374  Training loss = 4.3392  Validation loss = 2.2790  \n",
      "\n",
      "Fold: 22  Epoch: 375  Training loss = 4.3386  Validation loss = 2.2787  \n",
      "\n",
      "Fold: 22  Epoch: 376  Training loss = 4.3382  Validation loss = 2.2785  \n",
      "\n",
      "Fold: 22  Epoch: 377  Training loss = 4.3375  Validation loss = 2.2784  \n",
      "\n",
      "Fold: 22  Epoch: 378  Training loss = 4.3371  Validation loss = 2.2783  \n",
      "\n",
      "Fold: 22  Epoch: 379  Training loss = 4.3368  Validation loss = 2.2781  \n",
      "\n",
      "Fold: 22  Epoch: 380  Training loss = 4.3364  Validation loss = 2.2781  \n",
      "\n",
      "Fold: 22  Epoch: 381  Training loss = 4.3358  Validation loss = 2.2779  \n",
      "\n",
      "Fold: 22  Epoch: 382  Training loss = 4.3355  Validation loss = 2.2779  \n",
      "\n",
      "Fold: 22  Epoch: 383  Training loss = 4.3350  Validation loss = 2.2778  \n",
      "\n",
      "Fold: 22  Epoch: 384  Training loss = 4.3347  Validation loss = 2.2777  \n",
      "\n",
      "Fold: 22  Epoch: 385  Training loss = 4.3342  Validation loss = 2.2776  \n",
      "\n",
      "Fold: 22  Epoch: 386  Training loss = 4.3338  Validation loss = 2.2777  \n",
      "\n",
      "Fold: 22  Epoch: 387  Training loss = 4.3334  Validation loss = 2.2775  \n",
      "\n",
      "Fold: 22  Epoch: 388  Training loss = 4.3329  Validation loss = 2.2773  \n",
      "\n",
      "Fold: 22  Epoch: 389  Training loss = 4.3325  Validation loss = 2.2772  \n",
      "\n",
      "Fold: 22  Epoch: 390  Training loss = 4.3321  Validation loss = 2.2770  \n",
      "\n",
      "Fold: 22  Epoch: 391  Training loss = 4.3316  Validation loss = 2.2769  \n",
      "\n",
      "Fold: 22  Epoch: 392  Training loss = 4.3312  Validation loss = 2.2768  \n",
      "\n",
      "Fold: 22  Epoch: 393  Training loss = 4.3308  Validation loss = 2.2765  \n",
      "\n",
      "Fold: 22  Epoch: 394  Training loss = 4.3306  Validation loss = 2.2765  \n",
      "\n",
      "Fold: 22  Epoch: 395  Training loss = 4.3302  Validation loss = 2.2762  \n",
      "\n",
      "Fold: 22  Epoch: 396  Training loss = 4.3298  Validation loss = 2.2760  \n",
      "\n",
      "Fold: 22  Epoch: 397  Training loss = 4.3294  Validation loss = 2.2759  \n",
      "\n",
      "Fold: 22  Epoch: 398  Training loss = 4.3290  Validation loss = 2.2758  \n",
      "\n",
      "Fold: 22  Epoch: 399  Training loss = 4.3288  Validation loss = 2.2757  \n",
      "\n",
      "Fold: 22  Epoch: 400  Training loss = 4.3284  Validation loss = 2.2757  \n",
      "\n",
      "Fold: 22  Epoch: 401  Training loss = 4.3281  Validation loss = 2.2754  \n",
      "\n",
      "Fold: 22  Epoch: 402  Training loss = 4.3278  Validation loss = 2.2753  \n",
      "\n",
      "Fold: 22  Epoch: 403  Training loss = 4.3275  Validation loss = 2.2751  \n",
      "\n",
      "Fold: 22  Epoch: 404  Training loss = 4.3272  Validation loss = 2.2748  \n",
      "\n",
      "Fold: 22  Epoch: 405  Training loss = 4.3269  Validation loss = 2.2747  \n",
      "\n",
      "Fold: 22  Epoch: 406  Training loss = 4.3266  Validation loss = 2.2746  \n",
      "\n",
      "Fold: 22  Epoch: 407  Training loss = 4.3262  Validation loss = 2.2745  \n",
      "\n",
      "Fold: 22  Epoch: 408  Training loss = 4.3259  Validation loss = 2.2744  \n",
      "\n",
      "Fold: 22  Epoch: 409  Training loss = 4.3255  Validation loss = 2.2743  \n",
      "\n",
      "Fold: 22  Epoch: 410  Training loss = 4.3251  Validation loss = 2.2741  \n",
      "\n",
      "Fold: 22  Epoch: 411  Training loss = 4.3249  Validation loss = 2.2741  \n",
      "\n",
      "Fold: 22  Epoch: 412  Training loss = 4.3245  Validation loss = 2.2740  \n",
      "\n",
      "Fold: 22  Epoch: 413  Training loss = 4.3242  Validation loss = 2.2739  \n",
      "\n",
      "Fold: 22  Epoch: 414  Training loss = 4.3238  Validation loss = 2.2738  \n",
      "\n",
      "Fold: 22  Epoch: 415  Training loss = 4.3235  Validation loss = 2.2737  \n",
      "\n",
      "Fold: 22  Epoch: 416  Training loss = 4.3232  Validation loss = 2.2736  \n",
      "\n",
      "Fold: 22  Epoch: 417  Training loss = 4.3228  Validation loss = 2.2735  \n",
      "\n",
      "Fold: 22  Epoch: 418  Training loss = 4.3224  Validation loss = 2.2733  \n",
      "\n",
      "Fold: 22  Epoch: 419  Training loss = 4.3221  Validation loss = 2.2731  \n",
      "\n",
      "Fold: 22  Epoch: 420  Training loss = 4.3215  Validation loss = 2.2729  \n",
      "\n",
      "Fold: 22  Epoch: 421  Training loss = 4.3212  Validation loss = 2.2728  \n",
      "\n",
      "Fold: 22  Epoch: 422  Training loss = 4.3209  Validation loss = 2.2726  \n",
      "\n",
      "Fold: 22  Epoch: 423  Training loss = 4.3206  Validation loss = 2.2725  \n",
      "\n",
      "Fold: 22  Epoch: 424  Training loss = 4.3202  Validation loss = 2.2723  \n",
      "\n",
      "Fold: 22  Epoch: 425  Training loss = 4.3199  Validation loss = 2.2721  \n",
      "\n",
      "Fold: 22  Epoch: 426  Training loss = 4.3195  Validation loss = 2.2721  \n",
      "\n",
      "Fold: 22  Epoch: 427  Training loss = 4.3192  Validation loss = 2.2720  \n",
      "\n",
      "Fold: 22  Epoch: 428  Training loss = 4.3188  Validation loss = 2.2720  \n",
      "\n",
      "Fold: 22  Epoch: 429  Training loss = 4.3184  Validation loss = 2.2718  \n",
      "\n",
      "Fold: 22  Epoch: 430  Training loss = 4.3181  Validation loss = 2.2717  \n",
      "\n",
      "Fold: 22  Epoch: 431  Training loss = 4.3177  Validation loss = 2.2714  \n",
      "\n",
      "Fold: 22  Epoch: 432  Training loss = 4.3173  Validation loss = 2.2713  \n",
      "\n",
      "Fold: 22  Epoch: 433  Training loss = 4.3170  Validation loss = 2.2712  \n",
      "\n",
      "Fold: 22  Epoch: 434  Training loss = 4.3167  Validation loss = 2.2710  \n",
      "\n",
      "Fold: 22  Epoch: 435  Training loss = 4.3163  Validation loss = 2.2709  \n",
      "\n",
      "Fold: 22  Epoch: 436  Training loss = 4.3159  Validation loss = 2.2708  \n",
      "\n",
      "Fold: 22  Epoch: 437  Training loss = 4.3156  Validation loss = 2.2707  \n",
      "\n",
      "Fold: 22  Epoch: 438  Training loss = 4.3153  Validation loss = 2.2706  \n",
      "\n",
      "Fold: 22  Epoch: 439  Training loss = 4.3151  Validation loss = 2.2704  \n",
      "\n",
      "Fold: 22  Epoch: 440  Training loss = 4.3147  Validation loss = 2.2703  \n",
      "\n",
      "Fold: 22  Epoch: 441  Training loss = 4.3144  Validation loss = 2.2703  \n",
      "\n",
      "Fold: 22  Epoch: 442  Training loss = 4.3141  Validation loss = 2.2701  \n",
      "\n",
      "Fold: 22  Epoch: 443  Training loss = 4.3138  Validation loss = 2.2701  \n",
      "\n",
      "Fold: 22  Epoch: 444  Training loss = 4.3135  Validation loss = 2.2700  \n",
      "\n",
      "Fold: 22  Epoch: 445  Training loss = 4.3132  Validation loss = 2.2698  \n",
      "\n",
      "Fold: 22  Epoch: 446  Training loss = 4.3129  Validation loss = 2.2696  \n",
      "\n",
      "Fold: 22  Epoch: 447  Training loss = 4.3125  Validation loss = 2.2696  \n",
      "\n",
      "Fold: 22  Epoch: 448  Training loss = 4.3121  Validation loss = 2.2694  \n",
      "\n",
      "Fold: 22  Epoch: 449  Training loss = 4.3117  Validation loss = 2.2692  \n",
      "\n",
      "Fold: 22  Epoch: 450  Training loss = 4.3115  Validation loss = 2.2691  \n",
      "\n",
      "Fold: 22  Epoch: 451  Training loss = 4.3111  Validation loss = 2.2689  \n",
      "\n",
      "Fold: 22  Epoch: 452  Training loss = 4.3108  Validation loss = 2.2688  \n",
      "\n",
      "Fold: 22  Epoch: 453  Training loss = 4.3105  Validation loss = 2.2687  \n",
      "\n",
      "Fold: 22  Epoch: 454  Training loss = 4.3102  Validation loss = 2.2684  \n",
      "\n",
      "Fold: 22  Epoch: 455  Training loss = 4.3099  Validation loss = 2.2683  \n",
      "\n",
      "Fold: 22  Epoch: 456  Training loss = 4.3096  Validation loss = 2.2682  \n",
      "\n",
      "Fold: 22  Epoch: 457  Training loss = 4.3092  Validation loss = 2.2682  \n",
      "\n",
      "Fold: 22  Epoch: 458  Training loss = 4.3090  Validation loss = 2.2682  \n",
      "\n",
      "Fold: 22  Epoch: 459  Training loss = 4.3087  Validation loss = 2.2681  \n",
      "\n",
      "Fold: 22  Epoch: 460  Training loss = 4.3083  Validation loss = 2.2677  \n",
      "\n",
      "Fold: 22  Epoch: 461  Training loss = 4.3081  Validation loss = 2.2676  \n",
      "\n",
      "Fold: 22  Epoch: 462  Training loss = 4.3077  Validation loss = 2.2674  \n",
      "\n",
      "Fold: 22  Epoch: 463  Training loss = 4.3072  Validation loss = 2.2672  \n",
      "\n",
      "Fold: 22  Epoch: 464  Training loss = 4.3068  Validation loss = 2.2671  \n",
      "\n",
      "Fold: 22  Epoch: 465  Training loss = 4.3065  Validation loss = 2.2670  \n",
      "\n",
      "Fold: 22  Epoch: 466  Training loss = 4.3061  Validation loss = 2.2667  \n",
      "\n",
      "Fold: 22  Epoch: 467  Training loss = 4.3058  Validation loss = 2.2666  \n",
      "\n",
      "Fold: 22  Epoch: 468  Training loss = 4.3056  Validation loss = 2.2665  \n",
      "\n",
      "Fold: 22  Epoch: 469  Training loss = 4.3053  Validation loss = 2.2663  \n",
      "\n",
      "Fold: 22  Epoch: 470  Training loss = 4.3049  Validation loss = 2.2660  \n",
      "\n",
      "Fold: 22  Epoch: 471  Training loss = 4.3045  Validation loss = 2.2659  \n",
      "\n",
      "Fold: 22  Epoch: 472  Training loss = 4.3042  Validation loss = 2.2659  \n",
      "\n",
      "Fold: 22  Epoch: 473  Training loss = 4.3039  Validation loss = 2.2656  \n",
      "\n",
      "Fold: 22  Epoch: 474  Training loss = 4.3036  Validation loss = 2.2652  \n",
      "\n",
      "Fold: 22  Epoch: 475  Training loss = 4.3033  Validation loss = 2.2651  \n",
      "\n",
      "Fold: 22  Epoch: 476  Training loss = 4.3030  Validation loss = 2.2651  \n",
      "\n",
      "Fold: 22  Epoch: 477  Training loss = 4.3027  Validation loss = 2.2648  \n",
      "\n",
      "Fold: 22  Epoch: 478  Training loss = 4.3025  Validation loss = 2.2647  \n",
      "\n",
      "Fold: 22  Epoch: 479  Training loss = 4.3022  Validation loss = 2.2645  \n",
      "\n",
      "Fold: 22  Epoch: 480  Training loss = 4.3020  Validation loss = 2.2644  \n",
      "\n",
      "Fold: 22  Epoch: 481  Training loss = 4.3018  Validation loss = 2.2643  \n",
      "\n",
      "Fold: 22  Epoch: 482  Training loss = 4.3015  Validation loss = 2.2642  \n",
      "\n",
      "Fold: 22  Epoch: 483  Training loss = 4.3012  Validation loss = 2.2641  \n",
      "\n",
      "Fold: 22  Epoch: 484  Training loss = 4.3008  Validation loss = 2.2639  \n",
      "\n",
      "Fold: 22  Epoch: 485  Training loss = 4.3005  Validation loss = 2.2638  \n",
      "\n",
      "Fold: 22  Epoch: 486  Training loss = 4.3002  Validation loss = 2.2637  \n",
      "\n",
      "Fold: 22  Epoch: 487  Training loss = 4.2999  Validation loss = 2.2636  \n",
      "\n",
      "Fold: 22  Epoch: 488  Training loss = 4.2996  Validation loss = 2.2634  \n",
      "\n",
      "Fold: 22  Epoch: 489  Training loss = 4.2994  Validation loss = 2.2631  \n",
      "\n",
      "Fold: 22  Epoch: 490  Training loss = 4.2990  Validation loss = 2.2632  \n",
      "\n",
      "Fold: 22  Epoch: 491  Training loss = 4.2986  Validation loss = 2.2631  \n",
      "\n",
      "Fold: 22  Epoch: 492  Training loss = 4.2983  Validation loss = 2.2630  \n",
      "\n",
      "Fold: 22  Epoch: 493  Training loss = 4.2980  Validation loss = 2.2629  \n",
      "\n",
      "Fold: 22  Epoch: 494  Training loss = 4.2977  Validation loss = 2.2627  \n",
      "\n",
      "Fold: 22  Epoch: 495  Training loss = 4.2974  Validation loss = 2.2625  \n",
      "\n",
      "Fold: 22  Epoch: 496  Training loss = 4.2972  Validation loss = 2.2626  \n",
      "\n",
      "Fold: 22  Epoch: 497  Training loss = 4.2969  Validation loss = 2.2625  \n",
      "\n",
      "Fold: 22  Epoch: 498  Training loss = 4.2966  Validation loss = 2.2624  \n",
      "\n",
      "Fold: 22  Epoch: 499  Training loss = 4.2962  Validation loss = 2.2623  \n",
      "\n",
      "Fold: 22  Epoch: 500  Training loss = 4.2959  Validation loss = 2.2623  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 500  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 4.3247  Validation loss = 1.6559  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 4.3244  Validation loss = 1.6559  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 4.3241  Validation loss = 1.6559  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 4.3238  Validation loss = 1.6559  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 4.3234  Validation loss = 1.6559  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 4.3231  Validation loss = 1.6559  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 4.3228  Validation loss = 1.6559  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 4.3224  Validation loss = 1.6558  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 4.3221  Validation loss = 1.6558  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 4.3217  Validation loss = 1.6558  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 4.3214  Validation loss = 1.6557  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 4.3209  Validation loss = 1.6558  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 4.3207  Validation loss = 1.6558  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 4.3204  Validation loss = 1.6558  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 4.3201  Validation loss = 1.6558  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 4.3197  Validation loss = 1.6556  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 4.3193  Validation loss = 1.6556  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 4.3189  Validation loss = 1.6556  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 4.3185  Validation loss = 1.6555  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 4.3182  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 4.3180  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 4.3177  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 23  Epoch: 23  Training loss = 4.3174  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 23  Epoch: 24  Training loss = 4.3170  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 23  Epoch: 25  Training loss = 4.3166  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 23  Epoch: 26  Training loss = 4.3163  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 23  Epoch: 27  Training loss = 4.3159  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 23  Epoch: 28  Training loss = 4.3155  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 23  Epoch: 29  Training loss = 4.3152  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 23  Epoch: 30  Training loss = 4.3147  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 23  Epoch: 31  Training loss = 4.3145  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 23  Epoch: 32  Training loss = 4.3142  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 23  Epoch: 33  Training loss = 4.3138  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 23  Epoch: 34  Training loss = 4.3134  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 23  Epoch: 35  Training loss = 4.3131  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 23  Epoch: 36  Training loss = 4.3129  Validation loss = 1.6554  \n",
      "\n",
      "Fold: 23  Epoch: 37  Training loss = 4.3124  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 23  Epoch: 38  Training loss = 4.3120  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 23  Epoch: 39  Training loss = 4.3116  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 23  Epoch: 40  Training loss = 4.3113  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 23  Epoch: 41  Training loss = 4.3107  Validation loss = 1.6552  \n",
      "\n",
      "Fold: 23  Epoch: 42  Training loss = 4.3103  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 23  Epoch: 43  Training loss = 4.3099  Validation loss = 1.6550  \n",
      "\n",
      "Fold: 23  Epoch: 44  Training loss = 4.3095  Validation loss = 1.6550  \n",
      "\n",
      "Fold: 23  Epoch: 45  Training loss = 4.3091  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 23  Epoch: 46  Training loss = 4.3086  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 23  Epoch: 47  Training loss = 4.3082  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 23  Epoch: 48  Training loss = 4.3079  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 23  Epoch: 49  Training loss = 4.3076  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 23  Epoch: 50  Training loss = 4.3072  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 23  Epoch: 51  Training loss = 4.3068  Validation loss = 1.6551  \n",
      "\n",
      "Fold: 23  Epoch: 52  Training loss = 4.3061  Validation loss = 1.6552  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 44  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 4.3059  Validation loss = 2.0049  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 4.3052  Validation loss = 2.0042  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 4.3049  Validation loss = 2.0038  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 4.3044  Validation loss = 2.0032  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 4.3036  Validation loss = 2.0024  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 4.3032  Validation loss = 2.0020  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 4.3026  Validation loss = 2.0014  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 4.3018  Validation loss = 2.0007  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 4.3014  Validation loss = 2.0002  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 4.3009  Validation loss = 1.9995  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 4.3005  Validation loss = 1.9992  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 4.3001  Validation loss = 1.9987  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 4.2997  Validation loss = 1.9983  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 4.2992  Validation loss = 1.9978  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 4.2987  Validation loss = 1.9973  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 4.2984  Validation loss = 1.9970  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 4.2977  Validation loss = 1.9963  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 4.2974  Validation loss = 1.9959  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 4.2969  Validation loss = 1.9954  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 4.2966  Validation loss = 1.9951  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 4.2961  Validation loss = 1.9946  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 4.2957  Validation loss = 1.9941  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 4.2954  Validation loss = 1.9938  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 4.2949  Validation loss = 1.9933  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 4.2944  Validation loss = 1.9928  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 4.2941  Validation loss = 1.9924  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 4.2937  Validation loss = 1.9920  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 4.2932  Validation loss = 1.9916  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 4.2929  Validation loss = 1.9912  \n",
      "\n",
      "Fold: 24  Epoch: 30  Training loss = 4.2925  Validation loss = 1.9907  \n",
      "\n",
      "Fold: 24  Epoch: 31  Training loss = 4.2921  Validation loss = 1.9903  \n",
      "\n",
      "Fold: 24  Epoch: 32  Training loss = 4.2918  Validation loss = 1.9899  \n",
      "\n",
      "Fold: 24  Epoch: 33  Training loss = 4.2914  Validation loss = 1.9895  \n",
      "\n",
      "Fold: 24  Epoch: 34  Training loss = 4.2911  Validation loss = 1.9891  \n",
      "\n",
      "Fold: 24  Epoch: 35  Training loss = 4.2906  Validation loss = 1.9886  \n",
      "\n",
      "Fold: 24  Epoch: 36  Training loss = 4.2902  Validation loss = 1.9881  \n",
      "\n",
      "Fold: 24  Epoch: 37  Training loss = 4.2898  Validation loss = 1.9878  \n",
      "\n",
      "Fold: 24  Epoch: 38  Training loss = 4.2895  Validation loss = 1.9873  \n",
      "\n",
      "Fold: 24  Epoch: 39  Training loss = 4.2890  Validation loss = 1.9868  \n",
      "\n",
      "Fold: 24  Epoch: 40  Training loss = 4.2887  Validation loss = 1.9865  \n",
      "\n",
      "Fold: 24  Epoch: 41  Training loss = 4.2883  Validation loss = 1.9860  \n",
      "\n",
      "Fold: 24  Epoch: 42  Training loss = 4.2880  Validation loss = 1.9856  \n",
      "\n",
      "Fold: 24  Epoch: 43  Training loss = 4.2875  Validation loss = 1.9849  \n",
      "\n",
      "Fold: 24  Epoch: 44  Training loss = 4.2871  Validation loss = 1.9845  \n",
      "\n",
      "Fold: 24  Epoch: 45  Training loss = 4.2867  Validation loss = 1.9841  \n",
      "\n",
      "Fold: 24  Epoch: 46  Training loss = 4.2864  Validation loss = 1.9837  \n",
      "\n",
      "Fold: 24  Epoch: 47  Training loss = 4.2860  Validation loss = 1.9834  \n",
      "\n",
      "Fold: 24  Epoch: 48  Training loss = 4.2856  Validation loss = 1.9829  \n",
      "\n",
      "Fold: 24  Epoch: 49  Training loss = 4.2852  Validation loss = 1.9824  \n",
      "\n",
      "Fold: 24  Epoch: 50  Training loss = 4.2849  Validation loss = 1.9821  \n",
      "\n",
      "Fold: 24  Epoch: 51  Training loss = 4.2845  Validation loss = 1.9816  \n",
      "\n",
      "Fold: 24  Epoch: 52  Training loss = 4.2841  Validation loss = 1.9811  \n",
      "\n",
      "Fold: 24  Epoch: 53  Training loss = 4.2836  Validation loss = 1.9806  \n",
      "\n",
      "Fold: 24  Epoch: 54  Training loss = 4.2833  Validation loss = 1.9803  \n",
      "\n",
      "Fold: 24  Epoch: 55  Training loss = 4.2830  Validation loss = 1.9799  \n",
      "\n",
      "Fold: 24  Epoch: 56  Training loss = 4.2826  Validation loss = 1.9795  \n",
      "\n",
      "Fold: 24  Epoch: 57  Training loss = 4.2822  Validation loss = 1.9791  \n",
      "\n",
      "Fold: 24  Epoch: 58  Training loss = 4.2818  Validation loss = 1.9786  \n",
      "\n",
      "Fold: 24  Epoch: 59  Training loss = 4.2814  Validation loss = 1.9782  \n",
      "\n",
      "Fold: 24  Epoch: 60  Training loss = 4.2810  Validation loss = 1.9779  \n",
      "\n",
      "Fold: 24  Epoch: 61  Training loss = 4.2807  Validation loss = 1.9775  \n",
      "\n",
      "Fold: 24  Epoch: 62  Training loss = 4.2803  Validation loss = 1.9771  \n",
      "\n",
      "Fold: 24  Epoch: 63  Training loss = 4.2801  Validation loss = 1.9769  \n",
      "\n",
      "Fold: 24  Epoch: 64  Training loss = 4.2797  Validation loss = 1.9765  \n",
      "\n",
      "Fold: 24  Epoch: 65  Training loss = 4.2793  Validation loss = 1.9761  \n",
      "\n",
      "Fold: 24  Epoch: 66  Training loss = 4.2790  Validation loss = 1.9757  \n",
      "\n",
      "Fold: 24  Epoch: 67  Training loss = 4.2786  Validation loss = 1.9751  \n",
      "\n",
      "Fold: 24  Epoch: 68  Training loss = 4.2782  Validation loss = 1.9747  \n",
      "\n",
      "Fold: 24  Epoch: 69  Training loss = 4.2779  Validation loss = 1.9743  \n",
      "\n",
      "Fold: 24  Epoch: 70  Training loss = 4.2775  Validation loss = 1.9738  \n",
      "\n",
      "Fold: 24  Epoch: 71  Training loss = 4.2770  Validation loss = 1.9733  \n",
      "\n",
      "Fold: 24  Epoch: 72  Training loss = 4.2766  Validation loss = 1.9728  \n",
      "\n",
      "Fold: 24  Epoch: 73  Training loss = 4.2762  Validation loss = 1.9723  \n",
      "\n",
      "Fold: 24  Epoch: 74  Training loss = 4.2758  Validation loss = 1.9719  \n",
      "\n",
      "Fold: 24  Epoch: 75  Training loss = 4.2754  Validation loss = 1.9714  \n",
      "\n",
      "Fold: 24  Epoch: 76  Training loss = 4.2750  Validation loss = 1.9710  \n",
      "\n",
      "Fold: 24  Epoch: 77  Training loss = 4.2748  Validation loss = 1.9707  \n",
      "\n",
      "Fold: 24  Epoch: 78  Training loss = 4.2744  Validation loss = 1.9703  \n",
      "\n",
      "Fold: 24  Epoch: 79  Training loss = 4.2740  Validation loss = 1.9699  \n",
      "\n",
      "Fold: 24  Epoch: 80  Training loss = 4.2736  Validation loss = 1.9695  \n",
      "\n",
      "Fold: 24  Epoch: 81  Training loss = 4.2733  Validation loss = 1.9691  \n",
      "\n",
      "Fold: 24  Epoch: 82  Training loss = 4.2730  Validation loss = 1.9686  \n",
      "\n",
      "Fold: 24  Epoch: 83  Training loss = 4.2726  Validation loss = 1.9683  \n",
      "\n",
      "Fold: 24  Epoch: 84  Training loss = 4.2723  Validation loss = 1.9679  \n",
      "\n",
      "Fold: 24  Epoch: 85  Training loss = 4.2719  Validation loss = 1.9674  \n",
      "\n",
      "Fold: 24  Epoch: 86  Training loss = 4.2714  Validation loss = 1.9669  \n",
      "\n",
      "Fold: 24  Epoch: 87  Training loss = 4.2711  Validation loss = 1.9666  \n",
      "\n",
      "Fold: 24  Epoch: 88  Training loss = 4.2708  Validation loss = 1.9663  \n",
      "\n",
      "Fold: 24  Epoch: 89  Training loss = 4.2704  Validation loss = 1.9659  \n",
      "\n",
      "Fold: 24  Epoch: 90  Training loss = 4.2702  Validation loss = 1.9657  \n",
      "\n",
      "Fold: 24  Epoch: 91  Training loss = 4.2698  Validation loss = 1.9652  \n",
      "\n",
      "Fold: 24  Epoch: 92  Training loss = 4.2694  Validation loss = 1.9648  \n",
      "\n",
      "Fold: 24  Epoch: 93  Training loss = 4.2691  Validation loss = 1.9644  \n",
      "\n",
      "Fold: 24  Epoch: 94  Training loss = 4.2687  Validation loss = 1.9640  \n",
      "\n",
      "Fold: 24  Epoch: 95  Training loss = 4.2684  Validation loss = 1.9636  \n",
      "\n",
      "Fold: 24  Epoch: 96  Training loss = 4.2681  Validation loss = 1.9633  \n",
      "\n",
      "Fold: 24  Epoch: 97  Training loss = 4.2676  Validation loss = 1.9628  \n",
      "\n",
      "Fold: 24  Epoch: 98  Training loss = 4.2673  Validation loss = 1.9623  \n",
      "\n",
      "Fold: 24  Epoch: 99  Training loss = 4.2670  Validation loss = 1.9619  \n",
      "\n",
      "Fold: 24  Epoch: 100  Training loss = 4.2666  Validation loss = 1.9615  \n",
      "\n",
      "Fold: 24  Epoch: 101  Training loss = 4.2663  Validation loss = 1.9613  \n",
      "\n",
      "Fold: 24  Epoch: 102  Training loss = 4.2661  Validation loss = 1.9609  \n",
      "\n",
      "Fold: 24  Epoch: 103  Training loss = 4.2658  Validation loss = 1.9605  \n",
      "\n",
      "Fold: 24  Epoch: 104  Training loss = 4.2655  Validation loss = 1.9602  \n",
      "\n",
      "Fold: 24  Epoch: 105  Training loss = 4.2652  Validation loss = 1.9598  \n",
      "\n",
      "Fold: 24  Epoch: 106  Training loss = 4.2648  Validation loss = 1.9594  \n",
      "\n",
      "Fold: 24  Epoch: 107  Training loss = 4.2643  Validation loss = 1.9589  \n",
      "\n",
      "Fold: 24  Epoch: 108  Training loss = 4.2640  Validation loss = 1.9586  \n",
      "\n",
      "Fold: 24  Epoch: 109  Training loss = 4.2636  Validation loss = 1.9581  \n",
      "\n",
      "Fold: 24  Epoch: 110  Training loss = 4.2633  Validation loss = 1.9578  \n",
      "\n",
      "Fold: 24  Epoch: 111  Training loss = 4.2631  Validation loss = 1.9575  \n",
      "\n",
      "Fold: 24  Epoch: 112  Training loss = 4.2628  Validation loss = 1.9572  \n",
      "\n",
      "Fold: 24  Epoch: 113  Training loss = 4.2624  Validation loss = 1.9568  \n",
      "\n",
      "Fold: 24  Epoch: 114  Training loss = 4.2620  Validation loss = 1.9564  \n",
      "\n",
      "Fold: 24  Epoch: 115  Training loss = 4.2617  Validation loss = 1.9560  \n",
      "\n",
      "Fold: 24  Epoch: 116  Training loss = 4.2614  Validation loss = 1.9557  \n",
      "\n",
      "Fold: 24  Epoch: 117  Training loss = 4.2610  Validation loss = 1.9553  \n",
      "\n",
      "Fold: 24  Epoch: 118  Training loss = 4.2606  Validation loss = 1.9548  \n",
      "\n",
      "Fold: 24  Epoch: 119  Training loss = 4.2602  Validation loss = 1.9544  \n",
      "\n",
      "Fold: 24  Epoch: 120  Training loss = 4.2599  Validation loss = 1.9541  \n",
      "\n",
      "Fold: 24  Epoch: 121  Training loss = 4.2596  Validation loss = 1.9538  \n",
      "\n",
      "Fold: 24  Epoch: 122  Training loss = 4.2593  Validation loss = 1.9533  \n",
      "\n",
      "Fold: 24  Epoch: 123  Training loss = 4.2590  Validation loss = 1.9530  \n",
      "\n",
      "Fold: 24  Epoch: 124  Training loss = 4.2585  Validation loss = 1.9525  \n",
      "\n",
      "Fold: 24  Epoch: 125  Training loss = 4.2580  Validation loss = 1.9521  \n",
      "\n",
      "Fold: 24  Epoch: 126  Training loss = 4.2577  Validation loss = 1.9517  \n",
      "\n",
      "Fold: 24  Epoch: 127  Training loss = 4.2575  Validation loss = 1.9515  \n",
      "\n",
      "Fold: 24  Epoch: 128  Training loss = 4.2572  Validation loss = 1.9511  \n",
      "\n",
      "Fold: 24  Epoch: 129  Training loss = 4.2568  Validation loss = 1.9507  \n",
      "\n",
      "Fold: 24  Epoch: 130  Training loss = 4.2565  Validation loss = 1.9503  \n",
      "\n",
      "Fold: 24  Epoch: 131  Training loss = 4.2561  Validation loss = 1.9498  \n",
      "\n",
      "Fold: 24  Epoch: 132  Training loss = 4.2557  Validation loss = 1.9494  \n",
      "\n",
      "Fold: 24  Epoch: 133  Training loss = 4.2554  Validation loss = 1.9491  \n",
      "\n",
      "Fold: 24  Epoch: 134  Training loss = 4.2553  Validation loss = 1.9489  \n",
      "\n",
      "Fold: 24  Epoch: 135  Training loss = 4.2549  Validation loss = 1.9486  \n",
      "\n",
      "Fold: 24  Epoch: 136  Training loss = 4.2546  Validation loss = 1.9482  \n",
      "\n",
      "Fold: 24  Epoch: 137  Training loss = 4.2543  Validation loss = 1.9479  \n",
      "\n",
      "Fold: 24  Epoch: 138  Training loss = 4.2539  Validation loss = 1.9474  \n",
      "\n",
      "Fold: 24  Epoch: 139  Training loss = 4.2535  Validation loss = 1.9470  \n",
      "\n",
      "Fold: 24  Epoch: 140  Training loss = 4.2532  Validation loss = 1.9467  \n",
      "\n",
      "Fold: 24  Epoch: 141  Training loss = 4.2528  Validation loss = 1.9464  \n",
      "\n",
      "Fold: 24  Epoch: 142  Training loss = 4.2525  Validation loss = 1.9460  \n",
      "\n",
      "Fold: 24  Epoch: 143  Training loss = 4.2522  Validation loss = 1.9457  \n",
      "\n",
      "Fold: 24  Epoch: 144  Training loss = 4.2519  Validation loss = 1.9453  \n",
      "\n",
      "Fold: 24  Epoch: 145  Training loss = 4.2516  Validation loss = 1.9451  \n",
      "\n",
      "Fold: 24  Epoch: 146  Training loss = 4.2512  Validation loss = 1.9446  \n",
      "\n",
      "Fold: 24  Epoch: 147  Training loss = 4.2508  Validation loss = 1.9443  \n",
      "\n",
      "Fold: 24  Epoch: 148  Training loss = 4.2505  Validation loss = 1.9438  \n",
      "\n",
      "Fold: 24  Epoch: 149  Training loss = 4.2502  Validation loss = 1.9435  \n",
      "\n",
      "Fold: 24  Epoch: 150  Training loss = 4.2498  Validation loss = 1.9431  \n",
      "\n",
      "Fold: 24  Epoch: 151  Training loss = 4.2495  Validation loss = 1.9427  \n",
      "\n",
      "Fold: 24  Epoch: 152  Training loss = 4.2492  Validation loss = 1.9424  \n",
      "\n",
      "Fold: 24  Epoch: 153  Training loss = 4.2488  Validation loss = 1.9419  \n",
      "\n",
      "Fold: 24  Epoch: 154  Training loss = 4.2485  Validation loss = 1.9416  \n",
      "\n",
      "Fold: 24  Epoch: 155  Training loss = 4.2481  Validation loss = 1.9412  \n",
      "\n",
      "Fold: 24  Epoch: 156  Training loss = 4.2478  Validation loss = 1.9409  \n",
      "\n",
      "Fold: 24  Epoch: 157  Training loss = 4.2475  Validation loss = 1.9405  \n",
      "\n",
      "Fold: 24  Epoch: 158  Training loss = 4.2471  Validation loss = 1.9400  \n",
      "\n",
      "Fold: 24  Epoch: 159  Training loss = 4.2467  Validation loss = 1.9396  \n",
      "\n",
      "Fold: 24  Epoch: 160  Training loss = 4.2464  Validation loss = 1.9394  \n",
      "\n",
      "Fold: 24  Epoch: 161  Training loss = 4.2461  Validation loss = 1.9390  \n",
      "\n",
      "Fold: 24  Epoch: 162  Training loss = 4.2458  Validation loss = 1.9387  \n",
      "\n",
      "Fold: 24  Epoch: 163  Training loss = 4.2455  Validation loss = 1.9384  \n",
      "\n",
      "Fold: 24  Epoch: 164  Training loss = 4.2451  Validation loss = 1.9379  \n",
      "\n",
      "Fold: 24  Epoch: 165  Training loss = 4.2449  Validation loss = 1.9375  \n",
      "\n",
      "Fold: 24  Epoch: 166  Training loss = 4.2445  Validation loss = 1.9371  \n",
      "\n",
      "Fold: 24  Epoch: 167  Training loss = 4.2442  Validation loss = 1.9367  \n",
      "\n",
      "Fold: 24  Epoch: 168  Training loss = 4.2438  Validation loss = 1.9362  \n",
      "\n",
      "Fold: 24  Epoch: 169  Training loss = 4.2434  Validation loss = 1.9358  \n",
      "\n",
      "Fold: 24  Epoch: 170  Training loss = 4.2432  Validation loss = 1.9355  \n",
      "\n",
      "Fold: 24  Epoch: 171  Training loss = 4.2429  Validation loss = 1.9351  \n",
      "\n",
      "Fold: 24  Epoch: 172  Training loss = 4.2426  Validation loss = 1.9348  \n",
      "\n",
      "Fold: 24  Epoch: 173  Training loss = 4.2421  Validation loss = 1.9344  \n",
      "\n",
      "Fold: 24  Epoch: 174  Training loss = 4.2418  Validation loss = 1.9340  \n",
      "\n",
      "Fold: 24  Epoch: 175  Training loss = 4.2414  Validation loss = 1.9336  \n",
      "\n",
      "Fold: 24  Epoch: 176  Training loss = 4.2411  Validation loss = 1.9332  \n",
      "\n",
      "Fold: 24  Epoch: 177  Training loss = 4.2407  Validation loss = 1.9328  \n",
      "\n",
      "Fold: 24  Epoch: 178  Training loss = 4.2403  Validation loss = 1.9325  \n",
      "\n",
      "Fold: 24  Epoch: 179  Training loss = 4.2401  Validation loss = 1.9322  \n",
      "\n",
      "Fold: 24  Epoch: 180  Training loss = 4.2396  Validation loss = 1.9316  \n",
      "\n",
      "Fold: 24  Epoch: 181  Training loss = 4.2393  Validation loss = 1.9313  \n",
      "\n",
      "Fold: 24  Epoch: 182  Training loss = 4.2390  Validation loss = 1.9309  \n",
      "\n",
      "Fold: 24  Epoch: 183  Training loss = 4.2387  Validation loss = 1.9306  \n",
      "\n",
      "Fold: 24  Epoch: 184  Training loss = 4.2384  Validation loss = 1.9302  \n",
      "\n",
      "Fold: 24  Epoch: 185  Training loss = 4.2382  Validation loss = 1.9300  \n",
      "\n",
      "Fold: 24  Epoch: 186  Training loss = 4.2379  Validation loss = 1.9296  \n",
      "\n",
      "Fold: 24  Epoch: 187  Training loss = 4.2375  Validation loss = 1.9292  \n",
      "\n",
      "Fold: 24  Epoch: 188  Training loss = 4.2372  Validation loss = 1.9288  \n",
      "\n",
      "Fold: 24  Epoch: 189  Training loss = 4.2369  Validation loss = 1.9285  \n",
      "\n",
      "Fold: 24  Epoch: 190  Training loss = 4.2365  Validation loss = 1.9282  \n",
      "\n",
      "Fold: 24  Epoch: 191  Training loss = 4.2362  Validation loss = 1.9279  \n",
      "\n",
      "Fold: 24  Epoch: 192  Training loss = 4.2358  Validation loss = 1.9273  \n",
      "\n",
      "Fold: 24  Epoch: 193  Training loss = 4.2355  Validation loss = 1.9270  \n",
      "\n",
      "Fold: 24  Epoch: 194  Training loss = 4.2352  Validation loss = 1.9267  \n",
      "\n",
      "Fold: 24  Epoch: 195  Training loss = 4.2347  Validation loss = 1.9262  \n",
      "\n",
      "Fold: 24  Epoch: 196  Training loss = 4.2344  Validation loss = 1.9258  \n",
      "\n",
      "Fold: 24  Epoch: 197  Training loss = 4.2339  Validation loss = 1.9253  \n",
      "\n",
      "Fold: 24  Epoch: 198  Training loss = 4.2335  Validation loss = 1.9250  \n",
      "\n",
      "Fold: 24  Epoch: 199  Training loss = 4.2332  Validation loss = 1.9246  \n",
      "\n",
      "Fold: 24  Epoch: 200  Training loss = 4.2328  Validation loss = 1.9241  \n",
      "\n",
      "Fold: 24  Epoch: 201  Training loss = 4.2325  Validation loss = 1.9238  \n",
      "\n",
      "Fold: 24  Epoch: 202  Training loss = 4.2321  Validation loss = 1.9234  \n",
      "\n",
      "Fold: 24  Epoch: 203  Training loss = 4.2317  Validation loss = 1.9231  \n",
      "\n",
      "Fold: 24  Epoch: 204  Training loss = 4.2312  Validation loss = 1.9226  \n",
      "\n",
      "Fold: 24  Epoch: 205  Training loss = 4.2298  Validation loss = 1.9221  \n",
      "\n",
      "Fold: 24  Epoch: 206  Training loss = 4.2254  Validation loss = 1.9217  \n",
      "\n",
      "Fold: 24  Epoch: 207  Training loss = 4.2250  Validation loss = 1.9213  \n",
      "\n",
      "Fold: 24  Epoch: 208  Training loss = 4.2247  Validation loss = 1.9210  \n",
      "\n",
      "Fold: 24  Epoch: 209  Training loss = 4.2244  Validation loss = 1.9205  \n",
      "\n",
      "Fold: 24  Epoch: 210  Training loss = 4.2241  Validation loss = 1.9202  \n",
      "\n",
      "Fold: 24  Epoch: 211  Training loss = 4.2238  Validation loss = 1.9199  \n",
      "\n",
      "Fold: 24  Epoch: 212  Training loss = 4.2234  Validation loss = 1.9195  \n",
      "\n",
      "Fold: 24  Epoch: 213  Training loss = 4.2230  Validation loss = 1.9191  \n",
      "\n",
      "Fold: 24  Epoch: 214  Training loss = 4.2227  Validation loss = 1.9187  \n",
      "\n",
      "Fold: 24  Epoch: 215  Training loss = 4.2225  Validation loss = 1.9184  \n",
      "\n",
      "Fold: 24  Epoch: 216  Training loss = 4.2222  Validation loss = 1.9180  \n",
      "\n",
      "Fold: 24  Epoch: 217  Training loss = 4.2220  Validation loss = 1.9178  \n",
      "\n",
      "Fold: 24  Epoch: 218  Training loss = 4.2218  Validation loss = 1.9175  \n",
      "\n",
      "Fold: 24  Epoch: 219  Training loss = 4.2213  Validation loss = 1.9171  \n",
      "\n",
      "Fold: 24  Epoch: 220  Training loss = 4.2210  Validation loss = 1.9167  \n",
      "\n",
      "Fold: 24  Epoch: 221  Training loss = 4.2208  Validation loss = 1.9164  \n",
      "\n",
      "Fold: 24  Epoch: 222  Training loss = 4.2205  Validation loss = 1.9160  \n",
      "\n",
      "Fold: 24  Epoch: 223  Training loss = 4.2201  Validation loss = 1.9156  \n",
      "\n",
      "Fold: 24  Epoch: 224  Training loss = 4.2197  Validation loss = 1.9152  \n",
      "\n",
      "Fold: 24  Epoch: 225  Training loss = 4.2193  Validation loss = 1.9147  \n",
      "\n",
      "Fold: 24  Epoch: 226  Training loss = 4.2190  Validation loss = 1.9143  \n",
      "\n",
      "Fold: 24  Epoch: 227  Training loss = 4.2186  Validation loss = 1.9139  \n",
      "\n",
      "Fold: 24  Epoch: 228  Training loss = 4.2183  Validation loss = 1.9136  \n",
      "\n",
      "Fold: 24  Epoch: 229  Training loss = 4.2180  Validation loss = 1.9134  \n",
      "\n",
      "Fold: 24  Epoch: 230  Training loss = 4.2178  Validation loss = 1.9131  \n",
      "\n",
      "Fold: 24  Epoch: 231  Training loss = 4.2176  Validation loss = 1.9128  \n",
      "\n",
      "Fold: 24  Epoch: 232  Training loss = 4.2173  Validation loss = 1.9125  \n",
      "\n",
      "Fold: 24  Epoch: 233  Training loss = 4.2170  Validation loss = 1.9121  \n",
      "\n",
      "Fold: 24  Epoch: 234  Training loss = 4.2167  Validation loss = 1.9118  \n",
      "\n",
      "Fold: 24  Epoch: 235  Training loss = 4.2163  Validation loss = 1.9114  \n",
      "\n",
      "Fold: 24  Epoch: 236  Training loss = 4.2161  Validation loss = 1.9112  \n",
      "\n",
      "Fold: 24  Epoch: 237  Training loss = 4.2158  Validation loss = 1.9109  \n",
      "\n",
      "Fold: 24  Epoch: 238  Training loss = 4.2155  Validation loss = 1.9105  \n",
      "\n",
      "Fold: 24  Epoch: 239  Training loss = 4.2151  Validation loss = 1.9101  \n",
      "\n",
      "Fold: 24  Epoch: 240  Training loss = 4.2149  Validation loss = 1.9098  \n",
      "\n",
      "Fold: 24  Epoch: 241  Training loss = 4.2145  Validation loss = 1.9094  \n",
      "\n",
      "Fold: 24  Epoch: 242  Training loss = 4.2142  Validation loss = 1.9090  \n",
      "\n",
      "Fold: 24  Epoch: 243  Training loss = 4.2138  Validation loss = 1.9086  \n",
      "\n",
      "Fold: 24  Epoch: 244  Training loss = 4.2134  Validation loss = 1.9082  \n",
      "\n",
      "Fold: 24  Epoch: 245  Training loss = 4.2130  Validation loss = 1.9077  \n",
      "\n",
      "Fold: 24  Epoch: 246  Training loss = 4.2127  Validation loss = 1.9074  \n",
      "\n",
      "Fold: 24  Epoch: 247  Training loss = 4.2123  Validation loss = 1.9070  \n",
      "\n",
      "Fold: 24  Epoch: 248  Training loss = 4.2120  Validation loss = 1.9066  \n",
      "\n",
      "Fold: 24  Epoch: 249  Training loss = 4.2118  Validation loss = 1.9064  \n",
      "\n",
      "Fold: 24  Epoch: 250  Training loss = 4.2116  Validation loss = 1.9062  \n",
      "\n",
      "Fold: 24  Epoch: 251  Training loss = 4.2112  Validation loss = 1.9059  \n",
      "\n",
      "Fold: 24  Epoch: 252  Training loss = 4.2109  Validation loss = 1.9056  \n",
      "\n",
      "Fold: 24  Epoch: 253  Training loss = 4.2107  Validation loss = 1.9053  \n",
      "\n",
      "Fold: 24  Epoch: 254  Training loss = 4.2104  Validation loss = 1.9049  \n",
      "\n",
      "Fold: 24  Epoch: 255  Training loss = 4.2100  Validation loss = 1.9046  \n",
      "\n",
      "Fold: 24  Epoch: 256  Training loss = 4.2097  Validation loss = 1.9043  \n",
      "\n",
      "Fold: 24  Epoch: 257  Training loss = 4.2094  Validation loss = 1.9039  \n",
      "\n",
      "Fold: 24  Epoch: 258  Training loss = 4.2091  Validation loss = 1.9036  \n",
      "\n",
      "Fold: 24  Epoch: 259  Training loss = 4.2087  Validation loss = 1.9032  \n",
      "\n",
      "Fold: 24  Epoch: 260  Training loss = 4.2084  Validation loss = 1.9029  \n",
      "\n",
      "Fold: 24  Epoch: 261  Training loss = 4.2080  Validation loss = 1.9025  \n",
      "\n",
      "Fold: 24  Epoch: 262  Training loss = 4.2077  Validation loss = 1.9021  \n",
      "\n",
      "Fold: 24  Epoch: 263  Training loss = 4.2074  Validation loss = 1.9017  \n",
      "\n",
      "Fold: 24  Epoch: 264  Training loss = 4.2071  Validation loss = 1.9014  \n",
      "\n",
      "Fold: 24  Epoch: 265  Training loss = 4.2068  Validation loss = 1.9010  \n",
      "\n",
      "Fold: 24  Epoch: 266  Training loss = 4.2065  Validation loss = 1.9006  \n",
      "\n",
      "Fold: 24  Epoch: 267  Training loss = 4.2062  Validation loss = 1.9002  \n",
      "\n",
      "Fold: 24  Epoch: 268  Training loss = 4.2058  Validation loss = 1.8998  \n",
      "\n",
      "Fold: 24  Epoch: 269  Training loss = 4.2054  Validation loss = 1.8994  \n",
      "\n",
      "Fold: 24  Epoch: 270  Training loss = 4.2051  Validation loss = 1.8990  \n",
      "\n",
      "Fold: 24  Epoch: 271  Training loss = 4.2048  Validation loss = 1.8986  \n",
      "\n",
      "Fold: 24  Epoch: 272  Training loss = 4.2045  Validation loss = 1.8984  \n",
      "\n",
      "Fold: 24  Epoch: 273  Training loss = 4.2042  Validation loss = 1.8980  \n",
      "\n",
      "Fold: 24  Epoch: 274  Training loss = 4.2038  Validation loss = 1.8977  \n",
      "\n",
      "Fold: 24  Epoch: 275  Training loss = 4.2034  Validation loss = 1.8972  \n",
      "\n",
      "Fold: 24  Epoch: 276  Training loss = 4.2031  Validation loss = 1.8968  \n",
      "\n",
      "Fold: 24  Epoch: 277  Training loss = 4.2028  Validation loss = 1.8964  \n",
      "\n",
      "Fold: 24  Epoch: 278  Training loss = 4.2025  Validation loss = 1.8962  \n",
      "\n",
      "Fold: 24  Epoch: 279  Training loss = 4.2023  Validation loss = 1.8958  \n",
      "\n",
      "Fold: 24  Epoch: 280  Training loss = 4.2019  Validation loss = 1.8954  \n",
      "\n",
      "Fold: 24  Epoch: 281  Training loss = 4.2015  Validation loss = 1.8950  \n",
      "\n",
      "Fold: 24  Epoch: 282  Training loss = 4.2012  Validation loss = 1.8946  \n",
      "\n",
      "Fold: 24  Epoch: 283  Training loss = 4.2007  Validation loss = 1.8941  \n",
      "\n",
      "Fold: 24  Epoch: 284  Training loss = 4.2004  Validation loss = 1.8937  \n",
      "\n",
      "Fold: 24  Epoch: 285  Training loss = 4.2003  Validation loss = 1.8936  \n",
      "\n",
      "Fold: 24  Epoch: 286  Training loss = 4.2000  Validation loss = 1.8932  \n",
      "\n",
      "Fold: 24  Epoch: 287  Training loss = 4.1996  Validation loss = 1.8928  \n",
      "\n",
      "Fold: 24  Epoch: 288  Training loss = 4.1993  Validation loss = 1.8925  \n",
      "\n",
      "Fold: 24  Epoch: 289  Training loss = 4.1989  Validation loss = 1.8921  \n",
      "\n",
      "Fold: 24  Epoch: 290  Training loss = 4.1986  Validation loss = 1.8917  \n",
      "\n",
      "Fold: 24  Epoch: 291  Training loss = 4.1982  Validation loss = 1.8914  \n",
      "\n",
      "Fold: 24  Epoch: 292  Training loss = 4.1980  Validation loss = 1.8910  \n",
      "\n",
      "Fold: 24  Epoch: 293  Training loss = 4.1977  Validation loss = 1.8907  \n",
      "\n",
      "Fold: 24  Epoch: 294  Training loss = 4.1973  Validation loss = 1.8903  \n",
      "\n",
      "Fold: 24  Epoch: 295  Training loss = 4.1969  Validation loss = 1.8898  \n",
      "\n",
      "Fold: 24  Epoch: 296  Training loss = 4.1966  Validation loss = 1.8896  \n",
      "\n",
      "Fold: 24  Epoch: 297  Training loss = 4.1964  Validation loss = 1.8893  \n",
      "\n",
      "Fold: 24  Epoch: 298  Training loss = 4.1961  Validation loss = 1.8890  \n",
      "\n",
      "Fold: 24  Epoch: 299  Training loss = 4.1958  Validation loss = 1.8886  \n",
      "\n",
      "Fold: 24  Epoch: 300  Training loss = 4.1955  Validation loss = 1.8883  \n",
      "\n",
      "Fold: 24  Epoch: 301  Training loss = 4.1952  Validation loss = 1.8880  \n",
      "\n",
      "Fold: 24  Epoch: 302  Training loss = 4.1949  Validation loss = 1.8877  \n",
      "\n",
      "Fold: 24  Epoch: 303  Training loss = 4.1946  Validation loss = 1.8874  \n",
      "\n",
      "Fold: 24  Epoch: 304  Training loss = 4.1942  Validation loss = 1.8871  \n",
      "\n",
      "Fold: 24  Epoch: 305  Training loss = 4.1938  Validation loss = 1.8866  \n",
      "\n",
      "Fold: 24  Epoch: 306  Training loss = 4.1935  Validation loss = 1.8863  \n",
      "\n",
      "Fold: 24  Epoch: 307  Training loss = 4.1932  Validation loss = 1.8859  \n",
      "\n",
      "Fold: 24  Epoch: 308  Training loss = 4.1928  Validation loss = 1.8855  \n",
      "\n",
      "Fold: 24  Epoch: 309  Training loss = 4.1925  Validation loss = 1.8852  \n",
      "\n",
      "Fold: 24  Epoch: 310  Training loss = 4.1922  Validation loss = 1.8849  \n",
      "\n",
      "Fold: 24  Epoch: 311  Training loss = 4.1919  Validation loss = 1.8847  \n",
      "\n",
      "Fold: 24  Epoch: 312  Training loss = 4.1917  Validation loss = 1.8843  \n",
      "\n",
      "Fold: 24  Epoch: 313  Training loss = 4.1913  Validation loss = 1.8840  \n",
      "\n",
      "Fold: 24  Epoch: 314  Training loss = 4.1910  Validation loss = 1.8836  \n",
      "\n",
      "Fold: 24  Epoch: 315  Training loss = 4.1907  Validation loss = 1.8832  \n",
      "\n",
      "Fold: 24  Epoch: 316  Training loss = 4.1903  Validation loss = 1.8828  \n",
      "\n",
      "Fold: 24  Epoch: 317  Training loss = 4.1900  Validation loss = 1.8825  \n",
      "\n",
      "Fold: 24  Epoch: 318  Training loss = 4.1897  Validation loss = 1.8822  \n",
      "\n",
      "Fold: 24  Epoch: 319  Training loss = 4.1893  Validation loss = 1.8818  \n",
      "\n",
      "Fold: 24  Epoch: 320  Training loss = 4.1888  Validation loss = 1.8812  \n",
      "\n",
      "Fold: 24  Epoch: 321  Training loss = 4.1885  Validation loss = 1.8808  \n",
      "\n",
      "Fold: 24  Epoch: 322  Training loss = 4.1882  Validation loss = 1.8805  \n",
      "\n",
      "Fold: 24  Epoch: 323  Training loss = 4.1878  Validation loss = 1.8802  \n",
      "\n",
      "Fold: 24  Epoch: 324  Training loss = 4.1875  Validation loss = 1.8798  \n",
      "\n",
      "Fold: 24  Epoch: 325  Training loss = 4.1873  Validation loss = 1.8795  \n",
      "\n",
      "Fold: 24  Epoch: 326  Training loss = 4.1870  Validation loss = 1.8792  \n",
      "\n",
      "Fold: 24  Epoch: 327  Training loss = 4.1867  Validation loss = 1.8789  \n",
      "\n",
      "Fold: 24  Epoch: 328  Training loss = 4.1865  Validation loss = 1.8786  \n",
      "\n",
      "Fold: 24  Epoch: 329  Training loss = 4.1861  Validation loss = 1.8782  \n",
      "\n",
      "Fold: 24  Epoch: 330  Training loss = 4.1858  Validation loss = 1.8778  \n",
      "\n",
      "Fold: 24  Epoch: 331  Training loss = 4.1855  Validation loss = 1.8775  \n",
      "\n",
      "Fold: 24  Epoch: 332  Training loss = 4.1852  Validation loss = 1.8771  \n",
      "\n",
      "Fold: 24  Epoch: 333  Training loss = 4.1849  Validation loss = 1.8768  \n",
      "\n",
      "Fold: 24  Epoch: 334  Training loss = 4.1847  Validation loss = 1.8765  \n",
      "\n",
      "Fold: 24  Epoch: 335  Training loss = 4.1845  Validation loss = 1.8764  \n",
      "\n",
      "Fold: 24  Epoch: 336  Training loss = 4.1841  Validation loss = 1.8759  \n",
      "\n",
      "Fold: 24  Epoch: 337  Training loss = 4.1839  Validation loss = 1.8757  \n",
      "\n",
      "Fold: 24  Epoch: 338  Training loss = 4.1835  Validation loss = 1.8753  \n",
      "\n",
      "Fold: 24  Epoch: 339  Training loss = 4.1832  Validation loss = 1.8750  \n",
      "\n",
      "Fold: 24  Epoch: 340  Training loss = 4.1830  Validation loss = 1.8748  \n",
      "\n",
      "Fold: 24  Epoch: 341  Training loss = 4.1827  Validation loss = 1.8745  \n",
      "\n",
      "Fold: 24  Epoch: 342  Training loss = 4.1822  Validation loss = 1.8740  \n",
      "\n",
      "Fold: 24  Epoch: 343  Training loss = 4.1820  Validation loss = 1.8737  \n",
      "\n",
      "Fold: 24  Epoch: 344  Training loss = 4.1816  Validation loss = 1.8733  \n",
      "\n",
      "Fold: 24  Epoch: 345  Training loss = 4.1812  Validation loss = 1.8729  \n",
      "\n",
      "Fold: 24  Epoch: 346  Training loss = 4.1809  Validation loss = 1.8725  \n",
      "\n",
      "Fold: 24  Epoch: 347  Training loss = 4.1806  Validation loss = 1.8722  \n",
      "\n",
      "Fold: 24  Epoch: 348  Training loss = 4.1802  Validation loss = 1.8717  \n",
      "\n",
      "Fold: 24  Epoch: 349  Training loss = 4.1798  Validation loss = 1.8713  \n",
      "\n",
      "Fold: 24  Epoch: 350  Training loss = 4.1796  Validation loss = 1.8711  \n",
      "\n",
      "Fold: 24  Epoch: 351  Training loss = 4.1793  Validation loss = 1.8708  \n",
      "\n",
      "Fold: 24  Epoch: 352  Training loss = 4.1789  Validation loss = 1.8702  \n",
      "\n",
      "Fold: 24  Epoch: 353  Training loss = 4.1785  Validation loss = 1.8698  \n",
      "\n",
      "Fold: 24  Epoch: 354  Training loss = 4.1783  Validation loss = 1.8695  \n",
      "\n",
      "Fold: 24  Epoch: 355  Training loss = 4.1780  Validation loss = 1.8691  \n",
      "\n",
      "Fold: 24  Epoch: 356  Training loss = 4.1777  Validation loss = 1.8688  \n",
      "\n",
      "Fold: 24  Epoch: 357  Training loss = 4.1774  Validation loss = 1.8685  \n",
      "\n",
      "Fold: 24  Epoch: 358  Training loss = 4.1771  Validation loss = 1.8682  \n",
      "\n",
      "Fold: 24  Epoch: 359  Training loss = 4.1768  Validation loss = 1.8678  \n",
      "\n",
      "Fold: 24  Epoch: 360  Training loss = 4.1765  Validation loss = 1.8675  \n",
      "\n",
      "Fold: 24  Epoch: 361  Training loss = 4.1762  Validation loss = 1.8670  \n",
      "\n",
      "Fold: 24  Epoch: 362  Training loss = 4.1758  Validation loss = 1.8666  \n",
      "\n",
      "Fold: 24  Epoch: 363  Training loss = 4.1755  Validation loss = 1.8663  \n",
      "\n",
      "Fold: 24  Epoch: 364  Training loss = 4.1752  Validation loss = 1.8658  \n",
      "\n",
      "Fold: 24  Epoch: 365  Training loss = 4.1749  Validation loss = 1.8656  \n",
      "\n",
      "Fold: 24  Epoch: 366  Training loss = 4.1747  Validation loss = 1.8653  \n",
      "\n",
      "Fold: 24  Epoch: 367  Training loss = 4.1744  Validation loss = 1.8649  \n",
      "\n",
      "Fold: 24  Epoch: 368  Training loss = 4.1740  Validation loss = 1.8647  \n",
      "\n",
      "Fold: 24  Epoch: 369  Training loss = 4.1738  Validation loss = 1.8645  \n",
      "\n",
      "Fold: 24  Epoch: 370  Training loss = 4.1734  Validation loss = 1.8639  \n",
      "\n",
      "Fold: 24  Epoch: 371  Training loss = 4.1731  Validation loss = 1.8636  \n",
      "\n",
      "Fold: 24  Epoch: 372  Training loss = 4.1729  Validation loss = 1.8632  \n",
      "\n",
      "Fold: 24  Epoch: 373  Training loss = 4.1726  Validation loss = 1.8631  \n",
      "\n",
      "Fold: 24  Epoch: 374  Training loss = 4.1724  Validation loss = 1.8628  \n",
      "\n",
      "Fold: 24  Epoch: 375  Training loss = 4.1721  Validation loss = 1.8624  \n",
      "\n",
      "Fold: 24  Epoch: 376  Training loss = 4.1718  Validation loss = 1.8621  \n",
      "\n",
      "Fold: 24  Epoch: 377  Training loss = 4.1715  Validation loss = 1.8618  \n",
      "\n",
      "Fold: 24  Epoch: 378  Training loss = 4.1712  Validation loss = 1.8615  \n",
      "\n",
      "Fold: 24  Epoch: 379  Training loss = 4.1709  Validation loss = 1.8610  \n",
      "\n",
      "Fold: 24  Epoch: 380  Training loss = 4.1706  Validation loss = 1.8607  \n",
      "\n",
      "Fold: 24  Epoch: 381  Training loss = 4.1702  Validation loss = 1.8603  \n",
      "\n",
      "Fold: 24  Epoch: 382  Training loss = 4.1700  Validation loss = 1.8601  \n",
      "\n",
      "Fold: 24  Epoch: 383  Training loss = 4.1697  Validation loss = 1.8597  \n",
      "\n",
      "Fold: 24  Epoch: 384  Training loss = 4.1694  Validation loss = 1.8593  \n",
      "\n",
      "Fold: 24  Epoch: 385  Training loss = 4.1691  Validation loss = 1.8590  \n",
      "\n",
      "Fold: 24  Epoch: 386  Training loss = 4.1689  Validation loss = 1.8588  \n",
      "\n",
      "Fold: 24  Epoch: 387  Training loss = 4.1685  Validation loss = 1.8583  \n",
      "\n",
      "Fold: 24  Epoch: 388  Training loss = 4.1682  Validation loss = 1.8580  \n",
      "\n",
      "Fold: 24  Epoch: 389  Training loss = 4.1678  Validation loss = 1.8575  \n",
      "\n",
      "Fold: 24  Epoch: 390  Training loss = 4.1675  Validation loss = 1.8571  \n",
      "\n",
      "Fold: 24  Epoch: 391  Training loss = 4.1672  Validation loss = 1.8567  \n",
      "\n",
      "Fold: 24  Epoch: 392  Training loss = 4.1669  Validation loss = 1.8563  \n",
      "\n",
      "Fold: 24  Epoch: 393  Training loss = 4.1665  Validation loss = 1.8560  \n",
      "\n",
      "Fold: 24  Epoch: 394  Training loss = 4.1663  Validation loss = 1.8557  \n",
      "\n",
      "Fold: 24  Epoch: 395  Training loss = 4.1659  Validation loss = 1.8554  \n",
      "\n",
      "Fold: 24  Epoch: 396  Training loss = 4.1656  Validation loss = 1.8550  \n",
      "\n",
      "Fold: 24  Epoch: 397  Training loss = 4.1652  Validation loss = 1.8546  \n",
      "\n",
      "Fold: 24  Epoch: 398  Training loss = 4.1648  Validation loss = 1.8541  \n",
      "\n",
      "Fold: 24  Epoch: 399  Training loss = 4.1644  Validation loss = 1.8536  \n",
      "\n",
      "Fold: 24  Epoch: 400  Training loss = 4.1641  Validation loss = 1.8533  \n",
      "\n",
      "Fold: 24  Epoch: 401  Training loss = 4.1637  Validation loss = 1.8528  \n",
      "\n",
      "Fold: 24  Epoch: 402  Training loss = 4.1633  Validation loss = 1.8524  \n",
      "\n",
      "Fold: 24  Epoch: 403  Training loss = 4.1631  Validation loss = 1.8521  \n",
      "\n",
      "Fold: 24  Epoch: 404  Training loss = 4.1627  Validation loss = 1.8518  \n",
      "\n",
      "Fold: 24  Epoch: 405  Training loss = 4.1625  Validation loss = 1.8515  \n",
      "\n",
      "Fold: 24  Epoch: 406  Training loss = 4.1621  Validation loss = 1.8511  \n",
      "\n",
      "Fold: 24  Epoch: 407  Training loss = 4.1619  Validation loss = 1.8508  \n",
      "\n",
      "Fold: 24  Epoch: 408  Training loss = 4.1615  Validation loss = 1.8504  \n",
      "\n",
      "Fold: 24  Epoch: 409  Training loss = 4.1613  Validation loss = 1.8502  \n",
      "\n",
      "Fold: 24  Epoch: 410  Training loss = 4.1610  Validation loss = 1.8499  \n",
      "\n",
      "Fold: 24  Epoch: 411  Training loss = 4.1607  Validation loss = 1.8495  \n",
      "\n",
      "Fold: 24  Epoch: 412  Training loss = 4.1604  Validation loss = 1.8492  \n",
      "\n",
      "Fold: 24  Epoch: 413  Training loss = 4.1601  Validation loss = 1.8489  \n",
      "\n",
      "Fold: 24  Epoch: 414  Training loss = 4.1597  Validation loss = 1.8484  \n",
      "\n",
      "Fold: 24  Epoch: 415  Training loss = 4.1594  Validation loss = 1.8481  \n",
      "\n",
      "Fold: 24  Epoch: 416  Training loss = 4.1591  Validation loss = 1.8478  \n",
      "\n",
      "Fold: 24  Epoch: 417  Training loss = 4.1589  Validation loss = 1.8474  \n",
      "\n",
      "Fold: 24  Epoch: 418  Training loss = 4.1586  Validation loss = 1.8471  \n",
      "\n",
      "Fold: 24  Epoch: 419  Training loss = 4.1582  Validation loss = 1.8467  \n",
      "\n",
      "Fold: 24  Epoch: 420  Training loss = 4.1580  Validation loss = 1.8465  \n",
      "\n",
      "Fold: 24  Epoch: 421  Training loss = 4.1577  Validation loss = 1.8463  \n",
      "\n",
      "Fold: 24  Epoch: 422  Training loss = 4.1574  Validation loss = 1.8458  \n",
      "\n",
      "Fold: 24  Epoch: 423  Training loss = 4.1572  Validation loss = 1.8456  \n",
      "\n",
      "Fold: 24  Epoch: 424  Training loss = 4.1568  Validation loss = 1.8452  \n",
      "\n",
      "Fold: 24  Epoch: 425  Training loss = 4.1565  Validation loss = 1.8447  \n",
      "\n",
      "Fold: 24  Epoch: 426  Training loss = 4.1562  Validation loss = 1.8444  \n",
      "\n",
      "Fold: 24  Epoch: 427  Training loss = 4.1559  Validation loss = 1.8441  \n",
      "\n",
      "Fold: 24  Epoch: 428  Training loss = 4.1557  Validation loss = 1.8438  \n",
      "\n",
      "Fold: 24  Epoch: 429  Training loss = 4.1554  Validation loss = 1.8434  \n",
      "\n",
      "Fold: 24  Epoch: 430  Training loss = 4.1551  Validation loss = 1.8431  \n",
      "\n",
      "Fold: 24  Epoch: 431  Training loss = 4.1548  Validation loss = 1.8428  \n",
      "\n",
      "Fold: 24  Epoch: 432  Training loss = 4.1546  Validation loss = 1.8426  \n",
      "\n",
      "Fold: 24  Epoch: 433  Training loss = 4.1543  Validation loss = 1.8423  \n",
      "\n",
      "Fold: 24  Epoch: 434  Training loss = 4.1540  Validation loss = 1.8420  \n",
      "\n",
      "Fold: 24  Epoch: 435  Training loss = 4.1538  Validation loss = 1.8417  \n",
      "\n",
      "Fold: 24  Epoch: 436  Training loss = 4.1535  Validation loss = 1.8413  \n",
      "\n",
      "Fold: 24  Epoch: 437  Training loss = 4.1531  Validation loss = 1.8409  \n",
      "\n",
      "Fold: 24  Epoch: 438  Training loss = 4.1528  Validation loss = 1.8407  \n",
      "\n",
      "Fold: 24  Epoch: 439  Training loss = 4.1525  Validation loss = 1.8403  \n",
      "\n",
      "Fold: 24  Epoch: 440  Training loss = 4.1521  Validation loss = 1.8399  \n",
      "\n",
      "Fold: 24  Epoch: 441  Training loss = 4.1518  Validation loss = 1.8396  \n",
      "\n",
      "Fold: 24  Epoch: 442  Training loss = 4.1515  Validation loss = 1.8392  \n",
      "\n",
      "Fold: 24  Epoch: 443  Training loss = 4.1511  Validation loss = 1.8389  \n",
      "\n",
      "Fold: 24  Epoch: 444  Training loss = 4.1509  Validation loss = 1.8386  \n",
      "\n",
      "Fold: 24  Epoch: 445  Training loss = 4.1505  Validation loss = 1.8382  \n",
      "\n",
      "Fold: 24  Epoch: 446  Training loss = 4.1501  Validation loss = 1.8378  \n",
      "\n",
      "Fold: 24  Epoch: 447  Training loss = 4.1499  Validation loss = 1.8375  \n",
      "\n",
      "Fold: 24  Epoch: 448  Training loss = 4.1496  Validation loss = 1.8372  \n",
      "\n",
      "Fold: 24  Epoch: 449  Training loss = 4.1493  Validation loss = 1.8369  \n",
      "\n",
      "Fold: 24  Epoch: 450  Training loss = 4.1491  Validation loss = 1.8368  \n",
      "\n",
      "Fold: 24  Epoch: 451  Training loss = 4.1488  Validation loss = 1.8364  \n",
      "\n",
      "Fold: 24  Epoch: 452  Training loss = 4.1485  Validation loss = 1.8361  \n",
      "\n",
      "Fold: 24  Epoch: 453  Training loss = 4.1482  Validation loss = 1.8357  \n",
      "\n",
      "Fold: 24  Epoch: 454  Training loss = 4.1479  Validation loss = 1.8354  \n",
      "\n",
      "Fold: 24  Epoch: 455  Training loss = 4.1476  Validation loss = 1.8351  \n",
      "\n",
      "Fold: 24  Epoch: 456  Training loss = 4.1473  Validation loss = 1.8348  \n",
      "\n",
      "Fold: 24  Epoch: 457  Training loss = 4.1470  Validation loss = 1.8344  \n",
      "\n",
      "Fold: 24  Epoch: 458  Training loss = 4.1466  Validation loss = 1.8340  \n",
      "\n",
      "Fold: 24  Epoch: 459  Training loss = 4.1463  Validation loss = 1.8338  \n",
      "\n",
      "Fold: 24  Epoch: 460  Training loss = 4.1460  Validation loss = 1.8334  \n",
      "\n",
      "Fold: 24  Epoch: 461  Training loss = 4.1458  Validation loss = 1.8331  \n",
      "\n",
      "Fold: 24  Epoch: 462  Training loss = 4.1455  Validation loss = 1.8328  \n",
      "\n",
      "Fold: 24  Epoch: 463  Training loss = 4.1452  Validation loss = 1.8325  \n",
      "\n",
      "Fold: 24  Epoch: 464  Training loss = 4.1449  Validation loss = 1.8322  \n",
      "\n",
      "Fold: 24  Epoch: 465  Training loss = 4.1447  Validation loss = 1.8319  \n",
      "\n",
      "Fold: 24  Epoch: 466  Training loss = 4.1443  Validation loss = 1.8315  \n",
      "\n",
      "Fold: 24  Epoch: 467  Training loss = 4.1441  Validation loss = 1.8313  \n",
      "\n",
      "Fold: 24  Epoch: 468  Training loss = 4.1438  Validation loss = 1.8309  \n",
      "\n",
      "Fold: 24  Epoch: 469  Training loss = 4.1435  Validation loss = 1.8306  \n",
      "\n",
      "Fold: 24  Epoch: 470  Training loss = 4.1432  Validation loss = 1.8303  \n",
      "\n",
      "Fold: 24  Epoch: 471  Training loss = 4.1429  Validation loss = 1.8300  \n",
      "\n",
      "Fold: 24  Epoch: 472  Training loss = 4.1426  Validation loss = 1.8297  \n",
      "\n",
      "Fold: 24  Epoch: 473  Training loss = 4.1424  Validation loss = 1.8294  \n",
      "\n",
      "Fold: 24  Epoch: 474  Training loss = 4.1421  Validation loss = 1.8291  \n",
      "\n",
      "Fold: 24  Epoch: 475  Training loss = 4.1418  Validation loss = 1.8288  \n",
      "\n",
      "Fold: 24  Epoch: 476  Training loss = 4.1417  Validation loss = 1.8286  \n",
      "\n",
      "Fold: 24  Epoch: 477  Training loss = 4.1413  Validation loss = 1.8283  \n",
      "\n",
      "Fold: 24  Epoch: 478  Training loss = 4.1410  Validation loss = 1.8280  \n",
      "\n",
      "Fold: 24  Epoch: 479  Training loss = 4.1406  Validation loss = 1.8276  \n",
      "\n",
      "Fold: 24  Epoch: 480  Training loss = 4.1403  Validation loss = 1.8273  \n",
      "\n",
      "Fold: 24  Epoch: 481  Training loss = 4.1399  Validation loss = 1.8269  \n",
      "\n",
      "Fold: 24  Epoch: 482  Training loss = 4.1395  Validation loss = 1.8264  \n",
      "\n",
      "Fold: 24  Epoch: 483  Training loss = 4.1392  Validation loss = 1.8261  \n",
      "\n",
      "Fold: 24  Epoch: 484  Training loss = 4.1388  Validation loss = 1.8256  \n",
      "\n",
      "Fold: 24  Epoch: 485  Training loss = 4.1385  Validation loss = 1.8253  \n",
      "\n",
      "Fold: 24  Epoch: 486  Training loss = 4.1382  Validation loss = 1.8250  \n",
      "\n",
      "Fold: 24  Epoch: 487  Training loss = 4.1379  Validation loss = 1.8247  \n",
      "\n",
      "Fold: 24  Epoch: 488  Training loss = 4.1376  Validation loss = 1.8243  \n",
      "\n",
      "Fold: 24  Epoch: 489  Training loss = 4.1373  Validation loss = 1.8240  \n",
      "\n",
      "Fold: 24  Epoch: 490  Training loss = 4.1369  Validation loss = 1.8236  \n",
      "\n",
      "Fold: 24  Epoch: 491  Training loss = 4.1366  Validation loss = 1.8232  \n",
      "\n",
      "Fold: 24  Epoch: 492  Training loss = 4.1363  Validation loss = 1.8228  \n",
      "\n",
      "Fold: 24  Epoch: 493  Training loss = 4.1360  Validation loss = 1.8225  \n",
      "\n",
      "Fold: 24  Epoch: 494  Training loss = 4.1357  Validation loss = 1.8221  \n",
      "\n",
      "Fold: 24  Epoch: 495  Training loss = 4.1355  Validation loss = 1.8219  \n",
      "\n",
      "Fold: 24  Epoch: 496  Training loss = 4.1353  Validation loss = 1.8218  \n",
      "\n",
      "Fold: 24  Epoch: 497  Training loss = 4.1350  Validation loss = 1.8214  \n",
      "\n",
      "Fold: 24  Epoch: 498  Training loss = 4.1346  Validation loss = 1.8209  \n",
      "\n",
      "Fold: 24  Epoch: 499  Training loss = 4.1343  Validation loss = 1.8207  \n",
      "\n",
      "Fold: 24  Epoch: 500  Training loss = 4.1340  Validation loss = 1.8203  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 500  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 4.0893  Validation loss = 2.6694  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 4.0890  Validation loss = 2.6691  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 4.0887  Validation loss = 2.6688  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 4.0885  Validation loss = 2.6686  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 4.0882  Validation loss = 2.6683  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 4.0879  Validation loss = 2.6681  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 4.0878  Validation loss = 2.6680  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 4.0876  Validation loss = 2.6678  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 4.0874  Validation loss = 2.6676  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 4.0870  Validation loss = 2.6672  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 4.0867  Validation loss = 2.6669  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 4.0865  Validation loss = 2.6666  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 4.0861  Validation loss = 2.6663  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 4.0858  Validation loss = 2.6660  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 4.0855  Validation loss = 2.6656  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 4.0851  Validation loss = 2.6653  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 4.0849  Validation loss = 2.6651  \n",
      "\n",
      "Fold: 25  Epoch: 18  Training loss = 4.0846  Validation loss = 2.6648  \n",
      "\n",
      "Fold: 25  Epoch: 19  Training loss = 4.0843  Validation loss = 2.6645  \n",
      "\n",
      "Fold: 25  Epoch: 20  Training loss = 4.0839  Validation loss = 2.6642  \n",
      "\n",
      "Fold: 25  Epoch: 21  Training loss = 4.0836  Validation loss = 2.6639  \n",
      "\n",
      "Fold: 25  Epoch: 22  Training loss = 4.0834  Validation loss = 2.6636  \n",
      "\n",
      "Fold: 25  Epoch: 23  Training loss = 4.0831  Validation loss = 2.6634  \n",
      "\n",
      "Fold: 25  Epoch: 24  Training loss = 4.0828  Validation loss = 2.6631  \n",
      "\n",
      "Fold: 25  Epoch: 25  Training loss = 4.0825  Validation loss = 2.6628  \n",
      "\n",
      "Fold: 25  Epoch: 26  Training loss = 4.0822  Validation loss = 2.6625  \n",
      "\n",
      "Fold: 25  Epoch: 27  Training loss = 4.0819  Validation loss = 2.6623  \n",
      "\n",
      "Fold: 25  Epoch: 28  Training loss = 4.0816  Validation loss = 2.6620  \n",
      "\n",
      "Fold: 25  Epoch: 29  Training loss = 4.0813  Validation loss = 2.6617  \n",
      "\n",
      "Fold: 25  Epoch: 30  Training loss = 4.0810  Validation loss = 2.6614  \n",
      "\n",
      "Fold: 25  Epoch: 31  Training loss = 4.0808  Validation loss = 2.6611  \n",
      "\n",
      "Fold: 25  Epoch: 32  Training loss = 4.0805  Validation loss = 2.6608  \n",
      "\n",
      "Fold: 25  Epoch: 33  Training loss = 4.0801  Validation loss = 2.6605  \n",
      "\n",
      "Fold: 25  Epoch: 34  Training loss = 4.0799  Validation loss = 2.6602  \n",
      "\n",
      "Fold: 25  Epoch: 35  Training loss = 4.0795  Validation loss = 2.6599  \n",
      "\n",
      "Fold: 25  Epoch: 36  Training loss = 4.0792  Validation loss = 2.6597  \n",
      "\n",
      "Fold: 25  Epoch: 37  Training loss = 4.0790  Validation loss = 2.6594  \n",
      "\n",
      "Fold: 25  Epoch: 38  Training loss = 4.0787  Validation loss = 2.6591  \n",
      "\n",
      "Fold: 25  Epoch: 39  Training loss = 4.0784  Validation loss = 2.6588  \n",
      "\n",
      "Fold: 25  Epoch: 40  Training loss = 4.0781  Validation loss = 2.6585  \n",
      "\n",
      "Fold: 25  Epoch: 41  Training loss = 4.0778  Validation loss = 2.6582  \n",
      "\n",
      "Fold: 25  Epoch: 42  Training loss = 4.0776  Validation loss = 2.6580  \n",
      "\n",
      "Fold: 25  Epoch: 43  Training loss = 4.0773  Validation loss = 2.6577  \n",
      "\n",
      "Fold: 25  Epoch: 44  Training loss = 4.0770  Validation loss = 2.6574  \n",
      "\n",
      "Fold: 25  Epoch: 45  Training loss = 4.0767  Validation loss = 2.6571  \n",
      "\n",
      "Fold: 25  Epoch: 46  Training loss = 4.0765  Validation loss = 2.6569  \n",
      "\n",
      "Fold: 25  Epoch: 47  Training loss = 4.0761  Validation loss = 2.6566  \n",
      "\n",
      "Fold: 25  Epoch: 48  Training loss = 4.0759  Validation loss = 2.6563  \n",
      "\n",
      "Fold: 25  Epoch: 49  Training loss = 4.0756  Validation loss = 2.6561  \n",
      "\n",
      "Fold: 25  Epoch: 50  Training loss = 4.0754  Validation loss = 2.6558  \n",
      "\n",
      "Fold: 25  Epoch: 51  Training loss = 4.0752  Validation loss = 2.6556  \n",
      "\n",
      "Fold: 25  Epoch: 52  Training loss = 4.0749  Validation loss = 2.6554  \n",
      "\n",
      "Fold: 25  Epoch: 53  Training loss = 4.0747  Validation loss = 2.6552  \n",
      "\n",
      "Fold: 25  Epoch: 54  Training loss = 4.0743  Validation loss = 2.6548  \n",
      "\n",
      "Fold: 25  Epoch: 55  Training loss = 4.0741  Validation loss = 2.6546  \n",
      "\n",
      "Fold: 25  Epoch: 56  Training loss = 4.0739  Validation loss = 2.6544  \n",
      "\n",
      "Fold: 25  Epoch: 57  Training loss = 4.0737  Validation loss = 2.6543  \n",
      "\n",
      "Fold: 25  Epoch: 58  Training loss = 4.0734  Validation loss = 2.6540  \n",
      "\n",
      "Fold: 25  Epoch: 59  Training loss = 4.0731  Validation loss = 2.6537  \n",
      "\n",
      "Fold: 25  Epoch: 60  Training loss = 4.0728  Validation loss = 2.6534  \n",
      "\n",
      "Fold: 25  Epoch: 61  Training loss = 4.0726  Validation loss = 2.6532  \n",
      "\n",
      "Fold: 25  Epoch: 62  Training loss = 4.0724  Validation loss = 2.6530  \n",
      "\n",
      "Fold: 25  Epoch: 63  Training loss = 4.0721  Validation loss = 2.6527  \n",
      "\n",
      "Fold: 25  Epoch: 64  Training loss = 4.0718  Validation loss = 2.6524  \n",
      "\n",
      "Fold: 25  Epoch: 65  Training loss = 4.0715  Validation loss = 2.6522  \n",
      "\n",
      "Fold: 25  Epoch: 66  Training loss = 4.0712  Validation loss = 2.6519  \n",
      "\n",
      "Fold: 25  Epoch: 67  Training loss = 4.0709  Validation loss = 2.6516  \n",
      "\n",
      "Fold: 25  Epoch: 68  Training loss = 4.0707  Validation loss = 2.6514  \n",
      "\n",
      "Fold: 25  Epoch: 69  Training loss = 4.0704  Validation loss = 2.6511  \n",
      "\n",
      "Fold: 25  Epoch: 70  Training loss = 4.0701  Validation loss = 2.6508  \n",
      "\n",
      "Fold: 25  Epoch: 71  Training loss = 4.0698  Validation loss = 2.6505  \n",
      "\n",
      "Fold: 25  Epoch: 72  Training loss = 4.0696  Validation loss = 2.6503  \n",
      "\n",
      "Fold: 25  Epoch: 73  Training loss = 4.0693  Validation loss = 2.6501  \n",
      "\n",
      "Fold: 25  Epoch: 74  Training loss = 4.0690  Validation loss = 2.6498  \n",
      "\n",
      "Fold: 25  Epoch: 75  Training loss = 4.0688  Validation loss = 2.6495  \n",
      "\n",
      "Fold: 25  Epoch: 76  Training loss = 4.0685  Validation loss = 2.6493  \n",
      "\n",
      "Fold: 25  Epoch: 77  Training loss = 4.0682  Validation loss = 2.6490  \n",
      "\n",
      "Fold: 25  Epoch: 78  Training loss = 4.0680  Validation loss = 2.6488  \n",
      "\n",
      "Fold: 25  Epoch: 79  Training loss = 4.0678  Validation loss = 2.6486  \n",
      "\n",
      "Fold: 25  Epoch: 80  Training loss = 4.0676  Validation loss = 2.6484  \n",
      "\n",
      "Fold: 25  Epoch: 81  Training loss = 4.0673  Validation loss = 2.6482  \n",
      "\n",
      "Fold: 25  Epoch: 82  Training loss = 4.0671  Validation loss = 2.6479  \n",
      "\n",
      "Fold: 25  Epoch: 83  Training loss = 4.0669  Validation loss = 2.6477  \n",
      "\n",
      "Fold: 25  Epoch: 84  Training loss = 4.0666  Validation loss = 2.6475  \n",
      "\n",
      "Fold: 25  Epoch: 85  Training loss = 4.0664  Validation loss = 2.6473  \n",
      "\n",
      "Fold: 25  Epoch: 86  Training loss = 4.0662  Validation loss = 2.6472  \n",
      "\n",
      "Fold: 25  Epoch: 87  Training loss = 4.0660  Validation loss = 2.6469  \n",
      "\n",
      "Fold: 25  Epoch: 88  Training loss = 4.0657  Validation loss = 2.6466  \n",
      "\n",
      "Fold: 25  Epoch: 89  Training loss = 4.0654  Validation loss = 2.6464  \n",
      "\n",
      "Fold: 25  Epoch: 90  Training loss = 4.0652  Validation loss = 2.6461  \n",
      "\n",
      "Fold: 25  Epoch: 91  Training loss = 4.0649  Validation loss = 2.6459  \n",
      "\n",
      "Fold: 25  Epoch: 92  Training loss = 4.0647  Validation loss = 2.6457  \n",
      "\n",
      "Fold: 25  Epoch: 93  Training loss = 4.0644  Validation loss = 2.6454  \n",
      "\n",
      "Fold: 25  Epoch: 94  Training loss = 4.0640  Validation loss = 2.6451  \n",
      "\n",
      "Fold: 25  Epoch: 95  Training loss = 4.0638  Validation loss = 2.6448  \n",
      "\n",
      "Fold: 25  Epoch: 96  Training loss = 4.0635  Validation loss = 2.6446  \n",
      "\n",
      "Fold: 25  Epoch: 97  Training loss = 4.0633  Validation loss = 2.6444  \n",
      "\n",
      "Fold: 25  Epoch: 98  Training loss = 4.0629  Validation loss = 2.6441  \n",
      "\n",
      "Fold: 25  Epoch: 99  Training loss = 4.0626  Validation loss = 2.6438  \n",
      "\n",
      "Fold: 25  Epoch: 100  Training loss = 4.0623  Validation loss = 2.6436  \n",
      "\n",
      "Fold: 25  Epoch: 101  Training loss = 4.0621  Validation loss = 2.6434  \n",
      "\n",
      "Fold: 25  Epoch: 102  Training loss = 4.0619  Validation loss = 2.6432  \n",
      "\n",
      "Fold: 25  Epoch: 103  Training loss = 4.0616  Validation loss = 2.6429  \n",
      "\n",
      "Fold: 25  Epoch: 104  Training loss = 4.0613  Validation loss = 2.6426  \n",
      "\n",
      "Fold: 25  Epoch: 105  Training loss = 4.0610  Validation loss = 2.6424  \n",
      "\n",
      "Fold: 25  Epoch: 106  Training loss = 4.0608  Validation loss = 2.6421  \n",
      "\n",
      "Fold: 25  Epoch: 107  Training loss = 4.0604  Validation loss = 2.6418  \n",
      "\n",
      "Fold: 25  Epoch: 108  Training loss = 4.0601  Validation loss = 2.6415  \n",
      "\n",
      "Fold: 25  Epoch: 109  Training loss = 4.0598  Validation loss = 2.6413  \n",
      "\n",
      "Fold: 25  Epoch: 110  Training loss = 4.0595  Validation loss = 2.6409  \n",
      "\n",
      "Fold: 25  Epoch: 111  Training loss = 4.0593  Validation loss = 2.6406  \n",
      "\n",
      "Fold: 25  Epoch: 112  Training loss = 4.0589  Validation loss = 2.6403  \n",
      "\n",
      "Fold: 25  Epoch: 113  Training loss = 4.0586  Validation loss = 2.6400  \n",
      "\n",
      "Fold: 25  Epoch: 114  Training loss = 4.0583  Validation loss = 2.6397  \n",
      "\n",
      "Fold: 25  Epoch: 115  Training loss = 4.0581  Validation loss = 2.6395  \n",
      "\n",
      "Fold: 25  Epoch: 116  Training loss = 4.0577  Validation loss = 2.6392  \n",
      "\n",
      "Fold: 25  Epoch: 117  Training loss = 4.0575  Validation loss = 2.6390  \n",
      "\n",
      "Fold: 25  Epoch: 118  Training loss = 4.0572  Validation loss = 2.6388  \n",
      "\n",
      "Fold: 25  Epoch: 119  Training loss = 4.0569  Validation loss = 2.6385  \n",
      "\n",
      "Fold: 25  Epoch: 120  Training loss = 4.0566  Validation loss = 2.6382  \n",
      "\n",
      "Fold: 25  Epoch: 121  Training loss = 4.0563  Validation loss = 2.6381  \n",
      "\n",
      "Fold: 25  Epoch: 122  Training loss = 4.0561  Validation loss = 2.6379  \n",
      "\n",
      "Fold: 25  Epoch: 123  Training loss = 4.0559  Validation loss = 2.6377  \n",
      "\n",
      "Fold: 25  Epoch: 124  Training loss = 4.0556  Validation loss = 2.6374  \n",
      "\n",
      "Fold: 25  Epoch: 125  Training loss = 4.0553  Validation loss = 2.6371  \n",
      "\n",
      "Fold: 25  Epoch: 126  Training loss = 4.0551  Validation loss = 2.6369  \n",
      "\n",
      "Fold: 25  Epoch: 127  Training loss = 4.0549  Validation loss = 2.6367  \n",
      "\n",
      "Fold: 25  Epoch: 128  Training loss = 4.0547  Validation loss = 2.6365  \n",
      "\n",
      "Fold: 25  Epoch: 129  Training loss = 4.0544  Validation loss = 2.6363  \n",
      "\n",
      "Fold: 25  Epoch: 130  Training loss = 4.0541  Validation loss = 2.6360  \n",
      "\n",
      "Fold: 25  Epoch: 131  Training loss = 4.0539  Validation loss = 2.6358  \n",
      "\n",
      "Fold: 25  Epoch: 132  Training loss = 4.0537  Validation loss = 2.6357  \n",
      "\n",
      "Fold: 25  Epoch: 133  Training loss = 4.0534  Validation loss = 2.6355  \n",
      "\n",
      "Fold: 25  Epoch: 134  Training loss = 4.0532  Validation loss = 2.6353  \n",
      "\n",
      "Fold: 25  Epoch: 135  Training loss = 4.0530  Validation loss = 2.6351  \n",
      "\n",
      "Fold: 25  Epoch: 136  Training loss = 4.0527  Validation loss = 2.6348  \n",
      "\n",
      "Fold: 25  Epoch: 137  Training loss = 4.0526  Validation loss = 2.6347  \n",
      "\n",
      "Fold: 25  Epoch: 138  Training loss = 4.0523  Validation loss = 2.6345  \n",
      "\n",
      "Fold: 25  Epoch: 139  Training loss = 4.0521  Validation loss = 2.6343  \n",
      "\n",
      "Fold: 25  Epoch: 140  Training loss = 4.0518  Validation loss = 2.6341  \n",
      "\n",
      "Fold: 25  Epoch: 141  Training loss = 4.0516  Validation loss = 2.6339  \n",
      "\n",
      "Fold: 25  Epoch: 142  Training loss = 4.0513  Validation loss = 2.6336  \n",
      "\n",
      "Fold: 25  Epoch: 143  Training loss = 4.0510  Validation loss = 2.6334  \n",
      "\n",
      "Fold: 25  Epoch: 144  Training loss = 4.0508  Validation loss = 2.6331  \n",
      "\n",
      "Fold: 25  Epoch: 145  Training loss = 4.0505  Validation loss = 2.6328  \n",
      "\n",
      "Fold: 25  Epoch: 146  Training loss = 4.0501  Validation loss = 2.6326  \n",
      "\n",
      "Fold: 25  Epoch: 147  Training loss = 4.0499  Validation loss = 2.6323  \n",
      "\n",
      "Fold: 25  Epoch: 148  Training loss = 4.0496  Validation loss = 2.6319  \n",
      "\n",
      "Fold: 25  Epoch: 149  Training loss = 4.0492  Validation loss = 2.6317  \n",
      "\n",
      "Fold: 25  Epoch: 150  Training loss = 4.0490  Validation loss = 2.6314  \n",
      "\n",
      "Fold: 25  Epoch: 151  Training loss = 4.0489  Validation loss = 2.6313  \n",
      "\n",
      "Fold: 25  Epoch: 152  Training loss = 4.0487  Validation loss = 2.6312  \n",
      "\n",
      "Fold: 25  Epoch: 153  Training loss = 4.0484  Validation loss = 2.6309  \n",
      "\n",
      "Fold: 25  Epoch: 154  Training loss = 4.0481  Validation loss = 2.6306  \n",
      "\n",
      "Fold: 25  Epoch: 155  Training loss = 4.0478  Validation loss = 2.6304  \n",
      "\n",
      "Fold: 25  Epoch: 156  Training loss = 4.0476  Validation loss = 2.6302  \n",
      "\n",
      "Fold: 25  Epoch: 157  Training loss = 4.0474  Validation loss = 2.6300  \n",
      "\n",
      "Fold: 25  Epoch: 158  Training loss = 4.0472  Validation loss = 2.6298  \n",
      "\n",
      "Fold: 25  Epoch: 159  Training loss = 4.0468  Validation loss = 2.6294  \n",
      "\n",
      "Fold: 25  Epoch: 160  Training loss = 4.0466  Validation loss = 2.6291  \n",
      "\n",
      "Fold: 25  Epoch: 161  Training loss = 4.0463  Validation loss = 2.6288  \n",
      "\n",
      "Fold: 25  Epoch: 162  Training loss = 4.0461  Validation loss = 2.6286  \n",
      "\n",
      "Fold: 25  Epoch: 163  Training loss = 4.0458  Validation loss = 2.6283  \n",
      "\n",
      "Fold: 25  Epoch: 164  Training loss = 4.0455  Validation loss = 2.6280  \n",
      "\n",
      "Fold: 25  Epoch: 165  Training loss = 4.0452  Validation loss = 2.6277  \n",
      "\n",
      "Fold: 25  Epoch: 166  Training loss = 4.0449  Validation loss = 2.6275  \n",
      "\n",
      "Fold: 25  Epoch: 167  Training loss = 4.0447  Validation loss = 2.6273  \n",
      "\n",
      "Fold: 25  Epoch: 168  Training loss = 4.0445  Validation loss = 2.6271  \n",
      "\n",
      "Fold: 25  Epoch: 169  Training loss = 4.0443  Validation loss = 2.6269  \n",
      "\n",
      "Fold: 25  Epoch: 170  Training loss = 4.0440  Validation loss = 2.6267  \n",
      "\n",
      "Fold: 25  Epoch: 171  Training loss = 4.0437  Validation loss = 2.6265  \n",
      "\n",
      "Fold: 25  Epoch: 172  Training loss = 4.0434  Validation loss = 2.6262  \n",
      "\n",
      "Fold: 25  Epoch: 173  Training loss = 4.0431  Validation loss = 2.6260  \n",
      "\n",
      "Fold: 25  Epoch: 174  Training loss = 4.0428  Validation loss = 2.6257  \n",
      "\n",
      "Fold: 25  Epoch: 175  Training loss = 4.0426  Validation loss = 2.6255  \n",
      "\n",
      "Fold: 25  Epoch: 176  Training loss = 4.0423  Validation loss = 2.6253  \n",
      "\n",
      "Fold: 25  Epoch: 177  Training loss = 4.0421  Validation loss = 2.6250  \n",
      "\n",
      "Fold: 25  Epoch: 178  Training loss = 4.0419  Validation loss = 2.6248  \n",
      "\n",
      "Fold: 25  Epoch: 179  Training loss = 4.0416  Validation loss = 2.6245  \n",
      "\n",
      "Fold: 25  Epoch: 180  Training loss = 4.0412  Validation loss = 2.6242  \n",
      "\n",
      "Fold: 25  Epoch: 181  Training loss = 4.0410  Validation loss = 2.6239  \n",
      "\n",
      "Fold: 25  Epoch: 182  Training loss = 4.0407  Validation loss = 2.6236  \n",
      "\n",
      "Fold: 25  Epoch: 183  Training loss = 4.0404  Validation loss = 2.6234  \n",
      "\n",
      "Fold: 25  Epoch: 184  Training loss = 4.0401  Validation loss = 2.6231  \n",
      "\n",
      "Fold: 25  Epoch: 185  Training loss = 4.0399  Validation loss = 2.6229  \n",
      "\n",
      "Fold: 25  Epoch: 186  Training loss = 4.0396  Validation loss = 2.6226  \n",
      "\n",
      "Fold: 25  Epoch: 187  Training loss = 4.0392  Validation loss = 2.6222  \n",
      "\n",
      "Fold: 25  Epoch: 188  Training loss = 4.0388  Validation loss = 2.6218  \n",
      "\n",
      "Fold: 25  Epoch: 189  Training loss = 4.0385  Validation loss = 2.6215  \n",
      "\n",
      "Fold: 25  Epoch: 190  Training loss = 4.0382  Validation loss = 2.6213  \n",
      "\n",
      "Fold: 25  Epoch: 191  Training loss = 4.0380  Validation loss = 2.6211  \n",
      "\n",
      "Fold: 25  Epoch: 192  Training loss = 4.0378  Validation loss = 2.6208  \n",
      "\n",
      "Fold: 25  Epoch: 193  Training loss = 4.0375  Validation loss = 2.6206  \n",
      "\n",
      "Fold: 25  Epoch: 194  Training loss = 4.0372  Validation loss = 2.6203  \n",
      "\n",
      "Fold: 25  Epoch: 195  Training loss = 4.0370  Validation loss = 2.6200  \n",
      "\n",
      "Fold: 25  Epoch: 196  Training loss = 4.0367  Validation loss = 2.6197  \n",
      "\n",
      "Fold: 25  Epoch: 197  Training loss = 4.0364  Validation loss = 2.6195  \n",
      "\n",
      "Fold: 25  Epoch: 198  Training loss = 4.0361  Validation loss = 2.6193  \n",
      "\n",
      "Fold: 25  Epoch: 199  Training loss = 4.0360  Validation loss = 2.6192  \n",
      "\n",
      "Fold: 25  Epoch: 200  Training loss = 4.0356  Validation loss = 2.6188  \n",
      "\n",
      "Fold: 25  Epoch: 201  Training loss = 4.0353  Validation loss = 2.6185  \n",
      "\n",
      "Fold: 25  Epoch: 202  Training loss = 4.0351  Validation loss = 2.6184  \n",
      "\n",
      "Fold: 25  Epoch: 203  Training loss = 4.0349  Validation loss = 2.6182  \n",
      "\n",
      "Fold: 25  Epoch: 204  Training loss = 4.0346  Validation loss = 2.6180  \n",
      "\n",
      "Fold: 25  Epoch: 205  Training loss = 4.0342  Validation loss = 2.6176  \n",
      "\n",
      "Fold: 25  Epoch: 206  Training loss = 4.0340  Validation loss = 2.6174  \n",
      "\n",
      "Fold: 25  Epoch: 207  Training loss = 4.0336  Validation loss = 2.6171  \n",
      "\n",
      "Fold: 25  Epoch: 208  Training loss = 4.0333  Validation loss = 2.6168  \n",
      "\n",
      "Fold: 25  Epoch: 209  Training loss = 4.0331  Validation loss = 2.6165  \n",
      "\n",
      "Fold: 25  Epoch: 210  Training loss = 4.0328  Validation loss = 2.6162  \n",
      "\n",
      "Fold: 25  Epoch: 211  Training loss = 4.0325  Validation loss = 2.6159  \n",
      "\n",
      "Fold: 25  Epoch: 212  Training loss = 4.0322  Validation loss = 2.6156  \n",
      "\n",
      "Fold: 25  Epoch: 213  Training loss = 4.0319  Validation loss = 2.6153  \n",
      "\n",
      "Fold: 25  Epoch: 214  Training loss = 4.0315  Validation loss = 2.6149  \n",
      "\n",
      "Fold: 25  Epoch: 215  Training loss = 4.0312  Validation loss = 2.6147  \n",
      "\n",
      "Fold: 25  Epoch: 216  Training loss = 4.0309  Validation loss = 2.6144  \n",
      "\n",
      "Fold: 25  Epoch: 217  Training loss = 4.0306  Validation loss = 2.6141  \n",
      "\n",
      "Fold: 25  Epoch: 218  Training loss = 4.0304  Validation loss = 2.6139  \n",
      "\n",
      "Fold: 25  Epoch: 219  Training loss = 4.0301  Validation loss = 2.6137  \n",
      "\n",
      "Fold: 25  Epoch: 220  Training loss = 4.0298  Validation loss = 2.6134  \n",
      "\n",
      "Fold: 25  Epoch: 221  Training loss = 4.0295  Validation loss = 2.6132  \n",
      "\n",
      "Fold: 25  Epoch: 222  Training loss = 4.0292  Validation loss = 2.6129  \n",
      "\n",
      "Fold: 25  Epoch: 223  Training loss = 4.0289  Validation loss = 2.6126  \n",
      "\n",
      "Fold: 25  Epoch: 224  Training loss = 4.0285  Validation loss = 2.6123  \n",
      "\n",
      "Fold: 25  Epoch: 225  Training loss = 4.0284  Validation loss = 2.6122  \n",
      "\n",
      "Fold: 25  Epoch: 226  Training loss = 4.0280  Validation loss = 2.6119  \n",
      "\n",
      "Fold: 25  Epoch: 227  Training loss = 4.0278  Validation loss = 2.6116  \n",
      "\n",
      "Fold: 25  Epoch: 228  Training loss = 4.0275  Validation loss = 2.6114  \n",
      "\n",
      "Fold: 25  Epoch: 229  Training loss = 4.0272  Validation loss = 2.6110  \n",
      "\n",
      "Fold: 25  Epoch: 230  Training loss = 4.0269  Validation loss = 2.6107  \n",
      "\n",
      "Fold: 25  Epoch: 231  Training loss = 4.0266  Validation loss = 2.6104  \n",
      "\n",
      "Fold: 25  Epoch: 232  Training loss = 4.0263  Validation loss = 2.6103  \n",
      "\n",
      "Fold: 25  Epoch: 233  Training loss = 4.0261  Validation loss = 2.6099  \n",
      "\n",
      "Fold: 25  Epoch: 234  Training loss = 4.0259  Validation loss = 2.6098  \n",
      "\n",
      "Fold: 25  Epoch: 235  Training loss = 4.0256  Validation loss = 2.6096  \n",
      "\n",
      "Fold: 25  Epoch: 236  Training loss = 4.0253  Validation loss = 2.6093  \n",
      "\n",
      "Fold: 25  Epoch: 237  Training loss = 4.0250  Validation loss = 2.6091  \n",
      "\n",
      "Fold: 25  Epoch: 238  Training loss = 4.0247  Validation loss = 2.6089  \n",
      "\n",
      "Fold: 25  Epoch: 239  Training loss = 4.0244  Validation loss = 2.6086  \n",
      "\n",
      "Fold: 25  Epoch: 240  Training loss = 4.0241  Validation loss = 2.6084  \n",
      "\n",
      "Fold: 25  Epoch: 241  Training loss = 4.0239  Validation loss = 2.6082  \n",
      "\n",
      "Fold: 25  Epoch: 242  Training loss = 4.0237  Validation loss = 2.6080  \n",
      "\n",
      "Fold: 25  Epoch: 243  Training loss = 4.0235  Validation loss = 2.6079  \n",
      "\n",
      "Fold: 25  Epoch: 244  Training loss = 4.0233  Validation loss = 2.6077  \n",
      "\n",
      "Fold: 25  Epoch: 245  Training loss = 4.0231  Validation loss = 2.6075  \n",
      "\n",
      "Fold: 25  Epoch: 246  Training loss = 4.0229  Validation loss = 2.6074  \n",
      "\n",
      "Fold: 25  Epoch: 247  Training loss = 4.0226  Validation loss = 2.6071  \n",
      "\n",
      "Fold: 25  Epoch: 248  Training loss = 4.0224  Validation loss = 2.6070  \n",
      "\n",
      "Fold: 25  Epoch: 249  Training loss = 4.0221  Validation loss = 2.6067  \n",
      "\n",
      "Fold: 25  Epoch: 250  Training loss = 4.0218  Validation loss = 2.6065  \n",
      "\n",
      "Fold: 25  Epoch: 251  Training loss = 4.0216  Validation loss = 2.6063  \n",
      "\n",
      "Fold: 25  Epoch: 252  Training loss = 4.0213  Validation loss = 2.6061  \n",
      "\n",
      "Fold: 25  Epoch: 253  Training loss = 4.0210  Validation loss = 2.6059  \n",
      "\n",
      "Fold: 25  Epoch: 254  Training loss = 4.0208  Validation loss = 2.6056  \n",
      "\n",
      "Fold: 25  Epoch: 255  Training loss = 4.0205  Validation loss = 2.6054  \n",
      "\n",
      "Fold: 25  Epoch: 256  Training loss = 4.0203  Validation loss = 2.6051  \n",
      "\n",
      "Fold: 25  Epoch: 257  Training loss = 4.0200  Validation loss = 2.6048  \n",
      "\n",
      "Fold: 25  Epoch: 258  Training loss = 4.0197  Validation loss = 2.6045  \n",
      "\n",
      "Fold: 25  Epoch: 259  Training loss = 4.0195  Validation loss = 2.6043  \n",
      "\n",
      "Fold: 25  Epoch: 260  Training loss = 4.0192  Validation loss = 2.6041  \n",
      "\n",
      "Fold: 25  Epoch: 261  Training loss = 4.0190  Validation loss = 2.6038  \n",
      "\n",
      "Fold: 25  Epoch: 262  Training loss = 4.0187  Validation loss = 2.6035  \n",
      "\n",
      "Fold: 25  Epoch: 263  Training loss = 4.0186  Validation loss = 2.6034  \n",
      "\n",
      "Fold: 25  Epoch: 264  Training loss = 4.0182  Validation loss = 2.6031  \n",
      "\n",
      "Fold: 25  Epoch: 265  Training loss = 4.0180  Validation loss = 2.6029  \n",
      "\n",
      "Fold: 25  Epoch: 266  Training loss = 4.0177  Validation loss = 2.6027  \n",
      "\n",
      "Fold: 25  Epoch: 267  Training loss = 4.0174  Validation loss = 2.6025  \n",
      "\n",
      "Fold: 25  Epoch: 268  Training loss = 4.0172  Validation loss = 2.6022  \n",
      "\n",
      "Fold: 25  Epoch: 269  Training loss = 4.0169  Validation loss = 2.6020  \n",
      "\n",
      "Fold: 25  Epoch: 270  Training loss = 4.0167  Validation loss = 2.6018  \n",
      "\n",
      "Fold: 25  Epoch: 271  Training loss = 4.0164  Validation loss = 2.6015  \n",
      "\n",
      "Fold: 25  Epoch: 272  Training loss = 4.0161  Validation loss = 2.6014  \n",
      "\n",
      "Fold: 25  Epoch: 273  Training loss = 4.0158  Validation loss = 2.6012  \n",
      "\n",
      "Fold: 25  Epoch: 274  Training loss = 4.0156  Validation loss = 2.6011  \n",
      "\n",
      "Fold: 25  Epoch: 275  Training loss = 4.0154  Validation loss = 2.6009  \n",
      "\n",
      "Fold: 25  Epoch: 276  Training loss = 4.0152  Validation loss = 2.6007  \n",
      "\n",
      "Fold: 25  Epoch: 277  Training loss = 4.0150  Validation loss = 2.6005  \n",
      "\n",
      "Fold: 25  Epoch: 278  Training loss = 4.0146  Validation loss = 2.6002  \n",
      "\n",
      "Fold: 25  Epoch: 279  Training loss = 4.0144  Validation loss = 2.6000  \n",
      "\n",
      "Fold: 25  Epoch: 280  Training loss = 4.0141  Validation loss = 2.5998  \n",
      "\n",
      "Fold: 25  Epoch: 281  Training loss = 4.0139  Validation loss = 2.5996  \n",
      "\n",
      "Fold: 25  Epoch: 282  Training loss = 4.0136  Validation loss = 2.5993  \n",
      "\n",
      "Fold: 25  Epoch: 283  Training loss = 4.0134  Validation loss = 2.5992  \n",
      "\n",
      "Fold: 25  Epoch: 284  Training loss = 4.0132  Validation loss = 2.5990  \n",
      "\n",
      "Fold: 25  Epoch: 285  Training loss = 4.0129  Validation loss = 2.5987  \n",
      "\n",
      "Fold: 25  Epoch: 286  Training loss = 4.0126  Validation loss = 2.5984  \n",
      "\n",
      "Fold: 25  Epoch: 287  Training loss = 4.0124  Validation loss = 2.5982  \n",
      "\n",
      "Fold: 25  Epoch: 288  Training loss = 4.0121  Validation loss = 2.5979  \n",
      "\n",
      "Fold: 25  Epoch: 289  Training loss = 4.0118  Validation loss = 2.5977  \n",
      "\n",
      "Fold: 25  Epoch: 290  Training loss = 4.0115  Validation loss = 2.5974  \n",
      "\n",
      "Fold: 25  Epoch: 291  Training loss = 4.0112  Validation loss = 2.5971  \n",
      "\n",
      "Fold: 25  Epoch: 292  Training loss = 4.0109  Validation loss = 2.5969  \n",
      "\n",
      "Fold: 25  Epoch: 293  Training loss = 4.0106  Validation loss = 2.5966  \n",
      "\n",
      "Fold: 25  Epoch: 294  Training loss = 4.0102  Validation loss = 2.5962  \n",
      "\n",
      "Fold: 25  Epoch: 295  Training loss = 4.0100  Validation loss = 2.5960  \n",
      "\n",
      "Fold: 25  Epoch: 296  Training loss = 4.0097  Validation loss = 2.5958  \n",
      "\n",
      "Fold: 25  Epoch: 297  Training loss = 4.0094  Validation loss = 2.5956  \n",
      "\n",
      "Fold: 25  Epoch: 298  Training loss = 4.0091  Validation loss = 2.5953  \n",
      "\n",
      "Fold: 25  Epoch: 299  Training loss = 4.0088  Validation loss = 2.5951  \n",
      "\n",
      "Fold: 25  Epoch: 300  Training loss = 4.0086  Validation loss = 2.5949  \n",
      "\n",
      "Fold: 25  Epoch: 301  Training loss = 4.0084  Validation loss = 2.5946  \n",
      "\n",
      "Fold: 25  Epoch: 302  Training loss = 4.0082  Validation loss = 2.5945  \n",
      "\n",
      "Fold: 25  Epoch: 303  Training loss = 4.0080  Validation loss = 2.5943  \n",
      "\n",
      "Fold: 25  Epoch: 304  Training loss = 4.0078  Validation loss = 2.5942  \n",
      "\n",
      "Fold: 25  Epoch: 305  Training loss = 4.0075  Validation loss = 2.5939  \n",
      "\n",
      "Fold: 25  Epoch: 306  Training loss = 4.0072  Validation loss = 2.5936  \n",
      "\n",
      "Fold: 25  Epoch: 307  Training loss = 4.0069  Validation loss = 2.5934  \n",
      "\n",
      "Fold: 25  Epoch: 308  Training loss = 4.0065  Validation loss = 2.5930  \n",
      "\n",
      "Fold: 25  Epoch: 309  Training loss = 4.0063  Validation loss = 2.5928  \n",
      "\n",
      "Fold: 25  Epoch: 310  Training loss = 4.0060  Validation loss = 2.5925  \n",
      "\n",
      "Fold: 25  Epoch: 311  Training loss = 4.0057  Validation loss = 2.5922  \n",
      "\n",
      "Fold: 25  Epoch: 312  Training loss = 4.0054  Validation loss = 2.5919  \n",
      "\n",
      "Fold: 25  Epoch: 313  Training loss = 4.0052  Validation loss = 2.5918  \n",
      "\n",
      "Fold: 25  Epoch: 314  Training loss = 4.0050  Validation loss = 2.5916  \n",
      "\n",
      "Fold: 25  Epoch: 315  Training loss = 4.0047  Validation loss = 2.5913  \n",
      "\n",
      "Fold: 25  Epoch: 316  Training loss = 4.0044  Validation loss = 2.5910  \n",
      "\n",
      "Fold: 25  Epoch: 317  Training loss = 4.0042  Validation loss = 2.5910  \n",
      "\n",
      "Fold: 25  Epoch: 318  Training loss = 4.0040  Validation loss = 2.5907  \n",
      "\n",
      "Fold: 25  Epoch: 319  Training loss = 4.0038  Validation loss = 2.5905  \n",
      "\n",
      "Fold: 25  Epoch: 320  Training loss = 4.0036  Validation loss = 2.5903  \n",
      "\n",
      "Fold: 25  Epoch: 321  Training loss = 4.0033  Validation loss = 2.5901  \n",
      "\n",
      "Fold: 25  Epoch: 322  Training loss = 4.0030  Validation loss = 2.5900  \n",
      "\n",
      "Fold: 25  Epoch: 323  Training loss = 4.0028  Validation loss = 2.5897  \n",
      "\n",
      "Fold: 25  Epoch: 324  Training loss = 4.0026  Validation loss = 2.5896  \n",
      "\n",
      "Fold: 25  Epoch: 325  Training loss = 4.0023  Validation loss = 2.5893  \n",
      "\n",
      "Fold: 25  Epoch: 326  Training loss = 4.0021  Validation loss = 2.5891  \n",
      "\n",
      "Fold: 25  Epoch: 327  Training loss = 4.0018  Validation loss = 2.5890  \n",
      "\n",
      "Fold: 25  Epoch: 328  Training loss = 4.0017  Validation loss = 2.5888  \n",
      "\n",
      "Fold: 25  Epoch: 329  Training loss = 4.0013  Validation loss = 2.5884  \n",
      "\n",
      "Fold: 25  Epoch: 330  Training loss = 4.0011  Validation loss = 2.5882  \n",
      "\n",
      "Fold: 25  Epoch: 331  Training loss = 4.0009  Validation loss = 2.5880  \n",
      "\n",
      "Fold: 25  Epoch: 332  Training loss = 4.0006  Validation loss = 2.5877  \n",
      "\n",
      "Fold: 25  Epoch: 333  Training loss = 4.0002  Validation loss = 2.5874  \n",
      "\n",
      "Fold: 25  Epoch: 334  Training loss = 4.0000  Validation loss = 2.5872  \n",
      "\n",
      "Fold: 25  Epoch: 335  Training loss = 3.9996  Validation loss = 2.5868  \n",
      "\n",
      "Fold: 25  Epoch: 336  Training loss = 3.9994  Validation loss = 2.5866  \n",
      "\n",
      "Fold: 25  Epoch: 337  Training loss = 3.9991  Validation loss = 2.5863  \n",
      "\n",
      "Fold: 25  Epoch: 338  Training loss = 3.9988  Validation loss = 2.5861  \n",
      "\n",
      "Fold: 25  Epoch: 339  Training loss = 3.9986  Validation loss = 2.5859  \n",
      "\n",
      "Fold: 25  Epoch: 340  Training loss = 3.9983  Validation loss = 2.5857  \n",
      "\n",
      "Fold: 25  Epoch: 341  Training loss = 3.9980  Validation loss = 2.5854  \n",
      "\n",
      "Fold: 25  Epoch: 342  Training loss = 3.9978  Validation loss = 2.5852  \n",
      "\n",
      "Fold: 25  Epoch: 343  Training loss = 3.9976  Validation loss = 2.5850  \n",
      "\n",
      "Fold: 25  Epoch: 344  Training loss = 3.9973  Validation loss = 2.5848  \n",
      "\n",
      "Fold: 25  Epoch: 345  Training loss = 3.9970  Validation loss = 2.5845  \n",
      "\n",
      "Fold: 25  Epoch: 346  Training loss = 3.9968  Validation loss = 2.5843  \n",
      "\n",
      "Fold: 25  Epoch: 347  Training loss = 3.9965  Validation loss = 2.5840  \n",
      "\n",
      "Fold: 25  Epoch: 348  Training loss = 3.9963  Validation loss = 2.5837  \n",
      "\n",
      "Fold: 25  Epoch: 349  Training loss = 3.9961  Validation loss = 2.5835  \n",
      "\n",
      "Fold: 25  Epoch: 350  Training loss = 3.9958  Validation loss = 2.5833  \n",
      "\n",
      "Fold: 25  Epoch: 351  Training loss = 3.9956  Validation loss = 2.5831  \n",
      "\n",
      "Fold: 25  Epoch: 352  Training loss = 3.9953  Validation loss = 2.5828  \n",
      "\n",
      "Fold: 25  Epoch: 353  Training loss = 3.9950  Validation loss = 2.5826  \n",
      "\n",
      "Fold: 25  Epoch: 354  Training loss = 3.9948  Validation loss = 2.5823  \n",
      "\n",
      "Fold: 25  Epoch: 355  Training loss = 3.9946  Validation loss = 2.5823  \n",
      "\n",
      "Fold: 25  Epoch: 356  Training loss = 3.9943  Validation loss = 2.5819  \n",
      "\n",
      "Fold: 25  Epoch: 357  Training loss = 3.9940  Validation loss = 2.5817  \n",
      "\n",
      "Fold: 25  Epoch: 358  Training loss = 3.9937  Validation loss = 2.5815  \n",
      "\n",
      "Fold: 25  Epoch: 359  Training loss = 3.9935  Validation loss = 2.5812  \n",
      "\n",
      "Fold: 25  Epoch: 360  Training loss = 3.9932  Validation loss = 2.5810  \n",
      "\n",
      "Fold: 25  Epoch: 361  Training loss = 3.9930  Validation loss = 2.5809  \n",
      "\n",
      "Fold: 25  Epoch: 362  Training loss = 3.9927  Validation loss = 2.5806  \n",
      "\n",
      "Fold: 25  Epoch: 363  Training loss = 3.9925  Validation loss = 2.5804  \n",
      "\n",
      "Fold: 25  Epoch: 364  Training loss = 3.9922  Validation loss = 2.5801  \n",
      "\n",
      "Fold: 25  Epoch: 365  Training loss = 3.9919  Validation loss = 2.5799  \n",
      "\n",
      "Fold: 25  Epoch: 366  Training loss = 3.9917  Validation loss = 2.5796  \n",
      "\n",
      "Fold: 25  Epoch: 367  Training loss = 3.9915  Validation loss = 2.5795  \n",
      "\n",
      "Fold: 25  Epoch: 368  Training loss = 3.9914  Validation loss = 2.5794  \n",
      "\n",
      "Fold: 25  Epoch: 369  Training loss = 3.9911  Validation loss = 2.5792  \n",
      "\n",
      "Fold: 25  Epoch: 370  Training loss = 3.9908  Validation loss = 2.5789  \n",
      "\n",
      "Fold: 25  Epoch: 371  Training loss = 3.9906  Validation loss = 2.5787  \n",
      "\n",
      "Fold: 25  Epoch: 372  Training loss = 3.9904  Validation loss = 2.5785  \n",
      "\n",
      "Fold: 25  Epoch: 373  Training loss = 3.9902  Validation loss = 2.5784  \n",
      "\n",
      "Fold: 25  Epoch: 374  Training loss = 3.9899  Validation loss = 2.5781  \n",
      "\n",
      "Fold: 25  Epoch: 375  Training loss = 3.9897  Validation loss = 2.5778  \n",
      "\n",
      "Fold: 25  Epoch: 376  Training loss = 3.9894  Validation loss = 2.5775  \n",
      "\n",
      "Fold: 25  Epoch: 377  Training loss = 3.9892  Validation loss = 2.5773  \n",
      "\n",
      "Fold: 25  Epoch: 378  Training loss = 3.9889  Validation loss = 2.5771  \n",
      "\n",
      "Fold: 25  Epoch: 379  Training loss = 3.9886  Validation loss = 2.5767  \n",
      "\n",
      "Fold: 25  Epoch: 380  Training loss = 3.9884  Validation loss = 2.5765  \n",
      "\n",
      "Fold: 25  Epoch: 381  Training loss = 3.9880  Validation loss = 2.5761  \n",
      "\n",
      "Fold: 25  Epoch: 382  Training loss = 3.9878  Validation loss = 2.5760  \n",
      "\n",
      "Fold: 25  Epoch: 383  Training loss = 3.9876  Validation loss = 2.5758  \n",
      "\n",
      "Fold: 25  Epoch: 384  Training loss = 3.9874  Validation loss = 2.5756  \n",
      "\n",
      "Fold: 25  Epoch: 385  Training loss = 3.9872  Validation loss = 2.5755  \n",
      "\n",
      "Fold: 25  Epoch: 386  Training loss = 3.9869  Validation loss = 2.5752  \n",
      "\n",
      "Fold: 25  Epoch: 387  Training loss = 3.9867  Validation loss = 2.5751  \n",
      "\n",
      "Fold: 25  Epoch: 388  Training loss = 3.9864  Validation loss = 2.5747  \n",
      "\n",
      "Fold: 25  Epoch: 389  Training loss = 3.9861  Validation loss = 2.5745  \n",
      "\n",
      "Fold: 25  Epoch: 390  Training loss = 3.9859  Validation loss = 2.5743  \n",
      "\n",
      "Fold: 25  Epoch: 391  Training loss = 3.9856  Validation loss = 2.5740  \n",
      "\n",
      "Fold: 25  Epoch: 392  Training loss = 3.9854  Validation loss = 2.5738  \n",
      "\n",
      "Fold: 25  Epoch: 393  Training loss = 3.9852  Validation loss = 2.5736  \n",
      "\n",
      "Fold: 25  Epoch: 394  Training loss = 3.9849  Validation loss = 2.5733  \n",
      "\n",
      "Fold: 25  Epoch: 395  Training loss = 3.9846  Validation loss = 2.5731  \n",
      "\n",
      "Fold: 25  Epoch: 396  Training loss = 3.9844  Validation loss = 2.5730  \n",
      "\n",
      "Fold: 25  Epoch: 397  Training loss = 3.9842  Validation loss = 2.5727  \n",
      "\n",
      "Fold: 25  Epoch: 398  Training loss = 3.9840  Validation loss = 2.5726  \n",
      "\n",
      "Fold: 25  Epoch: 399  Training loss = 3.9837  Validation loss = 2.5723  \n",
      "\n",
      "Fold: 25  Epoch: 400  Training loss = 3.9834  Validation loss = 2.5719  \n",
      "\n",
      "Fold: 25  Epoch: 401  Training loss = 3.9832  Validation loss = 2.5716  \n",
      "\n",
      "Fold: 25  Epoch: 402  Training loss = 3.9830  Validation loss = 2.5714  \n",
      "\n",
      "Fold: 25  Epoch: 403  Training loss = 3.9827  Validation loss = 2.5710  \n",
      "\n",
      "Fold: 25  Epoch: 404  Training loss = 3.9825  Validation loss = 2.5707  \n",
      "\n",
      "Fold: 25  Epoch: 405  Training loss = 3.9822  Validation loss = 2.5704  \n",
      "\n",
      "Fold: 25  Epoch: 406  Training loss = 3.9820  Validation loss = 2.5703  \n",
      "\n",
      "Fold: 25  Epoch: 407  Training loss = 3.9818  Validation loss = 2.5702  \n",
      "\n",
      "Fold: 25  Epoch: 408  Training loss = 3.9817  Validation loss = 2.5701  \n",
      "\n",
      "Fold: 25  Epoch: 409  Training loss = 3.9813  Validation loss = 2.5697  \n",
      "\n",
      "Fold: 25  Epoch: 410  Training loss = 3.9810  Validation loss = 2.5695  \n",
      "\n",
      "Fold: 25  Epoch: 411  Training loss = 3.9808  Validation loss = 2.5692  \n",
      "\n",
      "Fold: 25  Epoch: 412  Training loss = 3.9804  Validation loss = 2.5688  \n",
      "\n",
      "Fold: 25  Epoch: 413  Training loss = 3.9801  Validation loss = 2.5685  \n",
      "\n",
      "Fold: 25  Epoch: 414  Training loss = 3.9800  Validation loss = 2.5683  \n",
      "\n",
      "Fold: 25  Epoch: 415  Training loss = 3.9797  Validation loss = 2.5682  \n",
      "\n",
      "Fold: 25  Epoch: 416  Training loss = 3.9794  Validation loss = 2.5679  \n",
      "\n",
      "Fold: 25  Epoch: 417  Training loss = 3.9792  Validation loss = 2.5678  \n",
      "\n",
      "Fold: 25  Epoch: 418  Training loss = 3.9789  Validation loss = 2.5675  \n",
      "\n",
      "Fold: 25  Epoch: 419  Training loss = 3.9787  Validation loss = 2.5671  \n",
      "\n",
      "Fold: 25  Epoch: 420  Training loss = 3.9784  Validation loss = 2.5668  \n",
      "\n",
      "Fold: 25  Epoch: 421  Training loss = 3.9782  Validation loss = 2.5666  \n",
      "\n",
      "Fold: 25  Epoch: 422  Training loss = 3.9780  Validation loss = 2.5664  \n",
      "\n",
      "Fold: 25  Epoch: 423  Training loss = 3.9778  Validation loss = 2.5661  \n",
      "\n",
      "Fold: 25  Epoch: 424  Training loss = 3.9775  Validation loss = 2.5658  \n",
      "\n",
      "Fold: 25  Epoch: 425  Training loss = 3.9773  Validation loss = 2.5657  \n",
      "\n",
      "Fold: 25  Epoch: 426  Training loss = 3.9771  Validation loss = 2.5655  \n",
      "\n",
      "Fold: 25  Epoch: 427  Training loss = 3.9770  Validation loss = 2.5654  \n",
      "\n",
      "Fold: 25  Epoch: 428  Training loss = 3.9768  Validation loss = 2.5652  \n",
      "\n",
      "Fold: 25  Epoch: 429  Training loss = 3.9765  Validation loss = 2.5649  \n",
      "\n",
      "Fold: 25  Epoch: 430  Training loss = 3.9762  Validation loss = 2.5646  \n",
      "\n",
      "Fold: 25  Epoch: 431  Training loss = 3.9759  Validation loss = 2.5643  \n",
      "\n",
      "Fold: 25  Epoch: 432  Training loss = 3.9757  Validation loss = 2.5641  \n",
      "\n",
      "Fold: 25  Epoch: 433  Training loss = 3.9755  Validation loss = 2.5639  \n",
      "\n",
      "Fold: 25  Epoch: 434  Training loss = 3.9753  Validation loss = 2.5637  \n",
      "\n",
      "Fold: 25  Epoch: 435  Training loss = 3.9750  Validation loss = 2.5633  \n",
      "\n",
      "Fold: 25  Epoch: 436  Training loss = 3.9748  Validation loss = 2.5632  \n",
      "\n",
      "Fold: 25  Epoch: 437  Training loss = 3.9746  Validation loss = 2.5629  \n",
      "\n",
      "Fold: 25  Epoch: 438  Training loss = 3.9742  Validation loss = 2.5625  \n",
      "\n",
      "Fold: 25  Epoch: 439  Training loss = 3.9740  Validation loss = 2.5622  \n",
      "\n",
      "Fold: 25  Epoch: 440  Training loss = 3.9738  Validation loss = 2.5621  \n",
      "\n",
      "Fold: 25  Epoch: 441  Training loss = 3.9735  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 25  Epoch: 442  Training loss = 3.9734  Validation loss = 2.5617  \n",
      "\n",
      "Fold: 25  Epoch: 443  Training loss = 3.9731  Validation loss = 2.5614  \n",
      "\n",
      "Fold: 25  Epoch: 444  Training loss = 3.9729  Validation loss = 2.5612  \n",
      "\n",
      "Fold: 25  Epoch: 445  Training loss = 3.9725  Validation loss = 2.5608  \n",
      "\n",
      "Fold: 25  Epoch: 446  Training loss = 3.9722  Validation loss = 2.5605  \n",
      "\n",
      "Fold: 25  Epoch: 447  Training loss = 3.9719  Validation loss = 2.5602  \n",
      "\n",
      "Fold: 25  Epoch: 448  Training loss = 3.9716  Validation loss = 2.5598  \n",
      "\n",
      "Fold: 25  Epoch: 449  Training loss = 3.9714  Validation loss = 2.5597  \n",
      "\n",
      "Fold: 25  Epoch: 450  Training loss = 3.9712  Validation loss = 2.5594  \n",
      "\n",
      "Fold: 25  Epoch: 451  Training loss = 3.9709  Validation loss = 2.5591  \n",
      "\n",
      "Fold: 25  Epoch: 452  Training loss = 3.9706  Validation loss = 2.5589  \n",
      "\n",
      "Fold: 25  Epoch: 453  Training loss = 3.9704  Validation loss = 2.5585  \n",
      "\n",
      "Fold: 25  Epoch: 454  Training loss = 3.9702  Validation loss = 2.5583  \n",
      "\n",
      "Fold: 25  Epoch: 455  Training loss = 3.9699  Validation loss = 2.5580  \n",
      "\n",
      "Fold: 25  Epoch: 456  Training loss = 3.9695  Validation loss = 2.5575  \n",
      "\n",
      "Fold: 25  Epoch: 457  Training loss = 3.9693  Validation loss = 2.5574  \n",
      "\n",
      "Fold: 25  Epoch: 458  Training loss = 3.9690  Validation loss = 2.5571  \n",
      "\n",
      "Fold: 25  Epoch: 459  Training loss = 3.9688  Validation loss = 2.5569  \n",
      "\n",
      "Fold: 25  Epoch: 460  Training loss = 3.9685  Validation loss = 2.5566  \n",
      "\n",
      "Fold: 25  Epoch: 461  Training loss = 3.9682  Validation loss = 2.5563  \n",
      "\n",
      "Fold: 25  Epoch: 462  Training loss = 3.9680  Validation loss = 2.5561  \n",
      "\n",
      "Fold: 25  Epoch: 463  Training loss = 3.9678  Validation loss = 2.5559  \n",
      "\n",
      "Fold: 25  Epoch: 464  Training loss = 3.9676  Validation loss = 2.5557  \n",
      "\n",
      "Fold: 25  Epoch: 465  Training loss = 3.9674  Validation loss = 2.5555  \n",
      "\n",
      "Fold: 25  Epoch: 466  Training loss = 3.9672  Validation loss = 2.5553  \n",
      "\n",
      "Fold: 25  Epoch: 467  Training loss = 3.9669  Validation loss = 2.5551  \n",
      "\n",
      "Fold: 25  Epoch: 468  Training loss = 3.9667  Validation loss = 2.5549  \n",
      "\n",
      "Fold: 25  Epoch: 469  Training loss = 3.9665  Validation loss = 2.5546  \n",
      "\n",
      "Fold: 25  Epoch: 470  Training loss = 3.9662  Validation loss = 2.5544  \n",
      "\n",
      "Fold: 25  Epoch: 471  Training loss = 3.9661  Validation loss = 2.5543  \n",
      "\n",
      "Fold: 25  Epoch: 472  Training loss = 3.9660  Validation loss = 2.5542  \n",
      "\n",
      "Fold: 25  Epoch: 473  Training loss = 3.9657  Validation loss = 2.5539  \n",
      "\n",
      "Fold: 25  Epoch: 474  Training loss = 3.9655  Validation loss = 2.5538  \n",
      "\n",
      "Fold: 25  Epoch: 475  Training loss = 3.9653  Validation loss = 2.5535  \n",
      "\n",
      "Fold: 25  Epoch: 476  Training loss = 3.9651  Validation loss = 2.5533  \n",
      "\n",
      "Fold: 25  Epoch: 477  Training loss = 3.9648  Validation loss = 2.5530  \n",
      "\n",
      "Fold: 25  Epoch: 478  Training loss = 3.9646  Validation loss = 2.5528  \n",
      "\n",
      "Fold: 25  Epoch: 479  Training loss = 3.9644  Validation loss = 2.5526  \n",
      "\n",
      "Fold: 25  Epoch: 480  Training loss = 3.9641  Validation loss = 2.5523  \n",
      "\n",
      "Fold: 25  Epoch: 481  Training loss = 3.9639  Validation loss = 2.5520  \n",
      "\n",
      "Fold: 25  Epoch: 482  Training loss = 3.9636  Validation loss = 2.5517  \n",
      "\n",
      "Fold: 25  Epoch: 483  Training loss = 3.9634  Validation loss = 2.5514  \n",
      "\n",
      "Fold: 25  Epoch: 484  Training loss = 3.9631  Validation loss = 2.5511  \n",
      "\n",
      "Fold: 25  Epoch: 485  Training loss = 3.9629  Validation loss = 2.5508  \n",
      "\n",
      "Fold: 25  Epoch: 486  Training loss = 3.9626  Validation loss = 2.5506  \n",
      "\n",
      "Fold: 25  Epoch: 487  Training loss = 3.9623  Validation loss = 2.5502  \n",
      "\n",
      "Fold: 25  Epoch: 488  Training loss = 3.9621  Validation loss = 2.5500  \n",
      "\n",
      "Fold: 25  Epoch: 489  Training loss = 3.9619  Validation loss = 2.5498  \n",
      "\n",
      "Fold: 25  Epoch: 490  Training loss = 3.9617  Validation loss = 2.5497  \n",
      "\n",
      "Fold: 25  Epoch: 491  Training loss = 3.9615  Validation loss = 2.5494  \n",
      "\n",
      "Fold: 25  Epoch: 492  Training loss = 3.9613  Validation loss = 2.5492  \n",
      "\n",
      "Fold: 25  Epoch: 493  Training loss = 3.9610  Validation loss = 2.5489  \n",
      "\n",
      "Fold: 25  Epoch: 494  Training loss = 3.9608  Validation loss = 2.5486  \n",
      "\n",
      "Fold: 25  Epoch: 495  Training loss = 3.9606  Validation loss = 2.5484  \n",
      "\n",
      "Fold: 25  Epoch: 496  Training loss = 3.9604  Validation loss = 2.5481  \n",
      "\n",
      "Fold: 25  Epoch: 497  Training loss = 3.9601  Validation loss = 2.5479  \n",
      "\n",
      "Fold: 25  Epoch: 498  Training loss = 3.9598  Validation loss = 2.5476  \n",
      "\n",
      "Fold: 25  Epoch: 499  Training loss = 3.9596  Validation loss = 2.5474  \n",
      "\n",
      "Fold: 25  Epoch: 500  Training loss = 3.9594  Validation loss = 2.5472  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 500  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 3.7050  Validation loss = 1.4453  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 3.7048  Validation loss = 1.4450  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 3.7046  Validation loss = 1.4455  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 3.7045  Validation loss = 1.4457  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 3.7043  Validation loss = 1.4461  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 3.7041  Validation loss = 1.4461  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 3.7039  Validation loss = 1.4463  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 3.7037  Validation loss = 1.4463  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 3.7036  Validation loss = 1.4466  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 3.7033  Validation loss = 1.4469  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 3.7031  Validation loss = 1.4469  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 2  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 3.5688  Validation loss = 1.0642  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 3.5687  Validation loss = 1.0643  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 3.5685  Validation loss = 1.0644  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 3.5684  Validation loss = 1.0643  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 3.5682  Validation loss = 1.0644  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 3.5680  Validation loss = 1.0645  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 3.5679  Validation loss = 1.0645  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 3.5677  Validation loss = 1.0645  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 3.5676  Validation loss = 1.0644  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 3.5674  Validation loss = 1.0645  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 3.5672  Validation loss = 1.0646  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 1  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 3.5596  Validation loss = 1.7690  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 3.5594  Validation loss = 1.7689  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 3.5593  Validation loss = 1.7685  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 3.5592  Validation loss = 1.7684  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 3.5590  Validation loss = 1.7684  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 3.5588  Validation loss = 1.7685  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 3.5587  Validation loss = 1.7684  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 3.5585  Validation loss = 1.7683  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 3.5583  Validation loss = 1.7682  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 3.5582  Validation loss = 1.7683  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 3.5580  Validation loss = 1.7680  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 3.5579  Validation loss = 1.7677  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 3.5577  Validation loss = 1.7675  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 3.5575  Validation loss = 1.7675  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 3.5574  Validation loss = 1.7672  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 3.5572  Validation loss = 1.7672  \n",
      "\n",
      "Fold: 28  Epoch: 17  Training loss = 3.5571  Validation loss = 1.7671  \n",
      "\n",
      "Fold: 28  Epoch: 18  Training loss = 3.5569  Validation loss = 1.7671  \n",
      "\n",
      "Fold: 28  Epoch: 19  Training loss = 3.5568  Validation loss = 1.7670  \n",
      "\n",
      "Fold: 28  Epoch: 20  Training loss = 3.5566  Validation loss = 1.7671  \n",
      "\n",
      "Fold: 28  Epoch: 21  Training loss = 3.5564  Validation loss = 1.7671  \n",
      "\n",
      "Fold: 28  Epoch: 22  Training loss = 3.5563  Validation loss = 1.7669  \n",
      "\n",
      "Fold: 28  Epoch: 23  Training loss = 3.5560  Validation loss = 1.7669  \n",
      "\n",
      "Fold: 28  Epoch: 24  Training loss = 3.5559  Validation loss = 1.7669  \n",
      "\n",
      "Fold: 28  Epoch: 25  Training loss = 3.5557  Validation loss = 1.7668  \n",
      "\n",
      "Fold: 28  Epoch: 26  Training loss = 3.5555  Validation loss = 1.7667  \n",
      "\n",
      "Fold: 28  Epoch: 27  Training loss = 3.5554  Validation loss = 1.7667  \n",
      "\n",
      "Fold: 28  Epoch: 28  Training loss = 3.5552  Validation loss = 1.7666  \n",
      "\n",
      "Fold: 28  Epoch: 29  Training loss = 3.5550  Validation loss = 1.7667  \n",
      "\n",
      "Fold: 28  Epoch: 30  Training loss = 3.5549  Validation loss = 1.7664  \n",
      "\n",
      "Fold: 28  Epoch: 31  Training loss = 3.5547  Validation loss = 1.7665  \n",
      "\n",
      "Fold: 28  Epoch: 32  Training loss = 3.5546  Validation loss = 1.7663  \n",
      "\n",
      "Fold: 28  Epoch: 33  Training loss = 3.5544  Validation loss = 1.7662  \n",
      "\n",
      "Fold: 28  Epoch: 34  Training loss = 3.5543  Validation loss = 1.7661  \n",
      "\n",
      "Fold: 28  Epoch: 35  Training loss = 3.5541  Validation loss = 1.7661  \n",
      "\n",
      "Fold: 28  Epoch: 36  Training loss = 3.5539  Validation loss = 1.7661  \n",
      "\n",
      "Fold: 28  Epoch: 37  Training loss = 3.5537  Validation loss = 1.7658  \n",
      "\n",
      "Fold: 28  Epoch: 38  Training loss = 3.5536  Validation loss = 1.7656  \n",
      "\n",
      "Fold: 28  Epoch: 39  Training loss = 3.5534  Validation loss = 1.7654  \n",
      "\n",
      "Fold: 28  Epoch: 40  Training loss = 3.5533  Validation loss = 1.7653  \n",
      "\n",
      "Fold: 28  Epoch: 41  Training loss = 3.5531  Validation loss = 1.7653  \n",
      "\n",
      "Fold: 28  Epoch: 42  Training loss = 3.5529  Validation loss = 1.7655  \n",
      "\n",
      "Fold: 28  Epoch: 43  Training loss = 3.5528  Validation loss = 1.7655  \n",
      "\n",
      "Fold: 28  Epoch: 44  Training loss = 3.5527  Validation loss = 1.7653  \n",
      "\n",
      "Fold: 28  Epoch: 45  Training loss = 3.5525  Validation loss = 1.7654  \n",
      "\n",
      "Fold: 28  Epoch: 46  Training loss = 3.5523  Validation loss = 1.7654  \n",
      "\n",
      "Fold: 28  Epoch: 47  Training loss = 3.5522  Validation loss = 1.7654  \n",
      "\n",
      "Fold: 28  Epoch: 48  Training loss = 3.5520  Validation loss = 1.7655  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 44  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 3.5620  Validation loss = 0.8400  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.5618  Validation loss = 0.8399  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 3.5617  Validation loss = 0.8397  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.5615  Validation loss = 0.8396  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 3.5614  Validation loss = 0.8395  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 3.5612  Validation loss = 0.8394  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 3.5611  Validation loss = 0.8393  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 3.5610  Validation loss = 0.8393  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 3.5608  Validation loss = 0.8391  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 3.5606  Validation loss = 0.8389  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 3.5604  Validation loss = 0.8388  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 3.5603  Validation loss = 0.8387  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.5601  Validation loss = 0.8386  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 3.5599  Validation loss = 0.8385  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 3.5597  Validation loss = 0.8384  \n",
      "\n",
      "Fold: 29  Epoch: 16  Training loss = 3.5596  Validation loss = 0.8383  \n",
      "\n",
      "Fold: 29  Epoch: 17  Training loss = 3.5594  Validation loss = 0.8382  \n",
      "\n",
      "Fold: 29  Epoch: 18  Training loss = 3.5593  Validation loss = 0.8381  \n",
      "\n",
      "Fold: 29  Epoch: 19  Training loss = 3.5592  Validation loss = 0.8380  \n",
      "\n",
      "Fold: 29  Epoch: 20  Training loss = 3.5590  Validation loss = 0.8378  \n",
      "\n",
      "Fold: 29  Epoch: 21  Training loss = 3.5588  Validation loss = 0.8376  \n",
      "\n",
      "Fold: 29  Epoch: 22  Training loss = 3.5586  Validation loss = 0.8375  \n",
      "\n",
      "Fold: 29  Epoch: 23  Training loss = 3.5584  Validation loss = 0.8373  \n",
      "\n",
      "Fold: 29  Epoch: 24  Training loss = 3.5582  Validation loss = 0.8372  \n",
      "\n",
      "Fold: 29  Epoch: 25  Training loss = 3.5581  Validation loss = 0.8371  \n",
      "\n",
      "Fold: 29  Epoch: 26  Training loss = 3.5579  Validation loss = 0.8370  \n",
      "\n",
      "Fold: 29  Epoch: 27  Training loss = 3.5577  Validation loss = 0.8368  \n",
      "\n",
      "Fold: 29  Epoch: 28  Training loss = 3.5576  Validation loss = 0.8367  \n",
      "\n",
      "Fold: 29  Epoch: 29  Training loss = 3.5574  Validation loss = 0.8365  \n",
      "\n",
      "Fold: 29  Epoch: 30  Training loss = 3.5572  Validation loss = 0.8364  \n",
      "\n",
      "Fold: 29  Epoch: 31  Training loss = 3.5571  Validation loss = 0.8363  \n",
      "\n",
      "Fold: 29  Epoch: 32  Training loss = 3.5569  Validation loss = 0.8362  \n",
      "\n",
      "Fold: 29  Epoch: 33  Training loss = 3.5567  Validation loss = 0.8360  \n",
      "\n",
      "Fold: 29  Epoch: 34  Training loss = 3.5566  Validation loss = 0.8360  \n",
      "\n",
      "Fold: 29  Epoch: 35  Training loss = 3.5564  Validation loss = 0.8359  \n",
      "\n",
      "Fold: 29  Epoch: 36  Training loss = 3.5563  Validation loss = 0.8358  \n",
      "\n",
      "Fold: 29  Epoch: 37  Training loss = 3.5561  Validation loss = 0.8357  \n",
      "\n",
      "Fold: 29  Epoch: 38  Training loss = 3.5559  Validation loss = 0.8356  \n",
      "\n",
      "Fold: 29  Epoch: 39  Training loss = 3.5558  Validation loss = 0.8355  \n",
      "\n",
      "Fold: 29  Epoch: 40  Training loss = 3.5556  Validation loss = 0.8354  \n",
      "\n",
      "Fold: 29  Epoch: 41  Training loss = 3.5554  Validation loss = 0.8352  \n",
      "\n",
      "Fold: 29  Epoch: 42  Training loss = 3.5552  Validation loss = 0.8352  \n",
      "\n",
      "Fold: 29  Epoch: 43  Training loss = 3.5550  Validation loss = 0.8350  \n",
      "\n",
      "Fold: 29  Epoch: 44  Training loss = 3.5548  Validation loss = 0.8349  \n",
      "\n",
      "Fold: 29  Epoch: 45  Training loss = 3.5546  Validation loss = 0.8347  \n",
      "\n",
      "Fold: 29  Epoch: 46  Training loss = 3.5545  Validation loss = 0.8346  \n",
      "\n",
      "Fold: 29  Epoch: 47  Training loss = 3.5544  Validation loss = 0.8346  \n",
      "\n",
      "Fold: 29  Epoch: 48  Training loss = 3.5542  Validation loss = 0.8345  \n",
      "\n",
      "Fold: 29  Epoch: 49  Training loss = 3.5541  Validation loss = 0.8344  \n",
      "\n",
      "Fold: 29  Epoch: 50  Training loss = 3.5539  Validation loss = 0.8343  \n",
      "\n",
      "Fold: 29  Epoch: 51  Training loss = 3.5537  Validation loss = 0.8342  \n",
      "\n",
      "Fold: 29  Epoch: 52  Training loss = 3.5536  Validation loss = 0.8341  \n",
      "\n",
      "Fold: 29  Epoch: 53  Training loss = 3.5535  Validation loss = 0.8340  \n",
      "\n",
      "Fold: 29  Epoch: 54  Training loss = 3.5534  Validation loss = 0.8339  \n",
      "\n",
      "Fold: 29  Epoch: 55  Training loss = 3.5531  Validation loss = 0.8337  \n",
      "\n",
      "Fold: 29  Epoch: 56  Training loss = 3.5529  Validation loss = 0.8336  \n",
      "\n",
      "Fold: 29  Epoch: 57  Training loss = 3.5527  Validation loss = 0.8334  \n",
      "\n",
      "Fold: 29  Epoch: 58  Training loss = 3.5525  Validation loss = 0.8333  \n",
      "\n",
      "Fold: 29  Epoch: 59  Training loss = 3.5523  Validation loss = 0.8332  \n",
      "\n",
      "Fold: 29  Epoch: 60  Training loss = 3.5522  Validation loss = 0.8331  \n",
      "\n",
      "Fold: 29  Epoch: 61  Training loss = 3.5520  Validation loss = 0.8329  \n",
      "\n",
      "Fold: 29  Epoch: 62  Training loss = 3.5518  Validation loss = 0.8328  \n",
      "\n",
      "Fold: 29  Epoch: 63  Training loss = 3.5517  Validation loss = 0.8327  \n",
      "\n",
      "Fold: 29  Epoch: 64  Training loss = 3.5515  Validation loss = 0.8327  \n",
      "\n",
      "Fold: 29  Epoch: 65  Training loss = 3.5514  Validation loss = 0.8326  \n",
      "\n",
      "Fold: 29  Epoch: 66  Training loss = 3.5512  Validation loss = 0.8325  \n",
      "\n",
      "Fold: 29  Epoch: 67  Training loss = 3.5511  Validation loss = 0.8324  \n",
      "\n",
      "Fold: 29  Epoch: 68  Training loss = 3.5509  Validation loss = 0.8324  \n",
      "\n",
      "Fold: 29  Epoch: 69  Training loss = 3.5508  Validation loss = 0.8324  \n",
      "\n",
      "Fold: 29  Epoch: 70  Training loss = 3.5506  Validation loss = 0.8322  \n",
      "\n",
      "Fold: 29  Epoch: 71  Training loss = 3.5504  Validation loss = 0.8321  \n",
      "\n",
      "Fold: 29  Epoch: 72  Training loss = 3.5502  Validation loss = 0.8321  \n",
      "\n",
      "Fold: 29  Epoch: 73  Training loss = 3.5501  Validation loss = 0.8320  \n",
      "\n",
      "Fold: 29  Epoch: 74  Training loss = 3.5500  Validation loss = 0.8319  \n",
      "\n",
      "Fold: 29  Epoch: 75  Training loss = 3.5499  Validation loss = 0.8319  \n",
      "\n",
      "Fold: 29  Epoch: 76  Training loss = 3.5497  Validation loss = 0.8317  \n",
      "\n",
      "Fold: 29  Epoch: 77  Training loss = 3.5496  Validation loss = 0.8317  \n",
      "\n",
      "Fold: 29  Epoch: 78  Training loss = 3.5493  Validation loss = 0.8315  \n",
      "\n",
      "Fold: 29  Epoch: 79  Training loss = 3.5492  Validation loss = 0.8315  \n",
      "\n",
      "Fold: 29  Epoch: 80  Training loss = 3.5490  Validation loss = 0.8313  \n",
      "\n",
      "Fold: 29  Epoch: 81  Training loss = 3.5489  Validation loss = 0.8312  \n",
      "\n",
      "Fold: 29  Epoch: 82  Training loss = 3.5486  Validation loss = 0.8311  \n",
      "\n",
      "Fold: 29  Epoch: 83  Training loss = 3.5484  Validation loss = 0.8309  \n",
      "\n",
      "Fold: 29  Epoch: 84  Training loss = 3.5482  Validation loss = 0.8308  \n",
      "\n",
      "Fold: 29  Epoch: 85  Training loss = 3.5480  Validation loss = 0.8307  \n",
      "\n",
      "Fold: 29  Epoch: 86  Training loss = 3.5479  Validation loss = 0.8306  \n",
      "\n",
      "Fold: 29  Epoch: 87  Training loss = 3.5478  Validation loss = 0.8305  \n",
      "\n",
      "Fold: 29  Epoch: 88  Training loss = 3.5475  Validation loss = 0.8303  \n",
      "\n",
      "Fold: 29  Epoch: 89  Training loss = 3.5472  Validation loss = 0.8301  \n",
      "\n",
      "Fold: 29  Epoch: 90  Training loss = 3.5470  Validation loss = 0.8300  \n",
      "\n",
      "Fold: 29  Epoch: 91  Training loss = 3.5469  Validation loss = 0.8299  \n",
      "\n",
      "Fold: 29  Epoch: 92  Training loss = 3.5468  Validation loss = 0.8299  \n",
      "\n",
      "Fold: 29  Epoch: 93  Training loss = 3.5464  Validation loss = 0.8295  \n",
      "\n",
      "Fold: 29  Epoch: 94  Training loss = 3.5463  Validation loss = 0.8295  \n",
      "\n",
      "Fold: 29  Epoch: 95  Training loss = 3.5460  Validation loss = 0.8293  \n",
      "\n",
      "Fold: 29  Epoch: 96  Training loss = 3.5459  Validation loss = 0.8292  \n",
      "\n",
      "Fold: 29  Epoch: 97  Training loss = 3.5457  Validation loss = 0.8290  \n",
      "\n",
      "Fold: 29  Epoch: 98  Training loss = 3.5455  Validation loss = 0.8290  \n",
      "\n",
      "Fold: 29  Epoch: 99  Training loss = 3.5453  Validation loss = 0.8289  \n",
      "\n",
      "Fold: 29  Epoch: 100  Training loss = 3.5451  Validation loss = 0.8288  \n",
      "\n",
      "Fold: 29  Epoch: 101  Training loss = 3.5449  Validation loss = 0.8286  \n",
      "\n",
      "Fold: 29  Epoch: 102  Training loss = 3.5448  Validation loss = 0.8286  \n",
      "\n",
      "Fold: 29  Epoch: 103  Training loss = 3.5447  Validation loss = 0.8284  \n",
      "\n",
      "Fold: 29  Epoch: 104  Training loss = 3.5445  Validation loss = 0.8282  \n",
      "\n",
      "Fold: 29  Epoch: 105  Training loss = 3.5442  Validation loss = 0.8280  \n",
      "\n",
      "Fold: 29  Epoch: 106  Training loss = 3.5441  Validation loss = 0.8279  \n",
      "\n",
      "Fold: 29  Epoch: 107  Training loss = 3.5440  Validation loss = 0.8279  \n",
      "\n",
      "Fold: 29  Epoch: 108  Training loss = 3.5438  Validation loss = 0.8277  \n",
      "\n",
      "Fold: 29  Epoch: 109  Training loss = 3.5436  Validation loss = 0.8276  \n",
      "\n",
      "Fold: 29  Epoch: 110  Training loss = 3.5435  Validation loss = 0.8275  \n",
      "\n",
      "Fold: 29  Epoch: 111  Training loss = 3.5433  Validation loss = 0.8274  \n",
      "\n",
      "Fold: 29  Epoch: 112  Training loss = 3.5431  Validation loss = 0.8273  \n",
      "\n",
      "Fold: 29  Epoch: 113  Training loss = 3.5430  Validation loss = 0.8272  \n",
      "\n",
      "Fold: 29  Epoch: 114  Training loss = 3.5429  Validation loss = 0.8271  \n",
      "\n",
      "Fold: 29  Epoch: 115  Training loss = 3.5427  Validation loss = 0.8270  \n",
      "\n",
      "Fold: 29  Epoch: 116  Training loss = 3.5425  Validation loss = 0.8269  \n",
      "\n",
      "Fold: 29  Epoch: 117  Training loss = 3.5424  Validation loss = 0.8268  \n",
      "\n",
      "Fold: 29  Epoch: 118  Training loss = 3.5422  Validation loss = 0.8267  \n",
      "\n",
      "Fold: 29  Epoch: 119  Training loss = 3.5421  Validation loss = 0.8266  \n",
      "\n",
      "Fold: 29  Epoch: 120  Training loss = 3.5419  Validation loss = 0.8265  \n",
      "\n",
      "Fold: 29  Epoch: 121  Training loss = 3.5417  Validation loss = 0.8263  \n",
      "\n",
      "Fold: 29  Epoch: 122  Training loss = 3.5416  Validation loss = 0.8263  \n",
      "\n",
      "Fold: 29  Epoch: 123  Training loss = 3.5415  Validation loss = 0.8261  \n",
      "\n",
      "Fold: 29  Epoch: 124  Training loss = 3.5414  Validation loss = 0.8260  \n",
      "\n",
      "Fold: 29  Epoch: 125  Training loss = 3.5412  Validation loss = 0.8258  \n",
      "\n",
      "Fold: 29  Epoch: 126  Training loss = 3.5411  Validation loss = 0.8258  \n",
      "\n",
      "Fold: 29  Epoch: 127  Training loss = 3.5409  Validation loss = 0.8256  \n",
      "\n",
      "Fold: 29  Epoch: 128  Training loss = 3.5408  Validation loss = 0.8256  \n",
      "\n",
      "Fold: 29  Epoch: 129  Training loss = 3.5406  Validation loss = 0.8254  \n",
      "\n",
      "Fold: 29  Epoch: 130  Training loss = 3.5404  Validation loss = 0.8254  \n",
      "\n",
      "Fold: 29  Epoch: 131  Training loss = 3.5404  Validation loss = 0.8254  \n",
      "\n",
      "Fold: 29  Epoch: 132  Training loss = 3.5402  Validation loss = 0.8253  \n",
      "\n",
      "Fold: 29  Epoch: 133  Training loss = 3.5401  Validation loss = 0.8252  \n",
      "\n",
      "Fold: 29  Epoch: 134  Training loss = 3.5399  Validation loss = 0.8252  \n",
      "\n",
      "Fold: 29  Epoch: 135  Training loss = 3.5398  Validation loss = 0.8250  \n",
      "\n",
      "Fold: 29  Epoch: 136  Training loss = 3.5396  Validation loss = 0.8249  \n",
      "\n",
      "Fold: 29  Epoch: 137  Training loss = 3.5394  Validation loss = 0.8248  \n",
      "\n",
      "Fold: 29  Epoch: 138  Training loss = 3.5394  Validation loss = 0.8248  \n",
      "\n",
      "Fold: 29  Epoch: 139  Training loss = 3.5391  Validation loss = 0.8247  \n",
      "\n",
      "Fold: 29  Epoch: 140  Training loss = 3.5389  Validation loss = 0.8246  \n",
      "\n",
      "Fold: 29  Epoch: 141  Training loss = 3.5387  Validation loss = 0.8244  \n",
      "\n",
      "Fold: 29  Epoch: 142  Training loss = 3.5385  Validation loss = 0.8243  \n",
      "\n",
      "Fold: 29  Epoch: 143  Training loss = 3.5384  Validation loss = 0.8242  \n",
      "\n",
      "Fold: 29  Epoch: 144  Training loss = 3.5382  Validation loss = 0.8241  \n",
      "\n",
      "Fold: 29  Epoch: 145  Training loss = 3.5380  Validation loss = 0.8241  \n",
      "\n",
      "Fold: 29  Epoch: 146  Training loss = 3.5379  Validation loss = 0.8240  \n",
      "\n",
      "Fold: 29  Epoch: 147  Training loss = 3.5377  Validation loss = 0.8239  \n",
      "\n",
      "Fold: 29  Epoch: 148  Training loss = 3.5375  Validation loss = 0.8238  \n",
      "\n",
      "Fold: 29  Epoch: 149  Training loss = 3.5374  Validation loss = 0.8237  \n",
      "\n",
      "Fold: 29  Epoch: 150  Training loss = 3.5372  Validation loss = 0.8236  \n",
      "\n",
      "Fold: 29  Epoch: 151  Training loss = 3.5369  Validation loss = 0.8235  \n",
      "\n",
      "Fold: 29  Epoch: 152  Training loss = 3.5368  Validation loss = 0.8234  \n",
      "\n",
      "Fold: 29  Epoch: 153  Training loss = 3.5366  Validation loss = 0.8233  \n",
      "\n",
      "Fold: 29  Epoch: 154  Training loss = 3.5365  Validation loss = 0.8232  \n",
      "\n",
      "Fold: 29  Epoch: 155  Training loss = 3.5363  Validation loss = 0.8230  \n",
      "\n",
      "Fold: 29  Epoch: 156  Training loss = 3.5362  Validation loss = 0.8229  \n",
      "\n",
      "Fold: 29  Epoch: 157  Training loss = 3.5360  Validation loss = 0.8229  \n",
      "\n",
      "Fold: 29  Epoch: 158  Training loss = 3.5358  Validation loss = 0.8229  \n",
      "\n",
      "Fold: 29  Epoch: 159  Training loss = 3.5357  Validation loss = 0.8228  \n",
      "\n",
      "Fold: 29  Epoch: 160  Training loss = 3.5356  Validation loss = 0.8227  \n",
      "\n",
      "Fold: 29  Epoch: 161  Training loss = 3.5354  Validation loss = 0.8226  \n",
      "\n",
      "Fold: 29  Epoch: 162  Training loss = 3.5353  Validation loss = 0.8225  \n",
      "\n",
      "Fold: 29  Epoch: 163  Training loss = 3.5351  Validation loss = 0.8224  \n",
      "\n",
      "Fold: 29  Epoch: 164  Training loss = 3.5349  Validation loss = 0.8223  \n",
      "\n",
      "Fold: 29  Epoch: 165  Training loss = 3.5348  Validation loss = 0.8223  \n",
      "\n",
      "Fold: 29  Epoch: 166  Training loss = 3.5347  Validation loss = 0.8222  \n",
      "\n",
      "Fold: 29  Epoch: 167  Training loss = 3.5346  Validation loss = 0.8221  \n",
      "\n",
      "Fold: 29  Epoch: 168  Training loss = 3.5344  Validation loss = 0.8220  \n",
      "\n",
      "Fold: 29  Epoch: 169  Training loss = 3.5343  Validation loss = 0.8220  \n",
      "\n",
      "Fold: 29  Epoch: 170  Training loss = 3.5341  Validation loss = 0.8220  \n",
      "\n",
      "Fold: 29  Epoch: 171  Training loss = 3.5340  Validation loss = 0.8219  \n",
      "\n",
      "Fold: 29  Epoch: 172  Training loss = 3.5338  Validation loss = 0.8218  \n",
      "\n",
      "Fold: 29  Epoch: 173  Training loss = 3.5337  Validation loss = 0.8218  \n",
      "\n",
      "Fold: 29  Epoch: 174  Training loss = 3.5336  Validation loss = 0.8217  \n",
      "\n",
      "Fold: 29  Epoch: 175  Training loss = 3.5334  Validation loss = 0.8215  \n",
      "\n",
      "Fold: 29  Epoch: 176  Training loss = 3.5333  Validation loss = 0.8215  \n",
      "\n",
      "Fold: 29  Epoch: 177  Training loss = 3.5332  Validation loss = 0.8214  \n",
      "\n",
      "Fold: 29  Epoch: 178  Training loss = 3.5331  Validation loss = 0.8214  \n",
      "\n",
      "Fold: 29  Epoch: 179  Training loss = 3.5329  Validation loss = 0.8213  \n",
      "\n",
      "Fold: 29  Epoch: 180  Training loss = 3.5327  Validation loss = 0.8212  \n",
      "\n",
      "Fold: 29  Epoch: 181  Training loss = 3.5325  Validation loss = 0.8211  \n",
      "\n",
      "Fold: 29  Epoch: 182  Training loss = 3.5324  Validation loss = 0.8210  \n",
      "\n",
      "Fold: 29  Epoch: 183  Training loss = 3.5322  Validation loss = 0.8210  \n",
      "\n",
      "Fold: 29  Epoch: 184  Training loss = 3.5321  Validation loss = 0.8210  \n",
      "\n",
      "Fold: 29  Epoch: 185  Training loss = 3.5320  Validation loss = 0.8210  \n",
      "\n",
      "Fold: 29  Epoch: 186  Training loss = 3.5319  Validation loss = 0.8209  \n",
      "\n",
      "Fold: 29  Epoch: 187  Training loss = 3.5318  Validation loss = 0.8210  \n",
      "\n",
      "Fold: 29  Epoch: 188  Training loss = 3.5316  Validation loss = 0.8208  \n",
      "\n",
      "Fold: 29  Epoch: 189  Training loss = 3.5315  Validation loss = 0.8207  \n",
      "\n",
      "Fold: 29  Epoch: 190  Training loss = 3.5313  Validation loss = 0.8206  \n",
      "\n",
      "Fold: 29  Epoch: 191  Training loss = 3.5312  Validation loss = 0.8205  \n",
      "\n",
      "Fold: 29  Epoch: 192  Training loss = 3.5311  Validation loss = 0.8206  \n",
      "\n",
      "Fold: 29  Epoch: 193  Training loss = 3.5309  Validation loss = 0.8206  \n",
      "\n",
      "Fold: 29  Epoch: 194  Training loss = 3.5308  Validation loss = 0.8205  \n",
      "\n",
      "Fold: 29  Epoch: 195  Training loss = 3.5307  Validation loss = 0.8205  \n",
      "\n",
      "Fold: 29  Epoch: 196  Training loss = 3.5305  Validation loss = 0.8204  \n",
      "\n",
      "Fold: 29  Epoch: 197  Training loss = 3.5303  Validation loss = 0.8204  \n",
      "\n",
      "Fold: 29  Epoch: 198  Training loss = 3.5302  Validation loss = 0.8202  \n",
      "\n",
      "Fold: 29  Epoch: 199  Training loss = 3.5301  Validation loss = 0.8203  \n",
      "\n",
      "Fold: 29  Epoch: 200  Training loss = 3.5300  Validation loss = 0.8202  \n",
      "\n",
      "Fold: 29  Epoch: 201  Training loss = 3.5298  Validation loss = 0.8201  \n",
      "\n",
      "Fold: 29  Epoch: 202  Training loss = 3.5295  Validation loss = 0.8200  \n",
      "\n",
      "Fold: 29  Epoch: 203  Training loss = 3.5294  Validation loss = 0.8200  \n",
      "\n",
      "Fold: 29  Epoch: 204  Training loss = 3.5293  Validation loss = 0.8199  \n",
      "\n",
      "Fold: 29  Epoch: 205  Training loss = 3.5292  Validation loss = 0.8199  \n",
      "\n",
      "Fold: 29  Epoch: 206  Training loss = 3.5291  Validation loss = 0.8198  \n",
      "\n",
      "Fold: 29  Epoch: 207  Training loss = 3.5289  Validation loss = 0.8197  \n",
      "\n",
      "Fold: 29  Epoch: 208  Training loss = 3.5288  Validation loss = 0.8196  \n",
      "\n",
      "Fold: 29  Epoch: 209  Training loss = 3.5286  Validation loss = 0.8195  \n",
      "\n",
      "Fold: 29  Epoch: 210  Training loss = 3.5285  Validation loss = 0.8196  \n",
      "\n",
      "Fold: 29  Epoch: 211  Training loss = 3.5284  Validation loss = 0.8196  \n",
      "\n",
      "Fold: 29  Epoch: 212  Training loss = 3.5283  Validation loss = 0.8195  \n",
      "\n",
      "Fold: 29  Epoch: 213  Training loss = 3.5282  Validation loss = 0.8195  \n",
      "\n",
      "Fold: 29  Epoch: 214  Training loss = 3.5280  Validation loss = 0.8193  \n",
      "\n",
      "Fold: 29  Epoch: 215  Training loss = 3.5279  Validation loss = 0.8192  \n",
      "\n",
      "Fold: 29  Epoch: 216  Training loss = 3.5278  Validation loss = 0.8194  \n",
      "\n",
      "Fold: 29  Epoch: 217  Training loss = 3.5276  Validation loss = 0.8193  \n",
      "\n",
      "Fold: 29  Epoch: 218  Training loss = 3.5275  Validation loss = 0.8192  \n",
      "\n",
      "Fold: 29  Epoch: 219  Training loss = 3.5273  Validation loss = 0.8190  \n",
      "\n",
      "Fold: 29  Epoch: 220  Training loss = 3.5272  Validation loss = 0.8190  \n",
      "\n",
      "Fold: 29  Epoch: 221  Training loss = 3.5269  Validation loss = 0.8189  \n",
      "\n",
      "Fold: 29  Epoch: 222  Training loss = 3.5268  Validation loss = 0.8189  \n",
      "\n",
      "Fold: 29  Epoch: 223  Training loss = 3.5267  Validation loss = 0.8188  \n",
      "\n",
      "Fold: 29  Epoch: 224  Training loss = 3.5265  Validation loss = 0.8187  \n",
      "\n",
      "Fold: 29  Epoch: 225  Training loss = 3.5264  Validation loss = 0.8187  \n",
      "\n",
      "Fold: 29  Epoch: 226  Training loss = 3.5262  Validation loss = 0.8186  \n",
      "\n",
      "Fold: 29  Epoch: 227  Training loss = 3.5261  Validation loss = 0.8185  \n",
      "\n",
      "Fold: 29  Epoch: 228  Training loss = 3.5260  Validation loss = 0.8184  \n",
      "\n",
      "Fold: 29  Epoch: 229  Training loss = 3.5258  Validation loss = 0.8182  \n",
      "\n",
      "Fold: 29  Epoch: 230  Training loss = 3.5256  Validation loss = 0.8180  \n",
      "\n",
      "Fold: 29  Epoch: 231  Training loss = 3.5255  Validation loss = 0.8179  \n",
      "\n",
      "Fold: 29  Epoch: 232  Training loss = 3.5254  Validation loss = 0.8178  \n",
      "\n",
      "Fold: 29  Epoch: 233  Training loss = 3.5252  Validation loss = 0.8178  \n",
      "\n",
      "Fold: 29  Epoch: 234  Training loss = 3.5251  Validation loss = 0.8177  \n",
      "\n",
      "Fold: 29  Epoch: 235  Training loss = 3.5250  Validation loss = 0.8177  \n",
      "\n",
      "Fold: 29  Epoch: 236  Training loss = 3.5249  Validation loss = 0.8177  \n",
      "\n",
      "Fold: 29  Epoch: 237  Training loss = 3.5247  Validation loss = 0.8177  \n",
      "\n",
      "Fold: 29  Epoch: 238  Training loss = 3.5246  Validation loss = 0.8177  \n",
      "\n",
      "Fold: 29  Epoch: 239  Training loss = 3.5245  Validation loss = 0.8176  \n",
      "\n",
      "Fold: 29  Epoch: 240  Training loss = 3.5244  Validation loss = 0.8176  \n",
      "\n",
      "Fold: 29  Epoch: 241  Training loss = 3.5243  Validation loss = 0.8174  \n",
      "\n",
      "Fold: 29  Epoch: 242  Training loss = 3.5241  Validation loss = 0.8174  \n",
      "\n",
      "Fold: 29  Epoch: 243  Training loss = 3.5239  Validation loss = 0.8172  \n",
      "\n",
      "Fold: 29  Epoch: 244  Training loss = 3.5238  Validation loss = 0.8172  \n",
      "\n",
      "Fold: 29  Epoch: 245  Training loss = 3.5237  Validation loss = 0.8173  \n",
      "\n",
      "Fold: 29  Epoch: 246  Training loss = 3.5236  Validation loss = 0.8173  \n",
      "\n",
      "Fold: 29  Epoch: 247  Training loss = 3.5235  Validation loss = 0.8172  \n",
      "\n",
      "Fold: 29  Epoch: 248  Training loss = 3.5234  Validation loss = 0.8172  \n",
      "\n",
      "Fold: 29  Epoch: 249  Training loss = 3.5233  Validation loss = 0.8171  \n",
      "\n",
      "Fold: 29  Epoch: 250  Training loss = 3.5232  Validation loss = 0.8170  \n",
      "\n",
      "Fold: 29  Epoch: 251  Training loss = 3.5230  Validation loss = 0.8170  \n",
      "\n",
      "Fold: 29  Epoch: 252  Training loss = 3.5228  Validation loss = 0.8169  \n",
      "\n",
      "Fold: 29  Epoch: 253  Training loss = 3.5227  Validation loss = 0.8169  \n",
      "\n",
      "Fold: 29  Epoch: 254  Training loss = 3.5225  Validation loss = 0.8168  \n",
      "\n",
      "Fold: 29  Epoch: 255  Training loss = 3.5224  Validation loss = 0.8168  \n",
      "\n",
      "Fold: 29  Epoch: 256  Training loss = 3.5222  Validation loss = 0.8167  \n",
      "\n",
      "Fold: 29  Epoch: 257  Training loss = 3.5221  Validation loss = 0.8166  \n",
      "\n",
      "Fold: 29  Epoch: 258  Training loss = 3.5220  Validation loss = 0.8166  \n",
      "\n",
      "Fold: 29  Epoch: 259  Training loss = 3.5219  Validation loss = 0.8166  \n",
      "\n",
      "Fold: 29  Epoch: 260  Training loss = 3.5217  Validation loss = 0.8166  \n",
      "\n",
      "Fold: 29  Epoch: 261  Training loss = 3.5215  Validation loss = 0.8165  \n",
      "\n",
      "Fold: 29  Epoch: 262  Training loss = 3.5214  Validation loss = 0.8165  \n",
      "\n",
      "Fold: 29  Epoch: 263  Training loss = 3.5212  Validation loss = 0.8163  \n",
      "\n",
      "Fold: 29  Epoch: 264  Training loss = 3.5211  Validation loss = 0.8163  \n",
      "\n",
      "Fold: 29  Epoch: 265  Training loss = 3.5210  Validation loss = 0.8161  \n",
      "\n",
      "Fold: 29  Epoch: 266  Training loss = 3.5209  Validation loss = 0.8160  \n",
      "\n",
      "Fold: 29  Epoch: 267  Training loss = 3.5208  Validation loss = 0.8159  \n",
      "\n",
      "Fold: 29  Epoch: 268  Training loss = 3.5207  Validation loss = 0.8158  \n",
      "\n",
      "Fold: 29  Epoch: 269  Training loss = 3.5206  Validation loss = 0.8157  \n",
      "\n",
      "Fold: 29  Epoch: 270  Training loss = 3.5204  Validation loss = 0.8157  \n",
      "\n",
      "Fold: 29  Epoch: 271  Training loss = 3.5203  Validation loss = 0.8156  \n",
      "\n",
      "Fold: 29  Epoch: 272  Training loss = 3.5202  Validation loss = 0.8156  \n",
      "\n",
      "Fold: 29  Epoch: 273  Training loss = 3.5200  Validation loss = 0.8155  \n",
      "\n",
      "Fold: 29  Epoch: 274  Training loss = 3.5198  Validation loss = 0.8155  \n",
      "\n",
      "Fold: 29  Epoch: 275  Training loss = 3.5197  Validation loss = 0.8154  \n",
      "\n",
      "Fold: 29  Epoch: 276  Training loss = 3.5196  Validation loss = 0.8154  \n",
      "\n",
      "Fold: 29  Epoch: 277  Training loss = 3.5194  Validation loss = 0.8153  \n",
      "\n",
      "Fold: 29  Epoch: 278  Training loss = 3.5192  Validation loss = 0.8153  \n",
      "\n",
      "Fold: 29  Epoch: 279  Training loss = 3.5191  Validation loss = 0.8152  \n",
      "\n",
      "Fold: 29  Epoch: 280  Training loss = 3.5190  Validation loss = 0.8151  \n",
      "\n",
      "Fold: 29  Epoch: 281  Training loss = 3.5189  Validation loss = 0.8151  \n",
      "\n",
      "Fold: 29  Epoch: 282  Training loss = 3.5187  Validation loss = 0.8150  \n",
      "\n",
      "Fold: 29  Epoch: 283  Training loss = 3.5186  Validation loss = 0.8150  \n",
      "\n",
      "Fold: 29  Epoch: 284  Training loss = 3.5185  Validation loss = 0.8150  \n",
      "\n",
      "Fold: 29  Epoch: 285  Training loss = 3.5184  Validation loss = 0.8149  \n",
      "\n",
      "Fold: 29  Epoch: 286  Training loss = 3.5182  Validation loss = 0.8148  \n",
      "\n",
      "Fold: 29  Epoch: 287  Training loss = 3.5180  Validation loss = 0.8148  \n",
      "\n",
      "Fold: 29  Epoch: 288  Training loss = 3.5180  Validation loss = 0.8147  \n",
      "\n",
      "Fold: 29  Epoch: 289  Training loss = 3.5178  Validation loss = 0.8146  \n",
      "\n",
      "Fold: 29  Epoch: 290  Training loss = 3.5177  Validation loss = 0.8147  \n",
      "\n",
      "Fold: 29  Epoch: 291  Training loss = 3.5175  Validation loss = 0.8147  \n",
      "\n",
      "Fold: 29  Epoch: 292  Training loss = 3.5174  Validation loss = 0.8146  \n",
      "\n",
      "Fold: 29  Epoch: 293  Training loss = 3.5173  Validation loss = 0.8145  \n",
      "\n",
      "Fold: 29  Epoch: 294  Training loss = 3.5172  Validation loss = 0.8144  \n",
      "\n",
      "Fold: 29  Epoch: 295  Training loss = 3.5170  Validation loss = 0.8143  \n",
      "\n",
      "Fold: 29  Epoch: 296  Training loss = 3.5170  Validation loss = 0.8143  \n",
      "\n",
      "Fold: 29  Epoch: 297  Training loss = 3.5168  Validation loss = 0.8142  \n",
      "\n",
      "Fold: 29  Epoch: 298  Training loss = 3.5167  Validation loss = 0.8141  \n",
      "\n",
      "Fold: 29  Epoch: 299  Training loss = 3.5166  Validation loss = 0.8140  \n",
      "\n",
      "Fold: 29  Epoch: 300  Training loss = 3.5164  Validation loss = 0.8139  \n",
      "\n",
      "Fold: 29  Epoch: 301  Training loss = 3.5163  Validation loss = 0.8139  \n",
      "\n",
      "Fold: 29  Epoch: 302  Training loss = 3.5162  Validation loss = 0.8138  \n",
      "\n",
      "Fold: 29  Epoch: 303  Training loss = 3.5161  Validation loss = 0.8139  \n",
      "\n",
      "Fold: 29  Epoch: 304  Training loss = 3.5159  Validation loss = 0.8139  \n",
      "\n",
      "Fold: 29  Epoch: 305  Training loss = 3.5158  Validation loss = 0.8139  \n",
      "\n",
      "Fold: 29  Epoch: 306  Training loss = 3.5157  Validation loss = 0.8138  \n",
      "\n",
      "Fold: 29  Epoch: 307  Training loss = 3.5156  Validation loss = 0.8138  \n",
      "\n",
      "Fold: 29  Epoch: 308  Training loss = 3.5154  Validation loss = 0.8138  \n",
      "\n",
      "Fold: 29  Epoch: 309  Training loss = 3.5153  Validation loss = 0.8137  \n",
      "\n",
      "Fold: 29  Epoch: 310  Training loss = 3.5151  Validation loss = 0.8136  \n",
      "\n",
      "Fold: 29  Epoch: 311  Training loss = 3.5149  Validation loss = 0.8135  \n",
      "\n",
      "Fold: 29  Epoch: 312  Training loss = 3.5147  Validation loss = 0.8134  \n",
      "\n",
      "Fold: 29  Epoch: 313  Training loss = 3.5146  Validation loss = 0.8133  \n",
      "\n",
      "Fold: 29  Epoch: 314  Training loss = 3.5144  Validation loss = 0.8133  \n",
      "\n",
      "Fold: 29  Epoch: 315  Training loss = 3.5143  Validation loss = 0.8132  \n",
      "\n",
      "Fold: 29  Epoch: 316  Training loss = 3.5142  Validation loss = 0.8131  \n",
      "\n",
      "Fold: 29  Epoch: 317  Training loss = 3.5141  Validation loss = 0.8131  \n",
      "\n",
      "Fold: 29  Epoch: 318  Training loss = 3.5139  Validation loss = 0.8131  \n",
      "\n",
      "Fold: 29  Epoch: 319  Training loss = 3.5138  Validation loss = 0.8130  \n",
      "\n",
      "Fold: 29  Epoch: 320  Training loss = 3.5136  Validation loss = 0.8130  \n",
      "\n",
      "Fold: 29  Epoch: 321  Training loss = 3.5135  Validation loss = 0.8128  \n",
      "\n",
      "Fold: 29  Epoch: 322  Training loss = 3.5133  Validation loss = 0.8129  \n",
      "\n",
      "Fold: 29  Epoch: 323  Training loss = 3.5132  Validation loss = 0.8129  \n",
      "\n",
      "Fold: 29  Epoch: 324  Training loss = 3.5131  Validation loss = 0.8130  \n",
      "\n",
      "Fold: 29  Epoch: 325  Training loss = 3.5129  Validation loss = 0.8128  \n",
      "\n",
      "Fold: 29  Epoch: 326  Training loss = 3.5128  Validation loss = 0.8127  \n",
      "\n",
      "Fold: 29  Epoch: 327  Training loss = 3.5126  Validation loss = 0.8127  \n",
      "\n",
      "Fold: 29  Epoch: 328  Training loss = 3.5125  Validation loss = 0.8127  \n",
      "\n",
      "Fold: 29  Epoch: 329  Training loss = 3.5123  Validation loss = 0.8126  \n",
      "\n",
      "Fold: 29  Epoch: 330  Training loss = 3.5122  Validation loss = 0.8126  \n",
      "\n",
      "Fold: 29  Epoch: 331  Training loss = 3.5120  Validation loss = 0.8125  \n",
      "\n",
      "Fold: 29  Epoch: 332  Training loss = 3.5119  Validation loss = 0.8125  \n",
      "\n",
      "Fold: 29  Epoch: 333  Training loss = 3.5117  Validation loss = 0.8124  \n",
      "\n",
      "Fold: 29  Epoch: 334  Training loss = 3.5116  Validation loss = 0.8124  \n",
      "\n",
      "Fold: 29  Epoch: 335  Training loss = 3.5115  Validation loss = 0.8122  \n",
      "\n",
      "Fold: 29  Epoch: 336  Training loss = 3.5114  Validation loss = 0.8122  \n",
      "\n",
      "Fold: 29  Epoch: 337  Training loss = 3.5113  Validation loss = 0.8121  \n",
      "\n",
      "Fold: 29  Epoch: 338  Training loss = 3.5111  Validation loss = 0.8120  \n",
      "\n",
      "Fold: 29  Epoch: 339  Training loss = 3.5110  Validation loss = 0.8119  \n",
      "\n",
      "Fold: 29  Epoch: 340  Training loss = 3.5109  Validation loss = 0.8118  \n",
      "\n",
      "Fold: 29  Epoch: 341  Training loss = 3.5108  Validation loss = 0.8117  \n",
      "\n",
      "Fold: 29  Epoch: 342  Training loss = 3.5107  Validation loss = 0.8117  \n",
      "\n",
      "Fold: 29  Epoch: 343  Training loss = 3.5105  Validation loss = 0.8116  \n",
      "\n",
      "Fold: 29  Epoch: 344  Training loss = 3.5104  Validation loss = 0.8116  \n",
      "\n",
      "Fold: 29  Epoch: 345  Training loss = 3.5103  Validation loss = 0.8115  \n",
      "\n",
      "Fold: 29  Epoch: 346  Training loss = 3.5101  Validation loss = 0.8114  \n",
      "\n",
      "Fold: 29  Epoch: 347  Training loss = 3.5099  Validation loss = 0.8114  \n",
      "\n",
      "Fold: 29  Epoch: 348  Training loss = 3.5098  Validation loss = 0.8113  \n",
      "\n",
      "Fold: 29  Epoch: 349  Training loss = 3.5096  Validation loss = 0.8111  \n",
      "\n",
      "Fold: 29  Epoch: 350  Training loss = 3.5095  Validation loss = 0.8111  \n",
      "\n",
      "Fold: 29  Epoch: 351  Training loss = 3.5093  Validation loss = 0.8112  \n",
      "\n",
      "Fold: 29  Epoch: 352  Training loss = 3.5093  Validation loss = 0.8111  \n",
      "\n",
      "Fold: 29  Epoch: 353  Training loss = 3.5091  Validation loss = 0.8110  \n",
      "\n",
      "Fold: 29  Epoch: 354  Training loss = 3.5090  Validation loss = 0.8109  \n",
      "\n",
      "Fold: 29  Epoch: 355  Training loss = 3.5089  Validation loss = 0.8108  \n",
      "\n",
      "Fold: 29  Epoch: 356  Training loss = 3.5088  Validation loss = 0.8106  \n",
      "\n",
      "Fold: 29  Epoch: 357  Training loss = 3.5086  Validation loss = 0.8106  \n",
      "\n",
      "Fold: 29  Epoch: 358  Training loss = 3.5085  Validation loss = 0.8106  \n",
      "\n",
      "Fold: 29  Epoch: 359  Training loss = 3.5084  Validation loss = 0.8106  \n",
      "\n",
      "Fold: 29  Epoch: 360  Training loss = 3.5082  Validation loss = 0.8105  \n",
      "\n",
      "Fold: 29  Epoch: 361  Training loss = 3.5081  Validation loss = 0.8105  \n",
      "\n",
      "Fold: 29  Epoch: 362  Training loss = 3.5080  Validation loss = 0.8105  \n",
      "\n",
      "Fold: 29  Epoch: 363  Training loss = 3.5079  Validation loss = 0.8104  \n",
      "\n",
      "Fold: 29  Epoch: 364  Training loss = 3.5077  Validation loss = 0.8104  \n",
      "\n",
      "Fold: 29  Epoch: 365  Training loss = 3.5076  Validation loss = 0.8103  \n",
      "\n",
      "Fold: 29  Epoch: 366  Training loss = 3.5075  Validation loss = 0.8103  \n",
      "\n",
      "Fold: 29  Epoch: 367  Training loss = 3.5074  Validation loss = 0.8102  \n",
      "\n",
      "Fold: 29  Epoch: 368  Training loss = 3.5072  Validation loss = 0.8102  \n",
      "\n",
      "Fold: 29  Epoch: 369  Training loss = 3.5071  Validation loss = 0.8102  \n",
      "\n",
      "Fold: 29  Epoch: 370  Training loss = 3.5070  Validation loss = 0.8101  \n",
      "\n",
      "Fold: 29  Epoch: 371  Training loss = 3.5068  Validation loss = 0.8101  \n",
      "\n",
      "Fold: 29  Epoch: 372  Training loss = 3.5067  Validation loss = 0.8100  \n",
      "\n",
      "Fold: 29  Epoch: 373  Training loss = 3.5066  Validation loss = 0.8099  \n",
      "\n",
      "Fold: 29  Epoch: 374  Training loss = 3.5064  Validation loss = 0.8099  \n",
      "\n",
      "Fold: 29  Epoch: 375  Training loss = 3.5063  Validation loss = 0.8099  \n",
      "\n",
      "Fold: 29  Epoch: 376  Training loss = 3.5062  Validation loss = 0.8099  \n",
      "\n",
      "Fold: 29  Epoch: 377  Training loss = 3.5060  Validation loss = 0.8099  \n",
      "\n",
      "Fold: 29  Epoch: 378  Training loss = 3.5059  Validation loss = 0.8098  \n",
      "\n",
      "Fold: 29  Epoch: 379  Training loss = 3.5057  Validation loss = 0.8098  \n",
      "\n",
      "Fold: 29  Epoch: 380  Training loss = 3.5056  Validation loss = 0.8098  \n",
      "\n",
      "Fold: 29  Epoch: 381  Training loss = 3.5055  Validation loss = 0.8099  \n",
      "\n",
      "Fold: 29  Epoch: 382  Training loss = 3.5052  Validation loss = 0.8098  \n",
      "\n",
      "Fold: 29  Epoch: 383  Training loss = 3.5051  Validation loss = 0.8097  \n",
      "\n",
      "Fold: 29  Epoch: 384  Training loss = 3.5050  Validation loss = 0.8096  \n",
      "\n",
      "Fold: 29  Epoch: 385  Training loss = 3.5048  Validation loss = 0.8095  \n",
      "\n",
      "Fold: 29  Epoch: 386  Training loss = 3.5047  Validation loss = 0.8094  \n",
      "\n",
      "Fold: 29  Epoch: 387  Training loss = 3.5046  Validation loss = 0.8094  \n",
      "\n",
      "Fold: 29  Epoch: 388  Training loss = 3.5045  Validation loss = 0.8094  \n",
      "\n",
      "Fold: 29  Epoch: 389  Training loss = 3.5043  Validation loss = 0.8094  \n",
      "\n",
      "Fold: 29  Epoch: 390  Training loss = 3.5042  Validation loss = 0.8094  \n",
      "\n",
      "Fold: 29  Epoch: 391  Training loss = 3.5040  Validation loss = 0.8093  \n",
      "\n",
      "Fold: 29  Epoch: 392  Training loss = 3.5039  Validation loss = 0.8094  \n",
      "\n",
      "Fold: 29  Epoch: 393  Training loss = 3.5037  Validation loss = 0.8094  \n",
      "\n",
      "Fold: 29  Epoch: 394  Training loss = 3.5035  Validation loss = 0.8092  \n",
      "\n",
      "Fold: 29  Epoch: 395  Training loss = 3.5034  Validation loss = 0.8092  \n",
      "\n",
      "Fold: 29  Epoch: 396  Training loss = 3.5032  Validation loss = 0.8092  \n",
      "\n",
      "Fold: 29  Epoch: 397  Training loss = 3.5031  Validation loss = 0.8091  \n",
      "\n",
      "Fold: 29  Epoch: 398  Training loss = 3.5029  Validation loss = 0.8090  \n",
      "\n",
      "Fold: 29  Epoch: 399  Training loss = 3.5028  Validation loss = 0.8091  \n",
      "\n",
      "Fold: 29  Epoch: 400  Training loss = 3.5026  Validation loss = 0.8090  \n",
      "\n",
      "Fold: 29  Epoch: 401  Training loss = 3.5025  Validation loss = 0.8089  \n",
      "\n",
      "Fold: 29  Epoch: 402  Training loss = 3.5024  Validation loss = 0.8089  \n",
      "\n",
      "Fold: 29  Epoch: 403  Training loss = 3.5022  Validation loss = 0.8087  \n",
      "\n",
      "Fold: 29  Epoch: 404  Training loss = 3.5021  Validation loss = 0.8087  \n",
      "\n",
      "Fold: 29  Epoch: 405  Training loss = 3.5019  Validation loss = 0.8087  \n",
      "\n",
      "Fold: 29  Epoch: 406  Training loss = 3.5019  Validation loss = 0.8086  \n",
      "\n",
      "Fold: 29  Epoch: 407  Training loss = 3.5017  Validation loss = 0.8087  \n",
      "\n",
      "Fold: 29  Epoch: 408  Training loss = 3.5016  Validation loss = 0.8088  \n",
      "\n",
      "Fold: 29  Epoch: 409  Training loss = 3.5014  Validation loss = 0.8087  \n",
      "\n",
      "Fold: 29  Epoch: 410  Training loss = 3.5012  Validation loss = 0.8087  \n",
      "\n",
      "Fold: 29  Epoch: 411  Training loss = 3.5011  Validation loss = 0.8086  \n",
      "\n",
      "Fold: 29  Epoch: 412  Training loss = 3.5010  Validation loss = 0.8086  \n",
      "\n",
      "Fold: 29  Epoch: 413  Training loss = 3.5008  Validation loss = 0.8085  \n",
      "\n",
      "Fold: 29  Epoch: 414  Training loss = 3.5006  Validation loss = 0.8084  \n",
      "\n",
      "Fold: 29  Epoch: 415  Training loss = 3.5005  Validation loss = 0.8084  \n",
      "\n",
      "Fold: 29  Epoch: 416  Training loss = 3.5003  Validation loss = 0.8084  \n",
      "\n",
      "Fold: 29  Epoch: 417  Training loss = 3.5002  Validation loss = 0.8083  \n",
      "\n",
      "Fold: 29  Epoch: 418  Training loss = 3.5000  Validation loss = 0.8083  \n",
      "\n",
      "Fold: 29  Epoch: 419  Training loss = 3.4998  Validation loss = 0.8082  \n",
      "\n",
      "Fold: 29  Epoch: 420  Training loss = 3.4997  Validation loss = 0.8082  \n",
      "\n",
      "Fold: 29  Epoch: 421  Training loss = 3.4995  Validation loss = 0.8082  \n",
      "\n",
      "Fold: 29  Epoch: 422  Training loss = 3.4994  Validation loss = 0.8082  \n",
      "\n",
      "Fold: 29  Epoch: 423  Training loss = 3.4993  Validation loss = 0.8082  \n",
      "\n",
      "Fold: 29  Epoch: 424  Training loss = 3.4991  Validation loss = 0.8081  \n",
      "\n",
      "Fold: 29  Epoch: 425  Training loss = 3.4989  Validation loss = 0.8081  \n",
      "\n",
      "Fold: 29  Epoch: 426  Training loss = 3.4987  Validation loss = 0.8080  \n",
      "\n",
      "Fold: 29  Epoch: 427  Training loss = 3.4986  Validation loss = 0.8079  \n",
      "\n",
      "Fold: 29  Epoch: 428  Training loss = 3.4984  Validation loss = 0.8079  \n",
      "\n",
      "Fold: 29  Epoch: 429  Training loss = 3.4982  Validation loss = 0.8080  \n",
      "\n",
      "Fold: 29  Epoch: 430  Training loss = 3.4981  Validation loss = 0.8079  \n",
      "\n",
      "Fold: 29  Epoch: 431  Training loss = 3.4979  Validation loss = 0.8078  \n",
      "\n",
      "Fold: 29  Epoch: 432  Training loss = 3.4977  Validation loss = 0.8078  \n",
      "\n",
      "Fold: 29  Epoch: 433  Training loss = 3.4976  Validation loss = 0.8077  \n",
      "\n",
      "Fold: 29  Epoch: 434  Training loss = 3.4974  Validation loss = 0.8076  \n",
      "\n",
      "Fold: 29  Epoch: 435  Training loss = 3.4972  Validation loss = 0.8074  \n",
      "\n",
      "Fold: 29  Epoch: 436  Training loss = 3.4971  Validation loss = 0.8074  \n",
      "\n",
      "Fold: 29  Epoch: 437  Training loss = 3.4970  Validation loss = 0.8074  \n",
      "\n",
      "Fold: 29  Epoch: 438  Training loss = 3.4967  Validation loss = 0.8073  \n",
      "\n",
      "Fold: 29  Epoch: 439  Training loss = 3.4965  Validation loss = 0.8072  \n",
      "\n",
      "Fold: 29  Epoch: 440  Training loss = 3.4964  Validation loss = 0.8071  \n",
      "\n",
      "Fold: 29  Epoch: 441  Training loss = 3.4962  Validation loss = 0.8071  \n",
      "\n",
      "Fold: 29  Epoch: 442  Training loss = 3.4960  Validation loss = 0.8069  \n",
      "\n",
      "Fold: 29  Epoch: 443  Training loss = 3.4958  Validation loss = 0.8069  \n",
      "\n",
      "Fold: 29  Epoch: 444  Training loss = 3.4955  Validation loss = 0.8068  \n",
      "\n",
      "Fold: 29  Epoch: 445  Training loss = 3.4954  Validation loss = 0.8067  \n",
      "\n",
      "Fold: 29  Epoch: 446  Training loss = 3.4951  Validation loss = 0.8067  \n",
      "\n",
      "Fold: 29  Epoch: 447  Training loss = 3.4947  Validation loss = 0.8065  \n",
      "\n",
      "Fold: 29  Epoch: 448  Training loss = 3.4945  Validation loss = 0.8065  \n",
      "\n",
      "Fold: 29  Epoch: 449  Training loss = 3.4944  Validation loss = 0.8065  \n",
      "\n",
      "Fold: 29  Epoch: 450  Training loss = 3.4942  Validation loss = 0.8065  \n",
      "\n",
      "Fold: 29  Epoch: 451  Training loss = 3.4941  Validation loss = 0.8065  \n",
      "\n",
      "Fold: 29  Epoch: 452  Training loss = 3.4938  Validation loss = 0.8064  \n",
      "\n",
      "Fold: 29  Epoch: 453  Training loss = 3.4937  Validation loss = 0.8063  \n",
      "\n",
      "Fold: 29  Epoch: 454  Training loss = 3.4934  Validation loss = 0.8063  \n",
      "\n",
      "Fold: 29  Epoch: 455  Training loss = 3.4932  Validation loss = 0.8062  \n",
      "\n",
      "Fold: 29  Epoch: 456  Training loss = 3.4931  Validation loss = 0.8062  \n",
      "\n",
      "Fold: 29  Epoch: 457  Training loss = 3.4929  Validation loss = 0.8063  \n",
      "\n",
      "Fold: 29  Epoch: 458  Training loss = 3.4928  Validation loss = 0.8062  \n",
      "\n",
      "Fold: 29  Epoch: 459  Training loss = 3.4927  Validation loss = 0.8062  \n",
      "\n",
      "Fold: 29  Epoch: 460  Training loss = 3.4925  Validation loss = 0.8062  \n",
      "\n",
      "Fold: 29  Epoch: 461  Training loss = 3.4923  Validation loss = 0.8062  \n",
      "\n",
      "Fold: 29  Epoch: 462  Training loss = 3.4922  Validation loss = 0.8063  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 459  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 3.4287  Validation loss = 1.7190  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 3.4286  Validation loss = 1.7194  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 3.4284  Validation loss = 1.7183  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.4282  Validation loss = 1.7176  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.4280  Validation loss = 1.7166  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.4279  Validation loss = 1.7170  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 3.4278  Validation loss = 1.7169  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 3.4276  Validation loss = 1.7157  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.4274  Validation loss = 1.7160  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 3.4273  Validation loss = 1.7154  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.4272  Validation loss = 1.7152  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 3.4271  Validation loss = 1.7134  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 3.4269  Validation loss = 1.7120  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 3.4268  Validation loss = 1.7123  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 3.4267  Validation loss = 1.7117  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 3.4266  Validation loss = 1.7113  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 3.4264  Validation loss = 1.7099  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 3.4263  Validation loss = 1.7105  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 3.4262  Validation loss = 1.7101  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 3.4261  Validation loss = 1.7108  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 3.4259  Validation loss = 1.7103  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 3.4259  Validation loss = 1.7096  \n",
      "\n",
      "Fold: 30  Epoch: 23  Training loss = 3.4258  Validation loss = 1.7095  \n",
      "\n",
      "Fold: 30  Epoch: 24  Training loss = 3.4257  Validation loss = 1.7087  \n",
      "\n",
      "Fold: 30  Epoch: 25  Training loss = 3.4256  Validation loss = 1.7084  \n",
      "\n",
      "Fold: 30  Epoch: 26  Training loss = 3.4255  Validation loss = 1.7080  \n",
      "\n",
      "Fold: 30  Epoch: 27  Training loss = 3.4255  Validation loss = 1.7078  \n",
      "\n",
      "Fold: 30  Epoch: 28  Training loss = 3.4254  Validation loss = 1.7075  \n",
      "\n",
      "Fold: 30  Epoch: 29  Training loss = 3.4253  Validation loss = 1.7065  \n",
      "\n",
      "Fold: 30  Epoch: 30  Training loss = 3.4252  Validation loss = 1.7068  \n",
      "\n",
      "Fold: 30  Epoch: 31  Training loss = 3.4251  Validation loss = 1.7074  \n",
      "\n",
      "Fold: 30  Epoch: 32  Training loss = 3.4249  Validation loss = 1.7084  \n",
      "\n",
      "Fold: 30  Epoch: 33  Training loss = 3.4249  Validation loss = 1.7081  \n",
      "\n",
      "Fold: 30  Epoch: 34  Training loss = 3.4248  Validation loss = 1.7066  \n",
      "\n",
      "Fold: 30  Epoch: 35  Training loss = 3.4247  Validation loss = 1.7066  \n",
      "\n",
      "Fold: 30  Epoch: 36  Training loss = 3.4246  Validation loss = 1.7056  \n",
      "\n",
      "Fold: 30  Epoch: 37  Training loss = 3.4244  Validation loss = 1.7071  \n",
      "\n",
      "Fold: 30  Epoch: 38  Training loss = 3.4244  Validation loss = 1.7066  \n",
      "\n",
      "Fold: 30  Epoch: 39  Training loss = 3.4243  Validation loss = 1.7069  \n",
      "\n",
      "Fold: 30  Epoch: 40  Training loss = 3.4242  Validation loss = 1.7072  \n",
      "\n",
      "Fold: 30  Epoch: 41  Training loss = 3.4241  Validation loss = 1.7075  \n",
      "\n",
      "Fold: 30  Epoch: 42  Training loss = 3.4240  Validation loss = 1.7092  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 36  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 3.0939  Validation loss = 1.1859  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 3.0938  Validation loss = 1.1853  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 3.0937  Validation loss = 1.1859  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 3.0935  Validation loss = 1.1857  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 3.0935  Validation loss = 1.1858  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 3.0934  Validation loss = 1.1860  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 3.0934  Validation loss = 1.1857  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 3.0933  Validation loss = 1.1858  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 3.0932  Validation loss = 1.1851  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 3.0932  Validation loss = 1.1846  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 3.0931  Validation loss = 1.1848  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 3.0931  Validation loss = 1.1848  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 3.0930  Validation loss = 1.1847  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 3.0929  Validation loss = 1.1842  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 3.0928  Validation loss = 1.1844  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 3.0928  Validation loss = 1.1845  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 3.0928  Validation loss = 1.1842  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 3.0927  Validation loss = 1.1836  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 3.0926  Validation loss = 1.1833  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 3.0926  Validation loss = 1.1838  \n",
      "\n",
      "Fold: 31  Epoch: 21  Training loss = 3.0925  Validation loss = 1.1840  \n",
      "\n",
      "Fold: 31  Epoch: 22  Training loss = 3.0925  Validation loss = 1.1841  \n",
      "\n",
      "Fold: 31  Epoch: 23  Training loss = 3.0924  Validation loss = 1.1835  \n",
      "\n",
      "Fold: 31  Epoch: 24  Training loss = 3.0924  Validation loss = 1.1838  \n",
      "\n",
      "Fold: 31  Epoch: 25  Training loss = 3.0923  Validation loss = 1.1836  \n",
      "\n",
      "Fold: 31  Epoch: 26  Training loss = 3.0923  Validation loss = 1.1837  \n",
      "\n",
      "Fold: 31  Epoch: 27  Training loss = 3.0922  Validation loss = 1.1831  \n",
      "\n",
      "Fold: 31  Epoch: 28  Training loss = 3.0921  Validation loss = 1.1831  \n",
      "\n",
      "Fold: 31  Epoch: 29  Training loss = 3.0920  Validation loss = 1.1834  \n",
      "\n",
      "Fold: 31  Epoch: 30  Training loss = 3.0920  Validation loss = 1.1836  \n",
      "\n",
      "Fold: 31  Epoch: 31  Training loss = 3.0919  Validation loss = 1.1833  \n",
      "\n",
      "Fold: 31  Epoch: 32  Training loss = 3.0918  Validation loss = 1.1833  \n",
      "\n",
      "Fold: 31  Epoch: 33  Training loss = 3.0917  Validation loss = 1.1830  \n",
      "\n",
      "Fold: 31  Epoch: 34  Training loss = 3.0917  Validation loss = 1.1822  \n",
      "\n",
      "Fold: 31  Epoch: 35  Training loss = 3.0917  Validation loss = 1.1832  \n",
      "\n",
      "Fold: 31  Epoch: 36  Training loss = 3.0916  Validation loss = 1.1839  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 34  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.3291  Validation loss = 2.7842  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.3290  Validation loss = 2.7836  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 2.3286  Validation loss = 2.7794  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.3284  Validation loss = 2.7765  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.3282  Validation loss = 2.7744  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 2.3281  Validation loss = 2.7740  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.3280  Validation loss = 2.7736  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.3279  Validation loss = 2.7724  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.3277  Validation loss = 2.7706  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.3276  Validation loss = 2.7701  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.3275  Validation loss = 2.7684  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.3272  Validation loss = 2.7663  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 2.3271  Validation loss = 2.7657  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 2.3270  Validation loss = 2.7643  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 2.3268  Validation loss = 2.7613  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 2.3267  Validation loss = 2.7604  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 2.3264  Validation loss = 2.7569  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 2.3262  Validation loss = 2.7538  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 2.3261  Validation loss = 2.7527  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 2.3259  Validation loss = 2.7513  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 2.3259  Validation loss = 2.7527  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 2.3259  Validation loss = 2.7524  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 2.3257  Validation loss = 2.7504  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 2.3257  Validation loss = 2.7521  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 2.3257  Validation loss = 2.7518  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 2.3255  Validation loss = 2.7505  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 2.3254  Validation loss = 2.7496  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 2.3252  Validation loss = 2.7463  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 2.3250  Validation loss = 2.7432  \n",
      "\n",
      "Fold: 32  Epoch: 30  Training loss = 2.3251  Validation loss = 2.7460  \n",
      "\n",
      "Fold: 32  Epoch: 31  Training loss = 2.3250  Validation loss = 2.7459  \n",
      "\n",
      "Fold: 32  Epoch: 32  Training loss = 2.3249  Validation loss = 2.7448  \n",
      "\n",
      "Fold: 32  Epoch: 33  Training loss = 2.3247  Validation loss = 2.7423  \n",
      "\n",
      "Fold: 32  Epoch: 34  Training loss = 2.3247  Validation loss = 2.7418  \n",
      "\n",
      "Fold: 32  Epoch: 35  Training loss = 2.3245  Validation loss = 2.7391  \n",
      "\n",
      "Fold: 32  Epoch: 36  Training loss = 2.3246  Validation loss = 2.7407  \n",
      "\n",
      "Fold: 32  Epoch: 37  Training loss = 2.3246  Validation loss = 2.7426  \n",
      "\n",
      "Fold: 32  Epoch: 38  Training loss = 2.3244  Validation loss = 2.7392  \n",
      "\n",
      "Fold: 32  Epoch: 39  Training loss = 2.3242  Validation loss = 2.7356  \n",
      "\n",
      "Fold: 32  Epoch: 40  Training loss = 2.3243  Validation loss = 2.7386  \n",
      "\n",
      "Fold: 32  Epoch: 41  Training loss = 2.3242  Validation loss = 2.7387  \n",
      "\n",
      "Fold: 32  Epoch: 42  Training loss = 2.3242  Validation loss = 2.7382  \n",
      "\n",
      "Fold: 32  Epoch: 43  Training loss = 2.3242  Validation loss = 2.7401  \n",
      "\n",
      "Fold: 32  Epoch: 44  Training loss = 2.3242  Validation loss = 2.7406  \n",
      "\n",
      "Fold: 32  Epoch: 45  Training loss = 2.3240  Validation loss = 2.7382  \n",
      "\n",
      "Fold: 32  Epoch: 46  Training loss = 2.3239  Validation loss = 2.7362  \n",
      "\n",
      "Fold: 32  Epoch: 47  Training loss = 2.3238  Validation loss = 2.7349  \n",
      "\n",
      "Fold: 32  Epoch: 48  Training loss = 2.3238  Validation loss = 2.7365  \n",
      "\n",
      "Fold: 32  Epoch: 49  Training loss = 2.3238  Validation loss = 2.7371  \n",
      "\n",
      "Fold: 32  Epoch: 50  Training loss = 2.3237  Validation loss = 2.7356  \n",
      "\n",
      "Fold: 32  Epoch: 51  Training loss = 2.3236  Validation loss = 2.7344  \n",
      "\n",
      "Fold: 32  Epoch: 52  Training loss = 2.3235  Validation loss = 2.7340  \n",
      "\n",
      "Fold: 32  Epoch: 53  Training loss = 2.3233  Validation loss = 2.7301  \n",
      "\n",
      "Fold: 32  Epoch: 54  Training loss = 2.3231  Validation loss = 2.7280  \n",
      "\n",
      "Fold: 32  Epoch: 55  Training loss = 2.3229  Validation loss = 2.7247  \n",
      "\n",
      "Fold: 32  Epoch: 56  Training loss = 2.3228  Validation loss = 2.7213  \n",
      "\n",
      "Fold: 32  Epoch: 57  Training loss = 2.3227  Validation loss = 2.7218  \n",
      "\n",
      "Fold: 32  Epoch: 58  Training loss = 2.3226  Validation loss = 2.7195  \n",
      "\n",
      "Fold: 32  Epoch: 59  Training loss = 2.3225  Validation loss = 2.7193  \n",
      "\n",
      "Fold: 32  Epoch: 60  Training loss = 2.3224  Validation loss = 2.7185  \n",
      "\n",
      "Fold: 32  Epoch: 61  Training loss = 2.3223  Validation loss = 2.7163  \n",
      "\n",
      "Fold: 32  Epoch: 62  Training loss = 2.3223  Validation loss = 2.7170  \n",
      "\n",
      "Fold: 32  Epoch: 63  Training loss = 2.3222  Validation loss = 2.7159  \n",
      "\n",
      "Fold: 32  Epoch: 64  Training loss = 2.3219  Validation loss = 2.7104  \n",
      "\n",
      "Fold: 32  Epoch: 65  Training loss = 2.3218  Validation loss = 2.7084  \n",
      "\n",
      "Fold: 32  Epoch: 66  Training loss = 2.3217  Validation loss = 2.7084  \n",
      "\n",
      "Fold: 32  Epoch: 67  Training loss = 2.3216  Validation loss = 2.7064  \n",
      "\n",
      "Fold: 32  Epoch: 68  Training loss = 2.3214  Validation loss = 2.7028  \n",
      "\n",
      "Fold: 32  Epoch: 69  Training loss = 2.3214  Validation loss = 2.7035  \n",
      "\n",
      "Fold: 32  Epoch: 70  Training loss = 2.3212  Validation loss = 2.6994  \n",
      "\n",
      "Fold: 32  Epoch: 71  Training loss = 2.3211  Validation loss = 2.6987  \n",
      "\n",
      "Fold: 32  Epoch: 72  Training loss = 2.3211  Validation loss = 2.6980  \n",
      "\n",
      "Fold: 32  Epoch: 73  Training loss = 2.3209  Validation loss = 2.6948  \n",
      "\n",
      "Fold: 32  Epoch: 74  Training loss = 2.3208  Validation loss = 2.6936  \n",
      "\n",
      "Fold: 32  Epoch: 75  Training loss = 2.3206  Validation loss = 2.6905  \n",
      "\n",
      "Fold: 32  Epoch: 76  Training loss = 2.3205  Validation loss = 2.6904  \n",
      "\n",
      "Fold: 32  Epoch: 77  Training loss = 2.3205  Validation loss = 2.6898  \n",
      "\n",
      "Fold: 32  Epoch: 78  Training loss = 2.3204  Validation loss = 2.6891  \n",
      "\n",
      "Fold: 32  Epoch: 79  Training loss = 2.3202  Validation loss = 2.6839  \n",
      "\n",
      "Fold: 32  Epoch: 80  Training loss = 2.3200  Validation loss = 2.6814  \n",
      "\n",
      "Fold: 32  Epoch: 81  Training loss = 2.3200  Validation loss = 2.6813  \n",
      "\n",
      "Fold: 32  Epoch: 82  Training loss = 2.3197  Validation loss = 2.6758  \n",
      "\n",
      "Fold: 32  Epoch: 83  Training loss = 2.3195  Validation loss = 2.6708  \n",
      "\n",
      "Fold: 32  Epoch: 84  Training loss = 2.3193  Validation loss = 2.6662  \n",
      "\n",
      "Fold: 32  Epoch: 85  Training loss = 2.3192  Validation loss = 2.6636  \n",
      "\n",
      "Fold: 32  Epoch: 86  Training loss = 2.3190  Validation loss = 2.6606  \n",
      "\n",
      "Fold: 32  Epoch: 87  Training loss = 2.3188  Validation loss = 2.6553  \n",
      "\n",
      "Fold: 32  Epoch: 88  Training loss = 2.3186  Validation loss = 2.6519  \n",
      "\n",
      "Fold: 32  Epoch: 89  Training loss = 2.3184  Validation loss = 2.6472  \n",
      "\n",
      "Fold: 32  Epoch: 90  Training loss = 2.3183  Validation loss = 2.6454  \n",
      "\n",
      "Fold: 32  Epoch: 91  Training loss = 2.3182  Validation loss = 2.6450  \n",
      "\n",
      "Fold: 32  Epoch: 92  Training loss = 2.3180  Validation loss = 2.6415  \n",
      "\n",
      "Fold: 32  Epoch: 93  Training loss = 2.3176  Validation loss = 2.6334  \n",
      "\n",
      "Fold: 32  Epoch: 94  Training loss = 2.3175  Validation loss = 2.6324  \n",
      "\n",
      "Fold: 32  Epoch: 95  Training loss = 2.3172  Validation loss = 2.6263  \n",
      "\n",
      "Fold: 32  Epoch: 96  Training loss = 2.3171  Validation loss = 2.6234  \n",
      "\n",
      "Fold: 32  Epoch: 97  Training loss = 2.3169  Validation loss = 2.6199  \n",
      "\n",
      "Fold: 32  Epoch: 98  Training loss = 2.3167  Validation loss = 2.6162  \n",
      "\n",
      "Fold: 32  Epoch: 99  Training loss = 2.3164  Validation loss = 2.6113  \n",
      "\n",
      "Fold: 32  Epoch: 100  Training loss = 2.3163  Validation loss = 2.6102  \n",
      "\n",
      "Fold: 32  Epoch: 101  Training loss = 2.3160  Validation loss = 2.6033  \n",
      "\n",
      "Fold: 32  Epoch: 102  Training loss = 2.3159  Validation loss = 2.6023  \n",
      "\n",
      "Fold: 32  Epoch: 103  Training loss = 2.3156  Validation loss = 2.5959  \n",
      "\n",
      "Fold: 32  Epoch: 104  Training loss = 2.3154  Validation loss = 2.5921  \n",
      "\n",
      "Fold: 32  Epoch: 105  Training loss = 2.3152  Validation loss = 2.5891  \n",
      "\n",
      "Fold: 32  Epoch: 106  Training loss = 2.3149  Validation loss = 2.5828  \n",
      "\n",
      "Fold: 32  Epoch: 107  Training loss = 2.3146  Validation loss = 2.5755  \n",
      "\n",
      "Fold: 32  Epoch: 108  Training loss = 2.3142  Validation loss = 2.5677  \n",
      "\n",
      "Fold: 32  Epoch: 109  Training loss = 2.3141  Validation loss = 2.5672  \n",
      "\n",
      "Fold: 32  Epoch: 110  Training loss = 2.3137  Validation loss = 2.5589  \n",
      "\n",
      "Fold: 32  Epoch: 111  Training loss = 2.3133  Validation loss = 2.5506  \n",
      "\n",
      "Fold: 32  Epoch: 112  Training loss = 2.3131  Validation loss = 2.5471  \n",
      "\n",
      "Fold: 32  Epoch: 113  Training loss = 2.3128  Validation loss = 2.5410  \n",
      "\n",
      "Fold: 32  Epoch: 114  Training loss = 2.3126  Validation loss = 2.5362  \n",
      "\n",
      "Fold: 32  Epoch: 115  Training loss = 2.3122  Validation loss = 2.5277  \n",
      "\n",
      "Fold: 32  Epoch: 116  Training loss = 2.3118  Validation loss = 2.5207  \n",
      "\n",
      "Fold: 32  Epoch: 117  Training loss = 2.3115  Validation loss = 2.5141  \n",
      "\n",
      "Fold: 32  Epoch: 118  Training loss = 2.3114  Validation loss = 2.5124  \n",
      "\n",
      "Fold: 32  Epoch: 119  Training loss = 2.3109  Validation loss = 2.5024  \n",
      "\n",
      "Fold: 32  Epoch: 120  Training loss = 2.3108  Validation loss = 2.5022  \n",
      "\n",
      "Fold: 32  Epoch: 121  Training loss = 2.3107  Validation loss = 2.5003  \n",
      "\n",
      "Fold: 32  Epoch: 122  Training loss = 2.3102  Validation loss = 2.4902  \n",
      "\n",
      "Fold: 32  Epoch: 123  Training loss = 2.3099  Validation loss = 2.4836  \n",
      "\n",
      "Fold: 32  Epoch: 124  Training loss = 2.3098  Validation loss = 2.4827  \n",
      "\n",
      "Fold: 32  Epoch: 125  Training loss = 2.3094  Validation loss = 2.4742  \n",
      "\n",
      "Fold: 32  Epoch: 126  Training loss = 2.3091  Validation loss = 2.4680  \n",
      "\n",
      "Fold: 32  Epoch: 127  Training loss = 2.3086  Validation loss = 2.4584  \n",
      "\n",
      "Fold: 32  Epoch: 128  Training loss = 2.3085  Validation loss = 2.4553  \n",
      "\n",
      "Fold: 32  Epoch: 129  Training loss = 2.3082  Validation loss = 2.4489  \n",
      "\n",
      "Fold: 32  Epoch: 130  Training loss = 2.3079  Validation loss = 2.4433  \n",
      "\n",
      "Fold: 32  Epoch: 131  Training loss = 2.3074  Validation loss = 2.4308  \n",
      "\n",
      "Fold: 32  Epoch: 132  Training loss = 2.3070  Validation loss = 2.4240  \n",
      "\n",
      "Fold: 32  Epoch: 133  Training loss = 2.3068  Validation loss = 2.4200  \n",
      "\n",
      "Fold: 32  Epoch: 134  Training loss = 2.3065  Validation loss = 2.4140  \n",
      "\n",
      "Fold: 32  Epoch: 135  Training loss = 2.3062  Validation loss = 2.4087  \n",
      "\n",
      "Fold: 32  Epoch: 136  Training loss = 2.3060  Validation loss = 2.4041  \n",
      "\n",
      "Fold: 32  Epoch: 137  Training loss = 2.3057  Validation loss = 2.3986  \n",
      "\n",
      "Fold: 32  Epoch: 138  Training loss = 2.3054  Validation loss = 2.3910  \n",
      "\n",
      "Fold: 32  Epoch: 139  Training loss = 2.3050  Validation loss = 2.3810  \n",
      "\n",
      "Fold: 32  Epoch: 140  Training loss = 2.3045  Validation loss = 2.3705  \n",
      "\n",
      "Fold: 32  Epoch: 141  Training loss = 2.3043  Validation loss = 2.3660  \n",
      "\n",
      "Fold: 32  Epoch: 142  Training loss = 2.3042  Validation loss = 2.3649  \n",
      "\n",
      "Fold: 32  Epoch: 143  Training loss = 2.3038  Validation loss = 2.3545  \n",
      "\n",
      "Fold: 32  Epoch: 144  Training loss = 2.3036  Validation loss = 2.3492  \n",
      "\n",
      "Fold: 32  Epoch: 145  Training loss = 2.3033  Validation loss = 2.3423  \n",
      "\n",
      "Fold: 32  Epoch: 146  Training loss = 2.3031  Validation loss = 2.3372  \n",
      "\n",
      "Fold: 32  Epoch: 147  Training loss = 2.3030  Validation loss = 2.3352  \n",
      "\n",
      "Fold: 32  Epoch: 148  Training loss = 2.3027  Validation loss = 2.3280  \n",
      "\n",
      "Fold: 32  Epoch: 149  Training loss = 2.3025  Validation loss = 2.3221  \n",
      "\n",
      "Fold: 32  Epoch: 150  Training loss = 2.3022  Validation loss = 2.3160  \n",
      "\n",
      "Fold: 32  Epoch: 151  Training loss = 2.3019  Validation loss = 2.3090  \n",
      "\n",
      "Fold: 32  Epoch: 152  Training loss = 2.3018  Validation loss = 2.3063  \n",
      "\n",
      "Fold: 32  Epoch: 153  Training loss = 2.3015  Validation loss = 2.3018  \n",
      "\n",
      "Fold: 32  Epoch: 154  Training loss = 2.3013  Validation loss = 2.2962  \n",
      "\n",
      "Fold: 32  Epoch: 155  Training loss = 2.3012  Validation loss = 2.2932  \n",
      "\n",
      "Fold: 32  Epoch: 156  Training loss = 2.3011  Validation loss = 2.2907  \n",
      "\n",
      "Fold: 32  Epoch: 157  Training loss = 2.3008  Validation loss = 2.2808  \n",
      "\n",
      "Fold: 32  Epoch: 158  Training loss = 2.3005  Validation loss = 2.2740  \n",
      "\n",
      "Fold: 32  Epoch: 159  Training loss = 2.3003  Validation loss = 2.2694  \n",
      "\n",
      "Fold: 32  Epoch: 160  Training loss = 2.3001  Validation loss = 2.2646  \n",
      "\n",
      "Fold: 32  Epoch: 161  Training loss = 2.2999  Validation loss = 2.2605  \n",
      "\n",
      "Fold: 32  Epoch: 162  Training loss = 2.2998  Validation loss = 2.2584  \n",
      "\n",
      "Fold: 32  Epoch: 163  Training loss = 2.2996  Validation loss = 2.2549  \n",
      "\n",
      "Fold: 32  Epoch: 164  Training loss = 2.2996  Validation loss = 2.2565  \n",
      "\n",
      "Fold: 32  Epoch: 165  Training loss = 2.2995  Validation loss = 2.2547  \n",
      "\n",
      "Fold: 32  Epoch: 166  Training loss = 2.2992  Validation loss = 2.2465  \n",
      "\n",
      "Fold: 32  Epoch: 167  Training loss = 2.2991  Validation loss = 2.2428  \n",
      "\n",
      "Fold: 32  Epoch: 168  Training loss = 2.2990  Validation loss = 2.2387  \n",
      "\n",
      "Fold: 32  Epoch: 169  Training loss = 2.2989  Validation loss = 2.2376  \n",
      "\n",
      "Fold: 32  Epoch: 170  Training loss = 2.2988  Validation loss = 2.2372  \n",
      "\n",
      "Fold: 32  Epoch: 171  Training loss = 2.2987  Validation loss = 2.2352  \n",
      "\n",
      "Fold: 32  Epoch: 172  Training loss = 2.2986  Validation loss = 2.2339  \n",
      "\n",
      "Fold: 32  Epoch: 173  Training loss = 2.2985  Validation loss = 2.2322  \n",
      "\n",
      "Fold: 32  Epoch: 174  Training loss = 2.2983  Validation loss = 2.2268  \n",
      "\n",
      "Fold: 32  Epoch: 175  Training loss = 2.2982  Validation loss = 2.2220  \n",
      "\n",
      "Fold: 32  Epoch: 176  Training loss = 2.2981  Validation loss = 2.2219  \n",
      "\n",
      "Fold: 32  Epoch: 177  Training loss = 2.2980  Validation loss = 2.2191  \n",
      "\n",
      "Fold: 32  Epoch: 178  Training loss = 2.2979  Validation loss = 2.2169  \n",
      "\n",
      "Fold: 32  Epoch: 179  Training loss = 2.2976  Validation loss = 2.2094  \n",
      "\n",
      "Fold: 32  Epoch: 180  Training loss = 2.2976  Validation loss = 2.2084  \n",
      "\n",
      "Fold: 32  Epoch: 181  Training loss = 2.2975  Validation loss = 2.2076  \n",
      "\n",
      "Fold: 32  Epoch: 182  Training loss = 2.2974  Validation loss = 2.2031  \n",
      "\n",
      "Fold: 32  Epoch: 183  Training loss = 2.2972  Validation loss = 2.1994  \n",
      "\n",
      "Fold: 32  Epoch: 184  Training loss = 2.2970  Validation loss = 2.1925  \n",
      "\n",
      "Fold: 32  Epoch: 185  Training loss = 2.2970  Validation loss = 2.1919  \n",
      "\n",
      "Fold: 32  Epoch: 186  Training loss = 2.2969  Validation loss = 2.1920  \n",
      "\n",
      "Fold: 32  Epoch: 187  Training loss = 2.2969  Validation loss = 2.1923  \n",
      "\n",
      "Fold: 32  Epoch: 188  Training loss = 2.2967  Validation loss = 2.1887  \n",
      "\n",
      "Fold: 32  Epoch: 189  Training loss = 2.2966  Validation loss = 2.1869  \n",
      "\n",
      "Fold: 32  Epoch: 190  Training loss = 2.2965  Validation loss = 2.1815  \n",
      "\n",
      "Fold: 32  Epoch: 191  Training loss = 2.2963  Validation loss = 2.1763  \n",
      "\n",
      "Fold: 32  Epoch: 192  Training loss = 2.2962  Validation loss = 2.1745  \n",
      "\n",
      "Fold: 32  Epoch: 193  Training loss = 2.2962  Validation loss = 2.1753  \n",
      "\n",
      "Fold: 32  Epoch: 194  Training loss = 2.2961  Validation loss = 2.1734  \n",
      "\n",
      "Fold: 32  Epoch: 195  Training loss = 2.2961  Validation loss = 2.1740  \n",
      "\n",
      "Fold: 32  Epoch: 196  Training loss = 2.2960  Validation loss = 2.1737  \n",
      "\n",
      "Fold: 32  Epoch: 197  Training loss = 2.2959  Validation loss = 2.1740  \n",
      "\n",
      "Fold: 32  Epoch: 198  Training loss = 2.2958  Validation loss = 2.1710  \n",
      "\n",
      "Fold: 32  Epoch: 199  Training loss = 2.2957  Validation loss = 2.1691  \n",
      "\n",
      "Fold: 32  Epoch: 200  Training loss = 2.2956  Validation loss = 2.1669  \n",
      "\n",
      "Fold: 32  Epoch: 201  Training loss = 2.2956  Validation loss = 2.1673  \n",
      "\n",
      "Fold: 32  Epoch: 202  Training loss = 2.2955  Validation loss = 2.1634  \n",
      "\n",
      "Fold: 32  Epoch: 203  Training loss = 2.2954  Validation loss = 2.1620  \n",
      "\n",
      "Fold: 32  Epoch: 204  Training loss = 2.2953  Validation loss = 2.1602  \n",
      "\n",
      "Fold: 32  Epoch: 205  Training loss = 2.2952  Validation loss = 2.1560  \n",
      "\n",
      "Fold: 32  Epoch: 206  Training loss = 2.2952  Validation loss = 2.1556  \n",
      "\n",
      "Fold: 32  Epoch: 207  Training loss = 2.2951  Validation loss = 2.1529  \n",
      "\n",
      "Fold: 32  Epoch: 208  Training loss = 2.2951  Validation loss = 2.1564  \n",
      "\n",
      "Fold: 32  Epoch: 209  Training loss = 2.2950  Validation loss = 2.1556  \n",
      "\n",
      "Fold: 32  Epoch: 210  Training loss = 2.2949  Validation loss = 2.1510  \n",
      "\n",
      "Fold: 32  Epoch: 211  Training loss = 2.2949  Validation loss = 2.1540  \n",
      "\n",
      "Fold: 32  Epoch: 212  Training loss = 2.2948  Validation loss = 2.1522  \n",
      "\n",
      "Fold: 32  Epoch: 213  Training loss = 2.2947  Validation loss = 2.1525  \n",
      "\n",
      "Fold: 32  Epoch: 214  Training loss = 2.2947  Validation loss = 2.1507  \n",
      "\n",
      "Fold: 32  Epoch: 215  Training loss = 2.2946  Validation loss = 2.1494  \n",
      "\n",
      "Fold: 32  Epoch: 216  Training loss = 2.2945  Validation loss = 2.1480  \n",
      "\n",
      "Fold: 32  Epoch: 217  Training loss = 2.2944  Validation loss = 2.1471  \n",
      "\n",
      "Fold: 32  Epoch: 218  Training loss = 2.2943  Validation loss = 2.1439  \n",
      "\n",
      "Fold: 32  Epoch: 219  Training loss = 2.2943  Validation loss = 2.1422  \n",
      "\n",
      "Fold: 32  Epoch: 220  Training loss = 2.2942  Validation loss = 2.1399  \n",
      "\n",
      "Fold: 32  Epoch: 221  Training loss = 2.2941  Validation loss = 2.1424  \n",
      "\n",
      "Fold: 32  Epoch: 222  Training loss = 2.2941  Validation loss = 2.1389  \n",
      "\n",
      "Fold: 32  Epoch: 223  Training loss = 2.2940  Validation loss = 2.1378  \n",
      "\n",
      "Fold: 32  Epoch: 224  Training loss = 2.2939  Validation loss = 2.1387  \n",
      "\n",
      "Fold: 32  Epoch: 225  Training loss = 2.2939  Validation loss = 2.1362  \n",
      "\n",
      "Fold: 32  Epoch: 226  Training loss = 2.2938  Validation loss = 2.1353  \n",
      "\n",
      "Fold: 32  Epoch: 227  Training loss = 2.2937  Validation loss = 2.1365  \n",
      "\n",
      "Fold: 32  Epoch: 228  Training loss = 2.2937  Validation loss = 2.1361  \n",
      "\n",
      "Fold: 32  Epoch: 229  Training loss = 2.2936  Validation loss = 2.1391  \n",
      "\n",
      "Fold: 32  Epoch: 230  Training loss = 2.2936  Validation loss = 2.1387  \n",
      "\n",
      "Fold: 32  Epoch: 231  Training loss = 2.2935  Validation loss = 2.1359  \n",
      "\n",
      "Fold: 32  Epoch: 232  Training loss = 2.2934  Validation loss = 2.1346  \n",
      "\n",
      "Fold: 32  Epoch: 233  Training loss = 2.2933  Validation loss = 2.1338  \n",
      "\n",
      "Fold: 32  Epoch: 234  Training loss = 2.2932  Validation loss = 2.1327  \n",
      "\n",
      "Fold: 32  Epoch: 235  Training loss = 2.2932  Validation loss = 2.1318  \n",
      "\n",
      "Fold: 32  Epoch: 236  Training loss = 2.2931  Validation loss = 2.1280  \n",
      "\n",
      "Fold: 32  Epoch: 237  Training loss = 2.2930  Validation loss = 2.1261  \n",
      "\n",
      "Fold: 32  Epoch: 238  Training loss = 2.2929  Validation loss = 2.1255  \n",
      "\n",
      "Fold: 32  Epoch: 239  Training loss = 2.2929  Validation loss = 2.1263  \n",
      "\n",
      "Fold: 32  Epoch: 240  Training loss = 2.2928  Validation loss = 2.1240  \n",
      "\n",
      "Fold: 32  Epoch: 241  Training loss = 2.2928  Validation loss = 2.1250  \n",
      "\n",
      "Fold: 32  Epoch: 242  Training loss = 2.2927  Validation loss = 2.1288  \n",
      "\n",
      "Fold: 32  Epoch: 243  Training loss = 2.2927  Validation loss = 2.1335  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 240  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 386\n",
      "Average validation error: 4.00981\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.8421  Test loss = 2.4927  \n",
      "\n",
      "Epoch: 2  Training loss = 1.8421  Test loss = 2.4927  \n",
      "\n",
      "Epoch: 3  Training loss = 1.8420  Test loss = 2.4926  \n",
      "\n",
      "Epoch: 4  Training loss = 1.8420  Test loss = 2.4925  \n",
      "\n",
      "Epoch: 5  Training loss = 1.8419  Test loss = 2.4925  \n",
      "\n",
      "Epoch: 6  Training loss = 1.8419  Test loss = 2.4924  \n",
      "\n",
      "Epoch: 7  Training loss = 1.8418  Test loss = 2.4923  \n",
      "\n",
      "Epoch: 8  Training loss = 1.8418  Test loss = 2.4922  \n",
      "\n",
      "Epoch: 9  Training loss = 1.8417  Test loss = 2.4922  \n",
      "\n",
      "Epoch: 10  Training loss = 1.8417  Test loss = 2.4921  \n",
      "\n",
      "Epoch: 11  Training loss = 1.8416  Test loss = 2.4920  \n",
      "\n",
      "Epoch: 12  Training loss = 1.8416  Test loss = 2.4920  \n",
      "\n",
      "Epoch: 13  Training loss = 1.8415  Test loss = 2.4919  \n",
      "\n",
      "Epoch: 14  Training loss = 1.8415  Test loss = 2.4918  \n",
      "\n",
      "Epoch: 15  Training loss = 1.8414  Test loss = 2.4918  \n",
      "\n",
      "Epoch: 16  Training loss = 1.8414  Test loss = 2.4917  \n",
      "\n",
      "Epoch: 17  Training loss = 1.8413  Test loss = 2.4916  \n",
      "\n",
      "Epoch: 18  Training loss = 1.8413  Test loss = 2.4915  \n",
      "\n",
      "Epoch: 19  Training loss = 1.8412  Test loss = 2.4915  \n",
      "\n",
      "Epoch: 20  Training loss = 1.8412  Test loss = 2.4914  \n",
      "\n",
      "Epoch: 21  Training loss = 1.8411  Test loss = 2.4913  \n",
      "\n",
      "Epoch: 22  Training loss = 1.8411  Test loss = 2.4913  \n",
      "\n",
      "Epoch: 23  Training loss = 1.8410  Test loss = 2.4912  \n",
      "\n",
      "Epoch: 24  Training loss = 1.8410  Test loss = 2.4911  \n",
      "\n",
      "Epoch: 25  Training loss = 1.8409  Test loss = 2.4911  \n",
      "\n",
      "Epoch: 26  Training loss = 1.8409  Test loss = 2.4910  \n",
      "\n",
      "Epoch: 27  Training loss = 1.8408  Test loss = 2.4909  \n",
      "\n",
      "Epoch: 28  Training loss = 1.8408  Test loss = 2.4909  \n",
      "\n",
      "Epoch: 29  Training loss = 1.8408  Test loss = 2.4908  \n",
      "\n",
      "Epoch: 30  Training loss = 1.8407  Test loss = 2.4907  \n",
      "\n",
      "Epoch: 31  Training loss = 1.8407  Test loss = 2.4907  \n",
      "\n",
      "Epoch: 32  Training loss = 1.8406  Test loss = 2.4906  \n",
      "\n",
      "Epoch: 33  Training loss = 1.8406  Test loss = 2.4905  \n",
      "\n",
      "Epoch: 34  Training loss = 1.8405  Test loss = 2.4905  \n",
      "\n",
      "Epoch: 35  Training loss = 1.8405  Test loss = 2.4904  \n",
      "\n",
      "Epoch: 36  Training loss = 1.8404  Test loss = 2.4903  \n",
      "\n",
      "Epoch: 37  Training loss = 1.8404  Test loss = 2.4903  \n",
      "\n",
      "Epoch: 38  Training loss = 1.8403  Test loss = 2.4902  \n",
      "\n",
      "Epoch: 39  Training loss = 1.8403  Test loss = 2.4901  \n",
      "\n",
      "Epoch: 40  Training loss = 1.8402  Test loss = 2.4901  \n",
      "\n",
      "Epoch: 41  Training loss = 1.8402  Test loss = 2.4900  \n",
      "\n",
      "Epoch: 42  Training loss = 1.8401  Test loss = 2.4899  \n",
      "\n",
      "Epoch: 43  Training loss = 1.8401  Test loss = 2.4899  \n",
      "\n",
      "Epoch: 44  Training loss = 1.8401  Test loss = 2.4898  \n",
      "\n",
      "Epoch: 45  Training loss = 1.8400  Test loss = 2.4897  \n",
      "\n",
      "Epoch: 46  Training loss = 1.8400  Test loss = 2.4897  \n",
      "\n",
      "Epoch: 47  Training loss = 1.8399  Test loss = 2.4896  \n",
      "\n",
      "Epoch: 48  Training loss = 1.8399  Test loss = 2.4895  \n",
      "\n",
      "Epoch: 49  Training loss = 1.8398  Test loss = 2.4895  \n",
      "\n",
      "Epoch: 50  Training loss = 1.8398  Test loss = 2.4894  \n",
      "\n",
      "Epoch: 51  Training loss = 1.8397  Test loss = 2.4893  \n",
      "\n",
      "Epoch: 52  Training loss = 1.8397  Test loss = 2.4893  \n",
      "\n",
      "Epoch: 53  Training loss = 1.8397  Test loss = 2.4892  \n",
      "\n",
      "Epoch: 54  Training loss = 1.8396  Test loss = 2.4891  \n",
      "\n",
      "Epoch: 55  Training loss = 1.8396  Test loss = 2.4891  \n",
      "\n",
      "Epoch: 56  Training loss = 1.8395  Test loss = 2.4890  \n",
      "\n",
      "Epoch: 57  Training loss = 1.8395  Test loss = 2.4890  \n",
      "\n",
      "Epoch: 58  Training loss = 1.8394  Test loss = 2.4889  \n",
      "\n",
      "Epoch: 59  Training loss = 1.8394  Test loss = 2.4888  \n",
      "\n",
      "Epoch: 60  Training loss = 1.8393  Test loss = 2.4888  \n",
      "\n",
      "Epoch: 61  Training loss = 1.8393  Test loss = 2.4887  \n",
      "\n",
      "Epoch: 62  Training loss = 1.8393  Test loss = 2.4886  \n",
      "\n",
      "Epoch: 63  Training loss = 1.8392  Test loss = 2.4886  \n",
      "\n",
      "Epoch: 64  Training loss = 1.8392  Test loss = 2.4885  \n",
      "\n",
      "Epoch: 65  Training loss = 1.8391  Test loss = 2.4884  \n",
      "\n",
      "Epoch: 66  Training loss = 1.8391  Test loss = 2.4884  \n",
      "\n",
      "Epoch: 67  Training loss = 1.8390  Test loss = 2.4883  \n",
      "\n",
      "Epoch: 68  Training loss = 1.8390  Test loss = 2.4883  \n",
      "\n",
      "Epoch: 69  Training loss = 1.8390  Test loss = 2.4882  \n",
      "\n",
      "Epoch: 70  Training loss = 1.8389  Test loss = 2.4881  \n",
      "\n",
      "Epoch: 71  Training loss = 1.8389  Test loss = 2.4881  \n",
      "\n",
      "Epoch: 72  Training loss = 1.8388  Test loss = 2.4880  \n",
      "\n",
      "Epoch: 73  Training loss = 1.8388  Test loss = 2.4880  \n",
      "\n",
      "Epoch: 74  Training loss = 1.8387  Test loss = 2.4879  \n",
      "\n",
      "Epoch: 75  Training loss = 1.8387  Test loss = 2.4878  \n",
      "\n",
      "Epoch: 76  Training loss = 1.8387  Test loss = 2.4878  \n",
      "\n",
      "Epoch: 77  Training loss = 1.8386  Test loss = 2.4877  \n",
      "\n",
      "Epoch: 78  Training loss = 1.8386  Test loss = 2.4876  \n",
      "\n",
      "Epoch: 79  Training loss = 1.8385  Test loss = 2.4876  \n",
      "\n",
      "Epoch: 80  Training loss = 1.8385  Test loss = 2.4875  \n",
      "\n",
      "Epoch: 81  Training loss = 1.8384  Test loss = 2.4875  \n",
      "\n",
      "Epoch: 82  Training loss = 1.8384  Test loss = 2.4874  \n",
      "\n",
      "Epoch: 83  Training loss = 1.8384  Test loss = 2.4873  \n",
      "\n",
      "Epoch: 84  Training loss = 1.8383  Test loss = 2.4873  \n",
      "\n",
      "Epoch: 85  Training loss = 1.8383  Test loss = 2.4872  \n",
      "\n",
      "Epoch: 86  Training loss = 1.8382  Test loss = 2.4872  \n",
      "\n",
      "Epoch: 87  Training loss = 1.8382  Test loss = 2.4871  \n",
      "\n",
      "Epoch: 88  Training loss = 1.8382  Test loss = 2.4870  \n",
      "\n",
      "Epoch: 89  Training loss = 1.8381  Test loss = 2.4870  \n",
      "\n",
      "Epoch: 90  Training loss = 1.8381  Test loss = 2.4869  \n",
      "\n",
      "Epoch: 91  Training loss = 1.8380  Test loss = 2.4869  \n",
      "\n",
      "Epoch: 92  Training loss = 1.8380  Test loss = 2.4868  \n",
      "\n",
      "Epoch: 93  Training loss = 1.8380  Test loss = 2.4867  \n",
      "\n",
      "Epoch: 94  Training loss = 1.8379  Test loss = 2.4867  \n",
      "\n",
      "Epoch: 95  Training loss = 1.8379  Test loss = 2.4866  \n",
      "\n",
      "Epoch: 96  Training loss = 1.8378  Test loss = 2.4866  \n",
      "\n",
      "Epoch: 97  Training loss = 1.8378  Test loss = 2.4865  \n",
      "\n",
      "Epoch: 98  Training loss = 1.8378  Test loss = 2.4864  \n",
      "\n",
      "Epoch: 99  Training loss = 1.8377  Test loss = 2.4864  \n",
      "\n",
      "Epoch: 100  Training loss = 1.8377  Test loss = 2.4863  \n",
      "\n",
      "Epoch: 101  Training loss = 1.8376  Test loss = 2.4863  \n",
      "\n",
      "Epoch: 102  Training loss = 1.8376  Test loss = 2.4862  \n",
      "\n",
      "Epoch: 103  Training loss = 1.8376  Test loss = 2.4862  \n",
      "\n",
      "Epoch: 104  Training loss = 1.8375  Test loss = 2.4861  \n",
      "\n",
      "Epoch: 105  Training loss = 1.8375  Test loss = 2.4860  \n",
      "\n",
      "Epoch: 106  Training loss = 1.8374  Test loss = 2.4860  \n",
      "\n",
      "Epoch: 107  Training loss = 1.8374  Test loss = 2.4859  \n",
      "\n",
      "Epoch: 108  Training loss = 1.8374  Test loss = 2.4859  \n",
      "\n",
      "Epoch: 109  Training loss = 1.8373  Test loss = 2.4858  \n",
      "\n",
      "Epoch: 110  Training loss = 1.8373  Test loss = 2.4858  \n",
      "\n",
      "Epoch: 111  Training loss = 1.8372  Test loss = 2.4857  \n",
      "\n",
      "Epoch: 112  Training loss = 1.8372  Test loss = 2.4856  \n",
      "\n",
      "Epoch: 113  Training loss = 1.8372  Test loss = 2.4856  \n",
      "\n",
      "Epoch: 114  Training loss = 1.8371  Test loss = 2.4855  \n",
      "\n",
      "Epoch: 115  Training loss = 1.8371  Test loss = 2.4855  \n",
      "\n",
      "Epoch: 116  Training loss = 1.8370  Test loss = 2.4854  \n",
      "\n",
      "Epoch: 117  Training loss = 1.8370  Test loss = 2.4854  \n",
      "\n",
      "Epoch: 118  Training loss = 1.8370  Test loss = 2.4853  \n",
      "\n",
      "Epoch: 119  Training loss = 1.8369  Test loss = 2.4852  \n",
      "\n",
      "Epoch: 120  Training loss = 1.8369  Test loss = 2.4852  \n",
      "\n",
      "Epoch: 121  Training loss = 1.8369  Test loss = 2.4851  \n",
      "\n",
      "Epoch: 122  Training loss = 1.8368  Test loss = 2.4851  \n",
      "\n",
      "Epoch: 123  Training loss = 1.8368  Test loss = 2.4850  \n",
      "\n",
      "Epoch: 124  Training loss = 1.8367  Test loss = 2.4850  \n",
      "\n",
      "Epoch: 125  Training loss = 1.8367  Test loss = 2.4849  \n",
      "\n",
      "Epoch: 126  Training loss = 1.8367  Test loss = 2.4848  \n",
      "\n",
      "Epoch: 127  Training loss = 1.8366  Test loss = 2.4848  \n",
      "\n",
      "Epoch: 128  Training loss = 1.8366  Test loss = 2.4847  \n",
      "\n",
      "Epoch: 129  Training loss = 1.8365  Test loss = 2.4847  \n",
      "\n",
      "Epoch: 130  Training loss = 1.8365  Test loss = 2.4846  \n",
      "\n",
      "Epoch: 131  Training loss = 1.8365  Test loss = 2.4846  \n",
      "\n",
      "Epoch: 132  Training loss = 1.8364  Test loss = 2.4845  \n",
      "\n",
      "Epoch: 133  Training loss = 1.8364  Test loss = 2.4845  \n",
      "\n",
      "Epoch: 134  Training loss = 1.8364  Test loss = 2.4844  \n",
      "\n",
      "Epoch: 135  Training loss = 1.8363  Test loss = 2.4844  \n",
      "\n",
      "Epoch: 136  Training loss = 1.8363  Test loss = 2.4843  \n",
      "\n",
      "Epoch: 137  Training loss = 1.8362  Test loss = 2.4842  \n",
      "\n",
      "Epoch: 138  Training loss = 1.8362  Test loss = 2.4842  \n",
      "\n",
      "Epoch: 139  Training loss = 1.8362  Test loss = 2.4841  \n",
      "\n",
      "Epoch: 140  Training loss = 1.8361  Test loss = 2.4841  \n",
      "\n",
      "Epoch: 141  Training loss = 1.8361  Test loss = 2.4840  \n",
      "\n",
      "Epoch: 142  Training loss = 1.8361  Test loss = 2.4840  \n",
      "\n",
      "Epoch: 143  Training loss = 1.8360  Test loss = 2.4839  \n",
      "\n",
      "Epoch: 144  Training loss = 1.8360  Test loss = 2.4839  \n",
      "\n",
      "Epoch: 145  Training loss = 1.8360  Test loss = 2.4838  \n",
      "\n",
      "Epoch: 146  Training loss = 1.8359  Test loss = 2.4838  \n",
      "\n",
      "Epoch: 147  Training loss = 1.8359  Test loss = 2.4837  \n",
      "\n",
      "Epoch: 148  Training loss = 1.8358  Test loss = 2.4837  \n",
      "\n",
      "Epoch: 149  Training loss = 1.8358  Test loss = 2.4836  \n",
      "\n",
      "Epoch: 150  Training loss = 1.8358  Test loss = 2.4835  \n",
      "\n",
      "Epoch: 151  Training loss = 1.8357  Test loss = 2.4835  \n",
      "\n",
      "Epoch: 152  Training loss = 1.8357  Test loss = 2.4834  \n",
      "\n",
      "Epoch: 153  Training loss = 1.8357  Test loss = 2.4834  \n",
      "\n",
      "Epoch: 154  Training loss = 1.8356  Test loss = 2.4833  \n",
      "\n",
      "Epoch: 155  Training loss = 1.8356  Test loss = 2.4833  \n",
      "\n",
      "Epoch: 156  Training loss = 1.8356  Test loss = 2.4832  \n",
      "\n",
      "Epoch: 157  Training loss = 1.8355  Test loss = 2.4832  \n",
      "\n",
      "Epoch: 158  Training loss = 1.8355  Test loss = 2.4831  \n",
      "\n",
      "Epoch: 159  Training loss = 1.8354  Test loss = 2.4831  \n",
      "\n",
      "Epoch: 160  Training loss = 1.8354  Test loss = 2.4830  \n",
      "\n",
      "Epoch: 161  Training loss = 1.8354  Test loss = 2.4830  \n",
      "\n",
      "Epoch: 162  Training loss = 1.8353  Test loss = 2.4829  \n",
      "\n",
      "Epoch: 163  Training loss = 1.8353  Test loss = 2.4829  \n",
      "\n",
      "Epoch: 164  Training loss = 1.8353  Test loss = 2.4828  \n",
      "\n",
      "Epoch: 165  Training loss = 1.8352  Test loss = 2.4828  \n",
      "\n",
      "Epoch: 166  Training loss = 1.8352  Test loss = 2.4827  \n",
      "\n",
      "Epoch: 167  Training loss = 1.8352  Test loss = 2.4827  \n",
      "\n",
      "Epoch: 168  Training loss = 1.8351  Test loss = 2.4826  \n",
      "\n",
      "Epoch: 169  Training loss = 1.8351  Test loss = 2.4825  \n",
      "\n",
      "Epoch: 170  Training loss = 1.8351  Test loss = 2.4825  \n",
      "\n",
      "Epoch: 171  Training loss = 1.8350  Test loss = 2.4824  \n",
      "\n",
      "Epoch: 172  Training loss = 1.8350  Test loss = 2.4824  \n",
      "\n",
      "Epoch: 173  Training loss = 1.8350  Test loss = 2.4823  \n",
      "\n",
      "Epoch: 174  Training loss = 1.8349  Test loss = 2.4823  \n",
      "\n",
      "Epoch: 175  Training loss = 1.8349  Test loss = 2.4822  \n",
      "\n",
      "Epoch: 176  Training loss = 1.8349  Test loss = 2.4822  \n",
      "\n",
      "Epoch: 177  Training loss = 1.8348  Test loss = 2.4821  \n",
      "\n",
      "Epoch: 178  Training loss = 1.8348  Test loss = 2.4821  \n",
      "\n",
      "Epoch: 179  Training loss = 1.8347  Test loss = 2.4820  \n",
      "\n",
      "Epoch: 180  Training loss = 1.8347  Test loss = 2.4820  \n",
      "\n",
      "Epoch: 181  Training loss = 1.8347  Test loss = 2.4819  \n",
      "\n",
      "Epoch: 182  Training loss = 1.8346  Test loss = 2.4819  \n",
      "\n",
      "Epoch: 183  Training loss = 1.8346  Test loss = 2.4818  \n",
      "\n",
      "Epoch: 184  Training loss = 1.8346  Test loss = 2.4818  \n",
      "\n",
      "Epoch: 185  Training loss = 1.8345  Test loss = 2.4817  \n",
      "\n",
      "Epoch: 186  Training loss = 1.8345  Test loss = 2.4817  \n",
      "\n",
      "Epoch: 187  Training loss = 1.8345  Test loss = 2.4816  \n",
      "\n",
      "Epoch: 188  Training loss = 1.8344  Test loss = 2.4816  \n",
      "\n",
      "Epoch: 189  Training loss = 1.8344  Test loss = 2.4815  \n",
      "\n",
      "Epoch: 190  Training loss = 1.8344  Test loss = 2.4815  \n",
      "\n",
      "Epoch: 191  Training loss = 1.8343  Test loss = 2.4814  \n",
      "\n",
      "Epoch: 192  Training loss = 1.8343  Test loss = 2.4814  \n",
      "\n",
      "Epoch: 193  Training loss = 1.8343  Test loss = 2.4813  \n",
      "\n",
      "Epoch: 194  Training loss = 1.8342  Test loss = 2.4813  \n",
      "\n",
      "Epoch: 195  Training loss = 1.8342  Test loss = 2.4812  \n",
      "\n",
      "Epoch: 196  Training loss = 1.8342  Test loss = 2.4812  \n",
      "\n",
      "Epoch: 197  Training loss = 1.8341  Test loss = 2.4811  \n",
      "\n",
      "Epoch: 198  Training loss = 1.8341  Test loss = 2.4811  \n",
      "\n",
      "Epoch: 199  Training loss = 1.8341  Test loss = 2.4810  \n",
      "\n",
      "Epoch: 200  Training loss = 1.8340  Test loss = 2.4810  \n",
      "\n",
      "Epoch: 201  Training loss = 1.8340  Test loss = 2.4809  \n",
      "\n",
      "Epoch: 202  Training loss = 1.8340  Test loss = 2.4809  \n",
      "\n",
      "Epoch: 203  Training loss = 1.8339  Test loss = 2.4809  \n",
      "\n",
      "Epoch: 204  Training loss = 1.8339  Test loss = 2.4808  \n",
      "\n",
      "Epoch: 205  Training loss = 1.8339  Test loss = 2.4808  \n",
      "\n",
      "Epoch: 206  Training loss = 1.8338  Test loss = 2.4807  \n",
      "\n",
      "Epoch: 207  Training loss = 1.8338  Test loss = 2.4807  \n",
      "\n",
      "Epoch: 208  Training loss = 1.8338  Test loss = 2.4806  \n",
      "\n",
      "Epoch: 209  Training loss = 1.8337  Test loss = 2.4806  \n",
      "\n",
      "Epoch: 210  Training loss = 1.8337  Test loss = 2.4805  \n",
      "\n",
      "Epoch: 211  Training loss = 1.8337  Test loss = 2.4805  \n",
      "\n",
      "Epoch: 212  Training loss = 1.8337  Test loss = 2.4804  \n",
      "\n",
      "Epoch: 213  Training loss = 1.8336  Test loss = 2.4804  \n",
      "\n",
      "Epoch: 214  Training loss = 1.8336  Test loss = 2.4803  \n",
      "\n",
      "Epoch: 215  Training loss = 1.8336  Test loss = 2.4803  \n",
      "\n",
      "Epoch: 216  Training loss = 1.8335  Test loss = 2.4802  \n",
      "\n",
      "Epoch: 217  Training loss = 1.8335  Test loss = 2.4802  \n",
      "\n",
      "Epoch: 218  Training loss = 1.8335  Test loss = 2.4801  \n",
      "\n",
      "Epoch: 219  Training loss = 1.8334  Test loss = 2.4801  \n",
      "\n",
      "Epoch: 220  Training loss = 1.8334  Test loss = 2.4800  \n",
      "\n",
      "Epoch: 221  Training loss = 1.8334  Test loss = 2.4800  \n",
      "\n",
      "Epoch: 222  Training loss = 1.8333  Test loss = 2.4799  \n",
      "\n",
      "Epoch: 223  Training loss = 1.8333  Test loss = 2.4799  \n",
      "\n",
      "Epoch: 224  Training loss = 1.8333  Test loss = 2.4799  \n",
      "\n",
      "Epoch: 225  Training loss = 1.8332  Test loss = 2.4798  \n",
      "\n",
      "Epoch: 226  Training loss = 1.8332  Test loss = 2.4798  \n",
      "\n",
      "Epoch: 227  Training loss = 1.8332  Test loss = 2.4797  \n",
      "\n",
      "Epoch: 228  Training loss = 1.8331  Test loss = 2.4797  \n",
      "\n",
      "Epoch: 229  Training loss = 1.8331  Test loss = 2.4796  \n",
      "\n",
      "Epoch: 230  Training loss = 1.8331  Test loss = 2.4796  \n",
      "\n",
      "Epoch: 231  Training loss = 1.8330  Test loss = 2.4795  \n",
      "\n",
      "Epoch: 232  Training loss = 1.8330  Test loss = 2.4795  \n",
      "\n",
      "Epoch: 233  Training loss = 1.8330  Test loss = 2.4794  \n",
      "\n",
      "Epoch: 234  Training loss = 1.8330  Test loss = 2.4794  \n",
      "\n",
      "Epoch: 235  Training loss = 1.8329  Test loss = 2.4793  \n",
      "\n",
      "Epoch: 236  Training loss = 1.8329  Test loss = 2.4793  \n",
      "\n",
      "Epoch: 237  Training loss = 1.8329  Test loss = 2.4792  \n",
      "\n",
      "Epoch: 238  Training loss = 1.8328  Test loss = 2.4792  \n",
      "\n",
      "Epoch: 239  Training loss = 1.8328  Test loss = 2.4792  \n",
      "\n",
      "Epoch: 240  Training loss = 1.8328  Test loss = 2.4791  \n",
      "\n",
      "Epoch: 241  Training loss = 1.8327  Test loss = 2.4791  \n",
      "\n",
      "Epoch: 242  Training loss = 1.8327  Test loss = 2.4790  \n",
      "\n",
      "Epoch: 243  Training loss = 1.8327  Test loss = 2.4790  \n",
      "\n",
      "Epoch: 244  Training loss = 1.8326  Test loss = 2.4789  \n",
      "\n",
      "Epoch: 245  Training loss = 1.8326  Test loss = 2.4789  \n",
      "\n",
      "Epoch: 246  Training loss = 1.8326  Test loss = 2.4788  \n",
      "\n",
      "Epoch: 247  Training loss = 1.8326  Test loss = 2.4788  \n",
      "\n",
      "Epoch: 248  Training loss = 1.8325  Test loss = 2.4787  \n",
      "\n",
      "Epoch: 249  Training loss = 1.8325  Test loss = 2.4787  \n",
      "\n",
      "Epoch: 250  Training loss = 1.8325  Test loss = 2.4787  \n",
      "\n",
      "Epoch: 251  Training loss = 1.8324  Test loss = 2.4786  \n",
      "\n",
      "Epoch: 252  Training loss = 1.8324  Test loss = 2.4786  \n",
      "\n",
      "Epoch: 253  Training loss = 1.8324  Test loss = 2.4785  \n",
      "\n",
      "Epoch: 254  Training loss = 1.8323  Test loss = 2.4785  \n",
      "\n",
      "Epoch: 255  Training loss = 1.8323  Test loss = 2.4784  \n",
      "\n",
      "Epoch: 256  Training loss = 1.8323  Test loss = 2.4784  \n",
      "\n",
      "Epoch: 257  Training loss = 1.8323  Test loss = 2.4783  \n",
      "\n",
      "Epoch: 258  Training loss = 1.8322  Test loss = 2.4783  \n",
      "\n",
      "Epoch: 259  Training loss = 1.8322  Test loss = 2.4783  \n",
      "\n",
      "Epoch: 260  Training loss = 1.8322  Test loss = 2.4782  \n",
      "\n",
      "Epoch: 261  Training loss = 1.8321  Test loss = 2.4782  \n",
      "\n",
      "Epoch: 262  Training loss = 1.8321  Test loss = 2.4781  \n",
      "\n",
      "Epoch: 263  Training loss = 1.8321  Test loss = 2.4781  \n",
      "\n",
      "Epoch: 264  Training loss = 1.8320  Test loss = 2.4780  \n",
      "\n",
      "Epoch: 265  Training loss = 1.8320  Test loss = 2.4780  \n",
      "\n",
      "Epoch: 266  Training loss = 1.8320  Test loss = 2.4779  \n",
      "\n",
      "Epoch: 267  Training loss = 1.8320  Test loss = 2.4779  \n",
      "\n",
      "Epoch: 268  Training loss = 1.8319  Test loss = 2.4779  \n",
      "\n",
      "Epoch: 269  Training loss = 1.8319  Test loss = 2.4778  \n",
      "\n",
      "Epoch: 270  Training loss = 1.8319  Test loss = 2.4778  \n",
      "\n",
      "Epoch: 271  Training loss = 1.8318  Test loss = 2.4777  \n",
      "\n",
      "Epoch: 272  Training loss = 1.8318  Test loss = 2.4777  \n",
      "\n",
      "Epoch: 273  Training loss = 1.8318  Test loss = 2.4776  \n",
      "\n",
      "Epoch: 274  Training loss = 1.8318  Test loss = 2.4776  \n",
      "\n",
      "Epoch: 275  Training loss = 1.8317  Test loss = 2.4776  \n",
      "\n",
      "Epoch: 276  Training loss = 1.8317  Test loss = 2.4775  \n",
      "\n",
      "Epoch: 277  Training loss = 1.8317  Test loss = 2.4775  \n",
      "\n",
      "Epoch: 278  Training loss = 1.8316  Test loss = 2.4774  \n",
      "\n",
      "Epoch: 279  Training loss = 1.8316  Test loss = 2.4774  \n",
      "\n",
      "Epoch: 280  Training loss = 1.8316  Test loss = 2.4773  \n",
      "\n",
      "Epoch: 281  Training loss = 1.8315  Test loss = 2.4773  \n",
      "\n",
      "Epoch: 282  Training loss = 1.8315  Test loss = 2.4772  \n",
      "\n",
      "Epoch: 283  Training loss = 1.8315  Test loss = 2.4772  \n",
      "\n",
      "Epoch: 284  Training loss = 1.8315  Test loss = 2.4772  \n",
      "\n",
      "Epoch: 285  Training loss = 1.8314  Test loss = 2.4771  \n",
      "\n",
      "Epoch: 286  Training loss = 1.8314  Test loss = 2.4771  \n",
      "\n",
      "Epoch: 287  Training loss = 1.8314  Test loss = 2.4770  \n",
      "\n",
      "Epoch: 288  Training loss = 1.8313  Test loss = 2.4770  \n",
      "\n",
      "Epoch: 289  Training loss = 1.8313  Test loss = 2.4770  \n",
      "\n",
      "Epoch: 290  Training loss = 1.8313  Test loss = 2.4769  \n",
      "\n",
      "Epoch: 291  Training loss = 1.8313  Test loss = 2.4769  \n",
      "\n",
      "Epoch: 292  Training loss = 1.8312  Test loss = 2.4768  \n",
      "\n",
      "Epoch: 293  Training loss = 1.8312  Test loss = 2.4768  \n",
      "\n",
      "Epoch: 294  Training loss = 1.8312  Test loss = 2.4767  \n",
      "\n",
      "Epoch: 295  Training loss = 1.8311  Test loss = 2.4767  \n",
      "\n",
      "Epoch: 296  Training loss = 1.8311  Test loss = 2.4767  \n",
      "\n",
      "Epoch: 297  Training loss = 1.8311  Test loss = 2.4766  \n",
      "\n",
      "Epoch: 298  Training loss = 1.8311  Test loss = 2.4766  \n",
      "\n",
      "Epoch: 299  Training loss = 1.8310  Test loss = 2.4765  \n",
      "\n",
      "Epoch: 300  Training loss = 1.8310  Test loss = 2.4765  \n",
      "\n",
      "Epoch: 301  Training loss = 1.8310  Test loss = 2.4764  \n",
      "\n",
      "Epoch: 302  Training loss = 1.8310  Test loss = 2.4764  \n",
      "\n",
      "Epoch: 303  Training loss = 1.8309  Test loss = 2.4764  \n",
      "\n",
      "Epoch: 304  Training loss = 1.8309  Test loss = 2.4763  \n",
      "\n",
      "Epoch: 305  Training loss = 1.8309  Test loss = 2.4763  \n",
      "\n",
      "Epoch: 306  Training loss = 1.8308  Test loss = 2.4762  \n",
      "\n",
      "Epoch: 307  Training loss = 1.8308  Test loss = 2.4762  \n",
      "\n",
      "Epoch: 308  Training loss = 1.8308  Test loss = 2.4762  \n",
      "\n",
      "Epoch: 309  Training loss = 1.8308  Test loss = 2.4761  \n",
      "\n",
      "Epoch: 310  Training loss = 1.8307  Test loss = 2.4761  \n",
      "\n",
      "Epoch: 311  Training loss = 1.8307  Test loss = 2.4760  \n",
      "\n",
      "Epoch: 312  Training loss = 1.8307  Test loss = 2.4760  \n",
      "\n",
      "Epoch: 313  Training loss = 1.8306  Test loss = 2.4760  \n",
      "\n",
      "Epoch: 314  Training loss = 1.8306  Test loss = 2.4759  \n",
      "\n",
      "Epoch: 315  Training loss = 1.8306  Test loss = 2.4759  \n",
      "\n",
      "Epoch: 316  Training loss = 1.8306  Test loss = 2.4758  \n",
      "\n",
      "Epoch: 317  Training loss = 1.8305  Test loss = 2.4758  \n",
      "\n",
      "Epoch: 318  Training loss = 1.8305  Test loss = 2.4757  \n",
      "\n",
      "Epoch: 319  Training loss = 1.8305  Test loss = 2.4757  \n",
      "\n",
      "Epoch: 320  Training loss = 1.8305  Test loss = 2.4757  \n",
      "\n",
      "Epoch: 321  Training loss = 1.8304  Test loss = 2.4756  \n",
      "\n",
      "Epoch: 322  Training loss = 1.8304  Test loss = 2.4756  \n",
      "\n",
      "Epoch: 323  Training loss = 1.8304  Test loss = 2.4755  \n",
      "\n",
      "Epoch: 324  Training loss = 1.8303  Test loss = 2.4755  \n",
      "\n",
      "Epoch: 325  Training loss = 1.8303  Test loss = 2.4755  \n",
      "\n",
      "Epoch: 326  Training loss = 1.8303  Test loss = 2.4754  \n",
      "\n",
      "Epoch: 327  Training loss = 1.8303  Test loss = 2.4754  \n",
      "\n",
      "Epoch: 328  Training loss = 1.8302  Test loss = 2.4753  \n",
      "\n",
      "Epoch: 329  Training loss = 1.8302  Test loss = 2.4753  \n",
      "\n",
      "Epoch: 330  Training loss = 1.8302  Test loss = 2.4753  \n",
      "\n",
      "Epoch: 331  Training loss = 1.8302  Test loss = 2.4752  \n",
      "\n",
      "Epoch: 332  Training loss = 1.8301  Test loss = 2.4752  \n",
      "\n",
      "Epoch: 333  Training loss = 1.8301  Test loss = 2.4751  \n",
      "\n",
      "Epoch: 334  Training loss = 1.8301  Test loss = 2.4751  \n",
      "\n",
      "Epoch: 335  Training loss = 1.8301  Test loss = 2.4751  \n",
      "\n",
      "Epoch: 336  Training loss = 1.8300  Test loss = 2.4750  \n",
      "\n",
      "Epoch: 337  Training loss = 1.8300  Test loss = 2.4750  \n",
      "\n",
      "Epoch: 338  Training loss = 1.8300  Test loss = 2.4749  \n",
      "\n",
      "Epoch: 339  Training loss = 1.8299  Test loss = 2.4749  \n",
      "\n",
      "Epoch: 340  Training loss = 1.8299  Test loss = 2.4749  \n",
      "\n",
      "Epoch: 341  Training loss = 1.8299  Test loss = 2.4748  \n",
      "\n",
      "Epoch: 342  Training loss = 1.8299  Test loss = 2.4748  \n",
      "\n",
      "Epoch: 343  Training loss = 1.8298  Test loss = 2.4747  \n",
      "\n",
      "Epoch: 344  Training loss = 1.8298  Test loss = 2.4747  \n",
      "\n",
      "Epoch: 345  Training loss = 1.8298  Test loss = 2.4747  \n",
      "\n",
      "Epoch: 346  Training loss = 1.8298  Test loss = 2.4746  \n",
      "\n",
      "Epoch: 347  Training loss = 1.8297  Test loss = 2.4746  \n",
      "\n",
      "Epoch: 348  Training loss = 1.8297  Test loss = 2.4746  \n",
      "\n",
      "Epoch: 349  Training loss = 1.8297  Test loss = 2.4745  \n",
      "\n",
      "Epoch: 350  Training loss = 1.8297  Test loss = 2.4745  \n",
      "\n",
      "Epoch: 351  Training loss = 1.8296  Test loss = 2.4744  \n",
      "\n",
      "Epoch: 352  Training loss = 1.8296  Test loss = 2.4744  \n",
      "\n",
      "Epoch: 353  Training loss = 1.8296  Test loss = 2.4744  \n",
      "\n",
      "Epoch: 354  Training loss = 1.8296  Test loss = 2.4743  \n",
      "\n",
      "Epoch: 355  Training loss = 1.8295  Test loss = 2.4743  \n",
      "\n",
      "Epoch: 356  Training loss = 1.8295  Test loss = 2.4742  \n",
      "\n",
      "Epoch: 357  Training loss = 1.8295  Test loss = 2.4742  \n",
      "\n",
      "Epoch: 358  Training loss = 1.8295  Test loss = 2.4742  \n",
      "\n",
      "Epoch: 359  Training loss = 1.8294  Test loss = 2.4741  \n",
      "\n",
      "Epoch: 360  Training loss = 1.8294  Test loss = 2.4741  \n",
      "\n",
      "Epoch: 361  Training loss = 1.8294  Test loss = 2.4740  \n",
      "\n",
      "Epoch: 362  Training loss = 1.8293  Test loss = 2.4740  \n",
      "\n",
      "Epoch: 363  Training loss = 1.8293  Test loss = 2.4740  \n",
      "\n",
      "Epoch: 364  Training loss = 1.8293  Test loss = 2.4739  \n",
      "\n",
      "Epoch: 365  Training loss = 1.8293  Test loss = 2.4739  \n",
      "\n",
      "Epoch: 366  Training loss = 1.8292  Test loss = 2.4739  \n",
      "\n",
      "Epoch: 367  Training loss = 1.8292  Test loss = 2.4738  \n",
      "\n",
      "Epoch: 368  Training loss = 1.8292  Test loss = 2.4738  \n",
      "\n",
      "Epoch: 369  Training loss = 1.8292  Test loss = 2.4737  \n",
      "\n",
      "Epoch: 370  Training loss = 1.8291  Test loss = 2.4737  \n",
      "\n",
      "Epoch: 371  Training loss = 1.8291  Test loss = 2.4737  \n",
      "\n",
      "Epoch: 372  Training loss = 1.8291  Test loss = 2.4736  \n",
      "\n",
      "Epoch: 373  Training loss = 1.8291  Test loss = 2.4736  \n",
      "\n",
      "Epoch: 374  Training loss = 1.8290  Test loss = 2.4736  \n",
      "\n",
      "Epoch: 375  Training loss = 1.8290  Test loss = 2.4735  \n",
      "\n",
      "Epoch: 376  Training loss = 1.8290  Test loss = 2.4735  \n",
      "\n",
      "Epoch: 377  Training loss = 1.8290  Test loss = 2.4734  \n",
      "\n",
      "Epoch: 378  Training loss = 1.8289  Test loss = 2.4734  \n",
      "\n",
      "Epoch: 379  Training loss = 1.8289  Test loss = 2.4734  \n",
      "\n",
      "Epoch: 380  Training loss = 1.8289  Test loss = 2.4733  \n",
      "\n",
      "Epoch: 381  Training loss = 1.8289  Test loss = 2.4733  \n",
      "\n",
      "Epoch: 382  Training loss = 1.8288  Test loss = 2.4733  \n",
      "\n",
      "Epoch: 383  Training loss = 1.8288  Test loss = 2.4732  \n",
      "\n",
      "Epoch: 384  Training loss = 1.8288  Test loss = 2.4732  \n",
      "\n",
      "Epoch: 385  Training loss = 1.8288  Test loss = 2.4731  \n",
      "\n",
      "Epoch: 386  Training loss = 1.8287  Test loss = 2.4731  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbafbe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY8bfygPRXgy9Sb8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcc839e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.47310712568 \n",
      "Fixed scheme MAE:  1.64370057375\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.8287  Test loss = 1.3548  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.8239  Test loss = 0.7640  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.8071  Test loss = 1.2225  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.8051  Test loss = 0.8817  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.7185  Test loss = 0.5277  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.6839  Test loss = 1.1601  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.6609  Test loss = 0.1781  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.6610  Test loss = 0.2084  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.6132  Test loss = 0.2371  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.6116  Test loss = 0.1240  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.5664  Test loss = 0.0034  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.5624  Test loss = 0.9357  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.5433  Test loss = 0.1397  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.5434  Test loss = 1.3613  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.5474  Test loss = 2.6279  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.5813  Test loss = 2.9835  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.6095  Test loss = 0.2660  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.6065  Test loss = 0.8425  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.5823  Test loss = 0.6109  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.3766  Test loss = 0.2954  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.3605  Test loss = 0.3525  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.3603  Test loss = 4.3922  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.4420  Test loss = 0.8977  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.4261  Test loss = 2.3065  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.4448  Test loss = 0.2887  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.4452  Test loss = 0.3944  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.4433  Test loss = 1.3605  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.4480  Test loss = 0.6667  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.4241  Test loss = 1.1961  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.4120  Test loss = 0.8862  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.3928  Test loss = 2.8271  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.3872  Test loss = 0.1324  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.3777  Test loss = 1.7500  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.3938  Test loss = 0.0349  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.3068  Test loss = 0.3975  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.3072  Test loss = 5.1822  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.3613  Test loss = 0.2455  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2967  Test loss = 1.2135  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.3046  Test loss = 0.9017  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.3087  Test loss = 2.3089  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.3095  Test loss = 0.8251  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.3075  Test loss = 2.2468  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.3368  Test loss = 3.7163  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.4140  Test loss = 11.4835  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 2.0072  Test loss = 5.5452  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1214  Test loss = 0.1504  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1214  Test loss = 0.7611  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1231  Test loss = 0.8353  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 2.0786  Test loss = 1.9002  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 2.0869  Test loss = 2.9795  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 2.1190  Test loss = 2.2870  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.1379  Test loss = 0.3224  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 2.1193  Test loss = 0.5866  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 2.1196  Test loss = 1.1455  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 2.1242  Test loss = 0.9595  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 2.1254  Test loss = 0.7838  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 2.1138  Test loss = 0.4163  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 2.1117  Test loss = 1.8096  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 2.1229  Test loss = 1.0313  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 2.1254  Test loss = 0.2321  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 2.1155  Test loss = 0.3913  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 2.1159  Test loss = 2.9954  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 2.1473  Test loss = 1.2669  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 2.1424  Test loss = 1.7423  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 2.1444  Test loss = 0.2388  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 2.1439  Test loss = 1.1368  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 2.1412  Test loss = 1.1353  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 2.1428  Test loss = 3.5303  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 2.1706  Test loss = 5.4340  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 2.2728  Test loss = 0.8333  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 2.2743  Test loss = 0.8887  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 2.2732  Test loss = 2.1512  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 2.2682  Test loss = 2.2541  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 2.2852  Test loss = 1.4834  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 2.2889  Test loss = 0.6399  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 2.2790  Test loss = 0.6055  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 2.2410  Test loss = 1.2786  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcee0da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.23767702694 \n",
      "Updating scheme MAE:  1.46081993584\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
