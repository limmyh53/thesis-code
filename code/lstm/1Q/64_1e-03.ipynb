{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/64_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-3\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 64 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 64 \n",
      "Learning rate = 0.001 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.001\n",
      "Fold: 1  Epoch: 1  Training loss = 3.0244  Validation loss = 3.0205  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.9114  Validation loss = 2.7490  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.8556  Validation loss = 2.5951  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.7948  Validation loss = 2.4084  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.7353  Validation loss = 2.1807  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.6977  Validation loss = 1.9970  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.6875  Validation loss = 1.9401  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.6790  Validation loss = 1.8915  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.6737  Validation loss = 1.8807  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.6626  Validation loss = 1.8093  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.6544  Validation loss = 1.6904  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.6528  Validation loss = 1.7223  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.6427  Validation loss = 1.6250  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 2.6354  Validation loss = 1.5444  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 2.6344  Validation loss = 1.6196  \n",
      "\n",
      "Fold: 1  Epoch: 16  Training loss = 2.6333  Validation loss = 1.6656  \n",
      "\n",
      "Fold: 1  Epoch: 17  Training loss = 2.6273  Validation loss = 1.5993  \n",
      "\n",
      "Fold: 1  Epoch: 18  Training loss = 2.6255  Validation loss = 1.5388  \n",
      "\n",
      "Fold: 1  Epoch: 19  Training loss = 2.6211  Validation loss = 1.4480  \n",
      "\n",
      "Fold: 1  Epoch: 20  Training loss = 2.6173  Validation loss = 1.5406  \n",
      "\n",
      "Fold: 1  Epoch: 21  Training loss = 2.6110  Validation loss = 1.4395  \n",
      "\n",
      "Fold: 1  Epoch: 22  Training loss = 2.6070  Validation loss = 1.4462  \n",
      "\n",
      "Fold: 1  Epoch: 23  Training loss = 2.6039  Validation loss = 1.5531  \n",
      "\n",
      "Fold: 1  Epoch: 24  Training loss = 2.5940  Validation loss = 1.4251  \n",
      "\n",
      "Fold: 1  Epoch: 25  Training loss = 2.5882  Validation loss = 1.3477  \n",
      "\n",
      "Fold: 1  Epoch: 26  Training loss = 2.5853  Validation loss = 1.4166  \n",
      "\n",
      "Fold: 1  Epoch: 27  Training loss = 2.5895  Validation loss = 1.5886  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 25  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.4635  Validation loss = 1.7960  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.4535  Validation loss = 1.7579  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.4468  Validation loss = 1.6906  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.4406  Validation loss = 1.7467  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.4300  Validation loss = 1.6924  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 2.4282  Validation loss = 1.7401  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 2.4262  Validation loss = 1.7230  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 2.4228  Validation loss = 1.7471  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 2.4127  Validation loss = 1.6795  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 2.4109  Validation loss = 1.6670  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 2.4099  Validation loss = 1.6736  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 2.3957  Validation loss = 1.7009  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 2.3841  Validation loss = 1.6878  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 2.3724  Validation loss = 1.6722  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 2.3663  Validation loss = 1.6887  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 2.3616  Validation loss = 1.6559  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 2.3511  Validation loss = 1.6315  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 2.3544  Validation loss = 1.7144  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 17  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.3399  Validation loss = 1.9547  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.3445  Validation loss = 2.0358  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.3347  Validation loss = 1.9242  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.3373  Validation loss = 1.8501  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.3337  Validation loss = 1.8070  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.3335  Validation loss = 1.7584  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.3237  Validation loss = 1.8623  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.3219  Validation loss = 1.8266  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.3203  Validation loss = 1.8255  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.3177  Validation loss = 1.8325  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.3169  Validation loss = 1.8274  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.3143  Validation loss = 1.7951  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.3113  Validation loss = 1.7918  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.3128  Validation loss = 1.8293  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.3127  Validation loss = 1.8104  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.3096  Validation loss = 1.8086  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.3128  Validation loss = 1.7116  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.3190  Validation loss = 1.6606  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.3105  Validation loss = 1.6919  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.3025  Validation loss = 1.7488  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.3072  Validation loss = 1.7640  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.3033  Validation loss = 1.7057  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 1.3076  Validation loss = 1.6442  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.3074  Validation loss = 1.6166  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.2985  Validation loss = 1.7250  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.3007  Validation loss = 1.6155  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 1.2933  Validation loss = 1.6434  \n",
      "\n",
      "Fold: 3  Epoch: 28  Training loss = 1.2973  Validation loss = 1.6268  \n",
      "\n",
      "Fold: 3  Epoch: 29  Training loss = 1.2911  Validation loss = 1.6653  \n",
      "\n",
      "Fold: 3  Epoch: 30  Training loss = 1.2954  Validation loss = 1.5734  \n",
      "\n",
      "Fold: 3  Epoch: 31  Training loss = 1.2897  Validation loss = 1.6157  \n",
      "\n",
      "Fold: 3  Epoch: 32  Training loss = 1.2981  Validation loss = 1.6946  \n",
      "\n",
      "Fold: 3  Epoch: 33  Training loss = 1.2971  Validation loss = 1.5345  \n",
      "\n",
      "Fold: 3  Epoch: 34  Training loss = 1.2906  Validation loss = 1.6629  \n",
      "\n",
      "Fold: 3  Epoch: 35  Training loss = 1.2863  Validation loss = 1.5871  \n",
      "\n",
      "Fold: 3  Epoch: 36  Training loss = 1.3056  Validation loss = 1.4896  \n",
      "\n",
      "Fold: 3  Epoch: 37  Training loss = 1.2837  Validation loss = 1.4809  \n",
      "\n",
      "Fold: 3  Epoch: 38  Training loss = 1.2843  Validation loss = 1.4591  \n",
      "\n",
      "Fold: 3  Epoch: 39  Training loss = 1.2884  Validation loss = 1.4226  \n",
      "\n",
      "Fold: 3  Epoch: 40  Training loss = 1.2770  Validation loss = 1.4834  \n",
      "\n",
      "Fold: 3  Epoch: 41  Training loss = 1.2852  Validation loss = 1.3997  \n",
      "\n",
      "Fold: 3  Epoch: 42  Training loss = 1.2774  Validation loss = 1.4356  \n",
      "\n",
      "Fold: 3  Epoch: 43  Training loss = 1.2831  Validation loss = 1.5479  \n",
      "\n",
      "Fold: 3  Epoch: 44  Training loss = 1.2826  Validation loss = 1.5203  \n",
      "\n",
      "Fold: 3  Epoch: 45  Training loss = 1.2798  Validation loss = 1.4165  \n",
      "\n",
      "Fold: 3  Epoch: 46  Training loss = 1.2796  Validation loss = 1.3985  \n",
      "\n",
      "Fold: 3  Epoch: 47  Training loss = 1.2705  Validation loss = 1.4076  \n",
      "\n",
      "Fold: 3  Epoch: 48  Training loss = 1.2717  Validation loss = 1.4081  \n",
      "\n",
      "Fold: 3  Epoch: 49  Training loss = 1.2708  Validation loss = 1.4149  \n",
      "\n",
      "Fold: 3  Epoch: 50  Training loss = 1.2674  Validation loss = 1.4417  \n",
      "\n",
      "Fold: 3  Epoch: 51  Training loss = 1.2706  Validation loss = 1.4084  \n",
      "\n",
      "Fold: 3  Epoch: 52  Training loss = 1.2670  Validation loss = 1.4483  \n",
      "\n",
      "Fold: 3  Epoch: 53  Training loss = 1.2673  Validation loss = 1.4244  \n",
      "\n",
      "Fold: 3  Epoch: 54  Training loss = 1.2835  Validation loss = 1.3479  \n",
      "\n",
      "Fold: 3  Epoch: 55  Training loss = 1.2674  Validation loss = 1.4167  \n",
      "\n",
      "Fold: 3  Epoch: 56  Training loss = 1.2696  Validation loss = 1.4241  \n",
      "\n",
      "Fold: 3  Epoch: 57  Training loss = 1.2598  Validation loss = 1.4967  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 54  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.2363  Validation loss = 2.7564  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.2313  Validation loss = 2.6968  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.2307  Validation loss = 2.6661  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.2290  Validation loss = 2.6492  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.2212  Validation loss = 2.6113  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.2194  Validation loss = 2.5859  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.2206  Validation loss = 2.5788  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.2223  Validation loss = 2.5411  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.2173  Validation loss = 2.5360  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.2178  Validation loss = 2.4659  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.2155  Validation loss = 2.4656  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.2092  Validation loss = 2.4685  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.2081  Validation loss = 2.4775  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.2353  Validation loss = 2.3895  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.2029  Validation loss = 2.4389  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 1.2148  Validation loss = 2.5018  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 1.2019  Validation loss = 2.4330  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 1.2045  Validation loss = 2.4225  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 1.1973  Validation loss = 2.4232  \n",
      "\n",
      "Fold: 4  Epoch: 20  Training loss = 1.1993  Validation loss = 2.4038  \n",
      "\n",
      "Fold: 4  Epoch: 21  Training loss = 1.2122  Validation loss = 2.4919  \n",
      "\n",
      "Fold: 4  Epoch: 22  Training loss = 1.1969  Validation loss = 2.4313  \n",
      "\n",
      "Fold: 4  Epoch: 23  Training loss = 1.1990  Validation loss = 2.4316  \n",
      "\n",
      "Fold: 4  Epoch: 24  Training loss = 1.2003  Validation loss = 2.3337  \n",
      "\n",
      "Fold: 4  Epoch: 25  Training loss = 1.2184  Validation loss = 2.2749  \n",
      "\n",
      "Fold: 4  Epoch: 26  Training loss = 1.1956  Validation loss = 2.3838  \n",
      "\n",
      "Fold: 4  Epoch: 27  Training loss = 1.1963  Validation loss = 2.3810  \n",
      "\n",
      "Fold: 4  Epoch: 28  Training loss = 1.1987  Validation loss = 2.3898  \n",
      "\n",
      "Fold: 4  Epoch: 29  Training loss = 1.1910  Validation loss = 2.4065  \n",
      "\n",
      "Fold: 4  Epoch: 30  Training loss = 1.2045  Validation loss = 2.3369  \n",
      "\n",
      "Fold: 4  Epoch: 31  Training loss = 1.1965  Validation loss = 2.3526  \n",
      "\n",
      "Fold: 4  Epoch: 32  Training loss = 1.1849  Validation loss = 2.3908  \n",
      "\n",
      "Fold: 4  Epoch: 33  Training loss = 1.1855  Validation loss = 2.3815  \n",
      "\n",
      "Fold: 4  Epoch: 34  Training loss = 1.1839  Validation loss = 2.3534  \n",
      "\n",
      "Fold: 4  Epoch: 35  Training loss = 1.1887  Validation loss = 2.4003  \n",
      "\n",
      "Fold: 4  Epoch: 36  Training loss = 1.1916  Validation loss = 2.3916  \n",
      "\n",
      "Fold: 4  Epoch: 37  Training loss = 1.1850  Validation loss = 2.3296  \n",
      "\n",
      "Fold: 4  Epoch: 38  Training loss = 1.1821  Validation loss = 2.3083  \n",
      "\n",
      "Fold: 4  Epoch: 39  Training loss = 1.1806  Validation loss = 2.3233  \n",
      "\n",
      "Fold: 4  Epoch: 40  Training loss = 1.1862  Validation loss = 2.3565  \n",
      "\n",
      "Fold: 4  Epoch: 41  Training loss = 1.1769  Validation loss = 2.3270  \n",
      "\n",
      "Fold: 4  Epoch: 42  Training loss = 1.1764  Validation loss = 2.3244  \n",
      "\n",
      "Fold: 4  Epoch: 43  Training loss = 1.1761  Validation loss = 2.3362  \n",
      "\n",
      "Fold: 4  Epoch: 44  Training loss = 1.1776  Validation loss = 2.3670  \n",
      "\n",
      "Fold: 4  Epoch: 45  Training loss = 1.1762  Validation loss = 2.3890  \n",
      "\n",
      "Fold: 4  Epoch: 46  Training loss = 1.1778  Validation loss = 2.4130  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 25  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.2098  Validation loss = 1.9352  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.2053  Validation loss = 1.9161  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.1935  Validation loss = 1.8407  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.1944  Validation loss = 1.8115  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.1757  Validation loss = 1.6789  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.1822  Validation loss = 1.7022  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.1861  Validation loss = 1.7464  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.1689  Validation loss = 1.6091  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.1672  Validation loss = 1.5295  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 1.1621  Validation loss = 1.5270  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 1.1535  Validation loss = 1.4859  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.1517  Validation loss = 1.5052  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.1492  Validation loss = 1.4927  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 1.1467  Validation loss = 1.4800  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 1.1462  Validation loss = 1.4398  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.1424  Validation loss = 1.4711  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 1.1517  Validation loss = 1.3595  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 1.1518  Validation loss = 1.3430  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 1.1380  Validation loss = 1.3148  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 1.1306  Validation loss = 1.3158  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 1.1290  Validation loss = 1.2841  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 1.1243  Validation loss = 1.2624  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 1.1342  Validation loss = 1.2033  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.1230  Validation loss = 1.2080  \n",
      "\n",
      "Fold: 5  Epoch: 25  Training loss = 1.1269  Validation loss = 1.1576  \n",
      "\n",
      "Fold: 5  Epoch: 26  Training loss = 1.1230  Validation loss = 1.1546  \n",
      "\n",
      "Fold: 5  Epoch: 27  Training loss = 1.1224  Validation loss = 1.1230  \n",
      "\n",
      "Fold: 5  Epoch: 28  Training loss = 1.1188  Validation loss = 1.1480  \n",
      "\n",
      "Fold: 5  Epoch: 29  Training loss = 1.1135  Validation loss = 1.1823  \n",
      "\n",
      "Fold: 5  Epoch: 30  Training loss = 1.1089  Validation loss = 1.1639  \n",
      "\n",
      "Fold: 5  Epoch: 31  Training loss = 1.1071  Validation loss = 1.1765  \n",
      "\n",
      "Fold: 5  Epoch: 32  Training loss = 1.1316  Validation loss = 1.2259  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 27  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 1.1479  Validation loss = 0.8361  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 1.1494  Validation loss = 0.8487  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 1.1296  Validation loss = 0.9733  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 1.1320  Validation loss = 0.8919  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 1.1238  Validation loss = 0.9443  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 1.1137  Validation loss = 0.8661  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 1.1128  Validation loss = 0.9094  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 1.1142  Validation loss = 0.9537  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 1.1170  Validation loss = 0.9780  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 1.1049  Validation loss = 0.9029  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 1.1066  Validation loss = 0.9546  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 1.1009  Validation loss = 0.9343  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 1.0989  Validation loss = 0.9680  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 1.1000  Validation loss = 0.9911  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 1  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 1.0773  Validation loss = 1.2725  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 1.0678  Validation loss = 1.1508  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 1.0711  Validation loss = 1.1216  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 1.0785  Validation loss = 1.0474  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 1.0596  Validation loss = 1.1993  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 1.0567  Validation loss = 1.1412  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 1.0537  Validation loss = 1.2346  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 1.0585  Validation loss = 1.0726  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.0631  Validation loss = 1.1506  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.0727  Validation loss = 1.3543  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 1.0465  Validation loss = 1.1030  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 1.0458  Validation loss = 1.0829  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 1.0500  Validation loss = 1.3044  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 1.0446  Validation loss = 1.2806  \n",
      "\n",
      "Fold: 7  Epoch: 15  Training loss = 1.0458  Validation loss = 1.2047  \n",
      "\n",
      "Fold: 7  Epoch: 16  Training loss = 1.0507  Validation loss = 1.2114  \n",
      "\n",
      "Fold: 7  Epoch: 17  Training loss = 1.0652  Validation loss = 1.0127  \n",
      "\n",
      "Fold: 7  Epoch: 18  Training loss = 1.0493  Validation loss = 1.3436  \n",
      "\n",
      "Fold: 7  Epoch: 19  Training loss = 1.0412  Validation loss = 1.2696  \n",
      "\n",
      "Fold: 7  Epoch: 20  Training loss = 1.0569  Validation loss = 1.4525  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 17  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.9911  Validation loss = 4.3189  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.9794  Validation loss = 4.5139  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.9864  Validation loss = 4.5858  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.9888  Validation loss = 4.6355  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.9766  Validation loss = 4.3479  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.9753  Validation loss = 4.5201  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.9859  Validation loss = 4.3753  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 1.0054  Validation loss = 4.7435  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 1.0161  Validation loss = 4.8467  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.9754  Validation loss = 4.3138  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.9793  Validation loss = 4.2395  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.9795  Validation loss = 4.2113  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 0.9692  Validation loss = 4.4678  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 0.9913  Validation loss = 4.6265  \n",
      "\n",
      "Fold: 8  Epoch: 15  Training loss = 0.9812  Validation loss = 4.5515  \n",
      "\n",
      "Fold: 8  Epoch: 16  Training loss = 1.0106  Validation loss = 4.6200  \n",
      "\n",
      "Fold: 8  Epoch: 17  Training loss = 0.9664  Validation loss = 4.3834  \n",
      "\n",
      "Fold: 8  Epoch: 18  Training loss = 0.9633  Validation loss = 4.3833  \n",
      "\n",
      "Fold: 8  Epoch: 19  Training loss = 0.9642  Validation loss = 4.2030  \n",
      "\n",
      "Fold: 8  Epoch: 20  Training loss = 0.9731  Validation loss = 4.5342  \n",
      "\n",
      "Fold: 8  Epoch: 21  Training loss = 0.9882  Validation loss = 4.1415  \n",
      "\n",
      "Fold: 8  Epoch: 22  Training loss = 0.9604  Validation loss = 4.2633  \n",
      "\n",
      "Fold: 8  Epoch: 23  Training loss = 0.9605  Validation loss = 4.2338  \n",
      "\n",
      "Fold: 8  Epoch: 24  Training loss = 0.9852  Validation loss = 4.5201  \n",
      "\n",
      "Fold: 8  Epoch: 25  Training loss = 0.9580  Validation loss = 4.2405  \n",
      "\n",
      "Fold: 8  Epoch: 26  Training loss = 0.9654  Validation loss = 4.5479  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 21  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.3890  Validation loss = 7.0149  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.3975  Validation loss = 7.2014  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.3739  Validation loss = 7.1541  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.3584  Validation loss = 7.1686  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.3610  Validation loss = 7.0464  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.3916  Validation loss = 7.1993  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.3572  Validation loss = 7.1068  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.3532  Validation loss = 7.1687  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.3520  Validation loss = 7.1066  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.3638  Validation loss = 7.0657  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.3344  Validation loss = 6.9824  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.3316  Validation loss = 6.9364  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.3559  Validation loss = 6.9487  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.3751  Validation loss = 6.7812  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 1.3244  Validation loss = 6.9752  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 1.3189  Validation loss = 6.9958  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.3573  Validation loss = 7.2641  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 14  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.0573  Validation loss = 2.5834  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.9018  Validation loss = 2.0224  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.7854  Validation loss = 1.8844  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.7323  Validation loss = 1.6553  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.7128  Validation loss = 1.7351  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.6908  Validation loss = 1.7932  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.8569  Validation loss = 1.5872  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.7784  Validation loss = 1.7425  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.7108  Validation loss = 1.7672  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.6510  Validation loss = 1.8173  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.6113  Validation loss = 1.8051  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 1.6263  Validation loss = 1.7450  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 1.5803  Validation loss = 1.7857  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.5630  Validation loss = 1.8721  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 7  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.5871  Validation loss = 1.3888  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.6268  Validation loss = 1.7314  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.6124  Validation loss = 1.4108  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.5869  Validation loss = 1.2354  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.5862  Validation loss = 1.3545  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.5857  Validation loss = 1.0809  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.5648  Validation loss = 1.2498  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.5491  Validation loss = 1.1224  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.5435  Validation loss = 1.0912  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.5102  Validation loss = 1.2074  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.5025  Validation loss = 1.5942  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.4940  Validation loss = 1.3088  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.5016  Validation loss = 1.4608  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.4590  Validation loss = 1.3168  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 1.4614  Validation loss = 1.4186  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 1.4518  Validation loss = 1.3579  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 1.4446  Validation loss = 1.4168  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 1.4818  Validation loss = 1.4554  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 1.4283  Validation loss = 1.3897  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 1.4263  Validation loss = 1.5154  \n",
      "\n",
      "Fold: 11  Epoch: 21  Training loss = 1.4109  Validation loss = 1.6013  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 6  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.4101  Validation loss = 1.0015  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.3934  Validation loss = 1.0296  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.4001  Validation loss = 1.2540  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.4041  Validation loss = 0.9709  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.4039  Validation loss = 0.9502  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.3654  Validation loss = 1.0852  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.3667  Validation loss = 1.2009  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.3889  Validation loss = 0.9787  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.3626  Validation loss = 0.9867  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.3899  Validation loss = 0.9905  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.3726  Validation loss = 0.9415  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.3825  Validation loss = 0.9597  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.3460  Validation loss = 0.9204  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.3837  Validation loss = 0.9035  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 1.3496  Validation loss = 0.8893  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 1.3536  Validation loss = 1.1108  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 1.3456  Validation loss = 0.9206  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 1.3468  Validation loss = 0.9591  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 1.3236  Validation loss = 0.9858  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 1.3866  Validation loss = 0.8971  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 1.3282  Validation loss = 0.9967  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 1.4130  Validation loss = 1.0307  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 1.3117  Validation loss = 1.0208  \n",
      "\n",
      "Fold: 12  Epoch: 24  Training loss = 1.3092  Validation loss = 0.9999  \n",
      "\n",
      "Fold: 12  Epoch: 25  Training loss = 1.3570  Validation loss = 1.0210  \n",
      "\n",
      "Fold: 12  Epoch: 26  Training loss = 1.2934  Validation loss = 1.0782  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 15  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.2865  Validation loss = 3.4564  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.3683  Validation loss = 3.4306  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.2944  Validation loss = 3.6179  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.2619  Validation loss = 3.3814  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.2564  Validation loss = 3.6419  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.2783  Validation loss = 3.6595  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.2663  Validation loss = 3.5488  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.2374  Validation loss = 3.3285  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.2562  Validation loss = 3.7560  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.2635  Validation loss = 3.3454  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.2706  Validation loss = 3.8320  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 8  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.4772  Validation loss = 4.9322  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.4930  Validation loss = 4.3603  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.4520  Validation loss = 4.4084  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.5422  Validation loss = 3.8346  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.4607  Validation loss = 4.5374  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.4141  Validation loss = 4.3912  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.4104  Validation loss = 4.1730  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.4476  Validation loss = 4.2805  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.4244  Validation loss = 4.3902  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.5915  Validation loss = 4.9382  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.4052  Validation loss = 4.1295  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.4149  Validation loss = 4.3180  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.4540  Validation loss = 4.1602  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.3995  Validation loss = 4.2852  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.3490  Validation loss = 4.3199  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 1.4018  Validation loss = 4.1523  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.4437  Validation loss = 3.8521  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.3712  Validation loss = 4.2009  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.3619  Validation loss = 4.4397  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 1.4915  Validation loss = 5.0456  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 4  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 1.8593  Validation loss = 4.3367  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 1.8478  Validation loss = 3.4886  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 1.7120  Validation loss = 3.6943  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.9701  Validation loss = 6.1630  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.8580  Validation loss = 4.5072  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.8347  Validation loss = 4.4527  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 1.7389  Validation loss = 4.6904  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 1.6979  Validation loss = 4.3004  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.6632  Validation loss = 4.2052  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 1.6450  Validation loss = 3.9724  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 1.6526  Validation loss = 4.0778  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 1.6179  Validation loss = 4.1161  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 1.6003  Validation loss = 3.9428  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 1.6312  Validation loss = 3.9284  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 1.6249  Validation loss = 4.2572  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 1.6578  Validation loss = 4.0847  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 1.7727  Validation loss = 3.9127  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 1.5878  Validation loss = 3.8641  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 1.7702  Validation loss = 3.8721  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 1.5635  Validation loss = 4.1198  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 1.5269  Validation loss = 3.9140  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 1.6419  Validation loss = 5.1357  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 2  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 1.8105  Validation loss = 4.6216  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 1.8788  Validation loss = 4.2420  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 1.8282  Validation loss = 4.4673  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 1.7513  Validation loss = 4.8026  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 1.7131  Validation loss = 4.7006  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 1.9180  Validation loss = 4.4147  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 1.7256  Validation loss = 4.6306  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 1.6790  Validation loss = 4.6036  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 1.6791  Validation loss = 4.7334  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 1.8394  Validation loss = 5.0546  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 1.6552  Validation loss = 5.0675  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 2  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 1.8817  Validation loss = 2.6526  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 1.8279  Validation loss = 2.5357  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 1.9829  Validation loss = 2.6722  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.0214  Validation loss = 2.5838  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.1529  Validation loss = 2.4932  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 1.9162  Validation loss = 2.5309  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 1.8661  Validation loss = 2.3902  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 1.7444  Validation loss = 2.3233  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 1.8314  Validation loss = 2.2241  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 1.7462  Validation loss = 2.1955  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 1.7306  Validation loss = 2.1851  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 1.7125  Validation loss = 2.1475  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 1.9344  Validation loss = 2.2858  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 1.9646  Validation loss = 2.0815  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 1.8414  Validation loss = 2.0510  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 1.7279  Validation loss = 2.0425  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 1.7645  Validation loss = 2.2919  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 1.7403  Validation loss = 2.3009  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 16  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 1.8219  Validation loss = 1.7138  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 1.7473  Validation loss = 1.8962  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 1.8224  Validation loss = 1.7654  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 1.7888  Validation loss = 2.2127  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 1.8140  Validation loss = 1.8033  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 1.7819  Validation loss = 1.9812  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 1.7298  Validation loss = 1.7203  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 1.7479  Validation loss = 1.8045  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 1.7604  Validation loss = 1.8012  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 1.8320  Validation loss = 1.8796  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 1.7580  Validation loss = 1.7588  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 1.6447  Validation loss = 1.8023  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 1.6461  Validation loss = 1.8778  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 1.7431  Validation loss = 1.9729  \n",
      "\n",
      "Fold: 18  Epoch: 15  Training loss = 1.6799  Validation loss = 1.6856  \n",
      "\n",
      "Fold: 18  Epoch: 16  Training loss = 1.6538  Validation loss = 1.7062  \n",
      "\n",
      "Fold: 18  Epoch: 17  Training loss = 1.6596  Validation loss = 1.8036  \n",
      "\n",
      "Fold: 18  Epoch: 18  Training loss = 1.7009  Validation loss = 1.8635  \n",
      "\n",
      "Fold: 18  Epoch: 19  Training loss = 1.5868  Validation loss = 1.8275  \n",
      "\n",
      "Fold: 18  Epoch: 20  Training loss = 1.6135  Validation loss = 1.7679  \n",
      "\n",
      "Fold: 18  Epoch: 21  Training loss = 1.6486  Validation loss = 1.7135  \n",
      "\n",
      "Fold: 18  Epoch: 22  Training loss = 1.5803  Validation loss = 1.6981  \n",
      "\n",
      "Fold: 18  Epoch: 23  Training loss = 1.5340  Validation loss = 1.6694  \n",
      "\n",
      "Fold: 18  Epoch: 24  Training loss = 1.5618  Validation loss = 1.6853  \n",
      "\n",
      "Fold: 18  Epoch: 25  Training loss = 1.6031  Validation loss = 1.7445  \n",
      "\n",
      "Fold: 18  Epoch: 26  Training loss = 1.4874  Validation loss = 1.5735  \n",
      "\n",
      "Fold: 18  Epoch: 27  Training loss = 1.5789  Validation loss = 1.7341  \n",
      "\n",
      "Fold: 18  Epoch: 28  Training loss = 1.7294  Validation loss = 1.6001  \n",
      "\n",
      "Fold: 18  Epoch: 29  Training loss = 1.4375  Validation loss = 1.8500  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 26  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 1.4956  Validation loss = 2.5537  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 1.5938  Validation loss = 2.6412  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 1.5468  Validation loss = 2.8110  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 1.4801  Validation loss = 2.8622  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 1.5875  Validation loss = 2.7062  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 1.4517  Validation loss = 2.8538  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 1.4302  Validation loss = 2.8731  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 1.4560  Validation loss = 2.8373  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 1.4375  Validation loss = 2.8211  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 1.4271  Validation loss = 2.7940  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 1.3963  Validation loss = 2.9778  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 1  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 1.6197  Validation loss = 2.5936  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 1.5907  Validation loss = 2.2472  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 1.5411  Validation loss = 1.7107  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 1.5400  Validation loss = 2.0128  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 1.4941  Validation loss = 2.1456  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 1.4877  Validation loss = 2.1628  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 1.5139  Validation loss = 2.3101  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 1.6241  Validation loss = 2.4390  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 1.4895  Validation loss = 2.2074  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 1.4515  Validation loss = 2.1818  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 1.4662  Validation loss = 2.2320  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 1.4188  Validation loss = 2.3371  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 1.4965  Validation loss = 2.6182  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 3  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 1.4485  Validation loss = 3.1862  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.5882  Validation loss = 2.8809  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 1.3990  Validation loss = 3.0031  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 1.4029  Validation loss = 2.9688  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 1.3722  Validation loss = 3.3772  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 1.3978  Validation loss = 3.3590  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 1.3222  Validation loss = 2.8956  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 1.4160  Validation loss = 3.0683  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 1.3781  Validation loss = 3.0647  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 1.3751  Validation loss = 3.3348  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 1.3148  Validation loss = 3.1110  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 1.3462  Validation loss = 3.3258  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 1.3075  Validation loss = 3.1722  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 1.3415  Validation loss = 3.3745  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 1.2980  Validation loss = 2.9065  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 1.2951  Validation loss = 3.0938  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 1.2762  Validation loss = 3.0118  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 1.4441  Validation loss = 3.3543  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 1.2936  Validation loss = 3.4942  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 2  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 1.4876  Validation loss = 3.7159  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 1.4399  Validation loss = 3.8939  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 1.3963  Validation loss = 3.8436  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 1.3821  Validation loss = 3.7570  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 1.4670  Validation loss = 4.0625  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 1.4180  Validation loss = 3.8445  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 1.4642  Validation loss = 3.7127  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 1.3539  Validation loss = 4.1520  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 1.4176  Validation loss = 3.8212  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 1.3572  Validation loss = 3.5733  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 1.4401  Validation loss = 3.8836  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 1.4117  Validation loss = 4.1239  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 1.3898  Validation loss = 3.9132  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 1.3524  Validation loss = 4.2680  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 10  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 1.6546  Validation loss = 2.5747  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 1.6816  Validation loss = 2.1014  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 1.8120  Validation loss = 1.7739  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 1.7590  Validation loss = 2.1057  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 1.4718  Validation loss = 2.3415  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 1.5783  Validation loss = 2.0908  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 1.5473  Validation loss = 1.8374  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 1.5439  Validation loss = 1.3914  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 1.4599  Validation loss = 2.0330  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 1.9150  Validation loss = 2.0663  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 1.5241  Validation loss = 1.7929  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 1.4881  Validation loss = 1.6691  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 1.4663  Validation loss = 2.0802  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 1.4597  Validation loss = 1.8813  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 1.4365  Validation loss = 1.5828  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 1.7189  Validation loss = 1.2796  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 1.4956  Validation loss = 2.4236  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 16  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.7766  Validation loss = 1.6134  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.5206  Validation loss = 1.4454  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 1.5945  Validation loss = 1.5001  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 1.4285  Validation loss = 1.6822  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.8979  Validation loss = 1.5393  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.7680  Validation loss = 1.1810  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 1.6246  Validation loss = 1.9247  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 1.4290  Validation loss = 1.6047  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 1.4496  Validation loss = 1.2490  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 1.3481  Validation loss = 1.0847  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 1.4557  Validation loss = 1.2398  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 1.5542  Validation loss = 1.3587  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 1.3353  Validation loss = 1.1899  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 1.4255  Validation loss = 1.3596  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 1.3365  Validation loss = 1.4025  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 1.4243  Validation loss = 1.4393  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 1.3534  Validation loss = 1.4198  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 1.4896  Validation loss = 1.5669  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 10  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 1.4494  Validation loss = 2.1914  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 1.3150  Validation loss = 2.3931  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 1.1949  Validation loss = 2.2123  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 1.3325  Validation loss = 2.5727  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 1.4195  Validation loss = 2.4612  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 1.6845  Validation loss = 2.7751  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 1.1939  Validation loss = 2.4253  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 1.6571  Validation loss = 2.5317  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 1.1755  Validation loss = 2.4863  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 1.3552  Validation loss = 2.5936  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 1.1953  Validation loss = 2.4863  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 1.2732  Validation loss = 2.5666  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 1.2313  Validation loss = 2.5125  \n",
      "\n",
      "Fold: 25  Epoch: 14  Training loss = 1.1850  Validation loss = 2.5692  \n",
      "\n",
      "Fold: 25  Epoch: 15  Training loss = 1.1565  Validation loss = 2.5838  \n",
      "\n",
      "Fold: 25  Epoch: 16  Training loss = 1.2658  Validation loss = 2.5477  \n",
      "\n",
      "Fold: 25  Epoch: 17  Training loss = 1.1643  Validation loss = 2.6350  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 1  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 1.3988  Validation loss = 1.9340  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 1.4629  Validation loss = 1.5226  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 1.6341  Validation loss = 1.7502  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 1.4400  Validation loss = 2.2315  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 1.3492  Validation loss = 2.1558  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 1.3275  Validation loss = 2.1731  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 1.2736  Validation loss = 1.8444  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 1.2179  Validation loss = 1.9895  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 1.2807  Validation loss = 2.1303  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 1.3546  Validation loss = 2.3847  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 1.3423  Validation loss = 1.6958  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 1.2995  Validation loss = 1.7500  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 1.2674  Validation loss = 2.1294  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 1.2238  Validation loss = 1.8035  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 1.3394  Validation loss = 1.6954  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 1.1765  Validation loss = 2.3705  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 1.2459  Validation loss = 2.4257  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 2  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 1.2961  Validation loss = 0.8614  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 1.4913  Validation loss = 0.6906  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 1.1908  Validation loss = 0.7984  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 1.1860  Validation loss = 0.8770  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 1.1723  Validation loss = 0.7271  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 1.2386  Validation loss = 0.9160  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 1.2002  Validation loss = 0.6500  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 1.0972  Validation loss = 0.8276  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 1.2494  Validation loss = 1.0789  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.1451  Validation loss = 1.0006  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 1.0972  Validation loss = 1.0120  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 1.2497  Validation loss = 0.6770  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 1.0900  Validation loss = 0.7962  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 1.1804  Validation loss = 0.9301  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 1.0552  Validation loss = 0.7077  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 1.5450  Validation loss = 0.6447  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 1.0961  Validation loss = 0.7931  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 1.0263  Validation loss = 0.9115  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 1.0044  Validation loss = 0.9360  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 1.1215  Validation loss = 1.2125  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 16  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 0.9847  Validation loss = 0.4216  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 1.1029  Validation loss = 0.3106  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 1.0259  Validation loss = 0.1464  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 0.9773  Validation loss = 0.5109  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 1.1447  Validation loss = 0.4860  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 1.0701  Validation loss = 0.4138  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 1.0541  Validation loss = 0.2145  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 0.9227  Validation loss = 0.4094  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 0.9926  Validation loss = 0.2548  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 0.9248  Validation loss = 0.3376  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 0.9370  Validation loss = 0.4420  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 0.9356  Validation loss = 0.4174  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 1.2190  Validation loss = 0.7179  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 3  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 1.0156  Validation loss = 1.1182  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 0.8530  Validation loss = 1.1680  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 0.8739  Validation loss = 1.3943  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 0.8123  Validation loss = 1.2812  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 0.8893  Validation loss = 1.1500  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 0.8994  Validation loss = 1.0679  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 0.8243  Validation loss = 1.2130  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 0.9296  Validation loss = 1.2246  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 0.8163  Validation loss = 1.1214  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 0.8264  Validation loss = 1.1123  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 0.9941  Validation loss = 0.9852  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 0.8014  Validation loss = 1.0378  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 1.0089  Validation loss = 1.5034  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 11  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 0.8696  Validation loss = 1.4635  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 0.9738  Validation loss = 1.0314  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 0.8027  Validation loss = 1.4804  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 0.8087  Validation loss = 1.6658  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 0.8732  Validation loss = 1.6742  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 0.9065  Validation loss = 1.2575  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 0.7982  Validation loss = 1.6644  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 0.8150  Validation loss = 1.3503  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 0.7945  Validation loss = 1.3916  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 0.7711  Validation loss = 1.4594  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 0.8054  Validation loss = 1.4505  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 0.7577  Validation loss = 1.6126  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 0.7870  Validation loss = 1.6337  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 0.8878  Validation loss = 1.7559  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 2  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 0.8533  Validation loss = 1.6012  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 0.8655  Validation loss = 1.4236  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 0.8764  Validation loss = 1.5370  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 0.8422  Validation loss = 1.6367  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 0.8587  Validation loss = 1.4957  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 0.8279  Validation loss = 1.4869  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 0.8121  Validation loss = 1.5364  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 0.8129  Validation loss = 1.4457  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 0.7847  Validation loss = 1.3635  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 0.8058  Validation loss = 1.3704  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 0.8071  Validation loss = 1.4296  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 0.8425  Validation loss = 1.4869  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 0.8416  Validation loss = 1.4886  \n",
      "\n",
      "Fold: 31  Epoch: 14  Training loss = 0.8761  Validation loss = 1.5092  \n",
      "\n",
      "Fold: 31  Epoch: 15  Training loss = 0.7979  Validation loss = 1.4081  \n",
      "\n",
      "Fold: 31  Epoch: 16  Training loss = 0.7952  Validation loss = 1.3959  \n",
      "\n",
      "Fold: 31  Epoch: 17  Training loss = 0.7946  Validation loss = 1.4439  \n",
      "\n",
      "Fold: 31  Epoch: 18  Training loss = 0.7914  Validation loss = 1.3177  \n",
      "\n",
      "Fold: 31  Epoch: 19  Training loss = 0.7673  Validation loss = 1.4412  \n",
      "\n",
      "Fold: 31  Epoch: 20  Training loss = 0.9654  Validation loss = 1.7735  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 18  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 0.8928  Validation loss = 2.3176  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 0.8483  Validation loss = 2.6626  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 0.8336  Validation loss = 1.6995  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 0.8150  Validation loss = 2.5999  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 0.9118  Validation loss = 2.4015  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 0.8519  Validation loss = 1.7293  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 0.7312  Validation loss = 1.9173  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 0.8556  Validation loss = 2.5618  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 0.7847  Validation loss = 1.6025  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 0.7673  Validation loss = 1.6070  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 0.7741  Validation loss = 2.2129  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 0.8974  Validation loss = 2.5735  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 0.8289  Validation loss = 2.5636  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 0.7423  Validation loss = 2.1450  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 0.8353  Validation loss = 1.6352  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 0.7287  Validation loss = 1.9954  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 0.7283  Validation loss = 2.0572  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 0.7822  Validation loss = 1.3627  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 0.7222  Validation loss = 2.0919  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 0.7054  Validation loss = 1.8719  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 0.7605  Validation loss = 2.1664  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 0.7335  Validation loss = 1.9743  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 0.7232  Validation loss = 1.8996  \n",
      "\n",
      "Fold: 32  Epoch: 24  Training loss = 0.7155  Validation loss = 1.6383  \n",
      "\n",
      "Fold: 32  Epoch: 25  Training loss = 0.7031  Validation loss = 1.7189  \n",
      "\n",
      "Fold: 32  Epoch: 26  Training loss = 0.7118  Validation loss = 1.5842  \n",
      "\n",
      "Fold: 32  Epoch: 27  Training loss = 0.7120  Validation loss = 1.6093  \n",
      "\n",
      "Fold: 32  Epoch: 28  Training loss = 0.7071  Validation loss = 1.7819  \n",
      "\n",
      "Fold: 32  Epoch: 29  Training loss = 0.7646  Validation loss = 2.1975  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 18  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 12\n",
      "Average validation error: 2.56397\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 0.8144  Test loss = 2.9125  \n",
      "\n",
      "Epoch: 2  Training loss = 0.7857  Test loss = 2.8727  \n",
      "\n",
      "Epoch: 3  Training loss = 0.7743  Test loss = 2.8541  \n",
      "\n",
      "Epoch: 4  Training loss = 0.7671  Test loss = 2.8444  \n",
      "\n",
      "Epoch: 5  Training loss = 0.7615  Test loss = 2.8386  \n",
      "\n",
      "Epoch: 6  Training loss = 0.7566  Test loss = 2.8348  \n",
      "\n",
      "Epoch: 7  Training loss = 0.7523  Test loss = 2.8320  \n",
      "\n",
      "Epoch: 8  Training loss = 0.7485  Test loss = 2.8298  \n",
      "\n",
      "Epoch: 9  Training loss = 0.7451  Test loss = 2.8279  \n",
      "\n",
      "Epoch: 10  Training loss = 0.7419  Test loss = 2.8263  \n",
      "\n",
      "Epoch: 11  Training loss = 0.7390  Test loss = 2.8250  \n",
      "\n",
      "Epoch: 12  Training loss = 0.7363  Test loss = 2.8238  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x48260b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6beb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.8238449912 \n",
      "Fixed scheme MAE:  1.79450435519\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 0.7363  Test loss = 2.3235  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 0.7896  Test loss = 2.8289  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 0.8635  Test loss = 0.9147  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 0.8709  Test loss = 0.8197  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 0.7093  Test loss = 1.1521  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 0.7224  Test loss = 0.6004  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 0.7252  Test loss = 0.2493  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 0.7249  Test loss = 0.0224  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 0.6554  Test loss = 0.1068  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 0.6554  Test loss = 1.3580  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 0.6749  Test loss = 0.8833  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 0.6835  Test loss = 0.8808  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 0.6117  Test loss = 0.7310  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 0.6183  Test loss = 0.5840  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 0.6225  Test loss = 3.7043  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 0.7735  Test loss = 3.5267  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 0.7484  Test loss = 0.7012  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 0.7521  Test loss = 1.1099  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 0.7645  Test loss = 0.4915  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 0.7604  Test loss = 0.8763  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.6684  Test loss = 2.5126  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.7375  Test loss = 3.3394  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 0.8369  Test loss = 2.1342  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 0.8757  Test loss = 0.8668  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 0.7564  Test loss = 1.9898  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 0.7942  Test loss = 0.8754  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 0.8015  Test loss = 0.8993  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 0.8089  Test loss = 1.3385  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 0.7596  Test loss = 0.2353  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 0.7597  Test loss = 0.0887  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 0.7582  Test loss = 4.1035  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 0.9078  Test loss = 0.8964  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 0.8286  Test loss = 0.8488  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 0.8352  Test loss = 0.2661  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.8191  Test loss = 1.6445  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.8400  Test loss = 6.3609  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.1020  Test loss = 0.5019  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.0968  Test loss = 1.3461  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.0981  Test loss = 0.0843  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.0980  Test loss = 2.5437  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.9029  Test loss = 3.1592  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.9839  Test loss = 1.2615  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.9962  Test loss = 3.0959  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.0666  Test loss = 12.7953  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.9497  Test loss = 7.6996  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 2.1710  Test loss = 0.5919  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 2.1722  Test loss = 0.5081  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 2.1726  Test loss = 1.4220  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.5544  Test loss = 3.0616  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.5997  Test loss = 2.7169  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.6348  Test loss = 0.7487  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.6373  Test loss = 2.1180  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.5043  Test loss = 5.1007  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.6279  Test loss = 4.2341  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.7106  Test loss = 1.3086  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.7113  Test loss = 0.7200  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.4257  Test loss = 0.5615  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.4274  Test loss = 1.9604  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.4474  Test loss = 1.5070  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.4592  Test loss = 0.0624  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.3895  Test loss = 2.0978  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.4116  Test loss = 2.6317  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.4397  Test loss = 0.8777  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.4430  Test loss = 1.8512  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.3690  Test loss = 1.6022  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.3832  Test loss = 0.1042  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.3823  Test loss = 0.7389  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.3853  Test loss = 2.9650  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.3596  Test loss = 5.4526  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.5185  Test loss = 1.1050  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.5246  Test loss = 1.8326  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.5412  Test loss = 3.0397  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.3704  Test loss = 2.9286  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.4170  Test loss = 0.8761  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.4177  Test loss = 1.4904  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.4286  Test loss = 0.0294  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.2735  Test loss = 1.6383  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4VNXWxt89yaSTRgIBQkhIIZBQIiU0qYIIShUEQYoi\n5douKnhFuV79rl6vvVwLqBQpShFFQEFEioQaQgsghJaEkkISUkidzPr+2HMmU86UJDOZlP17njyQ\nM6fsmZx5z9prrb0WIyIIBAKBoPGgcPQABAKBQGBbhLALBAJBI0MIu0AgEDQyhLALBAJBI0MIu0Ag\nEDQyhLALBAJBI0MIu0AgEDQyhLALBAJBI0MIu0AgEDQynB1x0YCAAAoNDXXEpQUCgaDBcvz48dtE\nFGhpP4cIe2hoKBITEx1xaYFAIGiwMMZSrdlPuGIEAoGgkSGEXSAQCBoZQtgFAoGgkSGEXSAQCBoZ\nQtgFAoGgkSGEXSAQCBoZQtgFAoGgkSGEXSCwEfn5+Vi1apWjhyEQCGEXCGzFxx9/jJkzZ+L69euO\nHoqgiWMTYWeM+TLGNjHG/mKMnWeM9bHFeQVNi9OnT2PevHmorKx09FBqxLZt2wAAJSUlDh6JoKlj\nK4v9YwA7iCgaQFcA5210XkETYsuWLVi6dClSU61aNV2vuHXrFo4dOwYAqKiocPBoBE2dWgs7Y8wH\nwAAA3wAAEZUT0Z3anlfQ9MjMzAQAXLt2zbEDqQHbt2/X/l8Iu8DR2MJiDwOQDWAFY+wEY+xrxpin\nDc4raGJkZWUBAK5evergkVQfyQ0DCGEXOB5bCLszgHsAfEFEcQDuAviH4U6MsTmMsUTGWGJ2drYN\nLitobDRUi720tBS7du1CeHg4ACHsAsdjC2G/DuA6ER3R/L4JXOj1IKJlRNSDiHoEBlosJyxogkjC\n3tAs9j179qC4uBjjx48HIIRd4HhqLexElAEgnTHWQbNpKIBztT2voOnRUC32rVu3wtPTE8OHDwcA\nlJeXO3hEgqaOrRptPANgLWPMBcAVALNsdF5BE6G8vBx37vCYe0Oy2IkI27Ztw7Bhw+Dl5QVAWOwC\nx2OTdEciOqlxs3QhorFElGeL8wqaDlLgNDg4GDdv3kRpaamDR2Qdp0+fRnp6Oh566CEolUoAQtgF\njkesPBXUCyQ3THx8PAAgLS3NkcOxGikbZuTIkULYBfUGIeyCeoFksUvC3lDcMVu3bkWvXr0QFBQE\nFxcXAELYBY5HCLugXmBosTeEAGpmZiaOHj2KBx98EAC0FrsIngocjRB2Qb1AEvZu3bpBqVQ2CIt9\n69atICIjYRcWu8DRCGEX1AuysrLg4eEBb29vtGvXrkFY7OvWrUNERAS6desGQAi7oP4ghF1QL8jM\nzETLli0BAKGhofXeYr9+/Tr27t2LadOmgTEGQAi7oP4ghF1QL9AV9rCwsHov7N999x2ICFOnTtVu\nE8FTQX1BCLugXpCVlYUWLVoA4MKenZ2Nu3fvOnRMV69excKFC1FWVmb02tq1axEfH4+IiAjtNquC\npwUFNh+nQGCIEHZBvcDQFQM4PjNm06ZNeO+99/DBBx/obU9OTsapU6f0rHXAClfMhg1AixZARoZd\nxisQSAhhr08sWwZERwNqtaNHUqdUVlYiOztbzxUDOF7YJXfQv//9b712d2vXroWTkxMeeeQRvf2d\nnJwAmBH21auBsjLg7Fn7DFgg0CCEvT7x88/AhQvApUuOHkmdkpOTA7VarXXFSBZ7rf3saWnAm2/W\n+EF57do1BAcHQ61W48UXXwQAqNVqrFu3DsOHD9eOV4IxBqVSKS/shYXAb7/x/zexv6+g7hHCXpcQ\nAaasOSLg8GH+/xMn6m5M9QBp1alksbds2RJubm61F/a1a4FXXzX5eWZkZOCzzz4DEcm+fvXqVfTq\n1Qv/+Mc/sH79euzduxcHDhxAWlqakRtGwqSwb98OSL73eiLseXl5+Oabb6BuYjPEpoAQ9tpy8ybw\nyy/cMnz4YeDxx7lIy/H220BYmLy4X7kC5OTw/zcxYZcWJ0nCzhhDaGho7V0xUr2ZP/+UffnVV1/F\n008/jUsyQktEuHbtGkJDQ7Fo0SKEhobimWeewapVq+Dp6YmxY8fKntPFxUVe2DdvBlq25K42a4W9\nogI4eNC6fatJYWEh7r//fsyePVvbq1XQeBDCXhteeglo0wYYNYpbhn/+CaxYARw5YryvWg18+SVw\n4wZw/Ljx65K13qxZkxV2XdeGTVIepabYMsKenZ2NNWvWAABSUlJkx1RaWoqwsDC4u7vjgw8+QHJy\nMpYvX46xY8fC01O++6NSqTTOiikp4Q//sWOBDh2sF/b/+z+gXz/gwAHr9reSkpISPPTQQ1pB/+uv\nv2x6foHjEcJeU374AXjnHWDqVGDfPiA/H0hJAdzdgVWrjPc/cKDKgvzjD+PXjxwBPD35l//ECdNW\nfyPE0BUDwDYWu66wG3yeS5cu1aYxXrx40ehQ6dqSv3/s2LEYNmwYAGDatGkmLynritm1C7h7Fxg/\nHoiIAC5ftuz3v3ULeP99/v8vvjC/bzUoLy/HxIkTsX//fqxatQrOzs64cOGCzc4vqB8IYa8Jly9z\nl0uvXsDy5cCAAYC3N/8ZPx74/nvAsJ746tVcuKOigD17jM955AjQowf/yc7mX+wGzv79+zF69Gio\nVCqz+2VmZsLZ2Rl+fn7abWFhYcjLy0N+fn7NLk7Ehd3Pj3+eOuJdXl6Ozz77DMOHD4ePj4+sxS7N\nFqQMHcYYvv76a7zxxhtagZdDVtg3bwZ8fYFBg7iwl5RY/vu+/jr3yY8eDWzaxN9DLamsrMT06dOx\nfft2fPHFF5g+fTrCw8OFsDdChLBXl9JSYNIkwMkJWL8e0Kw21DJjBnDnDrB1q/4xGzdy0R85klvv\nuoteSku5ld67NxAXx7c1AnfMpk2bsHXrVou11TMzM9GiRQvt0nzABrnsubncSp40if+u447ZsGED\nMjIysGDBAkRFRckKu3Tddu3aabeFhIRgyZIl2rRGOYyEvaKCZzs99BC/V6QFTebcMRcuAF9/Dcyb\nB/znP1zgV6yw/J4tsH79eqxfvx5vv/025s6dCwDo0KGDcMU0Qmwm7IwxJ8bYCcbYNlud0yJqNWDB\nGrQ5zz8PJCVxd4tGfPQYMoT73XXdMdu2cVfNY48BgwdzIZd86gBw8iQXgPh4oGtXvs0Owp6bm4s9\ncrMFO5GcnAwAuHLlitn9srKy9NwwQJWlXGM/u+SGGTYMCAzUCjsR4cMPP0R0dDSGDx+OyMhIk66Y\ngIAAbbs7azEKnu7bB+TlARMm8N8lYZd5mGhZvJi79JYsATp14jPCpUtrvb5hy5YtCAoKwsKFC7Xb\nOnTogEuXLqGysrJW5xbUL2xpsT8H4LwNz2eZ114DYmLqzh/900/c37lwIbfA5HBy4gK+Y0fVCsM1\na4BWrbjoDxgAKBT6fnZJ5OPjuTsnIsIuwv7+++9j+PDhskvk7YEk7JbEWXfVqYTNhD00FOjfXyvs\nCQkJSEpKwnPPPQeFQoGoqCikpaUZteK7evWqdgzVwSh4+sMPgIcHoGl0jbZtAaXStMV+6BB33Sxa\nxFepAsD8+Txrateuao9HoqKiAjt27MCoUaOgUFR97aOjo1FeXu7wxWAC22ITYWeMBQMYBeBrW5zP\nKoi43/riReDcuTq5ZMUXX6C8TRue2miOGTOAykqeR52TwzMiHn2Ui76vL9C9u76wHznCv/CtW/Pf\nu3XjVryNOXXqFFQqlbZptD3JyspCtsYvbMlilxN2f39/eHl51VxwJGFv1w64917g6lXgxg18/PHH\n8PPzw2OPPQYAiIyMBBEZjVFKdTRLWhrw8stV+ekwcMVUVgI//sjdb+7ufJuTE9C+vbywE3FBb9kS\nWLCgavu4cXzW8eWX1fkE9Dhw4AAKCgq0teMlOnToAADCz97IsJXF/hGARQDqbqXDmTNVX97ff7f/\n9crKoP7jD3yTkYG8oiLz+0ZHc+t71Sruh6+o4Fa8xJAhXMylIldHjvD9JeLiuIVW08ChCSQLui6E\nXboWYF7YiUivAJgEY6x2KY+pqdxSbt6cCzuA7M2bsXnzZsyZM0ebrhgZGQlAPzNGrVYjNTXVssX+\nww98bYJOPEVP2A8dAjIzeWxFl4gIeWH//Xcef/nXvwBdF5CrK/DEE9xXr1PaoDps27YNLi4uuO++\n+/S2C2FvnNRa2BljDwLIIiKZ5Gy9/eYwxhIZY4nZNojwY8sWgDFu3ezeXfvzWYASEuCqUuGXykps\n3LjR8gEzZvCHz1tvAbGxQJcuuHDhAlauXMmFvaICSEgAsrK4NWko7IBNrfbCwkKkah6EdSnsXbt2\nNSvsBQUFKCsrM7LYgVqmPKamcmudMT4D8vJCxqZNUKvVmD17tnY3Sdh1A6i3bt1CeXm5ZYtdElmd\nwKaesC9fzh8uo0bpHycJu6EL8ZdfADc3YNYs42vNmcP3/7pmk+Jt27Zh8ODBRjGDgIAA+Pv7iwBq\nI8MWFns/AKMZY9cAfA9gCGNsjeFORLSMiHoQUY/AwMDaX/Xnn7kYjhnDA1R2DqJmrl6NCgD7GcPq\n1astH/DIIzwL4sYNbq0zhn/+85+YNWsWboaFcT/rH39ULWbq3bvqWDtkxpzTcVfVlbAHBASgd+/e\nZq1uw1WnukgWu6kl/7rcuXMHixYtwvDhw7mPOy2NCzsAODsDffuipcYqbdu2rfY4X19fBAYG6gm7\nYaqjSdLT+b+//spXIEMneJqTA6xbx//23t76x0VE8Nma5r1r2bcP6NOHW+iGhIUBI0YAX31luiyF\nCS5evIiLFy8auWEkOnToUHcWuwW3nMA21FrYiehlIgomolAAkwH8QUSmV3DYghs3gMRELupDh/Ia\n14mJdr2keudOHATwxN//jgMHDsiKVXFxcdXydH9/Pj7GgEcfRVlZGX799VcAwPa9e/lDSRJ2Jyfg\nnnuqThQUxH9sKOy6rpG8vDybndfc9WJiYhAeHo6cnByT+ehyq04lwsLCUFRUpF3AJEdFRQU++eQT\nhIeH491338WuXbuQkZHBLfaQkKod770XLTIz0VKphKuBcBpmxhguTjLJ9etccNVqHu+BTvD0m294\nSutTTxkfJ5fymJfHZ2gDB5q+3uOP8weI3MpmM2zfvh0AMMpw5qAhOjq6boR92zYgPBw4dcr+12ri\nNMw8dsmnOXo0d2sA9nXHZGWh9a1bON+2Lf7+978DgHY5ui4zZ85E165dqyzi997jM4vgYOzbtw+F\nhYVQKBT8izZkCC8tsHMn0KULn7LrYuMAqq6w29tiJyIkJycjNjYW7du3B2A6u0Vu1alE586dAQBn\nzpyRPfbSpUuIiYnBc889h7i4OCxZsgQAUJiRAdy+XWWxA1o/+1A3N6PzGOayS2PVzWGXJT2dZzn1\n78/dMURQKpWoLC/n2VMDBwKa96CHnLAfOMBdLeaEffBg/q+J2jem2LZtG2JiYkzOQDp06ICMjIya\nLwazlp9+4v8eOmTf6whsK+xEtJeI5Od7tmTLFv7l6NgRCAjgImhHYb+zaRMAwOXBBxESEoJBgwbh\n22+/1XMR7Nu3Dxs3bkRxcTE2bNjAN4aEAJrp75YtW+Dh4YHp06fj999/R3n//tzSS0zUd8NIxMXx\nbB8bpSZKFjRgf2FPT09HYWEhYmNjtWJiys9uzhXTpUsXADybR47ly5fj6tWr2LZtG3bt2oX+/fsD\nAMolwdQV5l69oFIoMFBhfMtHRkbi5s2bKNIExa9du4agoCC4S5kscqhUfPVocDD3iV+4ABw6BKVS\niT55ecC1a8DTT8sf264dn6XpCvu+fdwFI3cvSDRvzuM1+/eb3seA/Px87N+/36QbBqijACoRTwEG\nGsXiu/pOw7PYCwu5C2P0aO7mALg7JiEBKC62yyWz167FbQA9nnwSAPDYY4/h0qVLOKKZEldWVuK5\n555DSEgIOnTogFUGtWKICD///DPuv/9+PPzww7h79y72lZXxQBmgHziViIvj4qFjadeG5ORk9OzZ\nE66urvZzxZSVAZcuaWcH1ljsmZmZYIwhICDA6LXAwEC0atUKp0+flj02KSkJMTExGDVqFBhj8Nb4\nslWXL/MddIXd3R0XfXzQW8Y/LQVQJTeaVTnsGRk8nbFtW2DiRF4uYsUKKJVKPJKTw1NXx4yRP1ap\n5Pn1BsKu7tULh0+eNB9TGDCA3+tWxpR27twJlUrleGFPTuYuVIVCCHsd0PCEfedOnjes+6UZOpRv\nS0iw/fWI0DwpCQkeHujcrRsA4OGHH4abm5s2iLp8+XKcOnUK77zzDp544gkcPHhQz2d74sQJXL9+\nHaNHj8bgwYPh5uaGbbt28Sk8YFrY+cG1fgs5OTnIyMhAbGwsfH19a2yxX7p0CUuWLEGBqb6dH34I\ndOiAPI1PNyYmBr6+vvDz8zNpsWdlZaF58+ZwdnaWfb1r166yFjsR4XhiIgZFR2u3ScLOpBIGBq6U\nE15e6FRSwgOQOguSoqKiAFRlxliVwy5lxAQH84qcEycC69cjoqgIA4qLeTkATas8WXRTHvPzgaQk\nnPLxQZ8+ffC+VPxLjgEDuHFjpZ9627Zt8Pf3R28zM4Hw8HA4OTnZV9g18SVMmsSzxep6xbgcZ87w\nGdCUKcDKlY2iPpMWIqrzn+7du1ONmTaNyN+fqKKialthIZGzM9FLL9X8vCYoPXaMCKBVgwfrbX/k\nkUfI39+fsrKyKDAwkPr3709qtZpu3rxJCoWCXnnlFe2+//znP0mhUFB2djYREY0cOZLCw8NJvWIF\nUe/eRJWVxheurCRq1ozoqadq/R727dtHAGjHjh3UoUMHmjRpUo3O8+KLLxIA6tixI128eNF4hwED\niAC61awZRbRqpd3cvXt3GjFihOw5x40bRzExMSav+dJLL5FSqaSysjK97WlpafRfgCqcnYkyM4mI\n6Pr16wSAkkaM4PeDSqV3zAMdO9JFHx8igCgoiOg//yHKy6OioiICQG+++SZVVFSQs7MzLV682PyH\nsWEDP8+pU/z3/fuJAMps1ozKAKJbt8wf//TTRD4+RGo10fbtRAD95777CAABoO+++07+uBs3+HU/\n+MD8+YlIpVJR8+bNaerUqRb3jYyMpIcfftjifmaprCQ6fVr+tUGDiLp0IVq9mo//zJnaXau2VFYS\n9enD/wZBQXxMAFGHDkTR0URt2vDXmjcn2rrVsWPVAUAiWaGxDctiV6l4J5oHH+QpbBJeXtw3aQc/\n+9VlywAAwTNn6m2fPn06cnNzMWLECNy+fRsff/wxGGNo1aoV7r//fnz77bfazjRbtmxBv379tO6G\nUaNG4fLly7jYpw8PJMn4faFQ8NhBbSz2GzeATZu0rpGYmBj4+fnV2GI/d+4cgoKCkJWVhV69emHn\nzp1VL969y9/LgAEIKizE+zp/n7CwMLM+drmMGIkuXbqgoqLCyJq8tmoVXgTgrFJpq2VKFrtrZia3\npA2KdV0oK8Pro0bx+6RrV75qNCoKnnfvonXr1rh48SJu3LgBlUpVPYsd4LOviAi0KCzEVldXntVk\njogIbqnfvs3960olvk1JwciRIzFgwADMmDEDe/fuNT6udWueWWKFn/3o0aPIyckx64aRsEkxsDff\n5IkAUpBUoqCAB4cfeKD+FLlbvpzfr598wjONTp7ki82io7kVP3w4X4sSHMxnY+Zq4qvVPFPp1Vd5\nqREzOlRnaaXWqL+tf2psse/Zw5+qmzYZv/avfxExRpSbW7Nzm+Bc27Z0ljEqLi7W215RUUEtWrQg\nAPTEE0/ovfb9998TAPr999/p2rVrBIDeffdd7evStvfff9/8xZ95hsjTU392okNGRgbt3LnT9PEj\nRxIB9OKsWeTj40NqtZpGjBhBPXv2NH9dE4SFhdHkyZPpypUr1KVLF1IoFFXvYccOIoBU27fTx05O\n/O/0229ERLRo0SJycXGhSpmZSUREBE2ePNnkNZOTkwkArV69umpjfj7l+vjQBYDUzZoRzZ1LRERq\ntZoYY3StbVuigQONzhUQEEDz58+v2nDgAL9nliyhQYMGUd++fWnv3r0EgH7TjN0kCxYQeXhwi1vi\nrbeIABru5WX+WCKibdv4Z3TwIFF8PJX17Km9J3Jzc6lTp07k4+NDZ+Qs21mzuCUpN9PT4dNPPyUA\ndOPGDYvDeeGFF8jV1ZVUBrMcq/nrLyIXF/6e4uL0P5fNm/n2PXv4vezmxj8/R5GdzWf9Awboj1OO\nrCyiqCgiX1/j2cipU0SPP07UogV/f05ORIGB2ntK93t79+5dWrBgATHGaMuWLTUeOqy02BuWsC9Y\nQOTqyl0vhvz5J387mzfX7NwyqO/epVKAfmzfXvb1RYsWka+vL2VkZOhtLykpIR8fH5o2bRp98skn\nBMDIdRETE0NDhgwxP4DvvuPv6dgxk9c3+cU9eFA7vXwuNpb69etHRESTJ0+myMhI89eV4e7du8QY\no9dff52IiIqKimj8+PEEgA4fPky0cCGRUkkpJ0+SG0B5rVvz6WxuLn355ZcEgNLT043O26xZM3ru\nuedMXreiooJcXFzoxRdfrNo4cyapAJoSFkY0ahSRzvvx8fGhXC8vounTjc7l4uJCLxm668aMIfL3\np6dmzaLAwEBasWIFAaCUlBTzH8jEifwLr0tpKf1v0iTy9PQ0fywRF0KA6PPPiZyc6Ny4cVWfJRGl\npqZS69atKTg4mIqKivSPXbGCH5ucbPYSzz77LHl5eZHakngR0bJlywgAXblyxfLYDVGr+YPU15e7\ntwB998WcOdytWF7Of+/Vi7tmHMXjj3NXnYXPT8u1a/xebtWK6OpVoqQkorFj+fv08iKaPJlo7Vqi\nnByioiL+4AWI7r2XKD2d9u7dS+Hh4QSA5s+fTwUFBTUeeuMU9r17iT75RP61sjJu3VbDJ52amkqf\nffYZrV27lnbs2EHHjh2jK1eu0J07d0itVtPVpUuJANr+zDOyx5eXl1NOTo7sa3PnziV3d3eKj4+n\njh07Gr2+aNEicnZ2pvz8fNMDvHmT/4l0rH1dRo4cSQBo6dKlxi8OHUrk50cE0BJ3d5qrsWrnzZtH\ngYGBsucrKiqi0yZ8pElJSQSANm7cqN1WUFBAAQEBdP/99xPdcw/RgAG0efNmAkBnV63iFsy0afTb\nb78RANq3b5/eOYuLi7W+bXPExcXR8OHD+S8//kgE0AeenvTYY48Rvfce/4yuXyciorDgYKqULCYd\nSktL5a914AARQL+NHUsA6LnnniPGGJWWlpodE/XuzT9jA1566SVycXExfywfEJFCQRQfTwTQF+PG\nkZubm14sYdOmTQSADh06pH/s5cv8PX/2mdlLPPDAA9StWzfLYyGi/fv3EwD69ddfrdpfj2++4eP5\n6isu3qGhXLzVav7Tti3RuHFV+8+dyx8Chg+cykpuoFnxIKoxmr93teNxycn8++Try4/38SF67TXT\nHoLVq0nt6UmFbm4UAlD79u3pjz/+qPXwG6ewW+KBB4hCQohu37Zq9yeeeEIbrDL8aaNQ0FGFgooB\numHJepPh0KFD2nMZWYlUFdDcJOdW0iUqiujBB2VfCg0NJQA0atQo/Rckl9UHH5CqVStaA9Cnn35K\nREQvv/wyOTs7y1px7777LimVSsrLyzN6be3atQSAkg2snHfeeYf8AVIzRvTGG/TGG28QY4xbma+8\nQgRQ6rZtBIBWrFihd6zkkvr666/NfgQzZ86k8MBAot27iQICqLxzZ1IC9NFHHxEdP87fq8ZVMzwq\niv9ucM6srCyCzuegRa0m6t2bCoOCSAFQp06dKDg42Ox4iIgoOJhoxgyjzUuWLCHGmFVWMoWGkjSF\nvzcujgYauI8kN9S6deuMx9ymDdEjj5g9fUREhNWB8szMTIL0mVaHzEwueAMGVLmGNAYR7dzJBRHg\n2yS+/JJvM5wdfPst356YWL0xWEt5OVFsLNcIw1mQNRw8SNS1K9HrrxPJfEcM2f/RR0QArevf33jW\nVUOsFfaGFTy1xIIFvP5Gv368sJYFjh8/jsGDB+Ovv/5CQkICtmzZguXLl2PNs8/inIcHuigU2DFt\nGlpLKwWrQXx8vDaNboxMPnPfvn3h6+urXe5tkoED+UpDg0YIxcXFSE1NhaurK3bv3o27UqVIIt6g\noXVrYN485LRrh3vAc8oBXhtFpVKhWCbnPy0tDRUVFTgu02z73LlzcHJy0uZ8S/ztb3/DWG9vMCJg\n6FAkJyejffv2vHriggWAqyvabNsGhUJhFEA1tzgJAA9QTp+O93/5BZeys3laa2kpEubNQwWAe+65\nhwdBfX21AdQIKcVQt5wAoE3R9Das28IY8OKL8MrIwFjN+7QYOFWpeMBNp+aMhFKpBBFZ17hCc19V\n3nMPDp4+jX79+um9LI3DaA0AYzztcf9+40JiGioqKnD16lWjv5cpAgMD4evrW/0A6oIFPHC+dGlV\nEoAUdPy//6tKc3zggapjTAVQpfUfFjpu1Zh163g+/Ucf8XUH1aVPHx5k/ec/+T1ngZ/T05EJYFJo\nqMnm5/aicQn7sGG8GUFWFv8jyAiURGlpKZKTk9G7d2906NABffv2xejRozHLyQlTly6Fd0AAXBMT\nMc6agl8yMMawcOFC9O3bF7169TJ63dnZGSNGjMAvv/zCp06mGDiQZ08Y5C1fuHABRIRZs2ahtLQU\nv0uli3ft4hH8V14B3N1x2dsbHQDEaETCV3NDymXGSMv7E2Xq7pw/fx4RERFwMWgF6OnpiWdjY1EI\nYF9xsbaUAAC+UnLSJDitXYsObdoYCZS5OjEA+ANqwwZURkTgVQBJ//43kJqK/bdvgzGGbt268cyX\ngQO1wh4mZcIY5LBLy+WNhB0Axo6Fun17SH2FrFqcpFZXZcTooNQ8WIz6nsqhEfbr4eGorKw0EnZP\nT0+0aNFCfnHXgAE871pajGXA1atXUVlZabWwM8aqXwzs0CEulosX82wSCVdX4B//4PfhBx/wZji6\nD8HOnfnfTVfYr1+v6lEgNaixJUTAxx/zsYwda/vzy7B33z5c9veHU1JSnVxPl8Yl7ACvCZKQwFd1\nDhzIGwFWzsnCAAAgAElEQVTLLIZITk6GSqXiVp/EG29wa6NvX+DYsao2dTVk9uzZSEhIMNkj8957\n70VmZiZu3Lhh+iRS7ZB9+/Q2S9Ua586dCx8fH/z8889V1npICK/fDSCxshIKAIGaxRfmhF0qp3zs\n2DGj186fP4+OHTvKDrFzVhYOu7ri5X/+ExcvXqwSdoAv1CksxOMeHkYWu7k6MSgoADZsAKZPh+Ln\nn/EmgD9cXQF/fxw/fhxRUVFo1qwZ33fIED5DS01FiNQ+zlqLHQCcnKB44QX0BtAXVhT/kqo6mrDY\ngeoJ+0HNMX369DHaJSwsTL508YAB/F8TaY/SYitrhR2oQZXHbdt42vHzzxu/9sQTvGvYrVv61jrA\nm45ER+sL+7p1VbMPewj7gQP8es8+W7Vi3Y7k5+cjKSkJpZ07A+fP80VldUjjE3aA15A5dAiIiuI5\nqAEBfMXbihXcmge07obu3bvzYz78kLfamzGDr26VWeJuayzVQgHArcLwcCNhP3/+PJycnNCpUyc8\n8MAD2Lp1Kyq3bAGOHuVTRU0Fw123b/MDNF8iPz8/AJoKj999V1W6AFVCayjsFRUVSElJkRf29HQo\nLl2C28iROHToEFQqlb6w9+kDdO6Mh2/fNhL2hF9+wUgPD7Rq1cr4vN9/z0tEPPEEmjdvjjZt2mg/\np6SkpKq/G1BVHGvPHrSqqECWQlFVrkGDJOw+Pj7G1wKAmTORr1RiIayw2A1z2HWolrCPGQNMm4bv\nMzK0awwMMdlsRKqTZELYpZXPkjvQGqKjo3Hz5k0UWitCe/YAPXvylbeGuLlBLfVWHTnS+PW4OH1h\nX7OGr0Vp0cK4nLGGiooKrF+/vmb9WT/6iFdcnWbfwrMSCQkJUKvVaP7AA/yBZcZ7YA8ap7AD3FpI\nSAA2buSNhA8c4GVPQ0OBd9/FycRE+Pn5cets+XJudTz8MC+3am4puA2RqheaqoWiZeBA/gXWaWZ8\n7tw5rWtk9OjRuJ2djdJFi/hDYPp0ALwT0B8pKShyc+MNuGFgsX/9NfcZaqbz2dnZcHJyQlpaml6p\n3EuXLkGlUqFTp07GY9Msxui1eDGCNUKnJ+yMAfPmITQnB20yMrS+/bSUFDy5eTO2FxfDRa4UxDff\n8Gmzxo0llRbIysrC9evX9WdaMTFc5PbsQcvSUqTKuLbMWuwA4OGBhK5dMRbAfdu2VXW3ksOMxS65\nqqy12CtXrsTeI0e0BcwMCQ0NRVpamrGYMcZnp2Ysdl9fXzRv3tzyODRI9+PBgwct71xUxGe10kNV\nhtU+PhgEYI+cqzEujscpsrK4m/HMGV67vmVLkxb7+vXrMXny5Koie9Zy7RpfNPXkk8ZVVO3E3r17\n4eLigqipU/mGo0fr5LoSjVfYAT7lk8T6xg1uIQwfDixahL+vXYspERFgmzfzP/jw4dxqMOE2sQc+\nPj4IDQ21Ttjz8vjNr0HXNTJixAhMYgyeKSnA669rH0ypqam4W1yMO2FhWutIEva7N29WiUJyMtRq\nNW7fvo2+ffsC0Peznz/Pe5TLWuy//w60aAHX7t3xzjvvoFu3bsZW4rRpqHB1xXxoap0TIWvcOPQB\nUOnjwx+qusJ15gz/IsyerZ02d+nSBefPn8dhTeNvPWFXKIBBg4A9e9C8qAhXiYyE1aKwA0h99FF8\nCqDt5s3cDWeqPO7161wgZAJoksWu19DaDGfPnkVBQYGRf10iLCwMFRUV8u66AQO4C0qn5LBESkoK\nIiMjwarhdhg2bBj8/f2xQqcjlEkOHOAzPTPC/s3KldgHYKOmOqoeul3CVq/mLp1HHuErdk0I+w5N\ndUjDInsW+ewzfh/J1ca3E3v37kV8fDzcg4N5j1sh7HZCapH200+o2LABzUpK8GliIjB5Mp8Cbt4s\n37nGznTp0sW8KwYw8rOXl5fj0qVLWgvar1kzvOvmhhRXV/5+NEilBNg99/BsgIoK7XTf59ChqthD\ncjLy8vJQWVmJ+++/H4wx7o6prATu3NH686N1A2QAn2Lu3s193IxhypQpOHHihFGAFd7eyBsxAlMA\npJ0+jbK33kKPs2exPiYGTl98UfXllpBmTTrT5q5du0KlUmHt2rUAgDhJGCQGDwbS0+Gfm4tUwKhQ\nmTXCPmPuXETt2MFdDGo1/9wXLjTOPElP59a6jGhWyxUDPmUHYFbYARPVMSdO5Pfsf/9r9JIk7NXB\n1dUVU6dOxY8//oicnBzzO+/Zw/9GGkPAkEuXLuHPP/+Ei4sLfvzxR215DS2agnpITOT+9ZEjebA9\nKEjWFaNWq7Fz504olUrs2rXLfFxKl7t3+cx0/HjZGZY9KCgowPHjxzFo0CC+oVcvPrupQ5qOsOuQ\nHBGBjgAuDx/OU+i2b69Z+pMN6KLphVqqU23QiHbtuAtJI+ySa0RrQa9ejbYlJVhUVobLmkBbZmYm\nPvroIzDG4Dd4MK9+ee6c1sfcJimJuy/CwoCzZ7WB0/bt2yM6OpoL+xdfAO3aIfXUKbRr1844Zev8\neW5dDR1q8X0qn34aHgAi/vMfuCxZgvUAQpYt4w+i+HiexXP3Li/9u3o1z1zQiXN01QSyf/rpJ4SH\nh2tnHlo0DVcYkUlhd3Z2hptMow0JDw8P3H///dz6P32au7Tee0/rxtJy/bqsfx2ombAHBQWZ9Oub\nFfY2bXgv1FWr9FrOlZaWIi0trVr+dYknnngC5eXlWLdunfkd9+zhfzcTro1vv/0WCoUC//73v5GR\nkaGdaWnx8+P39eef8wCr1OxdcsUYPEyTkpJw+/ZtvPrqq1Cr1bKNbkwMBLhzB9A0yNFFpVJhxYoV\nVs+u5MjNzTXaJvnX9YQ9Lc0+QWETNElhT0pKQgEAfPopL/5vRU6qvejSpQvUarVeT1JZdPzseq6R\nsjLg9ddR2rkzfgKwdetW/PTTT4iNjcXBgwfxxRdfwEPy3yYlQalUwtvDA+EXLvAmy126AMnJWp96\nYGAgevbsicTERNCePUBBAVoeOybvhtm1i/9rhbD7Dh2KRIUCEadP46yLCz7v0QN9+vblVu8HH3B/\n63vv8SYqubnarB6JyMhIuLq6ory8XD9wKtGhg7bwlilh9/b2tt414eXFi0Lpvk8JyWKXobrCfuDA\nAfTr18/kuEJCQsAYM9039qWXuPvwrbe0my5fvgwiqrbFDvAHaPfu3fHNN9+YTsPNz+fBQBNuGLVa\njVWrVmH48OGYO3cuXFxc8MMPPxjvGBfHXaQ+PtqGNAgK4iWVDf5+O3bsAGMM8+fPR//+/bFy5Urz\nacJ8ILzIV48ePIhvwP79+/H444/j22+/NX8eE5w+fRoBAQHYZOBq2rt3L5RKZVWp5J49+b91aLXX\nWtgZY20ZY3sYY+cYY2cZY8/ZYmD25Pjx4/D29kZ4eLijh6K1RK3ys9++DZw7pxX26OhoPs1MTYXb\ne+8hJiYGr732GsaNG4e2bdvi+PHjmDt3LhAZyWckGj/7fR4e8Cgr45XoYmOBixeRo2nG3KJFC/Ts\n2ROZmZmo1DQS6ZmeLi/s33/PHwyWskjA86SXt22LRCcnjCgrw1NSxgTAp/MPPwy88w7w7rs8VfG+\n+/SOd3Z21gZl9fzrVRfQCk0qYNTmTRL2ahEUxN+frrDrdk6SoTrB0xs3biA1NdVk4FQ6X3BwsGlh\nl7Haa5LqqMvjjz+OU6dOIclgppKbm4vPPvsMlXv3ctE0Iex79uxBWloaZs6cCW9vb9x3333YvHmz\nsRBL7rRJk6qymKSqmAbumB07dqBHjx4IDAzEjBkz8Ndff8mm5eqxbh3w11/Ac8/Jus1uazLGrIop\nyHDixAkQEZ5//vmqBYKo8q97SLOZuDj+8G1Iwg5ABeAFIuoEoDeApxhjMukT9YekpCTExcVBIVcu\nt44JDw+Hu7u7ZT+7NK3btw/nzp3jrhHGgH//mwfRhg3DpEmTUFRUhMWLF+Pw4cNVWSwKBQ8GaoT9\nQQAVCgUPGMfEAJWVqDh7FgC32Hv06IFAAM43bkDt6YlhajW6GD4EL18GDh8GpKi/Fdzs1g09Kyvh\nFBKC8ePH67/49ttcNBMTeas5mSC29BCUtdgBYNIklAcE4DJMW+zVZtgwHiiUVureusVFzQYWu9SB\nq68JP7VEaGiofC67hIHVXlthf/TRR+Hm5oZvvvlGu62kpAQPPfQQnn76aVxfvZr79mWsYABYuXIl\nfHx8tCuuJ0yYgGvXruGkYQ/f/v254M6aBYDPNJ564w3+mo7bIi8vD4cOHeJuMgATJ06Eu7s7Vq5c\nafpNXLkC/O1v3GjQiTvpIq3lMGyMYy1Sx6309HS8rZndFRYW6vvXAW5UxcbWaQC11spGRLeIKEnz\n/0IA5wG0qe15a8JXX32F/v37V63ClEGlUuHUqVOmxaGOcXJyQmxsrGWLPTSUi8kff0CZmIi3nJ35\nFysjg9fBZgyLFy9Geno63nzzTeMAZlwcD1Kq1Rhy9y5O+vjw/GONFeykWUoeEBCAbt26oZfmoXd5\nzBh4AOhtuKBp3Tr+pZwyxer3KrXJe+aZZ4w7JoWHc8tKqdR+0Q2599574enpafpvN3YsriUkoBg2\nstgB/vArL6/KIDKTww5ULysmQyNelhZEmcxllzCw2i9evKgtEVATfH19MWHCBKxbtw4lJSWorKzE\ntGnTcOjQITDGoExI4PeeTLyioKAAP/zwA6ZMmaKNZ4wePRpOTk7G7pghQ7hbS/OAOHDgAPZJAqsj\n7Lt374ZarcaIESMA8Gyy8ePH47vvvpOPTVVU8PtSoeD3qYnuXJKwM8bMPyRMcPnyZYSGhmLq1Kl4\n9913ceXKFSQkJKCyslJf2AHujjl2zGQJCFtjU5OVMRYKIA7AEVue1xoqKirwr3/9CwkJCRg2bBjG\njBmjfaLqcv78eZSWlspP5x2ElBlj1mfIGHfHbN6MVSkpmHzlCvcDf/mltsWes7MzWrduLX/8Pffw\n3ONff0W7khL8IQVCO3QAnJ3hdfUq/Pz8oFQq4ebmhlEtWkANYEd0NG4DCNO1toiAtWv5TKEamQYD\nBgxAZGQkZs+eLb/Df/7Dm0IblAOQmD59OtLT02UX8khI4m1osefn59dM2O+9l1unkjvGTA47UD2L\nXRIWk4umNISFheHGjRsoM9fY/B//0FrtNcmIMeTxxx9Hfn4+Nm/ejBdeeAGbN2/G+++/jwGxsQjK\nyDDphtmwYQNKSkowU6cxTUBAAAYOHIjNmzcbH9CmygZMS0uDJOc3ddxAO3bsgI+PD+J1WkjOmDED\nd+7cwdatW43P+dpr3Dr+6iuT9xLAP39nZ2eMHDkS3377bbUXPl26dAkRERH473//C2dnZzz//PNa\n/7rRKuJevXjsyETDGZtjTaUwa34AeAE4DmC8idfnAEgEkBgSEmKTSme6/PDDDwSA1q9fT2+99RZ5\neXmRUqmk1157Ta/SnlRv+/z58zYfQ02RarbfvHnT/I6JiXRn6lSaBNC31a3Cl5TEK+dpysT2061g\n2KkTHW3dmqJ06oufDAmh8woFzZo1i9a4uRF5e/NSs5pxGFXsqyfcvXuXANDbb7+ttz0iIoKmTJlS\ns5MOHcqrAhIRvf8+f+8myrUmJCQQwNsQWmLhwoXk7u5ucb+VK1cSZGr6G/Hss0ROTtSjRQuaIVN5\nsjpUVlZSWFgYNW/eXFvOmIhomaZ5S4WJErT9+vWjjh07GlW3/N///kcA6Ny5cyavOXv2bPLz8aEK\ngDZoauyr1Wpq06aNUds+lUpFwcHBNHLkSP2T7N7NG13Mnm3xPc6fP58CAgK05ZGt+Zvp4ufnR/Pm\nzSMiorfffpsAUPPmzbW9D/Q4eZLfN4aVOqsJ6rK6I2NMCeAHAGuJSOaxDBDRMiLqQUQ9AgMDbXFZ\nPT7//HOEhIRgwoQJePnll3Hx4kVMmDABr7/+ul7UOykpCZ6enrW2aGyJVaUFAKB7dxyYMgUbAIRL\nkXZriYnhbo4jR3CjeXOcLSrSe611Xp5eMa6I/HwcVavx66+/4kxkJM9SkIo0rVvHz/Xww9UbQx3g\n7u4OZ2dn27liAO5nT07m/vX0dO4zNeHmqK7Fbo27xGzKoy4vvAAiwpisrBqlOuqiUCgwa9Ys5OTk\nYPz48doG2wOJUAzglMyaj5SUFCQkJGDmzJlGWT7jxo0DAHmrXUNqaioiO3RAcbNmKEhJwdGjR3H2\n7FncuHFD64aRcHJywmOPPYadO3fi1q1bVbWFpk3js9CPPrL4HvPy8uDn54cHH3zQ+oVZGnJzc5GX\nl4cITb2fv//974iMjEROTo6xGwbg3z939zoLoNoiK4YB+AbAeSL6oPZDqj4XLlzA7t27MXfuXG3B\nrVatWmHNmjUYNGgQnnrqKW1w5Pjx44iLizNZmMsRWF1aAFXFv0wV5DKJiwu/uQBcio5Gfn5+1aKR\n2Fi0KilBG8nFcfMmPPPzkQjuBy7u0wfw9gZ++IEvWvruO76gxN+/emOoAxhj8Pb2tl3wFOB+doCv\nspVy2E2kJ1YnK8bmwh4SgoL+/TEbQJQVmUqWWLBgAb788kusWbNG+30Ju3oVCQD+lAkErl+/HgAw\nVSag3rp1a/Tp08essKelpSEkJASe4eEIUSrxyiuvaFebSoFTXWbNmIEZlZUoHjgQCAzkK1eJeLaW\nFetSpM9fWpj1008/8RpKVnBZU4ZDyqxzdXXFJ598AoVCgQcMi54B3M9/zz11FkC1hcXeD8BjAIYw\nxk5qfmSq/tiPL7/8EkqlEk8Y5D47OTlhzZo1cHNzw+TJk1FcXIyTJ0/WK/86APj7+yM4ONgqYT9/\n/jxatmxp1s9sEs37vtm9O4ioqthTbCwUADpLQSZNOYEzGpGK6tyZ5xlv2cJXmt66Va1smLrGx8dH\nz2IvLy9HaWlpzYW9a1cuHLt2mc1hB6oXPLVW2Fu3bg2lUmlZ2AGc7tsXQQC6S0HeWuDl5YW5c+fC\n3d2db8jOhvKvv3DKzw8HZJo7b9q0CX379kWbNvK5E+PHj0dSUhJSU1ONXiMirbA7tWqFzi1b4vff\nf8eHH36I2NhYbR0iXSL378c3ABRXr0L91FM8wH39utVVWXU//5kzZ6KsrAzff/+9VcdK8bsInV4N\nI0aMQG5urslVxOjViy92k6k2a2tskRVzgIgYEXUhom6an19sMThruHv3LlasWIEJEybIln9t06YN\nVqxYgRMnTmDixIkoLi6uNxkxunTt2tVqi122GJc1TJ0KPPIISjWuH8k6UWus/2jphktMBBQKkOYL\n0rFjR74k+/ZtvoKvWbOqBSX1EEOLXXqA1VjYFQq+CEsSdhMZMYB9XDFOTk4ICQkxn/Ko4YCnJ1IB\ntP3FDl9BjUV+Nz4eBw4c0Av2X7p0CadOncLDZtxz9957LwB5l2NOTg5KSkrQrl07ICgILdVqtG7d\nGjdv3jRywwDgKafvvYe89u3RXqXCtkGDeKC7GjNx3c8/Li4OXbp0sdodI1nsUqaXhNlAeM+eQEkJ\noEkttieOT+SuJd9//z3y8/Pxt7/9zeQ+Dz30EJ599ln8ornZ65vFDlQVuTKX+UBEZuuiW2TIEOD7\n7+GrcaFIWRm5fn4oBRAqLbJITARiYtBFs3KuY8eOwIgR3Ed4/jyvlilZcfUQQ2G3pk6MRYYP5yl4\nJjonSdhD2AErUh41XLh0Cd83awbnvXuBGuRmmyQri9f6HzIErcaORWZmplbcAGhTGSdMmGDyFFJc\nK0WmaFmapmtSSEgIEBQElpWFf776KgBg1KhRxifbtg24eBHeb7yB1q1b44svvqj2W9L9/BljmDVr\nFo4dO2Z5FTj4g6x169ZVi5CsIT4e6N69TmqzN2hhJyJ8/vnniI2NNbt6D4C28qCXl5dxMat6QJcu\nXaBSqcy2Jrt16xYKCgpqbrFrMGy2kZ2Xh/MAWuXmch9lYiLQsyeefvppvPPOO7xeuqcnF3cAePTR\nWl3f3hi6Ymwi7MOGVf2/ji12wHphT0lJwZGYGO7TXbbMqnNbxUsv8Vo+//sf+mssb113zKZNm9Cz\nZ08uzCbw9/eHv7+/rLBL7hlJ2KFSYc7EiUhMTJQPRr77LtCuHZweeQRPPvkkdu7caVTv3xJS8FRC\neijt3LnT4rFSqmO1aN+ef7csaJUtaNDCfuzYMSQlJWH+/PkWa4C4urpi586d+OOPP4wXx9QDpMwY\nc+6YGgdODZDERHLFZGVl4SwA/xs3eLGi7GygRw9ERUVh4cKFVZ/t88/zYk2aglv1FbtY7MHBVe3f\nzFjs1gZPiajawp6dnY0i3WwmGVJSUtA8NpYXUVuxgtddsRYivojNcD1FQgKwciX/+3fsiOjoaPj7\n+2uFPTU1FYmJiWbdMBKRkZGy60v0LHaNS5VlZsq7TQ8f5quBFywAnJ3x5JNPQqFQYOnSpVa/1dLS\nUpSVlel9/m3btkVkZCT+kLK/zHD58uXqC3sd0qCF/c0334SXlxemWdkVRaqDUh+JioqCq6urWWE3\nWxe9GkhWitZiz85GMgC37Gxt4wz06GF8YP/+vFpePcooksMuFjtQlR1jhcVuKXhaUlKCiooKi4uT\nJKTMGHN+9jt37iA7O5u7PObN4wti5Gqhm2L1ar5C+YEHqlbYqlR8aX7bttwVA54K2a9fP62wW+OG\nkYiIiDDpinF3d+eNQaR6MaaqIb73Hk831SRLtGnTBqNHj8by5cvNV0nVQbr3DR+sQ4YMwb59+6Ay\nE+AsKipCRkZGvag1ZYoGK+xbtmzBzz//jCVLltT+C1sPcHZ2RkxMjNlc9tOnT8Pf3x9B0o1fQ4xc\nMRphB8CFW6nkxa8aKHax2AHekGXSJJ4nbQJrXTGmhMUU1qQ8SoIZFRXFV4ZGRvKVydby3Xc8hfXP\nP3mpiW+/Bf73P17C+KOP9FII+/fvjwsXLiA7OxubNm1Ct27drBK6yMhIpKenGwlwWloa2rVrx2eH\n5oT98mXeO2H+fL7yWsP8+fNx+/Zto0qLpjAn7FK9F1NIsQVhsduYoqIiPPPMM4iNjcWCBQscPRyb\nYanpRlJSEu65555qdcWRQypfK93ckisGAK/53rmzQ5qO2Apvb2+Ul5drA9GS9W6tdWyS2FieGWJY\nh0cHewm7VE/GnLBLM7qoqCieyTNnDnejWON7zs3lefqzZ/NWdZ078/6/L7zAYyuaBUYSUkrfxo0b\ncejQIavcMAAXdiIy8oenpqZW+eel7Da53qcffsgNj2ee0ds8dOhQREREWB1ENfX5S/58c+4YIex2\n4vXXX0d6ejqWLl2q/SI1BuLi4rQ9PQ0pLy9HcnKyTTJ6FAoFvL29tT727OxsFPr5VVlkcm6YBoQk\n4JKg28xitwJ7CXuLFi3g4eFhVtgPHz6MZs2aoYM0oxgwgP+r01LRJD/9xN0ukyYBERHA3r3A++9z\ngf/0U6MFWT169ICrqyv+9a9/AUC1hB0wzoyRctgB8Prsrq7GFntODu9PPG0a72msg0KhwLx583Dw\n4EHtA84c0r1vuB6kRYsW6Ny5s1lhl2IEwhVjQ06dOoUPP/wQTz75pMVypw0NqciRVM5Vl3PnzqG8\nvNxmqZp+fn56FntAixbalamop3EIazEsBFZQUACFQlG91LQawhiDs7OzzYWdMWaxfO/BgwfRu3fv\nqlXVksBbIXTYuJHX1ZfuLycnHiw9eZILvQGurq7o2bMnsrOzERMTU/UwsYBk5eoKe2lpKTIzM6uE\nXXLHGAr79u08D9xE79KRI/m6SN1+vaYw9/kPGTIEBw4cMJl6fOnSJQQEBNR+BmhHGpSwq9VqzJs3\nD/7+/tr6x42Jbt26wcXFBUdllh1LTQ+Men3WEF9fXz0fewtdYW+EFnu1uifVEqVSaTF4Wl1hB8yn\nPBYUFODMmTP6xo6PD9C6NW82YQ7JDTNxoslSCXJIKcbWWusANyiaN2+uJ+zSDLWdbiXGli2NXTEJ\nCfw9Sf1SDYiIiICLi4u21685LAl7aWmpcTs/DfU9IwZoYML+1Vdf4fDhw3j//ffhXw/rlNQWV1dX\ndOvWTdZiP3HiBLy8vGx2Q/n6+uqlOwYGBvJsiC5dqgS+gSJnsddlgF2pVNrcYgeqhJ0M0xEBHD16\nFGq12ngWGx1tWdh13TDV4MEHH4S7uzumVKMmP2Cc8qiXwy4hZ7FLdeBNNMhRKpWIjo6utbAPGDAA\nCoXCpDumRjnsdUyDEvaysjKMGjXK6vTGhkh8fDwSExONakPbuuuTrismOzubC/vEiTxw1sDjFpKI\nG1rsdUV1hL060/mwsDAUFBTIFqo6ePAgGGN6NcsBcGE/f958gwdDN4yV9OvXD4WFhVa7YSQiIyP1\nLHa9HHYJQ2G/c4cvxTdVh0VDTEwMzlqxZD8vLw9ubm6yzc19fX3RvXt3WWEvKytDenp6vfavAw1M\n2J999lls3bq1zqbUjqBXr164e/eu3s1ZWVmJkydP2swNA1S5YiorK5GTk6NXsrehI4llfbfYTQmL\nKaQqoHIFuA4ePIjY2FjjB0XHjrykramc8Bq6YSRqUiU1IiIC6enpKCkpAcCFnTGmXzysZUtem0gy\ncA4d4v9aiKvFxsYiNTW1qsCdCSwtDhsyZAgOHz6s18sUgHbGJCx2G9OYRR2QD6BevHgRxcXFNq1x\nIwl7bm4u1Go17FEj31E42hXj4uJilbBXt3XdoEGD4Ofnh40bN+ptV6vVOHTokHwygbRa1pQ7poZu\nmNogZcZIKY9paWkICgqCq26KbVAQL/SVnc1/P3iQB3R79TJ7bqnhuaV6L9YIu0qlMnqIylV1rI80\nOGFv7ERERMDf318vgHpC04Ta1sJeVFSEmzdvAkCjstgbiiumusKuVCoxbtw4/Pzzz3oZG+fOnUNB\nQYF5YTeVGVNDN0xtMEx5lBYn6WG4SCkhgZfj1VmUJEeMJj5kyc9u6fPv168flEqlkTtGCLugRjDG\n0KtXLz2LPSkpCa6urjYtXibl70pfrsZksbu6usLV1dWhrhhrsmJq0mx64sSJKCgowG+//abddvDg\nQccTzuQAABQuSURBVACQF/Y2bbgYylnstXTD1BTDlEe9xUkSuouUVCrgyBGL/nWAxyHc3d1rLeye\nnp7o3bu3kbBfvnwZ3t7evPRBPUYIez0kPj4eZ8+e1RZ8SkpKQpcuXWy6GEu6qRujsAPcapcs9vz8\n/DrNObaXxQ7wFZaG7piDBw8iMDBQPqDHmOnMmF9+4aJZxy0OfX19ERAQgJSUFL0GG3roWuynTgHF\nxVYJu0KhsCqAaljZUY4hQ4YgKSlJL1gtZcTUd5ewEPZ6SHx8PNRqNRITE0FEOHHihM1ryEuiIrUM\nbEyuGIAHUAsKCqBSqVBcXNwoXDHSuceOHYstW7Zo3TEHDx5Ev379TItNx47yrpjdu4HmzXmN8DpG\nSnnMzs5GWVmZaYs9I4O7YQCLgVOJmJiYWlvsAF/wpFarMWLECG08oCGkOgI2EnbG2AjG2AXG2CXG\n2D9scc6mjFSB8siRI7h27Rru3Llj04wYwFjY6/vUsrpIhcBq3T2pBthT2AF9d0x2djZSUlLMr8KO\njubVGnUzRYh4c/JBg0zmhdsTKeVRSnU08rF7efESFxkZPHDatq3Zcsm6xMbG4tatW8jNzZV93dqS\nyb169cKmTZtw8eJFxMXFYe3atbh27Vq9T3UEbNPM2gnAZwAeANAJwBTGWO06QTRxAgICEB4ejqNH\nj2pXnNraYtf1sTdv3rxe1qivDVLp3rqsEyNhKSumurXYDdF1xxzSpAFaFHYAuHChatuVK7z2voNq\n60dEROD69evaxjKyDTqCgriPPSHBKjeMhBRANeWOKS4uhkqlsurznzBhAk6ePImYmBhMmzYNKpWq\nyVjsvQBcIqIrRFQO4HsAY2xw3iZNfHw8jhw5ghMnTsDJyUmbw2wrpJtauzipkSFZ7I4QdkvBU6kW\ne02F3cXFReuO2bNnD5RKpfk+vlL9fl0/uxQUdJCwS5kxe/bsAWBG2I8d47ONatSFklIeTbljqrvq\nt127dti3bx8WL14MDw8P40Vg9RBbCHsbAOk6v1/XbBPUgvj4eNy4cQNbt25FTExMtRayWIPuTd1Y\nhd1RFrslV0xNygkYIrljli1bhu7du5u/P8LDeQ64rrDv2cMrJFZz1aitkIR99+7d8PT0lA9ktmwJ\nSKUHqmGxBwcHw9vb26TFbqqyozmUSiXefPNNFBUVaWcE9Zk6c64xxuYwxhIZY4nZ0qIDgUkkq+D0\n6dM2968DPJ1Lcr80tsApUBU8bazCPnToUPj6+qK4uNhylVMXFy7uUgBV8q8PGVKnaY66SO6M1NTU\nqgYbhkiZMZ6e1Wr8whgzG0Ctzedf37NhJGwh7DcA6EY1gjXb9CCiZUTUg4h6NEYL0dZIlR4B2/vX\nAX6DSjd2Y/x7SK4YKeWxPgm7NKbaCLvkjgEs+NclOnasstjPn+e+awf2rvXx8dHedyYbYEvCHh/P\nm3NXg9jYWCQnJ8sWTLPFg7W+YwthPwYgkjEWxhhzATAZwM82OG+TRqr0CNhH2IGqG7uxWuyVlZXI\n0KxcrE/BU1sJy7x589C5c2dt1x+zREcDKSk8b93B/nUJyR1jUtillMdquGEkYmNjkZOTg6ysLKPX\nhLBbARGpADwNYCeA8wA2EJHl8moCi/Tu3RsKhQJdu3a1y/kbu8UOVNX6rk/B05pUdpQjPj4ep0+f\nti5VNToaqKjg2TB//MHLCGja7TkKi8IuNQ2vgbCbKy1QEx97Q8MmPnYi+oWIoogonIjetMU5BcDi\nxYuxY8cONGvWzC7nl27sxizs6enpYIzBy0KNEVtSFz72aiNlxpw9y9veDR5cd9c2gUVhHz4c2LSJ\n/1tNpMwYuQCqrR6s9ZnGlbzcyGjZsiWGDRtmt/M3dlcMwIW9WbNmNqtjbw31UtilXPb164G8PIe7\nYYAqYQ81NXNwdgYmTKjRuVu0aIGAgABZi/3OnTvw9PRsVP2SDRElBZowTcUVU5duGMA6YXd1dbV5\nCqtZfHx4euMPP/Df64HFPmbMGCxdutQuvYvNZcbUZnFYQ0EIexNGcsU0Zov95s2bdS7s1gRPHSIs\n0dE8eBodzXuhOhhXV1fMmTOnRs06rCE2NhZnz541yowRwi5o1HTt2hURERGNrk4MUGWxV1ZW1kuL\n3WHCDtQLN0xdEBMTg4KCAm0AXcKayo4NHSHsTZhHH30UKSkpdrOYHImumDtC2C1lxThE2KUAahMR\ndlOlBYTFLhA0UBwt7Gq1Gmq1WvZ1hwnL6NHAlCk1yjJpiAhhFwgaGc7OzvDw8ADgGGEHYNId4zBh\nadcOWLcOsFP6bH3Dz88Pbdq0EcIuEDQmpACqI4KnQD0U9iaIVFpAQq1WIz8/v9F//kLYBY0WSdDr\nk8Ve21rsguoRGxuLc+fOobKyEgBQWFgItVotgqcCQUPF0cIuF0AtLS1FeXm5EPY6IjY2FqWlpbh8\n+TKAplEnBhDCLmjESK6Yul46bs5ibyrCUl8wDKA2lc9fCLug0eJoi10Iu+Pp1KkTGGNC2AWCxoKj\ngqdC2OsPHh4eCA8PF8IuEDQWHGWxm8uKaSrCUp/QzYxpCiV7ASHsgkaMo10xcsFTIex1T2xsLC5e\nvIiysrIm8/kLYRc0WoQrRgBwYa+srMRff/2l/fzr+p6oa4SwCxotw4cPx9SpU9G6jisZCmGvX+hm\nxty5cwfe3t6Nsj6SLrUSdsbYu4yxvxhjpxljPzLGxN0qqDd07twZa9asgXM1GyHXFkvCXue12Js4\nUVFRUCqVSE5ObhKVHYHaW+y7AMQSURcAFwG8XPshCQQNG0vBU2Gt1y1KpRLR0dFai70pfP61EnYi\n+k3TzBoADgMIrv2QBIKGjSWLvSkIS30jNjYWZ86caTKfvy197I8D+NWG5xMIGiSWsmIacxPl+kps\nbCxSU1ORlpYmhB0AGGO/M8aSZX7G6OzzCgAVgLVmzjOHMZbIGEvMzs62zegFgnqIsNjrH1IA9dq1\na03i87cYVSKi+8y9zhibCeBBAEPJsLmg/nmWAVgGAD169DC5n0DQ0LEk7KGhoXU8IoEk7EDjX5wE\n1D4rZgSARQBGE1GxbYYkEDRsRPC0/hEaGgpPT08ATSPVtLY+9v8BaAZgF2PsJGPsSxuMSSBo0Jiy\n2EUtdsehUCgQExMDoGkIe60SfIkowlYDEQgaC6aCp6IWu2OJjY3F0aNHm8TnL1aeCgQ2xpTFLlad\nOhbJz94UPn8h7AKBjRHCXj+Jj48HALRr187BI7E/dbvWWiBoApgKnubn5wMQwu4o+vbtiytXriAs\nLMzRQ7E7wmIXCGyMsNjrL01B1AEh7AKBzVEoFFAoFEbBUyHsgrpCCLtAYAeUSqVJV0xjrwUucDxC\n2AUCOyAn7IWFhQCAZs2aOWJIgiaEEHaBwA6YE3YvLy9HDEnQhBDCLhDYARcXF1lh9/T0hEIhvnYC\n+yLuMIHADiiVSqPgaWFhoXDDCOoEIewCgR0w5YoRwi6oC4SwCwR2QAi7wJEIYRcI7IAQdoEjEcIu\nENgBU8FTIeyCukAIu0BgB4TFLnAkQtgFAjsgsmIEjkQIu0BgB4TFLnAkNhF2xtgLjDFijAXY4nwC\nQUPHUNhVKhVKSkqEsAvqhFoLO2OsLYDhANJqPxyBoHFgGDwtKioCIOrECOoGW1jsHwJYBIBscC6B\noFFgaLGLAmCCuqRWws4YGwPgBhGdstF4BIJGgWHwVAi7oC6x2BqPMfY7gCCZl14BsBjcDWMRxtgc\nAHMAICQkpBpDFAgaHsJiFzgSi8JORPfJbWeMdQYQBuAUYwwAggEkMcZ6EVGGzHmWAVgGAD169BBu\nG0GjRgi7wJHUuJk1EZ0B0EL6nTF2DUAPIrptg3EJBA0aIewCRyLy2AUCO2CYFSOEXVCX1NhiN4SI\nQm11LoGgoSOCpwJHIix2gcAOCFeMwJEIYRcI7ICcsCsUCri7uztwVIKmghB2gcAOKJVKqFQqEPEE\nMKlOjCaDTCCwK0LYBQI74OLiAoDXiAFEATBB3SKEXSCwA0qlEgC07hgh7IK6RAi7QGAHJGGXMmOE\nsAvqEiHsAoEdEBa7wJEIYRcI7IAQdoEjEcIuENgBKXgqhF3gCISwCwR2QFjsAkcihF0gsAMieCpw\nJELYBQI7oGuxl5WVoaKiQgi7oM4Qwi4Q2AFdYRd1YgR1jRB2gcAO6AZPhbAL6hoh7AKBHRAWu8CR\nCGEXCOyAbvBUCLugrrFZow2BQFCFrsUuFQITwi6oK2ptsTPGnmGM/cUYO8sYe8cWgxIIGjrCFSNw\nJLWy2BljgwGMAdCViMoYYy0sHSMQNAWEsAscSW0t9vkA3iaiMgAgoqzaD0kgaPiIrBiBI6mtsEcB\nuJcxdoQxto8x1tMWgxIIGjrCYhc4EouuGMbY7wCCZF56RXO8P4DeAHoC2MAYa09SPzD988wBMAcA\nQkJCajNmgaDeY5gV4+LiorXiBQJ7Y1HYieg+U68xxuYD2KwR8qOMMTWAAADZMudZBmAZAPTo0cNI\n+AWCxoShxS6sdUFdUltXzE8ABgMAYywKgAuA27UdlEDQ0BHCLnAktc1jXw5gOWMsGUA5gBlybhiB\noKlhGDwVwi6oS2ol7ERUDmCajcYiEDQahMUucCSipIBAYAcMg6dC2AV1iRB2gcAOODk5ARAWu8Ax\nCGEXCOwAYwxKpVIIu8AhCGEXCOyEi4uLEHaBQxDCLhDYCaVSifLychQVFQlhF9QpQtgFAjuhVCqR\nn58PtVothF1QpwhhFwjshFKpRG5uLgBRJ0ZQtwhhFwjshFKpRF5eHgAh7IK6RQi7QGAn/r+9e4ux\na4rjOP79RWfQltYtNKpKiaYPDCZ1jUtd0hHxJEI8eBB96UMrEtFMIvFIBH0QSeMWiSDu0ge38kKi\nNaUoVSUqrWJoiIQQl7+HvQ4nk5ox3T2z1t5+n2Rn9uX09JezZn6zzzpnz+nv7/cZu2XhYjfrEU/F\nWC4udrMe6evrY/fu3YCL3aaWi92sR/r6+vxB1paFi92sRzp/LwZc7Da1XOxmPeJit1xc7GY90v1R\neDNnzsyYxP5vXOxmPdI5Y58+ffrff+3RbCq42M16pFPsnoaxqVar2CUNSHpL0iZJI5IW76tgZk3n\nYrdc6p6x3wHcFhEDwK1p28xwsVs+dYs9gIPT+ixgV837M2uNzounLnabarU+zBpYCbwk6U6qXxJn\n149k1g4+Y7dcJix2Sa8CR+3h0DBwEXBjRDwt6SrgAeDif7mfZcAygHnz5u11YLOmcLFbLhMWe0Ts\nsagBJD0CrEibTwL3j3M/a4A1AIODgzG5mGbN42K3XOrOse8Czk/rS4BtNe/PrDVc7JZL3Tn2G4DV\nkqYBv5CmWszML55aPrWKPSLeAE7fR1nMWsVn7JaLrzw16xEXu+XiYjfrERe75eJiN+sRF7vl4mI3\n6xEXu+XiYjfrEb8rxnJxsZv1iIvdcnGxm/XI0NAQw8PDLFiwIHcU+59RxNRf3T84OBgjIyNT/v+a\nmTWZpI0RMTjR7XzGbmbWMi52M7OWcbGbmbWMi93MrGVc7GZmLeNiNzNrGRe7mVnLuNjNzFomywVK\nkr4FvtjLf3448N0+jLOvOV89zleP89VXcsZjI+KIiW6UpdjrkDTyX668ysX56nG+epyvviZknIin\nYszMWsbFbmbWMk0s9jW5A0zA+epxvnqcr74mZBxX4+bYzcxsfE08Yzczs3E0qtglLZW0VdKnkm4p\nIM+DkkYlbe7ad6ikVyRtS18PyZjvGEmvS/pI0oeSVpSUUdIBkjZIei/luy3tP07S+jTOT0jqz5Gv\nK+d+kt6VtLa0fJK2S/pA0iZJI2lfEeObssyW9JSkjyVtkXRWKfkknZQet87yo6SVpeSrozHFLmk/\n4F5gCFgEXCNpUd5UPAwsHbPvFmBdRJwIrEvbufwO3BQRi4AzgeXpMSsl46/Akog4BRgAlko6E7gd\nuDsiTgC+B67PlK9jBbCla7u0fBdGxEDXW/RKGV+A1cCLEbEQOIXqcSwiX0RsTY/bAHA68DPwbCn5\naomIRizAWcBLXdurgFUF5JoPbO7a3grMSetzgK25M3Zlex64pMSMwHTgHeAMqotDpu1p3DPkmkv1\nw70EWAuosHzbgcPH7CtifIFZwOek1/JKyzcm06XAm6Xmm+zSmDN24GhgR9f2zrSvNEdGxFdp/Wvg\nyJxhOiTNB04F1lNQxjTNsQkYBV4BPgN+iIjf001yj/M9wM3An2n7MMrKF8DLkjZKWpb2lTK+xwHf\nAg+lqaz7Jc0oKF+3q4HH0nqJ+SalScXeOFH9ys/+tiNJM4GngZUR8WP3sdwZI+KPqJ4KzwUWAwtz\nZRlL0uXAaERszJ1lHOdGxGlUU5TLJZ3XfTDz+E4DTgPui4hTgZ8YM62R+/sPIL1GcgXw5NhjJeTb\nG00q9i+BY7q256Z9pflG0hyA9HU0ZxhJfVSl/mhEPJN2F5URICJ+AF6nmtqYLWlaOpRznM8BrpC0\nHXicajpmNeXkIyK+TF9HqeaHF1PO+O4EdkbE+rT9FFXRl5KvYwh4JyK+Sdul5Zu0JhX728CJ6R0J\n/VRPnV7InGlPXgCuS+vXUc1rZyFJwAPAloi4q+tQERklHSFpdlo/kGr+fwtVwV+ZO19ErIqIuREx\nn+r77bWIuLaUfJJmSDqos041T7yZQsY3Ir4Gdkg6Ke26CPiIQvJ1uYZ/pmGgvHyTl3uSf5IvcFwG\nfEI1DztcQJ7HgK+A36jOTq6nmoNdB2wDXgUOzZjvXKqnke8Dm9JyWSkZgZOBd1O+zcCtaf/xwAbg\nU6qnx/sXMNYXAGtLypdyvJeWDzs/E6WMb8oyAIykMX4OOKSwfDOA3cCsrn3F5NvbxVeempm1TJOm\nYszM7D9wsZuZtYyL3cysZVzsZmYt42I3M2sZF7uZWcu42M3MWsbFbmbWMn8BUcH7q6OUF0QAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcf9c240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.68855503746 \n",
      "Updating scheme MAE:  1.85241681548\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
