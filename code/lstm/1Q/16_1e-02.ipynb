{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/16_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-2\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 16 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 16 \n",
      "Learning rate = 0.01 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.01\n",
      "Fold: 1  Epoch: 1  Training loss = 2.7491  Validation loss = 2.1153  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 2.7404  Validation loss = 2.1444  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.6720  Validation loss = 1.6824  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.6465  Validation loss = 1.8219  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.6294  Validation loss = 1.6002  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.6036  Validation loss = 1.4639  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 2.5795  Validation loss = 1.6640  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 2.5527  Validation loss = 1.4854  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 2.5467  Validation loss = 1.7098  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 2.5279  Validation loss = 1.7102  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 2.4846  Validation loss = 1.5064  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 2.4492  Validation loss = 1.3521  \n",
      "\n",
      "Fold: 1  Epoch: 13  Training loss = 2.4421  Validation loss = 1.3682  \n",
      "\n",
      "Fold: 1  Epoch: 14  Training loss = 2.3408  Validation loss = 0.7628  \n",
      "\n",
      "Fold: 1  Epoch: 15  Training loss = 2.3430  Validation loss = 1.7444  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 14  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 2.1605  Validation loss = 1.5466  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 2.1168  Validation loss = 1.5773  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 2.0370  Validation loss = 1.6358  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 2.0388  Validation loss = 1.6035  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 2.0146  Validation loss = 1.5097  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 1.9452  Validation loss = 1.6419  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 1.9397  Validation loss = 1.6791  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 1.8635  Validation loss = 1.8025  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 1.8372  Validation loss = 1.7259  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 1.7689  Validation loss = 1.7372  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 1.9202  Validation loss = 1.7159  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 1.7154  Validation loss = 1.8149  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 5  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.2134  Validation loss = 1.5090  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.3105  Validation loss = 1.5127  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.2200  Validation loss = 1.5947  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.1956  Validation loss = 1.7190  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.1973  Validation loss = 1.6448  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.1740  Validation loss = 1.7485  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.1885  Validation loss = 1.5715  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.1784  Validation loss = 1.5888  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.2185  Validation loss = 1.3347  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.1438  Validation loss = 1.5211  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.1451  Validation loss = 1.4724  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.1650  Validation loss = 1.3305  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.1677  Validation loss = 1.2457  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.1313  Validation loss = 1.4542  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.1489  Validation loss = 1.6447  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.1357  Validation loss = 1.6511  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 13  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 1.1304  Validation loss = 3.0083  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.0881  Validation loss = 3.1590  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 1.0824  Validation loss = 2.9231  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.0687  Validation loss = 3.0335  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.0613  Validation loss = 3.1804  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 1.1058  Validation loss = 2.8792  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 1.0543  Validation loss = 3.0556  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.0517  Validation loss = 2.9330  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 1.0832  Validation loss = 3.0222  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.0327  Validation loss = 2.9196  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 1.0861  Validation loss = 3.0397  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 1.0278  Validation loss = 3.1090  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 1.0344  Validation loss = 2.9298  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 1.1292  Validation loss = 3.0807  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 1.0555  Validation loss = 3.1114  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 6  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 1.2493  Validation loss = 1.9714  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 1.1586  Validation loss = 2.1931  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 1.2806  Validation loss = 2.8330  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 1.1149  Validation loss = 2.0772  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 1.0492  Validation loss = 1.4143  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 1.0412  Validation loss = 1.6513  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 1.0548  Validation loss = 1.1656  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 1.0536  Validation loss = 1.2216  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 1.0449  Validation loss = 1.8563  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 0.9713  Validation loss = 1.4023  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.9405  Validation loss = 1.4475  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 1.0150  Validation loss = 1.3716  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 1.0004  Validation loss = 1.6132  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 0.9504  Validation loss = 1.2366  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.9298  Validation loss = 1.1634  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 0.9017  Validation loss = 1.1510  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 0.9338  Validation loss = 1.2963  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 0.8798  Validation loss = 1.2286  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 0.9519  Validation loss = 1.2554  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 0.8721  Validation loss = 1.2907  \n",
      "\n",
      "Fold: 5  Epoch: 21  Training loss = 0.8532  Validation loss = 1.3262  \n",
      "\n",
      "Fold: 5  Epoch: 22  Training loss = 0.8617  Validation loss = 1.4818  \n",
      "\n",
      "Fold: 5  Epoch: 23  Training loss = 0.9323  Validation loss = 1.2602  \n",
      "\n",
      "Fold: 5  Epoch: 24  Training loss = 1.0840  Validation loss = 1.9475  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 16  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 0.9159  Validation loss = 1.2619  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 0.9661  Validation loss = 1.2593  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.9279  Validation loss = 1.3048  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.8943  Validation loss = 1.2796  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.8946  Validation loss = 1.3371  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.9102  Validation loss = 1.3277  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.9603  Validation loss = 1.4990  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.9251  Validation loss = 1.5090  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.8821  Validation loss = 1.2811  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.8573  Validation loss = 1.2787  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.8619  Validation loss = 1.2670  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.8871  Validation loss = 1.2846  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.8448  Validation loss = 1.3242  \n",
      "\n",
      "Fold: 6  Epoch: 14  Training loss = 0.8776  Validation loss = 1.3103  \n",
      "\n",
      "Fold: 6  Epoch: 15  Training loss = 0.8480  Validation loss = 1.2947  \n",
      "\n",
      "Fold: 6  Epoch: 16  Training loss = 0.8793  Validation loss = 1.3996  \n",
      "\n",
      "Fold: 6  Epoch: 17  Training loss = 0.9304  Validation loss = 1.3287  \n",
      "\n",
      "Fold: 6  Epoch: 18  Training loss = 0.8375  Validation loss = 1.4333  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 2  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.9016  Validation loss = 1.5135  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.8620  Validation loss = 0.8734  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.9077  Validation loss = 0.9299  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.8443  Validation loss = 0.9710  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.8590  Validation loss = 1.2069  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.8558  Validation loss = 0.6789  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.8762  Validation loss = 0.7665  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.8523  Validation loss = 1.1078  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 0.8087  Validation loss = 1.1118  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 0.8433  Validation loss = 0.8800  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.9213  Validation loss = 0.6204  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.8244  Validation loss = 1.0237  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.8321  Validation loss = 1.3539  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 11  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.8133  Validation loss = 4.9643  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.7983  Validation loss = 4.8123  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.7565  Validation loss = 4.4513  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.7326  Validation loss = 4.4831  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.7588  Validation loss = 4.3996  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.8458  Validation loss = 4.7016  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.7293  Validation loss = 4.3758  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.7355  Validation loss = 4.3134  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.7821  Validation loss = 4.3050  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.7678  Validation loss = 4.6261  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.6988  Validation loss = 4.5104  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.7189  Validation loss = 4.2223  \n",
      "\n",
      "Fold: 8  Epoch: 13  Training loss = 0.6954  Validation loss = 4.5655  \n",
      "\n",
      "Fold: 8  Epoch: 14  Training loss = 0.7507  Validation loss = 4.7847  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 12  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.2107  Validation loss = 6.2349  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.2448  Validation loss = 6.4458  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.1821  Validation loss = 6.2352  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.1696  Validation loss = 6.0348  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 1.1452  Validation loss = 5.9643  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.2139  Validation loss = 5.8771  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 1.1275  Validation loss = 6.6016  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 1.0555  Validation loss = 6.0328  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.2995  Validation loss = 5.8135  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 1.0986  Validation loss = 6.0522  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.0717  Validation loss = 6.1546  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 1.0284  Validation loss = 6.1555  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.0051  Validation loss = 6.0188  \n",
      "\n",
      "Fold: 9  Epoch: 14  Training loss = 1.0563  Validation loss = 6.0157  \n",
      "\n",
      "Fold: 9  Epoch: 15  Training loss = 0.9925  Validation loss = 6.1081  \n",
      "\n",
      "Fold: 9  Epoch: 16  Training loss = 0.9704  Validation loss = 6.0388  \n",
      "\n",
      "Fold: 9  Epoch: 17  Training loss = 1.1801  Validation loss = 6.0784  \n",
      "\n",
      "Fold: 9  Epoch: 18  Training loss = 1.0331  Validation loss = 6.1956  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 9  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 1.7120  Validation loss = 2.2449  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.6331  Validation loss = 3.0424  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.5263  Validation loss = 2.9588  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.7763  Validation loss = 2.6439  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.4881  Validation loss = 2.6533  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.6411  Validation loss = 2.7181  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.7354  Validation loss = 2.9150  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.7544  Validation loss = 1.8310  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.6113  Validation loss = 1.1459  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.5027  Validation loss = 1.3258  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.5015  Validation loss = 1.5560  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 1.3744  Validation loss = 2.0203  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 1.3678  Validation loss = 2.5028  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 1.4867  Validation loss = 2.9520  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 9  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.5836  Validation loss = 0.9054  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.6511  Validation loss = 2.6652  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.8585  Validation loss = 1.2415  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.4822  Validation loss = 1.4599  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.5312  Validation loss = 2.6053  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 1.5048  Validation loss = 2.0753  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.4246  Validation loss = 2.5503  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 1.3538  Validation loss = 2.2865  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.4117  Validation loss = 1.2821  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.4236  Validation loss = 1.2399  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 1.5469  Validation loss = 2.6806  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 1  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.7739  Validation loss = 1.1391  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.5004  Validation loss = 1.3903  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.4560  Validation loss = 1.1608  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.6434  Validation loss = 0.7554  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.4554  Validation loss = 0.7028  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.3790  Validation loss = 1.3969  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.3211  Validation loss = 1.0269  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.4040  Validation loss = 1.5293  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.3549  Validation loss = 1.9204  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.3106  Validation loss = 1.1565  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.2885  Validation loss = 0.7659  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.3268  Validation loss = 1.0032  \n",
      "\n",
      "Fold: 12  Epoch: 13  Training loss = 1.4553  Validation loss = 1.3913  \n",
      "\n",
      "Fold: 12  Epoch: 14  Training loss = 1.4269  Validation loss = 1.2189  \n",
      "\n",
      "Fold: 12  Epoch: 15  Training loss = 1.4452  Validation loss = 1.1507  \n",
      "\n",
      "Fold: 12  Epoch: 16  Training loss = 1.3769  Validation loss = 0.9422  \n",
      "\n",
      "Fold: 12  Epoch: 17  Training loss = 1.4128  Validation loss = 1.4579  \n",
      "\n",
      "Fold: 12  Epoch: 18  Training loss = 1.4853  Validation loss = 0.8148  \n",
      "\n",
      "Fold: 12  Epoch: 19  Training loss = 2.0187  Validation loss = 1.4138  \n",
      "\n",
      "Fold: 12  Epoch: 20  Training loss = 1.5810  Validation loss = 0.9519  \n",
      "\n",
      "Fold: 12  Epoch: 21  Training loss = 1.5180  Validation loss = 1.0400  \n",
      "\n",
      "Fold: 12  Epoch: 22  Training loss = 1.4669  Validation loss = 1.2215  \n",
      "\n",
      "Fold: 12  Epoch: 23  Training loss = 1.4063  Validation loss = 1.9213  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 5  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.4643  Validation loss = 1.1106  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.3459  Validation loss = 0.9529  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.4593  Validation loss = 0.9534  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 1.3698  Validation loss = 1.2232  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.4684  Validation loss = 1.1088  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.3243  Validation loss = 1.6599  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.6486  Validation loss = 1.7171  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.3517  Validation loss = 1.5832  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.3395  Validation loss = 1.7942  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.4037  Validation loss = 2.3869  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.4443  Validation loss = 1.2139  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.2666  Validation loss = 1.5867  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 1.2232  Validation loss = 2.0310  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 1.2735  Validation loss = 1.9307  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 1.3335  Validation loss = 1.0986  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 1.2687  Validation loss = 2.1922  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 1.3019  Validation loss = 1.7332  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 1.3199  Validation loss = 2.5347  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 2  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.3520  Validation loss = 4.9823  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.2141  Validation loss = 4.5208  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 1.5814  Validation loss = 4.7879  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.6256  Validation loss = 5.4776  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.3525  Validation loss = 4.8301  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.2463  Validation loss = 5.2219  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.2557  Validation loss = 5.7436  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.2602  Validation loss = 3.8029  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.1550  Validation loss = 4.2360  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.1703  Validation loss = 4.6224  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.1467  Validation loss = 3.6244  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.2916  Validation loss = 4.5628  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 1.4736  Validation loss = 4.2496  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.1138  Validation loss = 4.3174  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.6905  Validation loss = 4.6299  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 1.1746  Validation loss = 4.7990  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.2797  Validation loss = 4.1075  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.1377  Validation loss = 4.7390  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.0820  Validation loss = 3.9983  \n",
      "\n",
      "Fold: 14  Epoch: 20  Training loss = 1.2662  Validation loss = 4.2101  \n",
      "\n",
      "Fold: 14  Epoch: 21  Training loss = 1.1131  Validation loss = 4.2442  \n",
      "\n",
      "Fold: 14  Epoch: 22  Training loss = 1.0428  Validation loss = 4.6943  \n",
      "\n",
      "Fold: 14  Epoch: 23  Training loss = 1.0242  Validation loss = 4.4106  \n",
      "\n",
      "Fold: 14  Epoch: 24  Training loss = 1.1340  Validation loss = 4.6897  \n",
      "\n",
      "Fold: 14  Epoch: 25  Training loss = 1.2549  Validation loss = 5.3350  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 11  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 1.4088  Validation loss = 5.2261  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 1.3563  Validation loss = 5.7131  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 1.5477  Validation loss = 6.3529  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.4416  Validation loss = 4.8070  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.4097  Validation loss = 4.9084  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.5024  Validation loss = 6.5183  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 1.3203  Validation loss = 4.9629  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 1.4672  Validation loss = 4.9905  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.6058  Validation loss = 5.1097  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 1.3543  Validation loss = 5.1938  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 1.2248  Validation loss = 5.4494  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 1.3938  Validation loss = 5.1642  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 1.4055  Validation loss = 5.0446  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 1.4978  Validation loss = 5.0865  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 1.3232  Validation loss = 4.9407  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 1.2745  Validation loss = 4.8402  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 1.2053  Validation loss = 4.9459  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 1.2337  Validation loss = 4.9753  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 1.2726  Validation loss = 5.2831  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 1.4421  Validation loss = 5.4028  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 1.2863  Validation loss = 5.9188  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 4  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 1.6238  Validation loss = 4.9700  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 1.6232  Validation loss = 5.1018  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 1.6295  Validation loss = 4.5694  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 1.6586  Validation loss = 4.7144  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 1.5320  Validation loss = 4.3806  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 1.6179  Validation loss = 4.4985  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 1.7639  Validation loss = 4.1885  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 1.7208  Validation loss = 4.3964  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 1.5869  Validation loss = 4.6229  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 1.7431  Validation loss = 4.7736  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 1.8547  Validation loss = 4.7479  \n",
      "\n",
      "Fold: 16  Epoch: 12  Training loss = 1.7504  Validation loss = 4.5958  \n",
      "\n",
      "Fold: 16  Epoch: 13  Training loss = 1.6581  Validation loss = 4.6338  \n",
      "\n",
      "Fold: 16  Epoch: 14  Training loss = 2.0965  Validation loss = 6.1194  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 7  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.1547  Validation loss = 4.3021  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.0450  Validation loss = 4.3596  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 1.9065  Validation loss = 5.2197  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 1.9350  Validation loss = 5.3965  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 1.8052  Validation loss = 5.0735  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 1.8212  Validation loss = 5.0128  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 1.7066  Validation loss = 4.9231  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 1.7590  Validation loss = 5.2969  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 1.6433  Validation loss = 5.3190  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 1.9065  Validation loss = 5.1674  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 1.7489  Validation loss = 5.1329  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 1.7972  Validation loss = 5.9448  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 1  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.4811  Validation loss = 3.4245  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 1.9728  Validation loss = 2.2961  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 1.9136  Validation loss = 2.5834  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 1.8539  Validation loss = 3.6610  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 1.6727  Validation loss = 1.8754  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 1.7574  Validation loss = 2.5842  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 1.7295  Validation loss = 2.3854  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 1.8472  Validation loss = 3.5920  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 1.8056  Validation loss = 2.6251  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 1.6379  Validation loss = 2.8129  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 1.7684  Validation loss = 2.9109  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 1.7909  Validation loss = 3.0402  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 1.7549  Validation loss = 3.3771  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 1.7543  Validation loss = 3.6005  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 5  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 1.7489  Validation loss = 2.8052  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.3045  Validation loss = 2.8325  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.4104  Validation loss = 3.0339  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 1.9928  Validation loss = 2.8068  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 1.9501  Validation loss = 3.2514  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 1.7875  Validation loss = 3.5306  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 1.6084  Validation loss = 3.6918  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 1.8925  Validation loss = 4.5343  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 1.6322  Validation loss = 4.7762  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 1.7484  Validation loss = 4.2433  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 1.9963  Validation loss = 4.2731  \n",
      "\n",
      "Fold: 19  Epoch: 12  Training loss = 1.5850  Validation loss = 4.2887  \n",
      "\n",
      "Fold: 19  Epoch: 13  Training loss = 1.6305  Validation loss = 4.7969  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 1  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.4206  Validation loss = 4.6968  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 1.9828  Validation loss = 3.7142  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.2531  Validation loss = 4.4657  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 1.9125  Validation loss = 4.1753  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 1.8594  Validation loss = 3.6113  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 1.8563  Validation loss = 4.1799  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 1.8256  Validation loss = 4.0807  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 1.6780  Validation loss = 4.0228  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 1.7009  Validation loss = 3.8502  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 1.6720  Validation loss = 3.8163  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 1.7732  Validation loss = 3.5497  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 1.6688  Validation loss = 3.9926  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 1.6777  Validation loss = 3.6327  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.0674  Validation loss = 4.3098  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 11  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.0980  Validation loss = 3.3968  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.9839  Validation loss = 3.5442  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 1.8547  Validation loss = 3.1549  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 1.9075  Validation loss = 3.7684  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 1.7801  Validation loss = 3.5955  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 2.0592  Validation loss = 3.4667  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 1.8544  Validation loss = 3.3557  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 1.7739  Validation loss = 3.5021  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 1.8063  Validation loss = 3.5980  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 1.7769  Validation loss = 3.8064  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 1.8873  Validation loss = 3.0560  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 1.8608  Validation loss = 2.8265  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 1.8435  Validation loss = 2.7281  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 1.8249  Validation loss = 2.5800  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 1.7234  Validation loss = 2.4806  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 1.8031  Validation loss = 2.6537  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 1.8652  Validation loss = 3.3592  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 1.8362  Validation loss = 3.3665  \n",
      "\n",
      "Fold: 21  Epoch: 19  Training loss = 1.8896  Validation loss = 3.1947  \n",
      "\n",
      "Fold: 21  Epoch: 20  Training loss = 1.9050  Validation loss = 3.1431  \n",
      "\n",
      "Fold: 21  Epoch: 21  Training loss = 1.8816  Validation loss = 3.7712  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 15  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 1.7460  Validation loss = 4.2378  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 1.7534  Validation loss = 3.8069  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 1.7602  Validation loss = 3.8092  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 1.6949  Validation loss = 4.3058  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 1.8099  Validation loss = 3.9729  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 1.8560  Validation loss = 4.4296  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 1.7114  Validation loss = 3.7936  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 1.5958  Validation loss = 3.7808  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 1.9597  Validation loss = 3.6499  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 1.6902  Validation loss = 3.8462  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 1.7097  Validation loss = 3.7205  \n",
      "\n",
      "Fold: 22  Epoch: 12  Training loss = 1.6379  Validation loss = 4.0266  \n",
      "\n",
      "Fold: 22  Epoch: 13  Training loss = 1.6607  Validation loss = 4.0936  \n",
      "\n",
      "Fold: 22  Epoch: 14  Training loss = 1.7345  Validation loss = 4.6569  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 9  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.1025  Validation loss = 4.2692  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 2.1005  Validation loss = 2.4998  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 1.9982  Validation loss = 2.8151  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 2.0181  Validation loss = 3.3712  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 2.0294  Validation loss = 2.9550  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 1.9925  Validation loss = 2.7896  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.1515  Validation loss = 3.2843  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.0659  Validation loss = 3.0757  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 2.0332  Validation loss = 3.1547  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 2.0950  Validation loss = 3.8543  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 1.9435  Validation loss = 3.7173  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 1.9730  Validation loss = 3.4276  \n",
      "\n",
      "Fold: 23  Epoch: 13  Training loss = 1.8770  Validation loss = 3.6038  \n",
      "\n",
      "Fold: 23  Epoch: 14  Training loss = 1.8790  Validation loss = 3.6086  \n",
      "\n",
      "Fold: 23  Epoch: 15  Training loss = 1.8649  Validation loss = 3.5537  \n",
      "\n",
      "Fold: 23  Epoch: 16  Training loss = 1.8818  Validation loss = 3.1287  \n",
      "\n",
      "Fold: 23  Epoch: 17  Training loss = 1.8664  Validation loss = 3.3901  \n",
      "\n",
      "Fold: 23  Epoch: 18  Training loss = 1.8918  Validation loss = 3.7232  \n",
      "\n",
      "Fold: 23  Epoch: 19  Training loss = 1.6658  Validation loss = 3.7481  \n",
      "\n",
      "Fold: 23  Epoch: 20  Training loss = 1.6447  Validation loss = 3.5380  \n",
      "\n",
      "Fold: 23  Epoch: 21  Training loss = 1.6132  Validation loss = 3.3978  \n",
      "\n",
      "Fold: 23  Epoch: 22  Training loss = 1.7136  Validation loss = 4.0447  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 2  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 1.8302  Validation loss = 2.2950  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 1.7637  Validation loss = 2.1127  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.0086  Validation loss = 2.3183  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 1.9492  Validation loss = 1.4681  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 1.9221  Validation loss = 2.4925  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 1.7802  Validation loss = 2.5212  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 1.9727  Validation loss = 2.0745  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.1678  Validation loss = 2.0235  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.0480  Validation loss = 1.9194  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 1.9756  Validation loss = 1.7105  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 1.9732  Validation loss = 2.3070  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 1.8329  Validation loss = 1.7665  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 1.7581  Validation loss = 1.9981  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 2.0793  Validation loss = 2.2048  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.0272  Validation loss = 1.4692  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 1.9805  Validation loss = 2.3173  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 4  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 2.0459  Validation loss = 2.2719  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.0211  Validation loss = 2.6379  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 1.9762  Validation loss = 2.6911  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 2.1409  Validation loss = 2.5973  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 2.0890  Validation loss = 2.0298  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.0153  Validation loss = 2.5313  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 1.9447  Validation loss = 2.4361  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.1809  Validation loss = 1.5872  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.0263  Validation loss = 2.5102  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 1.9041  Validation loss = 2.4220  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 1.9332  Validation loss = 2.3451  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 1.9982  Validation loss = 2.3367  \n",
      "\n",
      "Fold: 25  Epoch: 13  Training loss = 2.0000  Validation loss = 2.8354  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 8  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.0974  Validation loss = 3.5102  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.0083  Validation loss = 3.7181  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.0839  Validation loss = 3.1631  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.0057  Validation loss = 3.6946  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.0402  Validation loss = 3.2316  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.0508  Validation loss = 3.6305  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.0255  Validation loss = 3.6098  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 2.0569  Validation loss = 3.8803  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 2.0658  Validation loss = 4.3582  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.0606  Validation loss = 4.5018  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 1.9866  Validation loss = 3.6112  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 1.9829  Validation loss = 4.1921  \n",
      "\n",
      "Fold: 26  Epoch: 13  Training loss = 2.0345  Validation loss = 3.7196  \n",
      "\n",
      "Fold: 26  Epoch: 14  Training loss = 1.9913  Validation loss = 3.6254  \n",
      "\n",
      "Fold: 26  Epoch: 15  Training loss = 1.9494  Validation loss = 3.6202  \n",
      "\n",
      "Fold: 26  Epoch: 16  Training loss = 1.9750  Validation loss = 3.9052  \n",
      "\n",
      "Fold: 26  Epoch: 17  Training loss = 2.0386  Validation loss = 3.3069  \n",
      "\n",
      "Fold: 26  Epoch: 18  Training loss = 2.0034  Validation loss = 3.9145  \n",
      "\n",
      "Fold: 26  Epoch: 19  Training loss = 1.9994  Validation loss = 4.1065  \n",
      "\n",
      "Fold: 26  Epoch: 20  Training loss = 1.9024  Validation loss = 3.2439  \n",
      "\n",
      "Fold: 26  Epoch: 21  Training loss = 1.9565  Validation loss = 3.7968  \n",
      "\n",
      "Fold: 26  Epoch: 22  Training loss = 1.8347  Validation loss = 3.5588  \n",
      "\n",
      "Fold: 26  Epoch: 23  Training loss = 1.8892  Validation loss = 3.8703  \n",
      "\n",
      "Fold: 26  Epoch: 24  Training loss = 1.8684  Validation loss = 3.3605  \n",
      "\n",
      "Fold: 26  Epoch: 25  Training loss = 1.9210  Validation loss = 3.2150  \n",
      "\n",
      "Fold: 26  Epoch: 26  Training loss = 1.9266  Validation loss = 3.3920  \n",
      "\n",
      "Fold: 26  Epoch: 27  Training loss = 1.9353  Validation loss = 3.2446  \n",
      "\n",
      "Fold: 26  Epoch: 28  Training loss = 1.9342  Validation loss = 3.3552  \n",
      "\n",
      "Fold: 26  Epoch: 29  Training loss = 1.9460  Validation loss = 3.6612  \n",
      "\n",
      "Fold: 26  Epoch: 30  Training loss = 1.9965  Validation loss = 3.6017  \n",
      "\n",
      "Fold: 26  Epoch: 31  Training loss = 1.9778  Validation loss = 3.3556  \n",
      "\n",
      "Fold: 26  Epoch: 32  Training loss = 1.9435  Validation loss = 3.2763  \n",
      "\n",
      "Fold: 26  Epoch: 33  Training loss = 1.8270  Validation loss = 3.3554  \n",
      "\n",
      "Fold: 26  Epoch: 34  Training loss = 1.9026  Validation loss = 3.3368  \n",
      "\n",
      "Fold: 26  Epoch: 35  Training loss = 1.8275  Validation loss = 3.3717  \n",
      "\n",
      "Fold: 26  Epoch: 36  Training loss = 1.8057  Validation loss = 3.6613  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 3  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.1456  Validation loss = 1.1145  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.1390  Validation loss = 1.1591  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 1.9442  Validation loss = 1.9019  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 2.0490  Validation loss = 1.6257  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 2.0536  Validation loss = 1.7150  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.0300  Validation loss = 1.6306  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.0095  Validation loss = 2.0182  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 2.0101  Validation loss = 1.4767  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 1.9758  Validation loss = 1.4256  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.9271  Validation loss = 1.4030  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 1.8999  Validation loss = 1.4007  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 1.9311  Validation loss = 1.7722  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 2.0394  Validation loss = 1.2812  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 2.0234  Validation loss = 1.4376  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.0505  Validation loss = 1.5571  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.0309  Validation loss = 1.5431  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 2.0267  Validation loss = 1.4194  \n",
      "\n",
      "Fold: 27  Epoch: 18  Training loss = 2.0163  Validation loss = 1.6761  \n",
      "\n",
      "Fold: 27  Epoch: 19  Training loss = 2.0107  Validation loss = 0.9192  \n",
      "\n",
      "Fold: 27  Epoch: 20  Training loss = 2.1496  Validation loss = 2.9253  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 19  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 2.0825  Validation loss = 2.3030  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.0791  Validation loss = 1.9126  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.0264  Validation loss = 2.1740  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 2.0313  Validation loss = 2.2791  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.0226  Validation loss = 2.2441  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.0278  Validation loss = 2.1355  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.0552  Validation loss = 2.1871  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.0439  Validation loss = 2.2989  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.0330  Validation loss = 2.2120  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.0316  Validation loss = 2.2455  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.0316  Validation loss = 2.1231  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.0282  Validation loss = 2.1747  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 2.0293  Validation loss = 2.1501  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.0351  Validation loss = 2.0941  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.0157  Validation loss = 2.3794  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 2  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.0765  Validation loss = 1.5663  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 2.0713  Validation loss = 1.5881  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.0867  Validation loss = 1.7472  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 2.0857  Validation loss = 1.6128  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.0685  Validation loss = 1.6709  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.0678  Validation loss = 1.5293  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.0767  Validation loss = 1.5415  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.0753  Validation loss = 1.5329  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.0498  Validation loss = 1.5757  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 2.0314  Validation loss = 1.5815  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.0257  Validation loss = 1.5240  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.0199  Validation loss = 1.5234  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 2.1011  Validation loss = 1.5272  \n",
      "\n",
      "Fold: 29  Epoch: 14  Training loss = 2.0426  Validation loss = 1.5500  \n",
      "\n",
      "Fold: 29  Epoch: 15  Training loss = 2.0497  Validation loss = 1.6061  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 12  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 2.0565  Validation loss = 2.5212  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.0467  Validation loss = 2.4079  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.0485  Validation loss = 2.2575  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 2.0448  Validation loss = 2.2238  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 2.0444  Validation loss = 2.0922  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 2.0460  Validation loss = 2.0454  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.0538  Validation loss = 1.9713  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.0399  Validation loss = 2.4370  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 2.0564  Validation loss = 2.5611  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.0385  Validation loss = 2.4471  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 2.0236  Validation loss = 2.4544  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.0419  Validation loss = 2.6588  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 7  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.0895  Validation loss = 3.3333  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.0856  Validation loss = 3.1186  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.0811  Validation loss = 3.1217  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.0915  Validation loss = 3.2817  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.0955  Validation loss = 3.4137  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.0914  Validation loss = 3.3239  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.0745  Validation loss = 3.0331  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.0808  Validation loss = 3.2594  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.1159  Validation loss = 3.5162  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 2.0886  Validation loss = 3.2762  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.0755  Validation loss = 3.3106  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 2.0577  Validation loss = 3.0398  \n",
      "\n",
      "Fold: 31  Epoch: 13  Training loss = 2.1627  Validation loss = 3.5335  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 7  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 1.9061  Validation loss = 5.4329  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 1.8393  Validation loss = 5.0195  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.8633  Validation loss = 5.0937  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 1.8605  Validation loss = 5.1966  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 1.8273  Validation loss = 5.1078  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.8197  Validation loss = 4.8451  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 1.7966  Validation loss = 4.9484  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 1.7979  Validation loss = 4.9991  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 1.9039  Validation loss = 5.2499  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 1.8260  Validation loss = 5.4874  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 1.7414  Validation loss = 4.6006  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 1.9690  Validation loss = 4.2088  \n",
      "\n",
      "Fold: 32  Epoch: 13  Training loss = 1.8106  Validation loss = 4.4186  \n",
      "\n",
      "Fold: 32  Epoch: 14  Training loss = 1.7883  Validation loss = 4.6210  \n",
      "\n",
      "Fold: 32  Epoch: 15  Training loss = 1.7698  Validation loss = 4.5364  \n",
      "\n",
      "Fold: 32  Epoch: 16  Training loss = 1.7412  Validation loss = 4.7911  \n",
      "\n",
      "Fold: 32  Epoch: 17  Training loss = 1.7208  Validation loss = 4.5824  \n",
      "\n",
      "Fold: 32  Epoch: 18  Training loss = 1.7068  Validation loss = 4.6187  \n",
      "\n",
      "Fold: 32  Epoch: 19  Training loss = 1.7026  Validation loss = 4.5650  \n",
      "\n",
      "Fold: 32  Epoch: 20  Training loss = 1.7146  Validation loss = 4.1219  \n",
      "\n",
      "Fold: 32  Epoch: 21  Training loss = 1.6978  Validation loss = 4.6306  \n",
      "\n",
      "Fold: 32  Epoch: 22  Training loss = 1.7090  Validation loss = 4.5409  \n",
      "\n",
      "Fold: 32  Epoch: 23  Training loss = 1.7075  Validation loss = 4.9640  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 20  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 7\n",
      "Average validation error: 3.42202\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.8473  Test loss = 3.8023  \n",
      "\n",
      "Epoch: 2  Training loss = 1.8186  Test loss = 3.7571  \n",
      "\n",
      "Epoch: 3  Training loss = 1.7935  Test loss = 3.7171  \n",
      "\n",
      "Epoch: 4  Training loss = 1.7713  Test loss = 3.6819  \n",
      "\n",
      "Epoch: 5  Training loss = 1.7514  Test loss = 3.6509  \n",
      "\n",
      "Epoch: 6  Training loss = 1.7335  Test loss = 3.6230  \n",
      "\n",
      "Epoch: 7  Training loss = 1.7170  Test loss = 3.5977  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcd651d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd01ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 3.59769759958 \n",
      "Fixed scheme MAE:  2.609556417\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.7170  Test loss = 2.8713  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.7526  Test loss = 2.3564  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.7768  Test loss = 0.5839  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.7774  Test loss = 0.1847  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.3142  Test loss = 1.5682  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.3283  Test loss = 0.8189  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.2970  Test loss = 0.6811  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.2951  Test loss = 0.1538  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.1322  Test loss = 0.0540  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.1322  Test loss = 2.1709  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.1556  Test loss = 0.0458  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.1501  Test loss = 0.2927  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.0695  Test loss = 2.4844  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.1125  Test loss = 2.0711  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.1418  Test loss = 2.2996  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.1768  Test loss = 1.8082  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.1343  Test loss = 1.2689  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.1451  Test loss = 0.1930  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.1454  Test loss = 1.0444  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.1513  Test loss = 0.9378  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 1.0947  Test loss = 1.7276  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 1.1133  Test loss = 3.6228  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.1842  Test loss = 1.5277  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.1973  Test loss = 0.2721  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.1560  Test loss = 0.3451  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.1563  Test loss = 0.5991  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.1585  Test loss = 1.5040  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.1706  Test loss = 0.4310  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.1086  Test loss = 2.0279  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.1368  Test loss = 1.0807  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.1444  Test loss = 2.4558  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.1323  Test loss = 0.0970  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.0926  Test loss = 0.2460  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.0930  Test loss = 0.6370  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 1.0129  Test loss = 1.0982  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 1.0217  Test loss = 5.2550  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.1834  Test loss = 1.1438  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.1385  Test loss = 1.2554  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.1425  Test loss = 0.2622  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.1395  Test loss = 3.1849  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 1.1035  Test loss = 2.3419  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 1.1402  Test loss = 0.5800  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 1.1394  Test loss = 1.6919  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 1.1567  Test loss = 12.5742  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.8009  Test loss = 6.5351  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 1.9748  Test loss = 1.0184  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 1.9743  Test loss = 0.1630  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 1.9742  Test loss = 0.7990  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.8631  Test loss = 2.2546  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.8835  Test loss = 3.8812  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.9387  Test loss = 4.5482  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 2.0191  Test loss = 2.8113  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.8733  Test loss = 5.4239  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.9884  Test loss = 0.2059  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.9870  Test loss = 1.6378  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.9862  Test loss = 0.3268  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.9754  Test loss = 0.8911  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.9783  Test loss = 0.0218  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.9661  Test loss = 0.0425  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.9482  Test loss = 0.7492  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.8479  Test loss = 0.2649  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.8482  Test loss = 1.1904  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.8518  Test loss = 1.2958  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.8582  Test loss = 0.4209  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.8768  Test loss = 2.6745  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.8995  Test loss = 4.8041  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.9871  Test loss = 0.7471  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.9885  Test loss = 2.2476  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.8744  Test loss = 1.4822  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.8827  Test loss = 0.1130  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.8766  Test loss = 0.6674  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.8781  Test loss = 2.1532  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.8772  Test loss = 3.2076  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.9184  Test loss = 1.9660  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.9336  Test loss = 0.2897  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.9332  Test loss = 0.8954  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.8975  Test loss = 1.2298  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXl4VOX5hu9vkslKEkLCGgIBkiBIBGQXUVAEQQQr7mux\n7lu1RX8uta211rZWrRsoKlpcKlpE0YqWRZFFgQSEsIawhQSysSQh+3J+f3znzD7JJJklCd99XVwh\nk8nkZDLznOc83/u9r9A0DYVCoVB0HEyBPgCFQqFQeBcl7AqFQtHBUMKuUCgUHQwl7AqFQtHBUMKu\nUCgUHQwl7AqFQtHBUMKuUCgUHQwl7AqFQtHBUMKuUCgUHYzgQPzQ+Ph4LSkpKRA/WqFQKNotGRkZ\nxZqmdW3qfgER9qSkJNLT0wPxoxUKhaLdIoQ47Mn9VBSjUCgUHQwl7AqFQtHBUMKuUCgUHQwl7AqF\nQtHBUMKuUCgUHQwl7AqFQtHBUMKuUCgUHQwl7AqFon1SUwNvvw319YE+kjaHEnaFQtE++fRTuOMO\n2LAh0EfS5lDCrlAo2ic//CA/Hj8e2ONogyhhVygU7ZO1a+XHU6cCexxtECXsCoWXyM7O5u6776Ze\nZb6+p7gYdu+W/z95MrDH0gZRwq5QeInXXnuNN998k5ycnEAfSsdn3Trr/5WwO+EVYRdCdBZC/EcI\nsUcIsVsIMc4bj6s4s/jqq69ITU2lqqoq0IfSbDRNY9myZQDU1tYG+GjOAH74AUJDoVMnFcW4wFuO\n/WXgG03TzgKGAru99LiKM4iNGzeyb98+9u/fH+hDaTY7d+7k4MGDQBsS9r174f77ZVlgR2PtWhgz\nBrp2VY7dBa0WdiFEDHAB8A6Apmk1mqapU6ii2RQUFABYBLI9Ybh1aCPCfvw4TJ8Or78Oe/YE+mi8\nS1kZbN0KF1wAsbFK2F3gDcfeDygC3hVCbBVCvC2EiHS8kxDiTiFEuhAivaioyAs/VtHRyM/PB9qv\nsAshAKgJtEOuqYHZs+HAAfl5eXlgj8fb/Pij3JQ0YQJ07qyiGBd4Q9iDgXOB+ZqmDQfKgccc76Rp\n2gJN00Zqmjaya9cmJzspzkDaq2PPz89n48aNTJgwAQiwY9c0uPdeWLMG7r5b3tbRhH3tWggKgnHj\nlGN3gzeEPRfI1TRto/75f5BCr1A0C0PYDxhOs53w1VdfATB79mwgwML+0kvwzjvwu9/JXZkAp08H\n7nh8wdq1MHw4REUpYXdDq4Vd07R84IgQYqB+08XArtY+ruLMQtO0duvYly1bRlJSEueeK/1MwIQ9\nPR3mzpUxzNNPy4oR6FiOvboafvpJxjAgoxgl7E54qyrmAeBDIcR2YBjwFy89ruIMoaysjKqqKoKC\ngjh48CCapgX6kDyioqKCFStWMHPmTEJCQoAAZuzffy+jmDfeAJMJIvWlro4k7OnpUtwvuEB+HhsL\nVVXyn8KCV4Rd07Sf9fz8HE3TrtA0TZ1CFc3CcOtDhw6lrKyMEydOBPiIPGPlypVUVVUxc+ZMzGYz\nEEDHvmcPdOsG8fHy844o7EYbgfPPlx9jY+VHtYBqh9p5qmgTGMI+duxYoP3EMcuWLSMmJoYLLrjA\n4tgDJux798JZZ1k/74jC/sMPMHiw9eRlCLuKY+xQwt4aNE31gvYSRqmjIeztYQG1oaGBL7/8kmnT\npmE2my2OPWBRzJ49MHCg9XOzWf7rKMJeXw/r11vzdZAZOyjH7oAS9tbwj39AcjI0NAT6SNo97dGx\nb9q0icLCQmbOnAkQ2Cjm+HHZGMvWsYN07R1F2DMzobTUXtiVY3eJEvbWsHQpHDok/ylaRUFBASaT\nif79+xMXF9cuhH3x4sWEhIQwbdo0gMBGMXv3yo+uhL2jlDvu2yc/pqVZb1PC7hIl7C2lvBw2b5b/\n37YtsMfSASgoKCA+Pp6goCD69evX5oW9rq6Ojz76iBkzZtBZjwMCGsUYbQNsoxiQJY8dxbHrcR09\ne1pvU1GMS5Swt5Qff4S6Ovn/n38O7LF0AAoKCujevTtAuxD2//3vfxQWFnLLLbdYbgtoFLNnD4SE\nQFKS/e0dKYrJz5c7TuPirLcpx+4SJewtZc0aWSucmKgcuxewFfb+/ftz6NChgA+sqK+vd9tb/f33\n3ycuLs4Sw0CAhX3vXkhNlcJnS0cT9u7d5fvOwGyWv6MSdjuUsLeUNWtgxAgYP77ljj03F/Tt6Gc6\njo69traWo0ePBvSYPvroI/r168ePP/5od3tpaSmff/451157rSVXhwBn7I4VMQYdTdh79HC+XTUC\nc0IJe0uorISNG+HCC2HYMDh8uGWO4dVXYeZMKCnx/jG2I4x2ArbCDoGvjNmxYwcNDQ3ce++91Bmx\nG7BkyRKqqqq4+eab7e4fsIy9pgb273deOIXGhf3wYbjhBmgnm8HcCrvqF+OEEvaWsHGjfDNdeCEM\nHSpv2769+Y9z9KishU9P9+7xtTNOnz5NRUVFmxP2gwcPYjab+fnnn3njjTcsty9atIiUlBTGjB4t\nxUZvfyCEICgoyP+O/cABWePdXGFfuxb+/W/48599e3zeQgm7xyhhbwlr1oAQclvzsGHytpbEMXrt\nNps2ee/Y2iFGDbsh7H369EEI4XNht2085oqDBw8yceJEpkyZwu9+9zsKCgrIycnh+++/5+abb0Ys\nXSorNBITYc4c+OgjepnN/hd2dxUx0Hi5Y2mp/Pjaa9DGF6tpaJDvF3dRjBJ2O5Swt4Q1a6Sgd+4s\nX2jdu7dsAdUQlY0bG79fB8cQ1x76mzY0NJSEhASf7z595ZVX6Nu3L8XFxS6/fvDgQfr168err75K\nRUUFjz76KB9++CEAN910k7xKEwLOOw+WLYMbb2R7VRXhx4/79LidaErY3Tj2/y1ZAoAmBDzxhK+O\nzjscPy6vStw5dpWx26GEvblUV8tSxwsvtN42dGjLHHthofy4caPlcv5MxNGxg6yM8aVjr62t5YUX\nXqC6uppdu5y7TJeVlXH8+HH69etHamoqjzzyCIsWLeKll17i/PPPl3FRTg706gWffCL/lqtW0RkY\nttvPI3/37JFXDtHRzl/r1El2PnSoMHruuefYvHo19cDemTPh44+t+zLaIkYNu4piPEIJe3PZvFm+\nUWyFfdgw2LkTmnMJ3tAARUXQpYt80ebmev9Y2wmuhN3XtexLlizhyJEjAGRlZTl93fjZRt7/xBNP\n0KdPH4qKiqyLpocPQ58+8v9BQXDRRWSYzYxw8Xg+xbH5ly1GI7CKCstNL7/8Mk888QTDBgygFPjv\n4MFyKPQjj7Rdg9GYsHfuLGMl1bfJghL25rJmjfxo269i6FC5mNqcocHGpeVll8nPO2DOfuTIEbtF\nR3cUFBQghMB2ZGK/fv04evQo1dXVXj8uTdN44YUXSElJISQkxCNhj4yMZMGCBYwYMYJrrrlG3ikn\nB/r2tfu+LyMj6XP8OPjLtWuafN01Jex6HPPWW2/x0EMP8Ytf/IJp551HRVAQ2w8dgj/8Qb62v/7a\nP8fdXJpy7HDGV5fZooS9uaxZI3tV2O5+a8kCqpGvX3KJ3DHYAXP2+fPnc88993Ds2LFG71dQUEBc\nXBzBwcGW2/r164emaRw+fNjrx7V+/XrS09P5zW9+Q3JycqPC3r9/f8ttU6dOJT09XbYQaGiAI0ec\nhP3bmBgahJDVJv6gsFDmy67ydbAT9vXr13PXXXcxbdo0/v3vf2MqL6cmLIw9e/bAnXdCSgo8+qh1\nR3Vbwni/NCbsKo6x4DVhF0IECSG2CiE67o6b2lrYsME+hgG54y8srHkLqMYLNTFRnhj84Njr6+v9\nOsAiMzMTaLoFb35+vl0MA1an7IsF1BdffJEuXbpwyy23kJqa6lbYO3XqRJztCdz+oOVVmhHF6JwK\nD2dH165S2P0Ra7hr/mVgI+wffvgh4eHhfPrpp4SGhkJZGXTqxJ49e9CCg+HJJ2HXrra5kzo/HyIi\nrOP+bDH6xShht+BNx/5rwM+rRn4mI0Ne0joKe3AwDBnSMsfevTuMHi1r2X2cEb722mukpKTYbbbx\nJZ4Ku+3mJANf1bJnZ2fz+eefc8899xAREcHAgQPJzs52al9gVMQIIVw/kNFqwMGxh4SE8ENCAmRn\n+2d/ghH/NSHsWlkZX375JVOnTiXSEPvSUoJiYyktLZX98I2uiW7aKAQUo4bd1d9DTVFywivCLoTo\nDVwGvO2Nx2urNKxeLf9jzFu0ZdgwKeyeujRbYR8zRp4wXFRneJN169Zx4sQJSnyVRS5fLsXhhRco\nzcuzxCj79++XvcKffx7uu8/6u+u4EvZevXoREhLidWF/+eWXCQ4O5r777gMgNTWV2tpap8jHEHa3\nGPd3cOxms5kf4uNlvPbRR149dpfs2QPh4fLKzxW6iO/fvp3c3Fwuv/xy69fKygjV1zX27NljfQx9\nUblN4W5zEqgoxgXecuz/BB4FOvTEiaPz5pEZHEyVq7KyYcPkgqin/U0KCmQDo9hY6djB53HMjh07\nADjpqzfAp5/K6qC5c4kYNIg/A5OAye+/D717y/x2wQIYOdLOzboSdpPJRFJSkleF/eTJkyxcuJAb\nbriBnnrr19TUVMC+MkbTNA4cONC4sLtx7GazmVMA06fD4sW+r9Qwmn+Z3LyV9egi44cfEEJwmbFY\nD1BaSif9edizZ48cNxcW1v6EXUUxTrRa2IUQM4BCTdMymrjfnUKIdCFEelFRUWt/rP85dIjeeXl8\nUFfHl19+6fx1o7VAI3FMcXEx69evl58UFsrBw0LIRavOnX26gFpVVcU+fVDBKV9dsm7aBNOmwcaN\nHElO5nFgNTD88GG4/XbYsUOWiwYFyV27ixZRXl5OeXm5ZXOSLaN69iRaj3O8wdKlS6moqODBBx+0\n3OZK2IuKiqioqGjascfEONWOm42dpzfcAMeOWauofEVjFTFgceyZP/3E2LFj6datm/VrZWVEdO9O\nZGSkFHYh5Am4vQm7imKc8IZjHw/MFEIcAj4GLhJCfOB4J03TFmiaNlLTtJG2ZW3thcJ58wD4FPjX\nv/7lfIdzzpEfG1l4evzxx5k4caJcwCwokDEMyDfU6NE+dey7d++25Mg+cexlZTJKGj0aRo/mxfHj\nGRkZyfyJExkaFye3rZ99tryySU+XuzVvvZX6229nEpAQE2N9rE2b4IYb+Nfatby1d69TdOOKuro6\n3nrrLR544AEa3IwqLNQ3hA0aNMhyW9euXYmJibETdsdSR5e4KHUEmbHX1tbCjBnSLfuyOqaqSrYC\ncFcRAxZhLzx0yDLCD5CRYVkZIiaGs846Swo7yDimrQl7TY28GnYn7BER8upXOXYLrRZ2TdMe1zSt\nt6ZpScB1wGpN025q9ZG54vRpmUUHYBNF/ccfkw6Mvf56vvnmG+ceI9HRaAMGUONm9159fT1ffPEF\ndXV1fPPNN/bCDjJnz8z0WYtVI4YBHwn7li3y7zJqFCAXTsPOOYeTl1zC/sJCym1/r/h4+N//4KGH\niFq8mNXAjffdJ696xoyR/776ikOpqZiAskZOeJqm8eWXX3LOOedw55138tprr7lt91taWkpwcDBh\nYWGW24QQTpUxHgn74cMuhd1sNsvujuHh8ItfyB2dM2bAxIkygrrwQu91U8zOls+5B449Euzz9YoK\nWbIZFdX2hd3Yoe1O2IVQ/WIcaF917I8/Ll1QSIgUhwED5CW+t3j/fbj0UukQbDl0iJ5HjrCuZ0+e\neuop6uvrLT1DbPlZ08j98ksqbHb5Gfz4448YEdSXX34phd32snj0aPlG27LFe7+PDZk2kYZPohjj\nhDZqFJqmkZmZyZAhQyx14E5ZeXAwvPQS//3Xv7gUyP/Vr+SJrqYG/vlPyM0l57HHAMh3E2ccO3aM\nSZMmMXPmTOrr67ldfy2UGs2tNE26Wp2SkhKio6OdKl1aLOwOC6dgE8UA3H8/9OsnIxlNk7s7166F\nv/3N9WPW1IAR1XmC8VrxQNgTY2MZPHiw9XbjOYqO5qyzziInJ0eefBMT5TpRW9rF2djmJAPVVsAO\nrwq7pmnfa5o2w5uPaceVV8o3xSOPwLXXyrP0u+86C3FL+fe/4dtvYf58u5vL33sPgIbZsxk0aBCj\nRo1yimO2bNnCwgMH6F9fzyYXDZWWLl1KSEgIs2fP5pvly9EKC+0du7GA6qOcPTMzk5SUFMBHjn3T\nJjmWrWtXjh07xokTJ0hLS2PAgAGA+5LH3PJyvgUa/vAH6eK3boVf/xqioxl48cVUAKfdlA2+8cYb\nrF27lnnz5rFjxw5mz54NYK36ef99efLUN0iVlpYSYxv56KSmppKTk0NlZSUghT0+Pp5Ormqm5Q+Q\n/xqLYkD+Tbdvl2Wya9bIqqGbboJXXoG8POfH/e1v5dqDzdVVo7zxhjQ3RgzogvKaGmqAcwYMsD+h\nlZXJj7pjB32dITFRinoTm8r8iqfCrjJ2C+3LsU+aJCsr/vIXeP11KQANDd5pOapp1oz7j3+UmZ5O\n5aJFbAYm6PMtb731VrZv387P+kKppmk88MADfNa1K7vMZobMn2/3ItM0jc8//5zJkydzww03QEkJ\noqbGXti7dZPC6KOcPTMzk9GjR8uqDV85dv3kZMQ+aWlpFse+f/9+l99mRFp2i3o6PRMS2B8cTJCb\n783IyGDQoEHcc889mM1movWFTIuwv/WWFLD337fcHu2ioik1NRVN0yzHePDgQbsdp04YFTFuHHuj\ngzaefloK55/+ZH/7mjVyHcL4f1P8+KP899BDzuPwbFi5ciXlwMDeve2/YAi77tihDZc8eiLsKoqx\no30JuyO6AyU7u/WPdeCAFPMHH5SXqX/8o7z94EHiDx7km6goRowYAcB1112H2Wy2uPYPP/yQDRs2\n8Mxf/8r6X/2K2JoaSu+5x/LQO3bs4MCBA1xxxRVccsklJOqTdnAo8WP0aJ849pMnT5KXl0daWhqx\nsbEtduyHDx/m+eefd46aiorg0CG7fB2ksHfp0oXo6Gi3jr2goIAuXbpYpg/ZIoTgeFwcXYyM1QZN\n00hPT7f8TQCLGy8tLZVRybp1Mn9duBA0jdLSUnth1zQoKXGqjGmyht1NqSM4RDGu6NcP7r4b3nkH\njPinvBxuu42ybt3IA7Lffdf99xu89JIUs1/+stG7LVu2jHIh7BenwRrFREWRnJyMyWQKvLAXFcm+\n9o77LAxhd3Hyt6CiGDvat7AnJ8uPehlfqzCc8pw58o03fz7s2kWdXtVQcdllmPRa4bi4OC6//HI+\n+ugjTpw4waOPPsqoUaP45S9/ydTHH+dFIPrjj+G77wD4/PPPEUJw+eWXExUVxSVGaaSjsI8YIUXD\n0xfosmVyQW7hQtedJU+cgP377Rx0586dWyzs8+bN49FHH2X8+PEcOnTI+gWbfB2ksPfs2ZO4uDiE\nEAwYMKBRx+5Yw25LTf/+9KqpodYQIp2jR49SUFDAyJEjLbcZwl5SUiIXLUFuk9+7F376yTmKee01\n6NGDVP3TrKwsywDrlmxOAg+E3TimsDB46in5+RNPwIEDvHbuuawBIjIyWPrZZ+6//9AhWLIE7rrL\n9RZ7nYaGBr766itEp06Y9JjJgk0UExYWRr9+/QIv7CtWwHvvyTjUlvx8Kdyhoe6/119RjKsIrQ3S\nvoU9Pl7WEnvDsW/aJCsZhgyRl8udOsHcuZS/9x4bgfE33mh391tvvZXCwkKmT5/OsWPHePXVVzGZ\nTPTp04cfLrqIQ8HBaHfcARUVLF26lHHjxllqtSfrW7cPOb7ZjMUtTzsDrlol89tf/QoGDYJ//UuK\n+aJFsmtk9+5w9tns27ABwOLYWxrF7Ny5k27dunHw4EFGjBjBihUr5Bc2b5YbZHT3bCycGvTv379R\nx+6qht0g4txzMQGHVq60uz1dz91tHbtdFPPRRzBunIzuIiNh4UL7KKa0VP6dq6ro9Ne/0rNnT7Ky\nssjLy6O2trZpYQ8JcRkN2GXs7ujeXebpn3wiF4pffRXuv5+F2dkcHzSIXsCT11/PDz/84Pr7X3lF\nPt/339/oj9m8eTOFhYWEx8U5V1vZLJ4C1sqYmBj52g+EsBs/0/GqtbEadgMjivFlxdzq1bLOvxVx\nqau+RL6gfQu7ENK1e8uxjxghqzXi4+H3v4fly4nZt4/Pg4O5+OKL7e4+bdo0unbtysaNG/nlL3/J\nmDFjLF+74fbbmVNXh9i/n5KHH2br1q1cccUVlq+P1i/hlztWwBj11R4Ke+WhQ5QnJMAXX0BUlLws\nj4uDW2+VC3Bz5kB1NRFffUVMTAy9e/dulWPftWsXkyZNIj09nV69enHppZfywgsvyOdu0CDo1In6\n+np27dpFmtF3BBgwYAAHDx50WV/elGPvofflOaZf/RhkZGRgMpkYZnTWBDp16oQQgtDsbLloecMN\n8nm5+mpYvJi6khKrY3/hBRm9XXklfPopl+vC7nENe2Kiy92eTWbsBr/9rfxbPfwwJCVR8NBDZGdn\nE6XvDJ3VpQszZ860q2YCZEzx9tuyeMAxN3fAOPlFdu/uLOw2jh2ksGdlZVHf0BC4kkcj4nIUTk+E\nPTZWrl24GwPoDd56S35sTntunfLych5++GHOOussli1b5uUDc6Z9CzvInL21jr22VpaOGZUpAPff\nj6ZHPUUTJxIeHm73LWazmTlz5hAbG8tzzz1n97UrrriCnzt3Zm2/fnR65x3M+m0GcXV11ANLvv/e\n/jiSkuQluoc9Y45t2UJ6Xh5HR46Uzv2zz+Rl/oYN8nJ9wQJIS2PItm2kpaUhhGixYy8vL+fIwYOM\n7NuX5ORkfvzxR6644grmzp1L7YYNludu//79VFVV2Ql7//79qampIc/FZayrzo629L3kEgAqtm61\nuz0jI4PBgwcTERFhuc1kMhEdHU3qli1SdK++Wn5hzhwoK+PiU6ekYy8slMJ+9dWyqio+nl8XFHgu\n7G5KHcHDKAakU/7jH+XC5zvvsFb//QbPng1duvDkhAlERkYybdo0TtuK1TvvSFF++OEmf0RWVhZR\nUVGExMZ65NirqqrIMU5agXTsGRn20aKnwg6+i2NOnoSlS+X/mxnHrFy5kiFDhvDPf/6Tu+++m4kT\nJ3r/+Bxo/8KenCxFrAUlj/v37+fvf/87S/RL8p2RkWzXmyVV1NWR/fTTPAiMu+46l9//7LPPcuDA\nAacoITw8nOuvv563c3MJqq9nxoABllJDAAoKqIiIYM26dfYiGxQka5I9dOwhJ06Qj1wgw2SSG2L+\n/GcZQeilbdqNNzKkrIyJenba2OJpaWkpm9xcZu7du5f7gYf/+U/Ys4dOnTqxaNEiRsTFYT51yuXC\nqYG7kseKigpOnz7dqLCbO3cm32wm2CajNxZOxw4dKnNZm8vv6Kgohu/eDZMnW9cwJkygYcAAbq6v\nl8L+7LOyvv2ZZ6SwPfEEg/PySCsqYsuWLQgh6ONGuAG3u07BwyjG4P775Ulm0iTWrl1LeHg4w0eM\ngPPPp9PWrbz66qvk5eVZXXtdHbz8stzkZBNBuSMrK4vU1FSEq7mnZWXyNaMbFqfKmEA59uBgqKy0\nL/n0NIoB3y2gfvyxHItpMnks7HV1ddx+++1ccsklsuvnDz8wb948l5VZ3qb9C3tKiix5tF3M85A/\n//nP/N///R8rnn0WgMueeYahQ4eSmJhIZGQkg265hVfBvnGSDcHBwXLoggvmzJlDhv4Gv94mbwag\noABTz57U1dXxreNC0aBBHjv26MpK8oEvvvjC7X2OTZxIA3C57tCMKEbTNLlZ5r77LMI4f/58zjvv\nPJc923ft2sVUIKimRi4uaxqRkZE8re9m3KyfSDIzMxFC2G2GcVfy6GokniuOd+1KXHGxPGYgLy+P\nwsJCfnXqFEyZAvfea9lQMyEkhG6nT8sYxkAIKq6+mknA4IICuTB+223Wrfj33ENlfDzPAd9+8w29\ne/cmJCTE9cHU1MgNPI049pqaGsuxNkmXLoDsvDl27FhZHTRhAmRnMyQ+HrDZ3LVkiRS/3/zGo4c2\nhJ3ISOeIorRUntT0v5uTsBcUeG9/iKfk5MgTMlhzdmO3uaeO3VfC/u67cr/AoEEeC/t///tf3nnn\nHR5++GG2bdvGBNupaz6m/Qt7Kypj0tPTmTp1Ki9cey11sbG8u2oVn376KQsWLOC5557jN7/5DfPm\nzWt0cc8dI0eOxHz22dQA5zuWmhUUEJGURHx8vHNDscGD5aV+E1lhWWEh0ZrGCbOZVatWWXdbOrDt\nxAm+B4Zs2waaRmxsLPX19ZQXFcHNN8O8eaAL7pEjR6ivr7dks7bs2bGD8YCWmCjrrBctAmBq585U\nA795913LjtPk5GS76CoxMZGgoCAnx+6psNclJ5NcV8cxvVWAcXyDc3Nln5A33oAbb4SaGq6orKTG\nuHqxoWj6dBqA6QsWSNf1+99bvxgWxqmHH2Y0cPa+fY3HMHl58kToxrEbZZuO/d0bo6ysjJ9//tn6\nxtfbQvfVXfOBAwfkz3zuOXlFN6PpPYDV1dUcOnRIXim6c+x6vg4QHx9PXFycVdg1zb8VIKdPS1G+\n8EK5xmVcOXpSww6+jWJ27pQFAnPmQEKCx8/Ld999R3h4OM8995xdGwt/0P6FvYW17OXl5ezatYsx\nY8YQmZlJ8HnnMemii7jqqqu44447eOyxx/j73//OPTb16M1BCMFjTz3F0agoehQX23+xoADRowfT\np09n+fLl9ouKhtM1JuO44cCPPwIwaNIkamtrZf8ZF2RmZvIhEJGbC5s3W64w6v/yF2vZnv4mMloe\nuIpjqn78kShA/P3vMH68XPwrLiZ461ZKkpJYt2kTX3/9NTt27LCLYUCKXd++fVvs2CPPPZcoYLfe\nDz8jI4MYk4monTvlvoO//122yJ01i8nHj7M2Otqp6+KJiAj+B4RUVcEDDzgtPMY99BC7gL8A/d2I\nNtBoqSNgcfoexzHIdhMNDQ2cf/758obhwyEigtCffqJnz57SsS9fLhvM/d//uW/Ra8OBAwdoaGiQ\njr1TJ9cZu8NzZKmMCUTJo/Gz+vSx38/R2Eg8W3wZxbz3noyIbryx2cI+fvx4Oa3Kz7R/YY+Ply/Q\nZjr2bdtaUjQEAAAgAElEQVS20dDQwJhBg2SmbVPV4i2uvfZaki6/HOFY2aC3Exg/fjwnTpywrwk3\nKmOaiGNyddd63pVX0rVrVz7//HOX98vMzOTHnj1lDfAHHxAbG8sAIGrePLjmGpmx6kJudD90Jexx\nO3fK/1x4oXTIJSVS3NPTiZs+nf79+/PYY4+RnZ3tJOzguuQxX3djTQl7j0mTACjQd2RmZGRwU2Ii\noq5Ozox95BFZsfC//xFbU8NnLtxRaWkp/wBKBw4EvQeNLSEREbzdvTtnARe62CxlwRD2Jhx7c4R9\n3bp1mEwmxo4dazyIXCdZu5Z+/frJ5+2556Tg2kZMjWCU1VmimKoq+/4vDo4d2pCwjxkj35Olpc13\n7N4W9tpauXN5xgzZ6ychQR5TE1PIiouL2b59O5P0166/af/CbvQzb6Zjz8iQ7eNHmUzystO2Isab\npKXJF61xiXj6tOys1707Q/WNSttsW/0mJ0t30ISwF+uLS72GD2fGjBl8/fXXLsvsMjMz6Tt0KFx+\nOXz8MV2iongFaDCbZQ31iBEuhd02I66srGTI8eMUd+kCPXvKWv+5c2UcU15O0Jgx/PGPf2THjh00\nNDS4FPYBAwY4Cfvnn39Ot27dLEMv3NHp3HPlcWzdalk4nRURISuIzjtP3un222HJEjYlJ/Olixik\npKSEVUD2Rx/ZDyK3IWfoUKqBUY31STFK8txMLDKE3aOSR521a9cyfPhwomyFdsIE2L6dIb17E7d7\nt9xF+8gjsn7eAwxht0QxIF93BmVlLh17YWEhJ4z7t1LYq6qqWLRokWexlO3zOnq0fE+mp9sJe1lZ\nGc8++6zLJnvExEgt8Lawf/utvGqYM0d+npAg1/SaaCW9RjchSthbQwtq2dPT0+nRowfxRjygV3V4\nHUPkjFV+4wXRrRtpaWmYTCZ7YTeb5UScJipjTusnsuDevbniiisoKSmxvJgM6urq2L17txTam26C\noiLS3nyT6cDu666TIj16tCz1rK2lsLCQ0NBQCgoKyM3NtTxO1p49nA+U2tSM89RTcns8wOjR3HDD\nDZYF0yGOi8VIx15cXGxZC9ixYwfffPMNDzzwAMHBwY3+riQkUBkUhPnAAXJzcykqKmLEyZMyi7Z1\n51dcwZIrr6TQxXqD8XNdNQEzSBw8mO+A/pmZ7je6HD4sq23cZKbNdew1NTVs3LjRGsMYXHABaBrn\nm0zcVlCA1rWr3IjmIVlZWXTr1k1GbzYDrS2Uljo59uHDhwOw6qef5KJuK4V9/vz53HrrrZ7Vbefk\nyIipVy/7hnj5+bJaLC6ODz/8kN/97ne8r/f+scNkkicqb2fs774rWxlMmyY/T0iQH5uIY7777jsi\nIyPtdkb7k44h7CkpzS55zMjIYMSIEYjNm+WJQa9O8DqGsBtxjM2s04iICFJSUuyFHTyqjKnLzZVz\nCLt2ZfLkyYSHhztVx+zbt4+amhop7NOmQZcudF26lO3A1vHj5Z3GjIHqauq2bOH48eNcdNFFgH0c\nc/Tbb4kFQoyKBZCLlh98ICtkUlMJCgri9ddf57rrriPZWNC2waiMMVz7iy++SHh4uGdrGEJwsls3\nup86xZo1a+gFdMnPlzGMA9HR0VRXV1NdXW13uyHsjZWaDR8+nP+aTITn5rpf42ik1BGan7Fv2bKF\nyspK54qJMWPAbGbSzp1MB07cfLN8zj3EUhEDroXdhWOfOHEiiYmJvP32260uedQ0jXfeeQeAJUuW\nNP0NR45Io2E2y/diSopV2Lt1g6Agli9fDsDChQtdP4a3+8UUF8OXX0pTZMRzzRD2CRMmuOyB5A86\nhrAnJzer5LG8vJzdu3fLs+mmTT7J1y0kJsrLRBfCDjB06FBnYR88WFaqOIiTQXl5OWGnTlEZGQlm\nMxEREUydOpUvvvjCLkIx6p+HDBkiL+GvuQaA+4AThqvV3VHF99+jaRqXXHIJZrPZTtjr9Y1UXa+6\nyv5AzjtPlg7qi3kTJ07k3//+N0Euug0atez79+8nPz+fDz/8kDlz5hDnJhZxpD4lhYHI6VVTjPaz\nticaHbtGYDYYHR8bE/Ybb7yRR4xt/O5cZiObk6D5Ucy6desAGG+caA0iImDECHpnZlIKbHd09E3g\nUthtK61cOPagoCBuu+02VqxYQUVcXKuEPT09nZ07dxIfH8+yZcucTrRO5OTYP6/GAuqxY9CjB9XV\n1axatYrY2Fg2bdrETmPNxxZvC/v338uMXX/fAB4Je0FBgWWXdqDoGMLezMqYn3/+mYaGBsYnJck/\nkK/ydZC5X1pao8J+8OBBa6tZkMLe0GDt/ufA3r176QbU2YjirFmzyM3NZYvepmDt2rU89thjsh7f\nWJD985+p//Zb1mEzbKNvX+jalXq9yqZ3794MHTqUzTaToLrs2EFecDChtpusmomtY3/ttdeora3l\nYQ92Txp0GjGCJGD9ypXMjomRC1ku+pDbNQKzobS0lNDQ0EYrFIKCgugzfjyce65rYde0Jh17c6OY\ndevWkZyc7LqkVnfx84B9zZgTXFpaSn5+vnvHro/FcxR2kPsvAHaUlFhz7xawcOFCwsPDefXVVykr\nK7P2FXLHkSP2wj5mjHTrGRnQowdr166lvLycF154geDgYN511QGzc+dmRTElJSXcddddHLdp0W3H\nli1yvcto2gfydWc2Q14eDQ0NLF++nDqHhdTvdSPkjx2m7ugYwt7MWnZLAyljUceXwg5WYdc0u4wd\nsCygbt++3Xr/Jipjdu3aRQ8gyKZkb8aMGZhMJhYvXszcuXO58MILEULwzTffWGto4+IImjKFmJgY\n6+5Tfd6qWe8t361bN0aPHk16erpc9NI0UvPz2dfEAmdTxMTEEBcXR2ZmJvPnz2fWrFkuIxt3dNav\nqlKB86urpVt3Ufbn1JNdx6llb2PMnCnbMji2Cy4qktUljTj25kQxDQ0NrFu3zv3GlWuvRRs1iteC\ng902UXOFMbTcIuxGB0hD2I2xeC6ej759+zJ16lRW7dsnG8q5WqhsgoqKCj766COuuuoqrrzySmJi\nYvjPf/7j/huME6btgrRxFa3vOl2+fDkhISFcc801XH755bz//vvOz3EzHfuGDRv4bsEC3nzzTdd3\n2LpVmizb9RSTSUZGeXmsXbuW6dOn8/zzz9t923fffUdUVBTn6ov+gaDVwi6ESBRCfCeE2CWE2CmE\n+LU3DqxZdO0qX6QeOvaMjAx69uxJl/375RnZdlHQF6SlyfLA3FwpFl26WDI7l5UxqanyBeRmAXXn\nzp30ACJsNtLEx8dz/vnn8/zzz/PCCy9w9913s23bNudFOXBuBDZmDJE5OURhFfaysjL27t1LTWYm\n8fX1nGxkSo+n9O/f39LqeO7cuc36XqGf7GYDnSsrXcYw0HgU0yxh1zT473/tb2+i1BGaF8Xs3buX\n48ePu/wbATBiBGLTJsKTkpxHCzaCXakjODt2hwZgjtxxxx3sNJ4/mzhm69atXHXVVU4nTUeWLl1K\naWkpt912GyEhIcyaNYsvvvjC/XNSVCRjxz59rLuehw61VgDpwj5x4kQiIyOZM2cOhYWFfP311/aP\n00xhN23eTBaQ+frrrgegb90q9xQ4otey79bfn88884zssaPz3XffccEFF8iiADeD1X2NNxx7HfBb\nTdMGA2OB+4QQg5v4Hu+id3ls0N8oFsrKXLr4jIwMma9nZcnRYr7eFWa7gOowxDohIYG4uDh7YQ8P\nh/793Tv2nTvpKQQmBxd9zz33cPbZZ/Ptt98yb948t6PdnBqBjR6N0DRGIoV9lF4htGnTJop0pxWs\nL6q2hgEDBlBfX8+YMWM4zyhT9JSUFBqAO43PmxB2V469sYoYO4YNk+7RMY4xjIOXohij5NZSv+6G\nxtoeuyIrK8vSBx9wFnaHBmCOzJgxg9PGhh9d2Pfv38+ll17KkiVLmoxVFi5cSP/+/blA30F71VVX\ncerUKVbrG8yc0H/GnvJy4uPjWblypdx3oRuu42Yzu3fvZppemTJt2jR69OjhHMc0M4oJ0p/TgUeP\nOrdIPnZMvlcbEfbs7GzLFdpvfvMbqK/n1D/+wf1ZWbxujBkMCYFZs2RPIz+KfKuFXdO0Y5qmbdH/\nXwbsBhJa+7jNJiWF4o0b6dGjBw8//LB0pDfdJBf4bBYUT58+ze7du2Uf7/37pbD7GqP8b/t2pyHW\nQgjXC6iNVMbk7NhBmKY5bdq47rrr2LFjB1OmTGn0cJwcuy7kY/XujwMHDiQqKorNmzdTt3o1R4E+\nXhB2I2efO3eu00DpJgkPp6ZHD7oDDSkpbuMQd1FMsxy7ENK1/+9/siEVyFatDz0k39SGE3ZBc4Td\nMCFNtaywbFLykKysLPr27WuN4Jrp2ENCQhinLxieysyksLCQSy+9lLq6OsLDw933iUf2tVm9ejVz\n5syxDKa55JJLiIqKch/H6G53R2kpmqbx2GOPySIAPY7J0BcqDWEPDg7m5ptv5quvvrLsXgakY6+s\ndFt04IT+vRcEBTlX2hjdRJsQ9pSUFJ588kmWLFlC+j/+QedHHuEWID4kRI7yvPdeOcJwyhT5nn7l\nFecJUT7Aqxm7ECIJGA44zXcTQtwphEgXQqQXNWMhyFMqExLoUlpK/8REXn75Za7v21c6ruJiu6z0\n559/RtM0Ro4YIcfh+UPYO3eWZ28Xjh1kHLNjxw77jRyDB8srCoeFmcrKSqqM6p8W9LABF469SxcK\noqM5PyQEk8lEUFAQI0eOZNPGjcRu385aINVomNUKrrvuOh566CF+4dDHxVPCdAdnauTE5S6KaZZj\nBynsFRVymMn+/WD041+5stGyw+Zk7MbfoKnj6t+/PydOnGgyAjHYt2+fNYaBZjt2gNkPPghA+tKl\nXHbZZeTl5fHVV18xbtw41q5d6/b73nvvPYQQ3HrrrfIGTSOsuJjfDx9O/48+ov7ee53bG+iOfbd+\ne0ZGhiyR1IV99e7d9OvXz+53mjNnDvX19XzwwQfWx2nm7lOzrkPjTCY++/RT++fXmJXgKqZNSIDT\npzm6Zw8pKSnMnTuX5ORkVv3jHwAMj44mbNs2uYHvlVfk7/fBBzKC/fWvPZtp20q8JuxCiE7AEuAh\nTdOcdohomrZA07SRmqaN7Nq1q7d+rIXv8/IIBpa98gpbt2zh70FBGBc+FTZu2Fg4Hdmvn3yB+0PY\nwbqA6kbYKysrLYtegBT22lpLgy6DrKwsuhlXIK0QdsfWvXuio62LycCoUaMo3baN6LIydnXt6tSP\nviWkpaXx0ksvuSyH9Ajj5OKift3AK4unIFsnREXJ9gkXXSRd4KpVsglXIzQnYz958iTR0dFNPh9G\nUzJPcnZN0+xLHcG53LEJxw6QfPbZnDCbObh2LVu2bGHx4sWMGzeOCRMmsG3bNpcnmfriYhJefJHV\n3buT+Mtfyqql+HhITGTuDz/wRGUlQfPng2M2npMDYWHsLiykT58+DB48mCeffJK6K66gdt48Xt+6\nlenTp9td5Q0aNIixY8eycOFCa4lvM/vFhOon1vDaWpKrqvjYGKcI0rEnJ7s++eklj9UHDpCcnExo\naCivvvoqPYuLyQXOmTTJ/m8aGir7zPz4o6zycdMt1pt4RdiFEGakqH+oaVojwxp9Q319PQv1y8OB\nJhND8/M559QpsqdPB+Cjp5+23DcjI4NevXrR3XiRNzaN3pukpVn7X7gQdnBYQHUzTWnXrl1YvruF\nwu5qitIWs5nudXWW+tzRo0czTb9aOH722S36OV5n0iTZvKuRMrKQkBDCwsJaF8WAfDNOmyYXUEtL\nZSzjYketI82JYk6dOuW27bMtRoTlibAXFRVRYjOgWz8o+c8ximnq+ejTh0TgzTff5HK9PfMFF1yA\npmls0Mct2pL9+99z5+nTjABZPdS/P1x1Fbz6KtWrVpEQEUGl2SxHzNmi17DnHDlC//79efbZZ8nK\nyuK9f/+b75OTOV1ZaYlhbJkzZw67du1io9EwTG9zjMMYRXdElpaSr+96vrpXL8uGKsD9wilYhL1r\nba2lsuvSSy9lQkwM22mijcC558qdtD7GG1UxAngH2K1p2outP6Tms3z5ctYY/T2ysuRw4H79SP30\nU+pNJgo3bOC9994DpGMfOXKk1Qn7y7Gfc441VnEQ9kGDBhEcHGwv7IYzdMjZd+7cSS/DubTCsVdU\nVNi5yg2GEOkbky7Mz+cfwA9AtC83cDWHWbPkZW0T0UVMTIydsGua1vwoBmT/mX794Jtv5BvSA5ob\nxXgi7IZj9yRnd6qIMbBt3WtEMY04doAu55zD5IEDuf322y23jR07luDgYNdxzNKl7DCZCD5wANav\nh88/hzffhPvvJ/Sii5hw+eX8IASao7AfOQKJiRw+fJi+ffsya9YsxowZw9NPP81nn31GaGioS7G8\n/vrriYqKYt68efKGiRPl1dyDD8orrSaILi9nd3Q09OzJ7J492bx5s9zUd+oUHDzYpLAngHWATk0N\nSRUVVCYnc5XjRr4A4A3HPh64GbhICPGz/m+6Fx7XY1577TXMPXuiRUXJwcBbt8pBxRERmAYM4Lyu\nXbnvvvvYtGkTe/fulQunxpuksd7b3sS2MZaDsIeGhjJo0CB+1mvJAfmm69PHSdh37drFoNhYWaZp\nZIrNxBAT25x9TUkJ9SaTFPYPPiDuwQfZbDZzGTCorTh2D4mJibHL2CsrK6k3pic1h0suka+TZpzY\nmhvFxHrwN4yNjSUmJsYjx+5W2G1b93rq2BMTCdZ74BtEREQwYsQIJ2GvPXaM5Px8sgYNchvb/eIX\nv+CbmhpEVpYs/TXIyaGhd2+OHj1Knz59EELw17/+ldzcXN58800mTpxoNwLRICoqiltuuYXFixfL\nltMhIXJdbcYMuOce2eSuEWKrqzkdFQXjx5NSVITZbJaLqMb70N3J3EbYLXsx9u5F1NYy+09/IiHB\n/7UjjnijKmadpmlC07RzNE0bpv/7uunv9A5ZWVl8++233H3PPYiUFPlGHDLE0t5UpKQwvmtXIiMj\nufTSS+XCqeHYe/WyjAbzOQMHSjEGJ2EHGDZsmOvWAi6imOSoKPkYHvTldoUhJoawV1VVUVRWRmGP\nHrLp0S23IC68kBcnT+Y0cHY7E/bo6Gg7x+5JOwFv4YsoRgjhcWVMVlYWISEhzqP9HB27zVg8tyQm\nypOAQ6w1YcIENm3aRFVVleW2vS++SBAQa3RBdMHQoUOxeHVjOHltLRw7Rkl0NA0NDfTVS0knTpzI\n1KlT0TTNZQxjcO+991JTU2ONUcLC5KSp2bPlXFiHecQWKiuJrq+nsnNnGD+eoJwc5kydyvvvv0+d\n0U7DnWMPD6ciLIw+JhO9jU2CxgZDL+z38AbtfufpvHnzMJvN3HHHHdYdqM8+a82xUlIwHz7MB++/\nbxEyv5Y6GoSEWOMVm3JHg6FDh3L06FGKbYdyGL3i9UXN6upqsrOzSQwObnEMA1bHbuTsRpXSidRU\nubg7eTJ89RXjJk8mKiqKgV6oiPEnjlGMJ50dvYUvhB1kzu6pY09OTnZekLUVdqMBWFMlp8b746mn\nZGauM2HCBGpqauzaTtR++im5QjC2kaZu/fv3Z6cQlIeHW3N2fSJVgd7qoa/NHoHnn3+eUaNGMXv2\nbLePOXjwYCZNmsT8+fOtVWUhIXJG6Q03yFhW3y9gh17qWBsXZ2n9fHdaGsePHyf/m2+k6XPxPjUo\nCgkhJTLSUtLJ9u3y5zZSCutP2rWwnz59mnfffZerr75a1gLfcoucjqMv9ACyj0x5OVPS0vjLX/7C\nlClT5GAHfws7WOMYF47d5QLquefKulzdte/bt4/6+nri6+tbJeyGY3cU9mNXXy1Hxi1bBhERPPjg\ng2RlZRFpVFW0ExyjGH86dl9k7CBz9oMHD7reIWmDU0WMgaNjbyJfB2Skce+9Mt4cMcIikEbDMiOO\nqS0pYeDhw+xMTia8iVLQvv36kRkXJ4XdaCUAHNFPMrbCnpaWxqZNm6yu2A333XcfOTk5fPXVV9Yb\ng4Ot4w9d7OBu0IsE6rt1k848PJy0sjLCwsII2r7dvVvXOdLQQB/bk+e2bfIKO0DdHB1p18K+aNEi\nSktLuf/+++UNl10m60ZtnYhNg7DHHntMDo+urJQDif0t7NddB9de6/IS2KWwGz3idWdkdLSL8mS4\nbyM4RjHGgI3I4cPl2oS+sSU4OLhF814DjWMU40nLXm/hacZeX19PaWmpRxk7SLdbXV1tmTrl7jGz\ns7ObFnY3DcCcMJvh9dflsImSEhg7Fp55hrjYWM4++2zLRqWd//wnEUDkTTc1+ZApKSl8J4QU9AMH\nLDXs+/QrgkQ3A0waY9asWSQkJPD666/bf8GIo1x0fa3UYy1htAoePZrgjRu5aOxYuh0/3qiwNzQ0\nkF1ZSTfbk/f27fbNwgJMuxX24uJi/vCHP3Deeec1viXbEHbbGnHjktZfpY4GM2fKS0QXdO3alZ49\ne9oLe0qKrADRM7+dO3cSJATBJ054NYoxhL1bI5ee7Yn2EMUYx9ccxw6NV8YcOXKE6upq98JulPi6\nmHfaKFOmyD0Y11wjXfDLLzNhwgQ2bNggB6N/+CEngREPPdTkQ6WmpvKp0fZj9WrrrtOSErp3796i\noc/BwcHcddddrFixwrJ4DEgD1b27tcePDcYmP7Mh/uedB1u3ckNyMkHAqUZM39GjR8mpryeqokJW\nuhUVyRYEbSRfh3Ys7HPnzuXUqVPMnz+/8e3piYnyjGwr7P4udfQQp9YCJpN07bqwb9myhXGpqQgv\nRTGOjr0jCXtZWZkltmiLUYzx3DcnY4fGa9ndVsRAyxy7LbGxcvfkrFnw2GPMTEqirKyMjI0bOSs7\nmx1JSYR78PympKSwtaKC+h49pLAfOQJdurDv6FG7GKa53HHHHZjNZmvpo0Hfvi4de21ODvVAqBHz\njB8PdXVcqp9o1hqVQy7Izs4mDzBpmuw+2cYWTqGdCvvq1av517/+xSOPPMI5TT2ZwcHSmbcDYR82\nbBi7du2yqzZg1Cj5wqmqIiMjgwuMN20TA6AbIywsjNDQUDvHHhYW5rZpWHvDcOZl+pszEI69qSim\nucJuiF5jjt3YVe2yism23LG5jt1ACHj7bejShckLFxIGfPbb3xKnaYTaDqNoBOOkU5yWJoVdH1xi\n1LC3lB49enDVVVfx3nvvcdp2oEhSkkvH3nD0KIVArLGpadw4ALp89x0nhWCZY4WaDfv27cNSrJmX\np4TdG1RWVnLXXXcxYMAAnnrqKc++KSXFWdijo90ONQ4UY8aMoba21r6effRoqKujeOVK8vPzGWk4\njFZm37ZtBQoLC+natWvzG3O1URzbChjCHtVcl9oCgoKCEEI06diN597TjD0sLIyEhIRGHfv69esZ\nPHgwXVyNeWytYzeIj4f33sOclcW8qCi6//QTVUCah22YjQ09exMSZA+nH35AS0wkJyenVcIOcNtt\nt1FSUmJfY9+3rxR2h0VnUVDAMWxOrF26wKBBiNpacuPiWOWuEyXSsRcapcuGsPfo0WgVjb9pd8L+\n7LPPkp2dzRtvvOF5/5KUFNly1fjjHjggXXwbE7Ix+kaYn376yXqjPgQkX28hO9h403pB2A3XWFRU\n1GFiGHBuBFZSUkJ4eLjf5k+azWavRzHQeJfHhoYGNmzY4DxizyAyUpYs1te7nHfaLKZOhQcfZE5Z\nGbcBu3r1ItzD/k99+/bFbDazwcjST5+mMj6e6urqVgv7iBEjAOtISEA69poa64AbHXNxMfk4nFj1\n567unHM4ePCg2+c6Ozsbc1KS/MQQ9jbk1qGdCfuOHTv429/+xi233MJkN/24XZKSYq2EgcCUOnpA\nz5496dOnj72w9+oFvXrR8NNPCCFIMt4QrRR2234xhYWFHVLYbR27P2IYg5CQEJ8Ie2O17Lt37+bU\nqVONCzvIjpWeljs2xl//yolevYgBmbt7SFBQEAMGDGBTQYGleKFYP7bWCntsbCwJCQns2LHDeqPx\nmA45e+jJk/aOHSz17N2mTgVg1apVLn/Ovn37iD/rLFm3fvgw7NyphL01/O1vfyMmJoYXXnihed9o\nOxO1vl5WxbRBYQfZi8NO2AFGjybuwAEGDhwoO9JFRFjHnbUQW8fe0YTdVRTjj4VTA7PZ3GTG3two\nBqRjz8vLczkY2u1QbAND2IuK3I7Faxbh4UQsW8ahYcMY+qc/NetbU1NTZSdTvcf/UX2Tj9Nu2RYw\nZMgQZ8cO9jl7fT0RZWXk4xDPzZoFt91Gr1/9il69erkUdk3TyM7OJjklRZqu776TnT+VsLect956\nixUrVhBvLHh4im3JY16evDTzd6mjh4wdO5bDhw9zzGhqBjB6NAnl5UwYMsQyA7K1MZLh2DVN63DC\n7ujYm93ZsZV4GsWYTKZmLVgnJyejaRq7XAxgWb9+Pd26dbNOTXLEEHbjdeWF9YawESNI2rqVoGa+\nH1NSUsjOzqZBF/Zsve1uax07yE1Nu3fvtg6YduXYi4sJ0jRKwsOtO0dB5uzvvIOIi+Piiy9m1apV\nThvCjh07RmVlpewRk5Bg7dvehmrYoZ0Je1hYGMOb2BHmksRE2YZ13z5r86827NgBaytS4KTeKmFK\nly5WYW8lxuLp6dOnqaqq6pDCbmTsbTWK6dy5c7MWrKdMmYLJZJJDKBxYv34948ePd/94jsLuxxOd\nIykpKVRVVZE7bhysWMEmTSM6OrpZsZQ7hgwZYmm9Acgr27g4e8eub/I63cjJ7eKLL6a4uNje/WMd\nFJ6SkmJpBkZwcJN9+v1NuxL2FmMySSHft6/NljoaDB8+HLPZbBfHpOsfR9TXyxdlK0odDWJjYykp\nKbGMFvPF8JNA4RjFBMKxe1Lu2Fwh69atGxdddBGLFy+2DpcA8vPzOXDggPuh2GCN7oydq36oEHKH\nUfK4b/9+mDyZw16oiDFI09t2OOXsto5dP7lVNvL8X6xPzHKMY4wThsWxg+zpZAzebiOcGcIOskGY\nIXsDOC0AABVFSURBVOzBwdLFt0GMqxJbYd+4dy97gN75+V5z7J07d6ahoYH9+omuIzn2yMhIgoKC\nArZ46kkU42nLXkeuueYasrOz2WrM5ES6dWgkX4c259jBuqGqtTXstgwaNAiTyeScs7tw7HWNREi9\ne/cmNTXVpbCbzWa5HmAIexvL1+FMEvaUFCnq+/bJM7hRh9oGGTt2rBwkreeEGRkZ7I2KwrxpExw/\n7rUoBqxvro4k7EIIoqOj7aIYfzr25kQxzeXKK68kODiYxYsXW25bt25d0zGlIextwLH36tWLiIgI\nS6xx+PBhryycAoSHh5OcnOzs2A8ftg61109u9U1cpU6ePJk1a9bYXX3t27eP/v37y+6ZhrC3sXwd\nzjRhr6qCtWvbbAxjMHbsWCoqKiwvzi1btnAyJUVWNIDXHDvA3r17gY4l7GBtBNbQ0BCQqhhfCXtc\nXByTJ0/mk08+scQx69evZ/To0ZZ2Bi5pQ47dZDKRnJxMVlYWpaWlnDp1ymuOHdxUxlRUyMH2AMeO\nUSoEkR4Ie3l5OY8//rhF3LOzs63DNYx21m1lwpgN3pp5eqkQYq8QIlsI8Zg3HtPrGJUxBQXtQthB\nLqAWFxeTk5ODWa+xBbzq2A1h70gZO1gbgZWXl6Npmt+jGE/KHVu6WHjttddy6NAhNm/eTEVFBVu3\nbm08hgGfVMW0BqPk8bAekXhT2NPS0sjOzqayshL9weVHI47Jz3euYXfB5Zdfzh133MGLL77I+PHj\n2bdvH9nZ2dZxeMOHy1GcF1zgtWP3Ft6YeRoEvA5MAwYD1wshBrf2cb2O8ceANi/sSUlJdOvWjZ9+\n+okMvQd2wmWXWeMjL0cxUVFRLeqq15YxerL7s2WvgaeOvSUZO8AVV1yB2Wxm8eLFbNq0ibq6usYX\nTqFNRTEgc/YDBw5Ydnd627HblYUatez6AmpDXh5HNa3J5z84OJgFCxbwn//8h/379zN06FDKy8ut\njl3+Il47bm/iDcc+GsjWNO2Apmk1wMeA51vR/EVCgqXPeFutYTcQQlg2Km3R62SHjR1rzfK8GMXk\n5OR0uBgGrFGMPzs7GjSVsVdXV1NZWdlix965c2emTp3KJ598YumLMk5vYuUWQ9gLC2WVWCMDMfxB\namoqdXV1lp7u3nbsYFMZ4+DYG44edW4n0AizZ89m27ZtlpYfabbzi9so3hD2BOCIzee5+m1tC5PJ\nOjqvjTt2kH1j9uzZw8qVKxkwYIAUAb1vjDeaDdm+qDuisBtRjD87Oxo0FcU0txe7K6699lpyc3OZ\nP38+Z599dtMiZTbLfw0N0q0HuE+SEWesWLGCkJAQOdXMSwwYMIDQ0FCrsHfuLOca6I7dVFjoURRj\nS2JiIitXrmTr1q1c0AajF0f8tngqhLhTCJEuhEg3RrH5HeOyqY07drDm7KtXr+ZcY1r6I4/AokXW\nK49WEBUVZdnM0lGFvbS0NCCOvakoxmgn0BphnzlzJqGhoRw7dqzpfN3AqGUP4MKpgVHLnpmZSWJi\nov0O0FYSHBzM4MGD7RdQjcqYsjJMFRUco3ntHED2uRk2bJjXjtOXeOPZzANsi8J767fZoWnaAk3T\nRmqaNjJgC3VTpsDEia3us+IPRo0aZRFeo2sd/frBzTd75fFNJpNFWDqisDtGMW1p56nRo6elGTvI\n32/69OlAE/XrthhxTIDzdYD4+HjL38SbMYzBkCFD7Esek5KkY9fXGPJp3Ym1reMNYd8MpAgh+gkh\nQoDrgGVeeFzvc/fdsmlPOyAqKoohQ4YANsLuZTqysMfExFBbW2uZDtWWdp62pLOjK26//XYiIiK4\nSO+50iSGsLcBxy6EsMQxvhD2tLQ08vLyLFdHFseuVwW1xLG3J1ot7Jqm1QH3A98Cu4FPNE3b2drH\nVVjjmBb1x/EA44Xd0UodwerQj+jDkttSFOMtYZ8+fTolJSX0NoavNEUbcuxgjWN85djBZgE1KUm2\nK969G6DZGXt7wyvbLzVN+xr42huPpbDyyCOPMHbsWOJ8NOnJEPaO6tjBKuz+mJ5k4GnG7g3HGNyc\nHdRtyLEDPnfsIDP8CRMmWCtj9FYdHT2Kabv76hWkpKRYN0P4gI4cxRgO/ciRI3Tq1EluAfcTnmbs\nfheWNurYvdVOwJaEhARiYmLsHTvATz9RFxREpdlMaGio139uW+HMaSmgcOJMcez+jGHAs4w9JCTE\n/5vC2phjnzlzJs8880zTm6tagBCCtLQ0a2WM4dj37KEkLIxYV3NhOxBK2M9gOrJjN4Q9Ly/PrxUx\n4FkU09xe7F7BqAZrI469U6dO/O53v2u8x00rMCpjNE2TPdn1E9vxkJAOHcOAEvYzmiFDhtCrVy+f\nZfiBxHDpdXV1fnfsnkQxAanIaGOO3dekpaVx6tQp8vLy5IYs3bUXBQV16IoYUMJ+RnPrrbeSm5vb\nvAW4doKtSw+EY28qigmIY2xjGbuvMSpjLHGMnrMf0zTl2BUdG7/HAX7C1qUHImNvaGhwmpdpoITd\nP9hWxgAWx55bX68cu0LRHgkODiZCb3QVCGEH3MYxrWnZ2yrOsCgmNjaWhIQEJ8d+qLpaOXaFor1i\nRDD+jmKMxUB3wh7wjP0MceyAy8qYg5WVyrErFO0VQ9AD5dhd5eyapgU+ijlDHDtIYd+9e7c8yU6Y\nQO2ECfxEx96cBErYFR0YQ9DbUhRTUVFBbW1tYIRl9GgYN67NDofwBWlpadTU1Mj5qr16kbdoEYV0\n7D4xoIRd0YFpi1FMwHadApx1FmzYcMY5drAuoHqznUNbRgm7osPSFqMYb7TsVXjOoEGDCAoKsgh7\nQE+sfkQJu6LDYgh6IOrYoQ069jOQ0NBQUlNTlWNXKDoKgXLsjUUx3piepGgetpUxZ8qJVQm7osMS\n6ChGOfa2QVpaGgcPHqSsrEw5doWivROoxVOVsbctjAXUnTt3cvLkSUwmE53awXjM1tDxmoQoFDrX\nXnstQgh69erl15/bmGM3HKO/TzZnMraVMcYeAm8Oz26LtOq3E0I8L4TYI4TYLoRYKoRQ15eKNkPP\nnj359a9/7fd+OE2VO0ZERPisVa3CmaSkJCIjI8nMzAxcOwc/09rT1gpgiKZp5wBZwOOtPySFon3T\nVBSjYhj/YjKZGDJkiMWxnwnPf6uEXdO0/+nDrAF+AjycqqtQdFyaWjw9ExxjW8OojFGOvfncBiz3\n4uMpFO2SpsodzwRhaWukpaVx/Phx9uzZc0Y49iYXT4UQK4EeLr70pKZpX+j3eRKoAz5s5HHuBO4E\n3wyvVSjaCk05dn8v5iqsC6hnyom1SWHXNG1yY18XQvwSmAFcrGma1sjjLAAWAIwcOdLt/RSK9k5T\nGfvZZ5/t70M64zGEHc6MUtPWVsVcCjwKzNQ0rcI7h6RQtG9Uxt72iI+Pp0cPGTycCc9/azP214Ao\nYIUQ4mchxBteOCaFol3jLmNvaGhQwh5ADNd+Jjj2Vm1Q0jQt2VsHolB0FNxFMWVlZWhnwCDltso5\n55zDihUrzghh79jbrxSKAOAuilHtBAKL4djPhBOrEnaFwsu4i2JUZ8fAMnXqVGbMmMHIkSMDfSg+\nR/WKUSi8TFOOXQl7YOjRowdffvlloA/DLyjHrlB4meBg6ZccM3Yl7Ap/oYRdofAyQgiCg4OVY1cE\nDCXsCoUPCAkJcRL20tJSwP+DPxRnHkrYFQofYDabXZY7AkRFRQXikBRnEErYFQofYDabnRx7WVkZ\nZrOZ0NDQAB2V4kxBCbtC4QNcRTFlZWUqhlH4BSXsCoUPcBXFlJaWqhhG4ReUsCsUPsBdFKOEXeEP\nlLArFD5ACbsikChhVyh8gMrYFYFECbtC4QNUxq4IJErYFQofoKIYRSBRwq5Q+AB3UYwSdoU/8Iqw\nCyF+K4TQhBDx3ng8haK94xjFNDQ0cPr0aZWxK/xCq4VdCJEITAFyWn84CkXHwDGKKS8vR9M05dgV\nfsEbjv0l5EBrzQuPpVB0CByjGNUnRuFPWiXsQohZQJ6madu8dDwKRYfA0bErYVf4kyYnKAkhVgI9\nXHzpSeAJZAzTJEKIO4E7Afr06dOMQ1Qo2h+OGbsh7CpjV/iDJoVd07TJrm4XQqQB/YBtQgiA3sAW\nIcRoTdPyXTzOAmABwMiRI1Vso+jQODp2oxe7cuwKf9DimaeapmUC3YzPhRCHgJGaphV74bgUinaN\nytgVgUTVsSsUPsBdFKOEXeEPWuzYHdE0Lclbj6VQtHfcLZ6qjF3hD5RjVyh8gGMUozJ2hT9Rwq5Q\n+ABXjt1kMhERERHAo1KcKShhVyh8gCHsmiYLwMrKyujUqRN6BZlC4VOUsCsUPsBsNgNQV1cHqF7s\nCv+ihF2h8AEhISEAljhGdXZU+BMl7AqFDzAcu1HyqIZsKPyJEnaFwgcYwq4cuyIQKGFXKHyAqyhG\nZewKf6GEXaHwAcqxKwKJEnaFwgeojF0RSJSwKxQ+wNaxa5qmHLvCryhhVyh8gG3GXl1dTV1dncrY\nFX5DCbtC4QNsoxjV2VHhb5SwKxQ+wDaKUQ3AFP5GCbtC4QNsoxjl2BX+Rgm7QuEDbB276sWu8Dde\nG7ShUCis2GbsRsmjcuwKf9Fqxy6EeEAIsUcIsVMI8XdvHJRC0d6xjWJUxq7wN61y7EKIScAsYKim\nadVCiG5NfY9CcSbgKopRwq7wF6117PcAf9U0rRpA07TC1h+SQtH+cVXuqDJ2hb9orbCnAhOEEBuF\nEGuEEKO8cVAKRXvHlWPv1KlTIA9JcQbRZBQjhFgJ9HDxpSf17+8CjAVGAZ8IIfprxjww+8e5E7gT\noE+fPq05ZoWizeOYsUdERBAUFBTgo1KcKTQp7JqmTXb3NSHEPcBnupBvEkI0APFAkYvHWQAsABg5\ncqST8CsUHQnHKEbl6wp/0too5nNgEoAQIhUIAYpbe1CK/2/v7mLkquswjn+fpTO+VNOCEGwstVgI\npBeywKaCEl+KmrIxXBkjkaQXxN5w0RoTQ7MJCZcao/bCmDRQjYlBA/hCeiFC5UYTi1soulBKMdZQ\n3hbbEpK6iujPi/OfOE7WLtuzZ/7/c3g+yWTPOTPdfTJn99n//HZmam03OorxfN3Gqe7z2PcB+yTN\nAW8A2xcbw5i93Yy+8tQrdhunWsUeEW8At65QFrPOGH2vGBe7jZPfUsCsAZ6xW04udrMGTExMMDEx\n4Rm7ZeFiN2tIv9/3jN2ycLGbNaTX63kUY1m42M0a0uv1WFhYYGFhwcVuY+ViN2tIv9/n9OnTgN8n\nxsbLxW7WkF6vx8mTJwG/s6ONl4vdrCEudsvFxW7WkF6vx6lTpwCPYmy8XOxmDen3+16xWxYudrOG\n9Ho9zpw5A7jYbbxc7GYNGbytALjYbbxc7GYNGbzDI3jGbuPlYjdriFfslouL3awhg2Lv9/v/s3o3\na5qL3awhg2L3at3GzcVu1pDBKt3zdRu3WsUuaVLS7yQdljQractKBTNrO6/YLZe6K/ZvAHdFxCRw\nZ9o3M1zslk/dYg9g8DhzDfBizc9n1hmDUYyL3cat1n9mDewCHpL0TapfEh/9fzeUtAPYAbBhw4aa\nX9asfIMVu2fsNm5LFrukR4D3L3LVDHAj8JWIeEDSF4B7gE8v9nkiYi+wF2BqairOObFZS3gUY7ks\nWewRsWhRA0j6IbAz7d4H3L1Cucxaz6MYy6XujP1F4BNpeytwrObnM+sMr9gtl7oz9i8DeyStAv5O\nmqGbmWfslk+tYo+I3wDXrlAWs07xit1y8StPzRriGbvl4mI3a4hX7JaLi92sIZ6xWy4udrOGeBRj\nubjYzRriUYzl4mI3a8j09DQzMzNs2rQpdxR7m1HE+F/dPzU1FbOzs2P/umZmbSbpUERMLXU7r9jN\nzDrGxW5m1jEudjOzjnGxm5l1jIvdzKxjXOxmZh3jYjcz6xgXu5lZx2R5gZKkV4G/nOM/vxD46wrG\nWWnOV4/z1eN89ZWc8YMRcdFSN8pS7HVImn0rr7zKxfnqcb56nK++NmRcikcxZmYd42I3M+uYNhb7\n3twBluB89ThfPc5XXxsynlXrZuxmZnZ2bVyxm5nZWbSq2CVtk3RU0nOS7iggzz5J85Lmho5dIOlh\nScfSx/Mz5rtE0qOSnpb0lKSdJWWU9E5Jj0l6MuW7Kx2/VNLBdJ5/IqmfI99QzvMkPSFpf2n5JB2X\n9EdJhyXNpmNFnN+UZa2k+yU9I+mIpOtLySfpinS/DS6vS9pVSr46WlPsks4DvgvcBGwGbpG0OW8q\nfgBsGzl2B3AgIi4HDqT9XN4EvhoRm4HrgNvTfVZKxn8AWyPiKmAS2CbpOuDrwLcj4jLgNHBbpnwD\nO4EjQ/ul5ftUREwOPUWvlPMLsAf4ZURcCVxFdT8WkS8ijqb7bRK4Fvgb8LNS8tUSEa24ANcDDw3t\n7wZ2F5BrIzA3tH8UWJe21wFHc2ccyvYL4DMlZgTeDTwOfITqxSGrFjvvGXKtp/rh3grsB1RYvuPA\nhSPHiji/wBrgz6S/5ZWWbyTTZ4HflppvuZfWrNiBDwDPD+2fSMdKc3FEvJS2XwYuzhlmQNJG4Grg\nIAVlTGOOw8A88DDwJ+C1iHgz3ST3ef4O8DXg32n/fZSVL4BfSTokaUc6Vsr5vRR4Ffh+GmXdLWl1\nQfmGfRG4N22XmG9Z2lTsrRPVr/zsTzuS9B7gAWBXRLw+fF3ujBHxr6geCq8HtgBX5soyStLngPmI\nOJQ7y1ncEBHXUI0ob5f08eErM5/fVcA1wPci4mrgDCNjjdzffwDpbyQ3A/eNXldCvnPRpmJ/Abhk\naH99OlaaVyStA0gf53OGkdSjKvUfRcRP0+GiMgJExGvAo1SjjbWSVqWrcp7njwE3SzoO/JhqHLOH\ncvIRES+kj/NU8+EtlHN+TwAnIuJg2r+fquhLyTdwE/B4RLyS9kvLt2xtKvbfA5enZyT0qR46PZg5\n02IeBLan7e1Uc+0sJAm4BzgSEd8auqqIjJIukrQ2bb+Lav5/hKrgP587X0Tsjoj1EbGR6vvt1xHx\npVLySVot6b2Dbao58RyFnN+IeBl4XtIV6dCNwNMUkm/ILfx3DAPl5Vu+3EP+Zf6BYxp4lmoOO1NA\nnnuBl4B/Uq1ObqOawR4AjgGPABdkzHcD1cPIPwCH02W6lIzAh4EnUr454M50/EPAY8BzVA+P31HA\nuf4ksL+kfCnHk+ny1OBnopTzm7JMArPpHP8cOL+wfKuBk8CaoWPF5DvXi195ambWMW0axZiZ2Vvg\nYjcz6xgXu5lZx7jYzcw6xsVuZtYxLnYzs45xsZuZdYyL3cysY/4D9lysbqSFY3oAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd427dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.4888141273 \n",
      "Updating scheme MAE:  1.64688032866\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
