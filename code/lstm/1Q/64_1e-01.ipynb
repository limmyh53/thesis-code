{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Directories\n",
    "MODEL_FOLDER = \"../../../models/lstm/\"\n",
    "MODEL_FILENAME = MODEL_FOLDER + \"1Q/64_units/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: model saver\n",
    "def saveModel(sess, MODEL_FILENAME):\n",
    "    if not os.path.exists(MODEL_FOLDER):\n",
    "        print('Creating path where to save model: ' + MODEL_FOLDER)\n",
    "        os.mkdir(MODEL_FOLDER)\n",
    "\n",
    "    #print('Saving model at: ' + MODEL_FILENAME)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, MODEL_FILENAME)\n",
    "    #print('Model successfully saved.\\n')\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: model loader\n",
    "def loadModel(sess, MODEL_FILENAME):\n",
    "    if os.path.exists(MODEL_FILENAME + \".index\"):\n",
    "        print('Loading save model from: ' + MODEL_FILENAME)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, MODEL_FILENAME)\n",
    "        print('Model successfully loaded.\\n')\n",
    "        return True\n",
    "    else:\n",
    "        print('Model file <<' + MODEL_FILENAME + '>> does not exists!')\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Hyperparameters\n",
    "epochs = 500\n",
    "learning_rate = 1e-1\n",
    "batch_size = 5\n",
    "early_stop_iters = 10\n",
    "folds = 32\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 3  # data input\n",
    "n_steps = 4  # timesteps\n",
    "n_hidden = 64 # dimension of recurrent unit\n",
    "\n",
    "# (REPRODUCIBILITY) set random seeds\n",
    "tf.set_random_seed(123)\n",
    "\n",
    "# Define weights and biases\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden, 1], stddev = 1.0 / tf.sqrt(float(n_hidden))),\n",
    "        name='out_weight')\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.zeros([1]),\n",
    "        name='out_bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Helper fct: Build model\n",
    "def RNN(X, weights, biases, n_hidden):\n",
    "\n",
    "    # Define a LSTM cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)\n",
    "    outputs, _ = tf.nn.dynamic_rnn(lstm_cell, X, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    out_layer = tf.matmul(outputs[:,-1,:], weights['out']) + biases['out']\n",
    "\n",
    "    return out_layer\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Helper fct: select batch\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n",
      "Finished: data loaded. Stats below: \n",
      "Nr of training samples: 193\n",
      "Nr of testing  samples: 77\n",
      "Number of variables: 3\n",
      "Number of lags: 4\n",
      "Window length: 65\n",
      "Number of validation folds: 32\n"
     ]
    }
   ],
   "source": [
    "# =================================\n",
    "# 0. Load dataset\n",
    "# =================================\n",
    "print(\"Loading the data...\")\n",
    "# Training set pre-processing\n",
    "train = pd.read_csv('../../../Data/train.csv')\n",
    "train_4lag_inflation = np.array(train[['inflation.lag1',\n",
    "                                       'inflation.lag2',\n",
    "                                       'inflation.lag3',\n",
    "                                       'inflation.lag4']])\n",
    "train_4lag_unemp = np.array(train[['unemp.lag1',\n",
    "                                   'unemp.lag2',\n",
    "                                   'unemp.lag3',\n",
    "                                   'unemp.lag4']])\n",
    "train_4lag_oil = np.array(train[['oil.lag1',\n",
    "                                 'oil.lag2',\n",
    "                                 'oil.lag3',\n",
    "                                 'oil.lag4']])\n",
    "train_features = np.concatenate((train_4lag_inflation[:,:,np.newaxis], \n",
    "\t                             train_4lag_unemp[:,:,np.newaxis],\n",
    "\t                             train_4lag_oil[:,:,np.newaxis]),\n",
    "\t                             axis=2)\n",
    "train_target = np.array(train['inflation.target'])\n",
    "\n",
    "# Test set pre-processing\n",
    "test = pd.read_csv('../../../Data/test.csv')\n",
    "test_4lag_inflation = np.array(test[['inflation.lag1',\n",
    "                                     'inflation.lag2',\n",
    "                                     'inflation.lag3',\n",
    "                                     'inflation.lag4']])\n",
    "test_4lag_unemp = np.array(test[['unemp.lag1',\n",
    "                                 'unemp.lag2',\n",
    "                                 'unemp.lag3',\n",
    "                                 'unemp.lag4']])\n",
    "test_4lag_oil = np.array(test[['oil.lag1',\n",
    "                               'oil.lag2',\n",
    "                               'oil.lag3',\n",
    "                               'oil.lag4']])\n",
    "test_features = np.concatenate((test_4lag_inflation[:,:,np.newaxis], \n",
    "\t                            test_4lag_unemp[:,:,np.newaxis],\n",
    "\t                            test_4lag_oil[:,:,np.newaxis]),\n",
    "\t                            axis=2)\n",
    "test_target = np.array(test['inflation.target'])\n",
    "\n",
    "(nrTrainSamples, timesteps, variables) = train_features.shape\n",
    "(nrTestSamples, _, _) = test_features.shape\n",
    "\n",
    "# Window length and validation fold index\n",
    "window_length = 65\n",
    "valIndex = np.linspace(start=window_length, stop=nrTrainSamples, \n",
    "                       endpoint=True, num=folds+1, dtype=np.int)\n",
    "\n",
    "print(\"Finished: data loaded. Stats below: \")\n",
    "print(\"Nr of training samples: %d\" % nrTrainSamples)\n",
    "print(\"Nr of testing  samples: %d\" % nrTestSamples)\n",
    "print(\"Number of variables: %d\" % variables)\n",
    "print(\"Number of lags: %d\" % timesteps)\n",
    "print(\"Window length: %d\" % window_length)\n",
    "print(\"Number of validation folds: %d\" % folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# 1. Build model\n",
    "# ==================================\n",
    "# tf graph input\n",
    "x = tf.placeholder(\"float\", [None, n_steps, n_input], name='Batch')\n",
    "y = tf.placeholder(\"float\", name='True_labels_of_batch')\n",
    "lr = tf.placeholder(\"float\", name='Learning_rate')\n",
    "\n",
    "# Make predictions with the model\n",
    "pred = RNN(x, weights, biases, n_hidden)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss = tf.reduce_mean(tf.diag_part(tf.square(tf.subtract(x=pred, y=y))))\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training \n",
      "Hyperparameters: \n",
      "Dimension of recurrent unit = 64 \n",
      "Learning rate = 0.1 \n",
      "Epochs = 500 \n",
      "Batch size = 5 \n",
      "Early stopping epochs = 10 \n",
      "Learning rate = 0.1\n",
      "Fold: 1  Epoch: 1  Training loss = 2.8565  Validation loss = 0.4434  \n",
      "\n",
      "Fold: 1  Epoch: 2  Training loss = 4.1579  Validation loss = 2.3253  \n",
      "\n",
      "Fold: 1  Epoch: 3  Training loss = 2.4032  Validation loss = 1.4061  \n",
      "\n",
      "Fold: 1  Epoch: 4  Training loss = 2.2496  Validation loss = 1.9224  \n",
      "\n",
      "Fold: 1  Epoch: 5  Training loss = 2.0370  Validation loss = 1.5304  \n",
      "\n",
      "Fold: 1  Epoch: 6  Training loss = 2.0049  Validation loss = 0.7365  \n",
      "\n",
      "Fold: 1  Epoch: 7  Training loss = 1.6175  Validation loss = 1.5666  \n",
      "\n",
      "Fold: 1  Epoch: 8  Training loss = 1.7153  Validation loss = 1.1507  \n",
      "\n",
      "Fold: 1  Epoch: 9  Training loss = 1.9641  Validation loss = 0.6502  \n",
      "\n",
      "Fold: 1  Epoch: 10  Training loss = 1.8374  Validation loss = 1.7239  \n",
      "\n",
      "Fold: 1  Epoch: 11  Training loss = 1.9262  Validation loss = 1.7577  \n",
      "\n",
      "Fold: 1  Epoch: 12  Training loss = 1.5355  Validation loss = 2.4163  \n",
      "\n",
      "Check model:  Fold: 1  Optimal epoch: 1  \n",
      "\n",
      "Fold: 2  Epoch: 1  Training loss = 1.4416  Validation loss = 1.7983  \n",
      "\n",
      "Fold: 2  Epoch: 2  Training loss = 1.4343  Validation loss = 2.0727  \n",
      "\n",
      "Fold: 2  Epoch: 3  Training loss = 1.7400  Validation loss = 1.9718  \n",
      "\n",
      "Fold: 2  Epoch: 4  Training loss = 1.3322  Validation loss = 1.8938  \n",
      "\n",
      "Fold: 2  Epoch: 5  Training loss = 1.4296  Validation loss = 2.2615  \n",
      "\n",
      "Fold: 2  Epoch: 6  Training loss = 1.4731  Validation loss = 1.7831  \n",
      "\n",
      "Fold: 2  Epoch: 7  Training loss = 1.3801  Validation loss = 1.8774  \n",
      "\n",
      "Fold: 2  Epoch: 8  Training loss = 1.4061  Validation loss = 1.5444  \n",
      "\n",
      "Fold: 2  Epoch: 9  Training loss = 1.3667  Validation loss = 1.6173  \n",
      "\n",
      "Fold: 2  Epoch: 10  Training loss = 1.3296  Validation loss = 1.6588  \n",
      "\n",
      "Fold: 2  Epoch: 11  Training loss = 1.5481  Validation loss = 2.0904  \n",
      "\n",
      "Fold: 2  Epoch: 12  Training loss = 1.5006  Validation loss = 1.4425  \n",
      "\n",
      "Fold: 2  Epoch: 13  Training loss = 1.3691  Validation loss = 2.1557  \n",
      "\n",
      "Fold: 2  Epoch: 14  Training loss = 1.2042  Validation loss = 1.7399  \n",
      "\n",
      "Fold: 2  Epoch: 15  Training loss = 1.2380  Validation loss = 1.7482  \n",
      "\n",
      "Fold: 2  Epoch: 16  Training loss = 1.3274  Validation loss = 1.5467  \n",
      "\n",
      "Fold: 2  Epoch: 17  Training loss = 1.3170  Validation loss = 1.8717  \n",
      "\n",
      "Fold: 2  Epoch: 18  Training loss = 1.2155  Validation loss = 1.8093  \n",
      "\n",
      "Fold: 2  Epoch: 19  Training loss = 1.2546  Validation loss = 1.9749  \n",
      "\n",
      "Fold: 2  Epoch: 20  Training loss = 1.1729  Validation loss = 1.9345  \n",
      "\n",
      "Fold: 2  Epoch: 21  Training loss = 1.1912  Validation loss = 2.0814  \n",
      "\n",
      "Fold: 2  Epoch: 22  Training loss = 1.1765  Validation loss = 1.9647  \n",
      "\n",
      "Fold: 2  Epoch: 23  Training loss = 1.1965  Validation loss = 2.2837  \n",
      "\n",
      "Check model:  Fold: 2  Optimal epoch: 12  \n",
      "\n",
      "Fold: 3  Epoch: 1  Training loss = 1.1832  Validation loss = 1.3511  \n",
      "\n",
      "Fold: 3  Epoch: 2  Training loss = 1.1537  Validation loss = 1.5063  \n",
      "\n",
      "Fold: 3  Epoch: 3  Training loss = 1.1416  Validation loss = 1.0574  \n",
      "\n",
      "Fold: 3  Epoch: 4  Training loss = 1.4309  Validation loss = 2.7945  \n",
      "\n",
      "Fold: 3  Epoch: 5  Training loss = 1.1925  Validation loss = 1.1278  \n",
      "\n",
      "Fold: 3  Epoch: 6  Training loss = 1.1623  Validation loss = 1.2678  \n",
      "\n",
      "Fold: 3  Epoch: 7  Training loss = 1.1915  Validation loss = 0.9029  \n",
      "\n",
      "Fold: 3  Epoch: 8  Training loss = 1.1874  Validation loss = 0.7572  \n",
      "\n",
      "Fold: 3  Epoch: 9  Training loss = 1.0782  Validation loss = 1.2167  \n",
      "\n",
      "Fold: 3  Epoch: 10  Training loss = 1.2075  Validation loss = 1.6653  \n",
      "\n",
      "Fold: 3  Epoch: 11  Training loss = 1.0786  Validation loss = 1.0625  \n",
      "\n",
      "Fold: 3  Epoch: 12  Training loss = 1.1211  Validation loss = 1.4659  \n",
      "\n",
      "Fold: 3  Epoch: 13  Training loss = 1.1103  Validation loss = 1.5020  \n",
      "\n",
      "Fold: 3  Epoch: 14  Training loss = 1.1020  Validation loss = 1.5541  \n",
      "\n",
      "Fold: 3  Epoch: 15  Training loss = 1.1125  Validation loss = 1.0548  \n",
      "\n",
      "Fold: 3  Epoch: 16  Training loss = 1.0893  Validation loss = 1.4615  \n",
      "\n",
      "Fold: 3  Epoch: 17  Training loss = 1.0691  Validation loss = 1.0583  \n",
      "\n",
      "Fold: 3  Epoch: 18  Training loss = 1.1924  Validation loss = 1.0410  \n",
      "\n",
      "Fold: 3  Epoch: 19  Training loss = 1.0294  Validation loss = 1.2376  \n",
      "\n",
      "Fold: 3  Epoch: 20  Training loss = 1.0400  Validation loss = 0.9612  \n",
      "\n",
      "Fold: 3  Epoch: 21  Training loss = 1.0755  Validation loss = 1.0079  \n",
      "\n",
      "Fold: 3  Epoch: 22  Training loss = 1.0297  Validation loss = 1.2780  \n",
      "\n",
      "Fold: 3  Epoch: 23  Training loss = 0.9753  Validation loss = 0.8798  \n",
      "\n",
      "Fold: 3  Epoch: 24  Training loss = 1.0072  Validation loss = 1.1383  \n",
      "\n",
      "Fold: 3  Epoch: 25  Training loss = 1.1955  Validation loss = 0.6740  \n",
      "\n",
      "Fold: 3  Epoch: 26  Training loss = 1.0690  Validation loss = 1.1505  \n",
      "\n",
      "Fold: 3  Epoch: 27  Training loss = 0.9899  Validation loss = 1.3116  \n",
      "\n",
      "Check model:  Fold: 3  Optimal epoch: 25  \n",
      "\n",
      "Fold: 4  Epoch: 1  Training loss = 0.9610  Validation loss = 1.9029  \n",
      "\n",
      "Fold: 4  Epoch: 2  Training loss = 1.0879  Validation loss = 1.5172  \n",
      "\n",
      "Fold: 4  Epoch: 3  Training loss = 0.9607  Validation loss = 1.1755  \n",
      "\n",
      "Fold: 4  Epoch: 4  Training loss = 1.0227  Validation loss = 1.9102  \n",
      "\n",
      "Fold: 4  Epoch: 5  Training loss = 1.1522  Validation loss = 1.1964  \n",
      "\n",
      "Fold: 4  Epoch: 6  Training loss = 0.8887  Validation loss = 1.3211  \n",
      "\n",
      "Fold: 4  Epoch: 7  Training loss = 0.9909  Validation loss = 2.3554  \n",
      "\n",
      "Fold: 4  Epoch: 8  Training loss = 1.0163  Validation loss = 1.3184  \n",
      "\n",
      "Fold: 4  Epoch: 9  Training loss = 0.9407  Validation loss = 1.9844  \n",
      "\n",
      "Fold: 4  Epoch: 10  Training loss = 1.0740  Validation loss = 1.2559  \n",
      "\n",
      "Fold: 4  Epoch: 11  Training loss = 0.8793  Validation loss = 1.5468  \n",
      "\n",
      "Fold: 4  Epoch: 12  Training loss = 0.9765  Validation loss = 1.2718  \n",
      "\n",
      "Fold: 4  Epoch: 13  Training loss = 0.8724  Validation loss = 1.6431  \n",
      "\n",
      "Fold: 4  Epoch: 14  Training loss = 0.9267  Validation loss = 1.4919  \n",
      "\n",
      "Fold: 4  Epoch: 15  Training loss = 0.9058  Validation loss = 1.9249  \n",
      "\n",
      "Fold: 4  Epoch: 16  Training loss = 0.8691  Validation loss = 1.6317  \n",
      "\n",
      "Fold: 4  Epoch: 17  Training loss = 0.9371  Validation loss = 1.4021  \n",
      "\n",
      "Fold: 4  Epoch: 18  Training loss = 0.8671  Validation loss = 1.4376  \n",
      "\n",
      "Fold: 4  Epoch: 19  Training loss = 0.8298  Validation loss = 1.9619  \n",
      "\n",
      "Check model:  Fold: 4  Optimal epoch: 3  \n",
      "\n",
      "Fold: 5  Epoch: 1  Training loss = 0.8801  Validation loss = 1.5023  \n",
      "\n",
      "Fold: 5  Epoch: 2  Training loss = 0.7882  Validation loss = 0.8784  \n",
      "\n",
      "Fold: 5  Epoch: 3  Training loss = 0.8134  Validation loss = 0.9407  \n",
      "\n",
      "Fold: 5  Epoch: 4  Training loss = 0.7857  Validation loss = 0.8409  \n",
      "\n",
      "Fold: 5  Epoch: 5  Training loss = 0.9326  Validation loss = 1.1921  \n",
      "\n",
      "Fold: 5  Epoch: 6  Training loss = 0.8527  Validation loss = 1.5302  \n",
      "\n",
      "Fold: 5  Epoch: 7  Training loss = 0.9260  Validation loss = 2.4376  \n",
      "\n",
      "Fold: 5  Epoch: 8  Training loss = 0.9622  Validation loss = 1.7997  \n",
      "\n",
      "Fold: 5  Epoch: 9  Training loss = 0.8690  Validation loss = 1.8264  \n",
      "\n",
      "Fold: 5  Epoch: 10  Training loss = 0.8408  Validation loss = 1.4779  \n",
      "\n",
      "Fold: 5  Epoch: 11  Training loss = 0.8723  Validation loss = 1.3396  \n",
      "\n",
      "Fold: 5  Epoch: 12  Training loss = 0.7953  Validation loss = 1.3466  \n",
      "\n",
      "Fold: 5  Epoch: 13  Training loss = 0.8039  Validation loss = 1.7800  \n",
      "\n",
      "Fold: 5  Epoch: 14  Training loss = 0.8611  Validation loss = 1.8738  \n",
      "\n",
      "Fold: 5  Epoch: 15  Training loss = 0.7810  Validation loss = 1.6410  \n",
      "\n",
      "Fold: 5  Epoch: 16  Training loss = 1.0084  Validation loss = 1.6061  \n",
      "\n",
      "Fold: 5  Epoch: 17  Training loss = 0.8114  Validation loss = 1.5418  \n",
      "\n",
      "Fold: 5  Epoch: 18  Training loss = 0.7574  Validation loss = 1.4030  \n",
      "\n",
      "Fold: 5  Epoch: 19  Training loss = 0.8510  Validation loss = 1.4005  \n",
      "\n",
      "Fold: 5  Epoch: 20  Training loss = 0.8415  Validation loss = 2.1712  \n",
      "\n",
      "Check model:  Fold: 5  Optimal epoch: 4  \n",
      "\n",
      "Fold: 6  Epoch: 1  Training loss = 0.8458  Validation loss = 1.7300  \n",
      "\n",
      "Fold: 6  Epoch: 2  Training loss = 0.8250  Validation loss = 1.2621  \n",
      "\n",
      "Fold: 6  Epoch: 3  Training loss = 0.8514  Validation loss = 1.8109  \n",
      "\n",
      "Fold: 6  Epoch: 4  Training loss = 0.8610  Validation loss = 1.9026  \n",
      "\n",
      "Fold: 6  Epoch: 5  Training loss = 0.8246  Validation loss = 1.3788  \n",
      "\n",
      "Fold: 6  Epoch: 6  Training loss = 0.8394  Validation loss = 1.7489  \n",
      "\n",
      "Fold: 6  Epoch: 7  Training loss = 0.8435  Validation loss = 2.0175  \n",
      "\n",
      "Fold: 6  Epoch: 8  Training loss = 0.7673  Validation loss = 1.7852  \n",
      "\n",
      "Fold: 6  Epoch: 9  Training loss = 0.7640  Validation loss = 1.8289  \n",
      "\n",
      "Fold: 6  Epoch: 10  Training loss = 0.8427  Validation loss = 1.7626  \n",
      "\n",
      "Fold: 6  Epoch: 11  Training loss = 0.8870  Validation loss = 1.5562  \n",
      "\n",
      "Fold: 6  Epoch: 12  Training loss = 0.8099  Validation loss = 1.5885  \n",
      "\n",
      "Fold: 6  Epoch: 13  Training loss = 0.8774  Validation loss = 2.1308  \n",
      "\n",
      "Check model:  Fold: 6  Optimal epoch: 2  \n",
      "\n",
      "Fold: 7  Epoch: 1  Training loss = 0.8893  Validation loss = 1.3953  \n",
      "\n",
      "Fold: 7  Epoch: 2  Training loss = 0.9847  Validation loss = 2.4824  \n",
      "\n",
      "Fold: 7  Epoch: 3  Training loss = 0.8235  Validation loss = 1.5318  \n",
      "\n",
      "Fold: 7  Epoch: 4  Training loss = 0.8339  Validation loss = 0.7914  \n",
      "\n",
      "Fold: 7  Epoch: 5  Training loss = 0.7853  Validation loss = 1.0141  \n",
      "\n",
      "Fold: 7  Epoch: 6  Training loss = 0.7721  Validation loss = 1.1711  \n",
      "\n",
      "Fold: 7  Epoch: 7  Training loss = 0.8484  Validation loss = 0.6469  \n",
      "\n",
      "Fold: 7  Epoch: 8  Training loss = 0.8285  Validation loss = 0.6921  \n",
      "\n",
      "Fold: 7  Epoch: 9  Training loss = 1.1481  Validation loss = 0.8012  \n",
      "\n",
      "Fold: 7  Epoch: 10  Training loss = 1.1053  Validation loss = 0.4271  \n",
      "\n",
      "Fold: 7  Epoch: 11  Training loss = 0.7557  Validation loss = 1.0809  \n",
      "\n",
      "Fold: 7  Epoch: 12  Training loss = 0.7787  Validation loss = 0.9937  \n",
      "\n",
      "Fold: 7  Epoch: 13  Training loss = 0.7356  Validation loss = 1.0516  \n",
      "\n",
      "Fold: 7  Epoch: 14  Training loss = 0.7830  Validation loss = 1.4601  \n",
      "\n",
      "Check model:  Fold: 7  Optimal epoch: 10  \n",
      "\n",
      "Fold: 8  Epoch: 1  Training loss = 0.7007  Validation loss = 4.4941  \n",
      "\n",
      "Fold: 8  Epoch: 2  Training loss = 0.7364  Validation loss = 4.3725  \n",
      "\n",
      "Fold: 8  Epoch: 3  Training loss = 0.7684  Validation loss = 4.0621  \n",
      "\n",
      "Fold: 8  Epoch: 4  Training loss = 0.7910  Validation loss = 4.6994  \n",
      "\n",
      "Fold: 8  Epoch: 5  Training loss = 0.6701  Validation loss = 4.3967  \n",
      "\n",
      "Fold: 8  Epoch: 6  Training loss = 0.7104  Validation loss = 4.2585  \n",
      "\n",
      "Fold: 8  Epoch: 7  Training loss = 0.6619  Validation loss = 3.8489  \n",
      "\n",
      "Fold: 8  Epoch: 8  Training loss = 0.6704  Validation loss = 4.2423  \n",
      "\n",
      "Fold: 8  Epoch: 9  Training loss = 0.7341  Validation loss = 4.3096  \n",
      "\n",
      "Fold: 8  Epoch: 10  Training loss = 0.7280  Validation loss = 4.3016  \n",
      "\n",
      "Fold: 8  Epoch: 11  Training loss = 0.6919  Validation loss = 4.1174  \n",
      "\n",
      "Fold: 8  Epoch: 12  Training loss = 0.7835  Validation loss = 4.8267  \n",
      "\n",
      "Check model:  Fold: 8  Optimal epoch: 7  \n",
      "\n",
      "Fold: 9  Epoch: 1  Training loss = 1.2037  Validation loss = 6.6303  \n",
      "\n",
      "Fold: 9  Epoch: 2  Training loss = 1.4408  Validation loss = 6.2576  \n",
      "\n",
      "Fold: 9  Epoch: 3  Training loss = 1.2152  Validation loss = 5.8405  \n",
      "\n",
      "Fold: 9  Epoch: 4  Training loss = 1.3897  Validation loss = 4.6072  \n",
      "\n",
      "Fold: 9  Epoch: 5  Training loss = 0.9865  Validation loss = 5.7407  \n",
      "\n",
      "Fold: 9  Epoch: 6  Training loss = 1.0742  Validation loss = 5.4226  \n",
      "\n",
      "Fold: 9  Epoch: 7  Training loss = 0.9889  Validation loss = 5.3164  \n",
      "\n",
      "Fold: 9  Epoch: 8  Training loss = 0.9861  Validation loss = 5.4600  \n",
      "\n",
      "Fold: 9  Epoch: 9  Training loss = 1.0192  Validation loss = 5.8649  \n",
      "\n",
      "Fold: 9  Epoch: 10  Training loss = 0.9474  Validation loss = 6.2816  \n",
      "\n",
      "Fold: 9  Epoch: 11  Training loss = 1.0515  Validation loss = 5.9442  \n",
      "\n",
      "Fold: 9  Epoch: 12  Training loss = 0.8631  Validation loss = 6.0172  \n",
      "\n",
      "Fold: 9  Epoch: 13  Training loss = 1.0798  Validation loss = 7.0949  \n",
      "\n",
      "Check model:  Fold: 9  Optimal epoch: 4  \n",
      "\n",
      "Fold: 10  Epoch: 1  Training loss = 2.4030  Validation loss = 3.1852  \n",
      "\n",
      "Fold: 10  Epoch: 2  Training loss = 1.4841  Validation loss = 2.8010  \n",
      "\n",
      "Fold: 10  Epoch: 3  Training loss = 1.4840  Validation loss = 2.2349  \n",
      "\n",
      "Fold: 10  Epoch: 4  Training loss = 1.4852  Validation loss = 2.9522  \n",
      "\n",
      "Fold: 10  Epoch: 5  Training loss = 1.2636  Validation loss = 3.2023  \n",
      "\n",
      "Fold: 10  Epoch: 6  Training loss = 1.8997  Validation loss = 1.7715  \n",
      "\n",
      "Fold: 10  Epoch: 7  Training loss = 1.2162  Validation loss = 2.2847  \n",
      "\n",
      "Fold: 10  Epoch: 8  Training loss = 1.0290  Validation loss = 2.5274  \n",
      "\n",
      "Fold: 10  Epoch: 9  Training loss = 1.5652  Validation loss = 2.4602  \n",
      "\n",
      "Fold: 10  Epoch: 10  Training loss = 1.0601  Validation loss = 2.3063  \n",
      "\n",
      "Fold: 10  Epoch: 11  Training loss = 1.0756  Validation loss = 1.8227  \n",
      "\n",
      "Fold: 10  Epoch: 12  Training loss = 0.9681  Validation loss = 2.9461  \n",
      "\n",
      "Fold: 10  Epoch: 13  Training loss = 0.9112  Validation loss = 2.8752  \n",
      "\n",
      "Fold: 10  Epoch: 14  Training loss = 0.8460  Validation loss = 2.7155  \n",
      "\n",
      "Fold: 10  Epoch: 15  Training loss = 1.0200  Validation loss = 2.7147  \n",
      "\n",
      "Fold: 10  Epoch: 16  Training loss = 0.8465  Validation loss = 2.9148  \n",
      "\n",
      "Fold: 10  Epoch: 17  Training loss = 0.8799  Validation loss = 2.7996  \n",
      "\n",
      "Fold: 10  Epoch: 18  Training loss = 0.8625  Validation loss = 2.8140  \n",
      "\n",
      "Fold: 10  Epoch: 19  Training loss = 0.8425  Validation loss = 2.9259  \n",
      "\n",
      "Fold: 10  Epoch: 20  Training loss = 1.1457  Validation loss = 2.1479  \n",
      "\n",
      "Fold: 10  Epoch: 21  Training loss = 0.9450  Validation loss = 2.6355  \n",
      "\n",
      "Fold: 10  Epoch: 22  Training loss = 1.0090  Validation loss = 2.6011  \n",
      "\n",
      "Fold: 10  Epoch: 23  Training loss = 0.8810  Validation loss = 2.4460  \n",
      "\n",
      "Fold: 10  Epoch: 24  Training loss = 0.9850  Validation loss = 2.2765  \n",
      "\n",
      "Fold: 10  Epoch: 25  Training loss = 0.8263  Validation loss = 3.0199  \n",
      "\n",
      "Check model:  Fold: 10  Optimal epoch: 6  \n",
      "\n",
      "Fold: 11  Epoch: 1  Training loss = 1.0131  Validation loss = 2.7931  \n",
      "\n",
      "Fold: 11  Epoch: 2  Training loss = 1.1262  Validation loss = 2.7251  \n",
      "\n",
      "Fold: 11  Epoch: 3  Training loss = 1.1708  Validation loss = 2.9882  \n",
      "\n",
      "Fold: 11  Epoch: 4  Training loss = 1.0035  Validation loss = 2.3958  \n",
      "\n",
      "Fold: 11  Epoch: 5  Training loss = 1.3042  Validation loss = 3.8949  \n",
      "\n",
      "Fold: 11  Epoch: 6  Training loss = 0.9775  Validation loss = 3.4039  \n",
      "\n",
      "Fold: 11  Epoch: 7  Training loss = 1.6667  Validation loss = 3.4758  \n",
      "\n",
      "Fold: 11  Epoch: 8  Training loss = 0.9824  Validation loss = 2.7976  \n",
      "\n",
      "Fold: 11  Epoch: 9  Training loss = 1.2212  Validation loss = 2.6716  \n",
      "\n",
      "Fold: 11  Epoch: 10  Training loss = 1.1719  Validation loss = 2.2900  \n",
      "\n",
      "Fold: 11  Epoch: 11  Training loss = 0.9878  Validation loss = 2.5522  \n",
      "\n",
      "Fold: 11  Epoch: 12  Training loss = 1.0390  Validation loss = 2.2583  \n",
      "\n",
      "Fold: 11  Epoch: 13  Training loss = 1.0996  Validation loss = 2.7482  \n",
      "\n",
      "Fold: 11  Epoch: 14  Training loss = 1.2542  Validation loss = 1.4663  \n",
      "\n",
      "Fold: 11  Epoch: 15  Training loss = 0.9571  Validation loss = 2.0908  \n",
      "\n",
      "Fold: 11  Epoch: 16  Training loss = 1.1682  Validation loss = 1.6636  \n",
      "\n",
      "Fold: 11  Epoch: 17  Training loss = 1.2265  Validation loss = 2.3322  \n",
      "\n",
      "Fold: 11  Epoch: 18  Training loss = 1.0778  Validation loss = 2.5693  \n",
      "\n",
      "Fold: 11  Epoch: 19  Training loss = 1.0459  Validation loss = 2.3704  \n",
      "\n",
      "Fold: 11  Epoch: 20  Training loss = 0.8975  Validation loss = 2.9794  \n",
      "\n",
      "Check model:  Fold: 11  Optimal epoch: 14  \n",
      "\n",
      "Fold: 12  Epoch: 1  Training loss = 1.9739  Validation loss = 1.6161  \n",
      "\n",
      "Fold: 12  Epoch: 2  Training loss = 1.6417  Validation loss = 0.6099  \n",
      "\n",
      "Fold: 12  Epoch: 3  Training loss = 1.4447  Validation loss = 0.9873  \n",
      "\n",
      "Fold: 12  Epoch: 4  Training loss = 1.4228  Validation loss = 1.1929  \n",
      "\n",
      "Fold: 12  Epoch: 5  Training loss = 1.3461  Validation loss = 0.7738  \n",
      "\n",
      "Fold: 12  Epoch: 6  Training loss = 1.3610  Validation loss = 0.9170  \n",
      "\n",
      "Fold: 12  Epoch: 7  Training loss = 1.3152  Validation loss = 1.7297  \n",
      "\n",
      "Fold: 12  Epoch: 8  Training loss = 1.3244  Validation loss = 1.3495  \n",
      "\n",
      "Fold: 12  Epoch: 9  Training loss = 1.2600  Validation loss = 1.1637  \n",
      "\n",
      "Fold: 12  Epoch: 10  Training loss = 1.9474  Validation loss = 2.1120  \n",
      "\n",
      "Fold: 12  Epoch: 11  Training loss = 1.6283  Validation loss = 1.2941  \n",
      "\n",
      "Fold: 12  Epoch: 12  Training loss = 1.8582  Validation loss = 2.5877  \n",
      "\n",
      "Check model:  Fold: 12  Optimal epoch: 2  \n",
      "\n",
      "Fold: 13  Epoch: 1  Training loss = 1.5269  Validation loss = 2.9529  \n",
      "\n",
      "Fold: 13  Epoch: 2  Training loss = 1.8084  Validation loss = 3.1144  \n",
      "\n",
      "Fold: 13  Epoch: 3  Training loss = 1.7318  Validation loss = 4.2774  \n",
      "\n",
      "Fold: 13  Epoch: 4  Training loss = 2.1333  Validation loss = 4.4890  \n",
      "\n",
      "Fold: 13  Epoch: 5  Training loss = 1.3159  Validation loss = 2.8041  \n",
      "\n",
      "Fold: 13  Epoch: 6  Training loss = 1.2987  Validation loss = 2.7357  \n",
      "\n",
      "Fold: 13  Epoch: 7  Training loss = 1.8509  Validation loss = 1.7198  \n",
      "\n",
      "Fold: 13  Epoch: 8  Training loss = 1.1956  Validation loss = 2.1573  \n",
      "\n",
      "Fold: 13  Epoch: 9  Training loss = 1.5355  Validation loss = 4.1521  \n",
      "\n",
      "Fold: 13  Epoch: 10  Training loss = 1.2682  Validation loss = 1.6227  \n",
      "\n",
      "Fold: 13  Epoch: 11  Training loss = 1.3879  Validation loss = 1.8383  \n",
      "\n",
      "Fold: 13  Epoch: 12  Training loss = 1.2997  Validation loss = 3.3060  \n",
      "\n",
      "Fold: 13  Epoch: 13  Training loss = 1.3855  Validation loss = 1.8161  \n",
      "\n",
      "Fold: 13  Epoch: 14  Training loss = 1.5283  Validation loss = 1.9841  \n",
      "\n",
      "Fold: 13  Epoch: 15  Training loss = 1.1206  Validation loss = 3.5310  \n",
      "\n",
      "Fold: 13  Epoch: 16  Training loss = 1.1573  Validation loss = 2.6483  \n",
      "\n",
      "Fold: 13  Epoch: 17  Training loss = 1.1027  Validation loss = 2.3347  \n",
      "\n",
      "Fold: 13  Epoch: 18  Training loss = 1.1472  Validation loss = 2.1588  \n",
      "\n",
      "Fold: 13  Epoch: 19  Training loss = 1.2212  Validation loss = 2.4230  \n",
      "\n",
      "Fold: 13  Epoch: 20  Training loss = 1.3857  Validation loss = 1.3155  \n",
      "\n",
      "Fold: 13  Epoch: 21  Training loss = 1.0096  Validation loss = 1.9224  \n",
      "\n",
      "Fold: 13  Epoch: 22  Training loss = 1.0097  Validation loss = 1.6470  \n",
      "\n",
      "Fold: 13  Epoch: 23  Training loss = 1.3382  Validation loss = 2.0484  \n",
      "\n",
      "Fold: 13  Epoch: 24  Training loss = 1.1979  Validation loss = 1.6298  \n",
      "\n",
      "Fold: 13  Epoch: 25  Training loss = 0.9764  Validation loss = 2.0898  \n",
      "\n",
      "Fold: 13  Epoch: 26  Training loss = 1.2445  Validation loss = 2.8368  \n",
      "\n",
      "Check model:  Fold: 13  Optimal epoch: 20  \n",
      "\n",
      "Fold: 14  Epoch: 1  Training loss = 1.5405  Validation loss = 5.5776  \n",
      "\n",
      "Fold: 14  Epoch: 2  Training loss = 1.1422  Validation loss = 4.8516  \n",
      "\n",
      "Fold: 14  Epoch: 3  Training loss = 3.2810  Validation loss = 3.5555  \n",
      "\n",
      "Fold: 14  Epoch: 4  Training loss = 1.5125  Validation loss = 6.0574  \n",
      "\n",
      "Fold: 14  Epoch: 5  Training loss = 1.9459  Validation loss = 1.6939  \n",
      "\n",
      "Fold: 14  Epoch: 6  Training loss = 1.4250  Validation loss = 4.2691  \n",
      "\n",
      "Fold: 14  Epoch: 7  Training loss = 1.2581  Validation loss = 5.0738  \n",
      "\n",
      "Fold: 14  Epoch: 8  Training loss = 1.1978  Validation loss = 4.7967  \n",
      "\n",
      "Fold: 14  Epoch: 9  Training loss = 1.3170  Validation loss = 2.9279  \n",
      "\n",
      "Fold: 14  Epoch: 10  Training loss = 1.1292  Validation loss = 6.1244  \n",
      "\n",
      "Fold: 14  Epoch: 11  Training loss = 1.6561  Validation loss = 5.2575  \n",
      "\n",
      "Fold: 14  Epoch: 12  Training loss = 1.7416  Validation loss = 3.7169  \n",
      "\n",
      "Fold: 14  Epoch: 13  Training loss = 2.2126  Validation loss = 3.0762  \n",
      "\n",
      "Fold: 14  Epoch: 14  Training loss = 1.4261  Validation loss = 4.0568  \n",
      "\n",
      "Fold: 14  Epoch: 15  Training loss = 1.5015  Validation loss = 5.1762  \n",
      "\n",
      "Fold: 14  Epoch: 16  Training loss = 1.7283  Validation loss = 4.1034  \n",
      "\n",
      "Fold: 14  Epoch: 17  Training loss = 1.3633  Validation loss = 4.9683  \n",
      "\n",
      "Fold: 14  Epoch: 18  Training loss = 1.5511  Validation loss = 5.0058  \n",
      "\n",
      "Fold: 14  Epoch: 19  Training loss = 1.7931  Validation loss = 7.0415  \n",
      "\n",
      "Check model:  Fold: 14  Optimal epoch: 5  \n",
      "\n",
      "Fold: 15  Epoch: 1  Training loss = 1.8142  Validation loss = 5.8942  \n",
      "\n",
      "Fold: 15  Epoch: 2  Training loss = 1.9894  Validation loss = 5.1917  \n",
      "\n",
      "Fold: 15  Epoch: 3  Training loss = 2.2503  Validation loss = 6.6434  \n",
      "\n",
      "Fold: 15  Epoch: 4  Training loss = 1.9677  Validation loss = 5.1991  \n",
      "\n",
      "Fold: 15  Epoch: 5  Training loss = 1.7757  Validation loss = 6.4846  \n",
      "\n",
      "Fold: 15  Epoch: 6  Training loss = 1.8850  Validation loss = 5.0560  \n",
      "\n",
      "Fold: 15  Epoch: 7  Training loss = 2.7784  Validation loss = 6.1325  \n",
      "\n",
      "Fold: 15  Epoch: 8  Training loss = 1.8513  Validation loss = 6.0374  \n",
      "\n",
      "Fold: 15  Epoch: 9  Training loss = 1.9109  Validation loss = 5.9204  \n",
      "\n",
      "Fold: 15  Epoch: 10  Training loss = 2.0334  Validation loss = 6.6095  \n",
      "\n",
      "Fold: 15  Epoch: 11  Training loss = 1.9918  Validation loss = 6.5136  \n",
      "\n",
      "Fold: 15  Epoch: 12  Training loss = 1.9861  Validation loss = 6.2132  \n",
      "\n",
      "Fold: 15  Epoch: 13  Training loss = 2.2027  Validation loss = 6.2832  \n",
      "\n",
      "Fold: 15  Epoch: 14  Training loss = 2.3715  Validation loss = 4.5901  \n",
      "\n",
      "Fold: 15  Epoch: 15  Training loss = 1.7313  Validation loss = 5.2468  \n",
      "\n",
      "Fold: 15  Epoch: 16  Training loss = 1.6391  Validation loss = 4.9724  \n",
      "\n",
      "Fold: 15  Epoch: 17  Training loss = 1.7716  Validation loss = 5.7179  \n",
      "\n",
      "Fold: 15  Epoch: 18  Training loss = 1.9240  Validation loss = 4.9779  \n",
      "\n",
      "Fold: 15  Epoch: 19  Training loss = 1.7618  Validation loss = 6.3968  \n",
      "\n",
      "Fold: 15  Epoch: 20  Training loss = 3.1304  Validation loss = 4.4858  \n",
      "\n",
      "Fold: 15  Epoch: 21  Training loss = 2.0043  Validation loss = 4.5821  \n",
      "\n",
      "Fold: 15  Epoch: 22  Training loss = 1.8533  Validation loss = 4.2376  \n",
      "\n",
      "Fold: 15  Epoch: 23  Training loss = 1.4916  Validation loss = 4.9536  \n",
      "\n",
      "Fold: 15  Epoch: 24  Training loss = 2.7263  Validation loss = 4.5911  \n",
      "\n",
      "Fold: 15  Epoch: 25  Training loss = 1.7434  Validation loss = 6.7278  \n",
      "\n",
      "Check model:  Fold: 15  Optimal epoch: 22  \n",
      "\n",
      "Fold: 16  Epoch: 1  Training loss = 2.5166  Validation loss = 5.5681  \n",
      "\n",
      "Fold: 16  Epoch: 2  Training loss = 2.3408  Validation loss = 6.1855  \n",
      "\n",
      "Fold: 16  Epoch: 3  Training loss = 2.1241  Validation loss = 6.2627  \n",
      "\n",
      "Fold: 16  Epoch: 4  Training loss = 2.4374  Validation loss = 5.9792  \n",
      "\n",
      "Fold: 16  Epoch: 5  Training loss = 2.9818  Validation loss = 5.8693  \n",
      "\n",
      "Fold: 16  Epoch: 6  Training loss = 4.3008  Validation loss = 6.1188  \n",
      "\n",
      "Fold: 16  Epoch: 7  Training loss = 2.6773  Validation loss = 7.2597  \n",
      "\n",
      "Fold: 16  Epoch: 8  Training loss = 2.2974  Validation loss = 6.6121  \n",
      "\n",
      "Fold: 16  Epoch: 9  Training loss = 2.1880  Validation loss = 7.6428  \n",
      "\n",
      "Fold: 16  Epoch: 10  Training loss = 2.7760  Validation loss = 7.0153  \n",
      "\n",
      "Fold: 16  Epoch: 11  Training loss = 2.2461  Validation loss = 8.9484  \n",
      "\n",
      "Check model:  Fold: 16  Optimal epoch: 1  \n",
      "\n",
      "Fold: 17  Epoch: 1  Training loss = 2.2846  Validation loss = 3.5520  \n",
      "\n",
      "Fold: 17  Epoch: 2  Training loss = 2.1463  Validation loss = 2.4279  \n",
      "\n",
      "Fold: 17  Epoch: 3  Training loss = 2.2012  Validation loss = 2.8937  \n",
      "\n",
      "Fold: 17  Epoch: 4  Training loss = 2.9804  Validation loss = 4.1395  \n",
      "\n",
      "Fold: 17  Epoch: 5  Training loss = 2.4363  Validation loss = 4.2634  \n",
      "\n",
      "Fold: 17  Epoch: 6  Training loss = 2.4066  Validation loss = 3.0906  \n",
      "\n",
      "Fold: 17  Epoch: 7  Training loss = 2.2497  Validation loss = 2.6979  \n",
      "\n",
      "Fold: 17  Epoch: 8  Training loss = 2.6298  Validation loss = 2.2376  \n",
      "\n",
      "Fold: 17  Epoch: 9  Training loss = 2.2876  Validation loss = 2.5890  \n",
      "\n",
      "Fold: 17  Epoch: 10  Training loss = 2.0702  Validation loss = 3.5923  \n",
      "\n",
      "Fold: 17  Epoch: 11  Training loss = 2.1606  Validation loss = 2.9979  \n",
      "\n",
      "Fold: 17  Epoch: 12  Training loss = 2.2108  Validation loss = 3.3189  \n",
      "\n",
      "Fold: 17  Epoch: 13  Training loss = 2.1004  Validation loss = 2.7876  \n",
      "\n",
      "Fold: 17  Epoch: 14  Training loss = 2.4817  Validation loss = 3.0970  \n",
      "\n",
      "Fold: 17  Epoch: 15  Training loss = 2.8196  Validation loss = 2.6669  \n",
      "\n",
      "Fold: 17  Epoch: 16  Training loss = 2.1896  Validation loss = 2.1841  \n",
      "\n",
      "Fold: 17  Epoch: 17  Training loss = 2.9234  Validation loss = 2.4944  \n",
      "\n",
      "Fold: 17  Epoch: 18  Training loss = 2.7815  Validation loss = 3.1664  \n",
      "\n",
      "Fold: 17  Epoch: 19  Training loss = 1.9035  Validation loss = 2.3074  \n",
      "\n",
      "Fold: 17  Epoch: 20  Training loss = 2.1508  Validation loss = 2.6436  \n",
      "\n",
      "Fold: 17  Epoch: 21  Training loss = 2.4073  Validation loss = 2.4656  \n",
      "\n",
      "Fold: 17  Epoch: 22  Training loss = 1.9819  Validation loss = 2.2513  \n",
      "\n",
      "Fold: 17  Epoch: 23  Training loss = 2.0194  Validation loss = 2.3465  \n",
      "\n",
      "Fold: 17  Epoch: 24  Training loss = 2.0201  Validation loss = 1.8586  \n",
      "\n",
      "Fold: 17  Epoch: 25  Training loss = 1.6552  Validation loss = 2.9264  \n",
      "\n",
      "Fold: 17  Epoch: 26  Training loss = 2.0166  Validation loss = 2.2202  \n",
      "\n",
      "Fold: 17  Epoch: 27  Training loss = 1.9452  Validation loss = 1.5814  \n",
      "\n",
      "Fold: 17  Epoch: 28  Training loss = 1.9496  Validation loss = 2.1435  \n",
      "\n",
      "Fold: 17  Epoch: 29  Training loss = 2.1843  Validation loss = 1.9127  \n",
      "\n",
      "Fold: 17  Epoch: 30  Training loss = 1.7655  Validation loss = 2.1138  \n",
      "\n",
      "Fold: 17  Epoch: 31  Training loss = 2.0971  Validation loss = 2.2968  \n",
      "\n",
      "Fold: 17  Epoch: 32  Training loss = 1.8063  Validation loss = 2.3727  \n",
      "\n",
      "Fold: 17  Epoch: 33  Training loss = 1.9503  Validation loss = 2.4639  \n",
      "\n",
      "Fold: 17  Epoch: 34  Training loss = 2.2411  Validation loss = 2.0061  \n",
      "\n",
      "Fold: 17  Epoch: 35  Training loss = 2.4736  Validation loss = 1.9959  \n",
      "\n",
      "Fold: 17  Epoch: 36  Training loss = 1.8668  Validation loss = 2.1216  \n",
      "\n",
      "Fold: 17  Epoch: 37  Training loss = 1.7981  Validation loss = 1.8082  \n",
      "\n",
      "Fold: 17  Epoch: 38  Training loss = 1.9478  Validation loss = 1.7929  \n",
      "\n",
      "Fold: 17  Epoch: 39  Training loss = 1.7502  Validation loss = 2.2587  \n",
      "\n",
      "Fold: 17  Epoch: 40  Training loss = 1.9272  Validation loss = 1.6537  \n",
      "\n",
      "Fold: 17  Epoch: 41  Training loss = 2.2736  Validation loss = 2.8198  \n",
      "\n",
      "Check model:  Fold: 17  Optimal epoch: 27  \n",
      "\n",
      "Fold: 18  Epoch: 1  Training loss = 2.1677  Validation loss = 4.1584  \n",
      "\n",
      "Fold: 18  Epoch: 2  Training loss = 2.0685  Validation loss = 3.6509  \n",
      "\n",
      "Fold: 18  Epoch: 3  Training loss = 1.8904  Validation loss = 4.8748  \n",
      "\n",
      "Fold: 18  Epoch: 4  Training loss = 2.1195  Validation loss = 5.4135  \n",
      "\n",
      "Fold: 18  Epoch: 5  Training loss = 2.0571  Validation loss = 5.7849  \n",
      "\n",
      "Fold: 18  Epoch: 6  Training loss = 2.3300  Validation loss = 5.6406  \n",
      "\n",
      "Fold: 18  Epoch: 7  Training loss = 1.8854  Validation loss = 4.9342  \n",
      "\n",
      "Fold: 18  Epoch: 8  Training loss = 2.0883  Validation loss = 5.4339  \n",
      "\n",
      "Fold: 18  Epoch: 9  Training loss = 1.8373  Validation loss = 4.8238  \n",
      "\n",
      "Fold: 18  Epoch: 10  Training loss = 1.8045  Validation loss = 4.0044  \n",
      "\n",
      "Fold: 18  Epoch: 11  Training loss = 2.7133  Validation loss = 3.9420  \n",
      "\n",
      "Fold: 18  Epoch: 12  Training loss = 1.9028  Validation loss = 4.7562  \n",
      "\n",
      "Fold: 18  Epoch: 13  Training loss = 2.0646  Validation loss = 5.2652  \n",
      "\n",
      "Fold: 18  Epoch: 14  Training loss = 2.4355  Validation loss = 6.1272  \n",
      "\n",
      "Check model:  Fold: 18  Optimal epoch: 2  \n",
      "\n",
      "Fold: 19  Epoch: 1  Training loss = 2.5001  Validation loss = 1.6502  \n",
      "\n",
      "Fold: 19  Epoch: 2  Training loss = 2.0536  Validation loss = 2.8794  \n",
      "\n",
      "Fold: 19  Epoch: 3  Training loss = 2.0810  Validation loss = 2.2071  \n",
      "\n",
      "Fold: 19  Epoch: 4  Training loss = 2.6145  Validation loss = 3.2868  \n",
      "\n",
      "Fold: 19  Epoch: 5  Training loss = 2.2317  Validation loss = 2.0873  \n",
      "\n",
      "Fold: 19  Epoch: 6  Training loss = 2.3765  Validation loss = 4.1295  \n",
      "\n",
      "Fold: 19  Epoch: 7  Training loss = 2.1131  Validation loss = 3.9535  \n",
      "\n",
      "Fold: 19  Epoch: 8  Training loss = 1.7919  Validation loss = 4.6376  \n",
      "\n",
      "Fold: 19  Epoch: 9  Training loss = 2.1420  Validation loss = 5.4574  \n",
      "\n",
      "Fold: 19  Epoch: 10  Training loss = 1.9900  Validation loss = 5.0240  \n",
      "\n",
      "Fold: 19  Epoch: 11  Training loss = 1.9855  Validation loss = 5.8631  \n",
      "\n",
      "Check model:  Fold: 19  Optimal epoch: 1  \n",
      "\n",
      "Fold: 20  Epoch: 1  Training loss = 2.1849  Validation loss = 2.7342  \n",
      "\n",
      "Fold: 20  Epoch: 2  Training loss = 2.0339  Validation loss = 2.4064  \n",
      "\n",
      "Fold: 20  Epoch: 3  Training loss = 2.1484  Validation loss = 4.0312  \n",
      "\n",
      "Fold: 20  Epoch: 4  Training loss = 2.0235  Validation loss = 2.1735  \n",
      "\n",
      "Fold: 20  Epoch: 5  Training loss = 2.3104  Validation loss = 1.2259  \n",
      "\n",
      "Fold: 20  Epoch: 6  Training loss = 2.7238  Validation loss = 3.3774  \n",
      "\n",
      "Fold: 20  Epoch: 7  Training loss = 2.0423  Validation loss = 1.2844  \n",
      "\n",
      "Fold: 20  Epoch: 8  Training loss = 2.0370  Validation loss = 0.4954  \n",
      "\n",
      "Fold: 20  Epoch: 9  Training loss = 1.9080  Validation loss = 0.9294  \n",
      "\n",
      "Fold: 20  Epoch: 10  Training loss = 2.0065  Validation loss = 2.7843  \n",
      "\n",
      "Fold: 20  Epoch: 11  Training loss = 2.0627  Validation loss = 1.4355  \n",
      "\n",
      "Fold: 20  Epoch: 12  Training loss = 2.0821  Validation loss = 2.2058  \n",
      "\n",
      "Fold: 20  Epoch: 13  Training loss = 1.9783  Validation loss = 2.4917  \n",
      "\n",
      "Fold: 20  Epoch: 14  Training loss = 2.1704  Validation loss = 0.8515  \n",
      "\n",
      "Fold: 20  Epoch: 15  Training loss = 2.0093  Validation loss = 0.8395  \n",
      "\n",
      "Fold: 20  Epoch: 16  Training loss = 2.1916  Validation loss = 1.7437  \n",
      "\n",
      "Fold: 20  Epoch: 17  Training loss = 1.8744  Validation loss = 1.8740  \n",
      "\n",
      "Fold: 20  Epoch: 18  Training loss = 1.5608  Validation loss = 1.4443  \n",
      "\n",
      "Fold: 20  Epoch: 19  Training loss = 1.6194  Validation loss = 1.1924  \n",
      "\n",
      "Fold: 20  Epoch: 20  Training loss = 2.1771  Validation loss = 2.5669  \n",
      "\n",
      "Check model:  Fold: 20  Optimal epoch: 8  \n",
      "\n",
      "Fold: 21  Epoch: 1  Training loss = 2.1039  Validation loss = 2.4616  \n",
      "\n",
      "Fold: 21  Epoch: 2  Training loss = 1.9932  Validation loss = 3.0678  \n",
      "\n",
      "Fold: 21  Epoch: 3  Training loss = 2.3236  Validation loss = 3.8388  \n",
      "\n",
      "Fold: 21  Epoch: 4  Training loss = 1.9526  Validation loss = 2.9066  \n",
      "\n",
      "Fold: 21  Epoch: 5  Training loss = 2.4999  Validation loss = 3.1485  \n",
      "\n",
      "Fold: 21  Epoch: 6  Training loss = 1.6597  Validation loss = 3.4274  \n",
      "\n",
      "Fold: 21  Epoch: 7  Training loss = 2.5217  Validation loss = 4.7804  \n",
      "\n",
      "Fold: 21  Epoch: 8  Training loss = 2.0584  Validation loss = 3.4153  \n",
      "\n",
      "Fold: 21  Epoch: 9  Training loss = 1.6258  Validation loss = 3.0111  \n",
      "\n",
      "Fold: 21  Epoch: 10  Training loss = 1.6686  Validation loss = 3.7537  \n",
      "\n",
      "Fold: 21  Epoch: 11  Training loss = 1.9941  Validation loss = 2.7798  \n",
      "\n",
      "Fold: 21  Epoch: 12  Training loss = 2.8189  Validation loss = 2.6535  \n",
      "\n",
      "Fold: 21  Epoch: 13  Training loss = 1.6081  Validation loss = 3.9005  \n",
      "\n",
      "Fold: 21  Epoch: 14  Training loss = 1.6196  Validation loss = 3.2525  \n",
      "\n",
      "Fold: 21  Epoch: 15  Training loss = 1.5535  Validation loss = 3.8680  \n",
      "\n",
      "Fold: 21  Epoch: 16  Training loss = 1.6742  Validation loss = 3.0493  \n",
      "\n",
      "Fold: 21  Epoch: 17  Training loss = 1.5169  Validation loss = 3.2431  \n",
      "\n",
      "Fold: 21  Epoch: 18  Training loss = 2.0007  Validation loss = 3.9993  \n",
      "\n",
      "Check model:  Fold: 21  Optimal epoch: 1  \n",
      "\n",
      "Fold: 22  Epoch: 1  Training loss = 1.7784  Validation loss = 3.7441  \n",
      "\n",
      "Fold: 22  Epoch: 2  Training loss = 1.5607  Validation loss = 3.6374  \n",
      "\n",
      "Fold: 22  Epoch: 3  Training loss = 1.6169  Validation loss = 3.7080  \n",
      "\n",
      "Fold: 22  Epoch: 4  Training loss = 2.3891  Validation loss = 4.5624  \n",
      "\n",
      "Fold: 22  Epoch: 5  Training loss = 2.1364  Validation loss = 3.5717  \n",
      "\n",
      "Fold: 22  Epoch: 6  Training loss = 1.3617  Validation loss = 3.3954  \n",
      "\n",
      "Fold: 22  Epoch: 7  Training loss = 1.4630  Validation loss = 3.9938  \n",
      "\n",
      "Fold: 22  Epoch: 8  Training loss = 2.0401  Validation loss = 3.4405  \n",
      "\n",
      "Fold: 22  Epoch: 9  Training loss = 1.5176  Validation loss = 3.8702  \n",
      "\n",
      "Fold: 22  Epoch: 10  Training loss = 1.3835  Validation loss = 4.4612  \n",
      "\n",
      "Fold: 22  Epoch: 11  Training loss = 1.5101  Validation loss = 4.7437  \n",
      "\n",
      "Check model:  Fold: 22  Optimal epoch: 6  \n",
      "\n",
      "Fold: 23  Epoch: 1  Training loss = 2.7150  Validation loss = 4.7796  \n",
      "\n",
      "Fold: 23  Epoch: 2  Training loss = 1.9914  Validation loss = 4.2023  \n",
      "\n",
      "Fold: 23  Epoch: 3  Training loss = 2.0853  Validation loss = 2.6826  \n",
      "\n",
      "Fold: 23  Epoch: 4  Training loss = 3.1200  Validation loss = 2.1701  \n",
      "\n",
      "Fold: 23  Epoch: 5  Training loss = 1.9332  Validation loss = 5.1087  \n",
      "\n",
      "Fold: 23  Epoch: 6  Training loss = 2.1140  Validation loss = 5.9081  \n",
      "\n",
      "Fold: 23  Epoch: 7  Training loss = 2.5676  Validation loss = 6.4623  \n",
      "\n",
      "Fold: 23  Epoch: 8  Training loss = 2.2800  Validation loss = 7.1219  \n",
      "\n",
      "Fold: 23  Epoch: 9  Training loss = 1.8642  Validation loss = 5.0917  \n",
      "\n",
      "Fold: 23  Epoch: 10  Training loss = 3.3126  Validation loss = 4.0718  \n",
      "\n",
      "Fold: 23  Epoch: 11  Training loss = 1.7896  Validation loss = 5.2411  \n",
      "\n",
      "Fold: 23  Epoch: 12  Training loss = 2.3020  Validation loss = 7.2912  \n",
      "\n",
      "Check model:  Fold: 23  Optimal epoch: 4  \n",
      "\n",
      "Fold: 24  Epoch: 1  Training loss = 2.2091  Validation loss = 4.5892  \n",
      "\n",
      "Fold: 24  Epoch: 2  Training loss = 3.0378  Validation loss = 6.4978  \n",
      "\n",
      "Fold: 24  Epoch: 3  Training loss = 2.6837  Validation loss = 5.5150  \n",
      "\n",
      "Fold: 24  Epoch: 4  Training loss = 3.0454  Validation loss = 6.6114  \n",
      "\n",
      "Fold: 24  Epoch: 5  Training loss = 2.0800  Validation loss = 5.9861  \n",
      "\n",
      "Fold: 24  Epoch: 6  Training loss = 3.5565  Validation loss = 5.3793  \n",
      "\n",
      "Fold: 24  Epoch: 7  Training loss = 2.1732  Validation loss = 6.6542  \n",
      "\n",
      "Fold: 24  Epoch: 8  Training loss = 2.1834  Validation loss = 6.9885  \n",
      "\n",
      "Fold: 24  Epoch: 9  Training loss = 2.1410  Validation loss = 5.0739  \n",
      "\n",
      "Fold: 24  Epoch: 10  Training loss = 2.9216  Validation loss = 6.0100  \n",
      "\n",
      "Fold: 24  Epoch: 11  Training loss = 2.1002  Validation loss = 5.9978  \n",
      "\n",
      "Fold: 24  Epoch: 12  Training loss = 2.1688  Validation loss = 3.9751  \n",
      "\n",
      "Fold: 24  Epoch: 13  Training loss = 2.1015  Validation loss = 4.3391  \n",
      "\n",
      "Fold: 24  Epoch: 14  Training loss = 3.2002  Validation loss = 6.2320  \n",
      "\n",
      "Fold: 24  Epoch: 15  Training loss = 2.4855  Validation loss = 6.4459  \n",
      "\n",
      "Fold: 24  Epoch: 16  Training loss = 3.0201  Validation loss = 5.0182  \n",
      "\n",
      "Fold: 24  Epoch: 17  Training loss = 2.1535  Validation loss = 5.2537  \n",
      "\n",
      "Fold: 24  Epoch: 18  Training loss = 2.4322  Validation loss = 6.3770  \n",
      "\n",
      "Fold: 24  Epoch: 19  Training loss = 2.2571  Validation loss = 5.8321  \n",
      "\n",
      "Fold: 24  Epoch: 20  Training loss = 2.9404  Validation loss = 5.0325  \n",
      "\n",
      "Fold: 24  Epoch: 21  Training loss = 2.1335  Validation loss = 3.7466  \n",
      "\n",
      "Fold: 24  Epoch: 22  Training loss = 2.2293  Validation loss = 5.6110  \n",
      "\n",
      "Fold: 24  Epoch: 23  Training loss = 1.8271  Validation loss = 4.9527  \n",
      "\n",
      "Fold: 24  Epoch: 24  Training loss = 2.1795  Validation loss = 5.7154  \n",
      "\n",
      "Fold: 24  Epoch: 25  Training loss = 2.0467  Validation loss = 5.2866  \n",
      "\n",
      "Fold: 24  Epoch: 26  Training loss = 2.5285  Validation loss = 6.0991  \n",
      "\n",
      "Fold: 24  Epoch: 27  Training loss = 2.0627  Validation loss = 5.6953  \n",
      "\n",
      "Fold: 24  Epoch: 28  Training loss = 2.7640  Validation loss = 5.9111  \n",
      "\n",
      "Fold: 24  Epoch: 29  Training loss = 2.6888  Validation loss = 6.1238  \n",
      "\n",
      "Check model:  Fold: 24  Optimal epoch: 21  \n",
      "\n",
      "Fold: 25  Epoch: 1  Training loss = 3.3160  Validation loss = 1.7578  \n",
      "\n",
      "Fold: 25  Epoch: 2  Training loss = 2.7399  Validation loss = 2.0875  \n",
      "\n",
      "Fold: 25  Epoch: 3  Training loss = 2.4359  Validation loss = 1.9937  \n",
      "\n",
      "Fold: 25  Epoch: 4  Training loss = 3.5856  Validation loss = 3.4222  \n",
      "\n",
      "Fold: 25  Epoch: 5  Training loss = 3.1497  Validation loss = 2.1539  \n",
      "\n",
      "Fold: 25  Epoch: 6  Training loss = 2.9429  Validation loss = 2.9913  \n",
      "\n",
      "Fold: 25  Epoch: 7  Training loss = 2.4286  Validation loss = 2.9047  \n",
      "\n",
      "Fold: 25  Epoch: 8  Training loss = 2.6272  Validation loss = 3.5003  \n",
      "\n",
      "Fold: 25  Epoch: 9  Training loss = 2.1586  Validation loss = 2.0939  \n",
      "\n",
      "Fold: 25  Epoch: 10  Training loss = 2.2693  Validation loss = 2.1083  \n",
      "\n",
      "Fold: 25  Epoch: 11  Training loss = 2.6780  Validation loss = 1.6829  \n",
      "\n",
      "Fold: 25  Epoch: 12  Training loss = 2.8356  Validation loss = 3.6694  \n",
      "\n",
      "Check model:  Fold: 25  Optimal epoch: 11  \n",
      "\n",
      "Fold: 26  Epoch: 1  Training loss = 2.7667  Validation loss = 4.0337  \n",
      "\n",
      "Fold: 26  Epoch: 2  Training loss = 2.2702  Validation loss = 2.1427  \n",
      "\n",
      "Fold: 26  Epoch: 3  Training loss = 2.2468  Validation loss = 2.5781  \n",
      "\n",
      "Fold: 26  Epoch: 4  Training loss = 2.3397  Validation loss = 2.9373  \n",
      "\n",
      "Fold: 26  Epoch: 5  Training loss = 2.3782  Validation loss = 2.3448  \n",
      "\n",
      "Fold: 26  Epoch: 6  Training loss = 2.8088  Validation loss = 1.7591  \n",
      "\n",
      "Fold: 26  Epoch: 7  Training loss = 2.1853  Validation loss = 3.3387  \n",
      "\n",
      "Fold: 26  Epoch: 8  Training loss = 1.9266  Validation loss = 1.6077  \n",
      "\n",
      "Fold: 26  Epoch: 9  Training loss = 1.9842  Validation loss = 1.9351  \n",
      "\n",
      "Fold: 26  Epoch: 10  Training loss = 2.1293  Validation loss = 1.5621  \n",
      "\n",
      "Fold: 26  Epoch: 11  Training loss = 1.9111  Validation loss = 2.7972  \n",
      "\n",
      "Fold: 26  Epoch: 12  Training loss = 3.3503  Validation loss = 5.5226  \n",
      "\n",
      "Check model:  Fold: 26  Optimal epoch: 10  \n",
      "\n",
      "Fold: 27  Epoch: 1  Training loss = 2.6397  Validation loss = 3.2505  \n",
      "\n",
      "Fold: 27  Epoch: 2  Training loss = 2.0743  Validation loss = 1.9018  \n",
      "\n",
      "Fold: 27  Epoch: 3  Training loss = 2.4116  Validation loss = 2.2165  \n",
      "\n",
      "Fold: 27  Epoch: 4  Training loss = 1.9249  Validation loss = 1.2133  \n",
      "\n",
      "Fold: 27  Epoch: 5  Training loss = 1.9939  Validation loss = 2.0550  \n",
      "\n",
      "Fold: 27  Epoch: 6  Training loss = 2.5975  Validation loss = 1.2431  \n",
      "\n",
      "Fold: 27  Epoch: 7  Training loss = 2.0644  Validation loss = 1.7270  \n",
      "\n",
      "Fold: 27  Epoch: 8  Training loss = 1.9940  Validation loss = 1.5567  \n",
      "\n",
      "Fold: 27  Epoch: 9  Training loss = 1.9745  Validation loss = 1.4974  \n",
      "\n",
      "Fold: 27  Epoch: 10  Training loss = 1.8287  Validation loss = 1.5468  \n",
      "\n",
      "Fold: 27  Epoch: 11  Training loss = 2.1116  Validation loss = 1.7213  \n",
      "\n",
      "Fold: 27  Epoch: 12  Training loss = 2.2030  Validation loss = 1.5504  \n",
      "\n",
      "Fold: 27  Epoch: 13  Training loss = 1.9457  Validation loss = 1.8684  \n",
      "\n",
      "Fold: 27  Epoch: 14  Training loss = 1.9351  Validation loss = 1.7526  \n",
      "\n",
      "Fold: 27  Epoch: 15  Training loss = 2.0710  Validation loss = 1.3826  \n",
      "\n",
      "Fold: 27  Epoch: 16  Training loss = 2.2941  Validation loss = 1.5564  \n",
      "\n",
      "Fold: 27  Epoch: 17  Training loss = 1.9565  Validation loss = 1.9403  \n",
      "\n",
      "Check model:  Fold: 27  Optimal epoch: 4  \n",
      "\n",
      "Fold: 28  Epoch: 1  Training loss = 1.9687  Validation loss = 2.7479  \n",
      "\n",
      "Fold: 28  Epoch: 2  Training loss = 2.1943  Validation loss = 1.3350  \n",
      "\n",
      "Fold: 28  Epoch: 3  Training loss = 2.1743  Validation loss = 2.3454  \n",
      "\n",
      "Fold: 28  Epoch: 4  Training loss = 1.9972  Validation loss = 2.6094  \n",
      "\n",
      "Fold: 28  Epoch: 5  Training loss = 2.8726  Validation loss = 4.0414  \n",
      "\n",
      "Fold: 28  Epoch: 6  Training loss = 2.8849  Validation loss = 3.1653  \n",
      "\n",
      "Fold: 28  Epoch: 7  Training loss = 2.8898  Validation loss = 1.2807  \n",
      "\n",
      "Fold: 28  Epoch: 8  Training loss = 2.3954  Validation loss = 3.6567  \n",
      "\n",
      "Fold: 28  Epoch: 9  Training loss = 2.0726  Validation loss = 3.7735  \n",
      "\n",
      "Fold: 28  Epoch: 10  Training loss = 2.0592  Validation loss = 3.9324  \n",
      "\n",
      "Fold: 28  Epoch: 11  Training loss = 2.1095  Validation loss = 3.3156  \n",
      "\n",
      "Fold: 28  Epoch: 12  Training loss = 2.1518  Validation loss = 3.2284  \n",
      "\n",
      "Fold: 28  Epoch: 13  Training loss = 1.9887  Validation loss = 3.9674  \n",
      "\n",
      "Fold: 28  Epoch: 14  Training loss = 2.0659  Validation loss = 3.8664  \n",
      "\n",
      "Fold: 28  Epoch: 15  Training loss = 2.3619  Validation loss = 2.7068  \n",
      "\n",
      "Fold: 28  Epoch: 16  Training loss = 2.9479  Validation loss = 4.6685  \n",
      "\n",
      "Check model:  Fold: 28  Optimal epoch: 7  \n",
      "\n",
      "Fold: 29  Epoch: 1  Training loss = 2.2822  Validation loss = 3.2204  \n",
      "\n",
      "Fold: 29  Epoch: 2  Training loss = 3.3698  Validation loss = 1.9382  \n",
      "\n",
      "Fold: 29  Epoch: 3  Training loss = 2.1795  Validation loss = 2.3159  \n",
      "\n",
      "Fold: 29  Epoch: 4  Training loss = 3.1626  Validation loss = 1.6753  \n",
      "\n",
      "Fold: 29  Epoch: 5  Training loss = 2.8561  Validation loss = 1.3120  \n",
      "\n",
      "Fold: 29  Epoch: 6  Training loss = 2.4144  Validation loss = 1.3042  \n",
      "\n",
      "Fold: 29  Epoch: 7  Training loss = 2.4164  Validation loss = 1.6249  \n",
      "\n",
      "Fold: 29  Epoch: 8  Training loss = 2.1584  Validation loss = 1.9340  \n",
      "\n",
      "Fold: 29  Epoch: 9  Training loss = 2.1224  Validation loss = 1.4889  \n",
      "\n",
      "Fold: 29  Epoch: 10  Training loss = 2.2693  Validation loss = 1.7834  \n",
      "\n",
      "Fold: 29  Epoch: 11  Training loss = 2.9430  Validation loss = 1.5662  \n",
      "\n",
      "Fold: 29  Epoch: 12  Training loss = 2.1416  Validation loss = 1.4757  \n",
      "\n",
      "Fold: 29  Epoch: 13  Training loss = 3.2687  Validation loss = 2.1637  \n",
      "\n",
      "Check model:  Fold: 29  Optimal epoch: 6  \n",
      "\n",
      "Fold: 30  Epoch: 1  Training loss = 2.2409  Validation loss = 2.9892  \n",
      "\n",
      "Fold: 30  Epoch: 2  Training loss = 2.7910  Validation loss = 3.6096  \n",
      "\n",
      "Fold: 30  Epoch: 3  Training loss = 2.1760  Validation loss = 2.2111  \n",
      "\n",
      "Fold: 30  Epoch: 4  Training loss = 3.0217  Validation loss = 4.2527  \n",
      "\n",
      "Fold: 30  Epoch: 5  Training loss = 3.3631  Validation loss = 1.4856  \n",
      "\n",
      "Fold: 30  Epoch: 6  Training loss = 3.2469  Validation loss = 1.0296  \n",
      "\n",
      "Fold: 30  Epoch: 7  Training loss = 2.1116  Validation loss = 1.8092  \n",
      "\n",
      "Fold: 30  Epoch: 8  Training loss = 2.1358  Validation loss = 1.7916  \n",
      "\n",
      "Fold: 30  Epoch: 9  Training loss = 3.8037  Validation loss = 5.8034  \n",
      "\n",
      "Fold: 30  Epoch: 10  Training loss = 2.1158  Validation loss = 2.0543  \n",
      "\n",
      "Fold: 30  Epoch: 11  Training loss = 3.3146  Validation loss = 5.2993  \n",
      "\n",
      "Fold: 30  Epoch: 12  Training loss = 2.6110  Validation loss = 0.7873  \n",
      "\n",
      "Fold: 30  Epoch: 13  Training loss = 2.0811  Validation loss = 2.4047  \n",
      "\n",
      "Fold: 30  Epoch: 14  Training loss = 2.2314  Validation loss = 1.5656  \n",
      "\n",
      "Fold: 30  Epoch: 15  Training loss = 2.0590  Validation loss = 2.6437  \n",
      "\n",
      "Fold: 30  Epoch: 16  Training loss = 2.1858  Validation loss = 1.5262  \n",
      "\n",
      "Fold: 30  Epoch: 17  Training loss = 2.3338  Validation loss = 0.8525  \n",
      "\n",
      "Fold: 30  Epoch: 18  Training loss = 3.4874  Validation loss = 1.7642  \n",
      "\n",
      "Fold: 30  Epoch: 19  Training loss = 2.9326  Validation loss = 0.5423  \n",
      "\n",
      "Fold: 30  Epoch: 20  Training loss = 2.5908  Validation loss = 3.7885  \n",
      "\n",
      "Fold: 30  Epoch: 21  Training loss = 2.5627  Validation loss = 0.4854  \n",
      "\n",
      "Fold: 30  Epoch: 22  Training loss = 3.6743  Validation loss = 5.8688  \n",
      "\n",
      "Check model:  Fold: 30  Optimal epoch: 21  \n",
      "\n",
      "Fold: 31  Epoch: 1  Training loss = 2.5877  Validation loss = 4.5443  \n",
      "\n",
      "Fold: 31  Epoch: 2  Training loss = 2.2369  Validation loss = 3.7802  \n",
      "\n",
      "Fold: 31  Epoch: 3  Training loss = 2.5084  Validation loss = 3.1256  \n",
      "\n",
      "Fold: 31  Epoch: 4  Training loss = 2.4353  Validation loss = 3.6136  \n",
      "\n",
      "Fold: 31  Epoch: 5  Training loss = 2.4543  Validation loss = 3.5214  \n",
      "\n",
      "Fold: 31  Epoch: 6  Training loss = 2.1415  Validation loss = 5.5024  \n",
      "\n",
      "Fold: 31  Epoch: 7  Training loss = 2.4261  Validation loss = 3.0412  \n",
      "\n",
      "Fold: 31  Epoch: 8  Training loss = 2.4959  Validation loss = 5.5893  \n",
      "\n",
      "Fold: 31  Epoch: 9  Training loss = 2.7922  Validation loss = 6.5547  \n",
      "\n",
      "Fold: 31  Epoch: 10  Training loss = 3.2133  Validation loss = 6.5419  \n",
      "\n",
      "Fold: 31  Epoch: 11  Training loss = 2.3548  Validation loss = 5.6932  \n",
      "\n",
      "Fold: 31  Epoch: 12  Training loss = 3.4135  Validation loss = 7.7304  \n",
      "\n",
      "Check model:  Fold: 31  Optimal epoch: 7  \n",
      "\n",
      "Fold: 32  Epoch: 1  Training loss = 2.3925  Validation loss = 3.9615  \n",
      "\n",
      "Fold: 32  Epoch: 2  Training loss = 2.0586  Validation loss = 3.0458  \n",
      "\n",
      "Fold: 32  Epoch: 3  Training loss = 1.9740  Validation loss = 4.4136  \n",
      "\n",
      "Fold: 32  Epoch: 4  Training loss = 2.2332  Validation loss = 5.5455  \n",
      "\n",
      "Fold: 32  Epoch: 5  Training loss = 2.3143  Validation loss = 6.0581  \n",
      "\n",
      "Fold: 32  Epoch: 6  Training loss = 1.8827  Validation loss = 2.6942  \n",
      "\n",
      "Fold: 32  Epoch: 7  Training loss = 2.2123  Validation loss = 1.3838  \n",
      "\n",
      "Fold: 32  Epoch: 8  Training loss = 2.4301  Validation loss = 5.0518  \n",
      "\n",
      "Fold: 32  Epoch: 9  Training loss = 2.2934  Validation loss = 0.9890  \n",
      "\n",
      "Fold: 32  Epoch: 10  Training loss = 2.3816  Validation loss = 3.1659  \n",
      "\n",
      "Fold: 32  Epoch: 11  Training loss = 2.5284  Validation loss = 1.2183  \n",
      "\n",
      "Fold: 32  Epoch: 12  Training loss = 2.6432  Validation loss = 6.3381  \n",
      "\n",
      "Check model:  Fold: 32  Optimal epoch: 9  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 2. Train model\n",
    "# ==================================\n",
    "sess = tf.InteractiveSession()  # Launch Graph\n",
    "sess.run(tf.global_variables_initializer())  # Initialise all variables\n",
    "\n",
    "print(\"Start training\", \n",
    "      \"\\nHyperparameters:\",\n",
    "      \"\\nDimension of recurrent unit =\", n_hidden,\n",
    "      \"\\nLearning rate =\", learning_rate,\n",
    "      \"\\nEpochs =\", epochs,\n",
    "      \"\\nBatch size =\", batch_size,\n",
    "      \"\\nEarly stopping epochs =\", early_stop_iters,\n",
    "      \"\\nLearning rate =\", learning_rate)\n",
    "\n",
    "total_batch = int(window_length / batch_size)\n",
    "validation_fold_error = [] # store validation error of each fold\n",
    "optimal_epochs = []\n",
    "\n",
    "# loop through folds\n",
    "for fold in range(1, len(valIndex)):\n",
    "    validx = train_features[valIndex[fold-1]:valIndex[fold]]\n",
    "    validy = train_target[valIndex[fold-1]:valIndex[fold]]\n",
    "    trainx = train_features[(fold-1)*4:valIndex[(fold-1)]]\n",
    "    trainy = train_target[(fold-1)*4:valIndex[(fold-1)]]\n",
    "\n",
    "    loss_list = [] # store validation loss after each epoch for early stopping\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(total_batch):\n",
    "            # Backprop\n",
    "            batch_xs, batch_ys = next_batch(num=batch_size, data=trainx, labels=trainy)\n",
    "            optimizer.run(feed_dict={x:batch_xs, y:batch_ys, lr:learning_rate})\n",
    "\n",
    "        # Loss\n",
    "        loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "        loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "        loss_list.append(loss_valid)\n",
    "\n",
    "        print(\"Fold: {0:d}\".format(fold),\n",
    "              \" Epoch: {0:d}\".format(epoch+1),\n",
    "              \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "              \" Validation loss = {0:.4f}\".format(np.sqrt(loss_valid)),\n",
    "              \" \\n\")\n",
    "\n",
    "        if all(j <= loss_valid for j in loss_list[-early_stop_iters:]) and len(loss_list)>early_stop_iters:\n",
    "            break\n",
    "    \n",
    "    # Load model with lowest validation error for each fold\n",
    "    epoch_hat = np.argmin(loss_list) + 1\n",
    "    optimal_epochs.append(epoch_hat) # store optimal number of epochs for each fold\n",
    "    \n",
    "    # RMSE\n",
    "    loss_train = sess.run(loss, feed_dict={x:trainx, y:trainy})\n",
    "    loss_valid = sess.run(loss, feed_dict={x:validx, y:validy})\n",
    "    validation_fold_error.append(np.sqrt(loss_valid))\n",
    "    \n",
    "    print(\"Check model:\",\n",
    "          \" Fold: {0:d}\".format(fold),\n",
    "          \" Optimal epoch: {0:d}\".format(epoch_hat),\n",
    "          \" \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average number of epochs: 8\n",
      "Average validation error: 4.2886\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 3. Optimal epoch choice\n",
    "# ==================================\n",
    "# Pick number of epochs to train model for out-of-sample testing\n",
    "epoch_hat = int(np.mean(optimal_epochs))\n",
    "print(\"\\nAverage number of epochs:\", epoch_hat)\n",
    "# Average validation error\n",
    "print(\"Average validation error:\", np.mean(validation_fold_error))\n",
    "\n",
    "# Save validated model\n",
    "saveModel(sess, \n",
    "          MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + str(epoch_hat) + \"_validated\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed scheme:\n",
      "Epoch: 1  Training loss = 1.5836  Test loss = 2.6664  \n",
      "\n",
      "Epoch: 2  Training loss = 1.4861  Test loss = 2.8858  \n",
      "\n",
      "Epoch: 3  Training loss = 1.4348  Test loss = 2.8175  \n",
      "\n",
      "Epoch: 4  Training loss = 1.4101  Test loss = 2.8150  \n",
      "\n",
      "Epoch: 5  Training loss = 1.3994  Test loss = 2.8021  \n",
      "\n",
      "Epoch: 6  Training loss = 1.3918  Test loss = 2.7983  \n",
      "\n",
      "Epoch: 7  Training loss = 1.3854  Test loss = 2.7941  \n",
      "\n",
      "Epoch: 8  Training loss = 1.3799  Test loss = 2.7906  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# 4. Fixed scheme\n",
    "# ==================================\n",
    "print(\"\\nFixed scheme:\")\n",
    "for epoch in range(epoch_hat):\n",
    "    x_train = train_features[-window_length:]\n",
    "    y_train = train_target[-window_length:]\n",
    "    optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:test_features, y:test_target})\n",
    "    print(\"Epoch: {0:d}\".format(epoch+1),\n",
    "          \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "          \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "          \" \\n\")\n",
    "\n",
    "# Forecasts\n",
    "yhat_test_fixed = pred.eval(feed_dict={x:test_features})\n",
    "yhat_train_fixed = pred.eval(feed_dict={x:x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYVzsZmaFcbGbmRXGxW5mVhgXu5lZYf4B4E+TCFGXkyYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc0c3fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train set\n",
    "plt.plot(y_train, 'black')\n",
    "plt.plot(yhat_train_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6bcb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: fixed scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_test_fixed, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed scheme RMSE: 2.79062783363 \n",
      "Fixed scheme MAE:  2.03191961927\n"
     ]
    }
   ],
   "source": [
    "rmse_fixed = np.sqrt(np.mean((yhat_test_fixed[:,0]-test_target)**2))\n",
    "mae_fixed = np.mean(np.abs((yhat_test_fixed[:,0]-test_target)))\n",
    "print(\"Fixed scheme RMSE:\", rmse_fixed,\n",
    "     \"\\nFixed scheme MAE: \", mae_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Stack training and test set, this makes updating scheme easier to train\n",
    "all_features = np.concatenate((train_features[-window_length:], test_features), axis=0)\n",
    "all_target = np.concatenate((train_target[-window_length:], test_target), axis=0)\n",
    "\n",
    "# Vectors to store loss and forecasts\n",
    "test_loss = np.zeros(len(test_target))\n",
    "yhat_update = np.zeros(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test period = 1  Training loss = 1.3799  Test loss = 2.3863  Model updated 0 times  \n",
      "\n",
      "Test period = 2  Training loss = 1.3896  Test loss = 1.8696  Model updated 0 times  \n",
      "\n",
      "Test period = 3  Training loss = 1.4080  Test loss = 0.1720  Model updated 0 times  \n",
      "\n",
      "Test period = 4  Training loss = 1.4080  Test loss = 0.8745  Model updated 0 times  \n",
      "\n",
      "Test period = 5  Training loss = 1.1637  Test loss = 3.3437  Model updated 1 times  \n",
      "\n",
      "Test period = 6  Training loss = 1.2350  Test loss = 0.3360  Model updated 1 times  \n",
      "\n",
      "Test period = 7  Training loss = 1.1709  Test loss = 0.3068  Model updated 1 times  \n",
      "\n",
      "Test period = 8  Training loss = 1.1647  Test loss = 0.1112  Model updated 1 times  \n",
      "\n",
      "Test period = 9  Training loss = 1.0681  Test loss = 0.7575  Model updated 2 times  \n",
      "\n",
      "Test period = 10  Training loss = 1.0722  Test loss = 0.0871  Model updated 2 times  \n",
      "\n",
      "Test period = 11  Training loss = 1.0490  Test loss = 0.5907  Model updated 2 times  \n",
      "\n",
      "Test period = 12  Training loss = 1.0451  Test loss = 1.3805  Model updated 2 times  \n",
      "\n",
      "Test period = 13  Training loss = 1.0134  Test loss = 1.3478  Model updated 3 times  \n",
      "\n",
      "Test period = 14  Training loss = 1.0270  Test loss = 0.8926  Model updated 3 times  \n",
      "\n",
      "Test period = 15  Training loss = 1.0330  Test loss = 2.5090  Model updated 3 times  \n",
      "\n",
      "Test period = 16  Training loss = 1.0788  Test loss = 2.8384  Model updated 3 times  \n",
      "\n",
      "Test period = 17  Training loss = 1.0082  Test loss = 1.3777  Model updated 4 times  \n",
      "\n",
      "Test period = 18  Training loss = 1.0224  Test loss = 0.3333  Model updated 4 times  \n",
      "\n",
      "Test period = 19  Training loss = 1.0221  Test loss = 0.9929  Model updated 4 times  \n",
      "\n",
      "Test period = 20  Training loss = 1.0293  Test loss = 1.1435  Model updated 4 times  \n",
      "\n",
      "Test period = 21  Training loss = 0.9947  Test loss = 0.5802  Model updated 5 times  \n",
      "\n",
      "Test period = 22  Training loss = 0.9930  Test loss = 5.0463  Model updated 5 times  \n",
      "\n",
      "Test period = 23  Training loss = 1.1736  Test loss = 0.7173  Model updated 5 times  \n",
      "\n",
      "Test period = 24  Training loss = 1.1766  Test loss = 1.9396  Model updated 5 times  \n",
      "\n",
      "Test period = 25  Training loss = 1.1093  Test loss = 0.2300  Model updated 6 times  \n",
      "\n",
      "Test period = 26  Training loss = 1.1064  Test loss = 0.6734  Model updated 6 times  \n",
      "\n",
      "Test period = 27  Training loss = 1.1064  Test loss = 0.5242  Model updated 6 times  \n",
      "\n",
      "Test period = 28  Training loss = 1.1032  Test loss = 1.2642  Model updated 6 times  \n",
      "\n",
      "Test period = 29  Training loss = 1.0490  Test loss = 0.9443  Model updated 7 times  \n",
      "\n",
      "Test period = 30  Training loss = 1.0537  Test loss = 0.2492  Model updated 7 times  \n",
      "\n",
      "Test period = 31  Training loss = 1.0537  Test loss = 3.2177  Model updated 7 times  \n",
      "\n",
      "Test period = 32  Training loss = 1.0664  Test loss = 0.8028  Model updated 7 times  \n",
      "\n",
      "Test period = 33  Training loss = 1.0259  Test loss = 1.4679  Model updated 8 times  \n",
      "\n",
      "Test period = 34  Training loss = 1.0419  Test loss = 0.1445  Model updated 8 times  \n",
      "\n",
      "Test period = 35  Training loss = 0.9448  Test loss = 0.7433  Model updated 8 times  \n",
      "\n",
      "Test period = 36  Training loss = 0.9438  Test loss = 7.3860  Model updated 8 times  \n",
      "\n",
      "Test period = 37  Training loss = 1.3145  Test loss = 0.7674  Model updated 9 times  \n",
      "\n",
      "Test period = 38  Training loss = 1.2310  Test loss = 1.2677  Model updated 9 times  \n",
      "\n",
      "Test period = 39  Training loss = 1.2410  Test loss = 1.5380  Model updated 9 times  \n",
      "\n",
      "Test period = 40  Training loss = 1.2538  Test loss = 2.6004  Model updated 9 times  \n",
      "\n",
      "Test period = 41  Training loss = 0.8887  Test loss = 1.0219  Model updated 10 times  \n",
      "\n",
      "Test period = 42  Training loss = 0.8950  Test loss = 1.8989  Model updated 10 times  \n",
      "\n",
      "Test period = 43  Training loss = 0.9254  Test loss = 2.9263  Model updated 10 times  \n",
      "\n",
      "Test period = 44  Training loss = 0.9938  Test loss = 11.7257  Model updated 10 times  \n",
      "\n",
      "Test period = 45  Training loss = 1.7063  Test loss = 5.6370  Model updated 11 times  \n",
      "\n",
      "Test period = 46  Training loss = 1.8438  Test loss = 1.1765  Model updated 11 times  \n",
      "\n",
      "Test period = 47  Training loss = 1.8493  Test loss = 2.4261  Model updated 11 times  \n",
      "\n",
      "Test period = 48  Training loss = 1.8727  Test loss = 2.7421  Model updated 11 times  \n",
      "\n",
      "Test period = 49  Training loss = 1.7315  Test loss = 3.5494  Model updated 12 times  \n",
      "\n",
      "Test period = 50  Training loss = 1.7865  Test loss = 3.8118  Model updated 12 times  \n",
      "\n",
      "Test period = 51  Training loss = 1.8479  Test loss = 1.0091  Model updated 12 times  \n",
      "\n",
      "Test period = 52  Training loss = 1.8521  Test loss = 1.8409  Model updated 12 times  \n",
      "\n",
      "Test period = 53  Training loss = 1.7891  Test loss = 3.5802  Model updated 13 times  \n",
      "\n",
      "Test period = 54  Training loss = 1.8410  Test loss = 3.6958  Model updated 13 times  \n",
      "\n",
      "Test period = 55  Training loss = 1.8972  Test loss = 4.2182  Model updated 13 times  \n",
      "\n",
      "Test period = 56  Training loss = 1.9482  Test loss = 0.6092  Model updated 13 times  \n",
      "\n",
      "Test period = 57  Training loss = 1.6805  Test loss = 0.4870  Model updated 14 times  \n",
      "\n",
      "Test period = 58  Training loss = 1.6815  Test loss = 2.1460  Model updated 14 times  \n",
      "\n",
      "Test period = 59  Training loss = 1.6876  Test loss = 0.5623  Model updated 14 times  \n",
      "\n",
      "Test period = 60  Training loss = 1.6881  Test loss = 0.9201  Model updated 14 times  \n",
      "\n",
      "Test period = 61  Training loss = 1.6374  Test loss = 0.1122  Model updated 15 times  \n",
      "\n",
      "Test period = 62  Training loss = 1.6373  Test loss = 1.8444  Model updated 15 times  \n",
      "\n",
      "Test period = 63  Training loss = 1.6493  Test loss = 0.2036  Model updated 15 times  \n",
      "\n",
      "Test period = 64  Training loss = 1.6474  Test loss = 0.1837  Model updated 15 times  \n",
      "\n",
      "Test period = 65  Training loss = 1.6214  Test loss = 0.0685  Model updated 16 times  \n",
      "\n",
      "Test period = 66  Training loss = 1.6197  Test loss = 2.3078  Model updated 16 times  \n",
      "\n",
      "Test period = 67  Training loss = 1.6448  Test loss = 0.1284  Model updated 16 times  \n",
      "\n",
      "Test period = 68  Training loss = 1.6449  Test loss = 2.6680  Model updated 16 times  \n",
      "\n",
      "Test period = 69  Training loss = 1.6276  Test loss = 3.8191  Model updated 17 times  \n",
      "\n",
      "Test period = 70  Training loss = 1.6951  Test loss = 0.1572  Model updated 17 times  \n",
      "\n",
      "Test period = 71  Training loss = 1.6952  Test loss = 3.6016  Model updated 17 times  \n",
      "\n",
      "Test period = 72  Training loss = 1.7520  Test loss = 1.7101  Model updated 17 times  \n",
      "\n",
      "Test period = 73  Training loss = 1.6655  Test loss = 1.8732  Model updated 18 times  \n",
      "\n",
      "Test period = 74  Training loss = 1.6803  Test loss = 1.0152  Model updated 18 times  \n",
      "\n",
      "Test period = 75  Training loss = 1.6841  Test loss = 0.1870  Model updated 18 times  \n",
      "\n",
      "Test period = 76  Training loss = 1.6829  Test loss = 1.3724  Model updated 18 times  \n",
      "\n",
      "Test period = 77  Training loss = 1.6798  Test loss = 2.0830  Model updated 19 times  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrain_count = 0\n",
    "for t in range(len(test_target)):\n",
    "    x_test = np.reshape(test_features[t], newshape=(1,4,3))\n",
    "    y_test = test_target[t]\n",
    "    test_loss[t] = np.sqrt(sess.run(loss, feed_dict={x:x_test, y:y_test}))\n",
    "    yhat_update[t] = pred.eval(feed_dict={x:x_test})\n",
    "\n",
    "    x_train = all_features[t:(window_length+t)]\n",
    "    y_train = all_target[t:(window_length+t)]\n",
    "\n",
    "    loss_train = sess.run(loss, feed_dict={x:x_train, y:y_train})\n",
    "    loss_test = sess.run(loss, feed_dict={x:x_test, y:y_test})\n",
    "    \n",
    "    print(\"Test period = {0:d}\".format(t+1),\n",
    "      \" Training loss = {0:.4f}\".format(np.sqrt(loss_train)),\n",
    "      \" Test loss = {0:.4f}\".format(np.sqrt(loss_test)),\n",
    "      \" Model updated {0:d} times\".format(retrain_count),\n",
    "      \" \\n\")\n",
    "\n",
    "    if (t+1)%4==0:\n",
    "        retrain_count += 1\n",
    "        for epoch in range(epoch_hat):\n",
    "            for i in range(total_batch):\n",
    "                optimizer.run(feed_dict={x:x_train, y:y_train, lr:learning_rate})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkYU9SZKky8jCniRJ0mX8A18JkR/9Ycs/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc6220f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test set: updating scheme\n",
    "plt.plot(test_target, 'black')\n",
    "plt.plot(yhat_update, 'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating scheme RMSE: 2.53600641321 \n",
      "Updating scheme MAE:  1.75422506062\n"
     ]
    }
   ],
   "source": [
    "rmse_update = np.sqrt(np.mean((yhat_update-test_target)**2))\n",
    "mae_update = np.mean(np.abs((yhat_update-test_target)))\n",
    "print(\"Updating scheme RMSE:\", rmse_update,\n",
    "     \"\\nUpdating scheme MAE: \", mae_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_test_fixed.csv\", yhat_test_fixed)\n",
    "np.savetxt(MODEL_FILENAME + \"lr_\" + str(learning_rate) + \"/\" + \"yhat_update.csv\", yhat_update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
